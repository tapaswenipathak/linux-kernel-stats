commit aa4800e31c547ed00681318335ca2298c4bca33a
Merge: dcde56bb37a9 4ff17c448a7b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Dec 16 13:21:20 2022 -0600

    Merge tag 'perf-tools-for-v6.2-1-2022-12-16' of git://git.kernel.org/pub/scm/linux/kernel/git/acme/linux
    
    Pull perf tools updates from Arnaldo Carvalho de Melo:
     "Libraries:
    
       - Drop the old copy of libtraceevent in tools/lib/traceevent/ now
         that all major distros ship it from its external repository.
    
         This is now just another feature detection, emitting a warning when
         the libtraceevent-dev[el] package isn't installed, disabling the
         build of perf features and tools that strictly require parsing
         things from tracefs while keeping the core functionality present
         and working with a subset of the events, the most used ones like
         CPU cycles, hardware cache and also vendor events, etc.
    
         This was tested with lots of containers for Fedora, Debian,
         OpenSUSE, Alpine Linux, Ubuntu, with cross builds, etc.
    
      Build:
    
       - Update to C standard to gnu11, like was done for the kernel.
    
       - Install the tools/lib/ libraries locally instead of having headers
         searched directly from the source code directories, to help the
         cases where we can build either from in-kernel source libraries or
         from the same library shipped as a distro package, as is the case
         with libbpf and was the case with libtraceevent.
    
      perf stat:
    
       - Do not delay the workload with --delay, the delay is just for
         starting to count the events, to skip noise at workload startup.
    
       - When we have events for each cgroup, the metric should be printed
         for each cgroup separately.
    
            $ perf stat -a --for-each-cgroup system.slice,user.slice --metric-only sleep 1
    
            Performance counter stats for 'system wide':
    
                            GHz  insn per cycle  branch-misses of all branches
            system.slice  3.792      0.61                  3.24%
            user.slice    3.661      2.32                  0.37%
    
       - Fix printing field separator in CSV metrics output.
    
       - Fix --metric-only --json output.
    
       - Fix summary output in CSV with --metric-only.
    
       - Update event group check for support of uncore event.
    
      perf test:
    
       - Stop requiring a C toolchain in shell tests, instead add a workload
         option that has all the previously C snippets built as part of
         'perf test -w' that then get used in the 'perf test' shell scripts.
    
       - Add event group test for events in multiple PMUs
    
       - The "kernel lock contention analysis" test should not print
         warnings in quiet mode.
    
       - Add attr tests for ARM64's new VG register.
    
       - Fix record test on KVM guests, as using precise flag with the
         br_inst_retired.near_call event causes the test fail on KVM guests,
         even when the guests have PMU forwarding enabled and the event
         itself is supported, so just remove the precise flag from the
         event.
    
       - Add mechanism for skipping attr tests on specific kernel versions
         where it is known that these checks will fail.
    
       - Skip watchpoint tests if no watchpoints available.
    
       - Add more Intel PT 'perf test' entries: hybrid CPUs, split the
         packet decoder into a suite of subtests.
    
      perf script:
    
       - Introduce task analyzer python script, where one first records some events:
    
         Recording can be done in two ways:
    
            $ perf script record tasks-analyzer -- sleep 10
            $ perf record -e sched:sched_switch -a -- sleep 10
    
         The script can parse any perf.data files, as long as it has
         sched:sched_switch events, other events will be ignored.
    
         The most simple report use case is to just call the script without
         arguments.
    
         Runtime is the time the task was running on the CPU, Time Out-In is
         the time between the process being scheduled *out* and scheduled
         back *in*. So the last time span between two executions:
    
            $ perf script report tasks-analyzer
                Switched-In     Switched-Out CPU    PID    TID             Comm  Runtime  Time Out-In
            15576.658891407  15576.659156086   4   2412   2428            gdbus      265         1949
            15576.659111320  15576.659455410   0   2412   2412      gnome-shell      344         2267
            15576.659491326  15576.659506173   2     74     74      kworker/2:1       15        13145
            15576.659506173  15576.659825748   2   2858   2858  gnome-terminal-      320        63263
            15576.659871270  15576.659902872   6  20932  20932    kworker/u16:0       32      2314582
            15576.659909951  15576.659945501   3  27264  27264               sh       36           -1
            15576.659853285  15576.659971052   7  27265  27265             perf      118      5050741
            [...]
    
      perf lock:
    
       - Allow concurrent record and report to support live monitoring of
         kernel lock contention without BPF:
    
            # perf lock record -a -o- sleep 1 | perf lock contention -i-
             contended   total wait     max wait     avg wait         type   caller
    
                     2     10.27 us      6.17 us      5.13 us     spinlock   load_balance+0xc03
                     1      5.29 us      5.29 us      5.29 us     rwlock:W   ep_scan_ready_list+0x54
                     1      4.12 us      4.12 us      4.12 us     spinlock   smpboot_thread_fn+0x116
                     1      3.28 us      3.28 us      3.28 us        mutex   pipe_read+0x50
    
       - Implement -t/--threads option when using BPF:
    
            $ sudo ./perf lock contention -abt -E 5 sleep 1
             contended  total wait   max wait   avg wait      pid  comm
    
                     1   740.66 ms  740.66 ms  740.66 ms     1950  nv_queue
                     3   305.50 ms  298.19 ms  101.83 ms     1884  nvidia-modeset/
                     1    25.14 us   25.14 us   25.14 us  2725038  EventManager_De
                    12    23.09 us    9.30 us    1.92 us        0  swapper
                     1    20.18 us   20.18 us   20.18 us  2725033  EventManager_De
    
       - Add -l/--lock-addr to aggregate per-lock-instance contention:
    
            $ sudo ./perf lock contention -abl sleep 1
             contended  total wait  max wait  avg wait           address  symbol
    
                     1    36.28 us  36.28 us  36.28 us  ffff92615d6448b8
                     9    10.91 us   1.84 us   1.21 us  ffffffffbaed50c0  rcu_state
                     1    10.49 us  10.49 us  10.49 us  ffff9262ac4f0c80
                     8     4.68 us   1.67 us    585 ns  ffffffffbae07a40  jiffies_lock
                     3     3.03 us   1.45 us   1.01 us  ffff9262277861e0
                     1      924 ns    924 ns    924 ns  ffff926095ba9d20
                     1      436 ns    436 ns    436 ns  ffff9260bfda4f60
    
      perf record:
    
       - Add remaining branch filters: "no_cycles", "no_flags" & "hw_index",
         to be used with hardware such as Intel's LBR that allows things
         like stitching stacks of two samples to overcome the limits of the
         number of LBR registers.
    
      Symbol resolution:
    
       - Handle .debug files created with 'objcopy --only-keep-debug', where
         program headers are zeroed and thus can't be used for adjustments,
         use the info in the runtime_ss (runtime ELF) instead.
    
      perf trace:
    
       - Add BPF based augmenter for the 'perf_event_open's 'struct
         perf_event_attr' argument.
    
       - Add BPF based augmenter for the 'clock_gettime's 'struct timespec'
         argument.
    
       - In both cases the syscall tracepoint has just the pointer value, we
         need to hook a BPF program to collect the pointer contents, and
         then, in userspace, pretty print it in 'perf trace'.
    
      perf list:
    
       - Introduce JSON output of events.
    
       - Streamline how the expression specifying what events should be
         shown is handled, fixing several corner cases, such as the metric
         filter that is specified as a glob but was using strstr().
    
      perf probe:
    
       - Fix to avoid crashing if DW_AT_decl_file is NULL, coping with clang
         generating DWARF5 like that.
    
       - Use dwarf_attr_integrate() as generic DWARF attr accessor as it
         supersedes dwarf_attr(), supporting abstact origin DIEs.
    
      perf inject:
    
       - Set PERF_RECORD_MISC_BUILD_ID_SIZE in the PERF_RECORD_HEADER_BUILD_ID
         so that perf.data readers can get the real build-id size and avoid
         trailing zeroes.
    
      perf data:
    
       - Add tracepoint fields when converting a perf.data file to JSON.
    
      arm64:
    
       - Fix mksyscalltbl, don't lose syscalls due to sort -nu.
    
       - Add Arm Neoverse V2 PMU events.
    
      riscv:
    
       - Add riscv sbi firmware std event files.
    
       - Add Sifive U74 vendor events (JSON) file.
    
       - Add some more events and metrics for Alderlake/Alderlake-N.
    
      Documentation:
    
       - Add data documentation for the PMU structs in the C source code.
    
      Miscellaneous:
    
       - Periodic sanitization of headers, adding missing includes, removing
         needless ones, creating new ones, etc.
    
       - Use sig_atomic_t for signal handlers to avoid undefined behaviour
         in all perf tools.
    
       - Fixes for libbpf 1.0+ compatibility (maps, etc) on 'perf trace' BPF
         examples.
    
       - Remove some old perf bpf examples, leave the best ones that
         demonstrate how to associate BPF functions to points in the kernel.
    
       - Make quiet mode consistent between tools.
    
       - Use dedicated non-atomic clear/set bit helpers.
    
       - Use "grep -E" instead of "egrep" as recommended by warning emitted
         by GNU grep since at least version 3.8.
    
       - Complete list of supported subcommands in the 'perf daemon' help
         message.
    
       - Update John Garry's email address for arm64 perf tooling on the
         MAINTAINERS file, he moved from Huawei to Oracle"
    
    * tag 'perf-tools-for-v6.2-1-2022-12-16' of git://git.kernel.org/pub/scm/linux/kernel/git/acme/linux: (239 commits)
      libperf: Fix install_pkgconfig target
      perf tools: Use "grep -E" instead of "egrep"
      perf stat: Do not delay the workload with --delay
      perf evlist: Remove group option.
      perf build: Fix python/perf.so library's name
      perf test arm64: Add attr tests for new VG register
      perf test: Add mechanism for skipping attr tests on kernel versions
      perf test: Add mechanism for skipping attr tests on auxiliary vector values
      perf test: Add ability to test exit code for attr tests
      perf test: add new task-analyzer tests
      perf script: task-analyzer add csv support
      perf script: Introduce task analyzer python script
      perf cs-etm: Print auxtrace info even if OpenCSD isn't linked
      perf cs-etm: Cleanup cs_etm__process_auxtrace_info()
      perf cs-etm: Tidy up auxtrace info header printing
      perf cs-etm: Remove unused stub methods
      perf cs-etm: Print unknown header version as an error
      perf test: Update perf lock contention test
      perf lock contention: Add -l/--lock-addr option
      perf lock contention: Implement -t/--threads option for BPF
      ...

commit dff9b25cb97783936de6b6d53129c32fcd5edd01
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Tue Nov 8 10:13:23 2022 -0700

    RISC-V: vdso: Do not add missing symbols to version section in linker script
    
    [ Upstream commit fcae44fd36d052e956e69a64642fc03820968d78 ]
    
    Recently, ld.lld moved from '--undefined-version' to
    '--no-undefined-version' as the default, which breaks the compat vDSO
    build:
    
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_gettimeofday' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_gettime' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_getres' failed: symbol not defined
    
    These symbols are not present in the compat vDSO or the regular vDSO for
    32-bit but they are unconditionally included in the version section of
    the linker script, which is prohibited with '--no-undefined-version'.
    
    Fix this issue by only including the symbols that are actually exported
    in the version section of the linker script.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/1756
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Tested-by: Conor Dooley <conor.dooley@microchip.com>
    Link: https://lore.kernel.org/r/20221108171324.3377226-1-nathan@kernel.org/
    Signed-off-by: Palmer Dabbelt <palmer@rivosinc.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 43060827aec251418fccce4d8cc7038a161a97ca
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Tue Nov 8 10:13:23 2022 -0700

    RISC-V: vdso: Do not add missing symbols to version section in linker script
    
    [ Upstream commit fcae44fd36d052e956e69a64642fc03820968d78 ]
    
    Recently, ld.lld moved from '--undefined-version' to
    '--no-undefined-version' as the default, which breaks the compat vDSO
    build:
    
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_gettimeofday' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_gettime' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_getres' failed: symbol not defined
    
    These symbols are not present in the compat vDSO or the regular vDSO for
    32-bit but they are unconditionally included in the version section of
    the linker script, which is prohibited with '--no-undefined-version'.
    
    Fix this issue by only including the symbols that are actually exported
    in the version section of the linker script.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/1756
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Tested-by: Conor Dooley <conor.dooley@microchip.com>
    Link: https://lore.kernel.org/r/20221108171324.3377226-1-nathan@kernel.org/
    Signed-off-by: Palmer Dabbelt <palmer@rivosinc.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0454ad3f63f02cca534e9238cc0bddf7ffefcfe2
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Tue Nov 8 10:13:23 2022 -0700

    RISC-V: vdso: Do not add missing symbols to version section in linker script
    
    [ Upstream commit fcae44fd36d052e956e69a64642fc03820968d78 ]
    
    Recently, ld.lld moved from '--undefined-version' to
    '--no-undefined-version' as the default, which breaks the compat vDSO
    build:
    
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_gettimeofday' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_gettime' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_getres' failed: symbol not defined
    
    These symbols are not present in the compat vDSO or the regular vDSO for
    32-bit but they are unconditionally included in the version section of
    the linker script, which is prohibited with '--no-undefined-version'.
    
    Fix this issue by only including the symbols that are actually exported
    in the version section of the linker script.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/1756
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Tested-by: Conor Dooley <conor.dooley@microchip.com>
    Link: https://lore.kernel.org/r/20221108171324.3377226-1-nathan@kernel.org/
    Signed-off-by: Palmer Dabbelt <palmer@rivosinc.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 144452b42143c380d5b59a694cc66ce91afc84aa
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Tue Nov 8 10:13:23 2022 -0700

    RISC-V: vdso: Do not add missing symbols to version section in linker script
    
    [ Upstream commit fcae44fd36d052e956e69a64642fc03820968d78 ]
    
    Recently, ld.lld moved from '--undefined-version' to
    '--no-undefined-version' as the default, which breaks the compat vDSO
    build:
    
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_gettimeofday' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_gettime' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_getres' failed: symbol not defined
    
    These symbols are not present in the compat vDSO or the regular vDSO for
    32-bit but they are unconditionally included in the version section of
    the linker script, which is prohibited with '--no-undefined-version'.
    
    Fix this issue by only including the symbols that are actually exported
    in the version section of the linker script.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/1756
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Tested-by: Conor Dooley <conor.dooley@microchip.com>
    Link: https://lore.kernel.org/r/20221108171324.3377226-1-nathan@kernel.org/
    Signed-off-by: Palmer Dabbelt <palmer@rivosinc.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c0bb600f076832764b43ae4ef6ee003d9a71f7f9
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Tue Nov 8 10:13:23 2022 -0700

    RISC-V: vdso: Do not add missing symbols to version section in linker script
    
    [ Upstream commit fcae44fd36d052e956e69a64642fc03820968d78 ]
    
    Recently, ld.lld moved from '--undefined-version' to
    '--no-undefined-version' as the default, which breaks the compat vDSO
    build:
    
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_gettimeofday' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_gettime' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_getres' failed: symbol not defined
    
    These symbols are not present in the compat vDSO or the regular vDSO for
    32-bit but they are unconditionally included in the version section of
    the linker script, which is prohibited with '--no-undefined-version'.
    
    Fix this issue by only including the symbols that are actually exported
    in the version section of the linker script.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/1756
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Tested-by: Conor Dooley <conor.dooley@microchip.com>
    Link: https://lore.kernel.org/r/20221108171324.3377226-1-nathan@kernel.org/
    Signed-off-by: Palmer Dabbelt <palmer@rivosinc.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fcae44fd36d052e956e69a64642fc03820968d78
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Tue Nov 8 10:13:23 2022 -0700

    RISC-V: vdso: Do not add missing symbols to version section in linker script
    
    Recently, ld.lld moved from '--undefined-version' to
    '--no-undefined-version' as the default, which breaks the compat vDSO
    build:
    
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_gettimeofday' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_gettime' failed: symbol not defined
      ld.lld: error: version script assignment of 'LINUX_4.15' to symbol '__vdso_clock_getres' failed: symbol not defined
    
    These symbols are not present in the compat vDSO or the regular vDSO for
    32-bit but they are unconditionally included in the version section of
    the linker script, which is prohibited with '--no-undefined-version'.
    
    Fix this issue by only including the symbols that are actually exported
    in the version section of the linker script.
    
    Link: https://github.com/ClangBuiltLinux/linux/issues/1756
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Tested-by: Conor Dooley <conor.dooley@microchip.com>
    Link: https://lore.kernel.org/r/20221108171324.3377226-1-nathan@kernel.org/
    Signed-off-by: Palmer Dabbelt <palmer@rivosinc.com>

commit 6ac73820993c13f30d226f9521f8ffae62acdf42
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Nov 10 15:30:10 2022 -0300

    perf trace: Add augmenter for clock_gettime's rqtp timespec arg
    
    One more before going the BTF way:
    
      # perf trace -e /home/acme/git/perf/tools/perf/examples/bpf/augmented_raw_syscalls.o,*nanosleep
             ? pool-gsd-smart/2893  ... [continued]: clock_nanosleep())    = 0
             ? gpm/1042  ... [continued]: clock_nanosleep())    = 0
         1.232 pool-gsd-smart/2893 clock_nanosleep(rqtp: { .tv_sec: 1, .tv_nsec: 0 }, rmtp: 0x7f64d7ffec50) ...
         1.232 pool-gsd-smart/2893  ... [continued]: clock_nanosleep())    = 0
       327.329 gpm/1042 clock_nanosleep(rqtp: { .tv_sec: 2, .tv_nsec: 0 }, rmtp: 0x7ffddfd1cf20) ...
      1002.482 pool-gsd-smart/2893 clock_nanosleep(rqtp: { .tv_sec: 1, .tv_nsec: 0 }, rmtp: 0x7f64d7ffec50) = 0
       327.329 gpm/1042  ... [continued]: clock_nanosleep())    = 0
      2003.947 pool-gsd-smart/2893 clock_nanosleep(rqtp: { .tv_sec: 1, .tv_nsec: 0 }, rmtp: 0x7f64d7ffec50) ...
      2003.947 pool-gsd-smart/2893  ... [continued]: clock_nanosleep())    = 0
      2327.858 gpm/1042 clock_nanosleep(rqtp: { .tv_sec: 2, .tv_nsec: 0 }, rmtp: 0x7ffddfd1cf20) ...
             ? crond/1384  ... [continued]: clock_nanosleep())    = 0
      3005.382 pool-gsd-smart/2893 clock_nanosleep(rqtp: { .tv_sec: 1, .tv_nsec: 0 }, rmtp: 0x7f64d7ffec50) ...
      3005.382 pool-gsd-smart/2893  ... [continued]: clock_nanosleep())    = 0
      3675.633 crond/1384 clock_nanosleep(rqtp: { .tv_sec: 60, .tv_nsec: 0 }, rmtp: 0x7ffcc02b66b0) ...
    ^C#
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit d942f231afc037490538cea67bb0c667e6d12214
Author: Guo Ren <guoren@kernel.org>
Date:   Thu Nov 3 04:04:51 2022 -0400

    selftests/vDSO: Add riscv getcpu & gettimeofday test
    
    Enable vDSO getcpu & gettimeofday test for riscv. But only riscv64
    supports __vdso_gettimeofday and riscv32 is under development.
    
    VERSION
    {
            LINUX_4.15 {
            global:
                    __vdso_rt_sigreturn;
                    __vdso_gettimeofday;
                    __vdso_clock_gettime;
                    __vdso_clock_getres;
                    __vdso_getcpu;
                    __vdso_flush_icache;
            local: *;
            };
    }
    
    Co-developed-by: haocheng.zy <haocheng.zy@linux.alibaba.com>
    Signed-off-by: haocheng.zy <haocheng.zy@linux.alibaba.com>
    Suggested-by: Mao Han <han_mao@linux.alibaba.com>
    Reviewed-by: Shuah Khan <skhan@linuxfoundation.org>
    Signed-off-by: Guo Ren <guoren@linux.alibaba.com>
    Signed-off-by: Guo Ren <guoren@kernel.org>
    Cc: Paul Walmsley <paul.walmsley@sifive.com>
    Cc: Palmer Dabbelt <palmer@dabbelt.com>
    Cc: Elliott Hughes <enh@google.com>
    Signed-off-by: Shuah Khan <skhan@linuxfoundation.org>

commit aa06a9bd853306c239f759018fb227d7e8f4e203
Author: Sergei Trofimovich <slyich@gmail.com>
Date:   Sat Aug 20 19:18:13 2022 +0100

    ia64: fix clock_getres(CLOCK_MONOTONIC) to report ITC frequency
    
    clock_gettime(CLOCK_MONOTONIC, &tp) is very precise on ia64 as it uses ITC
    (similar to rdtsc on x86).  It's not quite a hrtimer as it is a few times
    slower than 1ns.  Usually 2-3ns.
    
    clock_getres(CLOCK_MONOTONIC, &res) never reflected that fact and reported
    0.04s precision (1/HZ value).
    
    In https://bugs.gentoo.org/596382 gstreamer's test suite failed loudly
    when it noticed precision discrepancy.
    
    Before the change:
    
        clock_getres(CLOCK_MONOTONIC, &res) reported 250Hz precision.
    
    After the change:
    
        clock_getres(CLOCK_MONOTONIC, &res) reports ITC (400Mhz) precision.
    
    The patch is based on matoro's fix. I added a bit of explanation why we
    need to special-case arch-specific clock_getres().
    
    [akpm@linux-foundation.org: coding-style cleanups]
    Link: https://lkml.kernel.org/r/20220820181813.2275195-1-slyich@gmail.com
    Signed-off-by: Sergei Trofimovich <slyich@gmail.com>
    Cc: matoro <matoro_mailinglist_kernel@matoro.tk>
    Cc: Émeric Maschino <emeric.maschino@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

commit 6fbc49b7f007823f5dbe8f178f69c951183112d3
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:51 2019 +0000

    lib/vdso: Mark do_hres() and do_coarse() as __always_inline
    
    [ Upstream commit c966533f8c6c45f93c52599f8460e7695f0b7eaa ]
    
    Performance numbers for Intel(R) Core(TM) i5-6300U CPU @ 2.40GHz
    (more clock_gettime() cycles - the better):
    
    clock            | before     | after      | diff
    ----------------------------------------------------------
    monotonic        |  153222105 |  166775025 | 8.8%
    monotonic-coarse |  671557054 |  691513017 | 3.0%
    monotonic-raw    |  147116067 |  161057395 | 9.5%
    boottime         |  153446224 |  166962668 | 9.1%
    
    The improvement for arm64 for monotonic and boottime is around 3.5%.
    
    clock            | before     | after      | diff
    ==================================================
    monotonic          17326692     17951770     3.6%
    monotonic-coarse   43624027     44215292     1.3%
    monotonic-raw      17541809     17554932     0.1%
    boottime           17334982     17954361     3.5%
    
    [ tglx: Avoid the goto ]
    
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-3-dima@arista.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 84e762060147582912581fd99cb25f3559ec8c22
Author: Huacai Chen <chenhuacai@loongson.cn>
Date:   Thu Aug 25 19:34:59 2022 +0800

    LoongArch: Fix build warnings in VDSO
    
    Fix build warnings in VDSO as below:
    
    arch/loongarch/vdso/vgettimeofday.c:9:5: warning: no previous prototype for '__vdso_clock_gettime' [-Wmissing-prototypes]
        9 | int __vdso_clock_gettime(clockid_t clock,
          |     ^~~~~~~~~~~~~~~~~~~~
    arch/loongarch/vdso/vgettimeofday.c:15:5: warning: no previous prototype for '__vdso_gettimeofday' [-Wmissing-prototypes]
       15 | int __vdso_gettimeofday(struct __kernel_old_timeval *tv,
          |     ^~~~~~~~~~~~~~~~~~~
    arch/loongarch/vdso/vgettimeofday.c:21:5: warning: no previous prototype for '__vdso_clock_getres' [-Wmissing-prototypes]
       21 | int __vdso_clock_getres(clockid_t clock_id,
          |     ^~~~~~~~~~~~~~~~~~~
    arch/loongarch/vdso/vgetcpu.c:27:5: warning: no previous prototype for '__vdso_getcpu' [-Wmissing-prototypes]
       27 | int __vdso_getcpu(unsigned int *cpu, unsigned int *node, struct getcpu_cache *unused)
    
    Reported-by: kernel test robot <lkp@intel.com>
    Signed-off-by: Huacai Chen <chenhuacai@loongson.cn>

commit f6eb0fed6a3957c0b93e3a00c1ffaad84d4ffc31
Merge: c5f1e32e3231 e362359ace6f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 13 14:38:22 2022 -0700

    Merge tag 'timers-urgent-2022-08-13' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer fixes from Ingo Molnar:
     "Misc timer fixes:
    
       - fix a potential use-after-free bug in posix timers
    
       - correct a prototype
    
       - address a build warning"
    
    * tag 'timers-urgent-2022-08-13' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      posix-cpu-timers: Cleanup CPU timers before freeing them during exec
      time: Correct the prototype of ns_to_kernel_old_timeval and ns_to_timespec64
      posix-timers: Make do_clock_gettime() static

commit 221f9d9cdf429df8c3843b4291f4f412fde11543
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Tue Jul 19 10:56:20 2022 +0200

    posix-timers: Make do_clock_gettime() static
    
    do_clock_gettime() is used only in posix-stubs.c, so make it static. It avoids
    a compiler warning too:
    time/posix-stubs.c:73:5: warning: no previous prototype for ‘do_clock_gettime’ [-Wmissing-prototypes]
    
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20220719085620.30567-1-jslaby@suse.cz

commit 9777de28cfea449d5a7d18a90205aaa32c9a088c
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 61967ac7ba2814fefd033eb3979058057a18edc1
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b557d3b3608da6e2338821264344ae7f2403ce02
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a81340705c9754bbb812c8191c42d6643b9de8c6
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8e9fccee26d2a5cb9baad50b18549038db4b209b
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 737b14e49070dfed30f7559b7834ca2fb73b9688
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 35abf2081fa9fa6cd23f5975f35b41a3f0647cc4
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    [ Upstream commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9 ]
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 12441ccdf5e2f5a01a46e344976cbbd3d46845c9
Author: Randy Dunlap <rdunlap@infradead.org>
Date:   Sun Mar 13 18:27:25 2022 -0700

    x86: Fix return value of __setup handlers
    
    __setup() handlers should return 1 to obsolete_checksetup() in
    init/main.c to indicate that the boot option has been handled. A return
    of 0 causes the boot option/value to be listed as an Unknown kernel
    parameter and added to init's (limited) argument (no '=') or environment
    (with '=') strings. So return 1 from these x86 __setup handlers.
    
    Examples:
    
      Unknown kernel command line parameters "apicpmtimer
        BOOT_IMAGE=/boot/bzImage-517rc8 vdso=1 ring3mwait=disable", will be
        passed to user space.
    
      Run /sbin/init as init process
       with arguments:
         /sbin/init
         apicpmtimer
       with environment:
         HOME=/
         TERM=linux
         BOOT_IMAGE=/boot/bzImage-517rc8
         vdso=1
         ring3mwait=disable
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Fixes: 77b52b4c5c66 ("x86: add "debugpat" boot option")
    Fixes: e16fd002afe2 ("x86/cpufeature: Enable RING3MWAIT for Knights Landing")
    Fixes: b8ce33590687 ("x86_64: convert to clock events")
    Reported-by: Igor Zhbanov <i.zhbanov@omprussia.ru>
    Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/64644a2f-4a20-bab3-1e15-3b2cdd0defe3@omprussia.ru
    Link: https://lore.kernel.org/r/20220314012725.26661-1-rdunlap@infradead.org

commit 6d65028eb67dbb7627651adfc460d64196d38bd8
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Mon May 2 22:50:10 2022 +1000

    powerpc/vdso: Fix incorrect CFI in gettimeofday.S
    
    As reported by Alan, the CFI (Call Frame Information) in the VDSO time
    routines is incorrect since commit ce7d8056e38b ("powerpc/vdso: Prepare
    for switching VDSO to generic C implementation.").
    
    DWARF has a concept called the CFA (Canonical Frame Address), which on
    powerpc is calculated as an offset from the stack pointer (r1). That
    means when the stack pointer is changed there must be a corresponding
    CFI directive to update the calculation of the CFA.
    
    The current code is missing those directives for the changes to r1,
    which prevents gdb from being able to generate a backtrace from inside
    VDSO functions, eg:
    
      Breakpoint 1, 0x00007ffff7f804dc in __kernel_clock_gettime ()
      (gdb) bt
      #0  0x00007ffff7f804dc in __kernel_clock_gettime ()
      #1  0x00007ffff7d8872c in clock_gettime@@GLIBC_2.17 () from /lib64/libc.so.6
      #2  0x00007fffffffd960 in ?? ()
      #3  0x00007ffff7d8872c in clock_gettime@@GLIBC_2.17 () from /lib64/libc.so.6
      Backtrace stopped: frame did not save the PC
    
    Alan helpfully describes some rules for correctly maintaining the CFI information:
    
      1) Every adjustment to the current frame address reg (ie. r1) must be
         described, and exactly at the instruction where r1 changes. Why?
         Because stack unwinding might want to access previous frames.
    
      2) If a function changes LR or any non-volatile register, the save
         location for those regs must be given. The CFI can be at any
         instruction after the saves up to the point that the reg is
         changed.
         (Exception: LR save should be described before a bl. not after)
    
      3) If asychronous unwind info is needed then restores of LR and
         non-volatile regs must also be described. The CFI can be at any
         instruction after the reg is restored up to the point where the
         save location is (potentially) trashed.
    
    Fix the inability to backtrace by adding CFI directives describing the
    changes to r1, ie. satisfying rule 1.
    
    Also change the information for LR to point to the copy saved on the
    stack, not the value in r0 that will be overwritten by the function
    call.
    
    Finally, add CFI directives describing the save/restore of r2.
    
    With the fix gdb can correctly back trace and navigate up and down the stack:
    
      Breakpoint 1, 0x00007ffff7f804dc in __kernel_clock_gettime ()
      (gdb) bt
      #0  0x00007ffff7f804dc in __kernel_clock_gettime ()
      #1  0x00007ffff7d8872c in clock_gettime@@GLIBC_2.17 () from /lib64/libc.so.6
      #2  0x0000000100015b60 in gettime ()
      #3  0x000000010000c8bc in print_long_format ()
      #4  0x000000010000d180 in print_current_files ()
      #5  0x00000001000054ac in main ()
      (gdb) up
      #1  0x00007ffff7d8872c in clock_gettime@@GLIBC_2.17 () from /lib64/libc.so.6
      (gdb)
      #2  0x0000000100015b60 in gettime ()
      (gdb)
      #3  0x000000010000c8bc in print_long_format ()
      (gdb)
      #4  0x000000010000d180 in print_current_files ()
      (gdb)
      #5  0x00000001000054ac in main ()
      (gdb)
      Initial frame selected; you cannot go up.
      (gdb) down
      #4  0x000000010000d180 in print_current_files ()
      (gdb)
      #3  0x000000010000c8bc in print_long_format ()
      (gdb)
      #2  0x0000000100015b60 in gettime ()
      (gdb)
      #1  0x00007ffff7d8872c in clock_gettime@@GLIBC_2.17 () from /lib64/libc.so.6
      (gdb)
      #0  0x00007ffff7f804dc in __kernel_clock_gettime ()
      (gdb)
    
    Fixes: ce7d8056e38b ("powerpc/vdso: Prepare for switching VDSO to generic C implementation.")
    Cc: stable@vger.kernel.org # v5.11+
    Reported-by: Alan Modra <amodra@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Reviewed-by: Segher Boessenkool <segher@kernel.crashing.org>
    Link: https://lore.kernel.org/r/20220502125010.1319370-1-mpe@ellerman.id.au

commit 9cb90f9ad5975ddfc90d0906b40e9c71c2eca44e
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Mon Mar 14 12:48:42 2022 -0700

    x86/Kconfig: Do not allow CONFIG_X86_X32_ABI=y with llvm-objcopy
    
    [ Upstream commit aaeed6ecc1253ce1463fa1aca0b70a4ccbc9fa75 ]
    
    There are two outstanding issues with CONFIG_X86_X32_ABI and
    llvm-objcopy, with similar root causes:
    
    1. llvm-objcopy does not properly convert .note.gnu.property when going
       from x86_64 to x86_x32, resulting in a corrupted section when
       linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/1141
    
    2. llvm-objcopy produces corrupted compressed debug sections when going
       from x86_64 to x86_x32, also resulting in an error when linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/514
    
    After commit 41c5ef31ad71 ("x86/ibt: Base IBT bits"), the
    .note.gnu.property section is always generated when
    CONFIG_X86_KERNEL_IBT is enabled, which causes the first issue to become
    visible with an allmodconfig build:
    
      ld.lld: error: arch/x86/entry/vdso/vclock_gettime-x32.o:(.note.gnu.property+0x1c): program property is too short
    
    To avoid this error, do not allow CONFIG_X86_X32_ABI to be selected when
    using llvm-objcopy. If the two issues ever get fixed in llvm-objcopy,
    this can be turned into a feature check.
    
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20220314194842.3452-3-nathan@kernel.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c393a9f4cb3bce27ed98d6bc4ffb0bef72ccd698
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Mon Mar 14 12:48:42 2022 -0700

    x86/Kconfig: Do not allow CONFIG_X86_X32_ABI=y with llvm-objcopy
    
    [ Upstream commit aaeed6ecc1253ce1463fa1aca0b70a4ccbc9fa75 ]
    
    There are two outstanding issues with CONFIG_X86_X32_ABI and
    llvm-objcopy, with similar root causes:
    
    1. llvm-objcopy does not properly convert .note.gnu.property when going
       from x86_64 to x86_x32, resulting in a corrupted section when
       linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/1141
    
    2. llvm-objcopy produces corrupted compressed debug sections when going
       from x86_64 to x86_x32, also resulting in an error when linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/514
    
    After commit 41c5ef31ad71 ("x86/ibt: Base IBT bits"), the
    .note.gnu.property section is always generated when
    CONFIG_X86_KERNEL_IBT is enabled, which causes the first issue to become
    visible with an allmodconfig build:
    
      ld.lld: error: arch/x86/entry/vdso/vclock_gettime-x32.o:(.note.gnu.property+0x1c): program property is too short
    
    To avoid this error, do not allow CONFIG_X86_X32_ABI to be selected when
    using llvm-objcopy. If the two issues ever get fixed in llvm-objcopy,
    this can be turned into a feature check.
    
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20220314194842.3452-3-nathan@kernel.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2141b80328b45f7bfe9691de7804988b4b4b1262
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Mon Mar 14 12:48:42 2022 -0700

    x86/Kconfig: Do not allow CONFIG_X86_X32_ABI=y with llvm-objcopy
    
    [ Upstream commit aaeed6ecc1253ce1463fa1aca0b70a4ccbc9fa75 ]
    
    There are two outstanding issues with CONFIG_X86_X32_ABI and
    llvm-objcopy, with similar root causes:
    
    1. llvm-objcopy does not properly convert .note.gnu.property when going
       from x86_64 to x86_x32, resulting in a corrupted section when
       linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/1141
    
    2. llvm-objcopy produces corrupted compressed debug sections when going
       from x86_64 to x86_x32, also resulting in an error when linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/514
    
    After commit 41c5ef31ad71 ("x86/ibt: Base IBT bits"), the
    .note.gnu.property section is always generated when
    CONFIG_X86_KERNEL_IBT is enabled, which causes the first issue to become
    visible with an allmodconfig build:
    
      ld.lld: error: arch/x86/entry/vdso/vclock_gettime-x32.o:(.note.gnu.property+0x1c): program property is too short
    
    To avoid this error, do not allow CONFIG_X86_X32_ABI to be selected when
    using llvm-objcopy. If the two issues ever get fixed in llvm-objcopy,
    this can be turned into a feature check.
    
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20220314194842.3452-3-nathan@kernel.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2b82b07ce3c7c3a34a5f88ea116d9d6f39844fa6
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Mon Mar 14 12:48:42 2022 -0700

    x86/Kconfig: Do not allow CONFIG_X86_X32_ABI=y with llvm-objcopy
    
    [ Upstream commit aaeed6ecc1253ce1463fa1aca0b70a4ccbc9fa75 ]
    
    There are two outstanding issues with CONFIG_X86_X32_ABI and
    llvm-objcopy, with similar root causes:
    
    1. llvm-objcopy does not properly convert .note.gnu.property when going
       from x86_64 to x86_x32, resulting in a corrupted section when
       linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/1141
    
    2. llvm-objcopy produces corrupted compressed debug sections when going
       from x86_64 to x86_x32, also resulting in an error when linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/514
    
    After commit 41c5ef31ad71 ("x86/ibt: Base IBT bits"), the
    .note.gnu.property section is always generated when
    CONFIG_X86_KERNEL_IBT is enabled, which causes the first issue to become
    visible with an allmodconfig build:
    
      ld.lld: error: arch/x86/entry/vdso/vclock_gettime-x32.o:(.note.gnu.property+0x1c): program property is too short
    
    To avoid this error, do not allow CONFIG_X86_X32_ABI to be selected when
    using llvm-objcopy. If the two issues ever get fixed in llvm-objcopy,
    this can be turned into a feature check.
    
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20220314194842.3452-3-nathan@kernel.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit aaeed6ecc1253ce1463fa1aca0b70a4ccbc9fa75
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Mon Mar 14 12:48:42 2022 -0700

    x86/Kconfig: Do not allow CONFIG_X86_X32_ABI=y with llvm-objcopy
    
    There are two outstanding issues with CONFIG_X86_X32_ABI and
    llvm-objcopy, with similar root causes:
    
    1. llvm-objcopy does not properly convert .note.gnu.property when going
       from x86_64 to x86_x32, resulting in a corrupted section when
       linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/1141
    
    2. llvm-objcopy produces corrupted compressed debug sections when going
       from x86_64 to x86_x32, also resulting in an error when linking:
    
       https://github.com/ClangBuiltLinux/linux/issues/514
    
    After commit 41c5ef31ad71 ("x86/ibt: Base IBT bits"), the
    .note.gnu.property section is always generated when
    CONFIG_X86_KERNEL_IBT is enabled, which causes the first issue to become
    visible with an allmodconfig build:
    
      ld.lld: error: arch/x86/entry/vdso/vclock_gettime-x32.o:(.note.gnu.property+0x1c): program property is too short
    
    To avoid this error, do not allow CONFIG_X86_X32_ABI to be selected when
    using llvm-objcopy. If the two issues ever get fixed in llvm-objcopy,
    this can be turned into a feature check.
    
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20220314194842.3452-3-nathan@kernel.org

commit 58cd4a088e8917b4092c7011d499e277e04a6644
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Jan 21 12:12:34 2022 +0000

    arm64: vdso: Fix "no previous prototype" warning
    
    If compiling the arm64 kernel with W=1 the following warning is produced:
    
    | arch/arm64/kernel/vdso/vgettimeofday.c:9:5: error: no previous prototype for ‘__kernel_clock_gettime’ [-Werror=missing-prototypes]
    |     9 | int __kernel_clock_gettime(clockid_t clock,
    |       |     ^~~~~~~~~~~~~~~~~~~~~~
    | arch/arm64/kernel/vdso/vgettimeofday.c:15:5: error: no previous prototype for ‘__kernel_gettimeofday’ [-Werror=missing-prototypes]
    |    15 | int __kernel_gettimeofday(struct __kernel_old_timeval *tv,
    |       |     ^~~~~~~~~~~~~~~~~~~~~
    | arch/arm64/kernel/vdso/vgettimeofday.c:21:5: error: no previous prototype for ‘__kernel_clock_getres’ [-Werror=missing-prototypes]
    |    21 | int __kernel_clock_getres(clockid_t clock_id,
    |       |     ^~~~~~~~~~~~~~~~~~~~~
    
    This patch removes "-Wmissing-prototypes" and "-Wmissing-declarations" compilers
    flags from the compilation of vgettimeofday.c to make possible to build the
    kernel with CONFIG_WERROR enabled.
    
    Cc: Will Deacon <will@kernel.org>
    Reported-by: Marc Kleine-Budde <mkl@pengutronix.de>
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Tested-by: Marc Kleine-Budde <mkl@pengutronix.de>
    Link: https://lore.kernel.org/r/20220121121234.47273-1-vincenzo.frascino@arm.com
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

commit 640a171c9347b52da668dbf83473a05572f06055
Merge: 5f6082642814 eb68db45b747
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Wed Jan 5 17:53:25 2022 -0800

    Merge branch 'samples/bpf: xdpsock app enhancements'
    
    Ong Boon says:
    
    ====================
    
    First of all, sorry for taking more time to get back to this series and
    thanks to all valuble feedback in series-1 at [1] from Jesper and Song
    Liu.
    
    Since then I have looked into what Jesper suggested in [2] and worked on
    revising the patch series into several patches for ease of review:
    
    v1->v2:
    1/7: [No change]. Add VLAN tag (ID & Priority) to the generated Tx-Only
         frames.
    
    2/7: [No change]. Add DMAC and SMAC setting to the generated Tx-Only
         frames. If parameters are not set, previous DMAC and SMAC are used.
    
    3/7: [New]. Add support for selecting different CLOCK for clock_gettime()
         used in get_nsecs.
    
    4/7: [New]. This is a total rework from series-1 3/4-patch [3]. It uses
         clock_nanosleep() suggested by Jesper. In addition, added statistic
         for Tx schedule variance under application stat (-a|--app-stats).
         Make the cyclic Tx operation and --poll mode to be mutually-
         exclusive. Still, the ability to specify TX cycle time and used
         together with batch size and packet count remain the same.
    
    5/7: [New]. Add the support for TX process schedule policy and priority
         setting. By default, SCHED_OTHER policy is used. This too is matching
         the schedule policy setting in [2].
    
    6/7: [Change]. This is update from series-1 4/4-patch [4]. Added TX clean
         process time-out in 1s granularity with configurable retries count
         (-O|--retries).
    
    7/7: [New]. Added timestamp for TX packet following pktgen_hdr format
         matching the implementation in [2]. However, the sequence ID remains
         the same as it is instead of process schedule diff in [2].
    
    To summarize on what program options have been added with v2 series
    using an example below:-
    
     DMAC (-G)                 = fa:8d:f1:e2:0b:e8
     SMAC (-H)                 = ce:17:07:17:3e:3a
    
     VLAN tagged (-V)
     VLAN ID (-J)              = 12
     VLAN Pri (-K)             = 3
    
     Tx Queue (-q)             = 3
     Cycle Time in us (-T)     = 1000
     Batch (-b)                = 2
     Packet Count              = 6
     Tx schedule policy (-W)   = FIFO
     Tx schedule priority (-U) = 50
     Clock selection (-w)      = REALTIME
    
     Tx timeout retries(-O)    = 5
     Tx timestamp (-y)
     Cyclic Tx schedule stat (-a)
    
    Note: xdpsock sets UDP dest-port and src-port to 0x1000 as default.
    
     Sending Board
     =============
     $ xdpsock -i eth0 -t -N -z -H ce:17:07:17:3e:3a -G fa:8d:f1:e2:0b:e8 \
       -V -J 12 -K 3 -q 3 \
       -T 1000 -b 2 -C 6 -W FIFO -U 50 -w REALTIME \
       -O 5 -y -a
    
      sock0@eth0:3 txonly xdp-drv
                        pps            pkts           0.00
     rx                 0              0
     tx                 0              6
    
                        calls/s        count
     rx empty polls     0              0
     fill fail polls    0              0
     copy tx sendtos    0              0
     tx wakeup sendtos  0              5
     opt polls          0              0
    
                        period     min        ave        max        cycle
     Cyclic TX          1000000    31033      32009      33397      3
    
     Receiving Board
     ===============
     $ tcpdump -nei eth0 udp port 0x1000 -vv -Q in -X \
        --time-stamp-precision nano
    tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes
    03:46:40.520111580 ce:17:07:17:3e:3a > fa:8d:f1:e2:0b:e8, ethertype 802.1Q (0x8100), length 62: vlan 12, p 3, ethertype IPv4, (tos 0x0, ttl 64, id 0, offset 0, flags [none], proto UDP (17), length 44)
        10.10.10.16.4096 > 10.10.10.32.4096: [udp sum ok] UDP, length 16
            0x0000:  4500 002c 0000 0000 4011 527e 0a0a 0a10  E..,....@.R~....
            0x0010:  0a0a 0a20 1000 1000 0018 e997 be9b e955  ...............U
            0x0020:  0000 0000 61cd 2ba1 0006 987c            ....a.+....|
    03:46:40.520112163 ce:17:07:17:3e:3a > fa:8d:f1:e2:0b:e8, ethertype 802.1Q (0x8100), length 62: vlan 12, p 3, ethertype IPv4, (tos 0x0, ttl 64, id 0, offset 0, flags [none], proto UDP (17), length 44)
        10.10.10.16.4096 > 10.10.10.32.4096: [udp sum ok] UDP, length 16
            0x0000:  4500 002c 0000 0000 4011 527e 0a0a 0a10  E..,....@.R~....
            0x0010:  0a0a 0a20 1000 1000 0018 e996 be9b e955  ...............U
            0x0020:  0000 0001 61cd 2ba1 0006 987c            ....a.+....|
    03:46:40.521066860 ce:17:07:17:3e:3a > fa:8d:f1:e2:0b:e8, ethertype 802.1Q (0x8100), length 62: vlan 12, p 3, ethertype IPv4, (tos 0x0, ttl 64, id 0, offset 0, flags [none], proto UDP (17), length 44)
        10.10.10.16.4096 > 10.10.10.32.4096: [udp sum ok] UDP, length 16
            0x0000:  4500 002c 0000 0000 4011 527e 0a0a 0a10  E..,....@.R~....
            0x0010:  0a0a 0a20 1000 1000 0018 e5af be9b e955  ...............U
            0x0020:  0000 0002 61cd 2ba1 0006 9c62            ....a.+....b
    03:46:40.521067012 ce:17:07:17:3e:3a > fa:8d:f1:e2:0b:e8, ethertype 802.1Q (0x8100), length 62: vlan 12, p 3, ethertype IPv4, (tos 0x0, ttl 64, id 0, offset 0, flags [none], proto UDP (17), length 44)
        10.10.10.16.4096 > 10.10.10.32.4096: [udp sum ok] UDP, length 16
            0x0000:  4500 002c 0000 0000 4011 527e 0a0a 0a10  E..,....@.R~....
            0x0010:  0a0a 0a20 1000 1000 0018 e5ae be9b e955  ...............U
            0x0020:  0000 0003 61cd 2ba1 0006 9c62            ....a.+....b
    03:46:40.522061935 ce:17:07:17:3e:3a > fa:8d:f1:e2:0b:e8, ethertype 802.1Q (0x8100), length 62: vlan 12, p 3, ethertype IPv4, (tos 0x0, ttl 64, id 0, offset 0, flags [none], proto UDP (17), length 44)
        10.10.10.16.4096 > 10.10.10.32.4096: [udp sum ok] UDP, length 16
            0x0000:  4500 002c 0000 0000 4011 527e 0a0a 0a10  E..,....@.R~....
            0x0010:  0a0a 0a20 1000 1000 0018 e1c5 be9b e955  ...............U
            0x0020:  0000 0004 61cd 2ba1 0006 a04a            ....a.+....J
    03:46:40.522062173 ce:17:07:17:3e:3a > fa:8d:f1:e2:0b:e8, ethertype 802.1Q (0x8100), length 62: vlan 12, p 3, ethertype IPv4, (tos 0x0, ttl 64, id 0, offset 0, flags [none], proto UDP (17), length 44)
        10.10.10.16.4096 > 10.10.10.32.4096: [udp sum ok] UDP, length 16
            0x0000:  4500 002c 0000 0000 4011 527e 0a0a 0a10  E..,....@.R~....
            0x0010:  0a0a 0a20 1000 1000 0018 e1c4 be9b e955  ...............U
            0x0020:  0000 0005 61cd 2ba1 0006 a04a            ....a.+....J
    
    I have tested the above with both tagged and untagged packet format and
    based on the timestamp in tcpdump found that the timing of the batch
    cyclic transmission is correct.
    
    Appreciate if community can give the patch series v2 a try and point out
    any gap.
    
    Thanks
    Boon Leong
    
    [1] https://patchwork.kernel.org/project/netdevbpf/cover/20211124091821.3916046-1-boon.leong.ong@intel.com/
    [2] https://github.com/netoptimizer/network-testing/blob/master/src/udp_pacer.c
    [3] https://patchwork.kernel.org/project/netdevbpf/patch/20211124091821.3916046-4-boon.leong.ong@intel.com/
    [4] https://patchwork.kernel.org/project/netdevbpf/patch/20211124091821.3916046-5-boon.leong.ong@intel.com/
    ====================
    
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

commit a1f18c5fe554750eb14f6b41d2526a13a697c185
Merge: c67939eff802 38970eac41db
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Dec 30 13:13:25 2021 +0000

    Merge branch '1GbE' of git://git.kernel.org/pub/scm/linux/kernel/git/tnguy/next-
    queue
    
    Tony Nguyen says:
    
    ====================
    1GbE Intel Wired LAN Driver Updates 2021-12-29
    
    Ruud Bos says:
    
    The igb driver provides support for PEROUT and EXTTS pin functions that
    allow adapter external use of timing signals. At Hottinger Bruel & Kjaer we
    are using the PEROUT function to feed a PTP corrected 1pps signal into an
    FPGA as cross system synchronized time source.
    
    Support for the PEROUT and EXTTS SDP functions is currently limited to
    i210/i211 based adapters. This patch series enables these functions also
    for 82580/i354/i350 based ones. Because the time registers of these
    adapters do not have the nice split in second rollovers as the i210 has,
    the implementation is slightly more complex compared to the i210
    implementation.
    
    The PEROUT function has been successfully tested on an i350 based ethernet
    adapter. Using the following user space code excerpt, the driver outputs a
    PTP corrected 1pps signal on the SDP0 pin of an i350:
    
        struct ptp_pin_desc desc;
        memset(&desc, 0, sizeof(desc));
        desc.index = 0;
        desc.func = PTP_PF_PEROUT;
        desc.chan = 0;
        if (ioctl(fd, PTP_PIN_SETFUNC, &desc) == 0) {
            struct timespec ts;
            if (clock_gettime(clkid, &ts) == 0) {
                struct ptp_perout_request rq;
                memset(&rq, 0, sizeof(rq));
                rq.index = 0;
                rq.start.sec = ts.tv_sec + 1;
                rq.start.nsec = 500000000;
                rq.period.sec  = 1;
                rq.period.nsec = 0;
                if (ioctl(fd, PTP_PEROUT_REQUEST, &rq) == 0) {
                    /* 1pps signal is now available on SDP0 */
                }
            }
        }
    
    The added EXTTS function has not been tested. However, looking at the data
    sheets, the layout of the registers involved match the i210 exactly except
    for the time registers mentioned before. Hence the almost identical
    implementation.
    
    ---
    Note: I made changes to fix RCT and checkpatch messages regarding
    unnecessary parenthesis.
    ====================
    
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c5664d508674c77a52d311af8b1e11d08ac0cf4b
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9f2c6af5a601a2e2bf40e5561bedc87a44d9649
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 62889094939c5fc0c43b207396e51bde905be1ca
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8938a4473e6244dff5c4ff3579e7b6d880d1f68c
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c0b25c6d1b91da64069c3c364e68775ad6d5437c
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 848a0e10fde6575bc3fa5253e9afc45444902cc7
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ed5dc41bb48e82478525c08c87a4c88847e8570c
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    commit 4e8c11b6b3f0b6a283e898344f154641eda94266 upstream.
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4e8c11b6b3f0b6a283e898344f154641eda94266
Author: Yu Liao <liaoyu15@huawei.com>
Date:   Mon Dec 13 21:57:27 2021 +0800

    timekeeping: Really make sure wall_to_monotonic isn't positive
    
    Even after commit e1d7ba873555 ("time: Always make sure wall_to_monotonic
    isn't positive") it is still possible to make wall_to_monotonic positive
    by running the following code:
    
        int main(void)
        {
            struct timespec time;
    
            clock_gettime(CLOCK_MONOTONIC, &time);
            time.tv_nsec = 0;
            clock_settime(CLOCK_REALTIME, &time);
            return 0;
        }
    
    The reason is that the second parameter of timespec64_compare(), ts_delta,
    may be unnormalized because the delta is calculated with an open coded
    substraction which causes the comparison of tv_sec to yield the wrong
    result:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec =  -9, .tv_nsec = -900000000 }
    
    That makes timespec64_compare() claim that wall_to_monotonic < ts_delta,
    but actually the result should be wall_to_monotonic > ts_delta.
    
    After normalization, the result of timespec64_compare() is correct because
    the tv_sec comparison is not longer misleading:
    
      wall_to_monotonic = { .tv_sec = -10, .tv_nsec =  900000000 }
      ts_delta          = { .tv_sec = -10, .tv_nsec =  100000000 }
    
    Use timespec64_sub() to ensure that ts_delta is normalized, which fixes the
    issue.
    
    Fixes: e1d7ba873555 ("time: Always make sure wall_to_monotonic isn't positive")
    Signed-off-by: Yu Liao <liaoyu15@huawei.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lore.kernel.org/r/20211213135727.1656662-1-liaoyu15@huawei.com

commit b8b60c1139c7912cf68a20638e9a480971c1b3d0
Author: Tong Tiangen <tongtiangen@huawei.com>
Date:   Wed Sep 1 02:46:20 2021 +0000

    riscv/vdso: Move vdso data page up front
    
    [ Upstream commit 78a743cd82a35ca0724179fc22834f06a2151fc2 ]
    
    As commit 601255ae3c98 ("arm64: vdso: move data page before code pages"), the
    same issue exists on riscv, testcase is shown below, make sure that vdso.so is
    bigger than page size,
    
      struct timespec tp;
      clock_gettime(5, &tp);
      printf("tv_sec: %ld, tv_nsec: %ld\n", tp.tv_sec, tp.tv_nsec);
    
    without this patch, test result : tv_sec: 0, tv_nsec: 0
       with this patch, test result : tv_sec: 1629271537, tv_nsec: 748000000
    
    Move the vdso data page in front of the VDSO area to fix the issue.
    
    Fixes: ad5d1122b82fb ("riscv: use vDSO common flow to reduce the latency of the time-related functions")
    Signed-off-by: Tong Tiangen <tongtiangen@huawei.com>
    Reviewed-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 78a743cd82a35ca0724179fc22834f06a2151fc2
Author: Tong Tiangen <tongtiangen@huawei.com>
Date:   Wed Sep 1 02:46:20 2021 +0000

    riscv/vdso: Move vdso data page up front
    
    As commit 601255ae3c98 ("arm64: vdso: move data page before code pages"), the
    same issue exists on riscv, testcase is shown below, make sure that vdso.so is
    bigger than page size,
    
      struct timespec tp;
      clock_gettime(5, &tp);
      printf("tv_sec: %ld, tv_nsec: %ld\n", tp.tv_sec, tp.tv_nsec);
    
    without this patch, test result : tv_sec: 0, tv_nsec: 0
       with this patch, test result : tv_sec: 1629271537, tv_nsec: 748000000
    
    Move the vdso data page in front of the VDSO area to fix the issue.
    
    Fixes: ad5d1122b82fb ("riscv: use vDSO common flow to reduce the latency of the time-related functions")
    Signed-off-by: Tong Tiangen <tongtiangen@huawei.com>
    Reviewed-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Palmer Dabbelt <palmerdabbelt@google.com>

commit c41c926d9dfb3c81da370faf678eb06f7f48ba77
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8be8d4ba1c4d4f5fb316957965f9f8d5f110f5b5
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a69d0ba42ec05cb54f07a595d47741ede9ceb01d
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8553099bdbe95a717e974552b6e6dbb8c4dac70b
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e9602efecf1986b27dd965094b545f4aa4c8bb43
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e09c9b558436405407563472f41b0aff437b9c7d
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 29cb4c6229201f22f6ce16d6a9fd15f76c001dc0
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 04ea267f5357ddcf39ff7098cdd03c855b9fa036
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    [ Upstream commit 47ce8527fbba145a7723685bc9a27d9855e06491 ]
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 47ce8527fbba145a7723685bc9a27d9855e06491
Author: Martin Fäcknitz <faecknitz@hotsplots.de>
Date:   Mon Jul 5 02:03:54 2021 +0200

    MIPS: vdso: Invalid GIC access through VDSO
    
    Accessing raw timers (currently only CLOCK_MONOTONIC_RAW) through VDSO
    doesn't return the correct time when using the GIC as clock source.
    The address of the GIC mapped page is in this case not calculated
    correctly. The GIC mapped page is calculated from the VDSO data by
    subtracting PAGE_SIZE:
    
      void *get_gic(const struct vdso_data *data) {
        return (void __iomem *)data - PAGE_SIZE;
      }
    
    However, the data pointer is not page aligned for raw clock sources.
    This is because the VDSO data for raw clock sources (CS_RAW = 1) is
    stored after the VDSO data for coarse clock sources (CS_HRES_COARSE = 0).
    Therefore, only the VDSO data for CS_HRES_COARSE is page aligned:
    
      +--------------------+
      |                    |
      | vd[CS_RAW]         | ---+
      | vd[CS_HRES_COARSE] |    |
      +--------------------+    | -PAGE_SIZE
      |                    |    |
      |  GIC mapped page   | <--+
      |                    |
      +--------------------+
    
    When __arch_get_hw_counter() is called with &vd[CS_RAW], get_gic returns
    the wrong address (somewhere inside the GIC mapped page). The GIC counter
    values are not returned which results in an invalid time.
    
    Fixes: a7f4df4e21dd ("MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()")
    Signed-off-by: Martin Fäcknitz <faecknitz@hotsplots.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>

commit a921d014868c5ab97f286efcf3149999d76765be
Author: Jian Cai <jiancai@google.com>
Date:   Wed May 5 18:25:08 2021 -0700

    arm64: vdso: remove commas between macro name and arguments
    
    LLVM's integrated assembler appears to assume an argument with default
    value is passed whenever it sees a comma right after the macro name.
    It will be fine if the number of following arguments is one less than
    the number of parameters specified in the macro definition. Otherwise,
    it fails. For example, the following code works:
    
    $ cat foo.s
    .macro  foo arg1=2, arg2=4
            ldr r0, [r1, #\arg1]
            ldr r0, [r1, #\arg2]
    .endm
    
    foo, arg2=8
    
    $ llvm-mc -triple=armv7a -filetype=obj foo.s -o ias.o
    arm-linux-gnueabihf-objdump -dr ias.o
    
    ias.o:     file format elf32-littlearm
    
    Disassembly of section .text:
    
    00000000 <.text>:
       0: e5910001 ldr r0, [r1, #2]
       4: e5910003 ldr r0, [r1, #8]
    
    While the the following code would fail:
    
    $ cat foo.s
    .macro  foo arg1=2, arg2=4
            ldr r0, [r1, #\arg1]
            ldr r0, [r1, #\arg2]
    .endm
    
    foo, arg1=2, arg2=8
    
    $ llvm-mc -triple=armv7a -filetype=obj foo.s -o ias.o
    foo.s:6:14: error: too many positional arguments
    foo, arg1=2, arg2=8
    
    This causes build failures as follows:
    
    arch/arm64/kernel/vdso/gettimeofday.S:230:24: error: too many positional
    arguments
     clock_gettime_return, shift=1
                           ^
    arch/arm64/kernel/vdso/gettimeofday.S:253:24: error: too many positional
    arguments
     clock_gettime_return, shift=1
                           ^
    arch/arm64/kernel/vdso/gettimeofday.S:274:24: error: too many positional
    arguments
     clock_gettime_return, shift=1
    
    This error is not in mainline because commit 28b1a824a4f4 ("arm64: vdso:
    Substitute gettimeofday() with C implementation") rewrote this assembler
    file in C as part of a 25 patch series that is unsuitable for stable.
    Just remove the comma in the clock_gettime_return invocations in 4.19 so
    that GNU as and LLVM's integrated assembler work the same.
    
    Link:
    https://github.com/ClangBuiltLinux/linux/issues/1349
    
    Suggested-by: Nathan Chancellor <nathan@kernel.org>
    Reviewed-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Jian Cai <jiancai@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f56607e85ee38f2a5bb7096e24e2d40f35d714f9
Author: Christophe Leroy <christophe.leroy@csgroup.eu>
Date:   Wed Mar 31 13:59:17 2021 +0000

    selftests/timens: Fix gettime_perf to work on powerpc
    
    On powerpc:
    - VDSO library is named linux-vdso32.so.1 or linux-vdso64.so.1
    - clock_gettime is named __kernel_clock_gettime()
    
    Ensure gettime_perf tries these names before giving up.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/469f37ab91984309eb68c0fb47e8438cdf5b6463.1617198956.git.christophe.leroy@csgroup.eu

commit 6ac86aae89289121db784161fe318819778f7f2a
Merge: 17860ccabff5 84d572e634e2
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 30 10:54:22 2021 -0700

    Merge tag 's390-5.12-5' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 updates from Heiko Carstens:
    
     - fix incorrect initialization and update of vdso data pages, which
       results in incorrect tod clock steering, and that
       clock_gettime(CLOCK_MONOTONIC_RAW, ...) returns incorrect values.
    
     - update MAINTAINERS for s390 vfio drivers
    
    * tag 's390-5.12-5' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux:
      MAINTAINERS: add backups for s390 vfio drivers
      s390/vdso: fix initializing and updating of vdso_data
      s390/vdso: fix tod_steering_delta type
      s390/vdso: copy tod_steering_delta value to vdso_data page

commit 5b43bd184530af6b868d8273b0a743a138d37ee8
Author: Heiko Carstens <hca@linux.ibm.com>
Date:   Wed Mar 24 20:23:55 2021 +0100

    s390/vdso: fix initializing and updating of vdso_data
    
    Li Wang reported that clock_gettime(CLOCK_MONOTONIC_RAW, ...) returns
    incorrect values when time is provided via vdso instead of system call:
    
    vdso_ts_nsec = 4484351380985507, vdso_ts.tv_sec = 4484351, vdso_ts.tv_nsec = 380985507
    sys_ts_nsec  = 1446923235377, sys_ts.tv_sec  = 1446, sys_ts.tv_nsec  = 923235377
    
    Within the s390 specific vdso function __arch_get_hw_counter() reads
    tod clock steering values from the arch_data member of the passed in
    vdso_data structure.
    
    Problem is that only for the CS_HRES_COARSE vdso_data arch_data is
    initialized and gets updated. The CS_RAW specific vdso_data does not
    contain any valid tod_clock_steering information, which explains the
    different values.
    
    Fix this by initializing and updating all vdso_datas.
    
    Reported-by: Li Wang <liwang@redhat.com>
    Tested-by: Li Wang <liwang@redhat.com>
    Fixes: 1ba2d6c0fd4e ("s390/vdso: simplify __arch_get_hw_counter()")
    Link: https://lore.kernel.org/linux-s390/YFnxr1ZlMIOIqjfq@osiris
    Signed-off-by: Heiko Carstens <hca@linux.ibm.com>

commit f405ac83fa252dd0e346f2715b66e7d2adba9027
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Thu Feb 4 15:50:42 2021 +0100

    selftests/vDSO: fix ABI selftest on riscv
    
    Only older versions of the RISC-V GCC toolchain define __riscv__. Check
    for __riscv as well, which is used by newer GCC toolchains. Also set
    VDSO_32BIT based on __riscv_xlen.
    
    Before (on riscv64):
    
    $ ./vdso_test_abi
    [vDSO kselftest] VDSO_VERSION: LINUX_4
    Could not find __vdso_gettimeofday
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_REALTIME [PASS]
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_BOOTTIME [PASS]
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_TAI [PASS]
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_REALTIME_COARSE [PASS]
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_MONOTONIC [PASS]
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_MONOTONIC_RAW [PASS]
    Could not find __vdso_clock_gettime
    Could not find __vdso_clock_getres
    clock_id: CLOCK_MONOTONIC_COARSE [PASS]
    Could not find __vdso_time
    
    After (on riscv32):
    
    $ ./vdso_test_abi
    [vDSO kselftest] VDSO_VERSION: LINUX_4.15
    The time is 1612449376.015086
    The time is 1612449376.18340784
    The resolution is 0 1
    clock_id: CLOCK_REALTIME [PASS]
    The time is 774.842586182
    The resolution is 0 1
    clock_id: CLOCK_BOOTTIME [PASS]
    The time is 1612449376.22536565
    The resolution is 0 1
    clock_id: CLOCK_TAI [PASS]
    The time is 1612449376.20885172
    The resolution is 0 4000000
    clock_id: CLOCK_REALTIME_COARSE [PASS]
    The time is 774.845491269
    The resolution is 0 1
    clock_id: CLOCK_MONOTONIC [PASS]
    The time is 774.849534200
    The resolution is 0 1
    clock_id: CLOCK_MONOTONIC_RAW [PASS]
    The time is 774.842139684
    The resolution is 0 4000000
    clock_id: CLOCK_MONOTONIC_COARSE [PASS]
    Could not find __vdso_time
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Reviewed-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Acked-by: Palmer Dabbelt <palmerdabbelt@google.com>
    Acked-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Shuah Khan <skhan@linuxfoundation.org>

commit a1339d6355ac42e1bf4fcdfce8bfce61172f8891
Merge: a527a2b32d20 41131a5e54ae
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 17 12:28:58 2021 -0800

    Merge tag 'powerpc-5.11-4' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux
    
    Pull powerpc fixes from Michael Ellerman:
     "One fix for a lack of alignment in our linker script, that can lead to
      crashes depending on configuration etc.
    
      One fix for the 32-bit VDSO after the C VDSO conversion.
    
      Thanks to Andreas Schwab, Ariel Marcovitch, and Christophe Leroy"
    
    * tag 'powerpc-5.11-4' of git://git.kernel.org/pub/scm/linux/kernel/git/powerpc/linux:
      powerpc/vdso: Fix clock_gettime_fallback for vdso32
      powerpc: Fix alignment bug within the init sections

commit 41131a5e54ae7ba5a2bb8d7b30d1818b3f5b13d2
Author: Andreas Schwab <schwab@linux-m68k.org>
Date:   Tue Jan 12 11:55:15 2021 +0000

    powerpc/vdso: Fix clock_gettime_fallback for vdso32
    
    The second argument of __kernel_clock_gettime64 points to a struct
    __kernel_timespec, with 64-bit time_t, so use the clock_gettime64
    syscall in the fallback function for the 32-bit VDSO. Similarly,
    clock_getres_fallback should use the clock_getres_time64 syscall,
    though it isn't yet called from the 32-bit VDSO.
    
    Fixes: d0e3fc69d00d ("powerpc/vdso: Provide __kernel_clock_gettime64() on vdso32")
    Signed-off-by: Andreas Schwab <schwab@linux-m68k.org>
    [chleroy: Moved into a single #ifdef __powerpc64__ block]
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/0c0ab0eb3cc80687c326f76ff0dd5762b8812ecc.1610452505.git.christophe.leroy@csgroup.eu

commit df00d02989024d193a6efd1a85513a5658c6a10f
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Thu Dec 17 17:32:35 2020 +0100

    selftests/vDSO: fix -Wformat warning in vdso_test_correctness
    
    Fix the following -Wformat warnings in vdso_test_correctness.c:
    
    vdso_test_correctness.c: In function ‘test_one_clock_gettime64’:
    vdso_test_correctness.c:352:21: warning: format ‘%ld’ expects argument of type ‘long int’, but argument 3 has type ‘long long int’ [-Wformat=]
      352 |  printf("\t%llu.%09ld %llu.%09ld %llu.%09ld\n",
          |                 ~~~~^
          |                     |
          |                     long int
          |                 %09lld
      353 |         (unsigned long long)start.tv_sec, start.tv_nsec,
          |                                           ~~~~~~~~~~~~~
          |                                                |
          |                                                long long int
    vdso_test_correctness.c:352:32: warning: format ‘%ld’ expects argument of type ‘long int’, but argument 5 has type ‘long long int’ [-Wformat=]
      352 |  printf("\t%llu.%09ld %llu.%09ld %llu.%09ld\n",
          |                            ~~~~^
          |                                |
          |                                long int
          |                            %09lld
      353 |         (unsigned long long)start.tv_sec, start.tv_nsec,
      354 |         (unsigned long long)vdso.tv_sec, vdso.tv_nsec,
          |                                          ~~~~~~~~~~~~
          |                                              |
          |                                              long long int
    vdso_test_correctness.c:352:43: warning: format ‘%ld’ expects argument of type ‘long int’, but argument 7 has type ‘long long int’ [-Wformat=]
    
    The tv_sec member of __kernel_timespec is long long, both in
    uapi/linux/time_types.h and locally in vdso_test_correctness.c.
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Signed-off-by: Shuah Khan <skhan@linuxfoundation.org>

commit 2eda7f11000646909a10298951c9defb2321b240
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Dec 18 22:16:19 2020 +1100

    powerpc/vdso: Fix DOTSYM for 32-bit LE VDSO
    
    Skirmisher reported on IRC that the 32-bit LE VDSO was hanging. This
    turned out to be due to a branch to self in eg. __kernel_gettimeofday.
    Looking at the disassembly with objdump -dR shows why:
    
      00000528 <__kernel_gettimeofday>:
       528:   f0 ff 21 94     stwu    r1,-16(r1)
       52c:   a6 02 08 7c     mflr    r0
       530:   f0 ff 21 94     stwu    r1,-16(r1)
       534:   14 00 01 90     stw     r0,20(r1)
       538:   05 00 9f 42     bcl     20,4*cr7+so,53c <__kernel_gettimeofday+0x14>
       53c:   a6 02 a8 7c     mflr    r5
       540:   ff ff a5 3c     addis   r5,r5,-1
       544:   c4 fa a5 38     addi    r5,r5,-1340
       548:   f0 00 a5 38     addi    r5,r5,240
       54c:   01 00 00 48     bl      54c <__kernel_gettimeofday+0x24>
                              54c: R_PPC_REL24        .__c_kernel_gettimeofday
    
    Because we don't process relocations for the VDSO, this branch remains
    a branch from 0x54c to 0x54c.
    
    With the preceding patch to prohibit R_PPC_REL24 relocations, we
    instead get a build failure:
    
      0000054c R_PPC_REL24       .__c_kernel_gettimeofday
      00000598 R_PPC_REL24       .__c_kernel_clock_gettime
      000005e4 R_PPC_REL24       .__c_kernel_clock_gettime64
      00000630 R_PPC_REL24       .__c_kernel_clock_getres
      0000067c R_PPC_REL24       .__c_kernel_time
      arch/powerpc/kernel/vdso32/vdso32.so.dbg: dynamic relocations are not supported
    
    The root cause is that we're branching to `.__c_kernel_gettimeofday`.
    But this is 32-bit LE code, which doesn't use function descriptors, so
    there are no dot symbols.
    
    The reason we're trying to branch to a dot symbol is because we're
    using the DOTSYM macro, but the ifdefs we use to define the DOTSYM
    macro do not currently work for 32-bit LE.
    
    So like previous commits we need to differentiate if the current
    compilation unit is 64-bit, rather than the kernel as a whole. ie.
    switch from CONFIG_PPC64 to __powerpc64__.
    
    With that fixed 32-bit LE code gets the empty version of DOTSYM, which
    just resolves to the original symbol name, leading to a direct branch
    and no relocations:
    
      000003f8 <__kernel_gettimeofday>:
       3f8:   f0 ff 21 94     stwu    r1,-16(r1)
       3fc:   a6 02 08 7c     mflr    r0
       400:   f0 ff 21 94     stwu    r1,-16(r1)
       404:   14 00 01 90     stw     r0,20(r1)
       408:   05 00 9f 42     bcl     20,4*cr7+so,40c <__kernel_gettimeofday+0x14>
       40c:   a6 02 a8 7c     mflr    r5
       410:   ff ff a5 3c     addis   r5,r5,-1
       414:   f4 fb a5 38     addi    r5,r5,-1036
       418:   f0 00 a5 38     addi    r5,r5,240
       41c:   85 06 00 48     bl      aa0 <__c_kernel_gettimeofday>
    
    Fixes: ab037dd87a2f ("powerpc/vdso: Switch VDSO to generic C implementation.")
    Reported-by: "Will Springer <skirmisher@protonmail.com>"
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20201218111619.1206391-3-mpe@ellerman.id.au

commit 107521e8039688f7a9548f17919dfde670b911c1
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Fri Dec 18 22:16:18 2020 +1100

    powerpc/vdso: Don't pass 64-bit ABI cflags to 32-bit VDSO
    
    When building the 32-bit VDSO, we are building 32-bit code as part of
    a 64-bit kernel build. That requires us to tweak the cflags to trick
    the compiler into building 32-bit code for us. The main way we do that
    is by passing -m32, but there are other options that affect code
    generation and ABI selection.
    
    In particular when building vgettimeofday.c, we end up passing
    -mcall-aixdesc because it's in KBUILD_CFLAGS, which causes the
    compiler to generate function descriptors, and dot symbols, eg:
    
      $ nm arch/powerpc/kernel/vdso32/vgettimeofday.o
      000005d0 T .__c_kernel_clock_getres
      00000024 D __c_kernel_clock_getres
      ...
    
    We get away with that at the moment because we also use the DOTSYM
    macro, and that is also incorrectly prepending a '.' in 32-bit VDSO
    code due to a separate bug.
    
    But we shouldn't be generating function descriptors for this file,
    there's no 32-bit ABI that includes function descriptors, so the
    resulting object file is some frankenstein and it's surprising that it
    even links.
    
    So filter out all the ABI-related options we add to CFLAGS for 64-bit
    builds, so that they're not used when building 32-bit code. With that
    we only see regular text symbols:
    
      $ nm arch/powerpc/kernel/vdso32/vgettimeofday.o                                                                                                                                     michael@alpine1-p1
      000005d0 T __c_kernel_clock_getres
      00000000 T __c_kernel_clock_gettime
      00000200 T __c_kernel_clock_gettime64
      00000410 T __c_kernel_gettimeofday
      00000650 T __c_kernel_time
    
    Fixes: ab037dd87a2f ("powerpc/vdso: Switch VDSO to generic C implementation.")
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20201218111619.1206391-2-mpe@ellerman.id.au

commit 0faa22f09caadc11af2aa7570870ebd2ac5b8170
Author: Christophe Leroy <christophe.leroy@csgroup.eu>
Date:   Sun Dec 20 18:18:26 2020 +0000

    powerpc/time: Force inlining of get_tb()
    
    Force inlining of get_tb() in order to avoid getting
    following function in vdso32, leading to suboptimal
    performance in clock_gettime()
    
    00000688 <.get_tb>:
     688:   7c 6d 42 a6     mftbu   r3
     68c:   7c 8c 42 a6     mftb    r4
     690:   7d 2d 42 a6     mftbu   r9
     694:   7c 03 48 40     cmplw   r3,r9
     698:   40 e2 ff f0     bne+    688 <.get_tb>
     69c:   4e 80 00 20     blr
    
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/df05d53eed1210cf1aa76d1fb44aa0fab29c018e.1608488286.git.christophe.leroy@csgroup.eu

commit 7194850efa47c8dac6e805087dd23c7b03af019d
Merge: b80affe33fdd c2e46f6b3e35
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Dec 16 00:17:58 2020 -0800

    Merge tag 'linux-kselftest-next-5.11-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/shuah/linux-kselftest
    
    Pull Kselftest updates from Shuah Khan:
    
     - Much needed gpio test Makefile cleanup to various problems with test
       dependencies and build errors from Michael Ellerman
    
     - Enabling vDSO test on non x86 platforms from Vincenzo Frascino
    
     - Fix intel_pstate to replace deprecated ftime() usages with
       clock_gettime() from Tommi Rantala
    
     - cgroup test build fix on older releases from Sachin Sant
    
     - A couple of spelling mistake fixes
    
    * tag 'linux-kselftest-next-5.11-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/shuah/linux-kselftest:
      selftests/cgroup: Fix build on older distros
      selftests/run_kselftest.sh: fix dry-run typo
      tool: selftests: fix spelling typo of 'writting'
      selftests/memfd: Fix implicit declaration warnings
      selftests: intel_pstate: ftime() is deprecated
      selftests/gpio: Add to CLEAN rule rather than overriding
      selftests/gpio: Fix build when source tree is read only
      selftests/gpio: Move include of lib.mk up
      selftests/gpio: Use TEST_GEN_PROGS_EXTENDED
      kselftest: Extend vdso correctness test to clock_gettime64
      kselftest: Move test_vdso to the vDSO test suite
      kselftest: Extend vDSO selftest to clock_getres
      kselftest: Extend vDSO selftest
      kselftest: Enable vDSO test on non x86 platforms

commit d0e3fc69d00d1f50d22d6b6acfc555ccda80ad1e
Author: Christophe Leroy <christophe.leroy@csgroup.eu>
Date:   Fri Nov 27 00:10:06 2020 +1100

    powerpc/vdso: Provide __kernel_clock_gettime64() on vdso32
    
    Provides __kernel_clock_gettime64() on vdso32. This is the
    64 bits version of __kernel_clock_gettime() which is
    y2038 compliant.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@csgroup.eu>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20201126131006.2431205-9-mpe@ellerman.id.au

commit fc4a3a1bf9ad799181e4d4ec9c2598c0405bc27d
Author: Tommi Rantala <tommi.t.rantala@nokia.com>
Date:   Mon Nov 2 09:39:18 2020 +0200

    selftests: intel_pstate: ftime() is deprecated
    
    Use clock_gettime() instead of deprecated ftime().
    
      aperf.c: In function ‘main’:
      aperf.c:58:2: warning: ‘ftime’ is deprecated [-Wdeprecated-declarations]
         58 |  ftime(&before);
            |  ^~~~~
      In file included from aperf.c:9:
      /usr/include/sys/timeb.h:39:12: note: declared here
         39 | extern int ftime (struct timeb *__timebuf)
            |            ^~~~~
    
    Signed-off-by: Tommi Rantala <tommi.t.rantala@nokia.com>
    Signed-off-by: Shuah Khan <skhan@linuxfoundation.org>

commit 10f8db3c60d2a75eaf2624a4c6ddfff3fa68a29a
Author: Andrei Vagin <avagin@gmail.com>
Date:   Thu Oct 15 09:00:19 2020 -0700

    futex: Adjust absolute futex timeouts with per time namespace offset
    
    commit c2f7d08cccf4af2ce6992feaabb9e68e4ae0bff3 upstream.
    
    For all commands except FUTEX_WAIT, the timeout is interpreted as an
    absolute value. This absolute value is inside the task's time namespace and
    has to be converted to the host's time.
    
    Fixes: 5a590f35add9 ("posix-clocks: Wire up clock_gettime() with timens offsets")
    Reported-by: Hans van der Laan <j.h.vanderlaan@student.utwente.nl>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: <stable@vger.kernel.org>
    Link: https://lore.kernel.org/r/20201015160020.293748-1-avagin@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b2f1c3db28870d88d1a19aa86a8374e7725d62c5
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Mon Oct 26 11:49:45 2020 +0000

    kselftest: Extend vdso correctness test to clock_gettime64
    
    With the release of Linux 5.1 has been added a new syscall,
    clock_gettime64, that provided a 64 bit time value for a specified
    clock_ID to make the kernel Y2038 safe on 32 bit architectures.
    
    Extend the vdso correctness test to cover the newly exposed vdso
    function.
    
    Cc: Shuah Khan <shuah@kernel.org>
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Shuah Khan <skhan@linuxfoundation.org>

commit 693f5ca08ca0767b407b7ca634dbf1b783676ec3
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Mon Oct 26 11:49:42 2020 +0000

    kselftest: Extend vDSO selftest
    
    The current version of the multiarch vDSO selftest verifies only
    gettimeofday.
    
    Extend the vDSO selftest to the other library functions:
     - time
     - clock_getres
     - clock_gettime
    
    The extension has been used to verify the unified vdso library on the
    supported architectures.
    
    Cc: Shuah Khan <shuah@kernel.org>
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Shuah Khan <skhan@linuxfoundation.org>

commit c2f7d08cccf4af2ce6992feaabb9e68e4ae0bff3
Author: Andrei Vagin <avagin@gmail.com>
Date:   Thu Oct 15 09:00:19 2020 -0700

    futex: Adjust absolute futex timeouts with per time namespace offset
    
    For all commands except FUTEX_WAIT, the timeout is interpreted as an
    absolute value. This absolute value is inside the task's time namespace and
    has to be converted to the host's time.
    
    Fixes: 5a590f35add9 ("posix-clocks: Wire up clock_gettime() with timens offsets")
    Reported-by: Hans van der Laan <j.h.vanderlaan@student.utwente.nl>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: <stable@vger.kernel.org>
    Link: https://lore.kernel.org/r/20201015160020.293748-1-avagin@gmail.com

commit 6a725c83a08d41f2bc1630835712a4edc2e6caad
Author: Vineeth Pillai <viremana@linux.microsoft.com>
Date:   Fri Aug 21 15:25:23 2020 +0000

    hv_utils: return error if host timesysnc update is stale
    
    [ Upstream commit 90b125f4cd2697f949f5877df723a0b710693dd0 ]
    
    If for any reason, host timesync messages were not processed by
    the guest, hv_ptp_gettime() returns a stale value and the
    caller (clock_gettime, PTP ioctl etc) has no means to know this
    now. Return an error so that the caller knows about this.
    
    Signed-off-by: Vineeth Pillai <viremana@linux.microsoft.com>
    Reviewed-by: Michael Kelley <mikelley@microsoft.com>
    Link: https://lore.kernel.org/r/20200821152523.99364-1-viremana@linux.microsoft.com
    Signed-off-by: Wei Liu <wei.liu@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 90b125f4cd2697f949f5877df723a0b710693dd0
Author: Vineeth Pillai <viremana@linux.microsoft.com>
Date:   Fri Aug 21 15:25:23 2020 +0000

    hv_utils: return error if host timesysnc update is stale
    
    If for any reason, host timesync messages were not processed by
    the guest, hv_ptp_gettime() returns a stale value and the
    caller (clock_gettime, PTP ioctl etc) has no means to know this
    now. Return an error so that the caller knows about this.
    
    Signed-off-by: Vineeth Pillai <viremana@linux.microsoft.com>
    Reviewed-by: Michael Kelley <mikelley@microsoft.com>
    Link: https://lore.kernel.org/r/20200821152523.99364-1-viremana@linux.microsoft.com
    Signed-off-by: Wei Liu <wei.liu@kernel.org>

commit d1e325cf40fec5fec9b18aa2b537de7e3680ef6c
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Wed Aug 5 11:34:40 2020 +0200

    perf header: Store clock references for -k/--clockid option
    
    Add a new CLOCK_DATA feature that stores reference times when
    -k/--clockid option is specified.
    
    It contains the clock id and its reference time together with wall clock
    time taken at the 'same time', both values are in nanoseconds.
    
    The format of data is as below:
    
      struct {
           u32 version;  /* version = 1 */
           u32 clockid;
           u64 wall_clock_ns;
           u64 clockid_time_ns;
      };
    
    This clock reference times will be used in following changes to display
    wall clock for perf events.
    
    It's available only for recording with clockid specified, because it's
    the only case where we can get reference time to wallclock time. It's
    can't do that with perf clock yet.
    
    Committer testing:
    
      $ perf record -h -k
    
       Usage: perf record [<options>] [<command>]
          or: perf record [<options>] -- <command> [<options>]
    
          -k, --clockid <clockid>
                                clockid to use for events, see clock_gettime()
    
      $ perf record -k monotonic sleep 1
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0.017 MB perf.data (8 samples) ]
      $ perf report --header-only | grep clockid -A1
      # event : name = cycles:u, , id = { 88815, 88816, 88817, 88818, 88819, 88820, 88821, 88822 }, size = 120, { sample_period, sample_freq } = 4000, sample_type = IP|TID|TIME|PERIOD, read_format = ID, disabled = 1, inherit = 1, exclude_kernel = 1, mmap = 1, comm = 1, freq = 1, enable_on_exec = 1, task = 1, precise_ip = 3, sample_id_all = 1, exclude_guest = 1, mmap2 = 1, comm_exec = 1, use_clockid = 1, ksymbol = 1, bpf_event = 1, clockid = 1
      # CPU_TOPOLOGY info available, use -I to display
      --
      # clockid frequency: 1000 MHz
      # cpu pmu capabilities: branches=32, max_precise=3, pmu_name=skylake
      # clockid: monotonic (1)
      # reference time: 2020-08-06 09:40:21.619290 = 1596717621.619290 (TOD) = 21931.077673635 (monotonic)
      $
    
    Original-patch-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Geneviève Bastien <gbastien@versatic.net>
    Cc: Ian Rogers <irogers@google.com>
    Cc: Jeremie Galarneau <jgalar@efficios.com>
    Cc: Michael Petlan <mpetlan@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: http://lore.kernel.org/lkml/20200805093444.314999-4-jolsa@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit f36d129d035c4084c7a7a09f3ef9325862f70c89
Author: Jaedon Shin <jaedon.shin@gmail.com>
Date:   Thu Jun 18 18:15:30 2020 +0100

    ARM: 8987/1: VDSO: Fix incorrect clock_gettime64
    
    commit 4405bdf3c57ec28d606bdf5325f1167505bfdcd4 upstream.
    
    __vdso_*() should be removed and fallback used if CNTCVT is not
    available by cntvct_functional(). __vdso_clock_gettime64 when added
    previous commit is using the incorrect CNTCVT value in that state.
    __vdso_clock_gettime64 is also added to remove it's symbol.
    
    Cc: stable@vger.kernel.org
    Fixes: 74d06efb9c2f ("ARM: 8932/1: Add clock_gettime64 entry point")
    Signed-off-by: Jaedon Shin <jaedon.shin@gmail.com>
    Tested-by: Robin Murphy <robin.mruphy@arm.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c1954ca6abdc69a02a768368eb31882e92cf5bfa
Merge: ae2911de2eb5 5c6360ee4a0e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Jul 31 09:33:45 2020 -0700

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM fixes from Russell King:
    
     - avoid invoking overflow handler for uaccess watchpoints
    
     - fix incorrect clock_gettime64 availability
    
     - fix EFI crash in create_mapping_late()
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm:
      ARM: 8988/1: mmu: fix crash in EFI calls due to p4d typo in create_mapping_late()
      ARM: 8987/1: VDSO: Fix incorrect clock_gettime64
      ARM: 8986/1: hw_breakpoint: Don't invoke overflow handler on uaccess watchpoints

commit 4405bdf3c57ec28d606bdf5325f1167505bfdcd4
Author: Jaedon Shin <jaedon.shin@gmail.com>
Date:   Thu Jun 18 18:15:30 2020 +0100

    ARM: 8987/1: VDSO: Fix incorrect clock_gettime64
    
    __vdso_*() should be removed and fallback used if CNTCVT is not
    available by cntvct_functional(). __vdso_clock_gettime64 when added
    previous commit is using the incorrect CNTCVT value in that state.
    __vdso_clock_gettime64 is also added to remove it's symbol.
    
    Cc: stable@vger.kernel.org
    Fixes: 74d06efb9c2f ("ARM: 8932/1: Add clock_gettime64 entry point")
    Signed-off-by: Jaedon Shin <jaedon.shin@gmail.com>
    Tested-by: Robin Murphy <robin.mruphy@arm.com>
    Signed-off-by: Robin Murphy <robin.murphy@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

commit 92ac971219a29336e466921156b16f8fa88d91aa
Merge: 623f6dc593ea b91c8c42ffdd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 11 15:36:28 2020 -0700

    Merge tag 'timers-urgent-2020-06-11' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer fix from Thomas Gleixner:
     "A small fix for the VDSO code to force inline
      __cvdso_clock_gettime_common() so the compiler
      can't generate horrible code"
    
    * tag 'timers-urgent-2020-06-11' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      lib/vdso: Force inlining of __cvdso_clock_gettime_common()

commit b91c8c42ffdd5c983923edb38b3c3e112bfe6263
Author: Christophe Leroy <christophe.leroy@c-s.fr>
Date:   Tue Apr 28 13:16:53 2020 +0000

    lib/vdso: Force inlining of __cvdso_clock_gettime_common()
    
    When adding gettime64() to a 32 bit architecture (namely powerpc/32)
    it has been noticed that GCC doesn't inline anymore
    __cvdso_clock_gettime_common() because it is called twice
    (Once by __cvdso_clock_gettime() and once by
    __cvdso_clock_gettime32).
    
    This has the effect of seriously degrading the performance:
    
    Before the implementation of gettime64(), gettime() runs in:
    
      clock-gettime-monotonic-raw:      vdso: 1003 nsec/call
      clock-gettime-monotonic-coarse:   vdso:  592 nsec/call
      clock-gettime-monotonic:          vdso:  942 nsec/call
    
    When adding a gettime64() entry point, the standard gettime()
    performance is degraded by 30% to 50%:
    
      clock-gettime-monotonic-raw:      vdso: 1300 nsec/call
      clock-gettime-monotonic-coarse:   vdso:  900 nsec/call
      clock-gettime-monotonic:          vdso: 1232 nsec/call
    
    Adding __always_inline() to __cvdso_clock_gettime_common() regains the
    original performance.
    
    In terms of code size, the inlining increases the code size by only 176
    bytes. This is in the noise for a kernel image.
    
    Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/1ab6a62c356c3bec35d1623563ef9c636205bcda.1588079622.git.christophe.leroy@c-s.fr

commit 964987738b3fe557cb1ee37acb4e7f85e29b7cea
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Mon Apr 27 07:55:07 2020 -0500

    posix-cpu-timers: Replace __get_task_for_clock with pid_for_clock
    
    Now that the codes store references to pids instead of referendes to
    tasks.  Looking up a task for a clock instead of looking up a struct
    pid makes the code more difficult to verify it is correct than
    necessary.
    
    In posix_cpu_timers_create get_task_pid can race with release_task for
    threads and return a NULL pid.  As put_pid and cpu_timer_task_rcu
    handle NULL pids just fine the code works without problems but it is
    an extra case to consider and keep in mind while verifying and
    modifying the code.
    
    There are races with de_thread to consider that only don't apply
    because thread clocks are only allowed for threads in the same
    thread_group.
    
    So instead of leaving a burden for people making modification to the
    code in the future return a rcu protected struct pid for the clock
    instead.
    
    The logic for __get_task_for_pid and lookup_task has been folded into
    the new function pid_for_clock with the only change being the logic
    has been modified from working on a task to working on a pid that
    will be returned.
    
    In posix_cpu_clock_get instead of calling pid_for_clock checking the
    result and then calling pid_task to get the task.  The result of
    pid_for_clock is fed directly into pid_task.  This is safe because
    pid_task handles NULL pids.  As such an extra error check was
    unnecessary.
    
    Instead of hiding the flag that enables the special clock_gettime
    handling, I have made the 3 callers just pass the flag in themselves.
    That is less code and seems just as simple to work with as the
    wrapper functions.
    
    Historically the clock_gettime special case of allowing a process
    clock to be found by the thread id did not even exist [33ab0fec3352]
    but Thomas Gleixner reports that he has found code that uses that
    functionality [55e8c8eb2c7b].
    
    Link: https://lkml.kernel.org/r/87zhaxqkwa.fsf@nanos.tec.linutronix.de/
    Ref: 33ab0fec3352 ("posix-timers: Consolidate posix_cpu_clock_get()")
    Ref: 55e8c8eb2c7b ("posix-cpu-timers: Store a reference to a pid not a task")
    Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>

commit 082b57e3eb09810d357083cca5ee2df02c16aec9
Author: Maciej Żenczykowski <maze@google.com>
Date:   Mon Apr 20 11:47:50 2020 -0700

    net: bpf: Make bpf_ktime_get_ns() available to non GPL programs
    
    The entire implementation is in kernel/bpf/helpers.c:
    
    BPF_CALL_0(bpf_ktime_get_ns) {
           /* NMI safe access to clock monotonic */
           return ktime_get_mono_fast_ns();
    }
    
    const struct bpf_func_proto bpf_ktime_get_ns_proto = {
           .func           = bpf_ktime_get_ns,
           .gpl_only       = false,
           .ret_type       = RET_INTEGER,
    };
    
    and this was presumably marked GPL due to kernel/time/timekeeping.c:
      EXPORT_SYMBOL_GPL(ktime_get_mono_fast_ns);
    
    and while that may make sense for kernel modules (although even that
    is doubtful), there is currently AFAICT no other source of time
    available to ebpf.
    
    Furthermore this is really just equivalent to clock_gettime(CLOCK_MONOTONIC)
    which is exposed to userspace (via vdso even to make it performant)...
    
    As such, I see no reason to keep the GPL restriction.
    (In the future I'd like to have access to time from Apache licensed ebpf code)
    
    Signed-off-by: Maciej Żenczykowski <maze@google.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

commit 12a5b00a5366467e95a25f55da751794e5fe6788
Author: Masahiro Yamada <masahiroy@kernel.org>
Date:   Mon Apr 6 20:09:30 2020 -0700

    sparc,x86: vdso: remove meaningless undefining CONFIG_OPTIMIZE_INLINING
    
    The code, #undef CONFIG_OPTIMIZE_INLINING, is not working as expected
    because <linux/compiler_types.h> is parsed before vclock_gettime.c since
    28128c61e08e ("kconfig.h: Include compiler types to avoid missed struct
    attributes").
    
    Since then, <linux/compiler_types.h> is included really early by using the
    '-include' option.  So, you cannot negate the decision of
    <linux/compiler_types.h> in this way.
    
    You can confirm it by checking the pre-processed code, like this:
    
      $ make arch/x86/entry/vdso/vdso32/vclock_gettime.i
    
    There is no difference with/without CONFIG_CC_OPTIMIZE_FOR_SIZE.
    
    It is about two years since 28128c61e08e.  Nobody has reported a problem
    (or, nobody has even noticed the fact that this code is not working).
    
    It is ugly and unreliable to attempt to undefine a CONFIG option from C
    files, and anyway the inlining heuristic is up to the compiler.
    
    Just remove the broken code.
    
    Signed-off-by: Masahiro Yamada <masahiroy@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Nathan Chancellor <natechancellor@gmail.com>
    Acked-by: Miguel Ojeda <miguel.ojeda.sandonis@gmail.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Masahiro Yamada <masahiroy@kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: David Miller <davem@davemloft.net>
    Link: http://lkml.kernel.org/r/20200220110807.32534-1-masahiroy@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 7b81a551f594371dcb2f2952b5f699fd782a9e6e
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    commit 45939ce292b4b11159719faaf60aba7d58d5fe33 upstream.
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1a9e78628d44803a8b146f4c641551d29afaa9b6
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    commit 45939ce292b4b11159719faaf60aba7d58d5fe33 upstream.
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8cf58ea4abd3debe79c714400232f1e312dec621
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    commit 45939ce292b4b11159719faaf60aba7d58d5fe33 upstream.
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1940bd214aeacfc27d27c082f0285fe3e673cff7
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    commit 45939ce292b4b11159719faaf60aba7d58d5fe33 upstream.
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3a4c51d02e70ca4af86cd5b50c4aef3007e04e03
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    commit 45939ce292b4b11159719faaf60aba7d58d5fe33 upstream.
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f936626b52d2beb8044f3ce40df1e59caf411da7
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    commit 45939ce292b4b11159719faaf60aba7d58d5fe33 upstream.
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 05f4a6e5a615841f7cf87ae969cbc6ec499bb2b3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jan 14 19:52:39 2020 +0100

    lib/vdso: Update coarse timekeeper unconditionally
    
    commit 9f24c540f7f8eb3a981528da9a9a636a5bdf5987 upstream.
    
    The low resolution parts of the VDSO, i.e.:
    
      clock_gettime(CLOCK_*_COARSE), clock_getres(), time()
    
    can be used even if there is no VDSO capable clocksource.
    
    But if an architecture opts out of the VDSO data update then this
    information becomes stale. This affects ARM when there is no architected
    timer available. The lack of update causes userspace to use stale data
    forever.
    
    Make the update of the low resolution parts unconditional and only skip
    the update of the high resolution parts if the architecture requests it.
    
    Fixes: 44f57d788e7d ("timekeeping: Provide a generic update_vsyscall() implementation")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200114185946.765577901@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1fabae5c846f2c14f98f7e96228caa0e871cf922
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jan 14 19:52:39 2020 +0100

    lib/vdso: Update coarse timekeeper unconditionally
    
    commit 9f24c540f7f8eb3a981528da9a9a636a5bdf5987 upstream.
    
    The low resolution parts of the VDSO, i.e.:
    
      clock_gettime(CLOCK_*_COARSE), clock_getres(), time()
    
    can be used even if there is no VDSO capable clocksource.
    
    But if an architecture opts out of the VDSO data update then this
    information becomes stale. This affects ARM when there is no architected
    timer available. The lack of update causes userspace to use stale data
    forever.
    
    Make the update of the low resolution parts unconditional and only skip
    the update of the high resolution parts if the architecture requests it.
    
    Fixes: 44f57d788e7d ("timekeeping: Provide a generic update_vsyscall() implementation")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200114185946.765577901@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 45939ce292b4b11159719faaf60aba7d58d5fe33
Author: Florian Fainelli <f.fainelli@gmail.com>
Date:   Tue Jan 28 20:22:13 2020 +0100

    ARM: 8957/1: VDSO: Match ARMv8 timer in cntvct_functional()
    
    It is possible for a system with an ARMv8 timer to run a 32-bit kernel.
    When this happens we will unconditionally have the vDSO code remove the
    __vdso_gettimeofday and __vdso_clock_gettime symbols because
    cntvct_functional() returns false since it does not match that
    compatibility string.
    
    Fixes: ecf99a439105 ("ARM: 8331/1: VDSO initialization, mapping, and synchronization")
    Signed-off-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

commit 9f24c540f7f8eb3a981528da9a9a636a5bdf5987
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jan 14 19:52:39 2020 +0100

    lib/vdso: Update coarse timekeeper unconditionally
    
    The low resolution parts of the VDSO, i.e.:
    
      clock_gettime(CLOCK_*_COARSE), clock_getres(), time()
    
    can be used even if there is no VDSO capable clocksource.
    
    But if an architecture opts out of the VDSO data update then this
    information becomes stale. This affects ARM when there is no architected
    timer available. The lack of update causes userspace to use stale data
    forever.
    
    Make the update of the low resolution parts unconditional and only skip
    the update of the high resolution parts if the architecture requests it.
    
    Fixes: 44f57d788e7d ("timekeeping: Provide a generic update_vsyscall() implementation")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20200114185946.765577901@linutronix.de

commit 99570c3da96a0f7aa11c6ad4981776f3adabf3b5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Jan 16 20:43:41 2020 +0100

    MIPS: vdso: Define BUILD_VDSO32 when building a 32bit kernel
    
    The confinement of the 32bit specific VDSO functions missed to define
    BUILD_VDSO32 when building a 32bit MIPS kernel:
    
    arch/mips/vdso/vgettimeofday.c: In function __vdso_clock_gettime:
    arch/mips/vdso/vgettimeofday.c:17:9: error: implicit declaration of function __cvdso_clock_gettime32
    
    arch/mips/vdso/vgettimeofday.c: In function __vdso_clock_getres:
    arch/mips/vdso/vgettimeofday.c:39:9: error: implicit declaration of function __cvdso_clock_getres_time32
    
    Force the define for 32bit builds in the VDSO Makefile.
    
    Fixes: bf279849ad59 ("lib/vdso: Build 32 bit specific functions in the right context")
    Reported-by: kbuild test robot <lkp@intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Paul Burton <paulburton@kernel.org>
    Link: https://lore.kernel.org/r/87d0bjfaqa.fsf@nanos.tec.linutronix.de

commit 1854b97e4fa6a476d5cdc3dc30c42e1528699f87
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:27:22 2019 +0000

    selftests/timens: Add a simple perf test for clock_gettime()
    
    Output on success:
    1..4
     ok 1 host:     clock:  monotonic       cycles:  148323947
     ok 2 host:     clock:   boottime       cycles:  148577503
     ok 3 ns:       clock:  monotonic       cycles:  137659217
     ok 4 ns:       clock:   boottime       cycles:  137959154
     # Pass 4 Fail 0 Xfail 0 Xpass 0 Skip 0 Error 0
    
    Output with lack of permissions:
     1..4
     ok 1 host:     clock:  monotonic       cycles:  145671139
     ok 2 host:     clock:   boottime       cycles:  146958357
     not ok 3 # SKIP need to run as root
    
    Output without support of time namespaces:
     1..4
     ok 1 host:     clock:  monotonic       cycles:  145671139
     ok 2 host:     clock:   boottime       cycles:  146958357
     not ok 3 # SKIP Time namespaces are not supported
    
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-34-dima@arista.com

commit 5a590f35add93c2bdf3ed83eee73111021679562
Author: Andrei Vagin <avagin@openvz.org>
Date:   Tue Nov 12 01:27:00 2019 +0000

    posix-clocks: Wire up clock_gettime() with timens offsets
    
    Adjust monotonic and boottime clocks with per-timens offsets.  As the
    result a process inside time namespace will see timers and clocks corrected
    to offsets that were set when the namespace was created
    
    Note that applications usually go through vDSO to get time, which is not
    yet adjusted. Further changes will complete time namespace virtualisation
    with vDSO support.
    
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-12-dima@arista.com

commit 9c71a2e8a757bc6aee256bc97c6fb711144b0a0f
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:58 2019 +0000

    posix-clocks: Introduce clock_get_ktime() callback
    
    The callsite in common_timer_get() has already a comment:
        /*
         * The timespec64 based conversion is suboptimal, but it's not
         * worth to implement yet another callback.
         */
        kc->clock_get(timr->it_clock, &ts64);
        now = timespec64_to_ktime(ts64);
    
    The upcoming support for time namespaces requires to have access to:
    
     - The time in a task's time namespace for sys_clock_gettime()
     - The time in the root name space for common_timer_get()
    
    That adds a valid reason to finally implement a separate callback which
    returns the time in ktime_t format.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-10-dima@arista.com

commit 2f58bf909abf9670fa4e848b433dc12ba4c2a44e
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:57 2019 +0000

    alarmtimer: Provide get_timespec() callback
    
    The upcoming support for time namespaces requires to have access to:
    
      - The time in a task's time namespace for sys_clock_gettime()
      - The time in the root name space for common_timer_get()
    
    Wire up alarm bases with get_timespec().
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-9-dima@arista.com

commit 41b3b8dffc1f84e581addfbc09bec0289db3315e
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:56 2019 +0000

    alarmtimer: Rename gettime() callback to get_ktime()
    
    The upcoming support for time namespaces requires to have access to:
    
      - The time in a tasks time namespace for sys_clock_gettime()
      - The time in the root name space for common_timer_get()
    
    struct alarm_base needs to follow the same naming convention, so rename
    .gettime() callback into get_ktime() as a preparation for introducing
    get_timespec().
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-8-dima@arista.com

commit eaf80194d0fe48be393587541c48a799a9a06a70
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:55 2019 +0000

    posix-clocks: Rename .clock_get_timespec() callbacks accordingly
    
    The upcoming support for time namespaces requires to have access to:
    
      - The time in a task's time namespace for sys_clock_gettime()
      - The time in the root name space for common_timer_get()
    
    That adds a valid reason to finally implement a separate callback which
    returns the time in ktime_t format in (struct k_clock).
    
    As a preparation ground for introducing clock_get_ktime(), the original
    callback clock_get() was renamed into clock_get_timespec().
    Reflect the renaming into the callback implementations.
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-7-dima@arista.com

commit 819a95fe3adfc7b558bfd96dd5ac589c4f543fd4
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:54 2019 +0000

    posix-clocks: Rename the clock_get() callback to clock_get_timespec()
    
    The upcoming support for time namespaces requires to have access to:
    
     - The time in a task's time namespace for sys_clock_gettime()
     - The time in the root name space for common_timer_get()
    
    That adds a valid reason to finally implement a separate callback which
    returns the time in ktime_t format, rather than in (struct timespec).
    
    Rename the clock_get() callback to clock_get_timespec() as a preparation
    for introducing clock_get_ktime().
    
    Suggested-by: Thomas Gleixner <tglx@linutronix.de>
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-6-dima@arista.com

commit c966533f8c6c45f93c52599f8460e7695f0b7eaa
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:51 2019 +0000

    lib/vdso: Mark do_hres() and do_coarse() as __always_inline
    
    Performance numbers for Intel(R) Core(TM) i5-6300U CPU @ 2.40GHz
    (more clock_gettime() cycles - the better):
    
    clock            | before     | after      | diff
    ----------------------------------------------------------
    monotonic        |  153222105 |  166775025 | 8.8%
    monotonic-coarse |  671557054 |  691513017 | 3.0%
    monotonic-raw    |  147116067 |  161057395 | 9.5%
    boottime         |  153446224 |  166962668 | 9.1%
    
    The improvement for arm64 for monotonic and boottime is around 3.5%.
    
    clock            | before     | after      | diff
    ==================================================
    monotonic          17326692     17951770     3.6%
    monotonic-coarse   43624027     44215292     1.3%
    monotonic-raw      17541809     17554932     0.1%
    boottime           17334982     17954361     3.5%
    
    [ tglx: Avoid the goto ]
    
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20191112012724.250792-3-dima@arista.com

commit 0898a16a362d436464b34fa644d0d46efc81df92
Author: Andrei Vagin <avagin@gmail.com>
Date:   Tue Nov 12 01:26:50 2019 +0000

    lib/vdso: Add unlikely() hint into vdso_read_begin()
    
    Place the branch with no concurrent write before the contended case.
    
    Performance numbers for Intel(R) Core(TM) i5-6300U CPU @ 2.40GHz
    (more clock_gettime() cycles - the better):
            | before    | after
    -----------------------------------
            | 150252214 | 153242367
            | 150301112 | 153324800
            | 150392773 | 153125401
            | 150373957 | 153399355
            | 150303157 | 153489417
            | 150365237 | 153494270
    -----------------------------------
    avg     | 150331408 | 153345935
    diff %  | 2         | 0
    -----------------------------------
    stdev % | 0.3       | 0.1
    
    Co-developed-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Andrei Vagin <avagin@gmail.com>
    Signed-off-by: Dmitry Safonov <dima@arista.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lore.kernel.org/r/20191112012724.250792-2-dima@arista.com

commit b767081c07a400ff1c6f95b87639a9405886e7a6
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Aug 30 14:58:58 2019 +0100

    lib/vdso: Remove VDSO_HAS_32BIT_FALLBACK
    
    VDSO_HAS_32BIT_FALLBACK was introduced to address a regression which
    caused seccomp to deny access to the applications to clock_gettime64()
    and clock_getres64() because they are not enabled in the existing
    filters.
    
    The purpose of VDSO_HAS_32BIT_FALLBACK was to simplify the conditional
    implementation of __cvdso_clock_get*time32() variants.
    
    Now that all the architectures that support the generic vDSO library
    have been converted to support the 32 bit fallbacks the conditional
    can be removed.
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20190830135902.20861-5-vincenzo.frascino@arm.com
    
    References: c60a32ea4f45 ("lib/vdso/32: Provide legacy syscall fallbacks")

commit bf279849ad59538a1518c667c0795ec1fe9dbd66
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Aug 30 14:58:56 2019 +0100

    lib/vdso: Build 32 bit specific functions in the right context
    
    clock_gettime32 and clock_getres_time32 should be compiled only with a
    32 bit vdso library.
    
    Exclude these symbols when BUILD_VDSO32 is not defined.
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lore.kernel.org/r/20190830135902.20861-3-vincenzo.frascino@arm.com

commit 3b5584afeef05319ade0fbf5f634a64fd3e5772b
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Aug 30 14:58:55 2019 +0100

    arm64: compat: vdso: Expose BUILD_VDSO32
    
    clock_gettime32 and clock_getres_time32 should be compiled only with the
    32 bit vdso library.
    
    Expose BUILD_VDSO32 when arm64 compat is compiled, to provide an
    indication to the generic library to include these symbols.
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Link: https://lore.kernel.org/r/20190830135902.20861-2-vincenzo.frascino@arm.com

commit 157560f95d4cb5e3d15a91e489d0acbf399fabf1
Author: Vladimir Oltean <vladimir.oltean@nxp.com>
Date:   Tue Dec 3 17:45:35 2019 +0200

    net: mscc: ocelot: unregister the PTP clock on deinit
    
    [ Upstream commit 9385973fe8db9743fa93bf17245635be4eb8c4a6 ]
    
    Currently a switch driver deinit frees the regmaps, but the PTP clock is
    still out there, available to user space via /dev/ptpN. Any PTP
    operation is a ticking time bomb, since it will attempt to use the freed
    regmaps and thus trigger kernel panics:
    
    [    4.291746] fsl_enetc 0000:00:00.2 eth1: error -22 setting up slave phy
    [    4.291871] mscc_felix 0000:00:00.5: Failed to register DSA switch: -22
    [    4.308666] mscc_felix: probe of 0000:00:00.5 failed with error -22
    [    6.358270] Unable to handle kernel NULL pointer dereference at virtual address 0000000000000088
    [    6.367090] Mem abort info:
    [    6.369888]   ESR = 0x96000046
    [    6.369891]   EC = 0x25: DABT (current EL), IL = 32 bits
    [    6.369892]   SET = 0, FnV = 0
    [    6.369894]   EA = 0, S1PTW = 0
    [    6.369895] Data abort info:
    [    6.369897]   ISV = 0, ISS = 0x00000046
    [    6.369899]   CM = 0, WnR = 1
    [    6.369902] user pgtable: 4k pages, 48-bit VAs, pgdp=00000020d58c7000
    [    6.369904] [0000000000000088] pgd=00000020d5912003, pud=00000020d5915003, pmd=0000000000000000
    [    6.369914] Internal error: Oops: 96000046 [#1] PREEMPT SMP
    [    6.420443] Modules linked in:
    [    6.423506] CPU: 1 PID: 262 Comm: phc_ctl Not tainted 5.4.0-03625-gb7b2a5dadd7f #204
    [    6.431273] Hardware name: LS1028A RDB Board (DT)
    [    6.435989] pstate: 40000085 (nZcv daIf -PAN -UAO)
    [    6.440802] pc : css_release+0x24/0x58
    [    6.444561] lr : regmap_read+0x40/0x78
    [    6.448316] sp : ffff800010513cc0
    [    6.451636] x29: ffff800010513cc0 x28: ffff002055873040
    [    6.456963] x27: 0000000000000000 x26: 0000000000000000
    [    6.462289] x25: 0000000000000000 x24: 0000000000000000
    [    6.467617] x23: 0000000000000000 x22: 0000000000000080
    [    6.472944] x21: ffff800010513d44 x20: 0000000000000080
    [    6.478270] x19: 0000000000000000 x18: 0000000000000000
    [    6.483596] x17: 0000000000000000 x16: 0000000000000000
    [    6.488921] x15: 0000000000000000 x14: 0000000000000000
    [    6.494247] x13: 0000000000000000 x12: 0000000000000000
    [    6.499573] x11: 0000000000000000 x10: 0000000000000000
    [    6.504899] x9 : 0000000000000000 x8 : 0000000000000000
    [    6.510225] x7 : 0000000000000000 x6 : ffff800010513cf0
    [    6.515550] x5 : 0000000000000000 x4 : 0000000fffffffe0
    [    6.520876] x3 : 0000000000000088 x2 : ffff800010513d44
    [    6.526202] x1 : ffffcada668ea000 x0 : ffffcada64d8b0c0
    [    6.531528] Call trace:
    [    6.533977]  css_release+0x24/0x58
    [    6.537385]  regmap_read+0x40/0x78
    [    6.540795]  __ocelot_read_ix+0x6c/0xa0
    [    6.544641]  ocelot_ptp_gettime64+0x4c/0x110
    [    6.548921]  ptp_clock_gettime+0x4c/0x58
    [    6.552853]  pc_clock_gettime+0x5c/0xa8
    [    6.556699]  __arm64_sys_clock_gettime+0x68/0xc8
    [    6.561331]  el0_svc_common.constprop.2+0x7c/0x178
    [    6.566133]  el0_svc_handler+0x34/0xa0
    [    6.569891]  el0_sync_handler+0x114/0x1d0
    [    6.573908]  el0_sync+0x140/0x180
    [    6.577232] Code: d503201f b00119a1 91022263 b27b7be4 (f9004663)
    [    6.583349] ---[ end trace d196b9b14cdae2da ]---
    [    6.587977] Kernel panic - not syncing: Fatal exception
    [    6.593216] SMP: stopping secondary CPUs
    [    6.597151] Kernel Offset: 0x4ada54400000 from 0xffff800010000000
    [    6.603261] PHYS_OFFSET: 0xffffd0a7c0000000
    [    6.607454] CPU features: 0x10002,21806008
    [    6.611558] Memory Limit: none
    
    And now that ocelot->ptp_clock is checked at exit, prevent a potential
    error where ptp_clock_register returned a pointer-encoded error, which
    we are keeping in the ocelot private data structure. So now,
    ocelot->ptp_clock is now either NULL or a valid pointer.
    
    Fixes: 4e3b0468e6d7 ("net: mscc: PTP Hardware Clock (PHC) support")
    Cc: Antoine Tenart <antoine.tenart@bootlin.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Vladimir Oltean <vladimir.oltean@nxp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9385973fe8db9743fa93bf17245635be4eb8c4a6
Author: Vladimir Oltean <vladimir.oltean@nxp.com>
Date:   Tue Dec 3 17:45:35 2019 +0200

    net: mscc: ocelot: unregister the PTP clock on deinit
    
    Currently a switch driver deinit frees the regmaps, but the PTP clock is
    still out there, available to user space via /dev/ptpN. Any PTP
    operation is a ticking time bomb, since it will attempt to use the freed
    regmaps and thus trigger kernel panics:
    
    [    4.291746] fsl_enetc 0000:00:00.2 eth1: error -22 setting up slave phy
    [    4.291871] mscc_felix 0000:00:00.5: Failed to register DSA switch: -22
    [    4.308666] mscc_felix: probe of 0000:00:00.5 failed with error -22
    [    6.358270] Unable to handle kernel NULL pointer dereference at virtual address 0000000000000088
    [    6.367090] Mem abort info:
    [    6.369888]   ESR = 0x96000046
    [    6.369891]   EC = 0x25: DABT (current EL), IL = 32 bits
    [    6.369892]   SET = 0, FnV = 0
    [    6.369894]   EA = 0, S1PTW = 0
    [    6.369895] Data abort info:
    [    6.369897]   ISV = 0, ISS = 0x00000046
    [    6.369899]   CM = 0, WnR = 1
    [    6.369902] user pgtable: 4k pages, 48-bit VAs, pgdp=00000020d58c7000
    [    6.369904] [0000000000000088] pgd=00000020d5912003, pud=00000020d5915003, pmd=0000000000000000
    [    6.369914] Internal error: Oops: 96000046 [#1] PREEMPT SMP
    [    6.420443] Modules linked in:
    [    6.423506] CPU: 1 PID: 262 Comm: phc_ctl Not tainted 5.4.0-03625-gb7b2a5dadd7f #204
    [    6.431273] Hardware name: LS1028A RDB Board (DT)
    [    6.435989] pstate: 40000085 (nZcv daIf -PAN -UAO)
    [    6.440802] pc : css_release+0x24/0x58
    [    6.444561] lr : regmap_read+0x40/0x78
    [    6.448316] sp : ffff800010513cc0
    [    6.451636] x29: ffff800010513cc0 x28: ffff002055873040
    [    6.456963] x27: 0000000000000000 x26: 0000000000000000
    [    6.462289] x25: 0000000000000000 x24: 0000000000000000
    [    6.467617] x23: 0000000000000000 x22: 0000000000000080
    [    6.472944] x21: ffff800010513d44 x20: 0000000000000080
    [    6.478270] x19: 0000000000000000 x18: 0000000000000000
    [    6.483596] x17: 0000000000000000 x16: 0000000000000000
    [    6.488921] x15: 0000000000000000 x14: 0000000000000000
    [    6.494247] x13: 0000000000000000 x12: 0000000000000000
    [    6.499573] x11: 0000000000000000 x10: 0000000000000000
    [    6.504899] x9 : 0000000000000000 x8 : 0000000000000000
    [    6.510225] x7 : 0000000000000000 x6 : ffff800010513cf0
    [    6.515550] x5 : 0000000000000000 x4 : 0000000fffffffe0
    [    6.520876] x3 : 0000000000000088 x2 : ffff800010513d44
    [    6.526202] x1 : ffffcada668ea000 x0 : ffffcada64d8b0c0
    [    6.531528] Call trace:
    [    6.533977]  css_release+0x24/0x58
    [    6.537385]  regmap_read+0x40/0x78
    [    6.540795]  __ocelot_read_ix+0x6c/0xa0
    [    6.544641]  ocelot_ptp_gettime64+0x4c/0x110
    [    6.548921]  ptp_clock_gettime+0x4c/0x58
    [    6.552853]  pc_clock_gettime+0x5c/0xa8
    [    6.556699]  __arm64_sys_clock_gettime+0x68/0xc8
    [    6.561331]  el0_svc_common.constprop.2+0x7c/0x178
    [    6.566133]  el0_svc_handler+0x34/0xa0
    [    6.569891]  el0_sync_handler+0x114/0x1d0
    [    6.573908]  el0_sync+0x140/0x180
    [    6.577232] Code: d503201f b00119a1 91022263 b27b7be4 (f9004663)
    [    6.583349] ---[ end trace d196b9b14cdae2da ]---
    [    6.587977] Kernel panic - not syncing: Fatal exception
    [    6.593216] SMP: stopping secondary CPUs
    [    6.597151] Kernel Offset: 0x4ada54400000 from 0xffff800010000000
    [    6.603261] PHYS_OFFSET: 0xffffd0a7c0000000
    [    6.607454] CPU features: 0x10002,21806008
    [    6.611558] Memory Limit: none
    
    And now that ocelot->ptp_clock is checked at exit, prevent a potential
    error where ptp_clock_register returned a pointer-encoded error, which
    we are keeping in the ocelot private data structure. So now,
    ocelot->ptp_clock is now either NULL or a valid pointer.
    
    Fixes: 4e3b0468e6d7 ("net: mscc: PTP Hardware Clock (PHC) support")
    Cc: Antoine Tenart <antoine.tenart@bootlin.com>
    Reviewed-by: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Vladimir Oltean <vladimir.oltean@nxp.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 9dd0013824fc29e618db7a5b0bac5545285b946a
Merge: 2309d0768237 1a70cf0e7ee6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Nov 30 14:29:19 2019 -0800

    Merge tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm
    
    Pull ARM updates from Russell King:
    
     - improve ARM implementation of pfn_valid()
    
     - various sparse fixes
    
     - spelling fixes
    
     - add further ARMv8 debug architecture versions
    
     - clang fix for decompressor
    
     - update to generic vDSO
    
     - remove Brahma-B53 from spectre hardening
    
     - initialise broadcast hrtimer device
    
     - use correct nm executable in decompressor
    
     - remove old mcount et.al.
    
    * tag 'for-linus' of git://git.armlinux.org.uk/~rmk/linux-arm: (26 commits)
      ARM: 8940/1: ftrace: remove mcount(),ftrace_caller_old() and ftrace_call_old()
      ARM: 8939/1: kbuild: use correct nm executable
      ARM: 8938/1: kernel: initialize broadcast hrtimer based clock event device
      ARM: 8937/1: spectre-v2: remove Brahma-B53 from hardening
      ARM: 8933/1: replace Sun/Solaris style flag on section directive
      ARM: 8932/1: Add clock_gettime64 entry point
      ARM: 8931/1: Add clock_getres entry point
      ARM: 8930/1: Add support for generic vDSO
      ARM: 8929/1: use APSR_nzcv instead of r15 as mrc operand
      ARM: 8927/1: ARM/hw_breakpoint: add more ARMv8 debug architecture versions support
      ARM: 8918/2: only build return_address() if needed
      ARM: 8928/1: ARM_ERRATA_775420: Spelling s/date/data/
      ARM: 8925/1: tcm: include <asm/tcm.h> for missing declarations
      ARM: 8924/1: tcm: make dtcm_end and itcm_end static
      ARM: 8923/1: mm: include <asm/vga.h> for vga_base
      ARM: 8922/1: parse_dt_topology() rate is pointer to __be32
      ARM: 8920/1: share get_signal_page from signal.c to process.c
      ARM: 8919/1: make unexported functions static
      ARM: 8917/1: mm: include <asm/set_memory.h>
      ARM: 8916/1: mm: make set_section_perms() static
      ...

commit 0b7600db547a532f8bf0b6a222c3eec73931febc
Author: Alan Modra <amodra@gmail.com>
Date:   Fri Sep 14 13:10:04 2018 +0930

    powerpc/vdso: Correct call frame information
    
    [ Upstream commit 56d20861c027498b5a1112b4f9f05b56d906fdda ]
    
    Call Frame Information is used by gdb for back-traces and inserting
    breakpoints on function return for the "finish" command.  This failed
    when inside __kernel_clock_gettime.  More concerning than difficulty
    debugging is that CFI is also used by stack frame unwinding code to
    implement exceptions.  If you have an app that needs to handle
    asynchronous exceptions for some reason, and you are unlucky enough to
    get one inside the VDSO time functions, your app will crash.
    
    What's wrong:  There is control flow in __kernel_clock_gettime that
    reaches label 99 without saving lr in r12.  CFI info however is
    interpreted by the unwinder without reference to control flow: It's a
    simple matter of "Execute all the CFI opcodes up to the current
    address".  That means the unwinder thinks r12 contains the return
    address at label 99.  Disabuse it of that notion by resetting CFI for
    the return address at label 99.
    
    Note that the ".cfi_restore lr" could have gone anywhere from the
    "mtlr r12" a few instructions earlier to the instruction at label 99.
    I put the CFI as late as possible, because in general that's best
    practice (and if possible grouped with other CFI in order to reduce
    the number of CFI opcodes executed when unwinding).  Using r12 as the
    return address is perfectly fine after the "mtlr r12" since r12 on
    that code path still contains the return address.
    
    __get_datapage also has a CFI error.  That function temporarily saves
    lr in r0, and reflects that fact with ".cfi_register lr,r0".  A later
    use of r0 means the CFI at that point isn't correct, as r0 no longer
    contains the return address.  Fix that too.
    
    Signed-off-by: Alan Modra <amodra@gmail.com>
    Tested-by: Reza Arbab <arbab@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 039eb3d5d06cab7eabca8557973a2bce783d84e3
Author: Alan Modra <amodra@gmail.com>
Date:   Fri Sep 14 13:10:04 2018 +0930

    powerpc/vdso: Correct call frame information
    
    [ Upstream commit 56d20861c027498b5a1112b4f9f05b56d906fdda ]
    
    Call Frame Information is used by gdb for back-traces and inserting
    breakpoints on function return for the "finish" command.  This failed
    when inside __kernel_clock_gettime.  More concerning than difficulty
    debugging is that CFI is also used by stack frame unwinding code to
    implement exceptions.  If you have an app that needs to handle
    asynchronous exceptions for some reason, and you are unlucky enough to
    get one inside the VDSO time functions, your app will crash.
    
    What's wrong:  There is control flow in __kernel_clock_gettime that
    reaches label 99 without saving lr in r12.  CFI info however is
    interpreted by the unwinder without reference to control flow: It's a
    simple matter of "Execute all the CFI opcodes up to the current
    address".  That means the unwinder thinks r12 contains the return
    address at label 99.  Disabuse it of that notion by resetting CFI for
    the return address at label 99.
    
    Note that the ".cfi_restore lr" could have gone anywhere from the
    "mtlr r12" a few instructions earlier to the instruction at label 99.
    I put the CFI as late as possible, because in general that's best
    practice (and if possible grouped with other CFI in order to reduce
    the number of CFI opcodes executed when unwinding).  Using r12 as the
    return address is perfectly fine after the "mtlr r12" since r12 on
    that code path still contains the return address.
    
    __get_datapage also has a CFI error.  That function temporarily saves
    lr in r0, and reflects that fact with ".cfi_register lr,r0".  A later
    use of r0 means the CFI at that point isn't correct, as r0 no longer
    contains the return address.  Fix that too.
    
    Signed-off-by: Alan Modra <amodra@gmail.com>
    Tested-by: Reza Arbab <arbab@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e70ccd8a13a9a966df74496fc65a7caa308ae481
Author: Alan Modra <amodra@gmail.com>
Date:   Fri Sep 14 13:10:04 2018 +0930

    powerpc/vdso: Correct call frame information
    
    [ Upstream commit 56d20861c027498b5a1112b4f9f05b56d906fdda ]
    
    Call Frame Information is used by gdb for back-traces and inserting
    breakpoints on function return for the "finish" command.  This failed
    when inside __kernel_clock_gettime.  More concerning than difficulty
    debugging is that CFI is also used by stack frame unwinding code to
    implement exceptions.  If you have an app that needs to handle
    asynchronous exceptions for some reason, and you are unlucky enough to
    get one inside the VDSO time functions, your app will crash.
    
    What's wrong:  There is control flow in __kernel_clock_gettime that
    reaches label 99 without saving lr in r12.  CFI info however is
    interpreted by the unwinder without reference to control flow: It's a
    simple matter of "Execute all the CFI opcodes up to the current
    address".  That means the unwinder thinks r12 contains the return
    address at label 99.  Disabuse it of that notion by resetting CFI for
    the return address at label 99.
    
    Note that the ".cfi_restore lr" could have gone anywhere from the
    "mtlr r12" a few instructions earlier to the instruction at label 99.
    I put the CFI as late as possible, because in general that's best
    practice (and if possible grouped with other CFI in order to reduce
    the number of CFI opcodes executed when unwinding).  Using r12 as the
    return address is perfectly fine after the "mtlr r12" since r12 on
    that code path still contains the return address.
    
    __get_datapage also has a CFI error.  That function temporarily saves
    lr in r0, and reflects that fact with ".cfi_register lr,r0".  A later
    use of r0 means the CFI at that point isn't correct, as r0 no longer
    contains the return address.  Fix that too.
    
    Signed-off-by: Alan Modra <amodra@gmail.com>
    Tested-by: Reza Arbab <arbab@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit dc87cafee594a0244824fa5668bf1b3e9540f286
Author: Alan Modra <amodra@gmail.com>
Date:   Fri Sep 14 13:10:04 2018 +0930

    powerpc/vdso: Correct call frame information
    
    [ Upstream commit 56d20861c027498b5a1112b4f9f05b56d906fdda ]
    
    Call Frame Information is used by gdb for back-traces and inserting
    breakpoints on function return for the "finish" command.  This failed
    when inside __kernel_clock_gettime.  More concerning than difficulty
    debugging is that CFI is also used by stack frame unwinding code to
    implement exceptions.  If you have an app that needs to handle
    asynchronous exceptions for some reason, and you are unlucky enough to
    get one inside the VDSO time functions, your app will crash.
    
    What's wrong:  There is control flow in __kernel_clock_gettime that
    reaches label 99 without saving lr in r12.  CFI info however is
    interpreted by the unwinder without reference to control flow: It's a
    simple matter of "Execute all the CFI opcodes up to the current
    address".  That means the unwinder thinks r12 contains the return
    address at label 99.  Disabuse it of that notion by resetting CFI for
    the return address at label 99.
    
    Note that the ".cfi_restore lr" could have gone anywhere from the
    "mtlr r12" a few instructions earlier to the instruction at label 99.
    I put the CFI as late as possible, because in general that's best
    practice (and if possible grouped with other CFI in order to reduce
    the number of CFI opcodes executed when unwinding).  Using r12 as the
    return address is perfectly fine after the "mtlr r12" since r12 on
    that code path still contains the return address.
    
    __get_datapage also has a CFI error.  That function temporarily saves
    lr in r0, and reflects that fact with ".cfi_register lr,r0".  A later
    use of r0 means the CFI at that point isn't correct, as r0 no longer
    contains the return address.  Fix that too.
    
    Signed-off-by: Alan Modra <amodra@gmail.com>
    Tested-by: Reza Arbab <arbab@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 74d06efb9c2f99b496eb118b1e941dc4c6404e93
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Mon Nov 4 12:04:41 2019 +0100

    ARM: 8932/1: Add clock_gettime64 entry point
    
    With the release of Linux 5.1 has been added a new syscall,
    clock_gettime64, that provided a 64 bit time value for a specified
    clock_ID to make the kernel Y2038 safe on 32 bit architectures.
    
    Update the arm specific vDSO library accordingly with what it has
    been done for the kernel syscall exposing the clock_gettime64 entry
    point.
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>

commit 176ed98c8a76ee08babf99b25b00992c2a5e7bbc
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sun Oct 27 17:26:55 2019 +0100

    y2038: vdso: powerpc: avoid timespec references
    
    As a preparation to stop using 'struct timespec' in the kernel,
    change the powerpc vdso implementation:
    
    - split up the vdso data definition to have equivalent members
       for seconds and nanoseconds instead of an xtime structure
    
    - use timespec64 as an intermediate for the xtime update
    
    - change the asm-offsets definition to be based the appropriate
      fixed-length types
    
    This is only a temporary fix for changing the types, in order
    to actually support a 64-bit safe vdso32 version of clock_gettime(),
    the entire powerpc vdso should be replaced with the generic
    lib/vdso/ implementation. If that happens first, this patch
    becomes obsolete.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

commit ddccf40fe82b7ac7c44b186ec4b6d1d1bbc2cbff
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Thu Nov 23 14:29:37 2017 +0100

    y2038: vdso: change timeval to __kernel_old_timeval
    
    The gettimeofday() function in vdso uses the traditional 'timeval'
    structure layout, which will be incompatible with future versions of
    glibc on 32-bit architectures that use a 64-bit time_t.
    
    This interface is problematic for y2038, when time_t overflows on 32-bit
    architectures, but the plan so far is that a libc with 64-bit time_t
    will not call into the gettimeofday() vdso helper at all, and only
    have a method for entering clock_gettime().  This means we don't have
    to fix it here, though we probably want to add a new clock_gettime()
    entry point using a 64-bit version of 'struct timespec' at some point.
    
    Changing the vdso code to use __kernel_old_timeval helps isolate
    this usage from the other ones that still need to be fixed properly,
    and it gets us closer to removing the 'timeval' definition from the
    kernel sources.
    
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

commit 5347291415a33bfa6efa5bb61350b078f200956b
Author: Masahiro Yamada <yamada.masahiro@socionext.com>
Date:   Sun Sep 22 20:34:36 2019 +0900

    sparc: vdso: fix build error of vdso32
    
    Since commit 54b8ae66ae1a ("kbuild: change *FLAGS_<basetarget>.o to
    take the path relative to $(obj)"), sparc allmodconfig fails to build
    as follows:
    
      CC      arch/sparc/vdso/vdso32/vclock_gettime.o
    unrecognized e_machine 18 arch/sparc/vdso/vdso32/vclock_gettime.o
    arch/sparc/vdso/vdso32/vclock_gettime.o: failed
    
    The cause of the breakage is that -pg flag not being dropped.
    
    The vdso32 files are located in the vdso32/ subdirectory, but I missed
    to update the Makefile.
    
    I removed the meaningless CFLAGS_REMOVE_vdso-note.o since it is only
    effective for C file.
    
    vdso-note.o is compiled from assembly file:
    
      arch/sparc/vdso/vdso-note.S
      arch/sparc/vdso/vdso32/vdso-note.S
    
    Fixes: 54b8ae66ae1a ("kbuild: change *FLAGS_<basetarget>.o to take the path relative to $(obj)")
    Reported-by: Anatoly Pugachev <matorola@gmail.com>
    Reported-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>
    Tested-by: Anatoly Pugachev <matorola@gmail.com>
    Acked-by: David S. Miller <davem@davemloft.net>

commit ab3664eabfa765e8fabcc106e23f7382ded518cb
Author: Huacai Chen <chenhc@lemote.com>
Date:   Thu Oct 24 11:28:29 2019 +0800

    timekeeping/vsyscall: Update VDSO data unconditionally
    
    [ Upstream commit 52338415cf4d4064ae6b8dd972dadbda841da4fa ]
    
    The update of the VDSO data is depending on __arch_use_vsyscall() returning
    True. This is a leftover from the attempt to map the features of various
    architectures 1:1 into generic code.
    
    The usage of __arch_use_vsyscall() in the actual vsyscall implementations
    got dropped and replaced by the requirement for the architecture code to
    return U64_MAX if the global clocksource is not usable in the VDSO.
    
    But the __arch_use_vsyscall() check in the update code stayed which causes
    the VDSO data to be stale or invalid when an architecture actually
    implements that function and returns False when the current clocksource is
    not usable in the VDSO.
    
    As a consequence the VDSO implementations of clock_getres(), time(),
    clock_gettime(CLOCK_.*_COARSE) operate on invalid data and return bogus
    information.
    
    Remove the __arch_use_vsyscall() check from the VDSO update function and
    update the VDSO data unconditionally.
    
    [ tglx: Massaged changelog and removed the now useless implementations in
            asm-generic/ARM64/MIPS ]
    
    Fixes: 44f57d788e7deecb50 ("timekeeping: Provide a generic update_vsyscall() implementation")
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/1571887709-11447-1-git-send-email-chenhc@lemote.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 52338415cf4d4064ae6b8dd972dadbda841da4fa
Author: Huacai Chen <chenhc@lemote.com>
Date:   Thu Oct 24 11:28:29 2019 +0800

    timekeeping/vsyscall: Update VDSO data unconditionally
    
    The update of the VDSO data is depending on __arch_use_vsyscall() returning
    True. This is a leftover from the attempt to map the features of various
    architectures 1:1 into generic code.
    
    The usage of __arch_use_vsyscall() in the actual vsyscall implementations
    got dropped and replaced by the requirement for the architecture code to
    return U64_MAX if the global clocksource is not usable in the VDSO.
    
    But the __arch_use_vsyscall() check in the update code stayed which causes
    the VDSO data to be stale or invalid when an architecture actually
    implements that function and returns False when the current clocksource is
    not usable in the VDSO.
    
    As a consequence the VDSO implementations of clock_getres(), time(),
    clock_gettime(CLOCK_.*_COARSE) operate on invalid data and return bogus
    information.
    
    Remove the __arch_use_vsyscall() check from the VDSO update function and
    update the VDSO data unconditionally.
    
    [ tglx: Massaged changelog and removed the now useless implementations in
            asm-generic/ARM64/MIPS ]
    
    Fixes: 44f57d788e7deecb50 ("timekeeping: Provide a generic update_vsyscall() implementation")
    Signed-off-by: Huacai Chen <chenhc@lemote.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: linux-mips@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/1571887709-11447-1-git-send-email-chenhc@lemote.com

commit ba149e6440840acb665147b4763274eacd6c1b6f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Oct 21 12:07:15 2019 +0200

    lib/vdso: Make clock_getres() POSIX compliant again
    
    commit 1638b8f096ca165965189b9626564c933c79fe63 upstream.
    
    A recent commit removed the NULL pointer check from the clock_getres()
    implementation causing a test case to fault.
    
    POSIX requires an explicit NULL pointer check for clock_getres() aside of
    the validity check of the clock_id argument for obscure reasons.
    
    Add it back for both 32bit and 64bit.
    
    Note, this is only a partial revert of the offending commit which does not
    bring back the broken fallback invocation in the the 32bit compat
    implementations of clock_getres() and clock_gettime().
    
    Fixes: a9446a906f52 ("lib/vdso/32: Remove inconsistent NULL pointer checks")
    Reported-by: Andreas Schwab <schwab@linux-m68k.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1910211202260.1904@nanos.tec.linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1638b8f096ca165965189b9626564c933c79fe63
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Oct 21 12:07:15 2019 +0200

    lib/vdso: Make clock_getres() POSIX compliant again
    
    A recent commit removed the NULL pointer check from the clock_getres()
    implementation causing a test case to fault.
    
    POSIX requires an explicit NULL pointer check for clock_getres() aside of
    the validity check of the clock_id argument for obscure reasons.
    
    Add it back for both 32bit and 64bit.
    
    Note, this is only a partial revert of the offending commit which does not
    bring back the broken fallback invocation in the the 32bit compat
    implementations of clock_getres() and clock_gettime().
    
    Fixes: a9446a906f52 ("lib/vdso/32: Remove inconsistent NULL pointer checks")
    Reported-by: Andreas Schwab <schwab@linux-m68k.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Christophe Leroy <christophe.leroy@c-s.fr>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1910211202260.1904@nanos.tec.linutronix.de

commit ba94094818a811758570990648160a6ba2ca05cb
Author: Stanislav Fomichev <sdf@google.com>
Date:   Tue Oct 15 11:31:24 2019 -0700

    bpf: Allow __sk_buff tstamp in BPF_PROG_TEST_RUN
    
    It's useful for implementing EDT related tests (set tstamp, run the
    test, see how the tstamp is changed or observe some other parameter).
    
    Note that bpf_ktime_get_ns() helper is using monotonic clock, so for
    the BPF programs that compare tstamp against it, tstamp should be
    derived from clock_gettime(CLOCK_MONOTONIC, ...).
    
    Signed-off-by: Stanislav Fomichev <sdf@google.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20191015183125.124413-1-sdf@google.com

commit 932bb934ed4d05d4bd5e8e3c3aaa5f92e0a89d90
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Aug 30 14:58:57 2019 +0100

    mips: compat: vdso: Use legacy syscalls as fallback
    
    The generic VDSO implementation uses the Y2038 safe clock_gettime64() and
    clock_getres_time64() syscalls as fallback for 32bit VDSO. This breaks
    seccomp setups because these syscalls might be not (yet) allowed.
    
    Implement the 32bit variants which use the legacy syscalls and select the
    variant in the core library.
    
    The 64bit time variants are not removed because they are required for the
    time64 based vdso accessors.
    
    Cc: Paul Burton <paul.burton@mips.com>
    Fixes: 00b26474c2f1 ("lib/vdso: Provide generic VDSO implementation")
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kselftest@vger.kernel.org
    Cc: catalin.marinas@arm.com
    Cc: will@kernel.org
    Cc: tglx@linutronix.de
    Cc: salyzyn@android.com
    Cc: 0x7f454c46@gmail.com
    Cc: luto@kernel.org

commit 75959d44f9dc8e44410667009724e4e238515502
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 16 21:47:27 2019 +0200

    kbuild: Fail if gold linker is detected
    
    The gold linker has known issues of failing the build both in random and in
    predictible ways:
    
     - The x86/X32 VDSO build fails with:
    
       arch/x86/entry/vdso/vclock_gettime-x32.o:vclock_gettime.c:function do_hres:
       error: relocation overflow: reference to 'hvclock_page'
    
       That's a known issue for years and the usual workaround is to disable
       CONFIG_X86_32
    
     - A recent build failure is caused by turning a relocation into an
       absolute one for unknown reasons. See link below.
    
     - There are a couple of gold workarounds applied already, but reports
       about broken builds with ld.gold keep coming in on a regular base and in
       most cases the root cause is unclear.
    
    In context of the most recent fail H.J. stated:
    
      "Since building a workable kernel for different kernel configurations
       isn't a requirement for gold, I don't recommend gold for kernel."
    
    So instead of dealing with attempts to duct tape gold support without
    understanding the root cause and without support from the gold folks, fail
    the build when gold is detected.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/CAMe9rOqMqkQ0LNpm25yE_Yt0FKp05WmHOrwc0aRDb53miFKM+w@mail.gmail.com
    Reviewed-by: Nathan Chancellor <natechancellor@gmail.com>
    Tested-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Masahiro Yamada <yamada.masahiro@socionext.com>

commit bb693bc07a915f22f93f4a67c09764bfbe356cd0
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 14 00:14:38 2019 +1100

    powerpc/vdso64: Fix CLOCK_MONOTONIC inconsistencies across Y2038
    
    commit b5b4453e7912f056da1ca7572574cada32ecb60c upstream.
    
    Jakub Drnec reported:
      Setting the realtime clock can sometimes make the monotonic clock go
      back by over a hundred years. Decreasing the realtime clock across
      the y2k38 threshold is one reliable way to reproduce. Allegedly this
      can also happen just by running ntpd, I have not managed to
      reproduce that other than booting with rtc at >2038 and then running
      ntp. When this happens, anything with timers (e.g. openjdk) breaks
      rather badly.
    
    And included a test case (slightly edited for brevity):
      #define _POSIX_C_SOURCE 199309L
      #include <stdio.h>
      #include <time.h>
      #include <stdlib.h>
      #include <unistd.h>
    
      long get_time(void) {
        struct timespec tp;
        clock_gettime(CLOCK_MONOTONIC, &tp);
        return tp.tv_sec + tp.tv_nsec / 1000000000;
      }
    
      int main(void) {
        long last = get_time();
        while(1) {
          long now = get_time();
          if (now < last) {
            printf("clock went backwards by %ld seconds!\n", last - now);
          }
          last = now;
          sleep(1);
        }
        return 0;
      }
    
    Which when run concurrently with:
     # date -s 2040-1-1
     # date -s 2037-1-1
    
    Will detect the clock going backward.
    
    The root cause is that wtom_clock_sec in struct vdso_data is only a
    32-bit signed value, even though we set its value to be equal to
    tk->wall_to_monotonic.tv_sec which is 64-bits.
    
    Because the monotonic clock starts at zero when the system boots the
    wall_to_montonic.tv_sec offset is negative for current and future
    dates. Currently on a freshly booted system the offset will be in the
    vicinity of negative 1.5 billion seconds.
    
    However if the wall clock is set past the Y2038 boundary, the offset
    from wall to monotonic becomes less than negative 2^31, and no longer
    fits in 32-bits. When that value is assigned to wtom_clock_sec it is
    truncated and becomes positive, causing the VDSO assembly code to
    calculate CLOCK_MONOTONIC incorrectly.
    
    That causes CLOCK_MONOTONIC to jump ahead by ~4 billion seconds which
    it is not meant to do. Worse, if the time is then set back before the
    Y2038 boundary CLOCK_MONOTONIC will jump backward.
    
    We can fix it simply by storing the full 64-bit offset in the
    vdso_data, and using that in the VDSO assembly code. We also shuffle
    some of the fields in vdso_data to avoid creating a hole.
    
    The original commit that added the CLOCK_MONOTONIC support to the VDSO
    did actually use a 64-bit value for wtom_clock_sec, see commit
    a7f290dad32e ("[PATCH] powerpc: Merge vdso's and add vdso support to
    32 bits kernel") (Nov 2005). However just 3 days later it was
    converted to 32-bits in commit 0c37ec2aa88b ("[PATCH] powerpc: vdso
    fixes (take #2)"), and the bug has existed since then AFAICS.
    
    Fixes: 0c37ec2aa88b ("[PATCH] powerpc: vdso fixes (take #2)")
    Link: http://lkml.kernel.org/r/HaC.ZfES.62bwlnvAvMP.1STMMj@seznam.cz
    Reported-by: Jakub Drnec <jaydee@email.cz>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    [bwh: Backported to 3.16: CLOCK_MONOTONIC_COARSE is not handled by
     this vDSO]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 3732a473be54b1eee65100b79d2d80c382f7e742
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jun 21 08:43:04 2019 -0700

    x86/vdso: Prevent segfaults due to hoisted vclock reads
    
    commit ff17bbe0bb405ad8b36e55815d381841f9fdeebc upstream.
    
    GCC 5.5.0 sometimes cleverly hoists reads of the pvclock and/or hvclock
    pages before the vclock mode checks.  This creates a path through
    vclock_gettime() in which no vclock is enabled at all (due to disabled
    TSC on old CPUs, for example) but the pvclock or hvclock page
    nevertheless read.  This will segfault on bare metal.
    
    This fixes commit 459e3a21535a ("gcc-9: properly declare the
    {pv,hv}clock_page storage") in the sense that, before that commit, GCC
    didn't seem to generate the offending code.  There was nothing wrong
    with that commit per se, and -stable maintainers should backport this to
    all supported kernels regardless of whether the offending commit was
    present, since the same crash could just as easily be triggered by the
    phase of the moon.
    
    On GCC 9.1.1, this doesn't seem to affect the generated code at all, so
    I'm not too concerned about performance regressions from this fix.
    
    Cc: stable@vger.kernel.org
    Cc: x86@kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Reported-by: Duncan Roe <duncan_roe@optusnet.com.au>
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2c04e80a6c4f1795ae296e2d7ab8f88d1abd9316
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jun 21 08:43:04 2019 -0700

    x86/vdso: Prevent segfaults due to hoisted vclock reads
    
    commit ff17bbe0bb405ad8b36e55815d381841f9fdeebc upstream.
    
    GCC 5.5.0 sometimes cleverly hoists reads of the pvclock and/or hvclock
    pages before the vclock mode checks.  This creates a path through
    vclock_gettime() in which no vclock is enabled at all (due to disabled
    TSC on old CPUs, for example) but the pvclock or hvclock page
    nevertheless read.  This will segfault on bare metal.
    
    This fixes commit 459e3a21535a ("gcc-9: properly declare the
    {pv,hv}clock_page storage") in the sense that, before that commit, GCC
    didn't seem to generate the offending code.  There was nothing wrong
    with that commit per se, and -stable maintainers should backport this to
    all supported kernels regardless of whether the offending commit was
    present, since the same crash could just as easily be triggered by the
    phase of the moon.
    
    On GCC 9.1.1, this doesn't seem to affect the generated code at all, so
    I'm not too concerned about performance regressions from this fix.
    
    Cc: stable@vger.kernel.org
    Cc: x86@kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Reported-by: Duncan Roe <duncan_roe@optusnet.com.au>
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0432a0a066b05361b6d4d26522233c3c76c9e5da
Merge: af42e7450f4b 33a58980ff3c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Aug 3 10:51:29 2019 -0700

    Merge branch 'timers-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull vdso timer fixes from Thomas Gleixner:
     "A series of commits to deal with the regression caused by the generic
      VDSO implementation.
    
      The usage of clock_gettime64() for 32bit compat fallback syscalls
      caused seccomp filters to kill innocent processes because they only
      allow clock_gettime().
    
      Handle the compat syscalls with clock_gettime() as before, which is
      not a functional problem for the VDSO as the legacy compat application
      interface is not y2038 safe anyway. It's just extra fallback code
      which needs to be implemented on every architecture.
    
      It's opt in for now so that it does not break the compile of already
      converted architectures in linux-next. Once these are fixed, the
      #ifdeffery goes away.
    
      So much for trying to be smart and reuse code..."
    
    * 'timers-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      arm64: compat: vdso: Use legacy syscalls as fallback
      x86/vdso/32: Use 32bit syscall fallback
      lib/vdso/32: Provide legacy syscall fallbacks
      lib/vdso: Move fallback invocation to the callers
      lib/vdso/32: Remove inconsistent NULL pointer checks

commit 33a58980ff3cc5dbf0bb1b325746ac69223eda0b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 28 15:12:56 2019 +0200

    arm64: compat: vdso: Use legacy syscalls as fallback
    
    The generic VDSO implementation uses the Y2038 safe clock_gettime64() and
    clock_getres_time64() syscalls as fallback for 32bit VDSO. This breaks
    seccomp setups because these syscalls might be not (yet) allowed.
    
    Implement the 32bit variants which use the legacy syscalls and select the
    variant in the core library.
    
    The 64bit time variants are not removed because they are required for the
    time64 based vdso accessors.
    
    Fixes: 00b26474c2f1 ("lib/vdso: Provide generic VDSO implementation")
    Reported-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Reported-by: Paul Bolle <pebolle@tiscali.nl>
    Suggested-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lkml.kernel.org/r/20190728131648.971361611@linutronix.de

commit d2f5d3fa26196183adb44a413c44caa9872275b4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 28 15:12:55 2019 +0200

    x86/vdso/32: Use 32bit syscall fallback
    
    The generic VDSO implementation uses the Y2038 safe clock_gettime64() and
    clock_getres_time64() syscalls as fallback for 32bit VDSO. This breaks
    seccomp setups because these syscalls might be not (yet) allowed.
    
    Implement the 32bit variants which use the legacy syscalls and select the
    variant in the core library.
    
    The 64bit time variants are not removed because they are required for the
    time64 based vdso accessors.
    
    Fixes: 7ac870747988 ("x86/vdso: Switch to generic vDSO implementation")
    Reported-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Reported-by: Paul Bolle <pebolle@tiscali.nl>
    Suggested-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lkml.kernel.org/r/20190728131648.879156507@linutronix.de

commit c60a32ea4f459f99b98d383cad3b1ac7cfb3f4be
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 30 11:38:50 2019 +0200

    lib/vdso/32: Provide legacy syscall fallbacks
    
    To address the regression which causes seccomp to deny applications the
    access to clock_gettime64() and clock_getres64() syscalls because they
    are not enabled in the existing filters.
    
    That trips over the fact that 32bit VDSOs use the new clock_gettime64() and
    clock_getres64() syscalls in the fallback path.
    
    Add a conditional to invoke the 32bit legacy fallback syscalls instead of
    the new 64bit variants. The conditional can go away once all architectures
    are converted.
    
    Fixes: 00b26474c2f1 ("lib/vdso: Provide generic VDSO implementation")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Reviewed-by: Sean Christopherson <sean.j.christopherson@intel.com>
    Link: https://lkml.kernel.org/r/alpine.DEB.2.21.1907301134470.1738@nanos.tec.linutronix.de

commit 502a590a170b3b3d0ad998ee0b639ac0b3db1dfa
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 28 15:12:53 2019 +0200

    lib/vdso: Move fallback invocation to the callers
    
    To allow syscall fallbacks using the legacy 32bit syscall for 32bit VDSO
    builds, move the fallback invocation out into the callers.
    
    Split the common code out of __cvdso_clock_gettime/getres() and invoke the
    syscall fallback in the 64bit and 32bit variants.
    
    Preparatory work for using legacy syscalls in 32bit VDSO. No functional
    change.
    
    Fixes: 00b26474c2f1 ("lib/vdso: Provide generic VDSO implementation")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lkml.kernel.org/r/20190728131648.695579736@linutronix.de

commit a9446a906f52292c52ecbd5be78eaa4d8395756c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Jul 28 15:12:52 2019 +0200

    lib/vdso/32: Remove inconsistent NULL pointer checks
    
    The 32bit variants of vdso_clock_gettime()/getres() have a NULL pointer
    check for the timespec pointer. That's inconsistent vs. 64bit.
    
    But the vdso implementation will never be consistent versus the syscall
    because the only case which it can handle is NULL. Any other invalid
    pointer will cause a segfault. So special casing NULL is not really useful.
    
    Remove it along with the superflouos syscall fallback invocation as that
    will return -EFAULT anyway. That also gets rid of the dubious typecast
    which only works because the pointer is NULL.
    
    Fixes: 00b26474c2f1 ("lib/vdso: Provide generic VDSO implementation")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Reviewed-by: Andy Lutomirski <luto@kernel.org>
    Link: https://lkml.kernel.org/r/20190728131648.587523358@linutronix.de

commit e36f25627362ab039a1bd728b631c0ab6f8102a3
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Mon May 27 08:14:55 2019 -0400

    media: saa7164: fix remove_proc_entry warning
    
    [ Upstream commit 50710eeefbc1ed25375942aad0c4d1eb4af0f330 ]
    
    if saa7164_proc_create() fails, saa7164_fini() will trigger a warning,
    
    name 'saa7164'
    WARNING: CPU: 1 PID: 6311 at fs/proc/generic.c:672 remove_proc_entry+0x1e8/0x3a0
      ? remove_proc_entry+0x1e8/0x3a0
      ? try_stop_module+0x7b/0x240
      ? proc_readdir+0x70/0x70
      ? rcu_read_lock_sched_held+0xd7/0x100
      saa7164_fini+0x13/0x1f [saa7164]
      __x64_sys_delete_module+0x30c/0x480
      ? __ia32_sys_delete_module+0x480/0x480
      ? __x64_sys_clock_gettime+0x11e/0x1c0
      ? __x64_sys_timer_create+0x1a0/0x1a0
      ? trace_hardirqs_off_caller+0x40/0x180
      ? do_syscall_64+0x18/0x450
      do_syscall_64+0x9f/0x450
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Fix it by checking the return of proc_create_single() before
    calling remove_proc_entry().
    
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    [hverkuil-cisco@xs4all.nl: use 0444 instead of S_IRUGO]
    [hverkuil-cisco@xs4all.nl: use pr_info instead of KERN_INFO]
    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 139f99f55fd2de1f3c2c7747cf26716cddec0b5b
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Mon May 27 08:14:55 2019 -0400

    media: saa7164: fix remove_proc_entry warning
    
    [ Upstream commit 50710eeefbc1ed25375942aad0c4d1eb4af0f330 ]
    
    if saa7164_proc_create() fails, saa7164_fini() will trigger a warning,
    
    name 'saa7164'
    WARNING: CPU: 1 PID: 6311 at fs/proc/generic.c:672 remove_proc_entry+0x1e8/0x3a0
      ? remove_proc_entry+0x1e8/0x3a0
      ? try_stop_module+0x7b/0x240
      ? proc_readdir+0x70/0x70
      ? rcu_read_lock_sched_held+0xd7/0x100
      saa7164_fini+0x13/0x1f [saa7164]
      __x64_sys_delete_module+0x30c/0x480
      ? __ia32_sys_delete_module+0x480/0x480
      ? __x64_sys_clock_gettime+0x11e/0x1c0
      ? __x64_sys_timer_create+0x1a0/0x1a0
      ? trace_hardirqs_off_caller+0x40/0x180
      ? do_syscall_64+0x18/0x450
      do_syscall_64+0x9f/0x450
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Fix it by checking the return of proc_create_single() before
    calling remove_proc_entry().
    
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    [hverkuil-cisco@xs4all.nl: use 0444 instead of S_IRUGO]
    [hverkuil-cisco@xs4all.nl: use pr_info instead of KERN_INFO]
    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fea9869ff4c2cc39d2e8e86868d6d47fdf543b36
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Mon May 27 08:14:55 2019 -0400

    media: saa7164: fix remove_proc_entry warning
    
    [ Upstream commit 50710eeefbc1ed25375942aad0c4d1eb4af0f330 ]
    
    if saa7164_proc_create() fails, saa7164_fini() will trigger a warning,
    
    name 'saa7164'
    WARNING: CPU: 1 PID: 6311 at fs/proc/generic.c:672 remove_proc_entry+0x1e8/0x3a0
      ? remove_proc_entry+0x1e8/0x3a0
      ? try_stop_module+0x7b/0x240
      ? proc_readdir+0x70/0x70
      ? rcu_read_lock_sched_held+0xd7/0x100
      saa7164_fini+0x13/0x1f [saa7164]
      __x64_sys_delete_module+0x30c/0x480
      ? __ia32_sys_delete_module+0x480/0x480
      ? __x64_sys_clock_gettime+0x11e/0x1c0
      ? __x64_sys_timer_create+0x1a0/0x1a0
      ? trace_hardirqs_off_caller+0x40/0x180
      ? do_syscall_64+0x18/0x450
      do_syscall_64+0x9f/0x450
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Fix it by checking the return of proc_create_single() before
    calling remove_proc_entry().
    
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    [hverkuil-cisco@xs4all.nl: use 0444 instead of S_IRUGO]
    [hverkuil-cisco@xs4all.nl: use pr_info instead of KERN_INFO]
    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1f66c45db3302386ca3bb3b5ed05248434237fc9
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Jun 21 10:52:48 2019 +0100

    mips: Add clock_gettime64 entry point
    
    With the release of Linux 5.1 has been added a new syscall,
    clock_gettime64, that provided a 64 bit time value for a specified
    clock_ID to make the kernel Y2038 safe on 32 bit architectures.
    
    Update the mips32 specific vDSO library accordingly with what it has
    been done for the kernel syscall exposing the clock_gettime64 entry
    point.
    
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Paul Burton <paul.burton@mips.com>

commit cf37b1a0902944f17ac95eb62177219b65c413cb
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jun 21 08:43:04 2019 -0700

    x86/vdso: Prevent segfaults due to hoisted vclock reads
    
    commit ff17bbe0bb405ad8b36e55815d381841f9fdeebc upstream.
    
    GCC 5.5.0 sometimes cleverly hoists reads of the pvclock and/or hvclock
    pages before the vclock mode checks.  This creates a path through
    vclock_gettime() in which no vclock is enabled at all (due to disabled
    TSC on old CPUs, for example) but the pvclock or hvclock page
    nevertheless read.  This will segfault on bare metal.
    
    This fixes commit 459e3a21535a ("gcc-9: properly declare the
    {pv,hv}clock_page storage") in the sense that, before that commit, GCC
    didn't seem to generate the offending code.  There was nothing wrong
    with that commit per se, and -stable maintainers should backport this to
    all supported kernels regardless of whether the offending commit was
    present, since the same crash could just as easily be triggered by the
    phase of the moon.
    
    On GCC 9.1.1, this doesn't seem to affect the generated code at all, so
    I'm not too concerned about performance regressions from this fix.
    
    Cc: stable@vger.kernel.org
    Cc: x86@kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Reported-by: Duncan Roe <duncan_roe@optusnet.com.au>
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 22ca962288c0a1c9729e8e440b9bb9ad05df6db6
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Jun 21 10:52:51 2019 +0100

    x86/vdso: Add clock_gettime64() entry point
    
    Linux 5.1 gained the new clock_gettime64() syscall to address the Y2038
    problem on 32bit systems. The x86 VDSO is missing support for this variant
    of clock_gettime().
    
    Update the x86 specific vDSO library accordingly so it exposes the new time
    getter.
    
    [ tglx: Massaged changelog ]
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kselftest@vger.kernel.org
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Mark Salyzyn <salyzyn@android.com>
    Cc: Peter Collingbourne <pcc@google.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Huw Davies <huw@codeweavers.com>
    Cc: Shijith Thotton <sthotton@marvell.com>
    Cc: Andre Przywara <andre.przywara@arm.com>
    Link: https://lkml.kernel.org/r/20190621095252.32307-25-vincenzo.frascino@arm.com

commit 53c489e1dfeb6092b9fb14eb73c2cbcb07224798
Author: Vincenzo Frascino <vincenzo.frascino@arm.com>
Date:   Fri Jun 21 10:52:33 2019 +0100

    arm64: compat: Add missing syscall numbers
    
    vDSO requires gettimeofday() and clock_gettime() syscalls to implement the
    fallback mechanism.
    
    Add the missing syscall numbers to unistd.h for arm64.
    
    Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Shijith Thotton <sthotton@marvell.com>
    Tested-by: Andre Przywara <andre.przywara@arm.com>
    Cc: linux-arch@vger.kernel.org
    Cc: linux-arm-kernel@lists.infradead.org
    Cc: linux-mips@vger.kernel.org
    Cc: linux-kselftest@vger.kernel.org
    Cc: Catalin Marinas <catalin.marinas@arm.com>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Ralf Baechle <ralf@linux-mips.org>
    Cc: Paul Burton <paul.burton@mips.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Mark Salyzyn <salyzyn@android.com>
    Cc: Peter Collingbourne <pcc@google.com>
    Cc: Shuah Khan <shuah@kernel.org>
    Cc: Dmitry Safonov <0x7f454c46@gmail.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Huw Davies <huw@codeweavers.com>
    Link: https://lkml.kernel.org/r/20190621095252.32307-7-vincenzo.frascino@arm.com

commit ff17bbe0bb405ad8b36e55815d381841f9fdeebc
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Jun 21 08:43:04 2019 -0700

    x86/vdso: Prevent segfaults due to hoisted vclock reads
    
    GCC 5.5.0 sometimes cleverly hoists reads of the pvclock and/or hvclock
    pages before the vclock mode checks.  This creates a path through
    vclock_gettime() in which no vclock is enabled at all (due to disabled
    TSC on old CPUs, for example) but the pvclock or hvclock page
    nevertheless read.  This will segfault on bare metal.
    
    This fixes commit 459e3a21535a ("gcc-9: properly declare the
    {pv,hv}clock_page storage") in the sense that, before that commit, GCC
    didn't seem to generate the offending code.  There was nothing wrong
    with that commit per se, and -stable maintainers should backport this to
    all supported kernels regardless of whether the offending commit was
    present, since the same crash could just as easily be triggered by the
    phase of the moon.
    
    On GCC 9.1.1, this doesn't seem to affect the generated code at all, so
    I'm not too concerned about performance regressions from this fix.
    
    Cc: stable@vger.kernel.org
    Cc: x86@kernel.org
    Cc: Borislav Petkov <bp@alien8.de>
    Reported-by: Duncan Roe <duncan_roe@optusnet.com.au>
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 50710eeefbc1ed25375942aad0c4d1eb4af0f330
Author: Kefeng Wang <wangkefeng.wang@huawei.com>
Date:   Mon May 27 08:14:55 2019 -0400

    media: saa7164: fix remove_proc_entry warning
    
    if saa7164_proc_create() fails, saa7164_fini() will trigger a warning,
    
    name 'saa7164'
    WARNING: CPU: 1 PID: 6311 at fs/proc/generic.c:672 remove_proc_entry+0x1e8/0x3a0
      ? remove_proc_entry+0x1e8/0x3a0
      ? try_stop_module+0x7b/0x240
      ? proc_readdir+0x70/0x70
      ? rcu_read_lock_sched_held+0xd7/0x100
      saa7164_fini+0x13/0x1f [saa7164]
      __x64_sys_delete_module+0x30c/0x480
      ? __ia32_sys_delete_module+0x480/0x480
      ? __x64_sys_clock_gettime+0x11e/0x1c0
      ? __x64_sys_timer_create+0x1a0/0x1a0
      ? trace_hardirqs_off_caller+0x40/0x180
      ? do_syscall_64+0x18/0x450
      do_syscall_64+0x9f/0x450
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Fix it by checking the return of proc_create_single() before
    calling remove_proc_entry().
    
    Signed-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    [hverkuil-cisco@xs4all.nl: use 0444 instead of S_IRUGO]
    [hverkuil-cisco@xs4all.nl: use pr_info instead of KERN_INFO]
    Signed-off-by: Mauro Carvalho Chehab <mchehab+samsung@kernel.org>

commit 06dcb6695d3c76cc4468a71a140162107b4a2e3c
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Apr 29 17:26:22 2019 +0100

    arm64: arch_timer: Ensure counter register reads occur with seqlock held
    
    commit 75a19a0202db21638a1c2b424afb867e1f9a2376 upstream.
    
    When executing clock_gettime(), either in the vDSO or via a system call,
    we need to ensure that the read of the counter register occurs within
    the seqlock reader critical section. This ensures that updates to the
    clocksource parameters (e.g. the multiplier) are consistent with the
    counter value and therefore avoids the situation where time appears to
    go backwards across multiple reads.
    
    Extend the vDSO logic so that the seqlock critical section covers the
    read of the counter register as well as accesses to the data page. Since
    reads of the counter system registers are not ordered by memory barrier
    instructions, introduce dependency ordering from the counter read to a
    subsequent memory access so that the seqlock memory barriers apply to
    the counter access in both the vDSO and the system call paths.
    
    Cc: <stable@vger.kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lore.kernel.org/linux-arm-kernel/alpine.DEB.2.21.1902081950260.1662@nanos.tec.linutronix.de/
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e57320e0177a27634263aa020b7ede884b7f72b8
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Apr 29 17:26:22 2019 +0100

    arm64: arch_timer: Ensure counter register reads occur with seqlock held
    
    commit 75a19a0202db21638a1c2b424afb867e1f9a2376 upstream.
    
    When executing clock_gettime(), either in the vDSO or via a system call,
    we need to ensure that the read of the counter register occurs within
    the seqlock reader critical section. This ensures that updates to the
    clocksource parameters (e.g. the multiplier) are consistent with the
    counter value and therefore avoids the situation where time appears to
    go backwards across multiple reads.
    
    Extend the vDSO logic so that the seqlock critical section covers the
    read of the counter register as well as accesses to the data page. Since
    reads of the counter system registers are not ordered by memory barrier
    instructions, introduce dependency ordering from the counter read to a
    subsequent memory access so that the seqlock memory barriers apply to
    the counter access in both the vDSO and the system call paths.
    
    Cc: <stable@vger.kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lore.kernel.org/linux-arm-kernel/alpine.DEB.2.21.1902081950260.1662@nanos.tec.linutronix.de/
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6d696ceb15a31bedf89b3c572bf62b64fe5d69c4
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Apr 29 17:26:22 2019 +0100

    arm64: arch_timer: Ensure counter register reads occur with seqlock held
    
    commit 75a19a0202db21638a1c2b424afb867e1f9a2376 upstream.
    
    When executing clock_gettime(), either in the vDSO or via a system call,
    we need to ensure that the read of the counter register occurs within
    the seqlock reader critical section. This ensures that updates to the
    clocksource parameters (e.g. the multiplier) are consistent with the
    counter value and therefore avoids the situation where time appears to
    go backwards across multiple reads.
    
    Extend the vDSO logic so that the seqlock critical section covers the
    read of the counter register as well as accesses to the data page. Since
    reads of the counter system registers are not ordered by memory barrier
    instructions, introduce dependency ordering from the counter read to a
    subsequent memory access so that the seqlock memory barriers apply to
    the counter access in both the vDSO and the system call paths.
    
    Cc: <stable@vger.kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lore.kernel.org/linux-arm-kernel/alpine.DEB.2.21.1902081950260.1662@nanos.tec.linutronix.de/
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e8e1c54c079a8daa6e0f94e5a71a0a3a1d1ac597
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Dec 6 11:12:31 2018 -0800

    x86/vdso: Drop implicit common-page-size linker flag
    
    commit ac3e233d29f7f77f28243af0132057d378d3ea58 upstream.
    
    GNU linker's -z common-page-size's default value is based on the target
    architecture. arch/x86/entry/vdso/Makefile sets it to the architecture
    default, which is implicit and redundant. Drop it.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Reported-by: Dmitry Golovin <dima@golovin.in>
    Reported-by: Bill Wendling <morbo@google.com>
    Suggested-by: Dmitry Golovin <dima@golovin.in>
    Suggested-by: Rui Ueyama <ruiu@google.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Fangrui Song <maskray@google.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20181206191231.192355-1-ndesaulniers@google.com
    Link: https://bugs.llvm.org/show_bug.cgi?id=38774
    Link: https://github.com/ClangBuiltLinux/linux/issues/31
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e56aeab565e2d5e82cef892ed34ef9cbef4fd15e
Author: Alistair Strachan <astrachan@google.com>
Date:   Fri Aug 3 10:39:31 2018 -0700

    x86: vdso: Use $LD instead of $CC to link
    
    commit 379d98ddf41344273d9718556f761420f4dc80b3 upstream.
    
    The vdso{32,64}.so can fail to link with CC=clang when clang tries to find
    a suitable GCC toolchain to link these libraries with.
    
    /usr/bin/ld: arch/x86/entry/vdso/vclock_gettime.o:
      access beyond end of merged section (782)
    
    This happens because the host environment leaked into the cross compiler
    environment due to the way clang searches for suitable GCC toolchains.
    
    Clang is a retargetable compiler, and each invocation of it must provide
    --target=<something> --gcc-toolchain=<something> to allow it to find the
    correct binutils for cross compilation. These flags had been added to
    KBUILD_CFLAGS, but the vdso code uses CC and not KBUILD_CFLAGS (for various
    reasons) which breaks clang's ability to find the correct linker when cross
    compiling.
    
    Most of the time this goes unnoticed because the host linker is new enough
    to work anyway, or is incompatible and skipped, but this cannot be reliably
    assumed.
    
    This change alters the vdso makefile to just use LD directly, which
    bypasses clang and thus the searching problem. The makefile will just use
    ${CROSS_COMPILE}ld instead, which is always what we want. This matches the
    method used to link vmlinux.
    
    This drops references to DISABLE_LTO; this option doesn't seem to be set
    anywhere, and not knowing what its possible values are, it's not clear how
    to convert it from CC to LD flag.
    
    Signed-off-by: Alistair Strachan <astrachan@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: kernel-team@android.com
    Cc: joel@joelfernandes.org
    Cc: Andi Kleen <andi.kleen@intel.com>
    Link: https://lkml.kernel.org/r/20180803173931.117515-1-astrachan@google.com
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 75a19a0202db21638a1c2b424afb867e1f9a2376
Author: Will Deacon <will.deacon@arm.com>
Date:   Mon Apr 29 17:26:22 2019 +0100

    arm64: arch_timer: Ensure counter register reads occur with seqlock held
    
    When executing clock_gettime(), either in the vDSO or via a system call,
    we need to ensure that the read of the counter register occurs within
    the seqlock reader critical section. This ensures that updates to the
    clocksource parameters (e.g. the multiplier) are consistent with the
    counter value and therefore avoids the situation where time appears to
    go backwards across multiple reads.
    
    Extend the vDSO logic so that the seqlock critical section covers the
    read of the counter register as well as accesses to the data page. Since
    reads of the counter system registers are not ordered by memory barrier
    instructions, introduce dependency ordering from the counter read to a
    subsequent memory access so that the seqlock memory barriers apply to
    the counter access in both the vDSO and the system call paths.
    
    Cc: <stable@vger.kernel.org>
    Cc: Marc Zyngier <marc.zyngier@arm.com>
    Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
    Link: https://lore.kernel.org/linux-arm-kernel/alpine.DEB.2.21.1902081950260.1662@nanos.tec.linutronix.de/
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

commit 7c45b45fd6e928c9ce275c32f6fa98d317e6f5ee
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Dec 6 11:12:31 2018 -0800

    x86/vdso: Drop implicit common-page-size linker flag
    
    commit ac3e233d29f7f77f28243af0132057d378d3ea58 upstream.
    
    GNU linker's -z common-page-size's default value is based on the target
    architecture. arch/x86/entry/vdso/Makefile sets it to the architecture
    default, which is implicit and redundant. Drop it.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Reported-by: Dmitry Golovin <dima@golovin.in>
    Reported-by: Bill Wendling <morbo@google.com>
    Suggested-by: Dmitry Golovin <dima@golovin.in>
    Suggested-by: Rui Ueyama <ruiu@google.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Fangrui Song <maskray@google.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20181206191231.192355-1-ndesaulniers@google.com
    Link: https://bugs.llvm.org/show_bug.cgi?id=38774
    Link: https://github.com/ClangBuiltLinux/linux/issues/31
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 79739ad2d0ac5787a15a1acf7caaf34cd95bbf3c
Author: Alistair Strachan <astrachan@google.com>
Date:   Fri Aug 3 10:39:31 2018 -0700

    x86: vdso: Use $LD instead of $CC to link
    
    commit 379d98ddf41344273d9718556f761420f4dc80b3 upstream.
    
    The vdso{32,64}.so can fail to link with CC=clang when clang tries to find
    a suitable GCC toolchain to link these libraries with.
    
    /usr/bin/ld: arch/x86/entry/vdso/vclock_gettime.o:
      access beyond end of merged section (782)
    
    This happens because the host environment leaked into the cross compiler
    environment due to the way clang searches for suitable GCC toolchains.
    
    Clang is a retargetable compiler, and each invocation of it must provide
    --target=<something> --gcc-toolchain=<something> to allow it to find the
    correct binutils for cross compilation. These flags had been added to
    KBUILD_CFLAGS, but the vdso code uses CC and not KBUILD_CFLAGS (for various
    reasons) which breaks clang's ability to find the correct linker when cross
    compiling.
    
    Most of the time this goes unnoticed because the host linker is new enough
    to work anyway, or is incompatible and skipped, but this cannot be reliably
    assumed.
    
    This change alters the vdso makefile to just use LD directly, which
    bypasses clang and thus the searching problem. The makefile will just use
    ${CROSS_COMPILE}ld instead, which is always what we want. This matches the
    method used to link vmlinux.
    
    This drops references to DISABLE_LTO; this option doesn't seem to be set
    anywhere, and not knowing what its possible values are, it's not clear how
    to convert it from CC to LD flag.
    
    Signed-off-by: Alistair Strachan <astrachan@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: kernel-team@android.com
    Cc: joel@joelfernandes.org
    Cc: Andi Kleen <andi.kleen@intel.com>
    Link: https://lkml.kernel.org/r/20180803173931.117515-1-astrachan@google.com
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c7415f2a3ad65d78c13b203364c843347a443254
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Dec 6 11:12:31 2018 -0800

    x86/vdso: Drop implicit common-page-size linker flag
    
    commit ac3e233d29f7f77f28243af0132057d378d3ea58 upstream.
    
    GNU linker's -z common-page-size's default value is based on the target
    architecture. arch/x86/entry/vdso/Makefile sets it to the architecture
    default, which is implicit and redundant. Drop it.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Reported-by: Dmitry Golovin <dima@golovin.in>
    Reported-by: Bill Wendling <morbo@google.com>
    Suggested-by: Dmitry Golovin <dima@golovin.in>
    Suggested-by: Rui Ueyama <ruiu@google.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Fangrui Song <maskray@google.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20181206191231.192355-1-ndesaulniers@google.com
    Link: https://bugs.llvm.org/show_bug.cgi?id=38774
    Link: https://github.com/ClangBuiltLinux/linux/issues/31
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 625c82068a277db442e9fa08727d1670373203f9
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Dec 6 11:12:31 2018 -0800

    x86/vdso: Drop implicit common-page-size linker flag
    
    commit ac3e233d29f7f77f28243af0132057d378d3ea58 upstream.
    
    GNU linker's -z common-page-size's default value is based on the target
    architecture. arch/x86/entry/vdso/Makefile sets it to the architecture
    default, which is implicit and redundant. Drop it.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Reported-by: Dmitry Golovin <dima@golovin.in>
    Reported-by: Bill Wendling <morbo@google.com>
    Suggested-by: Dmitry Golovin <dima@golovin.in>
    Suggested-by: Rui Ueyama <ruiu@google.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Fangrui Song <maskray@google.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20181206191231.192355-1-ndesaulniers@google.com
    Link: https://bugs.llvm.org/show_bug.cgi?id=38774
    Link: https://github.com/ClangBuiltLinux/linux/issues/31
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3d4b1ffc7edb1f963b0223469b0e8b699a197c1f
Author: Alistair Strachan <astrachan@google.com>
Date:   Fri Aug 3 10:39:31 2018 -0700

    x86: vdso: Use $LD instead of $CC to link
    
    commit 379d98ddf41344273d9718556f761420f4dc80b3 upstream.
    
    The vdso{32,64}.so can fail to link with CC=clang when clang tries to find
    a suitable GCC toolchain to link these libraries with.
    
    /usr/bin/ld: arch/x86/entry/vdso/vclock_gettime.o:
      access beyond end of merged section (782)
    
    This happens because the host environment leaked into the cross compiler
    environment due to the way clang searches for suitable GCC toolchains.
    
    Clang is a retargetable compiler, and each invocation of it must provide
    --target=<something> --gcc-toolchain=<something> to allow it to find the
    correct binutils for cross compilation. These flags had been added to
    KBUILD_CFLAGS, but the vdso code uses CC and not KBUILD_CFLAGS (for various
    reasons) which breaks clang's ability to find the correct linker when cross
    compiling.
    
    Most of the time this goes unnoticed because the host linker is new enough
    to work anyway, or is incompatible and skipped, but this cannot be reliably
    assumed.
    
    This change alters the vdso makefile to just use LD directly, which
    bypasses clang and thus the searching problem. The makefile will just use
    ${CROSS_COMPILE}ld instead, which is always what we want. This matches the
    method used to link vmlinux.
    
    This drops references to DISABLE_LTO; this option doesn't seem to be set
    anywhere, and not knowing what its possible values are, it's not clear how
    to convert it from CC to LD flag.
    
    Signed-off-by: Alistair Strachan <astrachan@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: kernel-team@android.com
    Cc: joel@joelfernandes.org
    Cc: Andi Kleen <andi.kleen@intel.com>
    Link: https://lkml.kernel.org/r/20180803173931.117515-1-astrachan@google.com
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 408d67a0fecf4cfe7869f518211ae278ee44376e
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Dec 6 11:12:31 2018 -0800

    x86/vdso: Drop implicit common-page-size linker flag
    
    GNU linker's -z common-page-size's default value is based on the target
    architecture. arch/x86/entry/vdso/Makefile sets it to the architecture
    default, which is implicit and redundant. Drop it.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Reported-by: Dmitry Golovin <dima@golovin.in>
    Reported-by: Bill Wendling <morbo@google.com>
    Suggested-by: Dmitry Golovin <dima@golovin.in>
    Suggested-by: Rui Ueyama <ruiu@google.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Fangrui Song <maskray@google.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20181206191231.192355-1-ndesaulniers@google.com
    Link: https://bugs.llvm.org/show_bug.cgi?id=38774
    Link: https://github.com/ClangBuiltLinux/linux/issues/31
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 94c0c4f033eee2304a98cf30a141f9dae35d3a62
Author: Alistair Strachan <astrachan@google.com>
Date:   Fri Aug 3 10:39:31 2018 -0700

    x86: vdso: Use $LD instead of $CC to link
    
    The vdso{32,64}.so can fail to link with CC=clang when clang tries to find
    a suitable GCC toolchain to link these libraries with.
    
    /usr/bin/ld: arch/x86/entry/vdso/vclock_gettime.o:
      access beyond end of merged section (782)
    
    This happens because the host environment leaked into the cross compiler
    environment due to the way clang searches for suitable GCC toolchains.
    
    Clang is a retargetable compiler, and each invocation of it must provide
    --target=<something> --gcc-toolchain=<something> to allow it to find the
    correct binutils for cross compilation. These flags had been added to
    KBUILD_CFLAGS, but the vdso code uses CC and not KBUILD_CFLAGS (for various
    reasons) which breaks clang's ability to find the correct linker when cross
    compiling.
    
    Most of the time this goes unnoticed because the host linker is new enough
    to work anyway, or is incompatible and skipped, but this cannot be reliably
    assumed.
    
    This change alters the vdso makefile to just use LD directly, which
    bypasses clang and thus the searching problem. The makefile will just use
    ${CROSS_COMPILE}ld instead, which is always what we want. This matches the
    method used to link vmlinux.
    
    This drops references to DISABLE_LTO; this option doesn't seem to be set
    anywhere, and not knowing what its possible values are, it's not clear how
    to convert it from CC to LD flag.
    
    Signed-off-by: Alistair Strachan <astrachan@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: kernel-team@android.com
    Cc: joel@joelfernandes.org
    Cc: Andi Kleen <andi.kleen@intel.com>
    Link: https://lkml.kernel.org/r/20180803173931.117515-1-astrachan@google.com
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 06b251dff78704c7d122bd109384d970a7dbe94d
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri Apr 12 20:16:15 2019 +0200

    x86/fpu: Restore regs in copy_fpstate_to_sigframe() in order to use the fastpath
    
    If a task is scheduled out and receives a signal then it won't be
    able to take the fastpath because the registers aren't available. The
    slowpath is more expensive compared to XRSTOR + XSAVE which usually
    succeeds.
    
    Here are some clock_gettime() numbers from a bigger box with AVX512
    during bootup:
    
    - __fpregs_load_activate() takes 140ns - 350ns. If it was the most recent
      FPU context on the CPU then the optimisation in __fpregs_load_activate()
      will skip the load (which was disabled during the test).
    
    - copy_fpregs_to_sigframe() takes 200ns - 450ns if it succeeds. On a
      pagefault it is 1.8us - 3us usually in the 2.6us area.
    
    - The slowpath takes 1.5us - 6us. Usually in the 2.6us area.
    
    My testcases (including lat_sig) take the fastpath without
    __fpregs_load_activate(). I expect this to be the majority.
    
    Since the slowpath is in the >1us area it makes sense to load the
    registers and attempt to save them directly. The direct save may fail
    but should only happen on the first invocation or after fork() while the
    page is read-only.
    
     [ bp: Massage a bit. ]
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Dave Hansen <dave.hansen@intel.com>
    Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Jann Horn <jannh@google.com>
    Cc: "Jason A. Donenfeld" <Jason@zx2c4.com>
    Cc: kvm ML <kvm@vger.kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Radim Krčmář <rkrcmar@redhat.com>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20190403164156.19645-27-bigeasy@linutronix.de

commit 7f5ffb4c7a710c1f441817cbeca7ca5aecc5f4ef
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 14 00:14:38 2019 +1100

    powerpc/vdso64: Fix CLOCK_MONOTONIC inconsistencies across Y2038
    
    commit b5b4453e7912f056da1ca7572574cada32ecb60c upstream.
    
    Jakub Drnec reported:
      Setting the realtime clock can sometimes make the monotonic clock go
      back by over a hundred years. Decreasing the realtime clock across
      the y2k38 threshold is one reliable way to reproduce. Allegedly this
      can also happen just by running ntpd, I have not managed to
      reproduce that other than booting with rtc at >2038 and then running
      ntp. When this happens, anything with timers (e.g. openjdk) breaks
      rather badly.
    
    And included a test case (slightly edited for brevity):
      #define _POSIX_C_SOURCE 199309L
      #include <stdio.h>
      #include <time.h>
      #include <stdlib.h>
      #include <unistd.h>
    
      long get_time(void) {
        struct timespec tp;
        clock_gettime(CLOCK_MONOTONIC, &tp);
        return tp.tv_sec + tp.tv_nsec / 1000000000;
      }
    
      int main(void) {
        long last = get_time();
        while(1) {
          long now = get_time();
          if (now < last) {
            printf("clock went backwards by %ld seconds!\n", last - now);
          }
          last = now;
          sleep(1);
        }
        return 0;
      }
    
    Which when run concurrently with:
     # date -s 2040-1-1
     # date -s 2037-1-1
    
    Will detect the clock going backward.
    
    The root cause is that wtom_clock_sec in struct vdso_data is only a
    32-bit signed value, even though we set its value to be equal to
    tk->wall_to_monotonic.tv_sec which is 64-bits.
    
    Because the monotonic clock starts at zero when the system boots the
    wall_to_montonic.tv_sec offset is negative for current and future
    dates. Currently on a freshly booted system the offset will be in the
    vicinity of negative 1.5 billion seconds.
    
    However if the wall clock is set past the Y2038 boundary, the offset
    from wall to monotonic becomes less than negative 2^31, and no longer
    fits in 32-bits. When that value is assigned to wtom_clock_sec it is
    truncated and becomes positive, causing the VDSO assembly code to
    calculate CLOCK_MONOTONIC incorrectly.
    
    That causes CLOCK_MONOTONIC to jump ahead by ~4 billion seconds which
    it is not meant to do. Worse, if the time is then set back before the
    Y2038 boundary CLOCK_MONOTONIC will jump backward.
    
    We can fix it simply by storing the full 64-bit offset in the
    vdso_data, and using that in the VDSO assembly code. We also shuffle
    some of the fields in vdso_data to avoid creating a hole.
    
    The original commit that added the CLOCK_MONOTONIC support to the VDSO
    did actually use a 64-bit value for wtom_clock_sec, see commit
    a7f290dad32e ("[PATCH] powerpc: Merge vdso's and add vdso support to
    32 bits kernel") (Nov 2005). However just 3 days later it was
    converted to 32-bits in commit 0c37ec2aa88b ("[PATCH] powerpc: vdso
    fixes (take #2)"), and the bug has existed since then AFAICS.
    
    Fixes: 0c37ec2aa88b ("[PATCH] powerpc: vdso fixes (take #2)")
    Cc: stable@vger.kernel.org # v2.6.15+
    Link: http://lkml.kernel.org/r/HaC.ZfES.62bwlnvAvMP.1STMMj@seznam.cz
    Reported-by: Jakub Drnec <jaydee@email.cz>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b8ea151a7ab5448782006b3723e6b25c33cbae64
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 14 00:14:38 2019 +1100

    powerpc/vdso64: Fix CLOCK_MONOTONIC inconsistencies across Y2038
    
    commit b5b4453e7912f056da1ca7572574cada32ecb60c upstream.
    
    Jakub Drnec reported:
      Setting the realtime clock can sometimes make the monotonic clock go
      back by over a hundred years. Decreasing the realtime clock across
      the y2k38 threshold is one reliable way to reproduce. Allegedly this
      can also happen just by running ntpd, I have not managed to
      reproduce that other than booting with rtc at >2038 and then running
      ntp. When this happens, anything with timers (e.g. openjdk) breaks
      rather badly.
    
    And included a test case (slightly edited for brevity):
      #define _POSIX_C_SOURCE 199309L
      #include <stdio.h>
      #include <time.h>
      #include <stdlib.h>
      #include <unistd.h>
    
      long get_time(void) {
        struct timespec tp;
        clock_gettime(CLOCK_MONOTONIC, &tp);
        return tp.tv_sec + tp.tv_nsec / 1000000000;
      }
    
      int main(void) {
        long last = get_time();
        while(1) {
          long now = get_time();
          if (now < last) {
            printf("clock went backwards by %ld seconds!\n", last - now);
          }
          last = now;
          sleep(1);
        }
        return 0;
      }
    
    Which when run concurrently with:
     # date -s 2040-1-1
     # date -s 2037-1-1
    
    Will detect the clock going backward.
    
    The root cause is that wtom_clock_sec in struct vdso_data is only a
    32-bit signed value, even though we set its value to be equal to
    tk->wall_to_monotonic.tv_sec which is 64-bits.
    
    Because the monotonic clock starts at zero when the system boots the
    wall_to_montonic.tv_sec offset is negative for current and future
    dates. Currently on a freshly booted system the offset will be in the
    vicinity of negative 1.5 billion seconds.
    
    However if the wall clock is set past the Y2038 boundary, the offset
    from wall to monotonic becomes less than negative 2^31, and no longer
    fits in 32-bits. When that value is assigned to wtom_clock_sec it is
    truncated and becomes positive, causing the VDSO assembly code to
    calculate CLOCK_MONOTONIC incorrectly.
    
    That causes CLOCK_MONOTONIC to jump ahead by ~4 billion seconds which
    it is not meant to do. Worse, if the time is then set back before the
    Y2038 boundary CLOCK_MONOTONIC will jump backward.
    
    We can fix it simply by storing the full 64-bit offset in the
    vdso_data, and using that in the VDSO assembly code. We also shuffle
    some of the fields in vdso_data to avoid creating a hole.
    
    The original commit that added the CLOCK_MONOTONIC support to the VDSO
    did actually use a 64-bit value for wtom_clock_sec, see commit
    a7f290dad32e ("[PATCH] powerpc: Merge vdso's and add vdso support to
    32 bits kernel") (Nov 2005). However just 3 days later it was
    converted to 32-bits in commit 0c37ec2aa88b ("[PATCH] powerpc: vdso
    fixes (take #2)"), and the bug has existed since then AFAICS.
    
    Fixes: 0c37ec2aa88b ("[PATCH] powerpc: vdso fixes (take #2)")
    Cc: stable@vger.kernel.org # v2.6.15+
    Link: http://lkml.kernel.org/r/HaC.ZfES.62bwlnvAvMP.1STMMj@seznam.cz
    Reported-by: Jakub Drnec <jaydee@email.cz>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b5b4453e7912f056da1ca7572574cada32ecb60c
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Thu Mar 14 00:14:38 2019 +1100

    powerpc/vdso64: Fix CLOCK_MONOTONIC inconsistencies across Y2038
    
    Jakub Drnec reported:
      Setting the realtime clock can sometimes make the monotonic clock go
      back by over a hundred years. Decreasing the realtime clock across
      the y2k38 threshold is one reliable way to reproduce. Allegedly this
      can also happen just by running ntpd, I have not managed to
      reproduce that other than booting with rtc at >2038 and then running
      ntp. When this happens, anything with timers (e.g. openjdk) breaks
      rather badly.
    
    And included a test case (slightly edited for brevity):
      #define _POSIX_C_SOURCE 199309L
      #include <stdio.h>
      #include <time.h>
      #include <stdlib.h>
      #include <unistd.h>
    
      long get_time(void) {
        struct timespec tp;
        clock_gettime(CLOCK_MONOTONIC, &tp);
        return tp.tv_sec + tp.tv_nsec / 1000000000;
      }
    
      int main(void) {
        long last = get_time();
        while(1) {
          long now = get_time();
          if (now < last) {
            printf("clock went backwards by %ld seconds!\n", last - now);
          }
          last = now;
          sleep(1);
        }
        return 0;
      }
    
    Which when run concurrently with:
     # date -s 2040-1-1
     # date -s 2037-1-1
    
    Will detect the clock going backward.
    
    The root cause is that wtom_clock_sec in struct vdso_data is only a
    32-bit signed value, even though we set its value to be equal to
    tk->wall_to_monotonic.tv_sec which is 64-bits.
    
    Because the monotonic clock starts at zero when the system boots the
    wall_to_montonic.tv_sec offset is negative for current and future
    dates. Currently on a freshly booted system the offset will be in the
    vicinity of negative 1.5 billion seconds.
    
    However if the wall clock is set past the Y2038 boundary, the offset
    from wall to monotonic becomes less than negative 2^31, and no longer
    fits in 32-bits. When that value is assigned to wtom_clock_sec it is
    truncated and becomes positive, causing the VDSO assembly code to
    calculate CLOCK_MONOTONIC incorrectly.
    
    That causes CLOCK_MONOTONIC to jump ahead by ~4 billion seconds which
    it is not meant to do. Worse, if the time is then set back before the
    Y2038 boundary CLOCK_MONOTONIC will jump backward.
    
    We can fix it simply by storing the full 64-bit offset in the
    vdso_data, and using that in the VDSO assembly code. We also shuffle
    some of the fields in vdso_data to avoid creating a hole.
    
    The original commit that added the CLOCK_MONOTONIC support to the VDSO
    did actually use a 64-bit value for wtom_clock_sec, see commit
    a7f290dad32e ("[PATCH] powerpc: Merge vdso's and add vdso support to
    32 bits kernel") (Nov 2005). However just 3 days later it was
    converted to 32-bits in commit 0c37ec2aa88b ("[PATCH] powerpc: vdso
    fixes (take #2)"), and the bug has existed since then AFAICS.
    
    Fixes: 0c37ec2aa88b ("[PATCH] powerpc: vdso fixes (take #2)")
    Cc: stable@vger.kernel.org # v2.6.15+
    Link: http://lkml.kernel.org/r/HaC.ZfES.62bwlnvAvMP.1STMMj@seznam.cz
    Reported-by: Jakub Drnec <jaydee@email.cz>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

commit b1b988a6a035212f5ea205155c49ce449beedee8
Merge: edaed168e135 cfbe271667b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 5 14:08:26 2019 -0800

    Merge branch 'timers-2038-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull year 2038 updates from Thomas Gleixner:
     "Another round of changes to make the kernel ready for 2038. After lots
      of preparatory work this is the first set of syscalls which are 2038
      safe:
    
        403 clock_gettime64
        404 clock_settime64
        405 clock_adjtime64
        406 clock_getres_time64
        407 clock_nanosleep_time64
        408 timer_gettime64
        409 timer_settime64
        410 timerfd_gettime64
        411 timerfd_settime64
        412 utimensat_time64
        413 pselect6_time64
        414 ppoll_time64
        416 io_pgetevents_time64
        417 recvmmsg_time64
        418 mq_timedsend_time64
        419 mq_timedreceiv_time64
        420 semtimedop_time64
        421 rt_sigtimedwait_time64
        422 futex_time64
        423 sched_rr_get_interval_time64
    
      The syscall numbers are identical all over the architectures"
    
    * 'timers-2038-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (36 commits)
      riscv: Use latest system call ABI
      checksyscalls: fix up mq_timedreceive and stat exceptions
      unicore32: Fix __ARCH_WANT_STAT64 definition
      asm-generic: Make time32 syscall numbers optional
      asm-generic: Drop getrlimit and setrlimit syscalls from default list
      32-bit userspace ABI: introduce ARCH_32BIT_OFF_T config option
      compat ABI: use non-compat openat and open_by_handle_at variants
      y2038: add 64-bit time_t syscalls to all 32-bit architectures
      y2038: rename old time and utime syscalls
      y2038: remove struct definition redirects
      y2038: use time32 syscall names on 32-bit
      syscalls: remove obsolete __IGNORE_ macros
      y2038: syscalls: rename y2038 compat syscalls
      x86/x32: use time64 versions of sigtimedwait and recvmmsg
      timex: change syscalls to use struct __kernel_timex
      timex: use __kernel_timex internally
      sparc64: add custom adjtimex/clock_adjtime functions
      time: fix sys_timer_settime prototype
      time: Add struct __kernel_timex
      time: make adjtime compat handling available for 32 bit
      ...

commit 41ea39101d6b84394fae0c12b702c4326aa71d17
Merge: fd659cc095af 48166e6ea47d
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Feb 10 20:50:32 2019 +0100

    Merge tag 'y2038-new-syscalls' of git://git.kernel.org:/pub/scm/linux/kernel/git/arnd/playground into timers/2038
    
    Pull y2038 - time64 system calls from Arnd Bergmann:
    
    This series finally gets us to the point of having system calls with 64-bit
    time_t on all architectures, after a long time of incremental preparation
    patches.
    
    There was actually one conversion that I missed during the summer,
    i.e. Deepa's timex series, which I now updated based the 5.0-rc1 changes
    and review comments.
    
    The following system calls are now added on all 32-bit architectures using
    the same system call numbers:
    
    403 clock_gettime64
    404 clock_settime64
    405 clock_adjtime64
    406 clock_getres_time64
    407 clock_nanosleep_time64
    408 timer_gettime64
    409 timer_settime64
    410 timerfd_gettime64
    411 timerfd_settime64
    412 utimensat_time64
    413 pselect6_time64
    414 ppoll_time64
    416 io_pgetevents_time64
    417 recvmmsg_time64
    418 mq_timedsend_time64
    419 mq_timedreceiv_time64
    420 semtimedop_time64
    421 rt_sigtimedwait_time64
    422 futex_time64
    423 sched_rr_get_interval_time64
    
    Each one of these corresponds directly to an existing system call that
    includes a 'struct timespec' argument, or a structure containing a timespec
    or (in case of clock_adjtime) timeval. Not included here are new versions
    of getitimer/setitimer and getrusage/waitid, which are planned for the
    future but only needed to make a consistent API rather than for correct
    operation beyond y2038. These four system calls are based on 'timeval', and
    it has not been finally decided what the replacement kernel interface will
    use instead.
    
    So far, I have done a lot of build testing across most architectures, which
    has found a number of bugs. Runtime testing so far included testing LTP on
    32-bit ARM with the existing system calls, to ensure we do not regress for
    existing binaries, and a test with a 32-bit x86 build of LTP against a
    modified version of the musl C library that has been adapted to the new
    system call interface [3].  This library can be used for testing on all
    architectures supported by musl-1.1.21, but it is not how the support is
    getting integrated into the official musl release. Official musl support is
    planned but will require more invasive changes to the library.
    
    Link: https://lore.kernel.org/lkml/20190110162435.309262-1-arnd@arndb.de/T/
    Link: https://lore.kernel.org/lkml/20190118161835.2259170-1-arnd@arndb.de/
    Link: https://git.linaro.org/people/arnd/musl-y2038.git/ [2]

commit d33c577cccd0b3e5bb2425f85037f26714a59363
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Sun Jan 6 23:45:29 2019 +0100

    y2038: rename old time and utime syscalls
    
    The time, stime, utime, utimes, and futimesat system calls are only
    used on older architectures, and we do not provide y2038 safe variants
    of them, as they are replaced by clock_gettime64, clock_settime64,
    and utimensat_time64.
    
    However, for consistency it seems better to have the 32-bit architectures
    that still use them call the "time32" entry points (leaving the
    traditional handlers for the 64-bit architectures), like we do for system
    calls that now require two versions.
    
    Note: We used to always define __ARCH_WANT_SYS_TIME and
    __ARCH_WANT_SYS_UTIME and only set __ARCH_WANT_COMPAT_SYS_TIME and
    __ARCH_WANT_SYS_UTIME32 for compat mode on 64-bit kernels. Now this is
    reversed: only 64-bit architectures set __ARCH_WANT_SYS_TIME/UTIME, while
    we need __ARCH_WANT_SYS_TIME32/UTIME32 for 32-bit architectures and compat
    mode. The resulting asm/unistd.h changes look a bit counterintuitive.
    
    This is only a cleanup patch and it should not change any behavior.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Acked-by: Heiko Carstens <heiko.carstens@de.ibm.com>

commit 4f9007359bcd28bc83c63cb9af38d8b2c8c1670d
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b upstream.
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org
    [bwh: Backported to 3.16: adjust filename]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit ac3e233d29f7f77f28243af0132057d378d3ea58
Author: Nick Desaulniers <ndesaulniers@google.com>
Date:   Thu Dec 6 11:12:31 2018 -0800

    x86/vdso: Drop implicit common-page-size linker flag
    
    GNU linker's -z common-page-size's default value is based on the target
    architecture. arch/x86/entry/vdso/Makefile sets it to the architecture
    default, which is implicit and redundant. Drop it.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Reported-by: Dmitry Golovin <dima@golovin.in>
    Reported-by: Bill Wendling <morbo@google.com>
    Suggested-by: Dmitry Golovin <dima@golovin.in>
    Suggested-by: Rui Ueyama <ruiu@google.com>
    Signed-off-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Fangrui Song <maskray@google.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: x86-ml <x86@kernel.org>
    Link: https://lkml.kernel.org/r/20181206191231.192355-1-ndesaulniers@google.com
    Link: https://bugs.llvm.org/show_bug.cgi?id=38774
    Link: https://github.com/ClangBuiltLinux/linux/issues/31

commit e312747b49d382584aaa62398952832765e28f74
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Nov 7 10:09:41 2018 -0300

    perf augmented_syscalls: Remove example hardcoded set of filtered pids
    
    Now that 'perf trace' fills in that "filtered_pids" BPF map, remove the
    set of filtered pids used as an example to test that feature.
    
    That feature works like this:
    
    Starting a system wide 'strace' like 'perf trace' augmented session we
    noticed that lots of events take place for a pid, which ends up being
    the feedback loop of perf trace's syscalls being processed by the
    'gnome-terminal' process:
    
      # perf trace -e tools/perf/examples/bpf/augmented_raw_syscalls.c
         0.391 ( 0.002 ms): gnome-terminal/2469 read(fd: 17</dev/ptmx>, buf: 0x564b79f750bc, count: 8176) = 453
         0.394 ( 0.001 ms): gnome-terminal/2469 read(fd: 17</dev/ptmx>, buf: 0x564b79f75280, count: 7724) = -1 EAGAIN Resource temporarily unavailable
         0.438 ( 0.001 ms): gnome-terminal/2469 read(fd: 4<anon_inode:[eventfd]>, buf: 0x7fffc696aeb0, count: 16) = 8
         0.519 ( 0.001 ms): gnome-terminal/2469 read(fd: 17</dev/ptmx>, buf: 0x564b79f75280, count: 7724) = 114
         0.522 ( 0.001 ms): gnome-terminal/2469 read(fd: 17</dev/ptmx>, buf: 0x564b79f752f1, count: 7611) = -1 EAGAIN Resource temporarily unavailable
      ^C
    
    So we can use --filter-pids to get rid of that one, and in this case what is
    being used to implement that functionality is that "filtered_pids" BPF map that
    the tools/perf/examples/bpf/augmented_raw_syscalls.c created and that 'perf trace'
    bpf loader noticed and created a "struct bpf_map" associated that then got populated
    by 'perf trace':
    
      # perf trace --filter-pids 2469 -e tools/perf/examples/bpf/augmented_raw_syscalls.c
         0.020 ( 0.002 ms): gnome-shell/1663 epoll_pwait(epfd: 12<anon_inode:[eventpoll]>, events: 0x7ffd8f3ef960, maxevents: 32, sigsetsize: 8) = 1
         0.025 ( 0.002 ms): gnome-shell/1663 read(fd: 24</dev/input/event4>, buf: 0x560c01bb8240, count: 8112) = 48
         0.029 ( 0.001 ms): gnome-shell/1663 read(fd: 24</dev/input/event4>, buf: 0x560c01bb8258, count: 8088) = -1 EAGAIN Resource temporarily unavailable
         0.032 ( 0.001 ms): gnome-shell/1663 read(fd: 24</dev/input/event4>, buf: 0x560c01bb8240, count: 8112) = -1 EAGAIN Resource temporarily unavailable
         0.040 ( 0.003 ms): gnome-shell/1663 recvmsg(fd: 46<socket:[35893]>, msg: 0x7ffd8f3ef950) = -1 EAGAIN Resource temporarily unavailable
        21.529 ( 0.002 ms): gnome-shell/1663 epoll_pwait(epfd: 5<anon_inode:[eventpoll]>, events: 0x7ffd8f3ef960, maxevents: 32, sigsetsize: 8) = 1
        21.533 ( 0.004 ms): gnome-shell/1663 recvmsg(fd: 82<socket:[42826]>, msg: 0x7ffd8f3ef7b0, flags: DONTWAIT|CMSG_CLOEXEC) = 236
        21.581 ( 0.006 ms): gnome-shell/1663 ioctl(fd: 8</dev/dri/card0>, cmd: DRM_I915_GEM_BUSY, arg: 0x7ffd8f3ef060) = 0
        21.605 ( 0.020 ms): gnome-shell/1663 ioctl(fd: 8</dev/dri/card0>, cmd: DRM_I915_GEM_CREATE, arg: 0x7ffd8f3eeea0) = 0
        21.626 ( 0.119 ms): gnome-shell/1663 ioctl(fd: 8</dev/dri/card0>, cmd: DRM_I915_GEM_SET_DOMAIN, arg: 0x7ffd8f3eee94) = 0
        21.746 ( 0.081 ms): gnome-shell/1663 ioctl(fd: 8</dev/dri/card0>, cmd: DRM_I915_GEM_PWRITE, arg: 0x7ffd8f3eeea0) = 0
      ^C
    
    Oops, yet another gnome process that is involved with the output that
    'perf trace' generates, lets filter that out too:
    
      # perf trace --filter-pids 2469,1663 -e tools/perf/examples/bpf/augmented_raw_syscalls.c
             ? (         ): wpa_supplicant/1366  ... [continued]: select()) = 0 Timeout
         0.006 ( 0.002 ms): wpa_supplicant/1366 clock_gettime(which_clock: BOOTTIME, tp: 0x7fffe5b1e430) = 0
         0.011 ( 0.001 ms): wpa_supplicant/1366 clock_gettime(which_clock: BOOTTIME, tp: 0x7fffe5b1e3e0) = 0
         0.014 ( 0.001 ms): wpa_supplicant/1366 clock_gettime(which_clock: BOOTTIME, tp: 0x7fffe5b1e430) = 0
             ? (         ): gmain/1791  ... [continued]: poll()) = 0 Timeout
         0.017 (         ): wpa_supplicant/1366 select(n: 6, inp: 0x55646fed3ad0, outp: 0x55646fed3b60, exp: 0x55646fed3bf0, tvp: 0x7fffe5b1e4a0) ...
       157.879 ( 0.019 ms): gmain/1791 inotify_add_watch(fd: 8<anon_inode:inotify>, pathname: , mask: 16789454) = -1 ENOENT No such file or directory
             ? (         ): cupsd/1001  ... [continued]: epoll_pwait()) = 0
             ? (         ): gsd-color/1908  ... [continued]: poll()) = 0 Timeout
       499.615 (         ): cupsd/1001 epoll_pwait(epfd: 4<anon_inode:[eventpoll]>, events: 0x557a21166500, maxevents: 4096, timeout: 1000, sigsetsize: 8) ...
       586.593 ( 0.004 ms): gsd-color/1908 recvmsg(fd: 3<socket:[38074]>, msg: 0x7ffdef34e800) = -1 EAGAIN Resource temporarily unavailable
             ? (         ): fwupd/2230  ... [continued]: poll()) = 0 Timeout
             ? (         ): rtkit-daemon/906  ... [continued]: poll()) = 0 Timeout
             ? (         ): rtkit-daemon/907  ... [continued]: poll()) = 1
       724.603 ( 0.007 ms): rtkit-daemon/907 read(fd: 6<anon_inode:[eventfd]>, buf: 0x7f05ff768d08, count: 8) = 8
             ? (         ): ssh/5461  ... [continued]: select()) = 1
       810.431 ( 0.002 ms): ssh/5461 clock_gettime(which_clock: BOOTTIME, tp: 0x7ffd7f39f870) = 0
       ^C
    
    Several syscall exit events for syscalls in flight when 'perf trace' started, etc. Saner :-)
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-c3tu5yg204p5mvr9kvwew07n@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit a97a2d4d56ea596871b739d63d41b084733bd9fb
Merge: 44786880df19 8dbc450f76dc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 24 06:42:00 2018 +0100

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc
    
    Pull sparc updates from David Miller:
     "Mostly VDSO cleanups and optimizations"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/sparc:
      sparc: Several small VDSO vclock_gettime.c improvements.
      sparc: Validate VDSO for undefined symbols.
      sparc: Really use linker with LDFLAGS.
      sparc: Improve VDSO CFLAGS.
      sparc: Set DISABLE_BRANCH_PROFILING in VDSO CFLAGS.
      sparc: Don't bother masking out TICK_PRIV_BIT in VDSO code.
      sparc: Inline VDSO gettime code aggressively.
      sparc: Improve VDSO instruction patching.
      sparc: Fix parport build warnings.

commit 8dbc450f76dc8f3b47fe117cd0cde166e1f21b64
Merge: 46b8306480fb 19832d244954
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Oct 22 19:14:24 2018 -0700

    Merge branch 'sparc-vdso'
    
    sparc: VDSO improvements
    
    I started out on these changes with the goal of improving perf
    annotations when the VDSO is in use.  Due to lack of inlining the
    helper functions are typically hit when profiling instead of
    __vdso_gettimeoday() or __vdso_vclock_gettime().
    
    The only symbols available by default are the dyanmic symbols,
    which therefore doesn't cover the helper functions.
    
    So the perf output looks terrible, because the symbols cannot be
    resolved and all show up as "Unknown".
    
    The sparc VDSO code forces no inlining because of the way the
    simplistic %tick register read code patching works.  So fixing that
    was the first order of business.  Tricks were taken from how x86
    implements alternates.  The crucial factor is that if you want to
    refer to locations (for the original and patch instruction(s)) you
    have to do so in a way that is resolvable at link time even for a
    shared object.  So you have to do this by storing PC-relative
    values, and not in executable sections.
    
    Next, we sanitize the Makefile so that the cflags et al. make more
    sense.  And LDFLAGS are applied actually to invocations of LD instead
    of CC.
    
    We also add some sanity checking, specifically in a post-link check
    that makes sure we don't have any unexpected unresolved symbols in the
    VDSO.  This is essential because the dynamic linker cannot resolve
    symbols in the VDSO because it cannot write to it.
    
    Finally some very minor optimizations are preformed to the
    vclock_gettime.c code.  One thing which is tricky with this code on
    sparc is that struct timeval and struct timespec are layed out
    differently on 64-bit.  This is because, unlike other architectures,
    sparc defined suseconds_t as 'int' even on 64-bit.  This is why we
    have all of the "union" tstv_t" business and the weird assignments
    in __vdso_gettimeofday().
    
    Performance wise we do gain some cycle shere, specifically here
    are cycle counts for a user application calling gettimeofday():
    
            no-VDSO         VDSO-orig       VDSO-new
    ================================================
    64-bit  853 cycles      112 cycles      125 cycles
    32-bit  849 cycles      134 cycles      141 cycles
    
    These results are with current glibc sources.
    
    To get better we'd need to implement this in assembler, and I might
    just do that at some point.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 19832d244954189c851d8492718607a14734679c
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Oct 21 22:38:56 2018 -0700

    sparc: Several small VDSO vclock_gettime.c improvements.
    
    Almost entirely borrowed from the x86 code.
    
    Main improvement is to avoid having to initialize
    ts->tv_nsec to zero before the sequence loops, by
    expanding timespec_add_ns().
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 44231b7fee3f086cf367588c7c79ec3b5d7619b2
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Oct 21 22:14:01 2018 -0700

    sparc: Set DISABLE_BRANCH_PROFILING in VDSO CFLAGS.
    
    Not in vclock_gettime.c itself.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1af2998c34e186636588e97a7ae6bcd6bb7b8936
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:16 2018 -0700

    selftests/x86: Add clock_gettime() tests to test_vdso
    
    commit 7c03e7035ac1cf2a6165754e4f3a49c2f1977838 upstream.
    
    Now that the vDSO implementation of clock_gettime() is getting
    reworked, add a selftest for it.  This tests that its output is
    consistent with the syscall version.
    
    This is marked for stable to serve as a test for commit
    
      715bd9d12f84 ("x86/vdso: Fix asm constraints on vDSO syscall fallbacks")
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/082399674de2619b2befd8c0dde49b260605b126.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e7e1889390a4a2b1e32edf26d7119ee92ad375cc
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b upstream.
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 64ff5747e2af415348ca3dd9221ef542ad07fdb9
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:16 2018 -0700

    selftests/x86: Add clock_gettime() tests to test_vdso
    
    commit 7c03e7035ac1cf2a6165754e4f3a49c2f1977838 upstream.
    
    Now that the vDSO implementation of clock_gettime() is getting
    reworked, add a selftest for it.  This tests that its output is
    consistent with the syscall version.
    
    This is marked for stable to serve as a test for commit
    
      715bd9d12f84 ("x86/vdso: Fix asm constraints on vDSO syscall fallbacks")
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/082399674de2619b2befd8c0dde49b260605b126.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 30500cc74a365c2fc90dc9b6d9611bbbc1304af9
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b upstream.
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9f14d89a13164552038977e7d1bc5b2e3c31f56a
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b upstream.
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5961c3d0064fdc4326d5390b30ceb50ae5d1459e
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b upstream.
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 430d094da434246199406b48ea1d17e7cdc532f4
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b upstream.
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 247373b5dd685fd307d2ea7fd0e58353486e4ad4
Merge: 8be673735e51 02e425668f5c
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Oct 5 15:40:57 2018 -0700

    Merge branch 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Ingo writes:
      "x86 fixes:
    
       Misc fixes:
    
        - fix various vDSO bugs: asm constraints and retpolines
        - add vDSO test units to make sure they never re-appear
        - fix UV platform TSC initialization bug
        - fix build warning on Clang"
    
    * 'x86-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86/vdso: Fix vDSO syscall fallback asm constraint regression
      x86/cpu/amd: Remove unnecessary parentheses
      x86/vdso: Only enable vDSO retpolines when enabled and supported
      x86/tsc: Fix UV TSC initialization
      x86/platform/uv: Provide is_early_uv_system()
      selftests/x86: Add clock_gettime() tests to test_vdso
      x86/vdso: Fix asm constraints on vDSO syscall fallbacks

commit 99c19e6a8fe4a95fa0dac191207a1d40461b1604
Author: Andy Lutomirski <luto@kernel.org>
Date:   Fri Oct 5 11:02:43 2018 -0700

    x86/vdso: Rearrange do_hres() to improve code generation
    
    vgetcyc() is full of barriers, so fetching values out of the vvar
    page before vgetcyc() for use after vgetcyc() results in poor code
    generation.  Put vgetcyc() first to avoid this problem.
    
    Also, pull the tv_sec division into the loop and put all the ts
    writes together.  The old code wrote ts->tv_sec on each iteration
    before the syscall fallback check and then added in the offset
    afterwards, which forced the compiler to pointlessly copy base->sec
    to ts->tv_sec on each iteration.  The new version seems to generate
    sensible code.
    
    Saves several cycles.  With this patch applied, the result is faster
    than before the clock_gettime() rewrite.
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lkml.kernel.org/r/3c05644d010b72216aa286a6d20b5078d5fae5cd.1538762487.git.luto@kernel.org

commit 4f72adc5068294268387a81a6bf91d9bb07ecc5c
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Sep 17 14:45:42 2018 +0200

    x86/vdso: Simplify the invalid vclock case
    
    The code flow for the vclocks is convoluted as it requires the vclocks
    which can be invalidated separately from the vsyscall_gtod_data sequence to
    store the fact in a separate variable. That's inefficient.
    
    Restructure the code so the vclock readout returns cycles and the
    conversion to nanoseconds is handled at the call site.
    
    If the clock gets invalidated or vclock is already VCLOCK_NONE, return
    U64_MAX as the cycle value, which is invalid for all clocks and leave the
    sequence loop immediately in that case by calling the fallback function
    directly.
    
    This allows to remove the gettimeofday fallback as it now uses the
    clock_gettime() fallback and does the nanoseconds to microseconds
    conversion in the same way as it does when the vclock is functional. It
    does not make a difference whether the division by 1000 happens in the
    kernel fallback or in userspace.
    
    Generates way better code and gains a few cycles back.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Matt Rickard <matt@softrans.com.au>
    Cc: Stephen Boyd <sboyd@kernel.org>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Florian Weimer <fweimer@redhat.com>
    Cc: "K. Y. Srinivasan" <kys@microsoft.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: devel@linuxdriverproject.org
    Cc: virtualization@lists.linux-foundation.org
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Juergen Gross <jgross@suse.com>
    Link: https://lkml.kernel.org/r/20180917130707.657928937@linutronix.de

commit 7c03e7035ac1cf2a6165754e4f3a49c2f1977838
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:16 2018 -0700

    selftests/x86: Add clock_gettime() tests to test_vdso
    
    Now that the vDSO implementation of clock_gettime() is getting
    reworked, add a selftest for it.  This tests that its output is
    consistent with the syscall version.
    
    This is marked for stable to serve as a test for commit
    
      715bd9d12f84 ("x86/vdso: Fix asm constraints on vDSO syscall fallbacks")
    
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/082399674de2619b2befd8c0dde49b260605b126.1538422295.git.luto@kernel.org

commit 715bd9d12f84d8f5cc8ad21d888f9bc304a8eb0b
Author: Andy Lutomirski <luto@kernel.org>
Date:   Mon Oct 1 12:52:15 2018 -0700

    x86/vdso: Fix asm constraints on vDSO syscall fallbacks
    
    The syscall fallbacks in the vDSO have incorrect asm constraints.
    They are not marked as writing to their outputs -- instead, they are
    marked as clobbering "memory", which is useless.  In particular, gcc
    is smart enough to know that the timespec parameter hasn't escaped,
    so a memory clobber doesn't clobber it.  And passing a pointer as an
    asm *input* does not tell gcc that the pointed-to value is changed.
    
    Add in the fact that the asm instructions weren't volatile, and gcc
    was free to omit them entirely unless their sole output (the return
    value) is used.  Which it is (phew!), but that stops happening with
    some upcoming patches.
    
    As a trivial example, the following code:
    
    void test_fallback(struct timespec *ts)
    {
            vdso_fallback_gettime(CLOCK_MONOTONIC, ts);
    }
    
    compiles to:
    
    00000000000000c0 <test_fallback>:
      c0:   c3                      retq
    
    To add insult to injury, the RCX and R11 clobbers on 64-bit
    builds were missing.
    
    The "memory" clobber is also unnecessary -- no ordering with respect to
    other memory operations is needed, but that's going to be fixed in a
    separate not-for-stable patch.
    
    Fixes: 2aae950b21e4 ("x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu")
    Signed-off-by: Andy Lutomirski <luto@kernel.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable@vger.kernel.org
    Link: https://lkml.kernel.org/r/2c0231690551989d2fafa60ed0e7b5cc8b403908.1538422295.git.luto@kernel.org

commit bd65d7bf59d966cdc6c56f141bf059678cec89e6
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Aug 30 11:01:21 2018 -0700

    MIPS: VDSO: Match data page cache colouring when D$ aliases
    
    commit 0f02cfbc3d9e413d450d8d0fd660077c23f67eff upstream.
    
    When a system suffers from dcache aliasing a user program may observe
    stale VDSO data from an aliased cache line. Notably this can break the
    expectation that clock_gettime(CLOCK_MONOTONIC, ...) is, as its name
    suggests, monotonic.
    
    In order to ensure that users observe updates to the VDSO data page as
    intended, align the user mappings of the VDSO data page such that their
    cache colouring matches that of the virtual address range which the
    kernel will use to update the data page - typically its unmapped address
    within kseg0.
    
    This ensures that we don't introduce aliasing cache lines for the VDSO
    data page, and therefore that userland will observe updates without
    requiring cache invalidation.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Reported-by: Hauke Mehrtens <hauke@hauke-m.de>
    Reported-by: Rene Nielsen <rene.nielsen@microsemi.com>
    Reported-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Fixes: ebb5e78cc634 ("MIPS: Initial implementation of a VDSO")
    Patchwork: https://patchwork.linux-mips.org/patch/20344/
    Tested-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Tested-by: Hauke Mehrtens <hauke@hauke-m.de>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: stable@vger.kernel.org # v4.4+
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 262ea6c0c422da1c5c8243cfde148fa9fdad7a26
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Aug 30 11:01:21 2018 -0700

    MIPS: VDSO: Match data page cache colouring when D$ aliases
    
    commit 0f02cfbc3d9e413d450d8d0fd660077c23f67eff upstream.
    
    When a system suffers from dcache aliasing a user program may observe
    stale VDSO data from an aliased cache line. Notably this can break the
    expectation that clock_gettime(CLOCK_MONOTONIC, ...) is, as its name
    suggests, monotonic.
    
    In order to ensure that users observe updates to the VDSO data page as
    intended, align the user mappings of the VDSO data page such that their
    cache colouring matches that of the virtual address range which the
    kernel will use to update the data page - typically its unmapped address
    within kseg0.
    
    This ensures that we don't introduce aliasing cache lines for the VDSO
    data page, and therefore that userland will observe updates without
    requiring cache invalidation.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Reported-by: Hauke Mehrtens <hauke@hauke-m.de>
    Reported-by: Rene Nielsen <rene.nielsen@microsemi.com>
    Reported-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Fixes: ebb5e78cc634 ("MIPS: Initial implementation of a VDSO")
    Patchwork: https://patchwork.linux-mips.org/patch/20344/
    Tested-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Tested-by: Hauke Mehrtens <hauke@hauke-m.de>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: stable@vger.kernel.org # v4.4+
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9efcaa7c4afba5628f2650a76f69c798f47eeb18
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Aug 30 11:01:21 2018 -0700

    MIPS: VDSO: Match data page cache colouring when D$ aliases
    
    commit 0f02cfbc3d9e413d450d8d0fd660077c23f67eff upstream.
    
    When a system suffers from dcache aliasing a user program may observe
    stale VDSO data from an aliased cache line. Notably this can break the
    expectation that clock_gettime(CLOCK_MONOTONIC, ...) is, as its name
    suggests, monotonic.
    
    In order to ensure that users observe updates to the VDSO data page as
    intended, align the user mappings of the VDSO data page such that their
    cache colouring matches that of the virtual address range which the
    kernel will use to update the data page - typically its unmapped address
    within kseg0.
    
    This ensures that we don't introduce aliasing cache lines for the VDSO
    data page, and therefore that userland will observe updates without
    requiring cache invalidation.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Reported-by: Hauke Mehrtens <hauke@hauke-m.de>
    Reported-by: Rene Nielsen <rene.nielsen@microsemi.com>
    Reported-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Fixes: ebb5e78cc634 ("MIPS: Initial implementation of a VDSO")
    Patchwork: https://patchwork.linux-mips.org/patch/20344/
    Tested-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Tested-by: Hauke Mehrtens <hauke@hauke-m.de>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: stable@vger.kernel.org # v4.4+
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 521983976c38b8d3b911628ff7760af3d9af4502
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Aug 30 11:01:21 2018 -0700

    MIPS: VDSO: Match data page cache colouring when D$ aliases
    
    commit 0f02cfbc3d9e413d450d8d0fd660077c23f67eff upstream.
    
    When a system suffers from dcache aliasing a user program may observe
    stale VDSO data from an aliased cache line. Notably this can break the
    expectation that clock_gettime(CLOCK_MONOTONIC, ...) is, as its name
    suggests, monotonic.
    
    In order to ensure that users observe updates to the VDSO data page as
    intended, align the user mappings of the VDSO data page such that their
    cache colouring matches that of the virtual address range which the
    kernel will use to update the data page - typically its unmapped address
    within kseg0.
    
    This ensures that we don't introduce aliasing cache lines for the VDSO
    data page, and therefore that userland will observe updates without
    requiring cache invalidation.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Reported-by: Hauke Mehrtens <hauke@hauke-m.de>
    Reported-by: Rene Nielsen <rene.nielsen@microsemi.com>
    Reported-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Fixes: ebb5e78cc634 ("MIPS: Initial implementation of a VDSO")
    Patchwork: https://patchwork.linux-mips.org/patch/20344/
    Tested-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Tested-by: Hauke Mehrtens <hauke@hauke-m.de>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: stable@vger.kernel.org # v4.4+
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 56d20861c027498b5a1112b4f9f05b56d906fdda
Author: Alan Modra <amodra@gmail.com>
Date:   Fri Sep 14 13:10:04 2018 +0930

    powerpc/vdso: Correct call frame information
    
    Call Frame Information is used by gdb for back-traces and inserting
    breakpoints on function return for the "finish" command.  This failed
    when inside __kernel_clock_gettime.  More concerning than difficulty
    debugging is that CFI is also used by stack frame unwinding code to
    implement exceptions.  If you have an app that needs to handle
    asynchronous exceptions for some reason, and you are unlucky enough to
    get one inside the VDSO time functions, your app will crash.
    
    What's wrong:  There is control flow in __kernel_clock_gettime that
    reaches label 99 without saving lr in r12.  CFI info however is
    interpreted by the unwinder without reference to control flow: It's a
    simple matter of "Execute all the CFI opcodes up to the current
    address".  That means the unwinder thinks r12 contains the return
    address at label 99.  Disabuse it of that notion by resetting CFI for
    the return address at label 99.
    
    Note that the ".cfi_restore lr" could have gone anywhere from the
    "mtlr r12" a few instructions earlier to the instruction at label 99.
    I put the CFI as late as possible, because in general that's best
    practice (and if possible grouped with other CFI in order to reduce
    the number of CFI opcodes executed when unwinding).  Using r12 as the
    return address is perfectly fine after the "mtlr r12" since r12 on
    that code path still contains the return address.
    
    __get_datapage also has a CFI error.  That function temporarily saves
    lr in r0, and reflects that fact with ".cfi_register lr,r0".  A later
    use of r0 means the CFI at that point isn't correct, as r0 no longer
    contains the return address.  Fix that too.
    
    Signed-off-by: Alan Modra <amodra@gmail.com>
    Tested-by: Reza Arbab <arbab@linux.ibm.com>
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

commit 2601dd392dd1cabd11935448c0afe3293feb27a3
Merge: c6ff25ce3564 0f02cfbc3d9e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 6 15:42:10 2018 -0700

    Merge tag 'mips_fixes_4.19_1' of git://git.kernel.org/pub/scm/linux/kernel/git/mips/linux
    
    Pull MIPS fix from Paul Burton:
     "A single fix for v4.19-rc3, resolving a problem with our VDSO data
      page for systems with dcache aliasing. Those systems could previously
      observe stale data, causing clock_gettime() & gettimeofday() to return
      incorrect values"
    
    * tag 'mips_fixes_4.19_1' of git://git.kernel.org/pub/scm/linux/kernel/git/mips/linux:
      MIPS: VDSO: Match data page cache colouring when D$ aliases

commit 0f02cfbc3d9e413d450d8d0fd660077c23f67eff
Author: Paul Burton <paul.burton@mips.com>
Date:   Thu Aug 30 11:01:21 2018 -0700

    MIPS: VDSO: Match data page cache colouring when D$ aliases
    
    When a system suffers from dcache aliasing a user program may observe
    stale VDSO data from an aliased cache line. Notably this can break the
    expectation that clock_gettime(CLOCK_MONOTONIC, ...) is, as its name
    suggests, monotonic.
    
    In order to ensure that users observe updates to the VDSO data page as
    intended, align the user mappings of the VDSO data page such that their
    cache colouring matches that of the virtual address range which the
    kernel will use to update the data page - typically its unmapped address
    within kseg0.
    
    This ensures that we don't introduce aliasing cache lines for the VDSO
    data page, and therefore that userland will observe updates without
    requiring cache invalidation.
    
    Signed-off-by: Paul Burton <paul.burton@mips.com>
    Reported-by: Hauke Mehrtens <hauke@hauke-m.de>
    Reported-by: Rene Nielsen <rene.nielsen@microsemi.com>
    Reported-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Fixes: ebb5e78cc634 ("MIPS: Initial implementation of a VDSO")
    Patchwork: https://patchwork.linux-mips.org/patch/20344/
    Tested-by: Alexandre Belloni <alexandre.belloni@bootlin.com>
    Tested-by: Hauke Mehrtens <hauke@hauke-m.de>
    Cc: James Hogan <jhogan@kernel.org>
    Cc: linux-mips@linux-mips.org
    Cc: stable@vger.kernel.org # v4.4+

commit 379d98ddf41344273d9718556f761420f4dc80b3
Author: Alistair Strachan <astrachan@google.com>
Date:   Fri Aug 3 10:39:31 2018 -0700

    x86: vdso: Use $LD instead of $CC to link
    
    The vdso{32,64}.so can fail to link with CC=clang when clang tries to find
    a suitable GCC toolchain to link these libraries with.
    
    /usr/bin/ld: arch/x86/entry/vdso/vclock_gettime.o:
      access beyond end of merged section (782)
    
    This happens because the host environment leaked into the cross compiler
    environment due to the way clang searches for suitable GCC toolchains.
    
    Clang is a retargetable compiler, and each invocation of it must provide
    --target=<something> --gcc-toolchain=<something> to allow it to find the
    correct binutils for cross compilation. These flags had been added to
    KBUILD_CFLAGS, but the vdso code uses CC and not KBUILD_CFLAGS (for various
    reasons) which breaks clang's ability to find the correct linker when cross
    compiling.
    
    Most of the time this goes unnoticed because the host linker is new enough
    to work anyway, or is incompatible and skipped, but this cannot be reliably
    assumed.
    
    This change alters the vdso makefile to just use LD directly, which
    bypasses clang and thus the searching problem. The makefile will just use
    ${CROSS_COMPILE}ld instead, which is always what we want. This matches the
    method used to link vmlinux.
    
    This drops references to DISABLE_LTO; this option doesn't seem to be set
    anywhere, and not knowing what its possible values are, it's not clear how
    to convert it from CC to LD flag.
    
    Signed-off-by: Alistair Strachan <astrachan@google.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Andy Lutomirski <luto@kernel.org>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: kernel-team@android.com
    Cc: joel@joelfernandes.org
    Cc: Andi Kleen <andi.kleen@intel.com>
    Link: https://lkml.kernel.org/r/20180803173931.117515-1-astrachan@google.com

commit b912885ab75c7c8aa841c615108afd755d0b97f8
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Aug 1 16:20:28 2018 -0300

    perf trace: Do not require --no-syscalls to suppress strace like output
    
    So far the --syscalls option was the default, requiring explicit
    --no-syscalls when wanting to process just some other event, invert that
    and assume it only when no other event was specified, allowing its
    explicit enablement when wanting to see all syscalls together with some
    other event:
    
    E.g:
    
    The existing default is maintained for a single workload:
    
      # perf trace sleep 1
    <SNIP>
         0.264 ( 0.003 ms): sleep/12762 mmap(len: 113045344, prot: READ, flags: PRIVATE, fd: 3) = 0x7f62cbf04000
         0.271 ( 0.001 ms): sleep/12762 close(fd: 3) = 0
         0.295 (1000.130 ms): sleep/12762 nanosleep(rqtp: 0x7ffd15194fd0) = 0
      1000.469 ( 0.006 ms): sleep/12762 close(fd: 1) = 0
      1000.480 ( 0.004 ms): sleep/12762 close(fd: 2) = 0
      1000.502 (         ): sleep/12762 exit_group()
      #
    
    For a pid:
    
      # pidof ssh
      7826 3961 3226 2628 2493
      # perf trace -p 3961
             ? (         ):  ... [continued]: select()) = 1
         0.023 ( 0.005 ms): clock_gettime(which_clock: BOOTTIME, tp: 0x7ffcc8fce870               ) = 0
         0.036 ( 0.009 ms): read(fd: 5</dev/pts/7>, buf: 0x7ffcc8fca7b0, count: 16384             ) = 3
         0.060 ( 0.004 ms): getpid(                                                               ) = 3961 (ssh)
         0.079 ( 0.004 ms): clock_gettime(which_clock: BOOTTIME, tp: 0x7ffcc8fce8e0               ) = 0
         0.088 ( 0.003 ms): clock_gettime(which_clock: BOOTTIME, tp: 0x7ffcc8fce7c0               ) = 0
    <SNIP>
    
    For system wide, threads, cgroups, user, etc when no event is specified,
    the existing behaviour is maintained, i.e. --syscalls is selected.
    
    When some event is specified, then --no-syscalls doesn't need to be
    specified:
    
      # perf trace -e tcp:tcp_probe ssh localhost
         0.000 tcp:tcp_probe:src=[::1]:22 dest=[::1]:39074 mark=0 length=53 snd_nxt=0xb67ce8f7 snd_una=0xb67ce8f7 snd_cwnd=10 ssthresh=2147483647 snd_wnd=43776 srtt=18 rcv_wnd=43690
         0.010 tcp:tcp_probe:src=[::1]:39074 dest=[::1]:22 mark=0 length=32 snd_nxt=0xa8f9ef38 snd_una=0xa8f9ef23 snd_cwnd=10 ssthresh=2147483647 snd_wnd=43690 srtt=31 rcv_wnd=43776
         4.525 tcp:tcp_probe:src=[::1]:22 dest=[::1]:39074 mark=0 length=1240 snd_nxt=0xb67ce90c snd_una=0xb67ce90c snd_cwnd=10 ssthresh=2147483647 snd_wnd=43776 srtt=18 rcv_wnd=43776
         7.242 tcp:tcp_probe:src=[::1]:22 dest=[::1]:39074 mark=0 length=80 snd_nxt=0xb67ced44 snd_una=0xb67ce90c snd_cwnd=10 ssthresh=2147483647 snd_wnd=43776 srtt=18 rcv_wnd=174720
      The authenticity of host 'localhost (::1)' can't be established.
      ECDSA key fingerprint is SHA256:TKZS58923458203490asekfjaklskljmkjfgPMBfHzY.
      ECDSA key fingerprint is MD5:d8:29:54:40:71:fa:b8:44:89:52:64:8a:35:42:d0:e8.
      Are you sure you want to continue connecting (yes/no)?
    ^C
      #
    
    To get the previous behaviour just use --syscalls and get all syscalls formatted
    strace like + the specified extra events:
    
      # trace -e sched:*switch --syscalls sleep 1
      <SNIP>
         0.160 ( 0.003 ms): sleep/12877 mprotect(start: 0x7fdfe2361000, len: 4096, prot: READ) = 0
         0.164 ( 0.009 ms): sleep/12877 munmap(addr: 0x7fdfe2345000, len: 113155) = 0
         0.211 ( 0.001 ms): sleep/12877 brk() = 0x55d3ce68e000
         0.212 ( 0.002 ms): sleep/12877 brk(brk: 0x55d3ce6af000) = 0x55d3ce6af000
         0.215 ( 0.001 ms): sleep/12877 brk() = 0x55d3ce6af000
         0.219 ( 0.004 ms): sleep/12877 open(filename: 0xe1f07c00, flags: CLOEXEC) = 3
         0.225 ( 0.001 ms): sleep/12877 fstat(fd: 3, statbuf: 0x7fdfe2138aa0) = 0
         0.227 ( 0.003 ms): sleep/12877 mmap(len: 113045344, prot: READ, flags: PRIVATE, fd: 3) = 0x7fdfdb1b8000
         0.234 ( 0.001 ms): sleep/12877 close(fd: 3) = 0
         0.257 (         ): sleep/12877 nanosleep(rqtp: 0x7fffb36b6020) ...
         0.260 (         ): sched:sched_switch:prev_comm=sleep prev_pid=12877 prev_prio=120 prev_state=D ==> next_comm=swapper/3 next_pid=0 next_prio=120
         0.257 (1000.134 ms): sleep/12877  ... [continued]: nanosleep()) = 0
      1000.428 ( 0.006 ms): sleep/12877 close(fd: 1) = 0
      1000.440 ( 0.004 ms): sleep/12877 close(fd: 2) = 0
      1000.461 (         ): sleep/12877 exit_group()
      #
    
    When specifiying just some syscalls, the behaviour doesn't change, i.e.:
    
      # trace -e nanosleep -e sched:*switch sleep 1
         0.000 (         ): sleep/14974 nanosleep(rqtp: 0x7ffc344ba9c0                                        ) ...
         0.007 (         ): sched:sched_switch:prev_comm=sleep prev_pid=14974 prev_prio=120 prev_state=D ==> next_comm=swapper/2 next_pid=0 next_prio=120
         0.000 (1000.139 ms): sleep/14974  ... [continued]: nanosleep()) = 0
      #
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-om2fulll97ytnxv40ler8jkf@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 9d2dcc8fc66087d7fd365e07cd4292adc873e568
Author: Michael O'Farrell <micpof@gmail.com>
Date:   Mon Jul 30 13:14:34 2018 -0700

    arm64: perf: Add cap_user_time aarch64
    
    It is useful to get the running time of a thread.  Doing so in an
    efficient manner can be important for performance of user applications.
    Avoiding system calls in `clock_gettime` when handling
    CLOCK_THREAD_CPUTIME_ID is important.  Other clocks are handled in the
    VDSO, but CLOCK_THREAD_CPUTIME_ID falls back on the system call.
    
    CLOCK_THREAD_CPUTIME_ID is not handled in the VDSO since it would have
    costs associated with maintaining updated user space accessible time
    offsets.  These offsets have to be updated everytime the a thread is
    scheduled/descheduled.  However, for programs regularly checking the
    running time of a thread, this is a performance improvement.
    
    This patch takes a middle ground, and adds support for cap_user_time an
    optional feature of the perf_event API.  This way costs are only
    incurred when the perf_event api is enabled.  This is done the same way
    as it is in x86.
    
    Ultimately this allows calculating the thread running time in userspace
    on aarch64 as follows (adapted from perf_event_open manpage):
    
    u32 seq, time_mult, time_shift;
    u64 running, count, time_offset, quot, rem, delta;
    struct perf_event_mmap_page *pc;
    pc = buf;  // buf is the perf event mmaped page as documented in the API.
    
    if (pc->cap_usr_time) {
        do {
            seq = pc->lock;
            barrier();
            running = pc->time_running;
    
            count = readCNTVCT_EL0();  // Read ARM hardware clock.
            time_offset = pc->time_offset;
            time_mult   = pc->time_mult;
            time_shift  = pc->time_shift;
    
            barrier();
        } while (pc->lock != seq);
    
        quot = (count >> time_shift);
        rem = count & (((u64)1 << time_shift) - 1);
        delta = time_offset + quot * time_mult +
                ((rem * time_mult) >> time_shift);
    
        running += delta;
        // running now has the current nanosecond level thread time.
    }
    
    Summary of changes in the patch:
    
    For aarch64 systems, make arch_perf_update_userpage update the timing
    information stored in the perf_event page.  Requiring the following
    calculations:
      - Calculate the appropriate time_mult, and time_shift factors to convert
        ticks to nano seconds for the current clock frequency.
      - Adjust the mult and shift factors to avoid shift factors of 32 bits.
        (possibly unnecessary)
      - The time_offset userspace should apply when doing calculations:
        negative the current sched time (now), because time_running and
        time_enabled fields of the perf_event page have just been updated.
    Toggle bits to appropriate values:
      - Enable cap_user_time
    
    Signed-off-by: Michael O'Farrell <micpof@gmail.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

commit fad76d4333fe73cf3f73704aa34d4ce523b1c458
Author: Seeteena Thoufeek <s1seetee@linux.vnet.ibm.com>
Date:   Fri Jun 8 16:32:28 2018 +0530

    perf script: Show hw-cache events
    
    'perf script' fails to report hardware cache events (PERF_TYPE_HW_CACHE)
    where as 'perf report' shows the samples. Fix it. Ex,
    
      # perf record -e L1-dcache-loads ./a.out
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 0.008 MB perf.data (11 samples)]
    
    Before patch:
    
      # perf script | wc -l
      0
    
    After patch:
    
      # perf script | wc -l
      11
    
    Committer testing:
    
      [root@jouet ~]# perf script | head -30 | tail
            Timer 9803 [2] 8.963330:  1554 L1-dcache-loads: 7ffef89baae4 __vdso_clock_gettime+0xf4 ([vdso])
          swapper    0 [2] 8.963343:  5626 L1-dcache-loads: ffffffffa66f4f6b cpuidle_not_av+0xb (/lib/modules/4.17.0-rc5/build/vmlinux)
          firefox 4853 [2] 8.964070: 18935 L1-dcache-loads: 7f0b9a00dc30 xcb_poll_for_event+0x0 (/usr/lib64/libxcb.so.1.1.0)
      Softwar~cTh 4928 [2] 8.964548: 15928 L1-dcache-loads: ffffffffa60d795c update_curr+0x10c (/lib/modules/4.17.0-rc5/build/vmlinux)
          firefox 4853 [2] 8.964675: 14978 L1-dcache-loads: ffffffffa6897018 mutex_unlock+0x18 (/lib/modules/4.17.0-rc5/build/vmlinux)
      gnome-shell 2026 [3] 8.964693: 50670 L1-dcache-loads: 7fa08854de6d g_source_iter_next+0x6d (/usr/lib64/libglib-2.0.so.0.5400.3)
       Compositor 4929 [1] 8.964784: 71772 L1-dcache-loads: 7f0b936bf078 [unknown] (/usr/lib64/firefox/libxul.so)
         Xwayland 2096 [2] 8.964919: 16799 L1-dcache-loads: 7f68ce2fcb8a glXGetCurrentContext+0x1a (/usr/lib64/libGLX.so.0.0.0)
      gnome-shell 2026 [3] 8.964997: 50670 L1-dcache-loads: 7fa08854de6d g_source_iter_next+0x6d (/usr/lib64/libglib-2.0.so.0.5400.3)
      [root@jouet ~]#
    
    Signed-off-by: Seeteena Thoufeek <s1seetee@linux.vnet.ibm.com>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1528455748-20087-1-git-send-email-s1seetee@linux.vnet.ibm.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 09f7ebaa436c9bdad4a21c24fed5057604e709c1
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 8 16:44:21 2017 -0700

    time: Fix CLOCK_MONOTONIC_RAW sub-nanosecond accounting
    
    commit 3d88d56c5873f6eebe23e05c3da701960146b801 upstream.
    
    Due to how the MONOTONIC_RAW accumulation logic was handled,
    there is the potential for a 1ns discontinuity when we do
    accumulations. This small discontinuity has for the most part
    gone un-noticed, but since ARM64 enabled CLOCK_MONOTONIC_RAW
    in their vDSO clock_gettime implementation, we've seen failures
    with the inconsistency-check test in kselftest.
    
    This patch addresses the issue by using the same sub-ns
    accumulation handling that CLOCK_MONOTONIC uses, which avoids
    the issue for in-kernel users.
    
    Since the ARM64 vDSO implementation has its own clock_gettime
    calculation logic, this patch reduces the frequency of errors,
    but failures are still seen. The ARM64 vDSO will need to be
    updated to include the sub-nanosecond xtime_nsec values in its
    calculation for this issue to be completely fixed.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: "stable #4 . 8+" <stable@vger.kernel.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-3-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    [fabrizio: cherry-pick to 4.4. Kept cycle_t type for function
    logarithmic_accumulation local variable "interval". Dropped
    casting of "interval" variable]
    Signed-off-by: Fabrizio Castro <fabrizio.castro@bp.renesas.com>
    Signed-off-by: Biju Das <biju.das@bp.renesas.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d066b246d482f69553e58d52f746377ce3966b66
Author: Russell King <rmk+kernel@armlinux.org.uk>
Date:   Tue Feb 20 10:22:22 2018 +0100

    drm/etnaviv: correct timeout calculation
    
    The old way did clamp the jiffy conversion and thus caused the timeouts
    to become negative after some time. Also it didn't work with userspace
    which actually fills the upper 32bits of the 64bit timestamp value.
    
    clock_gettime() is 32-bit on 32-bit architectures. Using 64-bit timespec
    math, like we do in this commit, means that when a wrap occurs, the
    specified timeout goes into the past and we can't request a timeout in
    the future. As the Linux implementation of CLOCK_MONOTONIC is reasonable
    and starts at 0, the first such timer wrap will occur after approx. 68
    years of system uptime.
    
    Signed-off-by: Russell King <rmk+kernel@armlinux.org.uk>
    Signed-off-by: Lucas Stach <l.stach@pengutronix.de>

commit 1cfd904f16740df21b2df7b41c7a0dc00cbd434c
Merge: 87ef12027b9b 01909974b410
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Apr 19 16:27:44 2018 +0200

    Merge tag 'y2038-timekeeping' of git://git.kernel.org/pub/scm/linux/kernel/git/arnd/playground into timers/core
    
    Pull y2038 timekeeping syscall changes from Arnd Bergmann:
    
    This is the first set of system call entry point changes to enable 32-bit
    architectures to have variants on both 32-bit and 64-bit time_t. Typically
    these system calls take a 'struct timespec' argument, but that structure
    is defined in user space by the C library and its layout will change.
    
    The kernel already supports handling the 32-bit time_t on 64-bit
    architectures through the CONFIG_COMPAT mechanism. As there are a total
    of 51 system calls suffering from this problem, reusing that mechanism
    on 32-bit architectures.
    
    We already have patches for most of the remaining system calls, but this
    set contains most of the complexity and is best tested.  There was one
    last-minute regression that prevented it from going into 4.17, but that
    is fixed now.
    
    More details from Deepa's patch series description:
    
       Big picture is as per the lwn article:
       https://lwn.net/Articles/643234/ [2]
    
       The series is directed at converting posix clock syscalls:
       clock_gettime, clock_settime, clock_getres and clock_nanosleep
       to use a new data structure __kernel_timespec at syscall boundaries.
       __kernel_timespec maintains 64 bit time_t across all execution modes.
    
       vdso will be handled as part of each architecture when they enable
       support for 64 bit time_t.
    
       The compat syscalls are repurposed to provide backward compatibility
       by using them as native syscalls as well for 32 bit architectures.
       They will continue to use timespec at syscall boundaries.
    
       CONFIG_64_BIT_TIME controls whether the syscalls use __kernel_timespec
       or timespec at syscall boundaries.
    
       The series does the following:
       1. Enable compat syscalls on 32 bit architectures.
       2. Add a new __kernel_timespec type to be used as the data structure
          for all the new syscalls.
       3. Add new config CONFIG_64BIT_TIME(intead of the CONFIG_COMPAT_TIME in
          [1] and [2] to switch to new definition of __kernel_timespec. It is
          the same as struct timespec otherwise.
       4. Add new CONFIG_32BIT_TIME to conditionally compile compat syscalls.

commit 6d5b84132459c644cf4ee8de090382bad44b8ebd
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Tue Mar 13 21:03:32 2018 -0700

    time: Change types to new y2038 safe __kernel_* types
    
    Change over clock_settime, clock_gettime and clock_getres
    syscalls to use __kernel_timespec times. This will enable
    changing over of these syscalls to use new y2038 safe syscalls
    when the architectures define the CONFIG_64BIT_TIME.
    
    Cc: linux-api@vger.kernel.org
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

commit b5793b0d92c95cdd5b7bd9bcb6d9307a217e0de7
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Tue Mar 13 21:03:29 2018 -0700

    posix-timers: Make compat syscalls depend on CONFIG_COMPAT_32BIT_TIME
    
    clock_gettime, clock_settime, clock_getres and clock_nanosleep
    compat syscalls are also repurposed to provide backward compatibility
    to support 32 bit time_t on 32 bit systems.
    
    Note that nanosleep compat syscall will also be treated the same way
    as the above syscalls as it shares common handler functions with
    clock_nanosleep. But, there is no plan to provide y2038 safe solution
    for nanosleep.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>

commit 72199320d49dbafa1a99f94f1cd60dc90035c154
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Mar 1 17:33:32 2018 +0100

    timekeeping: Add the new CLOCK_MONOTONIC_ACTIVE clock
    
    The planned change to unify the behaviour of the MONOTONIC and BOOTTIME
    clocks vs. suspend removes the ability to retrieve the active
    non-suspended time of a system.
    
    Provide a new CLOCK_MONOTONIC_ACTIVE clock which returns the active
    non-suspended time of the system via clock_gettime().
    
    This preserves the old behaviour of CLOCK_MONOTONIC before the
    BOOTTIME/MONOTONIC unification.
    
    This new clock also allows applications to detect programmatically that
    the MONOTONIC and BOOTTIME clocks are identical.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Dmitry Torokhov <dmitry.torokhov@gmail.com>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Kevin Easton <kevin@guarana.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Salyzyn <salyzyn@android.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Link: http://lkml.kernel.org/r/20180301165149.965235774@linutronix.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 99478423f5dc9ac3eb8525255ca2dfd74af329ef
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Dec 10 19:20:19 2015 -0800

    x86, vdso, pvclock: Simplify and speed up the vdso pvclock reader
    
    commit 6b078f5de7fc0851af4102493c7b5bb07e49c4cb upstream.
    
    The pvclock vdso code was too abstracted to understand easily
    and excessively paranoid.  Simplify it for a huge speedup.
    
    This opens the door for additional simplifications, as the vdso
    no longer accesses the pvti for any vcpu other than vcpu 0.
    
    Before, vclock_gettime using kvm-clock took about 45ns on my
    machine. With this change, it takes 29ns, which is almost as
    fast as the pure TSC implementation.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/6b51dcc41f1b101f963945c5ec7093d72bdac429.1449702533.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    [bwh: Backported to 3.16:
     - Open-code rdtsc_ordered()
     - Adjust filename]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 64e239804e21901f1a171681269460878bb5f198
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Dec 10 19:20:19 2015 -0800

    x86, vdso, pvclock: Simplify and speed up the vdso pvclock reader
    
    commit 6b078f5de7fc0851af4102493c7b5bb07e49c4cb upstream.
    
    The pvclock vdso code was too abstracted to understand easily
    and excessively paranoid.  Simplify it for a huge speedup.
    
    This opens the door for additional simplifications, as the vdso
    no longer accesses the pvti for any vcpu other than vcpu 0.
    
    Before, vclock_gettime using kvm-clock took about 45ns on my
    machine. With this change, it takes 29ns, which is almost as
    fast as the pure TSC implementation.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/6b51dcc41f1b101f963945c5ec7093d72bdac429.1449702533.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Cc: Jamie Iles <jamie.iles@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 19c832ed9b8f7b49fa5eeef06b4338af5fe5c1dc
Author: David Miller <davem@davemloft.net>
Date:   Tue Dec 19 15:22:03 2017 -0500

    bpf: Fix tools and testing build.
    
    I'm getting various build failures on sparc64.  The key is
    usually that the userland tools get built 32-bit.
    
    1) clock_gettime() is in librt, so that must be added to the link
       libraries.
    
    2) "sizeof(x)" must be printed with "%Z" printf prefix.
    
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

commit 88edb57d1e0b262e669c5cad36646dcf5a7f37f5
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Mon Dec 4 16:01:55 2017 +0100

    x86/vdso: Change time() prototype to match __vdso_time()
    
    gcc-8 warns that time() is an alias for __vdso_time() but the two
    have different prototypes:
    
      arch/x86/entry/vdso/vclock_gettime.c:327:5: error: 'time' alias between functions of incompatible types 'int(time_t *)' {aka 'int(long int *)'} and 'time_t(time_t *)' {aka 'long int(long int *)'} [-Werror=attribute-alias]
       int time(time_t *t)
           ^~~~
      arch/x86/entry/vdso/vclock_gettime.c:318:16: note: aliased declaration here
    
    I could not figure out whether this is intentional, but I see that
    changing it to return time_t avoids the warning.
    
    Returning 'int' from time() is also a bit questionable, as it causes an
    overflow in y2038 even on 64-bit architectures that use a 64-bit time_t
    type. On 32-bit architecture with 64-bit time_t, time() should always
    be implement by the C library by calling a (to be added) clock_gettime()
    variant that takes a sufficiently wide argument.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Link: http://lkml.kernel.org/r/20171204150203.852959-1-arnd@arndb.de
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 9a08862a5d2e266ecea1865547463da2745fc687
Author: Nagarathnam Muthusamy <nagarathnam.muthusamy@oracle.com>
Date:   Thu Sep 21 11:05:31 2017 -0400

    vDSO for sparc
    
    Following patch is based on work done by Nick Alcock on 64-bit vDSO for sparc
    in Oracle linux. I have extended it to include support for 32-bit vDSO for sparc
    on 64-bit kernel.
    
    vDSO for sparc is based on the X86 implementation. This patch
    provides vDSO support for both 64-bit and 32-bit programs on 64-bit kernel.
    vDSO will be disabled on 32-bit linux kernel on sparc.
    
    *) vclock_gettime.c contains all the vdso functions. Since data page is mapped
       before the vdso code page, the pointer to data page is got by subracting offset
       from an address in the vdso code page. The return address stored in
       %i7 is used for this purpose.
    *) During compilation, both 32-bit and 64-bit vdso images are compiled and are
       converted into raw bytes by vdso2c program to be ready for mapping into the
       process. 32-bit images are compiled only if CONFIG_COMPAT is enabled. vdso2c
       generates two files vdso-image-64.c and vdso-image-32.c which contains the
       respective vDSO image in C structure.
    *) During vdso initialization, required number of vdso pages are allocated and
       raw bytes are copied into the pages.
    *) During every exec, these pages are mapped into the process through
       arch_setup_additional_pages and the location of mapping is passed on to the
       process through aux vector AT_SYSINFO_EHDR which is used by glibc.
    *) A new update_vsyscall routine for sparc is added to keep the data page in
       vdso updated.
    *) As vDSO cannot contain dynamically relocatable references, a new version of
       cpu_relax is added for the use of vDSO.
    
    This change also requires a putback to glibc to use vDSO. For testing,
    programs planning to try vDSO can be compiled against the generated
    vdso(64/32).so in the source.
    
    Testing:
    
    ========
    [root@localhost ~]# cat vdso_test.c
    int main() {
            struct timespec tv_start, tv_end;
            struct timeval tv_tmp;
            int i;
            int count = 1 * 1000 * 10000;
            long long diff;
    
            clock_gettime(0, &tv_start);
            for (i = 0; i < count; i++)
                  gettimeofday(&tv_tmp, NULL);
            clock_gettime(0, &tv_end);
            diff = (long long)(tv_end.tv_sec -
                    tv_start.tv_sec)*(1*1000*1000*1000);
            diff += (tv_end.tv_nsec - tv_start.tv_nsec);
            printf("Start sec: %d\n", tv_start.tv_sec);
            printf("End sec  : %d\n", tv_end.tv_sec);
            printf("%d cycles in %lld ns = %f ns/cycle\n", count, diff,
                    (double)diff / (double)count);
            return 0;
    }
    
    [root@localhost ~]# cc vdso_test.c -o t32_without_fix -m32 -lrt
    [root@localhost ~]# ./t32_without_fix
    Start sec: 1502396130
    End sec  : 1502396140
    10000000 cycles in 9565148528 ns = 956.514853 ns/cycle
    [root@localhost ~]# cc vdso_test.c -o t32_with_fix -m32 ./vdso32.so.dbg
    [root@localhost ~]# ./t32_with_fix
    Start sec: 1502396168
    End sec  : 1502396169
    10000000 cycles in 798141262 ns = 79.814126 ns/cycle
    [root@localhost ~]# cc vdso_test.c -o t64_without_fix -m64 -lrt
    [root@localhost ~]# ./t64_without_fix
    Start sec: 1502396208
    End sec  : 1502396218
    10000000 cycles in 9846091800 ns = 984.609180 ns/cycle
    [root@localhost ~]# cc vdso_test.c -o t64_with_fix -m64 ./vdso64.so.dbg
    [root@localhost ~]# ./t64_with_fix
    Start sec: 1502396257
    End sec  : 1502396257
    10000000 cycles in 380984048 ns = 38.098405 ns/cycle
    
    V1 to V2 Changes:
    =================
            Added hot patching code to switch the read stick instruction to read
    tick instruction based on the hardware.
    
    V2 to V3 Changes:
    =================
            Merged latest changes from sparc-next and moved the initialization
    of clocksource_tick.archdata.vclock_mode to time_init_early. Disabled
    queued spinlock and rwlock configuration when simulating 32-bit config
    to compile 32-bit VDSO.
    
    V3 to V4 Changes:
    =================
            Hardcoded the page size as 8192 in linker script for both 64-bit and
    32-bit binaries. Removed unused variables in vdso2c.h. Added -mv8plus flag to
    Makefile to prevent the generation of relocation entries for __lshrdi3 in 32-bit
    vdso binary.
    
    Signed-off-by: Nick Alcock <nick.alcock@oracle.com>
    Signed-off-by: Nagarathnam Muthusamy <nagarathnam.muthusamy@oracle.com>
    Reviewed-by: Shannon Nelson <shannon.nelson@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 0aaba41b58bc5f3074c0c0a6136b9500b5e29e19
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Aug 22 12:08:22 2017 +0200

    s390: remove all code using the access register mode
    
    The vdso code for the getcpu() and the clock_gettime() call use the access
    register mode to access the per-CPU vdso data page with the current code.
    
    An alternative to the complicated AR mode is to use the secondary space
    mode. This makes the vdso faster and quite a bit simpler. The downside is
    that the uaccess code has to be changed quite a bit.
    
    Which instructions are used depends on the machine and what kind of uaccess
    operation is requested. The instruction dictates which ASCE value needs
    to be loaded into %cr1 and %cr7.
    
    The different cases:
    
    * User copy with MVCOS for z10 and newer machines
      The MVCOS instruction can copy between the primary space (aka user) and
      the home space (aka kernel) directly. For set_fs(KERNEL_DS) the kernel
      ASCE is loaded into %cr1. For set_fs(USER_DS) the user space is already
      loaded in %cr1.
    
    * User copy with MVCP/MVCS for older machines
      To be able to execute the MVCP/MVCS instructions the kernel needs to
      switch to primary mode. The control register %cr1 has to be set to the
      kernel ASCE and %cr7 to either the kernel ASCE or the user ASCE dependent
      on set_fs(KERNEL_DS) vs set_fs(USER_DS).
    
    * Data access in the user address space for strnlen / futex
      To use "normal" instruction with data from the user address space the
      secondary space mode is used. The kernel needs to switch to primary mode,
      %cr1 has to contain the kernel ASCE and %cr7 either the user ASCE or the
      kernel ASCE, dependent on set_fs.
    
    To load a new value into %cr1 or %cr7 is an expensive operation, the kernel
    tries to be lazy about it. E.g. for multiple user copies in a row with
    MVCP/MVCS the replacement of the vdso ASCE in %cr7 with the user ASCE is
    done only once. On return to user space a CPU bit is checked that loads the
    vdso ASCE again.
    
    To enable and disable the data access via the secondary space two new
    functions are added, enable_sacf_uaccess and disable_sacf_uaccess. The fact
    that a context is in secondary space uaccess mode is stored in the
    mm_segment_t value for the task. The code of an interrupt may use set_fs
    as long as it returns to the previous state it got with get_fs with another
    call to set_fs. The code in finish_arch_post_lock_switch simply has to do a
    set_fs with the current mm_segment_t value for the task.
    
    For CPUs with MVCOS:
    
    CPU running in                        | %cr1 ASCE | %cr7 ASCE |
    --------------------------------------|-----------|-----------|
    user space                            |  user     |  vdso     |
    kernel, USER_DS, normal-mode          |  user     |  vdso     |
    kernel, USER_DS, normal-mode, lazy    |  user     |  user     |
    kernel, USER_DS, sacf-mode            |  kernel   |  user     |
    kernel, KERNEL_DS, normal-mode        |  kernel   |  vdso     |
    kernel, KERNEL_DS, normal-mode, lazy  |  kernel   |  kernel   |
    kernel, KERNEL_DS, sacf-mode          |  kernel   |  kernel   |
    
    For CPUs without MVCOS:
    
    CPU running in                        | %cr1 ASCE | %cr7 ASCE |
    --------------------------------------|-----------|-----------|
    user space                            |  user     |  vdso     |
    kernel, USER_DS, normal-mode          |  user     |  vdso     |
    kernel, USER_DS, normal-mode lazy     |  kernel   |  user     |
    kernel, USER_DS, sacf-mode            |  kernel   |  user     |
    kernel, KERNEL_DS, normal-mode        |  kernel   |  vdso     |
    kernel, KERNEL_DS, normal-mode, lazy  |  kernel   |  kernel   |
    kernel, KERNEL_DS, sacf-mode          |  kernel   |  kernel   |
    
    The lines with "lazy" refer to the state after a copy via the secondary
    space with a delayed reload of %cr1 and %cr7.
    
    There are three hardware address spaces that can cause a DAT exception,
    primary, secondary and home space. The exception can be related to
    four different fault types: user space fault, vdso fault, kernel fault,
    and the gmap faults.
    
    Dependent on the set_fs state and normal vs. sacf mode there are a number
    of fault combinations:
    
    1) user address space fault via the primary ASCE
    2) gmap address space fault via the primary ASCE
    3) kernel address space fault via the primary ASCE for machines with
       MVCOS and set_fs(KERNEL_DS)
    4) vdso address space faults via the secondary ASCE with an invalid
       address while running in secondary space in problem state
    5) user address space fault via the secondary ASCE for user-copy
       based on the secondary space mode, e.g. futex_ops or strnlen_user
    6) kernel address space fault via the secondary ASCE for user-copy
       with secondary space mode with set_fs(KERNEL_DS)
    7) kernel address space fault via the primary ASCE for user-copy
       with secondary space mode with set_fs(USER_DS) on machines without
       MVCOS.
    8) kernel address space fault via the home space ASCE
    
    Replace user_space_fault() with a new function get_fault_type() that
    can distinguish all four different fault types.
    
    With these changes the futex atomic ops from the kernel and the
    strnlen_user will get a little bit slower, as well as the old style
    uaccess with MVCP/MVCS. All user accesses based on MVCOS will be as
    fast as before. On the positive side, the user space vdso code is a
    lot faster and Linux ceases to use the complicated AR mode.
    
    Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>

commit 6fae8663c9940bcaa9edd8e21a9ae0f562789a3d
Author: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
Date:   Wed Aug 2 20:12:16 2017 +0530

    perf scripting python: Add ppc64le to audit uname list
    
    Before patch:
    
      $ uname -m
      ppc64le
      $ ./perf script -s ./scripts/python/syscall-counts.py
      Install the audit-libs-python package to get syscall names.
      For example:
        # apt-get install python-audit (Ubuntu)
        # yum install audit-libs-python (Fedora)
        etc.
    
      Press control+C to stop and show the summary
      ^CWarning:
      4 out of order events recorded.
    
      syscall events:
    
      event                                          count
      ----------------------------------------  -----------
      4                                             504638
      54                                              1206
      221                                               42
      55                                                21
      3                                                 12
      167                                               10
      11                                                 8
      6                                                  7
      125                                                6
      5                                                  6
      108                                                5
      162                                                4
      90                                                 4
      45                                                 3
      33                                                 3
      311                                                1
      246                                                1
      238                                                1
      93                                                 1
      91                                                 1
    
    After patch:
      ./perf script -s ./scripts/python/syscall-counts.py
      Press control+C to stop and show the summary
      ^CWarning:
      5 out of order events recorded.
    
      syscall events:
    
      event                                          count
      ----------------------------------------  -----------
      write                                         643411
      ioctl                                           1206
      futex                                             54
      fcntl                                             27
      poll                                              14
      read                                              12
      execve                                             8
      close                                              7
      mprotect                                           6
      open                                               6
      nanosleep                                          5
      fstat                                              5
      mmap                                               4
      inotify_add_watch                                  3
      brk                                                3
      access                                             3
      timerfd_settime                                    1
      clock_gettime                                      1
      epoll_wait                                         1
      ftruncate                                          1
      munmap                                             1
    
    Signed-off-by: Naveen N. Rao <naveen.n.rao@linux.vnet.ibm.com>
    Acked-by: Paul Clarke <pc@us.ibm.com>
    Cc: linuxppc-dev@lists.ozlabs.org
    Link: http://lkml.kernel.org/n/tip-bnl67p1alkvx97pn9moxz3qp@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 568d135d337d3114688fef9fdbce7fb6dbbd04c7
Merge: 4ecd4ff55ac5 d40e0d4fb561
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Jul 15 10:59:54 2017 -0700

    Merge branch 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus
    
    Pull MIPS updates from Ralf Baechle:
     "Boston platform support:
       - Document DT bindings
       - Add CLK driver for board clocks
    
      CM:
       - Avoid per-core locking with CM3 & higher
       - WARN on attempt to lock invalid VP, not BUG
    
      CPS:
       - Select CONFIG_SYS_SUPPORTS_SCHED_SMT for MIPSr6
       - Prevent multi-core with dcache aliasing
       - Handle cores not powering down more gracefully
       - Handle spurious VP starts more gracefully
    
      DSP:
       - Add lwx & lhx missaligned access support
    
      eBPF:
       - Add MIPS support along with many supporting change to add the
         required infrastructure
    
      Generic arch code:
       - Misc sysmips MIPS_ATOMIC_SET fixes
       - Drop duplicate HAVE_SYSCALL_TRACEPOINTS
       - Negate error syscall return in trace
       - Correct forced syscall errors
       - Traced negative syscalls should return -ENOSYS
       - Allow samples/bpf/tracex5 to access syscall arguments for sane
         traces
       - Cleanup from old Kconfig options in defconfigs
       - Fix PREF instruction usage by memcpy for MIPS R6
       - Fix various special cases in the FPU eulation
       - Fix some special cases in MIPS16e2 support
       - Fix MIPS I ISA /proc/cpuinfo reporting
       - Sort MIPS Kconfig alphabetically
       - Fix minimum alignment requirement of IRQ stack as required by
         ABI / GCC
       - Fix special cases in the module loader
       - Perform post-DMA cache flushes on systems with MAARs
       - Probe the I6500 CPU
       - Cleanup cmpxchg and add support for 1 and 2 byte operations
       - Use queued read/write locks (qrwlock)
       - Use queued spinlocks (qspinlock)
       - Add CPU shared FTLB feature detection
       - Handle tlbex-tlbp race condition
       - Allow storing pgd in C0_CONTEXT for MIPSr6
       - Use current_cpu_type() in m4kc_tlbp_war()
       - Support Boston in the generic kernel
    
      Generic platform:
       - yamon-dt: Pull YAMON DT shim code out of SEAD-3 board
       - yamon-dt: Support > 256MB of RAM
       - yamon-dt: Use serial* rather than uart* aliases
       - Abstract FDT fixup application
       - Set RTC_ALWAYS_BCD to 0
       - Add a MAINTAINERS entry
    
      core kernel:
       - qspinlock.c: include linux/prefetch.h
    
      Loongson 3:
       - Add support
    
      Perf:
       - Add I6500 support
    
      SEAD-3:
       - Remove GIC timer from DT
       - Set interrupt-parent per-device, not at root node
       - Fix GIC interrupt specifiers
    
      SMP:
       - Skip IPI setup if we only have a single CPU
    
      VDSO:
       - Make comment match reality
       - Improvements to time code in VDSO"
    
    * 'upstream' of git://git.linux-mips.org/pub/scm/ralf/upstream-linus: (86 commits)
      locking/qspinlock: Include linux/prefetch.h
      MIPS: Fix MIPS I ISA /proc/cpuinfo reporting
      MIPS: Fix minimum alignment requirement of IRQ stack
      MIPS: generic: Support MIPS Boston development boards
      MIPS: DTS: img: Don't attempt to build-in all .dtb files
      clk: boston: Add a driver for MIPS Boston board clocks
      dt-bindings: Document img,boston-clock binding
      MIPS: Traced negative syscalls should return -ENOSYS
      MIPS: Correct forced syscall errors
      MIPS: Negate error syscall return in trace
      MIPS: Drop duplicate HAVE_SYSCALL_TRACEPOINTS select
      MIPS16e2: Provide feature overrides for non-MIPS16 systems
      MIPS: MIPS16e2: Report ASE presence in /proc/cpuinfo
      MIPS: MIPS16e2: Subdecode extended LWSP/SWSP instructions
      MIPS: MIPS16e2: Identify ASE presence
      MIPS: VDSO: Fix a mismatch between comment and preprocessor constant
      MIPS: VDSO: Add implementation of gettimeofday() fallback
      MIPS: VDSO: Add implementation of clock_gettime() fallback
      MIPS: VDSO: Fix conversions in do_monotonic()/do_monotonic_coarse()
      MIPS: Use current_cpu_type() in m4kc_tlbp_war()
      ...

commit 5c4994102fb508d4a0f7a8afa46560c314c1ebd4
Author: Deepa Dinamani <deepa.kernel@gmail.com>
Date:   Sat Jun 24 11:45:05 2017 -0700

    posix-timers: Use get_timespec64() and put_timespec64()
    
    Usage of these apis and their compat versions makes
    the syscalls: clock_gettime, clock_settime, clock_getres
    and their compat implementations simpler.
    
    This is a preparatory patch to isolate data conversions to
    struct timespec64 at userspace boundaries. This helps contain
    the changes needed to transition to new y2038 safe types.
    
    Signed-off-by: Deepa Dinamani <deepa.kernel@gmail.com>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 830146b6390a8f2cedbc7dc5e78331987c0418fa
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jun 8 16:44:22 2017 -0700

    arm64/vdso: Fix nsec handling for CLOCK_MONOTONIC_RAW
    
    commit dbb236c1ceb697a559e0694ac4c9e7b9131d0b16 upstream.
    
    Recently vDSO support for CLOCK_MONOTONIC_RAW was added in
    49eea433b326 ("arm64: Add support for CLOCK_MONOTONIC_RAW in
    clock_gettime() vDSO"). Noticing that the core timekeeping code
    never set tkr_raw.xtime_nsec, the vDSO implementation didn't
    bother exposing it via the data page and instead took the
    unshifted tk->raw_time.tv_nsec value which was then immediately
    shifted left in the vDSO code.
    
    Unfortunately, by accellerating the MONOTONIC_RAW clockid, it
    uncovered potential 1ns time inconsistencies caused by the
    timekeeping core not handing sub-ns resolution.
    
    Now that the core code has been fixed and is actually setting
    tkr_raw.xtime_nsec, we need to take that into account in the
    vDSO by adding it to the shifted raw_time value, in order to
    fix the user-visible inconsistency. Rather than do that at each
    use (and expand the data page in the process), instead perform
    the shift/addition operation when populating the data page and
    remove the shift from the vDSO code entirely.
    
    [jstultz: minor whitespace tweak, tried to improve commit
     message to make it more clear this fixes a regression]
    Reported-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Acked-by: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-4-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 102d12f1567fa3d637bbb2885691fa4aca367f33
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 8 16:44:21 2017 -0700

    time: Fix CLOCK_MONOTONIC_RAW sub-nanosecond accounting
    
    commit 3d88d56c5873f6eebe23e05c3da701960146b801 upstream.
    
    Due to how the MONOTONIC_RAW accumulation logic was handled,
    there is the potential for a 1ns discontinuity when we do
    accumulations. This small discontinuity has for the most part
    gone un-noticed, but since ARM64 enabled CLOCK_MONOTONIC_RAW
    in their vDSO clock_gettime implementation, we've seen failures
    with the inconsistency-check test in kselftest.
    
    This patch addresses the issue by using the same sub-ns
    accumulation handling that CLOCK_MONOTONIC uses, which avoids
    the issue for in-kernel users.
    
    Since the ARM64 vDSO implementation has its own clock_gettime
    calculation logic, this patch reduces the frequency of errors,
    but failures are still seen. The ARM64 vDSO will need to be
    updated to include the sub-nanosecond xtime_nsec values in its
    calculation for this issue to be completely fixed.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-3-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 99f66b5182a4f3d89563634f2fe156d4629b9c10
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jun 8 16:44:22 2017 -0700

    arm64/vdso: Fix nsec handling for CLOCK_MONOTONIC_RAW
    
    commit dbb236c1ceb697a559e0694ac4c9e7b9131d0b16 upstream.
    
    Recently vDSO support for CLOCK_MONOTONIC_RAW was added in
    49eea433b326 ("arm64: Add support for CLOCK_MONOTONIC_RAW in
    clock_gettime() vDSO"). Noticing that the core timekeeping code
    never set tkr_raw.xtime_nsec, the vDSO implementation didn't
    bother exposing it via the data page and instead took the
    unshifted tk->raw_time.tv_nsec value which was then immediately
    shifted left in the vDSO code.
    
    Unfortunately, by accellerating the MONOTONIC_RAW clockid, it
    uncovered potential 1ns time inconsistencies caused by the
    timekeeping core not handing sub-ns resolution.
    
    Now that the core code has been fixed and is actually setting
    tkr_raw.xtime_nsec, we need to take that into account in the
    vDSO by adding it to the shifted raw_time value, in order to
    fix the user-visible inconsistency. Rather than do that at each
    use (and expand the data page in the process), instead perform
    the shift/addition operation when populating the data page and
    remove the shift from the vDSO code entirely.
    
    [jstultz: minor whitespace tweak, tried to improve commit
     message to make it more clear this fixes a regression]
    Reported-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Acked-by: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-4-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a53bfdda06ac114c42796b4193aee10a8108bca1
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 8 16:44:21 2017 -0700

    time: Fix CLOCK_MONOTONIC_RAW sub-nanosecond accounting
    
    commit 3d88d56c5873f6eebe23e05c3da701960146b801 upstream.
    
    Due to how the MONOTONIC_RAW accumulation logic was handled,
    there is the potential for a 1ns discontinuity when we do
    accumulations. This small discontinuity has for the most part
    gone un-noticed, but since ARM64 enabled CLOCK_MONOTONIC_RAW
    in their vDSO clock_gettime implementation, we've seen failures
    with the inconsistency-check test in kselftest.
    
    This patch addresses the issue by using the same sub-ns
    accumulation handling that CLOCK_MONOTONIC uses, which avoids
    the issue for in-kernel users.
    
    Since the ARM64 vDSO implementation has its own clock_gettime
    calculation logic, this patch reduces the frequency of errors,
    but failures are still seen. The ARM64 vDSO will need to be
    updated to include the sub-nanosecond xtime_nsec values in its
    calculation for this issue to be completely fixed.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-3-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 180902e08f051f72c89ffa366f4e4f7a8e9c753e
Author: Goran Ferenc <goran.ferenc@imgtec.com>
Date:   Wed Jun 28 17:55:29 2017 +0200

    MIPS: VDSO: Add implementation of clock_gettime() fallback
    
    This patch adds clock_gettime_fallback() function that wraps assembly
    invocation of clock_gettime() syscall using __NR_clock_gettime.
    
    This function is used if pure VDSO implementation of clock_gettime()
    does not succeed for any reason. For example, it is called if the
    clkid parameter of clock_gettime() is not one of the clkids listed
    in the switch-case block of the function __vdso_clock_gettime()
    (one such case for clkid is CLOCK_BOOTIME).
    
    If syscall invocation via __NR_clock_gettime fails, register a3 will
    be set. So, after the syscall, register a3 is tested and the return
    value is negated if it's set.
    
    Signed-off-by: Goran Ferenc <goran.ferenc@imgtec.com>
    Signed-off-by: Miodrag Dinic <miodrag.dinic@imgtec.com>
    Signed-off-by: Aleksandar Markovic <aleksandar.markovic@imgtec.com>
    Cc: Douglas Leung <douglas.leung@imgtec.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Petar Jovanovic <petar.jovanovic@imgtec.com>
    Cc: Raghu Gandham <raghu.gandham@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/16639/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

commit 8ec7f15b8cca4f790df5cdf33f26e2926d4ee2fd
Author: Goran Ferenc <goran.ferenc@imgtec.com>
Date:   Wed Jun 28 17:55:28 2017 +0200

    MIPS: VDSO: Fix conversions in do_monotonic()/do_monotonic_coarse()
    
    Fix incorrect calculation in do_monotonic() and do_monotonic_coarse()
    function that in turn caused incorrect values returned by the vdso
    version of system call clock_gettime() on mips64 if its system clock
    ID parameter was CLOCK_MONOTONIC or CLOCK_MONOTONIC_COARSE.
    
    Consider these variables and their types on mips32 and mips64:
    
    tk->wall_to_monotonic.tv_sec  s64, s64   (kernel/vdso.c)
    vdso_data.wall_to_mono_sec    u32, u32   (kernel/vdso.c)
    to_mono_sec                   u32, u32   (vdso/gettimeofday.c)
    ts->tv_sec                    s32, s64   (vdso/gettimeofday.c)
    
    For mips64 case, u32 vdso_data.wall_to_mono_sec variable is updated
    from the 64-bit signed variable tk->wall_to_monotonic.tv_sec
    (kernel/vdso.c:76) which is a negative number holding the time passed
    from 1970-01-01 to the time boot started. This 64-bit signed value is
    currently around 47+ years, in seconds. For instance, let this value
    be:
    
    -1489757461
    
    or
    
    11111111111111111111111111111111 10100111001101000001101011101011
    
    By updating 32-bit vdso_data.wall_to_mono_sec variable, we lose upper
    32 bits (signed 1's).
    
    to_mono_sec variable is a parameter of do_monotonic() and
    do_monotonic_coarse() functions which holds vdso_data.wall_to_mono_sec
    value. Its value needs to be added (or subtracted considering it holds
    negative value from the tk->wall_to_monotonic.tv_sec) to the current
    time passed from 1970-01-01 (ts->tv_sec), which is again something like
    47+ years, but increased by the time passed from the boot to the
    current time. ts->tv_sec is 32-bit long in case of 32-bit architecture
    and 64-bit long in case of 64-bit architecture. Consider the update of
    ts->tv_sec (vdso/gettimeofday.c:55 & 167):
    
    ts->tv_sec += to_mono_sec;
    
    mips32 case: This update will be performed correctly, since both
    ts->tv_sec and to_mono_sec are 32-bit long and the sign in to_mono_sec
    is preserved. Implicit conversion from u32 to s32 will be done
    correctly.
    
    mips64 case: This update will be wrong, since the implicit conversion
    will not be done correctly. The reason is that the conversion will be
    from u32 to s64. This is because to_mono_sec is 32-bit long for both
    mips32 and mips64 cases and s64..33 bits of converted to_mono_sec
    variable will be zeros.
    
    So, in order to make MIPS64 implementation work properly for
    MONOTONIC and MONOTONIC_COARSE clock ids on mips64, the size of
    wall_to_mono_sec variable in mips_vdso_data union and respective
    parameters in do_monotonic() and do_monotonic_coarse() functions
    should be changed from u32 to u64. Because of consistency, this
    size change from u32 and u64 is also done for wall_to_mono_nsec
    variable and corresponding function parameters.
    
    As far as similar situations for other architectures are concerned,
    let's take a look at arm. Arm has two distinct vdso_data structures
    for 32-bit & 64-bit cases, and arm's wall_to_mono_sec and
    wall_to_mono_nsec are u32 for 32-bit and u64 for 64-bit cases.
    On the other hand, MIPS has only one structure (mips_vdso_data),
    hence the need for changing the size of above mentioned parameters.
    
    Signed-off-by: Goran Ferenc <goran.ferenc@imgtec.com>
    Signed-off-by: Miodrag Dinic <miodrag.dinic@imgtec.com>
    Signed-off-by: Aleksandar Markovic <aleksandar.markovic@imgtec.com>
    Cc: Douglas Leung <douglas.leung@imgtec.com>
    Cc: James Hogan <james.hogan@imgtec.com>
    Cc: Paul Burton <paul.burton@imgtec.com>
    Cc: Petar Jovanovic <petar.jovanovic@imgtec.com>
    Cc: Raghu Gandham <raghu.gandham@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/16638/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

commit 5f4b37d8784da4217ede8f8bcd301686853dcf8c
Merge: 35d8d5d47c0e 8e6cec1c7c5a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 25 11:59:19 2017 -0700

    Merge branch 'timers-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer fixes from Thomas Gleixner:
     "A few fixes for timekeeping and timers:
    
       - Plug a subtle race due to a missing READ_ONCE() in the timekeeping
         code where reloading of a pointer results in an inconsistent
         callback argument being supplied to the clocksource->read function.
    
       - Correct the CLOCK_MONOTONIC_RAW sub-nanosecond accounting in the
         time keeping core code, to prevent a possible discontuity.
    
       - Apply a similar fix to the arm64 vdso clock_gettime()
         implementation
    
       - Add missing includes to clocksource drivers, which relied on
         indirect includes which fails in certain configs.
    
       - Use the proper iomem pointer for read/iounmap in a probe function"
    
    * 'timers-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      arm64/vdso: Fix nsec handling for CLOCK_MONOTONIC_RAW
      time: Fix CLOCK_MONOTONIC_RAW sub-nanosecond accounting
      time: Fix clock->read(clock) race around clocksource changes
      clocksource: Explicitly include linux/clocksource.h when needed
      clocksource/drivers/arm_arch_timer: Fix read and iounmap of incorrect variable

commit d4cfb11387ee29ba4626546c676fd25c7abbbbb2
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Sat May 27 18:04:52 2017 +1000

    powerpc: Convert VDSO update function to use new update_vsyscall interface
    
    This converts the powerpc VDSO time update function to use the new
    interface introduced in commit 576094b7f0aa ("time: Introduce new
    GENERIC_TIME_VSYSCALL", 2012-09-11).  Where the old interface gave
    us the time as of the last update in seconds and whole nanoseconds,
    with the new interface we get the nanoseconds part effectively in
    a binary fixed-point format with tk->tkr_mono.shift bits to the
    right of the binary point.
    
    With the old interface, the fractional nanoseconds got truncated,
    meaning that the value returned by the VDSO clock_gettime function
    would have about 1ns of jitter in it compared to the value computed
    by the generic timekeeping code in the kernel.
    
    The powerpc VDSO time functions (clock_gettime and gettimeofday)
    already work in units of 2^-32 seconds, or 0.23283 ns, because that
    makes it simple to split the result into seconds and fractional
    seconds, and represent the fractional seconds in either microseconds
    or nanoseconds.  This is good enough accuracy for now, so this patch
    avoids changing how the VDSO works or the interface in the VDSO data
    page.
    
    This patch converts the powerpc update_vsyscall_old to be called
    update_vsyscall and use the new interface.  We convert the fractional
    second to units of 2^-32 seconds without truncating to whole nanoseconds.
    (There is still a conversion to whole nanoseconds for any legacy users
    of the vdso_data/systemcfg stamp_xtime field.)
    
    In addition, this improves the accuracy of the computation of tb_to_xs
    for those systems with high-frequency timebase clocks (>= 268.5 MHz)
    by doing the right shift in two parts, one before the multiplication and
    one after, rather than doing the right shift before the multiplication.
    (We can't do all of the right shift after the multiplication unless we
    use 128-bit arithmetic.)
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>

commit dbb236c1ceb697a559e0694ac4c9e7b9131d0b16
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Jun 8 16:44:22 2017 -0700

    arm64/vdso: Fix nsec handling for CLOCK_MONOTONIC_RAW
    
    Recently vDSO support for CLOCK_MONOTONIC_RAW was added in
    49eea433b326 ("arm64: Add support for CLOCK_MONOTONIC_RAW in
    clock_gettime() vDSO"). Noticing that the core timekeeping code
    never set tkr_raw.xtime_nsec, the vDSO implementation didn't
    bother exposing it via the data page and instead took the
    unshifted tk->raw_time.tv_nsec value which was then immediately
    shifted left in the vDSO code.
    
    Unfortunately, by accellerating the MONOTONIC_RAW clockid, it
    uncovered potential 1ns time inconsistencies caused by the
    timekeeping core not handing sub-ns resolution.
    
    Now that the core code has been fixed and is actually setting
    tkr_raw.xtime_nsec, we need to take that into account in the
    vDSO by adding it to the shifted raw_time value, in order to
    fix the user-visible inconsistency. Rather than do that at each
    use (and expand the data page in the process), instead perform
    the shift/addition operation when populating the data page and
    remove the shift from the vDSO code entirely.
    
    [jstultz: minor whitespace tweak, tried to improve commit
     message to make it more clear this fixes a regression]
    Reported-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Acked-by: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: "stable #4 . 8+" <stable@vger.kernel.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-4-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 3d88d56c5873f6eebe23e05c3da701960146b801
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 8 16:44:21 2017 -0700

    time: Fix CLOCK_MONOTONIC_RAW sub-nanosecond accounting
    
    Due to how the MONOTONIC_RAW accumulation logic was handled,
    there is the potential for a 1ns discontinuity when we do
    accumulations. This small discontinuity has for the most part
    gone un-noticed, but since ARM64 enabled CLOCK_MONOTONIC_RAW
    in their vDSO clock_gettime implementation, we've seen failures
    with the inconsistency-check test in kselftest.
    
    This patch addresses the issue by using the same sub-ns
    accumulation handling that CLOCK_MONOTONIC uses, which avoids
    the issue for in-kernel users.
    
    Since the ARM64 vDSO implementation has its own clock_gettime
    calculation logic, this patch reduces the frequency of errors,
    but failures are still seen. The ARM64 vDSO will need to be
    updated to include the sub-nanosecond xtime_nsec values in its
    calculation for this issue to be completely fixed.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Tested-by: Daniel Mentz <danielmentz@google.com>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Kevin Brodsky <kevin.brodsky@arm.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Stephen Boyd <stephen.boyd@linaro.org>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: "stable #4 . 8+" <stable@vger.kernel.org>
    Cc: Miroslav Lichvar <mlichvar@redhat.com>
    Link: http://lkml.kernel.org/r/1496965462-20003-3-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit d822cdcce43f9d4dcddbf9c68f9537d542ccc3c3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jun 7 09:42:38 2017 +0100

    posix-timers: Move compat versions of clock_gettime/settime/getres
    
    Move them to the native implementations and get rid of the set_fs() hackery.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Stultz <john.stultz@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20170607084241.28657-13-viro@ZenIV.linux.org.uk

commit baa73d9e478ff32d62f3f9422822b59dd9a95a21
Author: Nicolas Pitre <nicolas.pitre@linaro.org>
Date:   Fri Nov 11 00:10:10 2016 -0500

    posix-timers: Make them configurable
    
    Some embedded systems have no use for them.  This removes about
    25KB from the kernel binary size when configured out.
    
    Corresponding syscalls are routed to a stub logging the attempt to
    use those syscalls which should be enough of a clue if they were
    disabled without proper consideration. They are: timer_create,
    timer_gettime: timer_getoverrun, timer_settime, timer_delete,
    clock_adjtime, setitimer, getitimer, alarm.
    
    The clock_settime, clock_gettime, clock_getres and clock_nanosleep
    syscalls are replaced by simple wrappers compatible with CLOCK_REALTIME,
    CLOCK_MONOTONIC and CLOCK_BOOTTIME only which should cover the vast
    majority of use cases with very little code.
    
    Signed-off-by: Nicolas Pitre <nico@linaro.org>
    Acked-by: Richard Cochran <richardcochran@gmail.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: John Stultz <john.stultz@linaro.org>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Cc: Paul Bolle <pebolle@tiscali.nl>
    Cc: linux-kbuild@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Cc: Michal Marek <mmarek@suse.com>
    Cc: Edward Cree <ecree@solarflare.com>
    Link: http://lkml.kernel.org/r/1478841010-28605-7-git-send-email-nicolas.pitre@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 39b6b9005f6cd2ef2f6c554bb2da176ca87aab0d
Author: Mauro Carvalho Chehab <mchehab@kernel.org>
Date:   Thu Sep 8 05:51:10 2016 -0300

    [media] fix clock_gettime cross-references
    
    Fix those warnings:
    
            Documentation/media/uapi/cec/cec-ioc-dqevent.rst:124: WARNING: c:func reference target not found: clock_gettime(2)
    
    By replacing it with the right function name, using this shell script:
    
            for i in `find Documentation/media -type f`; do sed 's,clock_gettime(2),clock_gettime,' <$i >a && mv a $i; done
    
    Please notice that this will make the nitpick mode to shut up
    complaining about that, becasue clock_gettime is on its exclude list,
    but the cross reference will be undefined until someone documents
    this function at the core documentation.
    
    Signed-off-by: Mauro Carvalho Chehab <mchehab@s-opensource.com>

commit a1eb1411b4e4251db02179e39d234c2ee5192c72
Author: Stanislaw Gruszka <sgruszka@redhat.com>
Date:   Wed Aug 17 11:30:44 2016 +0200

    sched/cputime: Improve scalability by not accounting thread group tasks pending runtime
    
    Commit:
    
      d670ec13178d0 ("posix-cpu-timers: Cure SMP wobbles")
    
    started accounting thread group tasks pending runtime in thread_group_cputime().
    
    Another commit:
    
      6e998916dfe32 ("sched/cputime: Fix clock_nanosleep()/clock_gettime() inconsistency")
    
    updated scheduler runtime statistics (call update_curr()) when reading task pending
    runtime. Those changes cause bad performance of SYS_times() and
    SYS_clock_gettimes(CLOCK_PROCESS_CPUTIME_ID) syscalls, especially on
    larger systems with many CPUs.
    
    While we would like to have cpuclock monotonicity kept i.e. have
    problems fixed by above commits stay fixed, we also would like to have
    good performance.
    
    However when we notice that change from commit d670ec13178d0 is not
    longer needed to solve problem addressed by that commit, because of
    change from the second commit 6e998916dfe32, we can get room for
    optimization. Since we update task while reading it's pending runtime
    in task_sched_runtime(), clock_gettime(CLOCK_PROCESS_CPUTIME_ID) will
    see updated values and on testcase from d670ec13178d0 process cpuclock
    will not be smaller than thread cpuclock.
    
    I tested the patch on testcases from commits d670ec13178d0,
    6e998916dfe32 and some other cpuclock/cputimers testcases and
    did not found cpuclock monotonicity problems or other malfunction.
    
    This patch has the drawback that we will not provide thread group cputime
    up-to-date to the last moment. For example when arming cputime timer,
    we will arm it with possibly a bit outdated values and that timer will
    trigger earlier compared to behaviour without the patch. However that
    was the behaviour before d670ec13178d0 commit (kernel v3.1) so it's
    unlikely to affect applications.
    
    Patch improves related syscall performance, as measured by Giovanni's
    benchmarks described in commit:
    
      6075620b0590e ("sched/cputime: Mitigate performance regression in times()/clock_gettime()")
    
    The benchmark results are:
    
    SYS_clock_gettime():
    
      threads    4.7-rc7     3.18-rc3              4.7-rc7 + prefetch    4.7-rc7 + patch
                             (pre-6e998916dfe3)
      2          3.48        2.23 ( 35.68%)        3.06 ( 11.83%)        1.08 ( 68.81%)
      5          3.33        2.83 ( 14.84%)        3.25 (  2.40%)        0.71 ( 78.55%)
      8          3.37        2.84 ( 15.80%)        3.26 (  3.30%)        0.56 ( 83.49%)
      12         3.32        3.09 (  6.69%)        3.37 ( -1.60%)        0.42 ( 87.28%)
      21         4.01        3.14 ( 21.70%)        3.90 (  2.74%)        0.35 ( 91.35%)
      30         3.63        3.28 (  9.75%)        3.36 (  7.41%)        0.28 ( 92.23%)
      48         3.71        3.02 ( 18.69%)        3.11 ( 16.27%)        0.39 ( 89.39%)
      79         3.75        2.88 ( 23.23%)        3.16 ( 15.74%)        0.46 ( 87.76%)
      110        3.81        2.95 ( 22.62%)        3.25 ( 14.80%)        0.56 ( 85.41%)
      128        3.88        3.05 ( 21.28%)        3.31 ( 14.76%)        0.62 ( 84.10%)
    
    SYS_times():
    
      threads    4.7-rc7     3.18-rc3              4.7-rc7 + prefetch    4.7-rc7 + patch
                             (pre-6e998916dfe3)
      2          3.65        2.27 ( 37.94%)        3.25 ( 11.03%)        1.62 ( 55.71%)
      5          3.45        2.78 ( 19.34%)        3.17 (  7.92%)        2.33 ( 32.28%)
      8          3.52        2.79 ( 20.66%)        3.22 (  8.69%)        2.06 ( 41.44%)
      12         3.29        3.02 (  8.33%)        3.36 ( -2.04%)        2.00 ( 39.18%)
      21         4.07        3.10 ( 23.86%)        3.92 (  3.78%)        2.07 ( 49.18%)
      30         3.87        3.33 ( 13.80%)        3.40 ( 12.17%)        1.89 ( 51.12%)
      48         3.79        2.96 ( 21.94%)        3.16 ( 16.61%)        1.69 ( 55.46%)
      79         3.88        2.88 ( 25.82%)        3.28 ( 15.42%)        1.60 ( 58.81%)
      110        3.90        2.98 ( 23.73%)        3.38 ( 13.35%)        1.73 ( 55.61%)
      128        4.00        3.10 ( 22.40%)        3.38 ( 15.45%)        1.66 ( 58.52%)
    
    Reported-and-tested-by: Giovanni Gherdovich <ggherdovich@suse.cz>
    Signed-off-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Mike Galbraith <mgalbraith@suse.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Wanpeng Li <wanpeng.li@hotmail.com>
    Link: http://lkml.kernel.org/r/20160817093043.GA25206@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit e6e7214fbbdab1f90254af68e0927bdb24708d22
Merge: ad83242a8f06 26f2c75cd2cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 12 13:51:52 2016 -0700

    Merge branch 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler fixes from Ingo Molnar:
     "Misc fixes: cputime fixes, two deadline scheduler fixes and a cgroups
      scheduling fix"
    
    * 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      sched/cputime: Fix omitted ticks passed in parameter
      sched/cputime: Fix steal time accounting
      sched/deadline: Fix lock pinning warning during CPU hotplug
      sched/cputime: Mitigate performance regression in times()/clock_gettime()
      sched/fair: Fix typo in sync_throttle()
      sched/deadline: Fix wrap-around in DL heap

commit 6075620b0590eaf22f10ce88833eb20a57f760d6
Author: Giovanni Gherdovich <ggherdovich@suse.cz>
Date:   Fri Aug 5 10:21:56 2016 +0200

    sched/cputime: Mitigate performance regression in times()/clock_gettime()
    
    Commit:
    
      6e998916dfe3 ("sched/cputime: Fix clock_nanosleep()/clock_gettime() inconsistency")
    
    fixed a problem whereby clock_nanosleep() followed by clock_gettime() could
    allow a task to wake early. It addressed the problem by calling the scheduling
    classes update_curr() when the cputimer starts.
    
    Said change induced a considerable performance regression on the syscalls
    times() and clock_gettimes(CLOCK_PROCESS_CPUTIME_ID). There are some
    debuggers and applications that monitor their own performance that
    accidentally depend on the performance of these specific calls.
    
    This patch mitigates the performace loss by prefetching data in the CPU
    cache, as stalls due to cache misses appear to be where most time is spent
    in our benchmarks.
    
    Here are the performance gain of this patch over v4.7-rc7 on a Sandy Bridge
    box with 32 logical cores and 2 NUMA nodes. The test is repeated with a
    variable number of threads, from 2 to 4*num_cpus; the results are in
    seconds and correspond to the average of 10 runs; the percentage gain is
    computed with (before-after)/before so a positive value is an improvement
    (it's faster). The improvement varies between a few percents for 5-20
    threads and more than 10% for 2 or >20 threads.
    
    pound_clock_gettime:
    
        threads       4.7-rc7     patched 4.7-rc7
        [num]         [secs]      [secs (percent)]
          2           3.48        3.06 ( 11.83%)
          5           3.33        3.25 (  2.40%)
          8           3.37        3.26 (  3.30%)
         12           3.32        3.37 ( -1.60%)
         21           4.01        3.90 (  2.74%)
         30           3.63        3.36 (  7.41%)
         48           3.71        3.11 ( 16.27%)
         79           3.75        3.16 ( 15.74%)
        110           3.81        3.25 ( 14.80%)
        128           3.88        3.31 ( 14.76%)
    
    pound_times:
    
        threads       4.7-rc7     patched 4.7-rc7
        [num]         [secs]      [secs (percent)]
          2           3.65        3.25 ( 11.03%)
          5           3.45        3.17 (  7.92%)
          8           3.52        3.22 (  8.69%)
         12           3.29        3.36 ( -2.04%)
         21           4.07        3.92 (  3.78%)
         30           3.87        3.40 ( 12.17%)
         48           3.79        3.16 ( 16.61%)
         79           3.88        3.28 ( 15.42%)
        110           3.90        3.38 ( 13.35%)
        128           4.00        3.38 ( 15.45%)
    
    pound_clock_gettime and pound_clock_gettime are two benchmarks included in
    the MMTests framework. They launch a given number of threads which
    repeatedly call times() or clock_gettimes(). The results above can be
    reproduced with cloning MMTests from github.com and running the "poundtime"
    workload:
    
      $ git clone https://github.com/gormanm/mmtests.git
      $ cd mmtests
      $ cp configs/config-global-dhp__workload_poundtime config
      $ ./run-mmtests.sh --run-monitor $(uname -r)
    
    The above will run "poundtime" measuring the kernel currently running on
    the machine; Once a new kernel is installed and the machine rebooted,
    running again
    
      $ cd mmtests
      $ ./run-mmtests.sh --run-monitor $(uname -r)
    
    will produce results to compare with. A comparison table will be output
    with:
    
      $ cd mmtests/work/log
      $ ../../compare-kernels.sh
    
    the table will contain a lot of entries; grepping for "Amean" (as in
    "arithmetic mean") will give the tables presented above. The source code
    for the two benchmarks is reported at the end of this changelog for
    clairity.
    
    The cache misses addressed by this patch were found using a combination of
    `perf top`, `perf record` and `perf annotate`. The incriminated lines were
    found to be
    
        struct sched_entity *curr = cfs_rq->curr;
    
    and
    
        delta_exec = now - curr->exec_start;
    
    in the function update_curr() from kernel/sched/fair.c. This patch
    prefetches the data from memory just before update_curr is called in the
    interested execution path.
    
    A comparison of the total number of cycles before and after the patch
    follows; the data is obtained using `perf stat -r 10 -ddd <program>`
    running over the same sequence of number of threads used above (a positive
    gain is an improvement):
    
      threads   cycles before                 cycles after                gain
    
        2      19,699,563,964  +-1.19%      17,358,917,517  +-1.85%      11.88%
        5      47,401,089,566  +-2.96%      45,103,730,829  +-0.97%       4.85%
        8      80,923,501,004  +-3.01%      71,419,385,977  +-0.77%      11.74%
       12     112,326,485,473  +-0.47%     110,371,524,403  +-0.47%       1.74%
       21     193,455,574,299  +-0.72%     180,120,667,904  +-0.36%       6.89%
       30     315,073,519,013  +-1.64%     271,222,225,950  +-1.29%      13.92%
       48     321,969,515,332  +-1.48%     273,353,977,321  +-1.16%      15.10%
       79     337,866,003,422  +-0.97%     289,462,481,538  +-1.05%      14.33%
      110     338,712,691,920  +-0.78%     290,574,233,170  +-0.77%      14.21%
      128     348,384,794,006  +-0.50%     292,691,648,206  +-0.66%      15.99%
    
    A comparison of cache miss vs total cache loads ratios, before and after
    the patch (again from the `perf stat -r 10 -ddd <program>` tables):
    
      threads   L1 misses/total*100     L1 misses/total*100            gain
                             before                   after
          2           7.43  +-4.90%           7.36  +-4.70%           0.94%
          5          13.09  +-4.74%          13.52  +-3.73%          -3.28%
          8          13.79  +-5.61%          12.90  +-3.27%           6.45%
         12          11.57  +-2.44%           8.71  +-1.40%          24.72%
         21          12.39  +-3.92%           9.97  +-1.84%          19.53%
         30          13.91  +-2.53%          11.73  +-2.28%          15.67%
         48          13.71  +-1.59%          12.32  +-1.97%          10.14%
         79          14.44  +-0.66%          13.40  +-1.06%           7.20%
        110          15.86  +-0.50%          14.46  +-0.59%           8.83%
        128          16.51  +-0.32%          15.06  +-0.78%           8.78%
    
    As a final note, the following shows the evolution of performance figures
    in the "poundtime" benchmark and pinpoints commit 6e998916dfe3
    ("sched/cputime: Fix clock_nanosleep()/clock_gettime() inconsistency") as a
    major source of degradation, mostly unaddressed to this day (figures
    expressed in seconds).
    
    pound_clock_gettime:
    
      threads   parent of         6e998916dfe3        4.7-rc7
                6e998916dfe3            itself
        2        2.23          3.68 ( -64.56%)        3.48 (-55.48%)
        5        2.83          3.78 ( -33.42%)        3.33 (-17.43%)
        8        2.84          4.31 ( -52.12%)        3.37 (-18.76%)
        12       3.09          3.61 ( -16.74%)        3.32 ( -7.17%)
        21       3.14          4.63 ( -47.36%)        4.01 (-27.71%)
        30       3.28          5.75 ( -75.37%)        3.63 (-10.80%)
        48       3.02          6.05 (-100.56%)        3.71 (-22.99%)
        79       2.88          6.30 (-118.90%)        3.75 (-30.26%)
        110      2.95          6.46 (-119.00%)        3.81 (-29.24%)
        128      3.05          6.42 (-110.08%)        3.88 (-27.04%)
    
    pound_times:
    
      threads   parent of         6e998916dfe3        4.7-rc7
                6e998916dfe3            itself
        2        2.27          3.73 ( -64.71%)        3.65 (-61.14%)
        5        2.78          3.77 ( -35.56%)        3.45 (-23.98%)
        8        2.79          4.41 ( -57.71%)        3.52 (-26.05%)
        12       3.02          3.56 ( -17.94%)        3.29 ( -9.08%)
        21       3.10          4.61 ( -48.74%)        4.07 (-31.34%)
        30       3.33          5.75 ( -72.53%)        3.87 (-16.01%)
        48       2.96          6.06 (-105.04%)        3.79 (-28.10%)
        79       2.88          6.24 (-116.83%)        3.88 (-34.81%)
        110      2.98          6.37 (-114.08%)        3.90 (-31.12%)
        128      3.10          6.35 (-104.61%)        4.00 (-28.87%)
    
    The source code of the two benchmarks follows. To compile the two:
    
      NR_THREADS=42
      for FILE in pound_times pound_clock_gettime; do
          gcc -lrt -O2 -lpthread -DNUM_THREADS=$NR_THREADS $FILE.c -o $FILE
      done
    
    ==== BEGIN pound_times.c ====
    
    struct tms start;
    
    void *pound (void *threadid)
    {
      struct tms end;
      int oldutime = 0;
      int utime;
      int i;
      for (i = 0; i < 5000000 / NUM_THREADS; i++) {
              times(&end);
              utime = ((int)end.tms_utime - (int)start.tms_utime);
              if (oldutime > utime) {
                printf("utime decreased, was %d, now %d!\n", oldutime, utime);
              }
              oldutime = utime;
      }
      pthread_exit(NULL);
    }
    
    int main()
    {
      pthread_t th[NUM_THREADS];
      long i;
      times(&start);
      for (i = 0; i < NUM_THREADS; i++) {
        pthread_create (&th[i], NULL, pound, (void *)i);
      }
      pthread_exit(NULL);
      return 0;
    }
    ==== END pound_times.c ====
    
    ==== BEGIN pound_clock_gettime.c ====
    
    void *pound (void *threadid)
    {
            struct timespec ts;
            int rc, i;
            unsigned long prev = 0, this = 0;
    
            for (i = 0; i < 5000000 / NUM_THREADS; i++) {
                    rc = clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &ts);
                    if (rc < 0)
                            perror("clock_gettime");
                    this = (ts.tv_sec * 1000000000) + ts.tv_nsec;
                    if (0 && this < prev)
                            printf("%lu ns timewarp at iteration %d\n", prev - this, i);
                    prev = this;
            }
            pthread_exit(NULL);
    }
    
    int main()
    {
            pthread_t th[NUM_THREADS];
            long rc, i;
            pid_t pgid;
    
            for (i = 0; i < NUM_THREADS; i++) {
                    rc = pthread_create(&th[i], NULL, pound, (void *)i);
                    if (rc < 0)
                            perror("pthread_create");
            }
    
            pthread_exit(NULL);
            return 0;
    }
    ==== END pound_clock_gettime.c ====
    
    Suggested-by: Mike Galbraith <mgalbraith@suse.de>
    Signed-off-by: Giovanni Gherdovich <ggherdovich@suse.cz>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1470385316-15027-2-git-send-email-ggherdovich@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit e831101a73fbc8339ef1d1909dad3ef64f089e70
Merge: f9abf53af4c7 fd6380b75065
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 27 11:16:05 2016 -0700

    Merge tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux
    
    Pull arm64 updates from Catalin Marinas:
    
     - Kexec support for arm64
    
     - Kprobes support
    
     - Expose MIDR_EL1 and REVIDR_EL1 CPU identification registers to sysfs
    
     - Trapping of user space cache maintenance operations and emulation in
       the kernel (CPU errata workaround)
    
     - Clean-up of the early page tables creation (kernel linear mapping,
       EFI run-time maps) to avoid splitting larger blocks (e.g.  pmds) into
       smaller ones (e.g.  ptes)
    
     - VDSO support for CLOCK_MONOTONIC_RAW in clock_gettime()
    
     - ARCH_HAS_KCOV enabled for arm64
    
     - Optimise IP checksum helpers
    
     - SWIOTLB optimisation to only allocate/initialise the buffer if the
       available RAM is beyond the 32-bit mask
    
     - Properly handle the "nosmp" command line argument
    
     - Fix for the initialisation of the CPU debug state during early boot
    
     - vdso-offsets.h build dependency workaround
    
     - Build fix when RANDOMIZE_BASE is enabled with MODULES off
    
    * tag 'arm64-upstream' of git://git.kernel.org/pub/scm/linux/kernel/git/arm64/linux: (64 commits)
      arm64: arm: Fix-up the removal of the arm64 regs_query_register_name() prototype
      arm64: Only select ARM64_MODULE_PLTS if MODULES=y
      arm64: mm: run pgtable_page_ctor() on non-swapper translation table pages
      arm64: mm: make create_mapping_late() non-allocating
      arm64: Honor nosmp kernel command line option
      arm64: Fix incorrect per-cpu usage for boot CPU
      arm64: kprobes: Add KASAN instrumentation around stack accesses
      arm64: kprobes: Cleanup jprobe_return
      arm64: kprobes: Fix overflow when saving stack
      arm64: kprobes: WARN if attempting to step with PSTATE.D=1
      arm64: debug: remove unused local_dbg_{enable, disable} macros
      arm64: debug: remove redundant spsr manipulation
      arm64: debug: unmask PSTATE.D earlier
      arm64: localise Image objcopy flags
      arm64: ptrace: remove extra define for CPSR's E bit
      kprobes: Add arm64 case in kprobe example module
      arm64: Add kernel return probes support (kretprobes)
      arm64: Add trampoline code for kretprobes
      arm64: kprobes instruction simulation support
      arm64: Treat all entry code as non-kprobe-able
      ...

commit 49eea433b326a0ac5c7c941a011b2c65990bd19b
Author: Kevin Brodsky <kevin.brodsky@arm.com>
Date:   Tue Jul 12 11:24:00 2016 +0100

    arm64: Add support for CLOCK_MONOTONIC_RAW in clock_gettime() vDSO
    
    So far the arm64 clock_gettime() vDSO implementation only supported
    the following clocks, falling back to the syscall for the others:
    - CLOCK_REALTIME{,_COARSE}
    - CLOCK_MONOTONIC{,_COARSE}
    
    This patch adds support for the CLOCK_MONOTONIC_RAW clock, taking
    advantage of the recent refactoring of the vDSO time functions. Like
    the non-_COARSE clocks, this only works when the "arch_sys_counter"
    clocksource is in use (allowing us to read the current time from the
    virtual counter register), otherwise we also have to fall back to the
    syscall.
    
    Most of the data is shared with CLOCK_MONOTONIC, and the algorithm is
    similar. The reference implementation in kernel/time/timekeeping.c
    shows that:
    - CLOCK_MONOTONIC = tk->wall_to_monotonic + tk->xtime_sec +
      timekeeping_get_ns(&tk->tkr_mono)
    - CLOCK_MONOTONIC_RAW = tk->raw_time + timekeeping_get_ns(&tk->tkr_raw)
    - tkr_mono and tkr_raw are identical (in particular, same
      clocksource), except these members:
      * mult (only mono's multiplier is NTP-adjusted)
      * xtime_nsec (always 0 for raw)
    
    Therefore, tk->raw_time and tkr_raw->mult are now also stored in the
    vDSO data page.
    
    Cc: Ali Saidi <ali.saidi@arm.com>
    Signed-off-by: Kevin Brodsky <kevin.brodsky@arm.com>
    Reviewed-by: Dave Martin <dave.martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

commit b33f491f5a9aaf171b7de0f905362eb0314af478
Author: Kevin Brodsky <kevin.brodsky@arm.com>
Date:   Tue Jul 12 11:23:59 2016 +0100

    arm64: Refactor vDSO time functions
    
    Time functions are directly implemented in assembly in arm64, and it
    is desirable to keep it this way for performance reasons (everything
    fits in registers, so that the stack is not used at all). However, the
    current implementation is quite difficult to read and understand (even
    considering it's assembly).  Additionally, due to the structure of
    __kernel_clock_gettime, which heavily uses conditional branches to
    share code between the different clocks, it is difficult to support a
    new clock without making the branches even harder to follow.
    
    This commit completely refactors the structure of clock_gettime (and
    gettimeofday along the way) while keeping exactly the same algorithms.
    We no longer try to share code; instead, macros provide common
    operations. This new approach comes with a number of advantages:
    - In clock_gettime, clock implementations are no longer interspersed,
      making them much more readable. Additionally, macros only use
      registers passed as arguments or reserved with .req, this way it is
      easy to make sure that registers are properly allocated. To avoid a
      large number of branches in a given execution path, a jump table is
      used; a normal execution uses 3 unconditional branches.
    - __do_get_tspec has been replaced with 2 macros (get_ts_clock_mono,
      get_clock_shifted_nsec) and explicit loading of data from the vDSO
      page. Consequently, clock_gettime and gettimeofday are now leaf
      functions, and saving x30 (lr) is no longer necessary.
    - Variables protected by tb_seq_count are now loaded all at once,
      allowing to merge the seqcnt_read macro into seqcnt_check.
    - For CLOCK_REALTIME_COARSE, removed an unused load of the wall to
      monotonic timespec.
    - For CLOCK_MONOTONIC_COARSE, removed a few shift instructions.
    
    Obviously, the downside of sharing less code is an increase in code
    size. However since the vDSO has its own code page, this does not
    really matter, as long as the size of the DSO remains below 4 kB. For
    now this should be all right:
                        Before  After
      vdso.so size (B)  2776    3000
    
    Signed-off-by: Kevin Brodsky <kevin.brodsky@arm.com>
    Reviewed-by: Dave Martin <dave.martin@arm.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

commit bc2b7dab629a51e8beb5fda4222c62a23b729f26
Author: Gregor Boirie <gregor.boirie@parrot.com>
Date:   Wed Mar 9 19:05:49 2016 +0100

    iio:core: timestamping clock selection support
    
    Adds a new per-device sysfs attribute "current_timestamp_clock" to allow
    userspace to select a particular POSIX clock for buffered samples and
    events timestamping.
    
    Following clocks, as listed in clock_gettime(2), are supported:
    CLOCK_REALTIME, CLOCK_MONOTONIC, CLOCK_MONOTONIC_RAW,
    CLOCK_REALTIME_COARSE, CLOCK_MONOTONIC_COARSE, CLOCK_BOOTTIME and
    CLOCK_TAI.
    
    Signed-off-by: Gregor Boirie <gregor.boirie@parrot.com>
    Acked-by: Sanchayan Maity <maitysanchayan@gmail.com>
    Signed-off-by: Jonathan Cameron <jic23@kernel.org>

commit 0209b937569a133dedfe930cdfff3a0d1d68c9e9
Author: Thomas Graziadei <thomas.graziadei@omicronenergy.com>
Date:   Tue May 31 15:06:06 2016 +0200

    timekeeping: Fix 1ns/tick drift with GENERIC_TIME_VSYSCALL_OLD
    
    The user notices the problem in a raw and real time drift, calling
    clock_gettime with CLOCK_REALTIME / CLOCK_MONOTONIC_RAW on a system
    with no ntp correction taking place (no ntpd or ptp stuff running).
    
    The problem is, that old_vsyscall_fixup adds an extra 1ns even though
    xtime_nsec is already held in full nsecs and the remainder in this
    case is 0. Do the rounding up buisness only if needed.
    
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Thomas Graziadei <thomas.graziadei@omicronenergy.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

commit fff7fb0b2d908dec779783d8eaf3d7725230f75e
Author: Zhaoxiu Zeng <zhaoxiu.zeng@gmail.com>
Date:   Fri May 20 17:03:57 2016 -0700

    lib/GCD.c: use binary GCD algorithm instead of Euclidean
    
    The binary GCD algorithm is based on the following facts:
            1. If a and b are all evens, then gcd(a,b) = 2 * gcd(a/2, b/2)
            2. If a is even and b is odd, then gcd(a,b) = gcd(a/2, b)
            3. If a and b are all odds, then gcd(a,b) = gcd((a-b)/2, b) = gcd((a+b)/2, b)
    
    Even on x86 machines with reasonable division hardware, the binary
    algorithm runs about 25% faster (80% the execution time) than the
    division-based Euclidian algorithm.
    
    On platforms like Alpha and ARMv6 where division is a function call to
    emulation code, it's even more significant.
    
    There are two variants of the code here, depending on whether a fast
    __ffs (find least significant set bit) instruction is available.  This
    allows the unpredictable branches in the bit-at-a-time shifting loop to
    be eliminated.
    
    If fast __ffs is not available, the "even/odd" GCD variant is used.
    
    I use the following code to benchmark:
    
            #include <stdio.h>
            #include <stdlib.h>
            #include <stdint.h>
            #include <string.h>
            #include <time.h>
            #include <unistd.h>
    
            #define swap(a, b) \
                    do { \
                            a ^= b; \
                            b ^= a; \
                            a ^= b; \
                    } while (0)
    
            unsigned long gcd0(unsigned long a, unsigned long b)
            {
                    unsigned long r;
    
                    if (a < b) {
                            swap(a, b);
                    }
    
                    if (b == 0)
                            return a;
    
                    while ((r = a % b) != 0) {
                            a = b;
                            b = r;
                    }
    
                    return b;
            }
    
            unsigned long gcd1(unsigned long a, unsigned long b)
            {
                    unsigned long r = a | b;
    
                    if (!a || !b)
                            return r;
    
                    b >>= __builtin_ctzl(b);
    
                    for (;;) {
                            a >>= __builtin_ctzl(a);
                            if (a == b)
                                    return a << __builtin_ctzl(r);
    
                            if (a < b)
                                    swap(a, b);
                            a -= b;
                    }
            }
    
            unsigned long gcd2(unsigned long a, unsigned long b)
            {
                    unsigned long r = a | b;
    
                    if (!a || !b)
                            return r;
    
                    r &= -r;
    
                    while (!(b & r))
                            b >>= 1;
    
                    for (;;) {
                            while (!(a & r))
                                    a >>= 1;
                            if (a == b)
                                    return a;
    
                            if (a < b)
                                    swap(a, b);
                            a -= b;
                            a >>= 1;
                            if (a & r)
                                    a += b;
                            a >>= 1;
                    }
            }
    
            unsigned long gcd3(unsigned long a, unsigned long b)
            {
                    unsigned long r = a | b;
    
                    if (!a || !b)
                            return r;
    
                    b >>= __builtin_ctzl(b);
                    if (b == 1)
                            return r & -r;
    
                    for (;;) {
                            a >>= __builtin_ctzl(a);
                            if (a == 1)
                                    return r & -r;
                            if (a == b)
                                    return a << __builtin_ctzl(r);
    
                            if (a < b)
                                    swap(a, b);
                            a -= b;
                    }
            }
    
            unsigned long gcd4(unsigned long a, unsigned long b)
            {
                    unsigned long r = a | b;
    
                    if (!a || !b)
                            return r;
    
                    r &= -r;
    
                    while (!(b & r))
                            b >>= 1;
                    if (b == r)
                            return r;
    
                    for (;;) {
                            while (!(a & r))
                                    a >>= 1;
                            if (a == r)
                                    return r;
                            if (a == b)
                                    return a;
    
                            if (a < b)
                                    swap(a, b);
                            a -= b;
                            a >>= 1;
                            if (a & r)
                                    a += b;
                            a >>= 1;
                    }
            }
    
            static unsigned long (*gcd_func[])(unsigned long a, unsigned long b) = {
                    gcd0, gcd1, gcd2, gcd3, gcd4,
            };
    
            #define TEST_ENTRIES (sizeof(gcd_func) / sizeof(gcd_func[0]))
    
            #if defined(__x86_64__)
    
            #define rdtscll(val) do { \
                    unsigned long __a,__d; \
                    __asm__ __volatile__("rdtsc" : "=a" (__a), "=d" (__d)); \
                    (val) = ((unsigned long long)__a) | (((unsigned long long)__d)<<32); \
            } while(0)
    
            static unsigned long long benchmark_gcd_func(unsigned long (*gcd)(unsigned long, unsigned long),
                                                                    unsigned long a, unsigned long b, unsigned long *res)
            {
                    unsigned long long start, end;
                    unsigned long long ret;
                    unsigned long gcd_res;
    
                    rdtscll(start);
                    gcd_res = gcd(a, b);
                    rdtscll(end);
    
                    if (end >= start)
                            ret = end - start;
                    else
                            ret = ~0ULL - start + 1 + end;
    
                    *res = gcd_res;
                    return ret;
            }
    
            #else
    
            static inline struct timespec read_time(void)
            {
                    struct timespec time;
                    clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &time);
                    return time;
            }
    
            static inline unsigned long long diff_time(struct timespec start, struct timespec end)
            {
                    struct timespec temp;
    
                    if ((end.tv_nsec - start.tv_nsec) < 0) {
                            temp.tv_sec = end.tv_sec - start.tv_sec - 1;
                            temp.tv_nsec = 1000000000ULL + end.tv_nsec - start.tv_nsec;
                    } else {
                            temp.tv_sec = end.tv_sec - start.tv_sec;
                            temp.tv_nsec = end.tv_nsec - start.tv_nsec;
                    }
    
                    return temp.tv_sec * 1000000000ULL + temp.tv_nsec;
            }
    
            static unsigned long long benchmark_gcd_func(unsigned long (*gcd)(unsigned long, unsigned long),
                                                                    unsigned long a, unsigned long b, unsigned long *res)
            {
                    struct timespec start, end;
                    unsigned long gcd_res;
    
                    start = read_time();
                    gcd_res = gcd(a, b);
                    end = read_time();
    
                    *res = gcd_res;
                    return diff_time(start, end);
            }
    
            #endif
    
            static inline unsigned long get_rand()
            {
                    if (sizeof(long) == 8)
                            return (unsigned long)rand() << 32 | rand();
                    else
                            return rand();
            }
    
            int main(int argc, char **argv)
            {
                    unsigned int seed = time(0);
                    int loops = 100;
                    int repeats = 1000;
                    unsigned long (*res)[TEST_ENTRIES];
                    unsigned long long elapsed[TEST_ENTRIES];
                    int i, j, k;
    
                    for (;;) {
                            int opt = getopt(argc, argv, "n:r:s:");
                            /* End condition always first */
                            if (opt == -1)
                                    break;
    
                            switch (opt) {
                            case 'n':
                                    loops = atoi(optarg);
                                    break;
                            case 'r':
                                    repeats = atoi(optarg);
                                    break;
                            case 's':
                                    seed = strtoul(optarg, NULL, 10);
                                    break;
                            default:
                                    /* You won't actually get here. */
                                    break;
                            }
                    }
    
                    res = malloc(sizeof(unsigned long) * TEST_ENTRIES * loops);
                    memset(elapsed, 0, sizeof(elapsed));
    
                    srand(seed);
                    for (j = 0; j < loops; j++) {
                            unsigned long a = get_rand();
                            /* Do we have args? */
                            unsigned long b = argc > optind ? strtoul(argv[optind], NULL, 10) : get_rand();
                            unsigned long long min_elapsed[TEST_ENTRIES];
                            for (k = 0; k < repeats; k++) {
                                    for (i = 0; i < TEST_ENTRIES; i++) {
                                            unsigned long long tmp = benchmark_gcd_func(gcd_func[i], a, b, &res[j][i]);
                                            if (k == 0 || min_elapsed[i] > tmp)
                                                    min_elapsed[i] = tmp;
                                    }
                            }
                            for (i = 0; i < TEST_ENTRIES; i++)
                                    elapsed[i] += min_elapsed[i];
                    }
    
                    for (i = 0; i < TEST_ENTRIES; i++)
                            printf("gcd%d: elapsed %llu\n", i, elapsed[i]);
    
                    k = 0;
                    srand(seed);
                    for (j = 0; j < loops; j++) {
                            unsigned long a = get_rand();
                            unsigned long b = argc > optind ? strtoul(argv[optind], NULL, 10) : get_rand();
                            for (i = 1; i < TEST_ENTRIES; i++) {
                                    if (res[j][i] != res[j][0])
                                            break;
                            }
                            if (i < TEST_ENTRIES) {
                                    if (k == 0) {
                                            k = 1;
                                            fprintf(stderr, "Error:\n");
                                    }
                                    fprintf(stderr, "gcd(%lu, %lu): ", a, b);
                                    for (i = 0; i < TEST_ENTRIES; i++)
                                            fprintf(stderr, "%ld%s", res[j][i], i < TEST_ENTRIES - 1 ? ", " : "\n");
                            }
                    }
    
                    if (k == 0)
                            fprintf(stderr, "PASS\n");
    
                    free(res);
    
                    return 0;
            }
    
    Compiled with "-O2", on "VirtualBox 4.4.0-22-generic #38-Ubuntu x86_64" got:
    
      zhaoxiuzeng@zhaoxiuzeng-VirtualBox:~/develop$ ./gcd -r 500000 -n 10
      gcd0: elapsed 10174
      gcd1: elapsed 2120
      gcd2: elapsed 2902
      gcd3: elapsed 2039
      gcd4: elapsed 2812
      PASS
      zhaoxiuzeng@zhaoxiuzeng-VirtualBox:~/develop$ ./gcd -r 500000 -n 10
      gcd0: elapsed 9309
      gcd1: elapsed 2280
      gcd2: elapsed 2822
      gcd3: elapsed 2217
      gcd4: elapsed 2710
      PASS
      zhaoxiuzeng@zhaoxiuzeng-VirtualBox:~/develop$ ./gcd -r 500000 -n 10
      gcd0: elapsed 9589
      gcd1: elapsed 2098
      gcd2: elapsed 2815
      gcd3: elapsed 2030
      gcd4: elapsed 2718
      PASS
      zhaoxiuzeng@zhaoxiuzeng-VirtualBox:~/develop$ ./gcd -r 500000 -n 10
      gcd0: elapsed 9914
      gcd1: elapsed 2309
      gcd2: elapsed 2779
      gcd3: elapsed 2228
      gcd4: elapsed 2709
      PASS
    
    [akpm@linux-foundation.org: avoid #defining a CONFIG_ variable]
    Signed-off-by: Zhaoxiu Zeng <zhaoxiu.zeng@gmail.com>
    Signed-off-by: George Spelvin <linux@horizon.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 6b078f5de7fc0851af4102493c7b5bb07e49c4cb
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Thu Dec 10 19:20:19 2015 -0800

    x86, vdso, pvclock: Simplify and speed up the vdso pvclock reader
    
    The pvclock vdso code was too abstracted to understand easily
    and excessively paranoid.  Simplify it for a huge speedup.
    
    This opens the door for additional simplifications, as the vdso
    no longer accesses the pvti for any vcpu other than vcpu 0.
    
    Before, vclock_gettime using kvm-clock took about 45ns on my
    machine. With this change, it takes 29ns, which is almost as
    fast as the pure TSC implementation.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Brian Gerst <brgerst@gmail.com>
    Cc: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/6b51dcc41f1b101f963945c5ec7093d72bdac429.1449702533.git.luto@kernel.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit a7f4df4e21dd8a8dab96e88acd2c9c5017b83fc6
Author: Alex Smith <alex.smith@imgtec.com>
Date:   Wed Oct 21 09:57:44 2015 +0100

    MIPS: VDSO: Add implementations of gettimeofday() and clock_gettime()
    
    Add user-mode implementations of gettimeofday() and clock_gettime() to
    the VDSO. This is currently usable with 2 clocksources: the CP0 count
    register, which is accessible to user-mode via RDHWR on R2 and later
    cores, or the MIPS Global Interrupt Controller (GIC) timer, which
    provides a "user-mode visible" section containing a mirror of its
    counter registers. This section must be mapped into user memory, which
    is done below the VDSO data page.
    
    When a supported clocksource is not in use, the VDSO functions will
    return -ENOSYS, which causes libc to fall back on the standard syscall
    path.
    
    When support for neither of these clocksources is compiled into the
    kernel at all, the VDSO still provides clock_gettime(), as the coarse
    realtime/monotonic clocks can still be implemented. However,
    gettimeofday() is not provided in this case as nothing can be done
    without a suitable clocksource. This causes the symbol lookup to fail
    in libc and it will then always use the standard syscall path.
    
    This patch includes a workaround for a bug in QEMU which results in
    RDHWR on the CP0 count register always returning a constant (incorrect)
    value. A fix for this has been submitted, and the workaround can be
    removed after the fix has been in stable releases for a reasonable
    amount of time.
    
    A simple performance test which calls gettimeofday() 1000 times in a
    loop and calculates the average execution time gives the following
    results on a Malta + I6400 (running at 20MHz):
    
     - Syscall:    ~31000 ns
     - VDSO (GIC): ~15000 ns
     - VDSO (CP0): ~9500 ns
    
    [markos.chandras@imgtec.com:
    - Minor code re-arrangements in order for mappings to be made
    in the order they appear to the process' address space.
    - Move do_{monotonic, realtime} outside of the MIPS_CLOCK_VSYSCALL ifdef
    - Use gic_get_usm_range so we can do the GIC mapping in the
    arch/mips/kernel/vdso instead of the GIC irqchip driver]
    
    Signed-off-by: Alex Smith <alex.smith@imgtec.com>
    Signed-off-by: Markos Chandras <markos.chandras@imgtec.com>
    Cc: linux-kernel@vger.kernel.org
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/11338/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

commit ebb5e78cc63417a35254a791de66e1cc84f963cc
Author: Alex Smith <alex.smith@imgtec.com>
Date:   Wed Oct 21 09:54:38 2015 +0100

    MIPS: Initial implementation of a VDSO
    
    Add an initial implementation of a proper (i.e. an ELF shared library)
    VDSO. With this commit it does not export any symbols, it only replaces
    the current signal return trampoline page. A later commit will add user
    implementations of gettimeofday()/clock_gettime().
    
    To support both new toolchains and old ones which don't generate ABI
    flags section, we define its content manually and then use a tool
    (genvdso) to patch up the section to have the correct name and type.
    genvdso also extracts symbol offsets ({,rt_}sigreturn) needed by the
    kernel, and generates a C file containing a "struct mips_vdso_image"
    containing both the VDSO data and these offsets. This C file is
    compiled into the kernel.
    
    On 64-bit kernels we require a different VDSO for each supported ABI,
    so we may build up to 3 different VDSOs. The VDSO to use is selected by
    the mips_abi structure.
    
    A kernel/user shared data page is created and mapped below the VDSO
    image. This is currently empty, but will be used by the user time
    function implementations which are added later.
    
    [markos.chandras@imgtec.com:
    - Add more comments
    - Move abi detection in genvdso.h since it's the get_symbol function
    that needs it.
    - Add an R6 specific way to calculate the base address of VDSO in order
    to avoid the branch instruction which affects performance.
    - Do not patch .gnu.attributes since it's not needed for dynamic linking.
    - Simplify Makefile a little bit.
    - checkpatch fixes
    - Restrict VDSO support for binutils < 2.25 for pre-R6
    - Include atomic64.h for O32 variant on MIPS64]
    
    Signed-off-by: Alex Smith <alex.smith@imgtec.com>
    Signed-off-by: Markos Chandras <markos.chandras@imgtec.com>
    Cc: Matthew Fortune <matthew.fortune@imgtec.com>
    Cc: linux-mips@linux-mips.org
    Patchwork: https://patchwork.linux-mips.org/patch/11337/
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>

commit b02ac6b18cd4e2c76bf0a102c20c429b973f5f76
Merge: 105ff3cbf225 bebd23a2ed31
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Nov 3 17:38:09 2015 -0800

    Merge branch 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull perf updates from Ingo Molnar:
     "Kernel side changes:
    
       - Improve accuracy of perf/sched clock on x86.  (Adrian Hunter)
    
       - Intel DS and BTS updates.  (Alexander Shishkin)
    
       - Intel cstate PMU support.  (Kan Liang)
    
       - Add group read support to perf_event_read().  (Peter Zijlstra)
    
       - Branch call hardware sampling support, implemented on x86 and
         PowerPC.  (Stephane Eranian)
    
       - Event groups transactional interface enhancements.  (Sukadev
         Bhattiprolu)
    
       - Enable proper x86/intel/uncore PMU support on multi-segment PCI
         systems.  (Taku Izumi)
    
       - ... misc fixes and cleanups.
    
      The perf tooling team was very busy again with 200+ commits, the full
      diff doesn't fit into lkml size limits.  Here's an (incomplete) list
      of the tooling highlights:
    
      New features:
    
       - Change the default event used in all tools (record/top): use the
         most precise "cycles" hw counter available, i.e. when the user
         doesn't specify any event, it will try using cycles:ppp, cycles:pp,
         etc and fall back transparently until it finds a working counter.
         (Arnaldo Carvalho de Melo)
    
       - Integration of perf with eBPF that, given an eBPF .c source file
         (or .o file built for the 'bpf' target with clang), will get it
         automatically built, validated and loaded into the kernel via the
         sys_bpf syscall, which can then be used and seen using 'perf trace'
         and other tools.
    
         (Wang Nan)
    
      Various user interface improvements:
    
       - Automatic pager invocation on long help output.  (Namhyung Kim)
    
       - Search for more options when passing args to -h, e.g.: (Arnaldo
         Carvalho de Melo)
    
            $ perf report -h interface
    
            Usage: perf report [<options>]
    
             --gtk    Use the GTK2 interface
             --stdio  Use the stdio interface
             --tui    Use the TUI interface
    
       - Show ordered command line options when -h is used or when an
         unknown option is specified.  (Arnaldo Carvalho de Melo)
    
       - If options are passed after -h, show just its descriptions, not all
         options.  (Arnaldo Carvalho de Melo)
    
       - Implement column based horizontal scrolling in the hists browser
         (top, report), making it possible to use the TUI for things like
         'perf mem report' where there are many more columns than can fit in
         a terminal.  (Arnaldo Carvalho de Melo)
    
       - Enhance the error reporting of tracepoint event parsing, e.g.:
    
           $ oldperf record -e sched:sched_switc usleep 1
           event syntax error: 'sched:sched_switc'
                                \___ unknown tracepoint
           Run 'perf list' for a list of valid events
    
         Now we get the much nicer:
    
           $ perf record -e sched:sched_switc ls
           event syntax error: 'sched:sched_switc'
                                \___ can't access trace events
    
           Error: No permissions to read /sys/kernel/debug/tracing/events/sched/sched_switc
           Hint:  Try 'sudo mount -o remount,mode=755 /sys/kernel/debug'
    
         And after we have those mount point permissions fixed:
    
           $ perf record -e sched:sched_switc ls
           event syntax error: 'sched:sched_switc'
                                \___ unknown tracepoint
    
           Error: File /sys/kernel/debug/tracing/events/sched/sched_switc not found.
           Hint:  Perhaps this kernel misses some CONFIG_ setting to enable this feature?.
    
         I.e.  basically now the event parsing routing uses the strerror_open()
         routines introduced by and used in 'perf trace' work.  (Jiri Olsa)
    
       - Fail properly when pattern matching fails to find a tracepoint,
         i.e. '-e non:existent' was being correctly handled, with a proper
         error message about that not being a valid event, but '-e
         non:existent*' wasn't, fix it.  (Jiri Olsa)
    
       - Do event name substring search as last resort in 'perf list'.
         (Arnaldo Carvalho de Melo)
    
         E.g.:
    
           # perf list clock
    
           List of pre-defined events (to be used in -e):
    
            cpu-clock                                          [Software event]
            task-clock                                         [Software event]
    
            uncore_cbox_0/clockticks/                          [Kernel PMU event]
            uncore_cbox_1/clockticks/                          [Kernel PMU event]
    
            kvm:kvm_pvclock_update                             [Tracepoint event]
            kvm:kvm_update_master_clock                        [Tracepoint event]
            power:clock_disable                                [Tracepoint event]
            power:clock_enable                                 [Tracepoint event]
            power:clock_set_rate                               [Tracepoint event]
            syscalls:sys_enter_clock_adjtime                   [Tracepoint event]
            syscalls:sys_enter_clock_getres                    [Tracepoint event]
            syscalls:sys_enter_clock_gettime                   [Tracepoint event]
            syscalls:sys_enter_clock_nanosleep                 [Tracepoint event]
            syscalls:sys_enter_clock_settime                   [Tracepoint event]
            syscalls:sys_exit_clock_adjtime                    [Tracepoint event]
            syscalls:sys_exit_clock_getres                     [Tracepoint event]
            syscalls:sys_exit_clock_gettime                    [Tracepoint event]
            syscalls:sys_exit_clock_nanosleep                  [Tracepoint event]
            syscalls:sys_exit_clock_settime                    [Tracepoint event]
    
      Intel PT hardware tracing enhancements:
    
       - Accept a zero --itrace period, meaning "as often as possible".  In
         the case of Intel PT that is the same as a period of 1 and a unit
         of 'instructions' (i.e.  --itrace=i1i).  (Adrian Hunter)
    
       - Harmonize itrace's synthesized callchains with the existing
         --max-stack tool option.  (Adrian Hunter)
    
       - Allow time to be displayed in nanoseconds in 'perf script'.
         (Adrian Hunter)
    
       - Fix potential infinite loop when handling Intel PT timestamps.
         (Adrian Hunter)
    
       - Slighly improve Intel PT debug logging.  (Adrian Hunter)
    
       - Warn when AUX data has been lost, just like when processing
         PERF_RECORD_LOST.  (Adrian Hunter)
    
       - Further document export-to-postgresql.py script.  (Adrian Hunter)
    
       - Add option to synthesize branch stack from auxtrace data.  (Adrian
         Hunter)
    
      Misc notable changes:
    
       - Switch the default callchain output mode to 'graph,0.5,caller', to
         make it look like the default for other tools, reducing the
         learning curve for people used to 'caller' based viewing.  (Arnaldo
         Carvalho de Melo)
    
       - various call chain usability enhancements.  (Namhyung Kim)
    
       - Introduce the 'P' event modifier, meaning 'max precision level,
         please', i.e.:
    
            $ perf record -e cycles:P usleep 1
    
         Is now similar to:
    
            $ perf record usleep 1
    
         Useful, for instance, when specifying multiple events.  (Jiri Olsa)
    
       - Add 'socket' sort entry, to sort by the processor socket in 'perf
         top' and 'perf report'.  (Kan Liang)
    
       - Introduce --socket-filter to 'perf report', for filtering by
         processor socket.  (Kan Liang)
    
       - Add new "Zoom into Processor Socket" operation in the perf hists
         browser, used in 'perf top' and 'perf report'.  (Kan Liang)
    
       - Allow probing on kmodules without DWARF.  (Masami Hiramatsu)
    
       - Fix 'perf probe -l' for probes added to kernel module functions.
         (Masami Hiramatsu)
    
       - Preparatory work for the 'perf stat record' feature that will allow
         generating perf.data files with counting data in addition to the
         sampling mode we have now (Jiri Olsa)
    
       - Update libtraceevent KVM plugin.  (Paolo Bonzini)
    
       - ... plus lots of other enhancements that I failed to list properly,
         by: Adrian Hunter, Alexander Shishkin, Andi Kleen, Andrzej Hajda,
         Arnaldo Carvalho de Melo, Dima Kogan, Don Zickus, Geliang Tang, He
         Kuang, Huaitong Han, Ingo Molnar, Jan Stancek, Jiri Olsa, Kan
         Liang, Kirill Tkhai, Masami Hiramatsu, Matt Fleming, Namhyung Kim,
         Paolo Bonzini, Peter Zijlstra, Rabin Vincent, Scott Wood, Stephane
         Eranian, Sukadev Bhattiprolu, Taku Izumi, Vaishali Thakkar, Wang
         Nan, Yang Shi and Yunlong Song"
    
    * 'perf-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (260 commits)
      perf unwind: Pass symbol source to libunwind
      tools build: Fix libiberty feature detection
      perf tools: Compile scriptlets to BPF objects when passing '.c' to --event
      perf record: Add clang options for compiling BPF scripts
      perf bpf: Attach eBPF filter to perf event
      perf tools: Make sure fixdep is built before libbpf
      perf script: Enable printing of branch stack
      perf trace: Add cmd string table to decode sys_bpf first arg
      perf bpf: Collect perf_evsel in BPF object files
      perf tools: Load eBPF object into kernel
      perf tools: Create probe points for BPF programs
      perf tools: Enable passing bpf object file to --event
      perf ebpf: Add the libbpf glue
      perf tools: Make perf depend on libbpf
      perf symbols: Fix endless loop in dso__split_kallsyms_for_kcore
      perf tools: Enable pre-event inherit setting by config terms
      perf symbols: we can now read separate debug-info files based on a build ID
      perf symbols: Fix type error when reading a build-id
      perf tools: Search for more options when passing args to -h
      perf stat: Cache aggregated map entries in extra cpumap
      ...

commit e3b0ac1b7a8a590440a2030e7d10d48c59ab8a2a
Merge: c2365b9388e8 19afd1041095
Author: Ingo Molnar <mingo@kernel.org>
Date:   Sat Oct 3 08:20:14 2015 +0200

    Merge tag 'perf-core-for-mingo' of git://git.kernel.org/pub/scm/linux/kernel/git/acme/linux into perf/core
    
    Pull perf/core improvements and fixes from Arnaldo Carvalho de Melo:
    
    User visible changes:
    
     - Do event name substring search as last resort in 'perf list'.
       (Arnaldo Carvalho de Melo)
    
       E.g.:
    
        # perf list clock
    
        List of pre-defined events (to be used in -e):
    
         cpu-clock                                          [Software event]
         task-clock                                         [Software event]
    
         uncore_cbox_0/clockticks/                          [Kernel PMU event]
         uncore_cbox_1/clockticks/                          [Kernel PMU event]
    
         kvm:kvm_pvclock_update                             [Tracepoint event]
         kvm:kvm_update_master_clock                        [Tracepoint event]
         power:clock_disable                                [Tracepoint event]
         power:clock_enable                                 [Tracepoint event]
         power:clock_set_rate                               [Tracepoint event]
         syscalls:sys_enter_clock_adjtime                   [Tracepoint event]
         syscalls:sys_enter_clock_getres                    [Tracepoint event]
         syscalls:sys_enter_clock_gettime                   [Tracepoint event]
         syscalls:sys_enter_clock_nanosleep                 [Tracepoint event]
         syscalls:sys_enter_clock_settime                   [Tracepoint event]
         syscalls:sys_exit_clock_adjtime                    [Tracepoint event]
         syscalls:sys_exit_clock_getres                     [Tracepoint event]
         syscalls:sys_exit_clock_gettime                    [Tracepoint event]
         syscalls:sys_exit_clock_nanosleep                  [Tracepoint event]
         syscalls:sys_exit_clock_settime                    [Tracepoint event]
    
     - Reduce min 'perf stat --interval-print/-I' to 10ms. (Kan Liang)
    
       perf stat --interval in action:
    
       # perf stat -e cycles -I 50 -a usleep $((200 * 1000))
       print interval < 100ms. The overhead percentage could be high in some cases. Please proceed with caution.
       #   time                    counts unit events
          0.050233636         48,240,396      cycles
          0.100557098         35,492,594      cycles
          0.150804687         39,295,112      cycles
          0.201032269         33,101,961      cycles
          0.201980732            786,379      cycles
      #
    
     - Allow for max_stack greater than PERF_MAX_STACK_DEPTH, as when
       synthesizing callchains from Intel PT data. (Adrian Hunter)
    
     - Allow probing on kmodules without DWARF. (Masami Hiramatsu)
    
     - Fix a segfault when processing a perf.data file with callchains using
       "perf report --call-graph none". (Namhyung Kim)
    
     - Fix unresolved COMMs in 'perf top' when -s comm is used. (Namhyung Kim)
    
     - Register idle thread in 'perf top'. (Namhyung Kim)
    
     - Change 'record.samples' type to unsigned long long, fixing output of
       number of samples in 32-bit architectures. (Yang Shi)
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit fb535ccb30845fe0b7bd09caa37a838985b72ff9
Author: Toshi Kani <toshi.kani@hpe.com>
Date:   Thu Sep 17 12:24:14 2015 -0600

    x86/vdso32: Define PGTABLE_LEVELS to 32bit VDSO
    
    In case of CONFIG_X86_64, vdso32/vclock_gettime.c fakes a 32-bit
    non-PAE kernel configuration by re-defining it to CONFIG_X86_32.
    However, it does not re-define CONFIG_PGTABLE_LEVELS leaving it
    as 4 levels.
    
    This mismatch leads <asm/pgtable_type.h> to NOT include <asm-generic/
    pgtable-nopud.h> and <asm-generic/pgtable-nopmd.h>, which will cause
    compile errors when a later patch enhances <asm/pgtable_type.h> to
    use PUD_SHIFT and PMD_SHIFT.  These -nopud & -nopmd headers define
    these SHIFTs for the 32-bit non-PAE kernel.
    
    Fix it by re-defining CONFIG_PGTABLE_LEVELS to 2 levels.
    
    Signed-off-by: Toshi Kani <toshi.kani@hpe.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Juergen Gross <jgross@suse.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Konrad Wilk <konrad.wilk@oracle.com>
    Cc: Robert Elliot <elliott@hpe.com>
    Cc: linux-mm@kvack.org
    Link: http://lkml.kernel.org/r/1442514264-12475-2-git-send-email-toshi.kani@hpe.com
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 8418031d0806fa49e1732714a44fb41d4b75b60b
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Zefan Li <lizefan@huawei.com>

commit 96efdcf2d080687e041b0353c604b708546689fd
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 11 15:54:56 2015 -0700

    ntp: Do leapsecond adjustment in adjtimex read path
    
    Since the leapsecond is applied at tick-time, this means there is a
    small window of time at the start of a leap-second where we cross into
    the next second before applying the leap.
    
    This patch modified adjtimex so that the leap-second is applied on the
    second edge. Providing more correct leapsecond behavior.
    
    This does make it so that adjtimex()'s returned time values can be
    inconsistent with time values read from gettimeofday() or
    clock_gettime(CLOCK_REALTIME,...)  for a brief period of one tick at
    the leapsecond.  However, those other interfaces do not provide the
    TIME_OOP time_state return that adjtimex() provides, which allows the
    leapsecond to be properly represented. They instead only see a time
    discontinuity, and cannot tell the first 23:59:59 from the repeated
    23:59:59 leap second.
    
    This seems like a reasonable tradeoff given clock_gettime() /
    gettimeofday() cannot properly represent a leapsecond, and users
    likely care more about performance, while folks who are using
    adjtimex() more likely care about leap-second correctness.
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Daniel Bristot de Oliveira <bristot@redhat.com>
    Cc: Richard Cochran <richardcochran@gmail.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Jiri Bohac <jbohac@suse.cz>
    Cc: Ingo Molnar <mingo@kernel.org>
    Link: http://lkml.kernel.org/r/1434063297-28657-5-git-send-email-john.stultz@linaro.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 0c41f396fa25913aa1141c24e0898eee83a5b2bd
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit a3eb97bd80134ba07864ca00747466c02118aca1
Author: Marcelo Tosatti <mtosatti@redhat.com>
Date:   Fri Apr 24 22:36:14 2015 -0300

    x86: kvmclock: drop rdtsc_barrier()
    
    Drop unnecessary rdtsc_barrier(), as has been determined empirically,
    see 057e6a8c660e95c3f4e7162e00e2fee1fc90c50d for details.
    
    Noticed by Andy Lutomirski.
    
    Improves clock_gettime() by approximately 15% on
    Intel i7-3520M @ 2.90GHz.
    
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

commit eda3a683ed0b4f77e5453a8ba85127e72f6bec58
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit 6ec8e4a8302031aa303c56a6541f6f217ce838bf
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Luis Henriques <luis.henriques@canonical.com>

commit ad927769865b3e162266faf215918d4f83f7bb84
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    [ Upstream commit e893286918d2cde3a94850d8f7101cd1039e0c62 ]
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: <stable@vger.kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>

commit ecf99a439105ebd0a507af1a9cd901a2e166bf9a
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Mar 25 19:15:08 2015 +0100

    ARM: 8331/1: VDSO initialization, mapping, and synchronization
    
    Initialize the VDSO page list at boot, install the VDSO mapping at
    exec time, and update the data page during timer ticks.  This code is
    not built if CONFIG_VDSO is not enabled.
    
    Account for the VDSO length when randomizing the offset from the
    stack.  The [vdso] and [vvar] pages are placed immediately following
    the sigpage with separate _install_special_mapping calls.
    
    We want to "penalize" systems lacking the arch timer as little
    as possible.  Previous versions of this code installed the VDSO
    unconditionally and unmodified, making it a measurably slower way for
    glibc to invoke the real syscalls on such systems.  E.g. calling
    gettimeofday via glibc goes from ~560ns to ~630ns on i.MX6Q.
    
    If we can indicate to glibc that the time-related APIs in the VDSO are
    not accelerated, glibc can continue to invoke the syscalls directly
    instead of dispatching through the VDSO only to fall back to the slow
    path.
    
    Thus, if the architected timer is unusable for whatever reason, patch
    the VDSO at boot time so that symbol lookups for gettimeofday and
    clock_gettime return NULL.  (This is similar to what powerpc does and
    borrows code from there.)  This allows glibc to perform the syscall
    directly instead of passing control to the VDSO, which minimizes the
    penalty.  In my measurements the time taken for a gettimeofday call
    via glibc goes from ~560ns to ~580ns (again on i.MX6Q), and this is
    solely due to adding a test and branch to glibc's gettimeofday syscall
    wrapper.
    
    An alternative to patching the VDSO at boot would be to not install
    the VDSO at all when the arch timer isn't usable.  Another alternative
    is to include a separate "dummy" vdso.so without gettimeofday and
    clock_gettime, which would be selected at boot time.  Either of these
    would get cumbersome if the VDSO were to gain support for an API such
    as getcpu which is unrelated to arch timer support.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

commit 8512287a8165592466cb9cb347ba94892e9c56a5
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Mar 25 19:14:22 2015 +0100

    ARM: 8330/1: add VDSO user-space code
    
    Place VDSO-related user-space code in arch/arm/kernel/vdso/.
    
    It is almost completely written in C with some assembly helpers to
    load the data page address, sample the counter, and fall back to
    system calls when necessary.
    
    The VDSO can service gettimeofday and clock_gettime when
    CONFIG_ARM_ARCH_TIMER is enabled and the architected timer is present
    (and correctly configured).  It reads the CP15-based virtual counter
    to compute high-resolution timestamps.
    
    Of particular note is that a post-processing step ("vdsomunge") is
    necessary to produce a shared object which is architecturally allowed
    to be used by both soft- and hard-float EABI programs.
    
    The 2012 edition of the ARM ABI defines Tag_ABI_VFP_args = 3 "Code is
    compatible with both the base and VFP variants; the user did not
    permit non-variadic functions to pass FP parameters/results."
    Unfortunately current toolchains do not support this tag, which is
    ideally what we would use.
    
    The best available option is to ensure that both EF_ARM_ABI_FLOAT_SOFT
    and EF_ARM_ABI_FLOAT_HARD are unset in the ELF header's e_flags,
    indicating that the shared object is "old" and should be accepted for
    backward compatibility's sake.  While binutils < 2.24 appear to
    produce a vdso.so with both flags clear, 2.24 always sets
    EF_ARM_ABI_FLOAT_SOFT, with no way to inhibit this behavior.  So we
    have to fix things up with a custom post-processing step.
    
    In fact, the VDSO code in glibc does much less validation (including
    checking these flags) than the code for handling conventional
    file-backed shared libraries, so this is a bit moot unless glibc's
    VDSO code becomes more strict.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

commit df33f2aeb8963f303f72e891344fde5a7608c3dc
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 99a9adcaf4b58031d8802c266b9166d558415c38
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 427c08dcbc5600c017c1d9d2232d98b78ea982ac
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    commit e893286918d2cde3a94850d8f7101cd1039e0c62 upstream.
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e893286918d2cde3a94850d8f7101cd1039e0c62
Author: Jiri Slaby <jslaby@suse.cz>
Date:   Thu Mar 5 09:13:31 2015 +0100

    x86/vdso: Fix the build on GCC5
    
    On gcc5 the kernel does not link:
    
      ld: .eh_frame_hdr table[4] FDE at 0000000000000648 overlaps table[5] FDE at 0000000000000670.
    
    Because prior GCC versions always emitted NOPs on ALIGN directives, but
    gcc5 started omitting them.
    
    .LSTARTFDEDLSI1 says:
    
            /* HACK: The dwarf2 unwind routines will subtract 1 from the
               return address to get an address in the middle of the
               presumed call instruction.  Since we didn't get here via
               a call, we need to include the nop before the real start
               to make up for it.  */
            .long .LSTART_sigreturn-1-.     /* PC-relative start address */
    
    But commit 69d0627a7f6e ("x86 vDSO: reorder vdso32 code") from 2.6.25
    replaced .org __kernel_vsyscall+32,0x90 by ALIGN right before
    __kernel_sigreturn.
    
    Of course, ALIGN need not generate any NOP in there. Esp. gcc5 collapses
    vclock_gettime.o and int80.o together with no generated NOPs as "ALIGN".
    
    So fix this by adding to that point at least a single NOP and make the
    function ALIGN possibly with more NOPs then.
    
    Kudos for reporting and diagnosing should go to Richard.
    
    Reported-by: Richard Biener <rguenther@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Acked-by: Andy Lutomirski <luto@amacapital.net>
    Cc: <stable@vger.kernel.org>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1425543211-12542-1-git-send-email-jslaby@suse.cz
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit d34696c2208b2dc1b27ec8f0a017a91e4e6eb85d
Merge: f9677375b0c0 61b0b01686d4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Feb 21 11:18:26 2015 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 fixes from Martin Schwidefsky:
     "Two patches to save some memory if CONFIG_NR_CPUS is large, a changed
      default for the use of compare-and-delay, and a couple of bug fixes"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux:
      s390/spinlock: disabled compare-and-delay by default
      s390/mm: align 64-bit PIE binaries to 4GB
      s390/cacheinfo: coding style changes
      s390/cacheinfo: fix shared cpu masks
      s390/smp: reduce size of struct pcpu
      s390/topology: convert cpu_topology array to per cpu variable
      s390/topology: delay initialization of topology cpu masks
      s390/vdso: fix clock_gettime for CLOCK_THREAD_CPUTIME_ID, -2 and -3

commit 6a694a607a97d58c042fb7fbd60ef1caea26950c
Author: Shaohua Li <shli@fb.com>
Date:   Thu Feb 5 15:55:32 2015 -0800

    perf: Update userspace page info for software event
    
    For hardware events, the userspace page of the event gets updated in
    context switches, so if we read the timestamp in the page, we get
    fresh info.
    
    For software events, this is missing currently. This patch makes the
    behavior consistent.
    
    With this patch, we can implement clock_gettime(THREAD_CPUTIME) with
    PERF_COUNT_SW_DUMMY in userspace as suggested by Andy and Peter. Code
    like this:
    
      if (pc->cap_user_time) {
            do {
                    seq = pc->lock;
                    barrier();
    
                    running = pc->time_running;
                    cyc = rdtsc();
                    time_mult = pc->time_mult;
                    time_shift = pc->time_shift;
                    time_offset = pc->time_offset;
    
                    barrier();
            } while (pc->lock != seq);
    
            quot = (cyc >> time_shift);
            rem = cyc & ((1 << time_shift) - 1);
            delta = time_offset + quot * time_mult +
                    ((rem * time_mult) >> time_shift);
    
            running += delta;
            return running;
      }
    
    I tried it on a busy system, the userspace page updating doesn't
    have noticeable overhead.
    
    Signed-off-by: Shaohua Li <shli@fb.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/aa2dd2e4f1e9f2225758be5ba00f14d6909a8ce1.1423180257.git.shli@fb.com
    [ Improved the changelog. ]
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 49253925c0be02ed4eb7d94a426731107dd8059d
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Tue Jan 27 15:15:13 2015 +0100

    s390/vdso: fix clock_gettime for CLOCK_THREAD_CPUTIME_ID, -2 and -3
    
    Git commit 8d8f2e18a6dbd3d09dd918788422e6ac8c878e96
    "s390/vdso: ectg gettime support for CLOCK_THREAD_CPUTIME_ID"
    broke clock_gettime for CLOCK_THREAD_CPUTIME_ID.
    
    Git commit c742b31c03f37c5c499178f09f57381aa6c70131
    "fast vdso implementation for CLOCK_THREAD_CPUTIME_ID"
    introduced the ECTG for clock id -2. Correct would have been
    clock id -3.
    
    Fix the whole mess, CLOCK_THREAD_CPUTIME_ID is based on
    CPUCLOCK_SCHED and can not be speed up by the vdso. A speedup
    is only available for clock id -3 which is CPUCLOCK_VIRT for
    the task currently running on the CPU.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 779cf1d93e1194b041cd139b8e71e0baae4884a6
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Sun Dec 21 08:57:46 2014 -0800

    x86, vdso: Use asm volatile in __getcpu
    
    commit 1ddf0b1b11aa8a90cef6706e935fc31c75c406ba upstream.
    
    In Linux 3.18 and below, GCC hoists the lsl instructions in the
    pvclock code all the way to the beginning of __vdso_clock_gettime,
    slowing the non-paravirt case significantly.  For unknown reasons,
    presumably related to the removal of a branch, the performance issue
    is gone as of
    
    e76b027e6408 x86,vdso: Use LSL unconditionally for vgetcpu
    
    but I don't trust GCC enough to expect the problem to stay fixed.
    
    There should be no correctness issue, because the __getcpu calls in
    __vdso_vlock_gettime were never necessary in the first place.
    
    Note to stable maintainers: In 3.18 and below, depending on
    configuration, gcc 4.9.2 generates code like this:
    
         9c3:       44 0f 03 e8             lsl    %ax,%r13d
         9c7:       45 89 eb                mov    %r13d,%r11d
         9ca:       0f 03 d8                lsl    %ax,%ebx
    
    This patch won't apply as is to any released kernel, but I'll send a
    trivial backported version if needed.
    
    [
     Backported by Andy Lutomirski.  Should apply to all affected
     versions.  This fixes a functionality bug as well as a performance
     bug: buggy kernels can infinite loop in __vdso_clock_gettime on
     affected compilers.  See, for exammple:
    
     https://bugzilla.redhat.com/show_bug.cgi?id=1178975
    ]
    
    Fixes: 51c19b4f5927 x86: vdso: pvclock gettime support
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit ccf8296923d31dd16e9b8857213fa671d1252bb1
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Sun Dec 21 08:57:46 2014 -0800

    x86, vdso: Use asm volatile in __getcpu
    
    commit 1ddf0b1b11aa8a90cef6706e935fc31c75c406ba upstream.
    
    In Linux 3.18 and below, GCC hoists the lsl instructions in the
    pvclock code all the way to the beginning of __vdso_clock_gettime,
    slowing the non-paravirt case significantly.  For unknown reasons,
    presumably related to the removal of a branch, the performance issue
    is gone as of
    
    e76b027e6408 x86,vdso: Use LSL unconditionally for vgetcpu
    
    but I don't trust GCC enough to expect the problem to stay fixed.
    
    There should be no correctness issue, because the __getcpu calls in
    __vdso_vlock_gettime were never necessary in the first place.
    
    Note to stable maintainers: In 3.18 and below, depending on
    configuration, gcc 4.9.2 generates code like this:
    
         9c3:       44 0f 03 e8             lsl    %ax,%r13d
         9c7:       45 89 eb                mov    %r13d,%r11d
         9ca:       0f 03 d8                lsl    %ax,%ebx
    
    This patch won't apply as is to any released kernel, but I'll send a
    trivial backported version if needed.
    
    [
     Backported by Andy Lutomirski.  Should apply to all affected
     versions.  This fixes a functionality bug as well as a performance
     bug: buggy kernels can infinite loop in __vdso_clock_gettime on
     affected compilers.  See, for exammple:
    
     https://bugzilla.redhat.com/show_bug.cgi?id=1178975
    ]
    
    Fixes: 51c19b4f5927 x86: vdso: pvclock gettime support
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 99c8619590d4d44fe51b5ef0542c0edbd844b0b5
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Sun Dec 21 08:57:46 2014 -0800

    x86, vdso: Use asm volatile in __getcpu
    
    commit 1ddf0b1b11aa8a90cef6706e935fc31c75c406ba upstream.
    
    In Linux 3.18 and below, GCC hoists the lsl instructions in the
    pvclock code all the way to the beginning of __vdso_clock_gettime,
    slowing the non-paravirt case significantly.  For unknown reasons,
    presumably related to the removal of a branch, the performance issue
    is gone as of
    
    e76b027e6408 x86,vdso: Use LSL unconditionally for vgetcpu
    
    but I don't trust GCC enough to expect the problem to stay fixed.
    
    There should be no correctness issue, because the __getcpu calls in
    __vdso_vlock_gettime were never necessary in the first place.
    
    Note to stable maintainers: In 3.18 and below, depending on
    configuration, gcc 4.9.2 generates code like this:
    
         9c3:       44 0f 03 e8             lsl    %ax,%r13d
         9c7:       45 89 eb                mov    %r13d,%r11d
         9ca:       0f 03 d8                lsl    %ax,%ebx
    
    This patch won't apply as is to any released kernel, but I'll send a
    trivial backported version if needed.
    
    [
     Backported by Andy Lutomirski.  Should apply to all affected
     versions.  This fixes a functionality bug as well as a performance
     bug: buggy kernels can infinite loop in __vdso_clock_gettime on
     affected compilers.  See, for exammple:
    
     https://bugzilla.redhat.com/show_bug.cgi?id=1178975
    ]
    
    Fixes: 51c19b4f5927 x86: vdso: pvclock gettime support
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 04d98e96a02e24987a53f4a879abeae66440e49a
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Sun Dec 21 08:57:46 2014 -0800

    x86, vdso: Use asm volatile in __getcpu
    
    commit 1ddf0b1b11aa8a90cef6706e935fc31c75c406ba upstream.
    
    In Linux 3.18 and below, GCC hoists the lsl instructions in the
    pvclock code all the way to the beginning of __vdso_clock_gettime,
    slowing the non-paravirt case significantly.  For unknown reasons,
    presumably related to the removal of a branch, the performance issue
    is gone as of
    
    e76b027e6408 x86,vdso: Use LSL unconditionally for vgetcpu
    
    but I don't trust GCC enough to expect the problem to stay fixed.
    
    There should be no correctness issue, because the __getcpu calls in
    __vdso_vlock_gettime were never necessary in the first place.
    
    Note to stable maintainers: In 3.18 and below, depending on
    configuration, gcc 4.9.2 generates code like this:
    
         9c3:       44 0f 03 e8             lsl    %ax,%r13d
         9c7:       45 89 eb                mov    %r13d,%r11d
         9ca:       0f 03 d8                lsl    %ax,%ebx
    
    This patch won't apply as is to any released kernel, but I'll send a
    trivial backported version if needed.
    
    [
     Backported by Andy Lutomirski.  Should apply to all affected
     versions.  This fixes a functionality bug as well as a performance
     bug: buggy kernels can infinite loop in __vdso_clock_gettime on
     affected compilers.  See, for exammple:
    
     https://bugzilla.redhat.com/show_bug.cgi?id=1178975
    ]
    
    Fixes: 51c19b4f5927 x86: vdso: pvclock gettime support
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d1d9e22b05c49e39c5a7edbbe4c932e913fdda5b
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Sun Dec 21 08:57:46 2014 -0800

    x86, vdso: Use asm volatile in __getcpu
    
    commit 1ddf0b1b11aa8a90cef6706e935fc31c75c406ba upstream.
    
    In Linux 3.18 and below, GCC hoists the lsl instructions in the
    pvclock code all the way to the beginning of __vdso_clock_gettime,
    slowing the non-paravirt case significantly.  For unknown reasons,
    presumably related to the removal of a branch, the performance issue
    is gone as of
    
    e76b027e6408 x86,vdso: Use LSL unconditionally for vgetcpu
    
    but I don't trust GCC enough to expect the problem to stay fixed.
    
    There should be no correctness issue, because the __getcpu calls in
    __vdso_vlock_gettime were never necessary in the first place.
    
    Note to stable maintainers: In 3.18 and below, depending on
    configuration, gcc 4.9.2 generates code like this:
    
         9c3:       44 0f 03 e8             lsl    %ax,%r13d
         9c7:       45 89 eb                mov    %r13d,%r11d
         9ca:       0f 03 d8                lsl    %ax,%ebx
    
    This patch won't apply as is to any released kernel, but I'll send a
    trivial backported version if needed.
    
    [
     Backported by Andy Lutomirski.  Should apply to all affected
     versions.  This fixes a functionality bug as well as a performance
     bug: buggy kernels can infinite loop in __vdso_clock_gettime on
     affected compilers.  See, for exammple:
    
     https://bugzilla.redhat.com/show_bug.cgi?id=1178975
    ]
    
    Fixes: 51c19b4f5927 x86: vdso: pvclock gettime support
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    [ luis: backported to 3.16: used Andy's backport for stable kernels ]
    Signed-off-by: Luis Henriques <luis.henriques@canonical.com>

commit f5db310d77ef1742e40bfc303b8625584c55f9e3
Author: Andrey Skvortsov <andrej.skvortzov@gmail.com>
Date:   Wed Jan 7 21:35:54 2015 +0300

    selftests/vm: fix link error for transhuge-stress test
    
    add -lrt to fix undefined reference to `clock_gettime'
    error seen when the test is compiled using gcc 4.6.4.
    
    Signed-off-by: Andrey Skvortsov <andrej.skvortzov@gmail.com>
    Signed-off-by: Shuah Khan <shuahkh@osg.samsung.com>

commit 2aba73a6146bb85d4a42386ca41dec0f4aa4b3ad
Merge: 280dbc572357 1ddf0b1b11aa
Author: Ingo Molnar <mingo@kernel.org>
Date:   Thu Jan 1 22:21:22 2015 +0100

    Merge tag 'pr-20141223-x86-vdso' of git://git.kernel.org/pub/scm/linux/kernel/git/luto/linux into x86/urgent
    
    Pull VDSO fix from Andy Lutomirski:
    
     "This is hopefully the last vdso fix for 3.19.  It should be very
      safe (it just adds a volatile).
    
      I don't think it fixes an actual bug (the __getcpu calls in the
      pvclock code may not have been needed in the first place), but
      discussion on that point is ongoing.
    
      It also fixes a big performance issue in 3.18 and earlier in which
      the lsl instructions in vclock_gettime got hoisted so far up the
      function that they happened even when the function they were in was
      never called.  n 3.19, the performance issue seems to be gone due to
      the whims of my compiler and some interaction with a branch that's
      now gone.
    
      I'll hopefully have a much bigger overhaul of the pvclock code
      for 3.20, but it needs careful review."
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 1ddf0b1b11aa8a90cef6706e935fc31c75c406ba
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Sun Dec 21 08:57:46 2014 -0800

    x86, vdso: Use asm volatile in __getcpu
    
    In Linux 3.18 and below, GCC hoists the lsl instructions in the
    pvclock code all the way to the beginning of __vdso_clock_gettime,
    slowing the non-paravirt case significantly.  For unknown reasons,
    presumably related to the removal of a branch, the performance issue
    is gone as of
    
    e76b027e6408 x86,vdso: Use LSL unconditionally for vgetcpu
    
    but I don't trust GCC enough to expect the problem to stay fixed.
    
    There should be no correctness issue, because the __getcpu calls in
    __vdso_vlock_gettime were never necessary in the first place.
    
    Note to stable maintainers: In 3.18 and below, depending on
    configuration, gcc 4.9.2 generates code like this:
    
         9c3:       44 0f 03 e8             lsl    %ax,%r13d
         9c7:       45 89 eb                mov    %r13d,%r11d
         9ca:       0f 03 d8                lsl    %ax,%ebx
    
    This patch won't apply as is to any released kernel, but I'll send a
    trivial backported version if needed.
    
    Fixes: 51c19b4f5927 x86: vdso: pvclock gettime support
    Cc: stable@vger.kernel.org # 3.8+
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Acked-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>

commit 90e362f4a75d0911ca75e5cd95591a6cf1f169dc
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Sun Nov 23 23:04:52 2014 +0100

    sched: Provide update_curr callbacks for stop/idle scheduling classes
    
    Chris bisected a NULL pointer deference in task_sched_runtime() to
    commit 6e998916dfe3 'sched/cputime: Fix clock_nanosleep()/clock_gettime()
    inconsistency'.
    
    Chris observed crashes in atop or other /proc walking programs when he
    started fork bombs on his machine.  He assumed that this is a new exit
    race, but that does not make any sense when looking at that commit.
    
    What's interesting is that, the commit provides update_curr callbacks
    for all scheduling classes except stop_task and idle_task.
    
    While nothing can ever hit that via the clock_nanosleep() and
    clock_gettime() interfaces, which have been the target of the commit in
    question, the author obviously forgot that there are other code paths
    which invoke task_sched_runtime()
    
    do_task_stat(()
     thread_group_cputime_adjusted()
       thread_group_cputime()
         task_cputime()
           task_sched_runtime()
            if (task_current(rq, p) && task_on_rq_queued(p)) {
              update_rq_clock(rq);
              up->sched_class->update_curr(rq);
            }
    
    If the stats are read for a stomp machine task, aka 'migration/N' and
    that task is current on its cpu, this will happily call the NULL pointer
    of stop_task->update_curr.  Ooops.
    
    Chris observation that this happens faster when he runs the fork bomb
    makes sense as the fork bomb will kick migration threads more often so
    the probability to hit the issue will increase.
    
    Add the missing update_curr callbacks to the scheduler classes stop_task
    and idle_task.  While idle tasks cannot be monitored via /proc we have
    other means to hit the idle case.
    
    Fixes: 6e998916dfe3 'sched/cputime: Fix clock_nanosleep()/clock_gettime() inconsistency'
    Reported-by: Chris Mason <clm@fb.com>
    Reported-and-tested-by: Borislav Petkov <bp@alien8.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 8b2ed21e846c63d8f1bdee0d8df0645721a604a1
Merge: 13f5004c9478 6e998916dfe3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 21 15:44:54 2014 -0800

    Merge branch 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull scheduler fixes from Ingo Molnar:
     "Misc fixes: two NUMA fixes, two cputime fixes and an RCU/lockdep fix"
    
    * 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      sched/cputime: Fix clock_nanosleep()/clock_gettime() inconsistency
      sched/cputime: Fix cpu_timer_sample_group() double accounting
      sched/numa: Avoid selecting oneself as swap target
      sched/numa: Fix out of bounds read in sched_init_numa()
      sched: Remove lockdep check in sched_move_task()

commit 6e998916dfe327e785e7c2447959b2c1a3ea4930
Author: Stanislaw Gruszka <sgruszka@redhat.com>
Date:   Wed Nov 12 16:58:44 2014 +0100

    sched/cputime: Fix clock_nanosleep()/clock_gettime() inconsistency
    
    Commit d670ec13178d0 "posix-cpu-timers: Cure SMP wobbles" fixes one glibc
    test case in cost of breaking another one. After that commit, calling
    clock_nanosleep(TIMER_ABSTIME, X) and then clock_gettime(&Y) can result
    of Y time being smaller than X time.
    
    Reproducer/tester can be found further below, it can be compiled and ran by:
    
            gcc -o tst-cpuclock2 tst-cpuclock2.c -pthread
            while ./tst-cpuclock2 ; do : ; done
    
    This reproducer, when running on a buggy kernel, will complain
    about "clock_gettime difference too small".
    
    Issue happens because on start in thread_group_cputimer() we initialize
    sum_exec_runtime of cputimer with threads runtime not yet accounted and
    then add the threads runtime to running cputimer again on scheduler
    tick, making it's sum_exec_runtime bigger than actual threads runtime.
    
    KOSAKI Motohiro posted a fix for this problem, but that patch was never
    applied: https://lkml.org/lkml/2013/5/26/191 .
    
    This patch takes different approach to cure the problem. It calls
    update_curr() when cputimer starts, that assure we will have updated
    stats of running threads and on the next schedule tick we will account
    only the runtime that elapsed from cputimer start. That also assure we
    have consistent state between cpu times of individual threads and cpu
    time of the process consisted by those threads.
    
    Full reproducer (tst-cpuclock2.c):
    
            #define _GNU_SOURCE
            #include <unistd.h>
            #include <sys/syscall.h>
            #include <stdio.h>
            #include <time.h>
            #include <pthread.h>
            #include <stdint.h>
            #include <inttypes.h>
    
            /* Parameters for the Linux kernel ABI for CPU clocks.  */
            #define CPUCLOCK_SCHED          2
            #define MAKE_PROCESS_CPUCLOCK(pid, clock) \
                    ((~(clockid_t) (pid) << 3) | (clockid_t) (clock))
    
            static pthread_barrier_t barrier;
    
            /* Help advance the clock.  */
            static void *chew_cpu(void *arg)
            {
                    pthread_barrier_wait(&barrier);
                    while (1) ;
    
                    return NULL;
            }
    
            /* Don't use the glibc wrapper.  */
            static int do_nanosleep(int flags, const struct timespec *req)
            {
                    clockid_t clock_id = MAKE_PROCESS_CPUCLOCK(0, CPUCLOCK_SCHED);
    
                    return syscall(SYS_clock_nanosleep, clock_id, flags, req, NULL);
            }
    
            static int64_t tsdiff(const struct timespec *before, const struct timespec *after)
            {
                    int64_t before_i = before->tv_sec * 1000000000ULL + before->tv_nsec;
                    int64_t after_i = after->tv_sec * 1000000000ULL + after->tv_nsec;
    
                    return after_i - before_i;
            }
    
            int main(void)
            {
                    int result = 0;
                    pthread_t th;
    
                    pthread_barrier_init(&barrier, NULL, 2);
    
                    if (pthread_create(&th, NULL, chew_cpu, NULL) != 0) {
                            perror("pthread_create");
                            return 1;
                    }
    
                    pthread_barrier_wait(&barrier);
    
                    /* The test.  */
                    struct timespec before, after, sleeptimeabs;
                    int64_t sleepdiff, diffabs;
                    const struct timespec sleeptime = {.tv_sec = 0,.tv_nsec = 100000000 };
    
                    /* The relative nanosleep.  Not sure why this is needed, but its presence
                       seems to make it easier to reproduce the problem.  */
                    if (do_nanosleep(0, &sleeptime) != 0) {
                            perror("clock_nanosleep");
                            return 1;
                    }
    
                    /* Get the current time.  */
                    if (clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &before) < 0) {
                            perror("clock_gettime[2]");
                            return 1;
                    }
    
                    /* Compute the absolute sleep time based on the current time.  */
                    uint64_t nsec = before.tv_nsec + sleeptime.tv_nsec;
                    sleeptimeabs.tv_sec = before.tv_sec + nsec / 1000000000;
                    sleeptimeabs.tv_nsec = nsec % 1000000000;
    
                    /* Sleep for the computed time.  */
                    if (do_nanosleep(TIMER_ABSTIME, &sleeptimeabs) != 0) {
                            perror("absolute clock_nanosleep");
                            return 1;
                    }
    
                    /* Get the time after the sleep.  */
                    if (clock_gettime(CLOCK_PROCESS_CPUTIME_ID, &after) < 0) {
                            perror("clock_gettime[3]");
                            return 1;
                    }
    
                    /* The time after sleep should always be equal to or after the absolute sleep
                       time passed to clock_nanosleep.  */
                    sleepdiff = tsdiff(&sleeptimeabs, &after);
                    if (sleepdiff < 0) {
                            printf("absolute clock_nanosleep woke too early: %" PRId64 "\n", sleepdiff);
                            result = 1;
    
                            printf("Before %llu.%09llu\n", before.tv_sec, before.tv_nsec);
                            printf("After  %llu.%09llu\n", after.tv_sec, after.tv_nsec);
                            printf("Sleep  %llu.%09llu\n", sleeptimeabs.tv_sec, sleeptimeabs.tv_nsec);
                    }
    
                    /* The difference between the timestamps taken before and after the
                       clock_nanosleep call should be equal to or more than the duration of the
                       sleep.  */
                    diffabs = tsdiff(&before, &after);
                    if (diffabs < sleeptime.tv_nsec) {
                            printf("clock_gettime difference too small: %" PRId64 "\n", diffabs);
                            result = 1;
                    }
    
                    pthread_cancel(th);
    
                    return result;
            }
    
    Signed-off-by: Stanislaw Gruszka <sgruszka@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/20141112155843.GA24803@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit e92ce12ed6a46302f64269d2d406cf04525f0a8f
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Fri Oct 31 16:51:38 2014 +0900

    perf tools: Add gzip decompression support for kernel module
    
    Now my Archlinux box shows module symbols correctly.
    
    Before:
      $ perf report --stdio
      Failed to open /tmp/perf-3477.map, continuing without symbols
      no symbols found in /usr/bin/date, maybe install a debug package?
      No kallsyms or vmlinux with build-id 7b4ea0a49ae2111925857099aaf05c3246ff33e0 was found
      [drm] with build id 7b4ea0a49ae2111925857099aaf05c3246ff33e0 not found, continuing without symbols
      No kallsyms or vmlinux with build-id edd931629094b660ca9dec09a1b635c8d87aa2ee was found
      [jbd2] with build id edd931629094b660ca9dec09a1b635c8d87aa2ee not found, continuing without symbols
      No kallsyms or vmlinux with build-id a7b1eada671c34933e5610bb920b2ca4945a82c3 was found
      [ext4] with build id a7b1eada671c34933e5610bb920b2ca4945a82c3 not found, continuing without symbols
      No kallsyms or vmlinux with build-id d69511fa3e5840e770336ef45b06c83fef8d74e3 was found
      [scsi_mod] with build id d69511fa3e5840e770336ef45b06c83fef8d74e3 not found, continuing without symbols
      No kallsyms or vmlinux with build-id af0430af13461af058770ee9b87afc07922c2e77 was found
      [libata] with build id af0430af13461af058770ee9b87afc07922c2e77 not found, continuing without symbols
      No kallsyms or vmlinux with build-id aaeedff8160ce631a5f0333591c6ff291201d29f was found
      [libahci] with build id aaeedff8160ce631a5f0333591c6ff291201d29f not found, continuing without symbols
      No kallsyms or vmlinux with build-id c57907712becaf662dc4981824bb372c0441d605 was found
      [mac80211] with build id c57907712becaf662dc4981824bb372c0441d605 not found, continuing without symbols
      No kallsyms or vmlinux with build-id e0589077cc0ec8c3e4c40eb9f2d9e69d236bee8f was found
      [iwldvm] with build id e0589077cc0ec8c3e4c40eb9f2d9e69d236bee8f not found, continuing without symbols
      No kallsyms or vmlinux with build-id 2d86086bf136bf374a2f029cf85a48194f9b950b was found
      [cfg80211] with build id 2d86086bf136bf374a2f029cf85a48194f9b950b not found, continuing without symbols
      No kallsyms or vmlinux with build-id 4493c48599bdb3d91d0f8db5150e0be33fdd9221 was found
      [iwlwifi] with build id 4493c48599bdb3d91d0f8db5150e0be33fdd9221 not found, continuing without symbols
      ...
      #
      # Overhead  Command          Shared Object            Symbol
      # ........  ...............  .......................  ........................................................
      #
           0.03%  swapper          [ext4]                   [k] 0x000000000000fe2e
           0.03%  swapper          [kernel.kallsyms]        [k] account_entity_enqueue
           0.03%  swapper          [ext4]                   [k] 0x000000000000fc2b
           0.03%  irq/50-iwlwifi   [iwlwifi]                [k] 0x000000000000200b
           0.03%  swapper          [kernel.kallsyms]        [k] ktime_add_safe
           0.03%  swapper          [kernel.kallsyms]        [k] elv_completed_request
           0.03%  swapper          [libata]                 [k] 0x0000000000003997
           0.03%  swapper          [libahci]                [k] 0x0000000000001f25
           0.03%  swapper          [kernel.kallsyms]        [k] rb_next
           0.03%  swapper          [kernel.kallsyms]        [k] blk_finish_request
           0.03%  swapper          [ext4]                   [k] 0x0000000000010248
           0.00%  perf             [kernel.kallsyms]        [k] native_write_msr_safe
    
    After:
      $ perf report --stdio
      Failed to open /tmp/perf-3477.map, continuing without symbols
      no symbols found in /usr/bin/tr, maybe install a debug package?
      ...
      #
      # Overhead  Command          Shared Object                Symbol
      # ........  ...............  ...........................  ......................................................
      #
    
           0.04%  kworker/u16:3    [ext4]                       [k] ext4_read_block_bitmap
           0.03%  kworker/u16:0    [mac80211]                   [k] ieee80211_sta_reset_beacon_monitor
           0.02%  irq/50-iwlwifi   [mac80211]                   [k] ieee80211_get_bssid
           0.02%  firefox          [e1000e]                     [k] __ew32_prepare
           0.02%  swapper          [libahci]                    [k] ahci_handle_port_interrupt
           0.02%  emacs            libglib-2.0.so.0.4000.0      [.] g_mutex_unlock
           0.02%  swapper          [e1000e]                     [k] e1000_clean_tx_irq
           0.02%  dwm              [kernel.kallsyms]            [k] __schedule
           0.02%  gnome-terminal-  [vdso]                       [.] __vdso_clock_gettime
           0.02%  swapper          [e1000e]                     [k] e1000_alloc_rx_buffers
           0.02%  irq/50-iwlwifi   [mac80211]                   [k] ieee80211_rx
           0.01%  firefox          [vdso]                       [.] __vdso_gettimeofday
           0.01%  irq/50-iwlwifi   [iwlwifi]                    [k] iwl_pcie_rxq_restock.part.13
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Namhyung Kim <namhyung.kim@lge.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/87h9yexshi.fsf@sejong.aot.lge.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit f8e4fae2e79d2d293fc490ede87be44c9b215d9e
Merge: 6325e940e7e0 78410af51146
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 8 05:36:23 2014 -0400

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/cmetcalf/linux-tile
    
    Pull arch/tile updates from Chris Metcalf:
     "The only substantive pieces in this batch are some more vDSO support,
      and removing the reference to &platform_bus in tile-srom.c.
    
      The rest are minor issues reported to me"
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/cmetcalf/linux-tile:
      tile: add clock_gettime support to vDSO
      tile: switch to using seqlocks for the vDSO time code
      tile gxio: use better string copy primitive
      char: tile-srom: Add real platform bus parent
      Removed repeated word in comments
      tilegx: Enable ARCH_SUPPORTS_ATOMIC_RMW
      tile: Remove tile-specific _sinitdata and _einitdata
      tile: use ARRAY_SIZE

commit 78410af51146796f783925009c8676a30d6c6d90
Author: Chris Metcalf <cmetcalf@tilera.com>
Date:   Thu Oct 2 10:32:15 2014 -0400

    tile: add clock_gettime support to vDSO
    
    This change adds support for clock_gettime with CLOCK_REALTIME
    and CLOCK_MONOTONIC using vDSO.  It also updates the vdso
    struct nomenclature used for the clocks to match the x86 code
    to keep it easier to update going forward.
    
    We also support the *_COARSE clockid_t, for apps that want speed
    but aren't concerned about fine-grained timestamps; this saves
    about 20 cycles per call (see http://lwn.net/Articles/342018/).
    
    Signed-off-by: Chris Metcalf <cmetcalf@tilera.com>
    Acked-by: John Stultz <john.stultz@linaro.org>

commit 070b7be633dc33c0899e8c934b4d5fad046b06e8
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Aug 29 12:44:40 2014 +0200

    s390/vdso: replace stck with stcke
    
    If gettimeofday / clock_gettime are called multiple times in a row
    the STCK instruction will stall until a difference in the result is
    visible. This unnecessarily slows down the vdso calls, use stcke
    instead of stck to get rid of the stall.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 35af25616c6c0c42416545f732d36b2ba7199519
Merge: d030671f3f26 5da76157a4b7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 8 08:27:00 2014 -0700

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 fixes from Martin Schwidefsky:
     "A bug fix for the vdso code, the loadparm for booting from SCSI is
      added and the access permissions for the dasd module parameters are
      corrected"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux:
      s390/vdso: remove NULL pointer check from clock_gettime
      s390/ipl: Add missing SCSI loadparm attributes to /sys/firmware
      s390/dasd: Make module parameter visible in sysfs

commit e78c3496790ee8a36522a838b59b388e8a709e65
Author: Rik van Riel <riel@redhat.com>
Date:   Sat Aug 16 13:40:10 2014 -0400

    time, signal: Protect resource use statistics with seqlock
    
    Both times() and clock_gettime(CLOCK_PROCESS_CPUTIME_ID) have scalability
    issues on large systems, due to both functions being serialized with a
    lock.
    
    The lock protects against reporting a wrong value, due to a thread in the
    task group exiting, its statistics reporting up to the signal struct, and
    that exited task's statistics being counted twice (or not at all).
    
    Protecting that with a lock results in times() and clock_gettime() being
    completely serialized on large systems.
    
    This can be fixed by using a seqlock around the events that gather and
    propagate statistics. As an additional benefit, the protection code can
    be moved into thread_group_cputime(), slightly simplifying the calling
    functions.
    
    In the case of posix_cpu_clock_get_task() things can be simplified a
    lot, because the calling function already ensures that the task sticks
    around, and the rest is now taken care of in thread_group_cputime().
    
    This way the statistics reporting code can run lockless.
    
    Signed-off-by: Rik van Riel <riel@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alex Thorlton <athorlton@sgi.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Daeseok Youn <daeseok.youn@gmail.com>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Dongsheng Yang <yangds.fnst@cn.fujitsu.com>
    Cc: Geert Uytterhoeven <geert@linux-m68k.org>
    Cc: Guillaume Morin <guillaume@morinfr.org>
    Cc: Ionut Alexa <ionut.m.alexa@gmail.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Michal Schmidt <mschmidt@redhat.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Cc: umgwanakikbuti@gmail.com
    Cc: fweisbec@gmail.com
    Cc: srao@redhat.com
    Cc: lwoodman@redhat.com
    Cc: atheurer@redhat.com
    Link: http://lkml.kernel.org/r/20140816134010.26a9b572@annuminas.surriel.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 5da76157a4b7d5f595c846cf5e95f6d085b350e2
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Aug 29 10:16:03 2014 +0200

    s390/vdso: remove NULL pointer check from clock_gettime
    
    The explicit NULL pointer check on the timespec argument is only
    required for clock_getres but not for clock_gettime.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 4036ac1567834222fc763ab18e3e17df93b4eaaf
Author: Mike Galbraith <umgwanakikbuti@gmail.com>
Date:   Tue Jun 24 07:49:40 2014 +0200

    sched: Fix clock_gettime(CLOCK_[PROCESS/THREAD]_CPUTIME_ID) monotonicity
    
    If a task has been dequeued, it has been accounted.  Do not project
    cycles that may or may not ever be accounted to a dequeued task, as
    that may make clock_gettime() both inaccurate and non-monotonic.
    
    Protect update_rq_clock() from slight TSC skew while at it.
    
    Signed-off-by: Mike Galbraith <umgwanakikbuti@gmail.com>
    Cc: kosaki.motohiro@jp.fujitsu.com
    Cc: pjt@google.com
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/1403588980.29711.11.camel@marge.simpson.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 46b57a76930f01ebf31230ed35af5beeccb5ad95
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Tue Jun 24 13:46:52 2014 -0700

    x86/vdso: Move DISABLE_BRANCH_PROFILING into the vdso makefile
    
    DISABLE_BRANCH_PROFILING turns off branch profiling (i.e. a
    redefinition of 'if').  Branch profiling depends on a bunch of
    kernel-internal symbols and generates extra output sections, none of
    which are useful or functional in the vDSO.
    
    It's currently turned off for vclock_gettime.c, but vgetcpu.c also
    triggers branch profiling, so just turn it off in the makefile.
    
    This fixes the build on some configurations: the vdso could contain
    undefined symbols, and the fake section table overflowed due to
    ftrace's added sections.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Link: http://lkml.kernel.org/r/bf1ec29e03b2bbc081f6dcaefa64db1c3a83fb21.1403642755.git.luto@amacapital.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit f01b3751f964df3266ed9e52b1676ff52a91b60f
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Dec 2 18:00:36 2013 +0100

    s390/time,vdso: fix clock_gettime for CLOCK_MONOTONIC
    
    commit ca5de58ba746b08c920b2024aaf01aa1500b110d upstream.
    
    With git commit 79c74ecbebf76732f91b82a62ce7fc8a88326962
    "s390/time,vdso: convert to the new update_vsyscall interface"
    the new update_vsyscall function already does the sum of xtime
    and wall_to_monotonic. The old update_vsyscall function only
    copied the wall_to_monotonic offset. The vdso code needs to be
    modified to take this into consideration.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit c6f21243ce1e8d81ad8361da4d2eaa5947b667c4
Merge: 9447dc43941c 37c975545ec6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Apr 2 12:26:43 2014 -0700

    Merge branch 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull x86 vdso changes from Peter Anvin:
     "This is the revamp of the 32-bit vdso and the associated cleanups.
    
      This adds timekeeping support to the 32-bit vdso that we already have
      in the 64-bit vdso.  Although 32-bit x86 is legacy, it is likely to
      remain in the embedded space for a very long time to come.
    
      This removes the traditional COMPAT_VDSO support; the configuration
      variable is reused for simply removing the 32-bit vdso, which will
      produce correct results but obviously suffer a performance penalty.
      Only one beta version of glibc was affected, but that version was
      unfortunately included in one OpenSUSE release.
    
      This is not the end of the vdso cleanups.  Stefani and Andy have
      agreed to continue work for the next kernel cycle; in fact Andy has
      already produced another set of cleanups that came too late for this
      cycle.
    
      An incidental, but arguably important, change is that this ensures
      that unused space in the VVAR page is properly zeroed.  It wasn't
      before, and would contain whatever garbage was left in memory by BIOS
      or the bootloader.  Since the VVAR page is accessible to user space
      this had the potential of information leaks"
    
    * 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (23 commits)
      x86, vdso: Fix the symbol versions on the 32-bit vDSO
      x86, vdso, build: Don't rebuild 32-bit vdsos on every make
      x86, vdso: Actually discard the .discard sections
      x86, vdso: Fix size of get_unmapped_area()
      x86, vdso: Finish removing VDSO32_PRELINK
      x86, vdso: Move more vdso definitions into vdso.h
      x86: Load the 32-bit vdso in place, just like the 64-bit vdsos
      x86, vdso32: handle 32 bit vDSO larger one page
      x86, vdso32: Disable stack protector, adjust optimizations
      x86, vdso: Zero-pad the VVAR page
      x86, vdso: Add 32 bit VDSO time support for 64 bit kernel
      x86, vdso: Add 32 bit VDSO time support for 32 bit kernel
      x86, vdso: Patch alternatives in the 32-bit VDSO
      x86, vdso: Introduce VVAR marco for vdso32
      x86, vdso: Cleanup __vdso_gettimeofday()
      x86, vdso: Replace VVAR(vsyscall_gtod_data) by gtod macro
      x86, vdso: __vdso_clock_gettime() cleanup
      x86, vdso: Revamp vclock_gettime.c
      mm: Add new func _install_special_mapping() to mmap.c
      x86, vdso: Make vsyscall_gtod_data handling x86 generic
      ...

commit b9a4a56c1e5c72eac92d18aa48250a8c965632be
Author: Andy Lutomirski <luto@amacapital.net>
Date:   Tue Mar 25 16:25:53 2014 -0700

    x86, vdso, build: Don't rebuild 32-bit vdsos on every make
    
    vdso32/vclock_gettime.o was confusing kbuild.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Cc: Stefani Seibold <stefani@seibold.net>
    Link: http://lkml.kernel.org/r/d741449340642213744dd659471a35bb970a0c4c.1395789923.git.luto@amacapital.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit ce39c64028a075d14af32bfb8336bfe1370c0443
Author: Stefani Seibold <stefani@seibold.net>
Date:   Mon Mar 17 23:22:04 2014 +0100

    x86, vdso: __vdso_clock_gettime() cleanup
    
    This patch is a small code cleanup for the __vdso_clock_gettime() function.
    
    It removes the unneeded return values from do_monotonic_coarse() and
    do_realtime_coarse() and add a fallback label for doing the kernel
    gettimeofday() system call.
    
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Stefani Seibold <stefani@seibold.net>
    Link: http://lkml.kernel.org/r/1395094933-14252-5-git-send-email-stefani@seibold.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit 411f790cd7e91fac0db80d3cf789cb6deeac298e
Author: Stefani Seibold <stefani@seibold.net>
Date:   Mon Mar 17 23:22:03 2014 +0100

    x86, vdso: Revamp vclock_gettime.c
    
    This intermediate patch revamps the vclock_gettime.c by moving some functions
    around. It is only for spliting purpose, to make whole the 32 bit vdso timer
    patch easier to review.
    
    Reviewed-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: Stefani Seibold <stefani@seibold.net>
    Link: http://lkml.kernel.org/r/1395094933-14252-4-git-send-email-stefani@seibold.net
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit e1a6db9c9503479d7c28c2662b3895b68a7e96ed
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Nov 22 10:04:53 2013 +0100

    s390/time,vdso: convert to the new update_vsyscall interface
    
    commit 79c74ecbebf76732f91b82a62ce7fc8a88326962 upstream.
    
    Switch to the improved update_vsyscall interface that provides
    sub-nanosecond precision for gettimeofday and clock_gettime.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit d8cec633b0488655ac324684d4cf53e312bcdf41
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Feb 5 05:53:04 2014 +0000

    arm64: vdso: fix coarse clock handling
    
    commit 069b918623e1510e58dacf178905a72c3baa3ae4 upstream.
    
    When __kernel_clock_gettime is called with a CLOCK_MONOTONIC_COARSE or
    CLOCK_REALTIME_COARSE clock id, it returns incorrectly to whatever the
    caller has placed in x2 ("ret x2" to return from the fast path).  Fix
    this by saving x30/LR to x2 only in code that will call
    __do_get_tspec, restoring x30 afterward, and using a plain "ret" to
    return from the routine.
    
    Also: while the resulting tv_nsec value for CLOCK_REALTIME and
    CLOCK_MONOTONIC must be computed using intermediate values that are
    left-shifted by cs_shift (x12, set by __do_get_tspec), the results for
    coarse clocks should be calculated using unshifted values
    (xtime_coarse_nsec is in units of actual nanoseconds).  The current
    code shifts intermediate values by x12 unconditionally, but x12 is
    uninitialized when servicing a coarse clock.  Fix this by setting x12
    to 0 once we know we are dealing with a coarse clock id.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 61cdf59100deb76fc299ee8ad1fb4c9cda4ce011
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Feb 5 05:53:04 2014 +0000

    arm64: vdso: fix coarse clock handling
    
    commit 069b918623e1510e58dacf178905a72c3baa3ae4 upstream.
    
    When __kernel_clock_gettime is called with a CLOCK_MONOTONIC_COARSE or
    CLOCK_REALTIME_COARSE clock id, it returns incorrectly to whatever the
    caller has placed in x2 ("ret x2" to return from the fast path).  Fix
    this by saving x30/LR to x2 only in code that will call
    __do_get_tspec, restoring x30 afterward, and using a plain "ret" to
    return from the routine.
    
    Also: while the resulting tv_nsec value for CLOCK_REALTIME and
    CLOCK_MONOTONIC must be computed using intermediate values that are
    left-shifted by cs_shift (x12, set by __do_get_tspec), the results for
    coarse clocks should be calculated using unshifted values
    (xtime_coarse_nsec is in units of actual nanoseconds).  The current
    code shifts intermediate values by x12 unconditionally, but x12 is
    uninitialized when servicing a coarse clock.  Fix this by setting x12
    to 0 once we know we are dealing with a coarse clock id.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fb569d15d867a06e89b1be8278404b6fbf6b5bde
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Feb 5 05:53:04 2014 +0000

    arm64: vdso: fix coarse clock handling
    
    commit 069b918623e1510e58dacf178905a72c3baa3ae4 upstream.
    
    When __kernel_clock_gettime is called with a CLOCK_MONOTONIC_COARSE or
    CLOCK_REALTIME_COARSE clock id, it returns incorrectly to whatever the
    caller has placed in x2 ("ret x2" to return from the fast path).  Fix
    this by saving x30/LR to x2 only in code that will call
    __do_get_tspec, restoring x30 afterward, and using a plain "ret" to
    return from the routine.
    
    Also: while the resulting tv_nsec value for CLOCK_REALTIME and
    CLOCK_MONOTONIC must be computed using intermediate values that are
    left-shifted by cs_shift (x12, set by __do_get_tspec), the results for
    coarse clocks should be calculated using unshifted values
    (xtime_coarse_nsec is in units of actual nanoseconds).  The current
    code shifts intermediate values by x12 unconditionally, but x12 is
    uninitialized when servicing a coarse clock.  Fix this by setting x12
    to 0 once we know we are dealing with a coarse clock id.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 069b918623e1510e58dacf178905a72c3baa3ae4
Author: Nathan Lynch <nathan_lynch@mentor.com>
Date:   Wed Feb 5 05:53:04 2014 +0000

    arm64: vdso: fix coarse clock handling
    
    When __kernel_clock_gettime is called with a CLOCK_MONOTONIC_COARSE or
    CLOCK_REALTIME_COARSE clock id, it returns incorrectly to whatever the
    caller has placed in x2 ("ret x2" to return from the fast path).  Fix
    this by saving x30/LR to x2 only in code that will call
    __do_get_tspec, restoring x30 afterward, and using a plain "ret" to
    return from the routine.
    
    Also: while the resulting tv_nsec value for CLOCK_REALTIME and
    CLOCK_MONOTONIC must be computed using intermediate values that are
    left-shifted by cs_shift (x12, set by __do_get_tspec), the results for
    coarse clocks should be calculated using unshifted values
    (xtime_coarse_nsec is in units of actual nanoseconds).  The current
    code shifts intermediate values by x12 unconditionally, but x12 is
    uninitialized when servicing a coarse clock.  Fix this by setting x12
    to 0 once we know we are dealing with a coarse clock id.
    
    Signed-off-by: Nathan Lynch <nathan_lynch@mentor.com>
    Acked-by: Will Deacon <will.deacon@arm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

commit ae1bef09a739c7b1eaef7f18297c87cee6c0e690
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Mon Oct 14 17:33:16 2013 -0400

    alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
    
    commit 98d6f4dd84a134d942827584a3c5f67ffd8ec35f upstream.
    
    Fedora Ruby maintainer reported latest Ruby doesn't work on Fedora Rawhide
    on ARM. (http://bugs.ruby-lang.org/issues/9008)
    
    Because of, commit 1c6b39ad3f (alarmtimers: Return -ENOTSUPP if no
    RTC device is present) intruduced to return ENOTSUPP when
    clock_get{time,res} can't find a RTC device. However this is incorrect.
    
    First, ENOTSUPP isn't exported to userland (ENOTSUP or EOPNOTSUP are the
    closest userland equivlents).
    
    Second, Posix and Linux man pages agree that clock_gettime and
    clock_getres should return EINVAL if clk_id argument is invalid.
    While the arugment that the clockid is valid, but just not supported
    on this hardware could be made, this is just a technicality that
    doesn't help userspace applicaitons, and only complicates error
    handling.
    
    Thus, this patch changes the code to use EINVAL.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Reported-by: Vit Ondruch <v.ondruch@tiscali.cz>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    [jstultz: Tweaks to commit message to include full rational]
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 22056614ee39ef43670814d2000f810901768277
Merge: 17b2112f332d ca5de58ba746
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 10 11:02:33 2013 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 fixes from Martin Schwidefsky:
     "One patch to increase the number of possible CPUs to 256, with the
      latest machine a single LPAR can have up to 101 CPUs.  Plus a number
      of bug fixes, the clock_gettime patch fixes a regression added in the
      3.13 merge window"
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux:
      s390/time,vdso: fix clock_gettime for CLOCK_MONOTONIC
      s390/vdso: ectg gettime support for CLOCK_THREAD_CPUTIME_ID
      s390/vdso: fix access-list entry initialization
      s390: increase CONFIG_NR_CPUS limit
      s390/smp,sclp: fix size of sclp_cpu_info structure
      s390/sclp: replace uninitialized early_event_mask_sccb variable with sccb_early
      s390/dasd: fix memory leak caused by dangling references to request_queue

commit 33ab0fec33527e8b5ab124cff6aefd4746508e04
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Oct 11 17:41:11 2013 +0200

    posix-timers: Consolidate posix_cpu_clock_get()
    
    Consolidate the clock sampling common code used for both local
    and remote targets.
    
    Note that this introduces a tiny user ABI change: if a
    PID is passed to clock_gettime() along the clockid,
    we used to forbid a process wide clock sample when that
    PID doesn't belong to a group leader. Now after this patch
    we allow process wide clock samples if that PID belongs to
    the current task, even if the current task is not the
    group leader.
    
    But local process wide clock samples are allowed if PID == 0
    (current task) even if the current task is not the group leader.
    So in the end this should be no big deal as this actually harmonize
    the behaviour when the remote sample is actually a local one.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Kosaki Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>

commit a9a18cf66c99d3f797e8b89cff6d6240dc6fd97e
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Mon Oct 14 17:33:16 2013 -0400

    alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
    
    commit 98d6f4dd84a134d942827584a3c5f67ffd8ec35f upstream.
    
    Fedora Ruby maintainer reported latest Ruby doesn't work on Fedora Rawhide
    on ARM. (http://bugs.ruby-lang.org/issues/9008)
    
    Because of, commit 1c6b39ad3f (alarmtimers: Return -ENOTSUPP if no
    RTC device is present) intruduced to return ENOTSUPP when
    clock_get{time,res} can't find a RTC device. However this is incorrect.
    
    First, ENOTSUPP isn't exported to userland (ENOTSUP or EOPNOTSUP are the
    closest userland equivlents).
    
    Second, Posix and Linux man pages agree that clock_gettime and
    clock_getres should return EINVAL if clk_id argument is invalid.
    While the arugment that the clockid is valid, but just not supported
    on this hardware could be made, this is just a technicality that
    doesn't help userspace applicaitons, and only complicates error
    handling.
    
    Thus, this patch changes the code to use EINVAL.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Reported-by: Vit Ondruch <v.ondruch@tiscali.cz>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    [jstultz: Tweaks to commit message to include full rational]
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4501cfd0e3a1c06e5539c9f806866f8408232393
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Mon Oct 14 17:33:16 2013 -0400

    alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
    
    commit 98d6f4dd84a134d942827584a3c5f67ffd8ec35f upstream.
    
    Fedora Ruby maintainer reported latest Ruby doesn't work on Fedora Rawhide
    on ARM. (http://bugs.ruby-lang.org/issues/9008)
    
    Because of, commit 1c6b39ad3f (alarmtimers: Return -ENOTSUPP if no
    RTC device is present) intruduced to return ENOTSUPP when
    clock_get{time,res} can't find a RTC device. However this is incorrect.
    
    First, ENOTSUPP isn't exported to userland (ENOTSUP or EOPNOTSUP are the
    closest userland equivlents).
    
    Second, Posix and Linux man pages agree that clock_gettime and
    clock_getres should return EINVAL if clk_id argument is invalid.
    While the arugment that the clockid is valid, but just not supported
    on this hardware could be made, this is just a technicality that
    doesn't help userspace applicaitons, and only complicates error
    handling.
    
    Thus, this patch changes the code to use EINVAL.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Reported-by: Vit Ondruch <v.ondruch@tiscali.cz>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    [jstultz: Tweaks to commit message to include full rational]
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e05092412210f3a298ef2a4e5f58857513e9954
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Mon Oct 14 17:33:16 2013 -0400

    alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
    
    commit 98d6f4dd84a134d942827584a3c5f67ffd8ec35f upstream.
    
    Fedora Ruby maintainer reported latest Ruby doesn't work on Fedora Rawhide
    on ARM. (http://bugs.ruby-lang.org/issues/9008)
    
    Because of, commit 1c6b39ad3f (alarmtimers: Return -ENOTSUPP if no
    RTC device is present) intruduced to return ENOTSUPP when
    clock_get{time,res} can't find a RTC device. However this is incorrect.
    
    First, ENOTSUPP isn't exported to userland (ENOTSUP or EOPNOTSUP are the
    closest userland equivlents).
    
    Second, Posix and Linux man pages agree that clock_gettime and
    clock_getres should return EINVAL if clk_id argument is invalid.
    While the arugment that the clockid is valid, but just not supported
    on this hardware could be made, this is just a technicality that
    doesn't help userspace applicaitons, and only complicates error
    handling.
    
    Thus, this patch changes the code to use EINVAL.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Reported-by: Vit Ondruch <v.ondruch@tiscali.cz>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    [jstultz: Tweaks to commit message to include full rational]
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ca5de58ba746b08c920b2024aaf01aa1500b110d
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Mon Dec 2 18:00:36 2013 +0100

    s390/time,vdso: fix clock_gettime for CLOCK_MONOTONIC
    
    With git commit 79c74ecbebf76732f91b82a62ce7fc8a88326962
    "s390/time,vdso: convert to the new update_vsyscall interface"
    the new update_vsyscall function already does the sum of xtime
    and wall_to_monotonic. The old update_vsyscall function only
    copied the wall_to_monotonic offset. The vdso code needs to be
    modified to take this into consideration.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 79c74ecbebf76732f91b82a62ce7fc8a88326962
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Nov 22 10:04:53 2013 +0100

    s390/time,vdso: convert to the new update_vsyscall interface
    
    Switch to the improved update_vsyscall interface that provides
    sub-nanosecond precision for gettimeofday and clock_gettime.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 98d6f4dd84a134d942827584a3c5f67ffd8ec35f
Author: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
Date:   Mon Oct 14 17:33:16 2013 -0400

    alarmtimer: return EINVAL instead of ENOTSUPP if rtcdev doesn't exist
    
    Fedora Ruby maintainer reported latest Ruby doesn't work on Fedora Rawhide
    on ARM. (http://bugs.ruby-lang.org/issues/9008)
    
    Because of, commit 1c6b39ad3f (alarmtimers: Return -ENOTSUPP if no
    RTC device is present) intruduced to return ENOTSUPP when
    clock_get{time,res} can't find a RTC device. However this is incorrect.
    
    First, ENOTSUPP isn't exported to userland (ENOTSUP or EOPNOTSUP are the
    closest userland equivlents).
    
    Second, Posix and Linux man pages agree that clock_gettime and
    clock_getres should return EINVAL if clk_id argument is invalid.
    While the arugment that the clockid is valid, but just not supported
    on this hardware could be made, this is just a technicality that
    doesn't help userspace applicaitons, and only complicates error
    handling.
    
    Thus, this patch changes the code to use EINVAL.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: stable <stable@vger.kernel.org>  #3.0 and up
    Reported-by: Vit Ondruch <v.ondruch@tiscali.cz>
    Signed-off-by: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    [jstultz: Tweaks to commit message to include full rational]
    Signed-off-by: John Stultz <john.stultz@linaro.org>

commit 4f8c1b74c5fdac35ee4480685d42030446724848
Author: David Ahern <dsahern@gmail.com>
Date:   Sun Sep 22 19:45:00 2013 -0600

    perf trace: Add beautifier for clock_gettime's clk_id argument
    
    Before:
    0.030 ( 0.002 ms): 2571 clock_gettime(which_clock: 1, tp: 0x7f3b45729cd0 ) = 0
    
    After:
    0.030 ( 0.002 ms): 2571 clock_gettime(which_clock: MONOTONIC, tp: 0x7f3b45729cd0 ) = 0
    
    v2: Update to use the STRARRAY option
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Stephane Eranian <eranian@google.com>
    Link: http://lkml.kernel.org/r/1379900700-5186-6-git-send-email-dsahern@gmail.com
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit ff8b1fdc4aefc77d12f776b967aea8e2e0143949
Author: Peter Hurley <peter@hurleysoftware.com>
Date:   Wed Feb 27 15:28:28 2013 -0500

    x86/kvm: Fix pvclock vsyscall fixmap
    
    commit 3d2a80a230250c2534ce5b17503670adaf1d7fff upstream.
    
    The physical memory fixmapped for the pvclock clock_gettime vsyscall
    was allocated, and thus is not a kernel symbol. __pa() is the proper
    method to use in this case.
    
    Fixes the crash below when booting a next-20130204+ smp guest on a
    3.8-rc5+ KVM host.
    
    [    0.666410] udevd[97]: starting version 175
    [    0.674043] udevd[97]: udevd:[97]: segfault at ffffffffff5fd020
         ip 00007fff069e277f sp 00007fff068c9ef8 error d
    
    Acked-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Peter Hurley <peter@hurleysoftware.com>
    Signed-off-by: Gleb Natapov <gleb@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4622b3b7c0269bd2da531ea5949cadff98522da9
Author: Steffen Trumtrar <s.trumtrar@pengutronix.de>
Date:   Wed Jan 30 14:16:00 2013 +0100

    ARM: i.MX25: clk: parent per5_clk to AHB clock
    
    commit 4b526ca5f627188425184a22ed46c91baa602d43 upstream.
    
    The mxc-timer on the imx25 needs to be derived from the AHB clock.
    If a bootloader reparents this clock to the ipg_clk_highfreq, which according
    to the datasheet is a valid operation, the system can/will produce lockups/
    freezes after some time [1].
    
    This can be forced with code like
            while(1)
                    syscall(SYS_clock_gettime, CLOCK_REALTIME, &tp);
    
    This was already fixed with the commit
            "i.MX25 GPT clock fix: ensure correct the clock source" [2],
    for 3.1-rc2, but was lost, when i.MX was converted to the common clock framework
    ("ARM i.MX25: implement clocks using common clock framework") [3]
    
    [1]: http://lists.arm.linux.org.uk/lurker/message/20130129.161230.229bda17.en.html
    [2]: 2012d9ca2a1381ae3e733330a7f0d1d2f1988bba
    [3]: 6bbaec5676e4f475b0d78743cbd4c70a8804ce14
    
    Signed-off-by: Steffen Trumtrar <s.trumtrar@pengutronix.de>
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3d2a80a230250c2534ce5b17503670adaf1d7fff
Author: Peter Hurley <peter@hurleysoftware.com>
Date:   Wed Feb 27 15:28:28 2013 -0500

    x86/kvm: Fix pvclock vsyscall fixmap
    
    The physical memory fixmapped for the pvclock clock_gettime vsyscall
    was allocated, and thus is not a kernel symbol. __pa() is the proper
    method to use in this case.
    
    Fixes the crash below when booting a next-20130204+ smp guest on a
    3.8-rc5+ KVM host.
    
    [    0.666410] udevd[97]: starting version 175
    [    0.674043] udevd[97]: udevd:[97]: segfault at ffffffffff5fd020
         ip 00007fff069e277f sp 00007fff068c9ef8 error d
    
    Acked-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Peter Hurley <peter@hurleysoftware.com>
    Signed-off-by: Gleb Natapov <gleb@redhat.com>

commit 4b526ca5f627188425184a22ed46c91baa602d43
Author: Steffen Trumtrar <s.trumtrar@pengutronix.de>
Date:   Wed Jan 30 14:16:00 2013 +0100

    ARM: i.MX25: clk: parent per5_clk to AHB clock
    
    The mxc-timer on the imx25 needs to be derived from the AHB clock.
    If a bootloader reparents this clock to the ipg_clk_highfreq, which according
    to the datasheet is a valid operation, the system can/will produce lockups/
    freezes after some time [1].
    
    This can be forced with code like
            while(1)
                    syscall(SYS_clock_gettime, CLOCK_REALTIME, &tp);
    
    This was already fixed with the commit
            "i.MX25 GPT clock fix: ensure correct the clock source" [2],
    for 3.1-rc2, but was lost, when i.MX was converted to the common clock framework
    ("ARM i.MX25: implement clocks using common clock framework") [3]
    
    [1]: http://lists.arm.linux.org.uk/lurker/message/20130129.161230.229bda17.en.html
    [2]: 2012d9ca2a1381ae3e733330a7f0d1d2f1988bba
    [3]: 6bbaec5676e4f475b0d78743cbd4c70a8804ce14
    
    Signed-off-by: Steffen Trumtrar <s.trumtrar@pengutronix.de>
    Cc: stable@vger.kernel.org # v3.5+
    Signed-off-by: Sascha Hauer <s.hauer@pengutronix.de>

commit 7806334afcaf4f0352a9c6f813264f5ef27d00f9
Author: Hector Palacios <hector.palacios@digi.com>
Date:   Mon Nov 14 11:15:25 2011 +0100

    timekeeping: add arch_offset hook to ktime_get functions
    
    commit d004e024058a0eaca097513ce62cbcf978913e0a upstream.
    
    ktime_get and ktime_get_ts were calling timekeeping_get_ns()
    but later they were not calling arch_gettimeoffset() so architectures
    using this mechanism returned 0 ns when calling these functions.
    
    This happened for example when running Busybox's ping which calls
    syscall(__NR_clock_gettime, CLOCK_MONOTONIC, ts) which eventually
    calls ktime_get. As a result the returned ping travel time was zero.
    
    Signed-off-by: Hector Palacios <hector.palacios@digi.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

commit b6908c5824b42966d700c10a9c4241b5f82119e1
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Nov 7 10:44:08 2012 +0100

    s390/signal: set correct address space control
    
    commit fa968ee215c0ca91e4a9c3a69ac2405aae6e5d2f upstream.
    
    If user space is running in primary mode it can switch to secondary
    or access register mode, this is used e.g. in the clock_gettime code
    of the vdso. If a signal is delivered to the user space process while
    it has been running in access register mode the signal handler is
    executed in access register mode as well which will result in a crash
    most of the time.
    
    Set the address space control bits in the PSW to the default for the
    execution of the signal handler and make sure that the previous
    address space control is restored on signal return. Take care
    that user space can not switch to the kernel address space by
    modifying the registers in the signal frame.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    [bwh: Backported to 3.2:
     - Adjust filename
     - The RI bit is not included in PSW_MASK_USER]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit f84a935db47d7f261c025ba9eaa7700261257469
Author: Will Deacon <will.deacon@arm.com>
Date:   Thu Nov 29 22:11:51 2012 +0000

    arm64: vdso: check sequence counter even for coarse realtime operations
    
    When returning coarse realtime values from clock_gettime, we must still
    check the sequence counter to ensure that the kernel does not update
    the vdso datapage whilst we are loading the coarse timespec as this
    could potentially result in time appearing to go backwards.
    
    This patch delays the coarse realtime check until after we have loaded
    successfully from the vdso datapage. This does mean that we always load
    the wtm timespec, but conditionalising the load and adding an extra
    sequence test is unlikely to buy us anything other than messy code,
    particularly as the sequence test implies a read barrier.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

commit 38efab61680204d6f7cedfbacdc211ab1cfe0806
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Nov 7 10:44:08 2012 +0100

    s390/signal: set correct address space control
    
    commit fa968ee215c0ca91e4a9c3a69ac2405aae6e5d2f upstream.
    
    If user space is running in primary mode it can switch to secondary
    or access register mode, this is used e.g. in the clock_gettime code
    of the vdso. If a signal is delivered to the user space process while
    it has been running in access register mode the signal handler is
    executed in access register mode as well which will result in a crash
    most of the time.
    
    Set the address space control bits in the PSW to the default for the
    execution of the signal handler and make sure that the previous
    address space control is restored on signal return. Take care
    that user space can not switch to the kernel address space by
    modifying the registers in the signal frame.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 37a42f991f36aae9b064bc3f39b760006bd17131
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Nov 7 10:44:08 2012 +0100

    s390/signal: set correct address space control
    
    commit fa968ee215c0ca91e4a9c3a69ac2405aae6e5d2f upstream.
    
    If user space is running in primary mode it can switch to secondary
    or access register mode, this is used e.g. in the clock_gettime code
    of the vdso. If a signal is delivered to the user space process while
    it has been running in access register mode the signal handler is
    executed in access register mode as well which will result in a crash
    most of the time.
    
    Set the address space control bits in the PSW to the default for the
    execution of the signal handler and make sure that the previous
    address space control is restored on signal return. Take care
    that user space can not switch to the kernel address space by
    modifying the registers in the signal frame.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 62735e5231e2de4c491c7cd52f83ce0fe64b4c36
Merge: 7279d7cb529b ae289dc1f474
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 16 07:39:30 2012 -0800

    Merge branch 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux
    
    Pull s390 patches from Martin Schwidefsky:
     "Some more bug fixes and a config change.
    
      The signal bug is nasty, if the clock_gettime vdso function is
      interrupted by a signal while in access-register-mode we end up with
      an endless signal loop until the signal stack is full.  The config
      change is for aligned struct pages, gives us 8% improvement with
      hackbench."
    
    * 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/s390/linux:
      s390/3215: fix tty close handling
      s390/mm: have 16 byte aligned struct pages
      s390/gup: fix access_ok() usage in __get_user_pages_fast()
      s390/gup: add missing TASK_SIZE check to get_user_pages_fast()
      s390/topology: fix core id vs physical package id mix-up
      s390/signal: set correct address space control

commit fa968ee215c0ca91e4a9c3a69ac2405aae6e5d2f
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Wed Nov 7 10:44:08 2012 +0100

    s390/signal: set correct address space control
    
    If user space is running in primary mode it can switch to secondary
    or access register mode, this is used e.g. in the clock_gettime code
    of the vdso. If a signal is delivered to the user space process while
    it has been running in access register mode the signal handler is
    executed in access register mode as well which will result in a crash
    most of the time.
    
    Set the address space control bits in the PSW to the default for the
    execution of the signal handler and make sure that the previous
    address space control is restored on signal return. Take care
    that user space can not switch to the kernel address space by
    modifying the registers in the signal frame.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit bcd550745fc54f789c14e7526e0633222c505faa
Merge: 93f378883cec 646783a38982
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 29 14:16:48 2012 -0700

    Merge branch 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull timer core updates from Thomas Gleixner.
    
    * 'timers-core-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      ia64: vsyscall: Add missing paranthesis
      alarmtimer: Don't call rtc_timer_init() when CONFIG_RTC_CLASS=n
      x86: vdso: Put declaration before code
      x86-64: Inline vdso clock_gettime helpers
      x86-64: Simplify and optimize vdso clock_gettime monotonic variants
      kernel-time: fix s/then/than/ spelling errors
      time: remove no_sync_cmos_clock
      time: Avoid scary backtraces when warning of > 11% adj
      alarmtimer: Make sure we initialize the rtctimer
      ntp: Fix leap-second hrtimer livelock
      x86, tsc: Skip refined tsc calibration on systems with reliable TSC
      rtc: Provide flag for rtc devices that don't support UIE
      ia64: vsyscall: Use seqcount instead of seqlock
      x86: vdso: Use seqcount instead of seqlock
      x86: vdso: Remove bogus locking in update_vsyscall_tz()
      time: Remove bogus comments
      time: Fix change_clocksource locking
      time: x86: Fix race switching from vsyscall to non-vsyscall clock

commit 5f293474c4c6c4dc2baaf2dfd486748b5986de76
Author: Andy Lutomirski <luto@mit.edu>
Date:   Thu Mar 22 21:15:52 2012 -0700

    x86-64: Inline vdso clock_gettime helpers
    
    This is about a 3% speedup on Sandy Bridge.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

commit 91ec87d57fc38c529034e853687dfb7756de5406
Author: Andy Lutomirski <luto@mit.edu>
Date:   Thu Mar 22 21:15:51 2012 -0700

    x86-64: Simplify and optimize vdso clock_gettime monotonic variants
    
    We used to store the wall-to-monotonic offset and the realtime base.
    It's faster to precompute the monotonic base.
    
    This is about a 3% speedup on Sandy Bridge for CLOCK_MONOTONIC.
    It's much more impressive for CLOCK_MONOTONIC_COARSE.
    
    Signed-off-by: Andy Lutomirski <luto@amacapital.net>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

commit 5c3e9f55bbd366af73e51a12e1aa797a29532d67
Author: Hector Palacios <hector.palacios@digi.com>
Date:   Mon Nov 14 11:15:25 2011 +0100

    timekeeping: add arch_offset hook to ktime_get functions
    
    commit d004e024058a0eaca097513ce62cbcf978913e0a upstream.
    
    ktime_get and ktime_get_ts were calling timekeeping_get_ns()
    but later they were not calling arch_gettimeoffset() so architectures
    using this mechanism returned 0 ns when calling these functions.
    
    This happened for example when running Busybox's ping which calls
    syscall(__NR_clock_gettime, CLOCK_MONOTONIC, ts) which eventually
    calls ktime_get. As a result the returned ping travel time was zero.
    
    Signed-off-by: Hector Palacios <hector.palacios@digi.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 92ad5083db212ff3c5f6d1d085d85790f7a6c42c
Author: Hector Palacios <hector.palacios@digi.com>
Date:   Mon Nov 14 11:15:25 2011 +0100

    timekeeping: add arch_offset hook to ktime_get functions
    
    commit d004e024058a0eaca097513ce62cbcf978913e0a upstream.
    
    ktime_get and ktime_get_ts were calling timekeeping_get_ns()
    but later they were not calling arch_gettimeoffset() so architectures
    using this mechanism returned 0 ns when calling these functions.
    
    This happened for example when running Busybox's ping which calls
    syscall(__NR_clock_gettime, CLOCK_MONOTONIC, ts) which eventually
    calls ktime_get. As a result the returned ping travel time was zero.
    
    Signed-off-by: Hector Palacios <hector.palacios@digi.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit e1ef77bdad527601e9e47b377cbef5bee9df8248
Author: Hector Palacios <hector.palacios@digi.com>
Date:   Mon Nov 14 11:15:25 2011 +0100

    timekeeping: add arch_offset hook to ktime_get functions
    
    commit d004e024058a0eaca097513ce62cbcf978913e0a upstream.
    
    ktime_get and ktime_get_ts were calling timekeeping_get_ns()
    but later they were not calling arch_gettimeoffset() so architectures
    using this mechanism returned 0 ns when calling these functions.
    
    This happened for example when running Busybox's ping which calls
    syscall(__NR_clock_gettime, CLOCK_MONOTONIC, ts) which eventually
    calls ktime_get. As a result the returned ping travel time was zero.
    
    Signed-off-by: Hector Palacios <hector.palacios@digi.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit d004e024058a0eaca097513ce62cbcf978913e0a
Author: Hector Palacios <hector.palacios@digi.com>
Date:   Mon Nov 14 11:15:25 2011 +0100

    timekeeping: add arch_offset hook to ktime_get functions
    
    ktime_get and ktime_get_ts were calling timekeeping_get_ns()
    but later they were not calling arch_gettimeoffset() so architectures
    using this mechanism returned 0 ns when calling these functions.
    
    This happened for example when running Busybox's ping which calls
    syscall(__NR_clock_gettime, CLOCK_MONOTONIC, ts) which eventually
    calls ktime_get. As a result the returned ping travel time was zero.
    
    CC: stable@kernel.org
    Signed-off-by: Hector Palacios <hector.palacios@digi.com>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

commit 249cf808ba1a0d403fe7c476a74b66e2bc0a8e53
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Sep 1 12:42:04 2011 +0200

    posix-cpu-timers: Cure SMP wobbles
    
    commit d670ec13178d0fd8680e6742a2bc6e04f28f87d8 upstream.
    
    David reported:
    
      Attached below is a watered-down version of rt/tst-cpuclock2.c from
      GLIBC.  Just build it with "gcc -o test test.c -lpthread -lrt" or
      similar.
    
      Run it several times, and you will see cases where the main thread
      will measure a process clock difference before and after the nanosleep
      which is smaller than the cpu-burner thread's individual thread clock
      difference.  This doesn't make any sense since the cpu-burner thread
      is part of the top-level process's thread group.
    
      I've reproduced this on both x86-64 and sparc64 (using both 32-bit and
      64-bit binaries).
    
      For example:
    
      [davem@boricha build-x86_64-linux]$ ./test
      process: before(0.001221967) after(0.498624371) diff(497402404)
      thread:  before(0.000081692) after(0.498316431) diff(498234739)
      self:    before(0.001223521) after(0.001240219) diff(16698)
      [davem@boricha build-x86_64-linux]$
    
      The diff of 'process' should always be >= the diff of 'thread'.
    
      I make sure to wrap the 'thread' clock measurements the most tightly
      around the nanosleep() call, and that the 'process' clock measurements
      are the outer-most ones.
    
      ---
      #include <unistd.h>
      #include <stdio.h>
      #include <stdlib.h>
      #include <time.h>
      #include <fcntl.h>
      #include <string.h>
      #include <errno.h>
      #include <pthread.h>
    
      static pthread_barrier_t barrier;
    
      static void *chew_cpu(void *arg)
      {
              pthread_barrier_wait(&barrier);
              while (1)
                      __asm__ __volatile__("" : : : "memory");
              return NULL;
      }
    
      int main(void)
      {
              clockid_t process_clock, my_thread_clock, th_clock;
              struct timespec process_before, process_after;
              struct timespec me_before, me_after;
              struct timespec th_before, th_after;
              struct timespec sleeptime;
              unsigned long diff;
              pthread_t th;
              int err;
    
              err = clock_getcpuclockid(0, &process_clock);
              if (err)
                      return 1;
    
              err = pthread_getcpuclockid(pthread_self(), &my_thread_clock);
              if (err)
                      return 1;
    
              pthread_barrier_init(&barrier, NULL, 2);
              err = pthread_create(&th, NULL, chew_cpu, NULL);
              if (err)
                      return 1;
    
              err = pthread_getcpuclockid(th, &th_clock);
              if (err)
                      return 1;
    
              pthread_barrier_wait(&barrier);
    
              err = clock_gettime(process_clock, &process_before);
              if (err)
                      return 1;
    
              err = clock_gettime(my_thread_clock, &me_before);
              if (err)
                      return 1;
    
              err = clock_gettime(th_clock, &th_before);
              if (err)
                      return 1;
    
              sleeptime.tv_sec = 0;
              sleeptime.tv_nsec = 500000000;
              nanosleep(&sleeptime, NULL);
    
              err = clock_gettime(th_clock, &th_after);
              if (err)
                      return 1;
    
              err = clock_gettime(my_thread_clock, &me_after);
              if (err)
                      return 1;
    
              err = clock_gettime(process_clock, &process_after);
              if (err)
                      return 1;
    
              diff = process_after.tv_nsec - process_before.tv_nsec;
              printf("process: before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     process_before.tv_sec, process_before.tv_nsec,
                     process_after.tv_sec, process_after.tv_nsec, diff);
              diff = th_after.tv_nsec - th_before.tv_nsec;
              printf("thread:  before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     th_before.tv_sec, th_before.tv_nsec,
                     th_after.tv_sec, th_after.tv_nsec, diff);
              diff = me_after.tv_nsec - me_before.tv_nsec;
              printf("self:    before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     me_before.tv_sec, me_before.tv_nsec,
                     me_after.tv_sec, me_after.tv_nsec, diff);
    
              return 0;
      }
    
    This is due to us using p->se.sum_exec_runtime in
    thread_group_cputime() where we iterate the thread group and sum all
    data. This does not take time since the last schedule operation (tick
    or otherwise) into account. We can cure this by using
    task_sched_runtime() at the cost of having to take locks.
    
    This also means we can (and must) do away with
    thread_group_sched_runtime() since the modified thread_group_cputime()
    is now more accurate and would deadlock when called from
    thread_group_sched_runtime().
    
    Aside of that it makes the function safe on 32 bit systems. The old
    code added t->se.sum_exec_runtime unprotected. sum_exec_runtime is a
    64bit value and could be changed on another cpu at the same time.
    
    Reported-by: David Miller <davem@davemloft.net>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1314874459.7945.22.camel@twins
    Tested-by: David Miller <davem@davemloft.net>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit d670ec13178d0fd8680e6742a2bc6e04f28f87d8
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Sep 1 12:42:04 2011 +0200

    posix-cpu-timers: Cure SMP wobbles
    
    David reported:
    
      Attached below is a watered-down version of rt/tst-cpuclock2.c from
      GLIBC.  Just build it with "gcc -o test test.c -lpthread -lrt" or
      similar.
    
      Run it several times, and you will see cases where the main thread
      will measure a process clock difference before and after the nanosleep
      which is smaller than the cpu-burner thread's individual thread clock
      difference.  This doesn't make any sense since the cpu-burner thread
      is part of the top-level process's thread group.
    
      I've reproduced this on both x86-64 and sparc64 (using both 32-bit and
      64-bit binaries).
    
      For example:
    
      [davem@boricha build-x86_64-linux]$ ./test
      process: before(0.001221967) after(0.498624371) diff(497402404)
      thread:  before(0.000081692) after(0.498316431) diff(498234739)
      self:    before(0.001223521) after(0.001240219) diff(16698)
      [davem@boricha build-x86_64-linux]$
    
      The diff of 'process' should always be >= the diff of 'thread'.
    
      I make sure to wrap the 'thread' clock measurements the most tightly
      around the nanosleep() call, and that the 'process' clock measurements
      are the outer-most ones.
    
      ---
      #include <unistd.h>
      #include <stdio.h>
      #include <stdlib.h>
      #include <time.h>
      #include <fcntl.h>
      #include <string.h>
      #include <errno.h>
      #include <pthread.h>
    
      static pthread_barrier_t barrier;
    
      static void *chew_cpu(void *arg)
      {
              pthread_barrier_wait(&barrier);
              while (1)
                      __asm__ __volatile__("" : : : "memory");
              return NULL;
      }
    
      int main(void)
      {
              clockid_t process_clock, my_thread_clock, th_clock;
              struct timespec process_before, process_after;
              struct timespec me_before, me_after;
              struct timespec th_before, th_after;
              struct timespec sleeptime;
              unsigned long diff;
              pthread_t th;
              int err;
    
              err = clock_getcpuclockid(0, &process_clock);
              if (err)
                      return 1;
    
              err = pthread_getcpuclockid(pthread_self(), &my_thread_clock);
              if (err)
                      return 1;
    
              pthread_barrier_init(&barrier, NULL, 2);
              err = pthread_create(&th, NULL, chew_cpu, NULL);
              if (err)
                      return 1;
    
              err = pthread_getcpuclockid(th, &th_clock);
              if (err)
                      return 1;
    
              pthread_barrier_wait(&barrier);
    
              err = clock_gettime(process_clock, &process_before);
              if (err)
                      return 1;
    
              err = clock_gettime(my_thread_clock, &me_before);
              if (err)
                      return 1;
    
              err = clock_gettime(th_clock, &th_before);
              if (err)
                      return 1;
    
              sleeptime.tv_sec = 0;
              sleeptime.tv_nsec = 500000000;
              nanosleep(&sleeptime, NULL);
    
              err = clock_gettime(th_clock, &th_after);
              if (err)
                      return 1;
    
              err = clock_gettime(my_thread_clock, &me_after);
              if (err)
                      return 1;
    
              err = clock_gettime(process_clock, &process_after);
              if (err)
                      return 1;
    
              diff = process_after.tv_nsec - process_before.tv_nsec;
              printf("process: before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     process_before.tv_sec, process_before.tv_nsec,
                     process_after.tv_sec, process_after.tv_nsec, diff);
              diff = th_after.tv_nsec - th_before.tv_nsec;
              printf("thread:  before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     th_before.tv_sec, th_before.tv_nsec,
                     th_after.tv_sec, th_after.tv_nsec, diff);
              diff = me_after.tv_nsec - me_before.tv_nsec;
              printf("self:    before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     me_before.tv_sec, me_before.tv_nsec,
                     me_after.tv_sec, me_after.tv_nsec, diff);
    
              return 0;
      }
    
    This is due to us using p->se.sum_exec_runtime in
    thread_group_cputime() where we iterate the thread group and sum all
    data. This does not take time since the last schedule operation (tick
    or otherwise) into account. We can cure this by using
    task_sched_runtime() at the cost of having to take locks.
    
    This also means we can (and must) do away with
    thread_group_sched_runtime() since the modified thread_group_cputime()
    is now more accurate and would deadlock when called from
    thread_group_sched_runtime().
    
    Aside of that it makes the function safe on 32 bit systems. The old
    code added t->se.sum_exec_runtime unprotected. sum_exec_runtime is a
    64bit value and could be changed on another cpu at the same time.
    
    Reported-by: David Miller <davem@davemloft.net>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: stable@kernel.org
    Link: http://lkml.kernel.org/r/1314874459.7945.22.camel@twins
    Tested-by: David Miller <davem@davemloft.net>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit e8abccb719377af63cb0f1fed289db405e3def16
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Sep 1 12:42:04 2011 +0200

    posix-cpu-timers: Cure SMP accounting oddities
    
    David reported:
    
      Attached below is a watered-down version of rt/tst-cpuclock2.c from
      GLIBC.  Just build it with "gcc -o test test.c -lpthread -lrt" or
      similar.
    
      Run it several times, and you will see cases where the main thread
      will measure a process clock difference before and after the nanosleep
      which is smaller than the cpu-burner thread's individual thread clock
      difference.  This doesn't make any sense since the cpu-burner thread
      is part of the top-level process's thread group.
    
      I've reproduced this on both x86-64 and sparc64 (using both 32-bit and
      64-bit binaries).
    
      For example:
    
      [davem@boricha build-x86_64-linux]$ ./test
      process: before(0.001221967) after(0.498624371) diff(497402404)
      thread:  before(0.000081692) after(0.498316431) diff(498234739)
      self:    before(0.001223521) after(0.001240219) diff(16698)
      [davem@boricha build-x86_64-linux]$
    
      The diff of 'process' should always be >= the diff of 'thread'.
    
      I make sure to wrap the 'thread' clock measurements the most tightly
      around the nanosleep() call, and that the 'process' clock measurements
      are the outer-most ones.
    
      ---
      #include <unistd.h>
      #include <stdio.h>
      #include <stdlib.h>
      #include <time.h>
      #include <fcntl.h>
      #include <string.h>
      #include <errno.h>
      #include <pthread.h>
    
      static pthread_barrier_t barrier;
    
      static void *chew_cpu(void *arg)
      {
              pthread_barrier_wait(&barrier);
              while (1)
                      __asm__ __volatile__("" : : : "memory");
              return NULL;
      }
    
      int main(void)
      {
              clockid_t process_clock, my_thread_clock, th_clock;
              struct timespec process_before, process_after;
              struct timespec me_before, me_after;
              struct timespec th_before, th_after;
              struct timespec sleeptime;
              unsigned long diff;
              pthread_t th;
              int err;
    
              err = clock_getcpuclockid(0, &process_clock);
              if (err)
                      return 1;
    
              err = pthread_getcpuclockid(pthread_self(), &my_thread_clock);
              if (err)
                      return 1;
    
              pthread_barrier_init(&barrier, NULL, 2);
              err = pthread_create(&th, NULL, chew_cpu, NULL);
              if (err)
                      return 1;
    
              err = pthread_getcpuclockid(th, &th_clock);
              if (err)
                      return 1;
    
              pthread_barrier_wait(&barrier);
    
              err = clock_gettime(process_clock, &process_before);
              if (err)
                      return 1;
    
              err = clock_gettime(my_thread_clock, &me_before);
              if (err)
                      return 1;
    
              err = clock_gettime(th_clock, &th_before);
              if (err)
                      return 1;
    
              sleeptime.tv_sec = 0;
              sleeptime.tv_nsec = 500000000;
              nanosleep(&sleeptime, NULL);
    
              err = clock_gettime(th_clock, &th_after);
              if (err)
                      return 1;
    
              err = clock_gettime(my_thread_clock, &me_after);
              if (err)
                      return 1;
    
              err = clock_gettime(process_clock, &process_after);
              if (err)
                      return 1;
    
              diff = process_after.tv_nsec - process_before.tv_nsec;
              printf("process: before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     process_before.tv_sec, process_before.tv_nsec,
                     process_after.tv_sec, process_after.tv_nsec, diff);
              diff = th_after.tv_nsec - th_before.tv_nsec;
              printf("thread:  before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     th_before.tv_sec, th_before.tv_nsec,
                     th_after.tv_sec, th_after.tv_nsec, diff);
              diff = me_after.tv_nsec - me_before.tv_nsec;
              printf("self:    before(%lu.%.9lu) after(%lu.%.9lu) diff(%lu)\n",
                     me_before.tv_sec, me_before.tv_nsec,
                     me_after.tv_sec, me_after.tv_nsec, diff);
    
              return 0;
      }
    
    This is due to us using p->se.sum_exec_runtime in
    thread_group_cputime() where we iterate the thread group and sum all
    data. This does not take time since the last schedule operation (tick
    or otherwise) into account. We can cure this by using
    task_sched_runtime() at the cost of having to take locks.
    
    This also means we can (and must) do away with
    thread_group_sched_runtime() since the modified thread_group_cputime()
    is now more accurate and would deadlock when called from
    thread_group_sched_runtime().
    
    Reported-by: David Miller <davem@davemloft.net>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1314874459.7945.22.camel@twins
    Cc: stable@kernel.org
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 1c6b39ad3f01514fd8dd84b5b412bafb75c19388
Author: John Stultz <john.stultz@linaro.org>
Date:   Thu Jun 16 18:47:37 2011 -0700

    alarmtimers: Return -ENOTSUPP if no RTC device is present
    
    Toralf Förster and Richard Weinberger noted that if there is
    no RTC device, the alarm timers core prints out an annoying
    "ALARM timers will not wake from suspend" message.
    
    This warning has been removed in a previous patch, however
    the issue still remains:  The original idea was to support
    alarm timers even if there was no rtc device, as long as the
    system didn't go into suspend.
    
    However, after further consideration, communicating to the application
    that alarmtimers are not fully functional seems like the better
    solution.
    
    So this patch makes it so we return -ENOTSUPP to any posix _ALARM
    clockid calls if there is no backing RTC device on the system.
    
    Further this changes the behavior where when there is no rtc device
    we will check for one on clock_getres, clock_gettime, timer_create,
    and timer_nsleep instead of on suspend.
    
    CC: Toralf Förster <toralf.foerster@gmx.de>
    CC: Richard Weinberger <richard@nod.at
    CC: Peter Zijlstra <peterz@infradead.org>
    CC: Thomas Gleixner <tglx@linutronix.de>
    Reported-by: Toralf Förster <toralf.foerster@gmx.de>
    Reported by: Richard Weinberger <richard@nod.at>
    Signed-off-by: John Stultz <john.stultz@linaro.org>

commit 14587a2a25447813996e6fb9e48d48627cb75a5d
Merge: fce637e392a7 e9d35946c84c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu May 26 12:19:31 2011 -0700

    Merge branch 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'x86-vdso-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      x86: vdso: Remove unused variable
      x86-64: Optimize vDSO time()
      x86-64: Add time to vDSO
      x86-64: Turn off -pg and turn on -foptimize-sibling-calls for vDSO
      x86-64: Move vread_tsc into a new file with sensible options
      x86-64: Vclock_gettime(CLOCK_MONOTONIC) can't ever see nsec < 0
      x86-64: Don't generate cmov in vread_tsc
      x86-64: Remove unnecessary barrier in vread_tsc
      x86-64: Clean up vdso/kernel shared variables

commit 0f51f2852ccf0fe38a02d340d0ba625e8e32a863
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Mon May 23 09:31:27 2011 -0400

    x86-64: Vclock_gettime(CLOCK_MONOTONIC) can't ever see nsec < 0
    
    vclock_gettime's do_monotonic helper can't ever generate a negative
    nsec value, so it doesn't need to check whether it's negative.  In
    the CLOCK_MONOTONIC_COARSE case, ns can't ever exceed 2e9-1, so we
    can avoid the loop entirely.  This saves a single easily-predicted
    branch.
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Borislav Petkov <bp@amd64.org>
    Link: http://lkml.kernel.org/r/%3Cd6d528d32c7a21618057cfc9005942a0fe5cb54a.1306156808.git.luto%40mit.edu%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 057e6a8c660e95c3f4e7162e00e2fee1fc90c50d
Author: Andy Lutomirski <luto@MIT.EDU>
Date:   Mon May 23 09:31:25 2011 -0400

    x86-64: Remove unnecessary barrier in vread_tsc
    
    RDTSC is completely unordered on modern Intel and AMD CPUs.  The
    Intel manual says that lfence;rdtsc causes all previous instructions
    to complete before the tsc is read, and the AMD manual says to use
    mfence;rdtsc to do the same thing.
    
    From a decent amount of testing [1] this is enough to make rdtsc
    be ordered with respect to subsequent loads across a wide variety
    of CPUs.
    
    On Sandy Bridge (i7-2600), this improves a loop of
    clock_gettime(CLOCK_MONOTONIC) by more than 5 ns/iter.
    
    [1] https://lkml.org/lkml/2011/4/18/350
    
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Borislav Petkov <bp@amd64.org>
    Link: http://lkml.kernel.org/r/%3C1c158b9d74338aa5361f96dd473d0e6a58235302.1306156808.git.luto%40mit.edu%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 1791f881435fab951939ad700e947b66c062e083
Author: Richard Cochran <richardcochran@gmail.com>
Date:   Wed Mar 30 15:24:21 2011 +0200

    posix clocks: Replace mutex with reader/writer semaphore
    
    A dynamic posix clock is protected from asynchronous removal by a mutex.
    However, using a mutex has the unwanted effect that a long running clock
    operation in one process will unnecessarily block other processes.
    
    For example, one process might call read() to get an external time stamp
    coming in at one pulse per second. A second process calling clock_gettime
    would have to wait for almost a whole second.
    
    This patch fixes the issue by using a reader/writer semaphore instead of
    a mutex.
    
    Signed-off-by: Richard Cochran <richard.cochran@omicron.at>
    Cc: John Stultz <john.stultz@linaro.org>
    Link: http://lkml.kernel.org/r/%3C20110330132421.GA31771%40riccoc20.at.omicron.at%3E
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 6c6804fb2cef2d6aceb38b0eb0803210d77ff390
Author: Andrew Lutomirski <luto@mit.edu>
Date:   Thu Mar 24 00:36:56 2011 -0400

    perf symbols: Fix vsyscall symbol lookup
    
    Perf can't currently trace into the vsyscall page.  It looks like it was
    meant to work.
    
    Tested on 2.6.38 and today's -git.
    
    The bug is easy to reproduce.  Compile this:
    
    int main()
    {
            int i;
            struct timespec t;
            for(i = 0; i < 10000000; i++)
                    clock_gettime(CLOCK_MONOTONIC, &t);
            return 0;
    }
    
    and run it through perf record; perf report.  The top entry shows
    "[unknown]" and you can't zoom in.
    
    It looks like there are two issues.  The first is a that a test for user
    mode executing in kernel space is backwards.  (That's the first hunk
    below).  The second (I think) is that something's wrong with the code
    that generates lots of little struct dso objects for different sections
    -- when it runs on vmlinux it results in bogus long_name values which
    cause objdump to fail.
    
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LPU-Reference: <AANLkTikxSw5+wJZUWNz++nL7mgivCh_Zf=2Kq6=f9Ce_@mail.gmail.com>
    Signed-off-by: Andy Lutomirski <luto@mit.edu>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 0606f422b453f76c31ab2b1bd52943ff06a2dcf2
Author: Richard Cochran <richardcochran@gmail.com>
Date:   Tue Feb 1 13:52:35 2011 +0000

    posix clocks: Introduce dynamic clocks
    
    This patch adds support for adding and removing posix clocks. The
    clock lifetime cycle is patterned after usb devices. Each clock is
    represented by a standard character device. In addition, the driver
    may optionally implement custom character device operations.
    
    The posix clock and timer system calls listed below now work with
    dynamic posix clocks, as well as the traditional static clocks.
    The following system calls are affected:
    
       - clock_adjtime (brand new syscall)
       - clock_gettime
       - clock_getres
       - clock_settime
       - timer_create
       - timer_delete
       - timer_gettime
       - timer_settime
    
    [ tglx: Adapted to the posix-timer cleanup. Moved clock_posix_dynamic
            to posix-clock.c and made all referenced functions static ]
    
    Signed-off-by: Richard Cochran <richard.cochran@omicron.at>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    LKML-Reference: <20110201134420.164172635@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 42285777631aa0654fbb6442057b3e176445c6c5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Feb 1 13:51:50 2011 +0000

    posix-timers: Convert clock_gettime() to clockid_to_kclock()
    
    Use the new kclock decoding mechanism and rename the misnomed
    common_clock_get() to posix_clock_realtime_get().
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    Tested-by: Richard Cochran <richard.cochran@omicron.at>
    LKML-Reference: <20110201134418.611097203@linutronix.de>

commit 134da12cdde543d62dfcb3a39f6487edee674339
Author: Peter Korsgaard <jacmet@sunsite.dk>
Date:   Sat Sep 18 19:55:10 2010 +0100

    ARM: 6400/1: at91: fix arch_gettimeoffset fallout
    
    commit 79e27dc0677b969e2d53b76fa0fa58467cce946a upstream.
    
    5cfc8ee0bb51 (ARM: convert arm to arch_gettimeoffset()) marked all of
    at91 AND at91x40 as needing ARCH_USES_GETTIMEOFFSET, and hence no high
    res timer support / accurate clock_gettime() - But only at91x40 needs it.
    
    Signed-off-by: Peter Korsgaard <peter.korsgaard@barco.com>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    Acked-by: Jean-Christophe PLAGNIOL-VILLARD <plagnioj@jcrosoft.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 79e27dc0677b969e2d53b76fa0fa58467cce946a
Author: Peter Korsgaard <jacmet@sunsite.dk>
Date:   Sat Sep 18 19:55:10 2010 +0100

    ARM: 6400/1: at91: fix arch_gettimeoffset fallout
    
    5cfc8ee0bb51 (ARM: convert arm to arch_gettimeoffset()) marked all of
    at91 AND at91x40 as needing ARCH_USES_GETTIMEOFFSET, and hence no high
    res timer support / accurate clock_gettime() - But only at91x40 needs it.
    
    Cc: stable@kernel.org
    Signed-off-by: Peter Korsgaard <peter.korsgaard@barco.com>
    Acked-by: John Stultz <johnstul@us.ibm.com>
    Acked-by: Jean-Christophe PLAGNIOL-VILLARD <plagnioj@jcrosoft.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

commit 8aa3149405e33cec4f866cfe7f92c2b40d259613
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Tue Nov 17 13:49:50 2009 +0800

    timekeeping: Fix clock_gettime vsyscall time warp
    
    commit 0696b711e4be45fa104c12329f617beb29c03f78 upstream.
    
    Since commit 0a544198 "timekeeping: Move NTP adjusted clock multiplier
    to struct timekeeper" the clock multiplier of vsyscall is updated with
    the unmodified clock multiplier of the clock source and not with the
    NTP adjusted multiplier of the timekeeper.
    
    This causes user space observerable time warps:
    new CLOCK-warp maximum: 120 nsecs,  00000025c337c537 -> 00000025c337c4bf
    
    Add a new argument "mult" to update_vsyscall() and hand in the
    timekeeping internal NTP adjusted multiplier.
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Cc: "Zhang Yanmin" <yanmin_zhang@linux.intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Tony Luck <tony.luck@intel.com>
    LKML-Reference: <1258436990.17765.83.camel@minggr.sh.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Kurt Garloff <garloff@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 0e469db8f70c2645acdc90981c0480a3e19d5e68
Author: Paul Mackerras <paulus@samba.org>
Date:   Sun Jun 20 19:03:08 2010 +0000

    powerpc: Rework VDSO gettimeofday to prevent time going backwards
    
    Currently it is possible for userspace to see the result of
    gettimeofday() going backwards by 1 microsecond, assuming that
    userspace is using the gettimeofday() in the VDSO.  The VDSO
    gettimeofday() algorithm computes the time in "xsecs", which are
    units of 2^-20 seconds, or approximately 0.954 microseconds,
    using the algorithm
    
            now = (timebase - tb_orig_stamp) * tb_to_xs + stamp_xsec
    
    and then converts the time in xsecs to seconds and microseconds.
    
    The kernel updates the tb_orig_stamp and stamp_xsec values every
    tick in update_vsyscall().  If the length of the tick is not an
    integer number of xsecs, then some precision is lost in converting
    the current time to xsecs.  For example, with CONFIG_HZ=1000, the
    tick is 1ms long, which is 1048.576 xsecs.  That means that
    stamp_xsec will advance by either 1048 or 1049 on each tick.
    With the right conditions, it is possible for userspace to get
    (timebase - tb_orig_stamp) * tb_to_xs being 1049 if the kernel is
    slightly late in updating the vdso_datapage, and then for stamp_xsec
    to advance by 1048 when the kernel does update it, and for userspace
    to then see (timebase - tb_orig_stamp) * tb_to_xs being zero due to
    integer truncation.  The result is that time appears to go backwards
    by 1 microsecond.
    
    To fix this we change the VDSO gettimeofday to use a new field in the
    VDSO datapage which stores the nanoseconds part of the time as a
    fractional number of seconds in a 0.32 binary fraction format.
    (Or put another way, as a 32-bit number in units of 0.23283 ns.)
    This is convenient because we can use the mulhwu instruction to
    convert it to either microseconds or nanoseconds.
    
    Since it turns out that computing the time of day using this new field
    is simpler than either using stamp_xsec (as gettimeofday does) or
    stamp_xtime.tv_nsec (as clock_gettime does), this converts both
    gettimeofday and clock_gettime to use the new field.  The existing
    __do_get_tspec function is converted to use the new field and take
    a parameter in r7 that indicates the desired resolution, 1,000,000
    for microseconds or 1,000,000,000 for nanoseconds.  The __do_get_xsec
    function is then unused and is deleted.
    
    The new algorithm is
    
            now = ((timebase - tb_orig_stamp) << 12) * tb_to_xs
                    + (stamp_xtime_seconds << 32) + stamp_sec_fraction
    
    with 'now' in units of 2^-32 seconds.  That is then converted to
    seconds and either microseconds or nanoseconds with
    
            seconds = now >> 32
            partseconds = ((now & 0xffffffff) * resolution) >> 32
    
    The 32-bit VDSO code also makes a further simplification: it ignores
    the bottom 32 bits of the tb_to_xs value, which is a 0.64 format binary
    fraction.  Doing so gets rid of 4 multiply instructions.  Assuming
    a timebase frequency of 1GHz or less and an update interval of no
    more than 10ms, the upper 32 bits of tb_to_xs will be at least
    4503599, so the error from ignoring the low 32 bits will be at most
    2.2ns, which is more than an order of magnitude less than the time
    taken to do gettimeofday or clock_gettime on our fastest processors,
    so there is no possibility of seeing inconsistent values due to this.
    
    This also moves update_gtod() down next to its only caller, and makes
    update_vsyscall use the time passed in via the wall_time argument rather
    than accessing xtime directly.  At present, wall_time always points to
    xtime, but that could change in future.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

commit 8fd63a9ea7528463211a6c88d500c51851d960c8
Author: Paul Mackerras <paulus@samba.org>
Date:   Sun Jun 20 19:03:08 2010 +0000

    powerpc: Rework VDSO gettimeofday to prevent time going backwards
    
    Currently it is possible for userspace to see the result of
    gettimeofday() going backwards by 1 microsecond, assuming that
    userspace is using the gettimeofday() in the VDSO.  The VDSO
    gettimeofday() algorithm computes the time in "xsecs", which are
    units of 2^-20 seconds, or approximately 0.954 microseconds,
    using the algorithm
    
            now = (timebase - tb_orig_stamp) * tb_to_xs + stamp_xsec
    
    and then converts the time in xsecs to seconds and microseconds.
    
    The kernel updates the tb_orig_stamp and stamp_xsec values every
    tick in update_vsyscall().  If the length of the tick is not an
    integer number of xsecs, then some precision is lost in converting
    the current time to xsecs.  For example, with CONFIG_HZ=1000, the
    tick is 1ms long, which is 1048.576 xsecs.  That means that
    stamp_xsec will advance by either 1048 or 1049 on each tick.
    With the right conditions, it is possible for userspace to get
    (timebase - tb_orig_stamp) * tb_to_xs being 1049 if the kernel is
    slightly late in updating the vdso_datapage, and then for stamp_xsec
    to advance by 1048 when the kernel does update it, and for userspace
    to then see (timebase - tb_orig_stamp) * tb_to_xs being zero due to
    integer truncation.  The result is that time appears to go backwards
    by 1 microsecond.
    
    To fix this we change the VDSO gettimeofday to use a new field in the
    VDSO datapage which stores the nanoseconds part of the time as a
    fractional number of seconds in a 0.32 binary fraction format.
    (Or put another way, as a 32-bit number in units of 0.23283 ns.)
    This is convenient because we can use the mulhwu instruction to
    convert it to either microseconds or nanoseconds.
    
    Since it turns out that computing the time of day using this new field
    is simpler than either using stamp_xsec (as gettimeofday does) or
    stamp_xtime.tv_nsec (as clock_gettime does), this converts both
    gettimeofday and clock_gettime to use the new field.  The existing
    __do_get_tspec function is converted to use the new field and take
    a parameter in r7 that indicates the desired resolution, 1,000,000
    for microseconds or 1,000,000,000 for nanoseconds.  The __do_get_xsec
    function is then unused and is deleted.
    
    The new algorithm is
    
            now = ((timebase - tb_orig_stamp) << 12) * tb_to_xs
                    + (stamp_xtime_seconds << 32) + stamp_sec_fraction
    
    with 'now' in units of 2^-32 seconds.  That is then converted to
    seconds and either microseconds or nanoseconds with
    
            seconds = now >> 32
            partseconds = ((now & 0xffffffff) * resolution) >> 32
    
    The 32-bit VDSO code also makes a further simplification: it ignores
    the bottom 32 bits of the tb_to_xs value, which is a 0.64 format binary
    fraction.  Doing so gets rid of 4 multiply instructions.  Assuming
    a timebase frequency of 1GHz or less and an update interval of no
    more than 10ms, the upper 32 bits of tb_to_xs will be at least
    4503599, so the error from ignoring the low 32 bits will be at most
    2.2ns, which is more than an order of magnitude less than the time
    taken to do gettimeofday or clock_gettime on our fastest processors,
    so there is no possibility of seeing inconsistent values due to this.
    
    This also moves update_gtod() down next to its only caller, and makes
    update_vsyscall use the time passed in via the wall_time argument rather
    than accessing xtime directly.  At present, wall_time always points to
    xtime, but that could change in future.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>

commit 157a1a27d5921fc94db8c14e0d01363d13de99b5
Author: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
Date:   Thu Apr 22 17:17:06 2010 +0200

    [S390] vdso: use ntp adjusted clock multiplier
    
    Commit "timekeeping: Fix clock_gettime vsyscall time warp" (0696b711e)
    introduced the new parameter "mult" to update_vsyscall(). This parameter
    contains the internal NTP adjusted clock multiplier.
    
    The s390x vdso did not use this adjusted multiplier.  Instead, it used
    the constant clock multiplier for gettimeofday() and clock_gettime()
    variants.  This may result in observable time warps as explained in
    commit 0696b711e.
    
    Make the NTP adjusted clock multiplier available to the s390x vdso
    implementation and use it for time calculations.
    
    Cc: <stable@kernel.org>
    Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit abfe5a01ef1e463cbafdae461b693db34e308c02
Author: Stefan Richter <stefanr@s5r6.in-berlin.de>
Date:   Sat Feb 20 12:13:49 2010 +0100

    firewire: cdev: add more flexible cycle timer ioctl
    
    The system time from CLOCK_REALTIME is not monotonic, hence problematic
    for the main user of the FW_CDEV_IOC_GET_CYCLE_TIMER ioctl.  This issue
    exists in its successor ABI, i.e. raw1394, too.
    http://subversion.ffado.org/ticket/242
    
    We now offer an alternative ioctl which lets the caller choose between
    CLOCK_REALTIME, CLOCK_MONOTONIC, and CLOCK_MONOTONIC_RAW as source of
    the local time, very similar to the clock_gettime libc function.  The
    format of the local time return value matches that of clock_gettime
    (seconds and nanoseconds, instead of a single microseconds value from
    the existing ioctl).
    
    Signed-off-by: Stefan Richter <stefanr@s5r6.in-berlin.de>

commit 4f7d6662c57dbaa6be09cc0bad2c01d005638a4d
Author: Glauber Costa <glommer@redhat.com>
Date:   Mon Feb 1 16:54:05 2010 -0200

    KVM: allow userspace to adjust kvmclock offset
    
    (cherry picked from afbcf7ab8d1bc8c2d04792f6d9e786e0adeb328d)
    
    When we migrate a kvm guest that uses pvclock between two hosts, we may
    suffer a large skew. This is because there can be significant differences
    between the monotonic clock of the hosts involved. When a new host with
    a much larger monotonic time starts running the guest, the view of time
    will be significantly impacted.
    
    Situation is much worse when we do the opposite, and migrate to a host with
    a smaller monotonic clock.
    
    This proposed ioctl will allow userspace to inform us what is the monotonic
    clock value in the source host, so we can keep the time skew short, and
    more importantly, never goes backwards. Userspace may also need to trigger
    the current data, since from the first migration onwards, it won't be
    reflected by a simple call to clock_gettime() anymore.
    
    [marcelo: future-proof abi with a flags field]
    [jan: fix KVM_GET_CLOCK by clearing flags field instead of checking it]
    
    Signed-off-by: Glauber Costa <glommer@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit fbf07eac7bf21c262143194181bd97c5d18b8ceb
Merge: 60d8ce2cd6c2 8629ea2eaba8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 8 19:28:09 2009 -0800

    Merge branch 'timers-for-linus-urgent' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-for-linus-urgent' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      hrtimer: Fix /proc/timer_list regression
      itimers: Fix racy writes to cpu_itimer fields
      timekeeping: Fix clock_gettime vsyscall time warp

commit afbcf7ab8d1bc8c2d04792f6d9e786e0adeb328d
Author: Glauber Costa <glommer@redhat.com>
Date:   Fri Oct 16 15:28:36 2009 -0400

    KVM: allow userspace to adjust kvmclock offset
    
    When we migrate a kvm guest that uses pvclock between two hosts, we may
    suffer a large skew. This is because there can be significant differences
    between the monotonic clock of the hosts involved. When a new host with
    a much larger monotonic time starts running the guest, the view of time
    will be significantly impacted.
    
    Situation is much worse when we do the opposite, and migrate to a host with
    a smaller monotonic clock.
    
    This proposed ioctl will allow userspace to inform us what is the monotonic
    clock value in the source host, so we can keep the time skew short, and
    more importantly, never goes backwards. Userspace may also need to trigger
    the current data, since from the first migration onwards, it won't be
    reflected by a simple call to clock_gettime() anymore.
    
    [marcelo: future-proof abi with a flags field]
    [jan: fix KVM_GET_CLOCK by clearing flags field instead of checking it]
    
    Signed-off-by: Glauber Costa <glommer@redhat.com>
    Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
    Signed-off-by: Avi Kivity <avi@redhat.com>

commit 0696b711e4be45fa104c12329f617beb29c03f78
Author: Lin Ming <ming.m.lin@intel.com>
Date:   Tue Nov 17 13:49:50 2009 +0800

    timekeeping: Fix clock_gettime vsyscall time warp
    
    Since commit 0a544198 "timekeeping: Move NTP adjusted clock multiplier
    to struct timekeeper" the clock multiplier of vsyscall is updated with
    the unmodified clock multiplier of the clock source and not with the
    NTP adjusted multiplier of the timekeeper.
    
    This causes user space observerable time warps:
    new CLOCK-warp maximum: 120 nsecs,  00000025c337c537 -> 00000025c337c4bf
    
    Add a new argument "mult" to update_vsyscall() and hand in the
    timekeeping internal NTP adjusted multiplier.
    
    Signed-off-by: Lin Ming <ming.m.lin@intel.com>
    Cc: "Zhang Yanmin" <yanmin_zhang@linux.intel.com>
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Tony Luck <tony.luck@intel.com>
    LKML-Reference: <1258436990.17765.83.camel@minggr.sh.intel.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit da15cfdae03351c689736f8d142618592e3cebc3
Author: John Stultz <johnstul@us.ibm.com>
Date:   Wed Aug 19 19:13:34 2009 -0700

    time: Introduce CLOCK_REALTIME_COARSE
    
    After talking with some application writers who want very fast, but not
    fine-grained timestamps, I decided to try to implement new clock_ids
    to clock_gettime(): CLOCK_REALTIME_COARSE and CLOCK_MONOTONIC_COARSE
    which returns the time at the last tick. This is very fast as we don't
    have to access any hardware (which can be very painful if you're using
    something like the acpi_pm clocksource), and we can even use the vdso
    clock_gettime() method to avoid the syscall. The only trade off is you
    only get low-res tick grained time resolution.
    
    This isn't a new idea, I know Ingo has a patch in the -rt tree that made
    the vsyscall gettimeofday() return coarse grained time when the
    vsyscall64 sysctrl was set to 2. However this affects all applications
    on a system.
    
    With this method, applications can choose the proper speed/granularity
    trade-off for themselves.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Cc: Andi Kleen <andi@firstfloor.org>
    Cc: nikolag@ca.ibm.com
    Cc: Darren Hart <dvhltc@us.ibm.com>
    Cc: arjan@infradead.org
    Cc: jonathan@jonmasters.org
    LKML-Reference: <1250734414.6897.5.camel@localhost.localdomain>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 760dcc6e1839e7ca82507698fb077d5d78b24964
Merge: 4897f1011aff 8d406c6de2e6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 27 12:16:38 2009 -0700

    Merge branch 'for-linus' of git://git390.marist.edu/pub/scm/linux-2.6
    
    * 'for-linus' of git://git390.marist.edu/pub/scm/linux-2.6:
      [S390] zcrypt: fix scheduling of hrtimer ap_poll_timer
      [S390] vdso: clock_gettime of CLOCK_THREAD_CPUTIME_ID with noexec=on
      [S390] vdso: fix per cpu area allocation
      [S390] hibernation: fix register corruption on machine checks
      [S390] hibernation: fix lowcore handling

commit 1277580fe5dfb5aef84854bdb7983657df00b920
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Fri Jul 24 12:39:52 2009 +0200

    [S390] vdso: clock_gettime of CLOCK_THREAD_CPUTIME_ID with noexec=on
    
    The combination of noexec=on and a clock_gettime call with clock id
    CLOCK_THREAD_CPUTIME_ID is broken. The vdso code switches to the
    access register mode to get access to the per-cpu data structure to
    execute the magic ectg instruction. After the ectg instruction the
    code always switches back to the primary mode but for noexec=on the
    correct mode is the secondary mode. The effect of the bug is that the
    user space program looses the access to all mappings without PROT_EXEC,
    e.g. the stack. The problem is fixed by restoring the mode that has
    been active before the switch to the access register mode.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 03c8ba6109c7cd28edb072b2a84f46e4d9bb0fdd
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Thu Apr 9 18:20:12 2009 +0000

    posixtimers, sched: Fix posix clock monotonicity
    
    upstream commit: c5f8d99585d7b5b7e857fabf8aefd0174903a98c
    
    Impact: Regression fix (against clock_gettime() backwarding bug)
    
    This patch re-introduces a couple of functions, task_sched_runtime
    and thread_group_sched_runtime, which was once removed at the
    time of 2.6.28-rc1.
    
    These functions protect the sampling of thread/process clock with
    rq lock.  This rq lock is required not to update rq->clock during
    the sampling.
    
    i.e.
      The clock_gettime() may return
       ((accounted runtime before update) + (delta after update))
      that is less than what it should be.
    
    v2 -> v3:
            - Rename static helper function __task_delta_exec()
              to do_task_delta_exec() since -tip tree already has
              a __task_delta_exec() of different version.
    
    v1 -> v2:
            - Revises comments of function and patch description.
            - Add note about accuracy of thread group's runtime.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <49D1CC93.4080401@jp.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Chris Wright <chrisw@sous-sol.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 39cd13c96cfc4d9d5992e93625fe6d6cb4fe3991
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Thu Apr 9 18:20:12 2009 +0000

    posixtimers, sched: Fix posix clock monotonicity
    
    upstream commit: c5f8d99585d7b5b7e857fabf8aefd0174903a98c
    
    Impact: Regression fix (against clock_gettime() backwarding bug)
    
    This patch re-introduces a couple of functions, task_sched_runtime
    and thread_group_sched_runtime, which was once removed at the
    time of 2.6.28-rc1.
    
    These functions protect the sampling of thread/process clock with
    rq lock.  This rq lock is required not to update rq->clock during
    the sampling.
    
    i.e.
      The clock_gettime() may return
       ((accounted runtime before update) + (delta after update))
      that is less than what it should be.
    
    v2 -> v3:
            - Rename static helper function __task_delta_exec()
              to do_task_delta_exec() since -tip tree already has
              a __task_delta_exec() of different version.
    
    v1 -> v2:
            - Revises comments of function and patch description.
            - Add note about accuracy of thread group's runtime.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: stable@kernel.org   [2.6.28.x][2.6.29.x]
    LKML-Reference: <49D1CC93.4080401@jp.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Chris Wright <chrisw@sous-sol.org>

commit c5f8d99585d7b5b7e857fabf8aefd0174903a98c
Author: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
Date:   Tue Mar 31 16:56:03 2009 +0900

    posixtimers, sched: Fix posix clock monotonicity
    
    Impact: Regression fix (against clock_gettime() backwarding bug)
    
    This patch re-introduces a couple of functions, task_sched_runtime
    and thread_group_sched_runtime, which was once removed at the
    time of 2.6.28-rc1.
    
    These functions protect the sampling of thread/process clock with
    rq lock.  This rq lock is required not to update rq->clock during
    the sampling.
    
    i.e.
      The clock_gettime() may return
       ((accounted runtime before update) + (delta after update))
      that is less than what it should be.
    
    v2 -> v3:
            - Rename static helper function __task_delta_exec()
              to do_task_delta_exec() since -tip tree already has
              a __task_delta_exec() of different version.
    
    v1 -> v2:
            - Revises comments of function and patch description.
            - Add note about accuracy of thread group's runtime.
    
    Signed-off-by: Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: stable@kernel.org   [2.6.28.x][2.6.29.x]
    LKML-Reference: <49D1CC93.4080401@jp.fujitsu.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 4cd4c1b40d40447fb5e7ba80746c6d7ba91d7a53
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Feb 5 12:24:16 2009 +0100

    timers: split process wide cpu clocks/timers
    
    Change the process wide cpu timers/clocks so that we:
    
     1) don't mess up the kernel with too many threads,
     2) don't have a per-cpu allocation for each process,
     3) have no impact when not used.
    
    In order to accomplish this we're going to split it into two parts:
    
     - clocks; which can take all the time they want since they run
               from user context -- ie. sys_clock_gettime(CLOCK_PROCESS_CPUTIME_ID)
    
     - timers; which need constant time sampling but since they're
               explicity used, the user can pay the overhead.
    
    The clock readout will go back to a full sum of the thread group, while the
    timers will run of a global 'clock' that only runs when needed, so only
    programs that make use of the facility pay the price.
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reviewed-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit b020632e40c3ed5e8c0c066d022672907e8401cf
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Thu Dec 25 13:38:36 2008 +0100

    [S390] introduce vdso on s390
    
    Add a vdso to speed up gettimeofday and clock_getres/clock_gettime for
    CLOCK_REALTIME/CLOCK_MONOTONIC.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 4857339d7c01cd81ce8872da2d1f9183b07b1c87
Merge: 0efcafb0fb7a 6c9bacb41c10
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 4 21:40:29 2008 -0800

    Merge branch 'timers-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'timers-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      time: catch xtime_nsec underflows and fix them
      posix-cpu-timers: fix clock_gettime with CLOCK_PROCESS_CPUTIME_ID

commit eccdaeafaea3ed115068ba55d01f22e486e5437d
Author: Petr Tesarik <ptesarik@suse.cz>
Date:   Mon Nov 24 15:46:31 2008 +0100

    posix-cpu-timers: fix clock_gettime with CLOCK_PROCESS_CPUTIME_ID
    
    Since CLOCK_PROCESS_CPUTIME_ID is in fact translated to -6, the switch
    statement in cpu_clock_sample_group() must first mask off the irrelevant
    bits, similar to cpu_clock_sample().
    
    Signed-off-by: Petr Tesarik <ptesarik@suse.cz>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    
    --
     posix-cpu-timers.c |    2 +-
     1 file changed, 1 insertion(+), 1 deletion(-)

commit 2b7d0390a6d6d595f43ea3806639664afe5b9ebe
Author: Ingo Molnar <mingo@elte.hu>
Date:   Wed Nov 12 13:17:38 2008 +0100

    tracing: branch tracer, fix vdso crash
    
    Impact: fix bootup crash
    
    the branch tracer missed arch/x86/vdso/vclock_gettime.c from
    disabling tracing, which caused such bootup crashes:
    
      [  201.840097] init[1]: segfault at 7fffed3fe7c0 ip 00007fffed3fea2e sp 000077
    
    also clean up the ugly ifdefs in arch/x86/kernel/vsyscall_64.c by
    creating DISABLE_UNLIKELY_PROFILE facility for code to turn off
    instrumentation on a per file basis.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 597bc5c00b666fe123abb0af64f6e86f7ab72a90
Author: Paul Mackerras <paulus@samba.org>
Date:   Mon Oct 27 23:56:03 2008 +0000

    powerpc: Improve resolution of VDSO clock_gettime
    
    Currently the clock_gettime implementation in the VDSO produces a
    result with microsecond resolution for the cases that are handled
    without a system call, i.e. CLOCK_REALTIME and CLOCK_MONOTONIC.  The
    nanoseconds field of the result is obtained by computing a
    microseconds value and multiplying by 1000.
    
    This changes the code in the VDSO to do the computation for
    clock_gettime with nanosecond resolution.  That means that the
    resolution of the result will ultimately depend on the timebase
    frequency.
    
    Because the timestamp in the VDSO datapage (stamp_xsec, the real time
    corresponding to the timebase count in tb_orig_stamp) is in units of
    2^-20 seconds, it doesn't have sufficient resolution for computing a
    result with nanosecond resolution.  Therefore this adds a copy of
    xtime to the VDSO datapage and updates it in update_gtod() along with
    the other time-related fields.
    
    Signed-off-by: Paul Mackerras <paulus@samba.org>

commit 2d42244ae71d6c7b0884b5664cf2eda30fb2ae68
Author: John Stultz <johnstul@us.ibm.com>
Date:   Wed Aug 20 16:37:30 2008 -0700

    clocksource: introduce CLOCK_MONOTONIC_RAW
    
    In talking with Josip Loncaric, and his work on clock synchronization (see
    btime.sf.net), he mentioned that for really close synchronization, it is
    useful to have access to "hardware time", that is a notion of time that is
    not in any way adjusted by the clock slewing done to keep close time sync.
    
    Part of the issue is if we are using the kernel's ntp adjusted
    representation of time in order to measure how we should correct time, we
    can run into what Paul McKenney aptly described as "Painting a road using
    the lines we're painting as the guide".
    
    I had been thinking of a similar problem, and was trying to come up with a
    way to give users access to a purely hardware based time representation
    that avoided users having to know the underlying frequency and mask values
    needed to deal with the wide variety of possible underlying hardware
    counters.
    
    My solution is to introduce CLOCK_MONOTONIC_RAW.  This exposes a
    nanosecond based time value, that increments starting at bootup and has no
    frequency adjustments made to it what so ever.
    
    The time is accessed from userspace via the posix_clock_gettime() syscall,
    passing CLOCK_MONOTONIC_RAW as the clock_id.
    
    Signed-off-by: John Stultz <johnstul@us.ibm.com>
    Signed-off-by: Roman Zippel <zippel@linux-m68k.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 7b5acbaac3f94ab810a977c0ec4e5fcabbf51bed
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Wed Sep 19 14:21:56 2007 +1000

    [POWERPC] Don't expose clock vDSO functions when CPU has no timebase
    
    We forgot to remove the clock_gettime, clock_getres and get_tbfreq vDSO
    calls on CPUs that have no timebase such as 601 or 403 (old CPUs that have
    different mechanisms and for which the vDSO code will not work properly).
    This fixes it.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

commit 2aae950b21e4bc789d1fc6668faf67e8748300b7
Author: Andi Kleen <ak@suse.de>
Date:   Sat Jul 21 17:10:01 2007 +0200

    x86_64: Add vDSO for x86-64 with gettimeofday/clock_gettime/getcpu
    
    This implements new vDSO for x86-64.  The concept is similar
    to the existing vDSOs on i386 and PPC.  x86-64 has had static
    vsyscalls before,  but these are not flexible enough anymore.
    
    A vDSO is a ELF shared library supplied by the kernel that is mapped into
    user address space.  The vDSO mapping is randomized for each process
    for security reasons.
    
    Doing this was needed for clock_gettime, because clock_gettime
    always needs a syscall fallback and having one at a fixed
    address would have made buffer overflow exploits too easy to write.
    
    The vdso can be disabled with vdso=0
    
    It currently includes a new gettimeofday implemention and optimized
    clock_gettime(). The gettimeofday implementation is slightly faster
    than the one in the old vsyscall.  clock_gettime is significantly faster
    than the syscall for CLOCK_MONOTONIC and CLOCK_REALTIME.
    
    The new calls are generally faster than the old vsyscall.
    
    Advantages over the old x86-64 vsyscalls:
    - Extensible
    - Randomized
    - Cleaner
    - Easier to virtualize (the old static address range previously causes
    overhead e.g. for Xen because it has to create special page tables for it)
    
    Weak points:
    - glibc support still to be written
    
    The VM interface is partly based on Ingo Molnar's i386 version.
    
    Includes compile fix from Joachim Deguara
    
    Signed-off-by: Andi Kleen <ak@suse.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 1f2ea0837dbc263ce2a2512c4e73c83df68a6a55
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Feb 16 01:28:22 2007 -0800

    [PATCH] posix timers: RCU optimization for clock_gettime()
    
    Use RCU to avoid the need to acquire tasklist_lock in the single-threaded
    case of clock_gettime().  It still acquires tasklist_lock when for a
    (potentially multithreaded) process.  This change allows realtime
    applications to frequently monitor CPU consumption of individual tasks, as
    requested (and now deployed) by some off-list users.
    
    This has been in Ingo Molnar's -rt patchset since late 2005 with no
    problems reported, and tests successfully on 2.6.20-rc6, so I believe that
    it is long-since ready for mainline adoption.
    
    [paulmck@linux.vnet.ibm.com: fix exit()/posix_cpu_clock_get() race spotted by Oleg]
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: john stultz <johnstul@us.ibm.com>
    Cc: Roman Zippel <zippel@linux-m68k.org>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit a7f290dad32ee34d931561b7943c858fe2aae503
Author: Benjamin Herrenschmidt <benh@kernel.crashing.org>
Date:   Fri Nov 11 21:15:21 2005 +1100

    [PATCH] powerpc: Merge vdso's and add vdso support to 32 bits kernel
    
    This patch moves the vdso's to arch/powerpc, adds support for the 32
    bits vdso to the 32 bits kernel, rename systemcfg (finally !), and adds
    some new (still untested) routines to both vdso's: clock_gettime() with
    support for CLOCK_REALTIME and CLOCK_MONOTONIC, clock_getres() (same
    clocks) and get_tbfreq() for glibc to retreive the timebase frequency.
    
    Tom,Steve: The implementation of get_tbfreq() I've done for 32 bits
    returns a long long (r3, r4) not a long. This is such that if we ever
    add support for >4Ghz timebases on ppc32, the userland interface won't
    have to change.
    
    I have tested gettimeofday() using some glibc patches in both ppc32 and
    ppc64 kernels using 32 bits userland (I haven't had a chance to test a
    64 bits userland yet, but the implementation didn't change and was
    tested earlier). I haven't tested yet the new functions.
    
    Signed-off-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
