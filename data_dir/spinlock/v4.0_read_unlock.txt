commit 68a37dc77e2fb53530749ac982bd11f3fa2c9028
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Dec 3 18:37:21 2022 -0500

    tipc: call tipc_lxc_xmit without holding node_read_lock
    
    commit 88956177db179e4eba7cd590971961857d1565b8 upstream.
    
    When sending packets between nodes in netns, it calls tipc_lxc_xmit() for
    peer node to receive the packets where tipc_sk_mcast_rcv()/tipc_sk_rcv()
    might be called, and it's pretty much like in tipc_rcv().
    
    Currently the local 'node rw lock' is held during calling tipc_lxc_xmit()
    to protect the peer_net not being freed by another thread. However, when
    receiving these packets, tipc_node_add_conn() might be called where the
    peer 'node rw lock' is acquired. Then a dead lock warning is triggered by
    lockdep detector, although it is not a real dead lock:
    
        WARNING: possible recursive locking detected
        --------------------------------------------
        conn_server/1086 is trying to acquire lock:
        ffff8880065cb020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
    
        but task is already holding lock:
        ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_xmit+0x285/0xb30 [tipc]
    
        other info that might help us debug this:
         Possible unsafe locking scenario:
    
               CPU0
               ----
          lock(&n->lock#2);
          lock(&n->lock#2);
    
         *** DEADLOCK ***
    
         May be due to missing lock nesting notation
    
        4 locks held by conn_server/1086:
         #0: ffff8880036d1e40 (sk_lock-AF_TIPC){+.+.}-{0:0}, \
                              at: tipc_accept+0x9c0/0x10b0 [tipc]
         #1: ffff8880036d5f80 (sk_lock-AF_TIPC/1){+.+.}-{0:0}, \
                              at: tipc_accept+0x363/0x10b0 [tipc]
         #2: ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                              at: tipc_node_xmit+0x285/0xb30 [tipc]
         #3: ffff888012e13370 (slock-AF_TIPC){+...}-{2:2}, \
                              at: tipc_sk_rcv+0x2da/0x1b40 [tipc]
    
        Call Trace:
         <TASK>
         dump_stack_lvl+0x44/0x5b
         __lock_acquire.cold.77+0x1f2/0x3d7
         lock_acquire+0x1d2/0x610
         _raw_write_lock_bh+0x38/0x80
         tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
         tipc_sk_finish_conn+0x21e/0x640 [tipc]
         tipc_sk_filter_rcv+0x147b/0x3030 [tipc]
         tipc_sk_rcv+0xbb4/0x1b40 [tipc]
         tipc_lxc_xmit+0x225/0x26b [tipc]
         tipc_node_xmit.cold.82+0x4a/0x102 [tipc]
         __tipc_sendstream+0x879/0xff0 [tipc]
         tipc_accept+0x966/0x10b0 [tipc]
         do_accept+0x37d/0x590
    
    This patch avoids this warning by not holding the 'node rw lock' before
    calling tipc_lxc_xmit(). As to protect the 'peer_net', rcu_read_lock()
    should be enough, as in cleanup_net() when freeing the netns, it calls
    synchronize_rcu() before the free is continued.
    
    Also since tipc_lxc_xmit() is like the RX path in tipc_rcv(), it makes
    sense to call it under rcu_read_lock(). Note that the right lock order
    must be:
    
       rcu_read_lock();
       tipc_node_read_lock(n);
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    instead of:
    
       tipc_node_read_lock(n);
       rcu_read_lock();
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    and we have to call tipc_node_read_lock/unlock() twice in
    tipc_node_xmit().
    
    Fixes: f73b12812a3d ("tipc: improve throughput between nodes in netns")
    Reported-by: Shuang Li <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Link: https://lore.kernel.org/r/5bdd1f8fee9db695cfff4528a48c9b9d0523fb00.1670110641.git.lucien.xin@gmail.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7360b323e0343ea099091d4ae09576dbe1f09516
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6447beefd21326a3f4719ec2ea511df797f6c820
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 340524ae7b53a72cf5d9e7bd7790433422b3b12f
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8af52492717e3538eba3f81d012b1476af8a89a6
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3a52f17867727818ae8dbcfd9425033df32f92e0
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Fri Sep 23 00:50:23 2022 +0800

    fs/ntfs3: Validate resident attribute name
    
    [ Upstream commit 54e45702b648b7c0000e90b3e9b890e367e16ea8 ]
    
    Though we already have some sanity checks while enumerating attributes,
    resident attribute names aren't included. This patch checks the resident
    attribute names are in the valid ranges.
    
    [  259.209031] BUG: KASAN: slab-out-of-bounds in ni_create_attr_list+0x1e1/0x850
    [  259.210770] Write of size 426 at addr ffff88800632f2b2 by task exp/255
    [  259.211551]
    [  259.212035] CPU: 0 PID: 255 Comm: exp Not tainted 6.0.0-rc6 #37
    [  259.212955] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  259.214387] Call Trace:
    [  259.214640]  <TASK>
    [  259.214895]  dump_stack_lvl+0x49/0x63
    [  259.215284]  print_report.cold+0xf5/0x689
    [  259.215565]  ? kasan_poison+0x3c/0x50
    [  259.215778]  ? kasan_unpoison+0x28/0x60
    [  259.215991]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216270]  kasan_report+0xa7/0x130
    [  259.216481]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216719]  kasan_check_range+0x15a/0x1d0
    [  259.216939]  memcpy+0x3c/0x70
    [  259.217136]  ni_create_attr_list+0x1e1/0x850
    [  259.217945]  ? __rcu_read_unlock+0x5b/0x280
    [  259.218384]  ? ni_remove_attr+0x2e0/0x2e0
    [  259.218712]  ? kernel_text_address+0xcf/0xe0
    [  259.219064]  ? __kernel_text_address+0x12/0x40
    [  259.219434]  ? arch_stack_walk+0x9e/0xf0
    [  259.219668]  ? __this_cpu_preempt_check+0x13/0x20
    [  259.219904]  ? sysvec_apic_timer_interrupt+0x57/0xc0
    [  259.220140]  ? asm_sysvec_apic_timer_interrupt+0x1b/0x20
    [  259.220561]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.220984]  ? ni_create_attr_list+0x850/0x850
    [  259.221532]  ? run_deallocate+0x120/0x120
    [  259.221972]  ? vfs_setxattr+0x128/0x300
    [  259.222688]  ? setxattr+0x126/0x140
    [  259.222921]  ? path_setxattr+0x164/0x180
    [  259.223431]  ? __x64_sys_setxattr+0x6d/0x80
    [  259.223828]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.224417]  ? mi_find_attr+0x3c/0xf0
    [  259.224772]  ni_insert_attr+0x1ba/0x420
    [  259.225216]  ? ni_ins_attr_ext+0x5c0/0x5c0
    [  259.225504]  ? ntfs_read_ea+0x119/0x450
    [  259.225775]  ni_insert_resident+0xc0/0x1c0
    [  259.226316]  ? ni_insert_nonresident+0x400/0x400
    [  259.227001]  ? __kasan_kmalloc+0x88/0xb0
    [  259.227468]  ? __kmalloc+0x192/0x320
    [  259.227773]  ntfs_set_ea+0x6bf/0xb30
    [  259.228216]  ? ftrace_graph_ret_addr+0x2a/0xb0
    [  259.228494]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.228838]  ? ntfs_read_ea+0x450/0x450
    [  259.229098]  ? is_bpf_text_address+0x24/0x40
    [  259.229418]  ? kernel_text_address+0xcf/0xe0
    [  259.229681]  ? __kernel_text_address+0x12/0x40
    [  259.229948]  ? unwind_get_return_address+0x3a/0x60
    [  259.230271]  ? write_profile+0x270/0x270
    [  259.230537]  ? arch_stack_walk+0x9e/0xf0
    [  259.230836]  ntfs_setxattr+0x114/0x5c0
    [  259.231099]  ? ntfs_set_acl_ex+0x2e0/0x2e0
    [  259.231529]  ? evm_protected_xattr_common+0x6d/0x100
    [  259.231817]  ? posix_xattr_acl+0x13/0x80
    [  259.232073]  ? evm_protect_xattr+0x1f7/0x440
    [  259.232351]  __vfs_setxattr+0xda/0x120
    [  259.232635]  ? xattr_resolve_name+0x180/0x180
    [  259.232912]  __vfs_setxattr_noperm+0x93/0x300
    [  259.233219]  __vfs_setxattr_locked+0x141/0x160
    [  259.233492]  ? kasan_poison+0x3c/0x50
    [  259.233744]  vfs_setxattr+0x128/0x300
    [  259.234002]  ? __vfs_setxattr_locked+0x160/0x160
    [  259.234837]  do_setxattr+0xb8/0x170
    [  259.235567]  ? vmemdup_user+0x53/0x90
    [  259.236212]  setxattr+0x126/0x140
    [  259.236491]  ? do_setxattr+0x170/0x170
    [  259.236791]  ? debug_smp_processor_id+0x17/0x20
    [  259.237232]  ? kasan_quarantine_put+0x57/0x180
    [  259.237605]  ? putname+0x80/0xa0
    [  259.237870]  ? __kasan_slab_free+0x11c/0x1b0
    [  259.238234]  ? putname+0x80/0xa0
    [  259.238500]  ? preempt_count_sub+0x18/0xc0
    [  259.238775]  ? __mnt_want_write+0xaa/0x100
    [  259.238990]  ? mnt_want_write+0x8b/0x150
    [  259.239290]  path_setxattr+0x164/0x180
    [  259.239605]  ? setxattr+0x140/0x140
    [  259.239849]  ? debug_smp_processor_id+0x17/0x20
    [  259.240174]  ? fpregs_assert_state_consistent+0x67/0x80
    [  259.240411]  __x64_sys_setxattr+0x6d/0x80
    [  259.240715]  do_syscall_64+0x3b/0x90
    [  259.240934]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.241697] RIP: 0033:0x7fc6b26e4469
    [  259.242647] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  259.244512] RSP: 002b:00007ffc3c7841f8 EFLAGS: 00000217 ORIG_RAX: 00000000000000bc
    [  259.245086] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007fc6b26e4469
    [  259.246025] RDX: 00007ffc3c784380 RSI: 00007ffc3c7842e0 RDI: 00007ffc3c784238
    [  259.246961] RBP: 00007ffc3c788410 R08: 0000000000000001 R09: 00007ffc3c7884f8
    [  259.247775] R10: 000000000000007f R11: 0000000000000217 R12: 00000000004004e0
    [  259.248534] R13: 00007ffc3c7884f0 R14: 0000000000000000 R15: 0000000000000000
    [  259.249368]  </TASK>
    [  259.249644]
    [  259.249888] Allocated by task 255:
    [  259.250283]  kasan_save_stack+0x26/0x50
    [  259.250957]  __kasan_kmalloc+0x88/0xb0
    [  259.251826]  __kmalloc+0x192/0x320
    [  259.252745]  ni_create_attr_list+0x11e/0x850
    [  259.253298]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.253685]  ni_insert_attr+0x1ba/0x420
    [  259.253974]  ni_insert_resident+0xc0/0x1c0
    [  259.254311]  ntfs_set_ea+0x6bf/0xb30
    [  259.254629]  ntfs_setxattr+0x114/0x5c0
    [  259.254859]  __vfs_setxattr+0xda/0x120
    [  259.255155]  __vfs_setxattr_noperm+0x93/0x300
    [  259.255445]  __vfs_setxattr_locked+0x141/0x160
    [  259.255862]  vfs_setxattr+0x128/0x300
    [  259.256251]  do_setxattr+0xb8/0x170
    [  259.256522]  setxattr+0x126/0x140
    [  259.256911]  path_setxattr+0x164/0x180
    [  259.257308]  __x64_sys_setxattr+0x6d/0x80
    [  259.257637]  do_syscall_64+0x3b/0x90
    [  259.257970]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.258550]
    [  259.258772] The buggy address belongs to the object at ffff88800632f000
    [  259.258772]  which belongs to the cache kmalloc-1k of size 1024
    [  259.260190] The buggy address is located 690 bytes inside of
    [  259.260190]  1024-byte region [ffff88800632f000, ffff88800632f400)
    [  259.261412]
    [  259.261743] The buggy address belongs to the physical page:
    [  259.262354] page:0000000081e8cac9 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x632c
    [  259.263722] head:0000000081e8cac9 order:2 compound_mapcount:0 compound_pincount:0
    [  259.264284] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  259.265312] raw: 000fffffc0010200 ffffea0000060d00 dead000000000004 ffff888001041dc0
    [  259.265772] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  259.266305] page dumped because: kasan: bad access detected
    [  259.266588]
    [  259.266728] Memory state around the buggy address:
    [  259.267225]  ffff88800632f300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.267841]  ffff88800632f380: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.269111] >ffff88800632f400: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.269626]                    ^
    [  259.270162]  ffff88800632f480: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.270810]  ffff88800632f500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3cd9e5b41b83bb57ac3cf9888f9fef2a6ef8ed96
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Thu Sep 22 15:30:44 2022 +0800

    fs/ntfs3: Validate buffer length while parsing index
    
    [ Upstream commit 4d42ecda239cc13738d6fd84d098a32e67b368b9 ]
    
    indx_read is called when we have some NTFS directory operations that
    need more information from the index buffers. This adds a sanity check
    to make sure the returned index buffer length is legit, or we may have
    some out-of-bound memory accesses.
    
    [  560.897595] BUG: KASAN: slab-out-of-bounds in hdr_find_e.isra.0+0x10c/0x320
    [  560.898321] Read of size 2 at addr ffff888009497238 by task exp/245
    [  560.898760]
    [  560.899129] CPU: 0 PID: 245 Comm: exp Not tainted 6.0.0-rc6 #37
    [  560.899505] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  560.900170] Call Trace:
    [  560.900407]  <TASK>
    [  560.900732]  dump_stack_lvl+0x49/0x63
    [  560.901108]  print_report.cold+0xf5/0x689
    [  560.901395]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.901716]  kasan_report+0xa7/0x130
    [  560.901950]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.902208]  __asan_load2+0x68/0x90
    [  560.902427]  hdr_find_e.isra.0+0x10c/0x320
    [  560.902846]  ? cmp_uints+0xe0/0xe0
    [  560.903363]  ? cmp_sdh+0x90/0x90
    [  560.903883]  ? ntfs_bread_run+0x190/0x190
    [  560.904196]  ? rwsem_down_read_slowpath+0x750/0x750
    [  560.904969]  ? ntfs_fix_post_read+0xe0/0x130
    [  560.905259]  ? __kasan_check_write+0x14/0x20
    [  560.905599]  ? up_read+0x1a/0x90
    [  560.905853]  ? indx_read+0x22c/0x380
    [  560.906096]  indx_find+0x2ef/0x470
    [  560.906352]  ? indx_find_buffer+0x2d0/0x2d0
    [  560.906692]  ? __kasan_kmalloc+0x88/0xb0
    [  560.906977]  dir_search_u+0x196/0x2f0
    [  560.907220]  ? ntfs_nls_to_utf16+0x450/0x450
    [  560.907464]  ? __kasan_check_write+0x14/0x20
    [  560.907747]  ? mutex_lock+0x8f/0xe0
    [  560.907970]  ? __mutex_lock_slowpath+0x20/0x20
    [  560.908214]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.908459]  ntfs_lookup+0xe0/0x100
    [  560.908788]  __lookup_slow+0x116/0x220
    [  560.909050]  ? lookup_fast+0x1b0/0x1b0
    [  560.909309]  ? lookup_fast+0x13f/0x1b0
    [  560.909601]  walk_component+0x187/0x230
    [  560.909944]  link_path_walk.part.0+0x3f0/0x660
    [  560.910285]  ? handle_lookup_down+0x90/0x90
    [  560.910618]  ? path_init+0x642/0x6e0
    [  560.911084]  ? percpu_counter_add_batch+0x6e/0xf0
    [  560.912559]  ? __alloc_file+0x114/0x170
    [  560.913008]  path_openat+0x19c/0x1d10
    [  560.913419]  ? getname_flags+0x73/0x2b0
    [  560.913815]  ? kasan_save_stack+0x3a/0x50
    [  560.914125]  ? kasan_save_stack+0x26/0x50
    [  560.914542]  ? __kasan_slab_alloc+0x6d/0x90
    [  560.914924]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.915339]  ? getname_flags+0x73/0x2b0
    [  560.915647]  ? getname+0x12/0x20
    [  560.916114]  ? __x64_sys_open+0x4c/0x60
    [  560.916460]  ? path_lookupat.isra.0+0x230/0x230
    [  560.916867]  ? __isolate_free_page+0x2e0/0x2e0
    [  560.917194]  do_filp_open+0x15c/0x1f0
    [  560.917448]  ? may_open_dev+0x60/0x60
    [  560.917696]  ? expand_files+0xa4/0x3a0
    [  560.917923]  ? __kasan_check_write+0x14/0x20
    [  560.918185]  ? _raw_spin_lock+0x88/0xdb
    [  560.918409]  ? _raw_spin_lock_irqsave+0x100/0x100
    [  560.918783]  ? _find_next_bit+0x4a/0x130
    [  560.919026]  ? _raw_spin_unlock+0x19/0x40
    [  560.919276]  ? alloc_fd+0x14b/0x2d0
    [  560.919635]  do_sys_openat2+0x32a/0x4b0
    [  560.920035]  ? file_open_root+0x230/0x230
    [  560.920336]  ? __rcu_read_unlock+0x5b/0x280
    [  560.920813]  do_sys_open+0x99/0xf0
    [  560.921208]  ? filp_open+0x60/0x60
    [  560.921482]  ? exit_to_user_mode_prepare+0x49/0x180
    [  560.921867]  __x64_sys_open+0x4c/0x60
    [  560.922128]  do_syscall_64+0x3b/0x90
    [  560.922369]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.923030] RIP: 0033:0x7f7dff2e4469
    [  560.923681] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  560.924451] RSP: 002b:00007ffd41a210b8 EFLAGS: 00000206 ORIG_RAX: 0000000000000002
    [  560.925168] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f7dff2e4469
    [  560.925655] RDX: 0000000000000000 RSI: 0000000000000002 RDI: 00007ffd41a211f0
    [  560.926085] RBP: 00007ffd41a252a0 R08: 00007f7dff60fba0 R09: 00007ffd41a25388
    [  560.926405] R10: 0000000000400b80 R11: 0000000000000206 R12: 00000000004004e0
    [  560.926867] R13: 00007ffd41a25380 R14: 0000000000000000 R15: 0000000000000000
    [  560.927241]  </TASK>
    [  560.927491]
    [  560.927755] Allocated by task 245:
    [  560.928409]  kasan_save_stack+0x26/0x50
    [  560.929271]  __kasan_kmalloc+0x88/0xb0
    [  560.929778]  __kmalloc+0x192/0x320
    [  560.930023]  indx_read+0x249/0x380
    [  560.930224]  indx_find+0x2a2/0x470
    [  560.930695]  dir_search_u+0x196/0x2f0
    [  560.930892]  ntfs_lookup+0xe0/0x100
    [  560.931115]  __lookup_slow+0x116/0x220
    [  560.931323]  walk_component+0x187/0x230
    [  560.931570]  link_path_walk.part.0+0x3f0/0x660
    [  560.931791]  path_openat+0x19c/0x1d10
    [  560.932008]  do_filp_open+0x15c/0x1f0
    [  560.932226]  do_sys_openat2+0x32a/0x4b0
    [  560.932413]  do_sys_open+0x99/0xf0
    [  560.932709]  __x64_sys_open+0x4c/0x60
    [  560.933417]  do_syscall_64+0x3b/0x90
    [  560.933776]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.934235]
    [  560.934486] The buggy address belongs to the object at ffff888009497000
    [  560.934486]  which belongs to the cache kmalloc-512 of size 512
    [  560.935239] The buggy address is located 56 bytes to the right of
    [  560.935239]  512-byte region [ffff888009497000, ffff888009497200)
    [  560.936153]
    [  560.937326] The buggy address belongs to the physical page:
    [  560.938228] page:0000000062a3dfae refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x9496
    [  560.939616] head:0000000062a3dfae order:1 compound_mapcount:0 compound_pincount:0
    [  560.940219] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  560.942702] raw: 000fffffc0010200 ffffea0000164f80 dead000000000005 ffff888001041c80
    [  560.943932] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  560.944568] page dumped because: kasan: bad access detected
    [  560.945735]
    [  560.946112] Memory state around the buggy address:
    [  560.946870]  ffff888009497100: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947242]  ffff888009497180: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947611] >ffff888009497200: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.947915]                                         ^
    [  560.948249]  ffff888009497280: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.948687]  ffff888009497300: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c9ba3fbf6a488da6cad1d304c5234bd8d729eba3
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2f041a19f4eb72bcc851f9e3a15f3cfd1ae1addf
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Fri Sep 23 00:50:23 2022 +0800

    fs/ntfs3: Validate resident attribute name
    
    [ Upstream commit 54e45702b648b7c0000e90b3e9b890e367e16ea8 ]
    
    Though we already have some sanity checks while enumerating attributes,
    resident attribute names aren't included. This patch checks the resident
    attribute names are in the valid ranges.
    
    [  259.209031] BUG: KASAN: slab-out-of-bounds in ni_create_attr_list+0x1e1/0x850
    [  259.210770] Write of size 426 at addr ffff88800632f2b2 by task exp/255
    [  259.211551]
    [  259.212035] CPU: 0 PID: 255 Comm: exp Not tainted 6.0.0-rc6 #37
    [  259.212955] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  259.214387] Call Trace:
    [  259.214640]  <TASK>
    [  259.214895]  dump_stack_lvl+0x49/0x63
    [  259.215284]  print_report.cold+0xf5/0x689
    [  259.215565]  ? kasan_poison+0x3c/0x50
    [  259.215778]  ? kasan_unpoison+0x28/0x60
    [  259.215991]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216270]  kasan_report+0xa7/0x130
    [  259.216481]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216719]  kasan_check_range+0x15a/0x1d0
    [  259.216939]  memcpy+0x3c/0x70
    [  259.217136]  ni_create_attr_list+0x1e1/0x850
    [  259.217945]  ? __rcu_read_unlock+0x5b/0x280
    [  259.218384]  ? ni_remove_attr+0x2e0/0x2e0
    [  259.218712]  ? kernel_text_address+0xcf/0xe0
    [  259.219064]  ? __kernel_text_address+0x12/0x40
    [  259.219434]  ? arch_stack_walk+0x9e/0xf0
    [  259.219668]  ? __this_cpu_preempt_check+0x13/0x20
    [  259.219904]  ? sysvec_apic_timer_interrupt+0x57/0xc0
    [  259.220140]  ? asm_sysvec_apic_timer_interrupt+0x1b/0x20
    [  259.220561]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.220984]  ? ni_create_attr_list+0x850/0x850
    [  259.221532]  ? run_deallocate+0x120/0x120
    [  259.221972]  ? vfs_setxattr+0x128/0x300
    [  259.222688]  ? setxattr+0x126/0x140
    [  259.222921]  ? path_setxattr+0x164/0x180
    [  259.223431]  ? __x64_sys_setxattr+0x6d/0x80
    [  259.223828]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.224417]  ? mi_find_attr+0x3c/0xf0
    [  259.224772]  ni_insert_attr+0x1ba/0x420
    [  259.225216]  ? ni_ins_attr_ext+0x5c0/0x5c0
    [  259.225504]  ? ntfs_read_ea+0x119/0x450
    [  259.225775]  ni_insert_resident+0xc0/0x1c0
    [  259.226316]  ? ni_insert_nonresident+0x400/0x400
    [  259.227001]  ? __kasan_kmalloc+0x88/0xb0
    [  259.227468]  ? __kmalloc+0x192/0x320
    [  259.227773]  ntfs_set_ea+0x6bf/0xb30
    [  259.228216]  ? ftrace_graph_ret_addr+0x2a/0xb0
    [  259.228494]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.228838]  ? ntfs_read_ea+0x450/0x450
    [  259.229098]  ? is_bpf_text_address+0x24/0x40
    [  259.229418]  ? kernel_text_address+0xcf/0xe0
    [  259.229681]  ? __kernel_text_address+0x12/0x40
    [  259.229948]  ? unwind_get_return_address+0x3a/0x60
    [  259.230271]  ? write_profile+0x270/0x270
    [  259.230537]  ? arch_stack_walk+0x9e/0xf0
    [  259.230836]  ntfs_setxattr+0x114/0x5c0
    [  259.231099]  ? ntfs_set_acl_ex+0x2e0/0x2e0
    [  259.231529]  ? evm_protected_xattr_common+0x6d/0x100
    [  259.231817]  ? posix_xattr_acl+0x13/0x80
    [  259.232073]  ? evm_protect_xattr+0x1f7/0x440
    [  259.232351]  __vfs_setxattr+0xda/0x120
    [  259.232635]  ? xattr_resolve_name+0x180/0x180
    [  259.232912]  __vfs_setxattr_noperm+0x93/0x300
    [  259.233219]  __vfs_setxattr_locked+0x141/0x160
    [  259.233492]  ? kasan_poison+0x3c/0x50
    [  259.233744]  vfs_setxattr+0x128/0x300
    [  259.234002]  ? __vfs_setxattr_locked+0x160/0x160
    [  259.234837]  do_setxattr+0xb8/0x170
    [  259.235567]  ? vmemdup_user+0x53/0x90
    [  259.236212]  setxattr+0x126/0x140
    [  259.236491]  ? do_setxattr+0x170/0x170
    [  259.236791]  ? debug_smp_processor_id+0x17/0x20
    [  259.237232]  ? kasan_quarantine_put+0x57/0x180
    [  259.237605]  ? putname+0x80/0xa0
    [  259.237870]  ? __kasan_slab_free+0x11c/0x1b0
    [  259.238234]  ? putname+0x80/0xa0
    [  259.238500]  ? preempt_count_sub+0x18/0xc0
    [  259.238775]  ? __mnt_want_write+0xaa/0x100
    [  259.238990]  ? mnt_want_write+0x8b/0x150
    [  259.239290]  path_setxattr+0x164/0x180
    [  259.239605]  ? setxattr+0x140/0x140
    [  259.239849]  ? debug_smp_processor_id+0x17/0x20
    [  259.240174]  ? fpregs_assert_state_consistent+0x67/0x80
    [  259.240411]  __x64_sys_setxattr+0x6d/0x80
    [  259.240715]  do_syscall_64+0x3b/0x90
    [  259.240934]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.241697] RIP: 0033:0x7fc6b26e4469
    [  259.242647] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  259.244512] RSP: 002b:00007ffc3c7841f8 EFLAGS: 00000217 ORIG_RAX: 00000000000000bc
    [  259.245086] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007fc6b26e4469
    [  259.246025] RDX: 00007ffc3c784380 RSI: 00007ffc3c7842e0 RDI: 00007ffc3c784238
    [  259.246961] RBP: 00007ffc3c788410 R08: 0000000000000001 R09: 00007ffc3c7884f8
    [  259.247775] R10: 000000000000007f R11: 0000000000000217 R12: 00000000004004e0
    [  259.248534] R13: 00007ffc3c7884f0 R14: 0000000000000000 R15: 0000000000000000
    [  259.249368]  </TASK>
    [  259.249644]
    [  259.249888] Allocated by task 255:
    [  259.250283]  kasan_save_stack+0x26/0x50
    [  259.250957]  __kasan_kmalloc+0x88/0xb0
    [  259.251826]  __kmalloc+0x192/0x320
    [  259.252745]  ni_create_attr_list+0x11e/0x850
    [  259.253298]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.253685]  ni_insert_attr+0x1ba/0x420
    [  259.253974]  ni_insert_resident+0xc0/0x1c0
    [  259.254311]  ntfs_set_ea+0x6bf/0xb30
    [  259.254629]  ntfs_setxattr+0x114/0x5c0
    [  259.254859]  __vfs_setxattr+0xda/0x120
    [  259.255155]  __vfs_setxattr_noperm+0x93/0x300
    [  259.255445]  __vfs_setxattr_locked+0x141/0x160
    [  259.255862]  vfs_setxattr+0x128/0x300
    [  259.256251]  do_setxattr+0xb8/0x170
    [  259.256522]  setxattr+0x126/0x140
    [  259.256911]  path_setxattr+0x164/0x180
    [  259.257308]  __x64_sys_setxattr+0x6d/0x80
    [  259.257637]  do_syscall_64+0x3b/0x90
    [  259.257970]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.258550]
    [  259.258772] The buggy address belongs to the object at ffff88800632f000
    [  259.258772]  which belongs to the cache kmalloc-1k of size 1024
    [  259.260190] The buggy address is located 690 bytes inside of
    [  259.260190]  1024-byte region [ffff88800632f000, ffff88800632f400)
    [  259.261412]
    [  259.261743] The buggy address belongs to the physical page:
    [  259.262354] page:0000000081e8cac9 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x632c
    [  259.263722] head:0000000081e8cac9 order:2 compound_mapcount:0 compound_pincount:0
    [  259.264284] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  259.265312] raw: 000fffffc0010200 ffffea0000060d00 dead000000000004 ffff888001041dc0
    [  259.265772] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  259.266305] page dumped because: kasan: bad access detected
    [  259.266588]
    [  259.266728] Memory state around the buggy address:
    [  259.267225]  ffff88800632f300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.267841]  ffff88800632f380: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.269111] >ffff88800632f400: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.269626]                    ^
    [  259.270162]  ffff88800632f480: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.270810]  ffff88800632f500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3f6f75e8863f41c8b3dbfd9d99e3963aaca42601
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Thu Sep 22 15:30:44 2022 +0800

    fs/ntfs3: Validate buffer length while parsing index
    
    [ Upstream commit 4d42ecda239cc13738d6fd84d098a32e67b368b9 ]
    
    indx_read is called when we have some NTFS directory operations that
    need more information from the index buffers. This adds a sanity check
    to make sure the returned index buffer length is legit, or we may have
    some out-of-bound memory accesses.
    
    [  560.897595] BUG: KASAN: slab-out-of-bounds in hdr_find_e.isra.0+0x10c/0x320
    [  560.898321] Read of size 2 at addr ffff888009497238 by task exp/245
    [  560.898760]
    [  560.899129] CPU: 0 PID: 245 Comm: exp Not tainted 6.0.0-rc6 #37
    [  560.899505] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  560.900170] Call Trace:
    [  560.900407]  <TASK>
    [  560.900732]  dump_stack_lvl+0x49/0x63
    [  560.901108]  print_report.cold+0xf5/0x689
    [  560.901395]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.901716]  kasan_report+0xa7/0x130
    [  560.901950]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.902208]  __asan_load2+0x68/0x90
    [  560.902427]  hdr_find_e.isra.0+0x10c/0x320
    [  560.902846]  ? cmp_uints+0xe0/0xe0
    [  560.903363]  ? cmp_sdh+0x90/0x90
    [  560.903883]  ? ntfs_bread_run+0x190/0x190
    [  560.904196]  ? rwsem_down_read_slowpath+0x750/0x750
    [  560.904969]  ? ntfs_fix_post_read+0xe0/0x130
    [  560.905259]  ? __kasan_check_write+0x14/0x20
    [  560.905599]  ? up_read+0x1a/0x90
    [  560.905853]  ? indx_read+0x22c/0x380
    [  560.906096]  indx_find+0x2ef/0x470
    [  560.906352]  ? indx_find_buffer+0x2d0/0x2d0
    [  560.906692]  ? __kasan_kmalloc+0x88/0xb0
    [  560.906977]  dir_search_u+0x196/0x2f0
    [  560.907220]  ? ntfs_nls_to_utf16+0x450/0x450
    [  560.907464]  ? __kasan_check_write+0x14/0x20
    [  560.907747]  ? mutex_lock+0x8f/0xe0
    [  560.907970]  ? __mutex_lock_slowpath+0x20/0x20
    [  560.908214]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.908459]  ntfs_lookup+0xe0/0x100
    [  560.908788]  __lookup_slow+0x116/0x220
    [  560.909050]  ? lookup_fast+0x1b0/0x1b0
    [  560.909309]  ? lookup_fast+0x13f/0x1b0
    [  560.909601]  walk_component+0x187/0x230
    [  560.909944]  link_path_walk.part.0+0x3f0/0x660
    [  560.910285]  ? handle_lookup_down+0x90/0x90
    [  560.910618]  ? path_init+0x642/0x6e0
    [  560.911084]  ? percpu_counter_add_batch+0x6e/0xf0
    [  560.912559]  ? __alloc_file+0x114/0x170
    [  560.913008]  path_openat+0x19c/0x1d10
    [  560.913419]  ? getname_flags+0x73/0x2b0
    [  560.913815]  ? kasan_save_stack+0x3a/0x50
    [  560.914125]  ? kasan_save_stack+0x26/0x50
    [  560.914542]  ? __kasan_slab_alloc+0x6d/0x90
    [  560.914924]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.915339]  ? getname_flags+0x73/0x2b0
    [  560.915647]  ? getname+0x12/0x20
    [  560.916114]  ? __x64_sys_open+0x4c/0x60
    [  560.916460]  ? path_lookupat.isra.0+0x230/0x230
    [  560.916867]  ? __isolate_free_page+0x2e0/0x2e0
    [  560.917194]  do_filp_open+0x15c/0x1f0
    [  560.917448]  ? may_open_dev+0x60/0x60
    [  560.917696]  ? expand_files+0xa4/0x3a0
    [  560.917923]  ? __kasan_check_write+0x14/0x20
    [  560.918185]  ? _raw_spin_lock+0x88/0xdb
    [  560.918409]  ? _raw_spin_lock_irqsave+0x100/0x100
    [  560.918783]  ? _find_next_bit+0x4a/0x130
    [  560.919026]  ? _raw_spin_unlock+0x19/0x40
    [  560.919276]  ? alloc_fd+0x14b/0x2d0
    [  560.919635]  do_sys_openat2+0x32a/0x4b0
    [  560.920035]  ? file_open_root+0x230/0x230
    [  560.920336]  ? __rcu_read_unlock+0x5b/0x280
    [  560.920813]  do_sys_open+0x99/0xf0
    [  560.921208]  ? filp_open+0x60/0x60
    [  560.921482]  ? exit_to_user_mode_prepare+0x49/0x180
    [  560.921867]  __x64_sys_open+0x4c/0x60
    [  560.922128]  do_syscall_64+0x3b/0x90
    [  560.922369]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.923030] RIP: 0033:0x7f7dff2e4469
    [  560.923681] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  560.924451] RSP: 002b:00007ffd41a210b8 EFLAGS: 00000206 ORIG_RAX: 0000000000000002
    [  560.925168] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f7dff2e4469
    [  560.925655] RDX: 0000000000000000 RSI: 0000000000000002 RDI: 00007ffd41a211f0
    [  560.926085] RBP: 00007ffd41a252a0 R08: 00007f7dff60fba0 R09: 00007ffd41a25388
    [  560.926405] R10: 0000000000400b80 R11: 0000000000000206 R12: 00000000004004e0
    [  560.926867] R13: 00007ffd41a25380 R14: 0000000000000000 R15: 0000000000000000
    [  560.927241]  </TASK>
    [  560.927491]
    [  560.927755] Allocated by task 245:
    [  560.928409]  kasan_save_stack+0x26/0x50
    [  560.929271]  __kasan_kmalloc+0x88/0xb0
    [  560.929778]  __kmalloc+0x192/0x320
    [  560.930023]  indx_read+0x249/0x380
    [  560.930224]  indx_find+0x2a2/0x470
    [  560.930695]  dir_search_u+0x196/0x2f0
    [  560.930892]  ntfs_lookup+0xe0/0x100
    [  560.931115]  __lookup_slow+0x116/0x220
    [  560.931323]  walk_component+0x187/0x230
    [  560.931570]  link_path_walk.part.0+0x3f0/0x660
    [  560.931791]  path_openat+0x19c/0x1d10
    [  560.932008]  do_filp_open+0x15c/0x1f0
    [  560.932226]  do_sys_openat2+0x32a/0x4b0
    [  560.932413]  do_sys_open+0x99/0xf0
    [  560.932709]  __x64_sys_open+0x4c/0x60
    [  560.933417]  do_syscall_64+0x3b/0x90
    [  560.933776]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.934235]
    [  560.934486] The buggy address belongs to the object at ffff888009497000
    [  560.934486]  which belongs to the cache kmalloc-512 of size 512
    [  560.935239] The buggy address is located 56 bytes to the right of
    [  560.935239]  512-byte region [ffff888009497000, ffff888009497200)
    [  560.936153]
    [  560.937326] The buggy address belongs to the physical page:
    [  560.938228] page:0000000062a3dfae refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x9496
    [  560.939616] head:0000000062a3dfae order:1 compound_mapcount:0 compound_pincount:0
    [  560.940219] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  560.942702] raw: 000fffffc0010200 ffffea0000164f80 dead000000000005 ffff888001041c80
    [  560.943932] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  560.944568] page dumped because: kasan: bad access detected
    [  560.945735]
    [  560.946112] Memory state around the buggy address:
    [  560.946870]  ffff888009497100: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947242]  ffff888009497180: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947611] >ffff888009497200: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.947915]                                         ^
    [  560.948249]  ffff888009497280: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.948687]  ffff888009497300: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6f6fc680b28a20b51156645c9f32908ec94eb8c9
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Fri Sep 23 00:50:23 2022 +0800

    fs/ntfs3: Validate resident attribute name
    
    [ Upstream commit 54e45702b648b7c0000e90b3e9b890e367e16ea8 ]
    
    Though we already have some sanity checks while enumerating attributes,
    resident attribute names aren't included. This patch checks the resident
    attribute names are in the valid ranges.
    
    [  259.209031] BUG: KASAN: slab-out-of-bounds in ni_create_attr_list+0x1e1/0x850
    [  259.210770] Write of size 426 at addr ffff88800632f2b2 by task exp/255
    [  259.211551]
    [  259.212035] CPU: 0 PID: 255 Comm: exp Not tainted 6.0.0-rc6 #37
    [  259.212955] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  259.214387] Call Trace:
    [  259.214640]  <TASK>
    [  259.214895]  dump_stack_lvl+0x49/0x63
    [  259.215284]  print_report.cold+0xf5/0x689
    [  259.215565]  ? kasan_poison+0x3c/0x50
    [  259.215778]  ? kasan_unpoison+0x28/0x60
    [  259.215991]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216270]  kasan_report+0xa7/0x130
    [  259.216481]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216719]  kasan_check_range+0x15a/0x1d0
    [  259.216939]  memcpy+0x3c/0x70
    [  259.217136]  ni_create_attr_list+0x1e1/0x850
    [  259.217945]  ? __rcu_read_unlock+0x5b/0x280
    [  259.218384]  ? ni_remove_attr+0x2e0/0x2e0
    [  259.218712]  ? kernel_text_address+0xcf/0xe0
    [  259.219064]  ? __kernel_text_address+0x12/0x40
    [  259.219434]  ? arch_stack_walk+0x9e/0xf0
    [  259.219668]  ? __this_cpu_preempt_check+0x13/0x20
    [  259.219904]  ? sysvec_apic_timer_interrupt+0x57/0xc0
    [  259.220140]  ? asm_sysvec_apic_timer_interrupt+0x1b/0x20
    [  259.220561]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.220984]  ? ni_create_attr_list+0x850/0x850
    [  259.221532]  ? run_deallocate+0x120/0x120
    [  259.221972]  ? vfs_setxattr+0x128/0x300
    [  259.222688]  ? setxattr+0x126/0x140
    [  259.222921]  ? path_setxattr+0x164/0x180
    [  259.223431]  ? __x64_sys_setxattr+0x6d/0x80
    [  259.223828]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.224417]  ? mi_find_attr+0x3c/0xf0
    [  259.224772]  ni_insert_attr+0x1ba/0x420
    [  259.225216]  ? ni_ins_attr_ext+0x5c0/0x5c0
    [  259.225504]  ? ntfs_read_ea+0x119/0x450
    [  259.225775]  ni_insert_resident+0xc0/0x1c0
    [  259.226316]  ? ni_insert_nonresident+0x400/0x400
    [  259.227001]  ? __kasan_kmalloc+0x88/0xb0
    [  259.227468]  ? __kmalloc+0x192/0x320
    [  259.227773]  ntfs_set_ea+0x6bf/0xb30
    [  259.228216]  ? ftrace_graph_ret_addr+0x2a/0xb0
    [  259.228494]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.228838]  ? ntfs_read_ea+0x450/0x450
    [  259.229098]  ? is_bpf_text_address+0x24/0x40
    [  259.229418]  ? kernel_text_address+0xcf/0xe0
    [  259.229681]  ? __kernel_text_address+0x12/0x40
    [  259.229948]  ? unwind_get_return_address+0x3a/0x60
    [  259.230271]  ? write_profile+0x270/0x270
    [  259.230537]  ? arch_stack_walk+0x9e/0xf0
    [  259.230836]  ntfs_setxattr+0x114/0x5c0
    [  259.231099]  ? ntfs_set_acl_ex+0x2e0/0x2e0
    [  259.231529]  ? evm_protected_xattr_common+0x6d/0x100
    [  259.231817]  ? posix_xattr_acl+0x13/0x80
    [  259.232073]  ? evm_protect_xattr+0x1f7/0x440
    [  259.232351]  __vfs_setxattr+0xda/0x120
    [  259.232635]  ? xattr_resolve_name+0x180/0x180
    [  259.232912]  __vfs_setxattr_noperm+0x93/0x300
    [  259.233219]  __vfs_setxattr_locked+0x141/0x160
    [  259.233492]  ? kasan_poison+0x3c/0x50
    [  259.233744]  vfs_setxattr+0x128/0x300
    [  259.234002]  ? __vfs_setxattr_locked+0x160/0x160
    [  259.234837]  do_setxattr+0xb8/0x170
    [  259.235567]  ? vmemdup_user+0x53/0x90
    [  259.236212]  setxattr+0x126/0x140
    [  259.236491]  ? do_setxattr+0x170/0x170
    [  259.236791]  ? debug_smp_processor_id+0x17/0x20
    [  259.237232]  ? kasan_quarantine_put+0x57/0x180
    [  259.237605]  ? putname+0x80/0xa0
    [  259.237870]  ? __kasan_slab_free+0x11c/0x1b0
    [  259.238234]  ? putname+0x80/0xa0
    [  259.238500]  ? preempt_count_sub+0x18/0xc0
    [  259.238775]  ? __mnt_want_write+0xaa/0x100
    [  259.238990]  ? mnt_want_write+0x8b/0x150
    [  259.239290]  path_setxattr+0x164/0x180
    [  259.239605]  ? setxattr+0x140/0x140
    [  259.239849]  ? debug_smp_processor_id+0x17/0x20
    [  259.240174]  ? fpregs_assert_state_consistent+0x67/0x80
    [  259.240411]  __x64_sys_setxattr+0x6d/0x80
    [  259.240715]  do_syscall_64+0x3b/0x90
    [  259.240934]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.241697] RIP: 0033:0x7fc6b26e4469
    [  259.242647] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  259.244512] RSP: 002b:00007ffc3c7841f8 EFLAGS: 00000217 ORIG_RAX: 00000000000000bc
    [  259.245086] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007fc6b26e4469
    [  259.246025] RDX: 00007ffc3c784380 RSI: 00007ffc3c7842e0 RDI: 00007ffc3c784238
    [  259.246961] RBP: 00007ffc3c788410 R08: 0000000000000001 R09: 00007ffc3c7884f8
    [  259.247775] R10: 000000000000007f R11: 0000000000000217 R12: 00000000004004e0
    [  259.248534] R13: 00007ffc3c7884f0 R14: 0000000000000000 R15: 0000000000000000
    [  259.249368]  </TASK>
    [  259.249644]
    [  259.249888] Allocated by task 255:
    [  259.250283]  kasan_save_stack+0x26/0x50
    [  259.250957]  __kasan_kmalloc+0x88/0xb0
    [  259.251826]  __kmalloc+0x192/0x320
    [  259.252745]  ni_create_attr_list+0x11e/0x850
    [  259.253298]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.253685]  ni_insert_attr+0x1ba/0x420
    [  259.253974]  ni_insert_resident+0xc0/0x1c0
    [  259.254311]  ntfs_set_ea+0x6bf/0xb30
    [  259.254629]  ntfs_setxattr+0x114/0x5c0
    [  259.254859]  __vfs_setxattr+0xda/0x120
    [  259.255155]  __vfs_setxattr_noperm+0x93/0x300
    [  259.255445]  __vfs_setxattr_locked+0x141/0x160
    [  259.255862]  vfs_setxattr+0x128/0x300
    [  259.256251]  do_setxattr+0xb8/0x170
    [  259.256522]  setxattr+0x126/0x140
    [  259.256911]  path_setxattr+0x164/0x180
    [  259.257308]  __x64_sys_setxattr+0x6d/0x80
    [  259.257637]  do_syscall_64+0x3b/0x90
    [  259.257970]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.258550]
    [  259.258772] The buggy address belongs to the object at ffff88800632f000
    [  259.258772]  which belongs to the cache kmalloc-1k of size 1024
    [  259.260190] The buggy address is located 690 bytes inside of
    [  259.260190]  1024-byte region [ffff88800632f000, ffff88800632f400)
    [  259.261412]
    [  259.261743] The buggy address belongs to the physical page:
    [  259.262354] page:0000000081e8cac9 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x632c
    [  259.263722] head:0000000081e8cac9 order:2 compound_mapcount:0 compound_pincount:0
    [  259.264284] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  259.265312] raw: 000fffffc0010200 ffffea0000060d00 dead000000000004 ffff888001041dc0
    [  259.265772] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  259.266305] page dumped because: kasan: bad access detected
    [  259.266588]
    [  259.266728] Memory state around the buggy address:
    [  259.267225]  ffff88800632f300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.267841]  ffff88800632f380: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.269111] >ffff88800632f400: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.269626]                    ^
    [  259.270162]  ffff88800632f480: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.270810]  ffff88800632f500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b15374365c9d10445ea7d66cdf885457a0223fc2
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Thu Sep 22 15:30:44 2022 +0800

    fs/ntfs3: Validate buffer length while parsing index
    
    [ Upstream commit 4d42ecda239cc13738d6fd84d098a32e67b368b9 ]
    
    indx_read is called when we have some NTFS directory operations that
    need more information from the index buffers. This adds a sanity check
    to make sure the returned index buffer length is legit, or we may have
    some out-of-bound memory accesses.
    
    [  560.897595] BUG: KASAN: slab-out-of-bounds in hdr_find_e.isra.0+0x10c/0x320
    [  560.898321] Read of size 2 at addr ffff888009497238 by task exp/245
    [  560.898760]
    [  560.899129] CPU: 0 PID: 245 Comm: exp Not tainted 6.0.0-rc6 #37
    [  560.899505] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  560.900170] Call Trace:
    [  560.900407]  <TASK>
    [  560.900732]  dump_stack_lvl+0x49/0x63
    [  560.901108]  print_report.cold+0xf5/0x689
    [  560.901395]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.901716]  kasan_report+0xa7/0x130
    [  560.901950]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.902208]  __asan_load2+0x68/0x90
    [  560.902427]  hdr_find_e.isra.0+0x10c/0x320
    [  560.902846]  ? cmp_uints+0xe0/0xe0
    [  560.903363]  ? cmp_sdh+0x90/0x90
    [  560.903883]  ? ntfs_bread_run+0x190/0x190
    [  560.904196]  ? rwsem_down_read_slowpath+0x750/0x750
    [  560.904969]  ? ntfs_fix_post_read+0xe0/0x130
    [  560.905259]  ? __kasan_check_write+0x14/0x20
    [  560.905599]  ? up_read+0x1a/0x90
    [  560.905853]  ? indx_read+0x22c/0x380
    [  560.906096]  indx_find+0x2ef/0x470
    [  560.906352]  ? indx_find_buffer+0x2d0/0x2d0
    [  560.906692]  ? __kasan_kmalloc+0x88/0xb0
    [  560.906977]  dir_search_u+0x196/0x2f0
    [  560.907220]  ? ntfs_nls_to_utf16+0x450/0x450
    [  560.907464]  ? __kasan_check_write+0x14/0x20
    [  560.907747]  ? mutex_lock+0x8f/0xe0
    [  560.907970]  ? __mutex_lock_slowpath+0x20/0x20
    [  560.908214]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.908459]  ntfs_lookup+0xe0/0x100
    [  560.908788]  __lookup_slow+0x116/0x220
    [  560.909050]  ? lookup_fast+0x1b0/0x1b0
    [  560.909309]  ? lookup_fast+0x13f/0x1b0
    [  560.909601]  walk_component+0x187/0x230
    [  560.909944]  link_path_walk.part.0+0x3f0/0x660
    [  560.910285]  ? handle_lookup_down+0x90/0x90
    [  560.910618]  ? path_init+0x642/0x6e0
    [  560.911084]  ? percpu_counter_add_batch+0x6e/0xf0
    [  560.912559]  ? __alloc_file+0x114/0x170
    [  560.913008]  path_openat+0x19c/0x1d10
    [  560.913419]  ? getname_flags+0x73/0x2b0
    [  560.913815]  ? kasan_save_stack+0x3a/0x50
    [  560.914125]  ? kasan_save_stack+0x26/0x50
    [  560.914542]  ? __kasan_slab_alloc+0x6d/0x90
    [  560.914924]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.915339]  ? getname_flags+0x73/0x2b0
    [  560.915647]  ? getname+0x12/0x20
    [  560.916114]  ? __x64_sys_open+0x4c/0x60
    [  560.916460]  ? path_lookupat.isra.0+0x230/0x230
    [  560.916867]  ? __isolate_free_page+0x2e0/0x2e0
    [  560.917194]  do_filp_open+0x15c/0x1f0
    [  560.917448]  ? may_open_dev+0x60/0x60
    [  560.917696]  ? expand_files+0xa4/0x3a0
    [  560.917923]  ? __kasan_check_write+0x14/0x20
    [  560.918185]  ? _raw_spin_lock+0x88/0xdb
    [  560.918409]  ? _raw_spin_lock_irqsave+0x100/0x100
    [  560.918783]  ? _find_next_bit+0x4a/0x130
    [  560.919026]  ? _raw_spin_unlock+0x19/0x40
    [  560.919276]  ? alloc_fd+0x14b/0x2d0
    [  560.919635]  do_sys_openat2+0x32a/0x4b0
    [  560.920035]  ? file_open_root+0x230/0x230
    [  560.920336]  ? __rcu_read_unlock+0x5b/0x280
    [  560.920813]  do_sys_open+0x99/0xf0
    [  560.921208]  ? filp_open+0x60/0x60
    [  560.921482]  ? exit_to_user_mode_prepare+0x49/0x180
    [  560.921867]  __x64_sys_open+0x4c/0x60
    [  560.922128]  do_syscall_64+0x3b/0x90
    [  560.922369]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.923030] RIP: 0033:0x7f7dff2e4469
    [  560.923681] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  560.924451] RSP: 002b:00007ffd41a210b8 EFLAGS: 00000206 ORIG_RAX: 0000000000000002
    [  560.925168] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f7dff2e4469
    [  560.925655] RDX: 0000000000000000 RSI: 0000000000000002 RDI: 00007ffd41a211f0
    [  560.926085] RBP: 00007ffd41a252a0 R08: 00007f7dff60fba0 R09: 00007ffd41a25388
    [  560.926405] R10: 0000000000400b80 R11: 0000000000000206 R12: 00000000004004e0
    [  560.926867] R13: 00007ffd41a25380 R14: 0000000000000000 R15: 0000000000000000
    [  560.927241]  </TASK>
    [  560.927491]
    [  560.927755] Allocated by task 245:
    [  560.928409]  kasan_save_stack+0x26/0x50
    [  560.929271]  __kasan_kmalloc+0x88/0xb0
    [  560.929778]  __kmalloc+0x192/0x320
    [  560.930023]  indx_read+0x249/0x380
    [  560.930224]  indx_find+0x2a2/0x470
    [  560.930695]  dir_search_u+0x196/0x2f0
    [  560.930892]  ntfs_lookup+0xe0/0x100
    [  560.931115]  __lookup_slow+0x116/0x220
    [  560.931323]  walk_component+0x187/0x230
    [  560.931570]  link_path_walk.part.0+0x3f0/0x660
    [  560.931791]  path_openat+0x19c/0x1d10
    [  560.932008]  do_filp_open+0x15c/0x1f0
    [  560.932226]  do_sys_openat2+0x32a/0x4b0
    [  560.932413]  do_sys_open+0x99/0xf0
    [  560.932709]  __x64_sys_open+0x4c/0x60
    [  560.933417]  do_syscall_64+0x3b/0x90
    [  560.933776]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.934235]
    [  560.934486] The buggy address belongs to the object at ffff888009497000
    [  560.934486]  which belongs to the cache kmalloc-512 of size 512
    [  560.935239] The buggy address is located 56 bytes to the right of
    [  560.935239]  512-byte region [ffff888009497000, ffff888009497200)
    [  560.936153]
    [  560.937326] The buggy address belongs to the physical page:
    [  560.938228] page:0000000062a3dfae refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x9496
    [  560.939616] head:0000000062a3dfae order:1 compound_mapcount:0 compound_pincount:0
    [  560.940219] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  560.942702] raw: 000fffffc0010200 ffffea0000164f80 dead000000000005 ffff888001041c80
    [  560.943932] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  560.944568] page dumped because: kasan: bad access detected
    [  560.945735]
    [  560.946112] Memory state around the buggy address:
    [  560.946870]  ffff888009497100: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947242]  ffff888009497180: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947611] >ffff888009497200: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.947915]                                         ^
    [  560.948249]  ffff888009497280: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.948687]  ffff888009497300: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1d854e4fbabb0cb12ca4a7fcd784eb67a65de5f8
Author: Qu Wenruo <wqu@suse.com>
Date:   Thu Dec 29 07:32:24 2022 +0800

    btrfs: fix false alert on bad tree level check
    
    [BUG]
    There is a bug report that on a RAID0 NVMe btrfs system, under heavy
    write load the filesystem can flip RO randomly.
    
    With extra debugging, it shows some tree blocks failed to pass their
    level checks, and if that happens at critical path of a transaction, we
    abort the transaction:
    
      BTRFS error (device nvme0n1p3): level verify failed on logical 5446121209856 mirror 1 wanted 0 found 1
      BTRFS error (device nvme0n1p3: state A): Transaction aborted (error -5)
      BTRFS: error (device nvme0n1p3: state A) in btrfs_finish_ordered_io:3343: errno=-5 IO failure
      BTRFS info (device nvme0n1p3: state EA): forced readonly
    
    [CAUSE]
    The reporter has already bisected to commit 947a629988f1 ("btrfs: move
    tree block parentness check into validate_extent_buffer()").
    
    And with extra debugging, it shows we can have btrfs_tree_parent_check
    filled with all zeros in the following call trace:
    
      submit_one_bio+0xd4/0xe0
      submit_extent_page+0x142/0x550
      read_extent_buffer_pages+0x584/0x9c0
      ? __pfx_end_bio_extent_readpage+0x10/0x10
      ? folio_unlock+0x1d/0x50
      btrfs_read_extent_buffer+0x98/0x150
      read_tree_block+0x43/0xa0
      read_block_for_search+0x266/0x370
      btrfs_search_slot+0x351/0xd30
      ? lock_is_held_type+0xe8/0x140
      btrfs_lookup_csum+0x63/0x150
      btrfs_csum_file_blocks+0x197/0x6c0
      ? sched_clock_cpu+0x9f/0xc0
      ? lock_release+0x14b/0x440
      ? _raw_read_unlock+0x29/0x50
      btrfs_finish_ordered_io+0x441/0x860
      btrfs_work_helper+0xfe/0x400
      ? lock_is_held_type+0xe8/0x140
      process_one_work+0x294/0x5b0
      worker_thread+0x4f/0x3a0
      ? __pfx_worker_thread+0x10/0x10
      kthread+0xf5/0x120
      ? __pfx_kthread+0x10/0x10
      ret_from_fork+0x2c/0x50
    
    Currently we only copy the btrfs_tree_parent_check structure into bbio
    at read_extent_buffer_pages() after we have assembled the bbio.
    
    But as shown above, submit_extent_page() itself can already submit the
    bbio, leaving the bbio->parent_check uninitialized, and cause the false
    alert.
    
    [FIX]
    Instead of copying @check into bbio after bbio is assembled, we pass
    @check in btrfs_bio_ctrl::parent_check, and copy the content of
    parent_check in submit_one_bio() for metadata read.
    
    By this we should be able to pass the needed info for metadata endio
    verification, and fix the false alert.
    
    Reported-by: Mikhail Gavrilov <mikhail.v.gavrilov@gmail.com>
    Link: https://lore.kernel.org/linux-btrfs/CABXGCsNzVxo4iq-tJSGm_kO1UggHXgq6CdcHDL=z5FL4njYXSQ@mail.gmail.com/
    Fixes: 947a629988f1 ("btrfs: move tree block parentness check into validate_extent_buffer()")
    Tested-by: Mikhail Gavrilov <mikhail.v.gavrilov@gmail.com>
    Signed-off-by: Qu Wenruo <wqu@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit 9aef34e1ae35a87e5f6a22278c17823b7ce64c88
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f52cf83c18cf95eba9d3737387f4ebd93608777f
Author: Bitterblue Smith <rtl8821cerfe2@gmail.com>
Date:   Mon Nov 21 22:56:58 2022 +0200

    wifi: rtl8xxxu: Fix use after rcu_read_unlock in rtl8xxxu_bss_info_changed
    
    [ Upstream commit 7927afb5e27baac694f585b59c436ba323528dc2 ]
    
    Commit a8b5aef2cca1 ("wifi: rtl8xxxu: gen2: Enable 40 MHz channel width")
    introduced a line where the pointer returned by ieee80211_find_sta() is
    used after rcu_read_unlock().
    
    Move rcu_read_unlock() a bit lower to fix this.
    
    Fixes: a8b5aef2cca1 ("wifi: rtl8xxxu: gen2: Enable 40 MHz channel width")
    Signed-off-by: Bitterblue Smith <rtl8821cerfe2@gmail.com>
    Reviewed-by: Ping-Ke Shih <pkshih@realtek.com>
    Signed-off-by: Kalle Valo <kvalo@kernel.org>
    Link: https://lore.kernel.org/r/3c82ad09-7593-3be1-1d2c-e58505fb43cb@gmail.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 601ae89375033ac4870c086e24ba03f235d38e55
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit bd5726c21f217e39bba47a6371ff9edcfa5a0bfb
Author: Bitterblue Smith <rtl8821cerfe2@gmail.com>
Date:   Mon Nov 21 22:56:58 2022 +0200

    wifi: rtl8xxxu: Fix use after rcu_read_unlock in rtl8xxxu_bss_info_changed
    
    [ Upstream commit 7927afb5e27baac694f585b59c436ba323528dc2 ]
    
    Commit a8b5aef2cca1 ("wifi: rtl8xxxu: gen2: Enable 40 MHz channel width")
    introduced a line where the pointer returned by ieee80211_find_sta() is
    used after rcu_read_unlock().
    
    Move rcu_read_unlock() a bit lower to fix this.
    
    Fixes: a8b5aef2cca1 ("wifi: rtl8xxxu: gen2: Enable 40 MHz channel width")
    Signed-off-by: Bitterblue Smith <rtl8821cerfe2@gmail.com>
    Reviewed-by: Ping-Ke Shih <pkshih@realtek.com>
    Signed-off-by: Kalle Valo <kvalo@kernel.org>
    Link: https://lore.kernel.org/r/3c82ad09-7593-3be1-1d2c-e58505fb43cb@gmail.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3eca9697c2f3905dea3ad2fc536ebaa1fbd735bd
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    [ Upstream commit b6702a942a069c2a975478d719e98d83cdae1797 ]
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1bb4f8be3797a1c12c1708253ca5535cff9afa9c
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Dec 3 18:37:21 2022 -0500

    tipc: call tipc_lxc_xmit without holding node_read_lock
    
    [ Upstream commit 88956177db179e4eba7cd590971961857d1565b8 ]
    
    When sending packets between nodes in netns, it calls tipc_lxc_xmit() for
    peer node to receive the packets where tipc_sk_mcast_rcv()/tipc_sk_rcv()
    might be called, and it's pretty much like in tipc_rcv().
    
    Currently the local 'node rw lock' is held during calling tipc_lxc_xmit()
    to protect the peer_net not being freed by another thread. However, when
    receiving these packets, tipc_node_add_conn() might be called where the
    peer 'node rw lock' is acquired. Then a dead lock warning is triggered by
    lockdep detector, although it is not a real dead lock:
    
        WARNING: possible recursive locking detected
        --------------------------------------------
        conn_server/1086 is trying to acquire lock:
        ffff8880065cb020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
    
        but task is already holding lock:
        ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_xmit+0x285/0xb30 [tipc]
    
        other info that might help us debug this:
         Possible unsafe locking scenario:
    
               CPU0
               ----
          lock(&n->lock#2);
          lock(&n->lock#2);
    
         *** DEADLOCK ***
    
         May be due to missing lock nesting notation
    
        4 locks held by conn_server/1086:
         #0: ffff8880036d1e40 (sk_lock-AF_TIPC){+.+.}-{0:0}, \
                              at: tipc_accept+0x9c0/0x10b0 [tipc]
         #1: ffff8880036d5f80 (sk_lock-AF_TIPC/1){+.+.}-{0:0}, \
                              at: tipc_accept+0x363/0x10b0 [tipc]
         #2: ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                              at: tipc_node_xmit+0x285/0xb30 [tipc]
         #3: ffff888012e13370 (slock-AF_TIPC){+...}-{2:2}, \
                              at: tipc_sk_rcv+0x2da/0x1b40 [tipc]
    
        Call Trace:
         <TASK>
         dump_stack_lvl+0x44/0x5b
         __lock_acquire.cold.77+0x1f2/0x3d7
         lock_acquire+0x1d2/0x610
         _raw_write_lock_bh+0x38/0x80
         tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
         tipc_sk_finish_conn+0x21e/0x640 [tipc]
         tipc_sk_filter_rcv+0x147b/0x3030 [tipc]
         tipc_sk_rcv+0xbb4/0x1b40 [tipc]
         tipc_lxc_xmit+0x225/0x26b [tipc]
         tipc_node_xmit.cold.82+0x4a/0x102 [tipc]
         __tipc_sendstream+0x879/0xff0 [tipc]
         tipc_accept+0x966/0x10b0 [tipc]
         do_accept+0x37d/0x590
    
    This patch avoids this warning by not holding the 'node rw lock' before
    calling tipc_lxc_xmit(). As to protect the 'peer_net', rcu_read_lock()
    should be enough, as in cleanup_net() when freeing the netns, it calls
    synchronize_rcu() before the free is continued.
    
    Also since tipc_lxc_xmit() is like the RX path in tipc_rcv(), it makes
    sense to call it under rcu_read_lock(). Note that the right lock order
    must be:
    
       rcu_read_lock();
       tipc_node_read_lock(n);
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    instead of:
    
       tipc_node_read_lock(n);
       rcu_read_lock();
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    and we have to call tipc_node_read_lock/unlock() twice in
    tipc_node_xmit().
    
    Fixes: f73b12812a3d ("tipc: improve throughput between nodes in netns")
    Reported-by: Shuang Li <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Link: https://lore.kernel.org/r/5bdd1f8fee9db695cfff4528a48c9b9d0523fb00.1670110641.git.lucien.xin@gmail.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d91edca1943453aaaba4f380f6f364346222e5cf
Author: Harshit Mogalapalli <harshit.m.mogalapalli@oracle.com>
Date:   Tue Dec 6 01:38:32 2022 -0800

    io_uring: Fix a null-ptr-deref in io_tctx_exit_cb()
    
    commit 998b30c3948e4d0b1097e639918c5cff332acac5 upstream.
    
    Syzkaller reports a NULL deref bug as follows:
    
     BUG: KASAN: null-ptr-deref in io_tctx_exit_cb+0x53/0xd3
     Read of size 4 at addr 0000000000000138 by task file1/1955
    
     CPU: 1 PID: 1955 Comm: file1 Not tainted 6.1.0-rc7-00103-gef4d3ea40565 #75
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.11.0-2.el7 04/01/2014
     Call Trace:
      <TASK>
      dump_stack_lvl+0xcd/0x134
      ? io_tctx_exit_cb+0x53/0xd3
      kasan_report+0xbb/0x1f0
      ? io_tctx_exit_cb+0x53/0xd3
      kasan_check_range+0x140/0x190
      io_tctx_exit_cb+0x53/0xd3
      task_work_run+0x164/0x250
      ? task_work_cancel+0x30/0x30
      get_signal+0x1c3/0x2440
      ? lock_downgrade+0x6e0/0x6e0
      ? lock_downgrade+0x6e0/0x6e0
      ? exit_signals+0x8b0/0x8b0
      ? do_raw_read_unlock+0x3b/0x70
      ? do_raw_spin_unlock+0x50/0x230
      arch_do_signal_or_restart+0x82/0x2470
      ? kmem_cache_free+0x260/0x4b0
      ? putname+0xfe/0x140
      ? get_sigframe_size+0x10/0x10
      ? do_execveat_common.isra.0+0x226/0x710
      ? lockdep_hardirqs_on+0x79/0x100
      ? putname+0xfe/0x140
      ? do_execveat_common.isra.0+0x238/0x710
      exit_to_user_mode_prepare+0x15f/0x250
      syscall_exit_to_user_mode+0x19/0x50
      do_syscall_64+0x42/0xb0
      entry_SYSCALL_64_after_hwframe+0x63/0xcd
     RIP: 0023:0x0
     Code: Unable to access opcode bytes at 0xffffffffffffffd6.
     RSP: 002b:00000000fffb7790 EFLAGS: 00000200 ORIG_RAX: 000000000000000b
     RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
      </TASK>
     Kernel panic - not syncing: panic_on_warn set ...
    
    This happens because the adding of task_work from io_ring_exit_work()
    isn't synchronized with canceling all work items from eg exec. The
    execution of the two are ordered in that they are both run by the task
    itself, but if io_tctx_exit_cb() is queued while we're canceling all
    work items off exec AND gets executed when the task exits to userspace
    rather than in the main loop in io_uring_cancel_generic(), then we can
    find current->io_uring == NULL and hit the above crash.
    
    It's safe to add this NULL check here, because the execution of the two
    paths are done by the task itself.
    
    Cc: stable@vger.kernel.org
    Fixes: d56d938b4bef ("io_uring: do ctx initiated file note removal")
    Reported-by: syzkaller <syzkaller@googlegroups.com>
    Signed-off-by: Harshit Mogalapalli <harshit.m.mogalapalli@oracle.com>
    Link: https://lore.kernel.org/r/20221206093833.3812138-1-harshit.m.mogalapalli@oracle.com
    [axboe: add code comment and also put an explanation in the commit msg]
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f895511de9d27fff71dad2c234ad53b4afd2b06c
Author: Harshit Mogalapalli <harshit.m.mogalapalli@oracle.com>
Date:   Tue Dec 6 01:38:32 2022 -0800

    io_uring: Fix a null-ptr-deref in io_tctx_exit_cb()
    
    [ Upstream commit 998b30c3948e4d0b1097e639918c5cff332acac5 ]
    
    Syzkaller reports a NULL deref bug as follows:
    
     BUG: KASAN: null-ptr-deref in io_tctx_exit_cb+0x53/0xd3
     Read of size 4 at addr 0000000000000138 by task file1/1955
    
     CPU: 1 PID: 1955 Comm: file1 Not tainted 6.1.0-rc7-00103-gef4d3ea40565 #75
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.11.0-2.el7 04/01/2014
     Call Trace:
      <TASK>
      dump_stack_lvl+0xcd/0x134
      ? io_tctx_exit_cb+0x53/0xd3
      kasan_report+0xbb/0x1f0
      ? io_tctx_exit_cb+0x53/0xd3
      kasan_check_range+0x140/0x190
      io_tctx_exit_cb+0x53/0xd3
      task_work_run+0x164/0x250
      ? task_work_cancel+0x30/0x30
      get_signal+0x1c3/0x2440
      ? lock_downgrade+0x6e0/0x6e0
      ? lock_downgrade+0x6e0/0x6e0
      ? exit_signals+0x8b0/0x8b0
      ? do_raw_read_unlock+0x3b/0x70
      ? do_raw_spin_unlock+0x50/0x230
      arch_do_signal_or_restart+0x82/0x2470
      ? kmem_cache_free+0x260/0x4b0
      ? putname+0xfe/0x140
      ? get_sigframe_size+0x10/0x10
      ? do_execveat_common.isra.0+0x226/0x710
      ? lockdep_hardirqs_on+0x79/0x100
      ? putname+0xfe/0x140
      ? do_execveat_common.isra.0+0x238/0x710
      exit_to_user_mode_prepare+0x15f/0x250
      syscall_exit_to_user_mode+0x19/0x50
      do_syscall_64+0x42/0xb0
      entry_SYSCALL_64_after_hwframe+0x63/0xcd
     RIP: 0023:0x0
     Code: Unable to access opcode bytes at 0xffffffffffffffd6.
     RSP: 002b:00000000fffb7790 EFLAGS: 00000200 ORIG_RAX: 000000000000000b
     RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
      </TASK>
     Kernel panic - not syncing: panic_on_warn set ...
    
    This happens because the adding of task_work from io_ring_exit_work()
    isn't synchronized with canceling all work items from eg exec. The
    execution of the two are ordered in that they are both run by the task
    itself, but if io_tctx_exit_cb() is queued while we're canceling all
    work items off exec AND gets executed when the task exits to userspace
    rather than in the main loop in io_uring_cancel_generic(), then we can
    find current->io_uring == NULL and hit the above crash.
    
    It's safe to add this NULL check here, because the execution of the two
    paths are done by the task itself.
    
    Cc: stable@vger.kernel.org
    Fixes: d56d938b4bef ("io_uring: do ctx initiated file note removal")
    Reported-by: syzkaller <syzkaller@googlegroups.com>
    Signed-off-by: Harshit Mogalapalli <harshit.m.mogalapalli@oracle.com>
    Link: https://lore.kernel.org/r/20221206093833.3812138-1-harshit.m.mogalapalli@oracle.com
    [axboe: add code comment and also put an explanation in the commit msg]
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d962d42d637613e16c7be218a167d42257eac5f4
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Dec 3 18:37:21 2022 -0500

    tipc: call tipc_lxc_xmit without holding node_read_lock
    
    [ Upstream commit 88956177db179e4eba7cd590971961857d1565b8 ]
    
    When sending packets between nodes in netns, it calls tipc_lxc_xmit() for
    peer node to receive the packets where tipc_sk_mcast_rcv()/tipc_sk_rcv()
    might be called, and it's pretty much like in tipc_rcv().
    
    Currently the local 'node rw lock' is held during calling tipc_lxc_xmit()
    to protect the peer_net not being freed by another thread. However, when
    receiving these packets, tipc_node_add_conn() might be called where the
    peer 'node rw lock' is acquired. Then a dead lock warning is triggered by
    lockdep detector, although it is not a real dead lock:
    
        WARNING: possible recursive locking detected
        --------------------------------------------
        conn_server/1086 is trying to acquire lock:
        ffff8880065cb020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
    
        but task is already holding lock:
        ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_xmit+0x285/0xb30 [tipc]
    
        other info that might help us debug this:
         Possible unsafe locking scenario:
    
               CPU0
               ----
          lock(&n->lock#2);
          lock(&n->lock#2);
    
         *** DEADLOCK ***
    
         May be due to missing lock nesting notation
    
        4 locks held by conn_server/1086:
         #0: ffff8880036d1e40 (sk_lock-AF_TIPC){+.+.}-{0:0}, \
                              at: tipc_accept+0x9c0/0x10b0 [tipc]
         #1: ffff8880036d5f80 (sk_lock-AF_TIPC/1){+.+.}-{0:0}, \
                              at: tipc_accept+0x363/0x10b0 [tipc]
         #2: ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                              at: tipc_node_xmit+0x285/0xb30 [tipc]
         #3: ffff888012e13370 (slock-AF_TIPC){+...}-{2:2}, \
                              at: tipc_sk_rcv+0x2da/0x1b40 [tipc]
    
        Call Trace:
         <TASK>
         dump_stack_lvl+0x44/0x5b
         __lock_acquire.cold.77+0x1f2/0x3d7
         lock_acquire+0x1d2/0x610
         _raw_write_lock_bh+0x38/0x80
         tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
         tipc_sk_finish_conn+0x21e/0x640 [tipc]
         tipc_sk_filter_rcv+0x147b/0x3030 [tipc]
         tipc_sk_rcv+0xbb4/0x1b40 [tipc]
         tipc_lxc_xmit+0x225/0x26b [tipc]
         tipc_node_xmit.cold.82+0x4a/0x102 [tipc]
         __tipc_sendstream+0x879/0xff0 [tipc]
         tipc_accept+0x966/0x10b0 [tipc]
         do_accept+0x37d/0x590
    
    This patch avoids this warning by not holding the 'node rw lock' before
    calling tipc_lxc_xmit(). As to protect the 'peer_net', rcu_read_lock()
    should be enough, as in cleanup_net() when freeing the netns, it calls
    synchronize_rcu() before the free is continued.
    
    Also since tipc_lxc_xmit() is like the RX path in tipc_rcv(), it makes
    sense to call it under rcu_read_lock(). Note that the right lock order
    must be:
    
       rcu_read_lock();
       tipc_node_read_lock(n);
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    instead of:
    
       tipc_node_read_lock(n);
       rcu_read_lock();
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    and we have to call tipc_node_read_lock/unlock() twice in
    tipc_node_xmit().
    
    Fixes: f73b12812a3d ("tipc: improve throughput between nodes in netns")
    Reported-by: Shuang Li <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Link: https://lore.kernel.org/r/5bdd1f8fee9db695cfff4528a48c9b9d0523fb00.1670110641.git.lucien.xin@gmail.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit cc668fddde4262f608baca2c9d85b9cf333e41c3
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Dec 3 18:37:21 2022 -0500

    tipc: call tipc_lxc_xmit without holding node_read_lock
    
    [ Upstream commit 88956177db179e4eba7cd590971961857d1565b8 ]
    
    When sending packets between nodes in netns, it calls tipc_lxc_xmit() for
    peer node to receive the packets where tipc_sk_mcast_rcv()/tipc_sk_rcv()
    might be called, and it's pretty much like in tipc_rcv().
    
    Currently the local 'node rw lock' is held during calling tipc_lxc_xmit()
    to protect the peer_net not being freed by another thread. However, when
    receiving these packets, tipc_node_add_conn() might be called where the
    peer 'node rw lock' is acquired. Then a dead lock warning is triggered by
    lockdep detector, although it is not a real dead lock:
    
        WARNING: possible recursive locking detected
        --------------------------------------------
        conn_server/1086 is trying to acquire lock:
        ffff8880065cb020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
    
        but task is already holding lock:
        ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_xmit+0x285/0xb30 [tipc]
    
        other info that might help us debug this:
         Possible unsafe locking scenario:
    
               CPU0
               ----
          lock(&n->lock#2);
          lock(&n->lock#2);
    
         *** DEADLOCK ***
    
         May be due to missing lock nesting notation
    
        4 locks held by conn_server/1086:
         #0: ffff8880036d1e40 (sk_lock-AF_TIPC){+.+.}-{0:0}, \
                              at: tipc_accept+0x9c0/0x10b0 [tipc]
         #1: ffff8880036d5f80 (sk_lock-AF_TIPC/1){+.+.}-{0:0}, \
                              at: tipc_accept+0x363/0x10b0 [tipc]
         #2: ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                              at: tipc_node_xmit+0x285/0xb30 [tipc]
         #3: ffff888012e13370 (slock-AF_TIPC){+...}-{2:2}, \
                              at: tipc_sk_rcv+0x2da/0x1b40 [tipc]
    
        Call Trace:
         <TASK>
         dump_stack_lvl+0x44/0x5b
         __lock_acquire.cold.77+0x1f2/0x3d7
         lock_acquire+0x1d2/0x610
         _raw_write_lock_bh+0x38/0x80
         tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
         tipc_sk_finish_conn+0x21e/0x640 [tipc]
         tipc_sk_filter_rcv+0x147b/0x3030 [tipc]
         tipc_sk_rcv+0xbb4/0x1b40 [tipc]
         tipc_lxc_xmit+0x225/0x26b [tipc]
         tipc_node_xmit.cold.82+0x4a/0x102 [tipc]
         __tipc_sendstream+0x879/0xff0 [tipc]
         tipc_accept+0x966/0x10b0 [tipc]
         do_accept+0x37d/0x590
    
    This patch avoids this warning by not holding the 'node rw lock' before
    calling tipc_lxc_xmit(). As to protect the 'peer_net', rcu_read_lock()
    should be enough, as in cleanup_net() when freeing the netns, it calls
    synchronize_rcu() before the free is continued.
    
    Also since tipc_lxc_xmit() is like the RX path in tipc_rcv(), it makes
    sense to call it under rcu_read_lock(). Note that the right lock order
    must be:
    
       rcu_read_lock();
       tipc_node_read_lock(n);
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    instead of:
    
       tipc_node_read_lock(n);
       rcu_read_lock();
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    and we have to call tipc_node_read_lock/unlock() twice in
    tipc_node_xmit().
    
    Fixes: f73b12812a3d ("tipc: improve throughput between nodes in netns")
    Reported-by: Shuang Li <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Link: https://lore.kernel.org/r/5bdd1f8fee9db695cfff4528a48c9b9d0523fb00.1670110641.git.lucien.xin@gmail.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a312a8cc3c7fe96f5e54e69c676f5bd12995f44e
Merge: bf57ae2165ba 674b745e22b3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 12 15:48:36 2022 -0800

    Merge tag 'cgroup-for-6.2' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup
    
    Pull cgroup updates from Tejun Heo:
     "Nothing too interesting:
    
       - Add CONFIG_DEBUG_GROUP_REF which makes cgroup refcnt operations
         kprobable
    
       - A couple cpuset optimizations
    
       - Other misc changes including doc and test updates"
    
    * tag 'cgroup-for-6.2' of git://git.kernel.org/pub/scm/linux/kernel/git/tj/cgroup:
      cgroup: remove rcu_read_lock()/rcu_read_unlock() in critical section of spin_lock_irq()
      cgroup/cpuset: Improve cpuset_css_alloc() description
      kselftest/cgroup: Add cleanup() to test_cpuset_prs.sh
      cgroup/cpuset: Optimize cpuset_attach() on v2
      cgroup/cpuset: Skip spread flags update on v2
      kselftest/cgroup: Fix gathering number of CPUs
      cgroup: cgroup refcnt functions should be exported when CONFIG_DEBUG_CGROUP_REF
      cgroup: Implement DEBUG_CGROUP_REF

commit 1fab45ab6e823f9d7e5bc9520b2aa6564d6d58a7
Merge: 830b3c68c1fb 87492c06e68d
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Dec 12 07:47:15 2022 -0800

    Merge tag 'rcu.2022.12.02a' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu
    
    Pull RCU updates from Paul McKenney:
    
     - Documentation updates. This is the second in a series from an ongoing
       review of the RCU documentation.
    
     - Miscellaneous fixes.
    
     - Introduce a default-off Kconfig option that depends on RCU_NOCB_CPU
       that, on CPUs mentioned in the nohz_full or rcu_nocbs boot-argument
       CPU lists, causes call_rcu() to introduce delays.
    
       These delays result in significant power savings on nearly idle
       Android and ChromeOS systems. These savings range from a few percent
       to more than ten percent.
    
       This series also includes several commits that change call_rcu() to a
       new call_rcu_hurry() function that avoids these delays in a few
       cases, for example, where timely wakeups are required. Several of
       these are outside of RCU and thus have acks and reviews from the
       relevant maintainers.
    
     - Create an srcu_read_lock_nmisafe() and an srcu_read_unlock_nmisafe()
       for architectures that support NMIs, but which do not provide
       NMI-safe this_cpu_inc(). These NMI-safe SRCU functions are required
       by the upcoming lockless printk() work by John Ogness et al.
    
     - Changes providing minor but important increases in torture test
       coverage for the new RCU polled-grace-period APIs.
    
     - Changes to torturescript that avoid redundant kernel builds, thus
       providing about a 30% speedup for the torture.sh acceptance test.
    
    * tag 'rcu.2022.12.02a' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu: (49 commits)
      net: devinet: Reduce refcount before grace period
      net: Use call_rcu_hurry() for dst_release()
      workqueue: Make queue_rcu_work() use call_rcu_hurry()
      percpu-refcount: Use call_rcu_hurry() for atomic switch
      scsi/scsi_error: Use call_rcu_hurry() instead of call_rcu()
      rcu/rcutorture: Use call_rcu_hurry() where needed
      rcu/rcuscale: Use call_rcu_hurry() for async reader test
      rcu/sync: Use call_rcu_hurry() instead of call_rcu
      rcuscale: Add laziness and kfree tests
      rcu: Shrinker for lazy rcu
      rcu: Refactor code a bit in rcu_nocb_do_flush_bypass()
      rcu: Make call_rcu() lazy to save power
      rcu: Implement lockdep_rcu_enabled for !CONFIG_DEBUG_LOCK_ALLOC
      srcu: Debug NMI safety even on archs that don't require it
      srcu: Explain the reason behind the read side critical section on GP start
      srcu: Warn when NMI-unsafe API is used in NMI
      arch/s390: Add ARCH_HAS_NMI_SAFE_THIS_CPU_OPS Kconfig option
      arch/loongarch: Add ARCH_HAS_NMI_SAFE_THIS_CPU_OPS Kconfig option
      rcu: Fix __this_cpu_read() lockdep warning in rcu_force_quiescent_state()
      rcu-tasks: Make grace-period-age message human-readable
      ...

commit 0641b614d1154f32c0dacecea46aca7460b69e32
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    commit b52be557e24c47286738276121177a41f54e3b83 upstream.
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4a4073a2e2fe392db08c00c39fdc5e2f8f198547
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    commit b52be557e24c47286738276121177a41f54e3b83 upstream.
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cc1b4718cc42d298fcc923d55d19c03ecdadbaae
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    [ Upstream commit b52be557e24c47286738276121177a41f54e3b83 ]
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3ab84e89135bc5fb998a362e195716fea75bc51f
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    [ Upstream commit b52be557e24c47286738276121177a41f54e3b83 ]
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a1504a9e205691940d44bf94ad33267eefea3b5e
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    [ Upstream commit b52be557e24c47286738276121177a41f54e3b83 ]
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 39a60b24d1d7c3509d2ff9768ec4ca6c292419cb
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    [ Upstream commit b52be557e24c47286738276121177a41f54e3b83 ]
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2d14123617f9917126c78719e0eaae3badbd624f
Merge: 26c386ecf021 36aa10ffd648
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Wed Dec 7 17:09:13 2022 -0800

    Merge branch 'Document some recent core kfunc additions'
    
    David Vernet says:
    
    ====================
    
    A series of recent patch sets introduced kfuncs that allowed struct
    task_struct and struct cgroup objects to be used as kptrs. These were
    introduced in [0], [1], and [2].
    
    [0]: https://lore.kernel.org/lkml/20221120051004.3605026-1-void@manifault.com/
    [1]: https://lore.kernel.org/lkml/20221122145300.251210-2-void@manifault.com/T/
    [2]: https://lore.kernel.org/lkml/20221122055458.173143-1-void@manifault.com/
    
    These are "core" kfuncs, in that they may be used by a wide variety of
    possible BPF tracepoint or struct_ops programs, and are defined in
    kernel/bpf/helpers.c. Even though as kfuncs they have no ABI stability
    guarantees, they should still be properly documented. This patch set
    adds that documentation.
    
    Some other kfuncs were added recently as well, such as
    bpf_rcu_read_lock() and bpf_rcu_read_unlock(). Those could and should be
    added to this "Core kfuncs" section as well in subsequent patch sets.
    
    Note that this patch set does not contain documentation for
    bpf_task_acquire_not_zero(), or bpf_task_kptr_get(). As discussed in
    [3], those kfuncs currently always return NULL pending resolution on how
    to properly protect their arguments using RCU.
    
    [3]: https://lore.kernel.org/all/20221206210538.597606-1-void@manifault.com/
    ---
    Changelog:
    v2 -> v3:
    - Don't document bpf_task_kptr_get(), and instead provide a more
      substantive example for bpf_cgroup_kptr_get().
    - Further clarify expected behavior of bpf_task_from_pid() in comments
      (Alexei)
    
    v1 -> v2:
    - Expand comment to specify that a map holds a reference to a task kptr
      if we don't end up releasing it (Alexei)
    - Just read task->pid instead of using a probed read (Alexei)
    ====================
    
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

commit 998b30c3948e4d0b1097e639918c5cff332acac5
Author: Harshit Mogalapalli <harshit.m.mogalapalli@oracle.com>
Date:   Tue Dec 6 01:38:32 2022 -0800

    io_uring: Fix a null-ptr-deref in io_tctx_exit_cb()
    
    Syzkaller reports a NULL deref bug as follows:
    
     BUG: KASAN: null-ptr-deref in io_tctx_exit_cb+0x53/0xd3
     Read of size 4 at addr 0000000000000138 by task file1/1955
    
     CPU: 1 PID: 1955 Comm: file1 Not tainted 6.1.0-rc7-00103-gef4d3ea40565 #75
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.11.0-2.el7 04/01/2014
     Call Trace:
      <TASK>
      dump_stack_lvl+0xcd/0x134
      ? io_tctx_exit_cb+0x53/0xd3
      kasan_report+0xbb/0x1f0
      ? io_tctx_exit_cb+0x53/0xd3
      kasan_check_range+0x140/0x190
      io_tctx_exit_cb+0x53/0xd3
      task_work_run+0x164/0x250
      ? task_work_cancel+0x30/0x30
      get_signal+0x1c3/0x2440
      ? lock_downgrade+0x6e0/0x6e0
      ? lock_downgrade+0x6e0/0x6e0
      ? exit_signals+0x8b0/0x8b0
      ? do_raw_read_unlock+0x3b/0x70
      ? do_raw_spin_unlock+0x50/0x230
      arch_do_signal_or_restart+0x82/0x2470
      ? kmem_cache_free+0x260/0x4b0
      ? putname+0xfe/0x140
      ? get_sigframe_size+0x10/0x10
      ? do_execveat_common.isra.0+0x226/0x710
      ? lockdep_hardirqs_on+0x79/0x100
      ? putname+0xfe/0x140
      ? do_execveat_common.isra.0+0x238/0x710
      exit_to_user_mode_prepare+0x15f/0x250
      syscall_exit_to_user_mode+0x19/0x50
      do_syscall_64+0x42/0xb0
      entry_SYSCALL_64_after_hwframe+0x63/0xcd
     RIP: 0023:0x0
     Code: Unable to access opcode bytes at 0xffffffffffffffd6.
     RSP: 002b:00000000fffb7790 EFLAGS: 00000200 ORIG_RAX: 000000000000000b
     RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000
     RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
      </TASK>
     Kernel panic - not syncing: panic_on_warn set ...
    
    This happens because the adding of task_work from io_ring_exit_work()
    isn't synchronized with canceling all work items from eg exec. The
    execution of the two are ordered in that they are both run by the task
    itself, but if io_tctx_exit_cb() is queued while we're canceling all
    work items off exec AND gets executed when the task exits to userspace
    rather than in the main loop in io_uring_cancel_generic(), then we can
    find current->io_uring == NULL and hit the above crash.
    
    It's safe to add this NULL check here, because the execution of the two
    paths are done by the task itself.
    
    Cc: stable@vger.kernel.org
    Fixes: d56d938b4bef ("io_uring: do ctx initiated file note removal")
    Reported-by: syzkaller <syzkaller@googlegroups.com>
    Signed-off-by: Harshit Mogalapalli <harshit.m.mogalapalli@oracle.com>
    Link: https://lore.kernel.org/r/20221206093833.3812138-1-harshit.m.mogalapalli@oracle.com
    [axboe: add code comment and also put an explanation in the commit msg]
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 88956177db179e4eba7cd590971961857d1565b8
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Dec 3 18:37:21 2022 -0500

    tipc: call tipc_lxc_xmit without holding node_read_lock
    
    When sending packets between nodes in netns, it calls tipc_lxc_xmit() for
    peer node to receive the packets where tipc_sk_mcast_rcv()/tipc_sk_rcv()
    might be called, and it's pretty much like in tipc_rcv().
    
    Currently the local 'node rw lock' is held during calling tipc_lxc_xmit()
    to protect the peer_net not being freed by another thread. However, when
    receiving these packets, tipc_node_add_conn() might be called where the
    peer 'node rw lock' is acquired. Then a dead lock warning is triggered by
    lockdep detector, although it is not a real dead lock:
    
        WARNING: possible recursive locking detected
        --------------------------------------------
        conn_server/1086 is trying to acquire lock:
        ffff8880065cb020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
    
        but task is already holding lock:
        ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                         at: tipc_node_xmit+0x285/0xb30 [tipc]
    
        other info that might help us debug this:
         Possible unsafe locking scenario:
    
               CPU0
               ----
          lock(&n->lock#2);
          lock(&n->lock#2);
    
         *** DEADLOCK ***
    
         May be due to missing lock nesting notation
    
        4 locks held by conn_server/1086:
         #0: ffff8880036d1e40 (sk_lock-AF_TIPC){+.+.}-{0:0}, \
                              at: tipc_accept+0x9c0/0x10b0 [tipc]
         #1: ffff8880036d5f80 (sk_lock-AF_TIPC/1){+.+.}-{0:0}, \
                              at: tipc_accept+0x363/0x10b0 [tipc]
         #2: ffff8880065cd020 (&n->lock#2){++--}-{2:2}, \
                              at: tipc_node_xmit+0x285/0xb30 [tipc]
         #3: ffff888012e13370 (slock-AF_TIPC){+...}-{2:2}, \
                              at: tipc_sk_rcv+0x2da/0x1b40 [tipc]
    
        Call Trace:
         <TASK>
         dump_stack_lvl+0x44/0x5b
         __lock_acquire.cold.77+0x1f2/0x3d7
         lock_acquire+0x1d2/0x610
         _raw_write_lock_bh+0x38/0x80
         tipc_node_add_conn.cold.76+0xaa/0x211 [tipc]
         tipc_sk_finish_conn+0x21e/0x640 [tipc]
         tipc_sk_filter_rcv+0x147b/0x3030 [tipc]
         tipc_sk_rcv+0xbb4/0x1b40 [tipc]
         tipc_lxc_xmit+0x225/0x26b [tipc]
         tipc_node_xmit.cold.82+0x4a/0x102 [tipc]
         __tipc_sendstream+0x879/0xff0 [tipc]
         tipc_accept+0x966/0x10b0 [tipc]
         do_accept+0x37d/0x590
    
    This patch avoids this warning by not holding the 'node rw lock' before
    calling tipc_lxc_xmit(). As to protect the 'peer_net', rcu_read_lock()
    should be enough, as in cleanup_net() when freeing the netns, it calls
    synchronize_rcu() before the free is continued.
    
    Also since tipc_lxc_xmit() is like the RX path in tipc_rcv(), it makes
    sense to call it under rcu_read_lock(). Note that the right lock order
    must be:
    
       rcu_read_lock();
       tipc_node_read_lock(n);
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    instead of:
    
       tipc_node_read_lock(n);
       rcu_read_lock();
       tipc_node_read_unlock(n);
       tipc_lxc_xmit();
       rcu_read_unlock();
    
    and we have to call tipc_node_read_lock/unlock() twice in
    tipc_node_xmit().
    
    Fixes: f73b12812a3d ("tipc: improve throughput between nodes in netns")
    Reported-by: Shuang Li <shuali@redhat.com>
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Link: https://lore.kernel.org/r/5bdd1f8fee9db695cfff4528a48c9b9d0523fb00.1670110641.git.lucien.xin@gmail.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>

commit b52be557e24c47286738276121177a41f54e3b83
Author: Jann Horn <jannh@google.com>
Date:   Mon Dec 5 17:59:27 2022 +0100

    ipc/sem: Fix dangling sem_array access in semtimedop race
    
    When __do_semtimedop() goes to sleep because it has to wait for a
    semaphore value becoming zero or becoming bigger than some threshold, it
    links the on-stack sem_queue to the sem_array, then goes to sleep
    without holding a reference on the sem_array.
    
    When __do_semtimedop() comes back out of sleep, one of two things must
    happen:
    
     a) We prove that the on-stack sem_queue has been disconnected from the
        (possibly freed) sem_array, making it safe to return from the stack
        frame that the sem_queue exists in.
    
     b) We stabilize our reference to the sem_array, lock the sem_array, and
        detach the sem_queue from the sem_array ourselves.
    
    sem_array has RCU lifetime, so for case (b), the reference can be
    stabilized inside an RCU read-side critical section by locklessly
    checking whether the sem_queue is still connected to the sem_array.
    
    However, the current code does the lockless check on sem_queue before
    starting an RCU read-side critical section, so the result of the
    lockless check immediately becomes useless.
    
    Fix it by doing rcu_read_lock() before the lockless check.  Now RCU
    ensures that if we observe the object being on our queue, the object
    can't be freed until rcu_read_unlock().
    
    This bug is only hittable on kernel builds with full preemption support
    (either CONFIG_PREEMPT or PREEMPT_DYNAMIC with preempt=full).
    
    Fixes: 370b262c896e ("ipc/sem: avoid idr tree lookup for interrupted semop")
    Cc: stable@vger.kernel.org
    Signed-off-by: Jann Horn <jannh@google.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit fc956ae0de7fa25f99114609f21b76e7d38dc25c
Author: John Ogness <john.ogness@linutronix.de>
Date:   Wed Nov 16 17:27:27 2022 +0106

    printk: console_flush_all: use srcu console list iterator
    
    Guarantee safe iteration of the console list by using SRCU.
    
    Note that in the case of a handover, the SRCU read lock is also
    released. This is documented in the function description and as
    comments in the code. It is a bit tricky, but this preserves the
    lockdep lock ordering for the context handing over the
    console_lock:
    
      console_lock()
      | mutex_acquire(&console_lock_dep_map)       <-- console lock
      |
      console_unlock()
      | console_flush_all()
      | | srcu_read_lock(&console_srcu)            <-- srcu lock
      | | console_emit_next_record()
      | | | console_lock_spinning_disable_and_check()
      | | | | srcu_read_unlock(&console_srcu)      <-- srcu unlock
      | | | | mutex_release(&console_lock_dep_map) <-- console unlock
    
    Signed-off-by: John Ogness <john.ogness@linutronix.de>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Link: https://lore.kernel.org/r/20221116162152.193147-16-john.ogness@linutronix.de

commit 7927afb5e27baac694f585b59c436ba323528dc2
Author: Bitterblue Smith <rtl8821cerfe2@gmail.com>
Date:   Mon Nov 21 22:56:58 2022 +0200

    wifi: rtl8xxxu: Fix use after rcu_read_unlock in rtl8xxxu_bss_info_changed
    
    Commit a8b5aef2cca1 ("wifi: rtl8xxxu: gen2: Enable 40 MHz channel width")
    introduced a line where the pointer returned by ieee80211_find_sta() is
    used after rcu_read_unlock().
    
    Move rcu_read_unlock() a bit lower to fix this.
    
    Fixes: a8b5aef2cca1 ("wifi: rtl8xxxu: gen2: Enable 40 MHz channel width")
    Signed-off-by: Bitterblue Smith <rtl8821cerfe2@gmail.com>
    Reviewed-by: Ping-Ke Shih <pkshih@realtek.com>
    Signed-off-by: Kalle Valo <kvalo@kernel.org>
    Link: https://lore.kernel.org/r/3c82ad09-7593-3be1-1d2c-e58505fb43cb@gmail.com

commit 6099754a1493467d2db15a20756e32e9a69c2cec
Merge: f471748b7fe5 48671232fcb8
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Thu Nov 24 12:27:13 2022 -0800

    Merge branch 'bpf: Add bpf_rcu_read_lock() support'
    
    Yonghong Song says:
    
    ====================
    
    Currently, without rcu attribute info in BTF, the verifier treats
    rcu tagged pointer as a normal pointer. This might be a problem
    for sleepable program where rcu_read_lock()/unlock() is not available.
    For example, for a sleepable fentry program, if rcu protected memory
    access is interleaved with a sleepable helper/kfunc, it is possible
    the memory access after the sleepable helper/kfunc might be invalid
    since the object might have been freed then. Even without
    a sleepable helper/kfunc, without rcu_read_lock() protection,
    it is possible that the rcu protected object might be release
    in the middle of bpf program execution which may cause incorrect
    result.
    
    To prevent above cases, enable btf_type_tag("rcu") attributes,
    introduce new bpf_rcu_read_lock/unlock() kfuncs and add verifier support.
    
    In the rest of patch set, Patch 1 enabled btf_type_tag for __rcu
    attribute. Patche 2 added might_sleep in bpf_func_proto. Patch 3 added new
    bpf_rcu_read_lock/unlock() kfuncs and verifier support.
    Patch 4 added some tests for these two new kfuncs.
    
    Changelogs:
      v9 -> v10:
        . if no rcu tag support in vmlinux btf, using bpf_rcu_read_lock/unlock()
          will cause verification error.
        . at bpf_rcu_read_unlock(), invalidate rcu ptr to PTR_UNTRUSTED
          instead of SCALAR_VALUE.
        . a few other comment changes and other minor changes.
      v8 -> v9:
        . remove sleepable prog check for ld_abs/ind checking in rcu read
          lock region.
        . fix a test failure with gcc-compiled kernel.
        . a couple of other minor fixes.
      v7 -> v8:
        . add might_sleep in bpf_func_proto so we can easily identify whether
          a helper is sleepable or not.
        . do not enforce rcu rules for sleepable, e.g., rcu dereference must
          be in a bpf_rcu_read_lock region. This is to keep old code working
          fine.
        . Mark 'b' in 'b = a->b' (b is tagged with __rcu) as MEM_RCU only if
          'b = a->b' in rcu read region and 'a' is trusted. This adds safety
          guarantee for 'b' inside the rcu read region.
      v6 -> v7:
        . rebase on top of bpf-next.
        . remove the patch which enables sleepable program using
          cgrp_local_storage map. This is orthogonal to this patch set
          and will be addressed separately.
        . mark the rcu pointer dereference result as UNTRUSTED if inside
          a bpf_rcu_read_lock() region.
      v5 -> v6:
        . fix selftest prog miss_unlock which tested nested locking.
        . add comments in selftest prog cgrp_succ to explain how to handle
          nested memory access after rcu memory load.
      v4 -> v5:
        . add new test to aarch64 deny list.
      v3 -> v4:
        . fix selftest failures when built with gcc. gcc doesn't support
          btf_type_tag yet and some tests relies on that. skip these
          tests if vmlinux BTF does not have btf_type_tag("rcu").
      v2 -> v3:
        . went back to MEM_RCU approach with invalidate rcu ptr registers
          at bpf_rcu_read_unlock() place.
        . remove KF_RCU_LOCK/UNLOCK flag and compare btf_id at verification
          time instead.
      v1 -> v2:
        . use kfunc instead of helper for bpf_rcu_read_lock/unlock.
        . not use MEM_RCU bpf_type_flag, instead use active_rcu_lock
          in reg state to identify rcu ptr's.
        . Add more self tests.
        . add new test to s390x deny list.
    ====================
    
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

commit 9bb00b2895cbfe0ad410457b605d0a72524168c1
Author: Yonghong Song <yhs@fb.com>
Date:   Wed Nov 23 21:32:17 2022 -0800

    bpf: Add kfunc bpf_rcu_read_lock/unlock()
    
    Add two kfunc's bpf_rcu_read_lock() and bpf_rcu_read_unlock(). These two kfunc's
    can be used for all program types. The following is an example about how
    rcu pointer are used w.r.t. bpf_rcu_read_lock()/bpf_rcu_read_unlock().
    
      struct task_struct {
        ...
        struct task_struct              *last_wakee;
        struct task_struct __rcu        *real_parent;
        ...
      };
    
    Let us say prog does 'task = bpf_get_current_task_btf()' to get a
    'task' pointer. The basic rules are:
      - 'real_parent = task->real_parent' should be inside bpf_rcu_read_lock
        region. This is to simulate rcu_dereference() operation. The
        'real_parent' is marked as MEM_RCU only if (1). task->real_parent is
        inside bpf_rcu_read_lock region, and (2). task is a trusted ptr. So
        MEM_RCU marked ptr can be 'trusted' inside the bpf_rcu_read_lock region.
      - 'last_wakee = real_parent->last_wakee' should be inside bpf_rcu_read_lock
        region since it tries to access rcu protected memory.
      - the ptr 'last_wakee' will be marked as PTR_UNTRUSTED since in general
        it is not clear whether the object pointed by 'last_wakee' is valid or
        not even inside bpf_rcu_read_lock region.
    
    The verifier will reset all rcu pointer register states to untrusted
    at bpf_rcu_read_unlock() kfunc call site, so any such rcu pointer
    won't be trusted any more outside the bpf_rcu_read_lock() region.
    
    The current implementation does not support nested rcu read lock
    region in the prog.
    
    Acked-by: Martin KaFai Lau <martin.lau@kernel.org>
    Signed-off-by: Yonghong Song <yhs@fb.com>
    Link: https://lore.kernel.org/r/20221124053217.2373910-1-yhs@fb.com
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>

commit 674b745e22b3caae48ad20422795eefd3f832a7b
Author: Ran Tian <tianran_trtr@163.com>
Date:   Wed Nov 23 22:45:14 2022 +0800

    cgroup: remove rcu_read_lock()/rcu_read_unlock() in critical section of spin_lock_irq()
    
    spin_lock_irq() already disable preempt, so remove rcu_read_lock().
    
    Signed-off-by: Ran Tian <tianran_trtr@163.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit 61242001d6c9c253df7645dab090842d8da08764
Author: Michal Luczaj <mhal@rbox.co>
Date:   Thu Oct 13 21:12:19 2022 +0000

    KVM: Initialize gfn_to_pfn_cache locks in dedicated helper
    
    commit 52491a38b2c2411f3f0229dc6ad610349c704a41 upstream.
    
    Move the gfn_to_pfn_cache lock initialization to another helper and
    call the new helper during VM/vCPU creation.  There are race
    conditions possible due to kvm_gfn_to_pfn_cache_init()'s
    ability to re-initialize the cache's locks.
    
    For example: a race between ioctl(KVM_XEN_HVM_EVTCHN_SEND) and
    kvm_gfn_to_pfn_cache_init() leads to a corrupted shinfo gpc lock.
    
                    (thread 1)                |           (thread 2)
                                              |
     kvm_xen_set_evtchn_fast                  |
      read_lock_irqsave(&gpc->lock, ...)      |
                                              | kvm_gfn_to_pfn_cache_init
                                              |  rwlock_init(&gpc->lock)
      read_unlock_irqrestore(&gpc->lock, ...) |
    
    Rename "cache_init" and "cache_destroy" to activate+deactivate to
    avoid implying that the cache really is destroyed/freed.
    
    Note, there more races in the newly named kvm_gpc_activate() that will
    be addressed separately.
    
    Fixes: 982ed0de4753 ("KVM: Reinstate gfn_to_pfn_cache with invalidation support")
    Cc: stable@vger.kernel.org
    Suggested-by: Sean Christopherson <seanjc@google.com>
    Signed-off-by: Michal Luczaj <mhal@rbox.co>
    [sean: call out that this is a bug fix]
    Signed-off-by: Sean Christopherson <seanjc@google.com>
    Message-Id: <20221013211234.1318131-2-seanjc@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 43d5109296fab30b7467d7d399bb51f1bb27eff4
Author: Kuniyuki Iwashima <kuniyu@amazon.com>
Date:   Fri Oct 14 11:26:25 2022 -0700

    udp: Update reuse->has_conns under reuseport_lock.
    
    commit 69421bf98482d089e50799f45e48b25ce4a8d154 upstream.
    
    When we call connect() for a UDP socket in a reuseport group, we have
    to update sk->sk_reuseport_cb->has_conns to 1.  Otherwise, the kernel
    could select a unconnected socket wrongly for packets sent to the
    connected socket.
    
    However, the current way to set has_conns is illegal and possible to
    trigger that problem.  reuseport_has_conns() changes has_conns under
    rcu_read_lock(), which upgrades the RCU reader to the updater.  Then,
    it must do the update under the updater's lock, reuseport_lock, but
    it doesn't for now.
    
    For this reason, there is a race below where we fail to set has_conns
    resulting in the wrong socket selection.  To avoid the race, let's split
    the reader and updater with proper locking.
    
     cpu1                               cpu2
    +----+                             +----+
    
    __ip[46]_datagram_connect()        reuseport_grow()
    .                                  .
    |- reuseport_has_conns(sk, true)   |- more_reuse = __reuseport_alloc(more_socks_size)
    |  .                               |
    |  |- rcu_read_lock()
    |  |- reuse = rcu_dereference(sk->sk_reuseport_cb)
    |  |
    |  |                               |  /* reuse->has_conns == 0 here */
    |  |                               |- more_reuse->has_conns = reuse->has_conns
    |  |- reuse->has_conns = 1         |  /* more_reuse->has_conns SHOULD BE 1 HERE */
    |  |                               |
    |  |                               |- rcu_assign_pointer(reuse->socks[i]->sk_reuseport_cb,
    |  |                               |                     more_reuse)
    |  `- rcu_read_unlock()            `- kfree_rcu(reuse, rcu)
    |
    |- sk->sk_state = TCP_ESTABLISHED
    
    Note the likely(reuse) in reuseport_has_conns_set() is always true,
    but we put the test there for ease of review.  [0]
    
    For the record, usually, sk_reuseport_cb is changed under lock_sock().
    The only exception is reuseport_grow() & TCP reqsk migration case.
    
      1) shutdown() TCP listener, which is moved into the latter part of
         reuse->socks[] to migrate reqsk.
    
      2) New listen() overflows reuse->socks[] and call reuseport_grow().
    
      3) reuse->max_socks overflows u16 with the new listener.
    
      4) reuseport_grow() pops the old shutdown()ed listener from the array
         and update its sk->sk_reuseport_cb as NULL without lock_sock().
    
    shutdown()ed TCP sk->sk_reuseport_cb can be changed without lock_sock(),
    but, reuseport_has_conns_set() is called only for UDP under lock_sock(),
    so likely(reuse) never be false in reuseport_has_conns_set().
    
    [0]: https://lore.kernel.org/netdev/CANn89iLja=eQHbsM_Ta2sQF0tOGU8vAGrh_izRuuHjuO1ouUag@mail.gmail.com/
    
    Fixes: acdcecc61285 ("udp: correct reuseport selection with connected sockets")
    Signed-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>
    Link: https://lore.kernel.org/r/20221014182625.89913-1-kuniyu@amazon.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f687e2111b6f1745bb32b7575224fe564d45b8b8
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:30 2021 +0800

    fcntl: fix potential deadlocks for &fown_struct.lock
    
    [ Upstream commit f671a691e299f58835d4660d642582bf0e8f6fda ]
    
    Syzbot reports a potential deadlock in do_fcntl:
    
    ========================================================
    WARNING: possible irq lock inversion dependency detected
    5.12.0-syzkaller #0 Not tainted
    --------------------------------------------------------
    syz-executor132/8391 just changed the state of lock:
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: f_getown_ex fs/fcntl.c:211 [inline]
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: do_fcntl+0x8b4/0x1200 fs/fcntl.c:395
    but this lock was taken by another, HARDIRQ-safe lock in the past:
     (&dev->event_lock){-...}-{2:2}
    
    and interrupts could create inverse lock ordering between them.
    
    other info that might help us debug this:
    Chain exists of:
      &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&f->f_owner.lock);
                                   local_irq_disable();
                                   lock(&dev->event_lock);
                                   lock(&new->fa_lock);
      <Interrupt>
        lock(&dev->event_lock);
    
     *** DEADLOCK ***
    
    This happens because there is a lock hierarchy of
    &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    However, since &dev->event_lock is HARDIRQ-safe, interrupts have to be
    disabled while grabbing &f->f_owner.lock, otherwise we invert the lock
    hierarchy.
    
    Hence, we replace calls to read_lock/read_unlock on &f->f_owner.lock,
    with read_lock_irq/read_unlock_irq.
    
    Reported-and-tested-by: syzbot+e6d5398a02c516ce5e70@syzkaller.appspotmail.com
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a8df9d0428c7b2e4f0c7ab8da3803f3fdddfce4d
Author: Kuniyuki Iwashima <kuniyu@amazon.com>
Date:   Fri Oct 14 11:26:25 2022 -0700

    udp: Update reuse->has_conns under reuseport_lock.
    
    [ Upstream commit 69421bf98482d089e50799f45e48b25ce4a8d154 ]
    
    When we call connect() for a UDP socket in a reuseport group, we have
    to update sk->sk_reuseport_cb->has_conns to 1.  Otherwise, the kernel
    could select a unconnected socket wrongly for packets sent to the
    connected socket.
    
    However, the current way to set has_conns is illegal and possible to
    trigger that problem.  reuseport_has_conns() changes has_conns under
    rcu_read_lock(), which upgrades the RCU reader to the updater.  Then,
    it must do the update under the updater's lock, reuseport_lock, but
    it doesn't for now.
    
    For this reason, there is a race below where we fail to set has_conns
    resulting in the wrong socket selection.  To avoid the race, let's split
    the reader and updater with proper locking.
    
     cpu1                               cpu2
    +----+                             +----+
    
    __ip[46]_datagram_connect()        reuseport_grow()
    .                                  .
    |- reuseport_has_conns(sk, true)   |- more_reuse = __reuseport_alloc(more_socks_size)
    |  .                               |
    |  |- rcu_read_lock()
    |  |- reuse = rcu_dereference(sk->sk_reuseport_cb)
    |  |
    |  |                               |  /* reuse->has_conns == 0 here */
    |  |                               |- more_reuse->has_conns = reuse->has_conns
    |  |- reuse->has_conns = 1         |  /* more_reuse->has_conns SHOULD BE 1 HERE */
    |  |                               |
    |  |                               |- rcu_assign_pointer(reuse->socks[i]->sk_reuseport_cb,
    |  |                               |                     more_reuse)
    |  `- rcu_read_unlock()            `- kfree_rcu(reuse, rcu)
    |
    |- sk->sk_state = TCP_ESTABLISHED
    
    Note the likely(reuse) in reuseport_has_conns_set() is always true,
    but we put the test there for ease of review.  [0]
    
    For the record, usually, sk_reuseport_cb is changed under lock_sock().
    The only exception is reuseport_grow() & TCP reqsk migration case.
    
      1) shutdown() TCP listener, which is moved into the latter part of
         reuse->socks[] to migrate reqsk.
    
      2) New listen() overflows reuse->socks[] and call reuseport_grow().
    
      3) reuse->max_socks overflows u16 with the new listener.
    
      4) reuseport_grow() pops the old shutdown()ed listener from the array
         and update its sk->sk_reuseport_cb as NULL without lock_sock().
    
    shutdown()ed TCP sk->sk_reuseport_cb can be changed without lock_sock(),
    but, reuseport_has_conns_set() is called only for UDP under lock_sock(),
    so likely(reuse) never be false in reuseport_has_conns_set().
    
    [0]: https://lore.kernel.org/netdev/CANn89iLja=eQHbsM_Ta2sQF0tOGU8vAGrh_izRuuHjuO1ouUag@mail.gmail.com/
    
    Fixes: acdcecc61285 ("udp: correct reuseport selection with connected sockets")
    Signed-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>
    Link: https://lore.kernel.org/r/20221014182625.89913-1-kuniyu@amazon.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1fb3a672317fba2a54f1bc8a6401235c6f11f883
Author: Kuniyuki Iwashima <kuniyu@amazon.com>
Date:   Fri Oct 14 11:26:25 2022 -0700

    udp: Update reuse->has_conns under reuseport_lock.
    
    [ Upstream commit 69421bf98482d089e50799f45e48b25ce4a8d154 ]
    
    When we call connect() for a UDP socket in a reuseport group, we have
    to update sk->sk_reuseport_cb->has_conns to 1.  Otherwise, the kernel
    could select a unconnected socket wrongly for packets sent to the
    connected socket.
    
    However, the current way to set has_conns is illegal and possible to
    trigger that problem.  reuseport_has_conns() changes has_conns under
    rcu_read_lock(), which upgrades the RCU reader to the updater.  Then,
    it must do the update under the updater's lock, reuseport_lock, but
    it doesn't for now.
    
    For this reason, there is a race below where we fail to set has_conns
    resulting in the wrong socket selection.  To avoid the race, let's split
    the reader and updater with proper locking.
    
     cpu1                               cpu2
    +----+                             +----+
    
    __ip[46]_datagram_connect()        reuseport_grow()
    .                                  .
    |- reuseport_has_conns(sk, true)   |- more_reuse = __reuseport_alloc(more_socks_size)
    |  .                               |
    |  |- rcu_read_lock()
    |  |- reuse = rcu_dereference(sk->sk_reuseport_cb)
    |  |
    |  |                               |  /* reuse->has_conns == 0 here */
    |  |                               |- more_reuse->has_conns = reuse->has_conns
    |  |- reuse->has_conns = 1         |  /* more_reuse->has_conns SHOULD BE 1 HERE */
    |  |                               |
    |  |                               |- rcu_assign_pointer(reuse->socks[i]->sk_reuseport_cb,
    |  |                               |                     more_reuse)
    |  `- rcu_read_unlock()            `- kfree_rcu(reuse, rcu)
    |
    |- sk->sk_state = TCP_ESTABLISHED
    
    Note the likely(reuse) in reuseport_has_conns_set() is always true,
    but we put the test there for ease of review.  [0]
    
    For the record, usually, sk_reuseport_cb is changed under lock_sock().
    The only exception is reuseport_grow() & TCP reqsk migration case.
    
      1) shutdown() TCP listener, which is moved into the latter part of
         reuse->socks[] to migrate reqsk.
    
      2) New listen() overflows reuse->socks[] and call reuseport_grow().
    
      3) reuse->max_socks overflows u16 with the new listener.
    
      4) reuseport_grow() pops the old shutdown()ed listener from the array
         and update its sk->sk_reuseport_cb as NULL without lock_sock().
    
    shutdown()ed TCP sk->sk_reuseport_cb can be changed without lock_sock(),
    but, reuseport_has_conns_set() is called only for UDP under lock_sock(),
    so likely(reuse) never be false in reuseport_has_conns_set().
    
    [0]: https://lore.kernel.org/netdev/CANn89iLja=eQHbsM_Ta2sQF0tOGU8vAGrh_izRuuHjuO1ouUag@mail.gmail.com/
    
    Fixes: acdcecc61285 ("udp: correct reuseport selection with connected sockets")
    Signed-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>
    Link: https://lore.kernel.org/r/20221014182625.89913-1-kuniyu@amazon.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 52491a38b2c2411f3f0229dc6ad610349c704a41
Author: Michal Luczaj <mhal@rbox.co>
Date:   Thu Oct 13 21:12:19 2022 +0000

    KVM: Initialize gfn_to_pfn_cache locks in dedicated helper
    
    Move the gfn_to_pfn_cache lock initialization to another helper and
    call the new helper during VM/vCPU creation.  There are race
    conditions possible due to kvm_gfn_to_pfn_cache_init()'s
    ability to re-initialize the cache's locks.
    
    For example: a race between ioctl(KVM_XEN_HVM_EVTCHN_SEND) and
    kvm_gfn_to_pfn_cache_init() leads to a corrupted shinfo gpc lock.
    
                    (thread 1)                |           (thread 2)
                                              |
     kvm_xen_set_evtchn_fast                  |
      read_lock_irqsave(&gpc->lock, ...)      |
                                              | kvm_gfn_to_pfn_cache_init
                                              |  rwlock_init(&gpc->lock)
      read_unlock_irqrestore(&gpc->lock, ...) |
    
    Rename "cache_init" and "cache_destroy" to activate+deactivate to
    avoid implying that the cache really is destroyed/freed.
    
    Note, there more races in the newly named kvm_gpc_activate() that will
    be addressed separately.
    
    Fixes: 982ed0de4753 ("KVM: Reinstate gfn_to_pfn_cache with invalidation support")
    Cc: stable@vger.kernel.org
    Suggested-by: Sean Christopherson <seanjc@google.com>
    Signed-off-by: Michal Luczaj <mhal@rbox.co>
    [sean: call out that this is a bug fix]
    Signed-off-by: Sean Christopherson <seanjc@google.com>
    Message-Id: <20221013211234.1318131-2-seanjc@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

commit 3e2d8b89f03152e07c95ec3075a7b3606380982e
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Mon Aug 8 10:26:26 2022 +0800

    rcu: Avoid triggering strict-GP irq-work when RCU is idle
    
    [ Upstream commit 621189a1fe93cb2b34d62c5cdb9e258bca044813 ]
    
    Kernels built with PREEMPT_RCU=y and RCU_STRICT_GRACE_PERIOD=y trigger
    irq-work from rcu_read_unlock(), and the resulting irq-work handler
    invokes rcu_preempt_deferred_qs_handle().  The point of this triggering
    is to force grace periods to end quickly in order to give tools like KASAN
    a better chance of detecting RCU usage bugs such as leaking RCU-protected
    pointers out of an RCU read-side critical section.
    
    However, this irq-work triggering is unconditional.  This works, but
    there is no point in doing this irq-work unless the current grace period
    is waiting on the running CPU or task, which is not the common case.
    After all, in the common case there are many rcu_read_unlock() calls
    per CPU per grace period.
    
    This commit therefore triggers the irq-work only when the current grace
    period is waiting on the running CPU or task.
    
    This change was tested as follows on a four-CPU system:
    
            echo rcu_preempt_deferred_qs_handler > /sys/kernel/debug/tracing/set_ftrace_filter
            echo 1 > /sys/kernel/debug/tracing/function_profile_enabled
            insmod rcutorture.ko
            sleep 20
            rmmod rcutorture.ko
            echo 0 > /sys/kernel/debug/tracing/function_profile_enabled
            echo > /sys/kernel/debug/tracing/set_ftrace_filter
    
    This procedure produces results in this per-CPU set of files:
    
            /sys/kernel/debug/tracing/trace_stat/function*
    
    Sample output from one of these files is as follows:
    
      Function                               Hit    Time            Avg             s^2
      --------                               ---    ----            ---             ---
      rcu_preempt_deferred_qs_handle      838746    182650.3 us     0.217 us        0.004 us
    
    The baseline sum of the "Hit" values (the number of calls to this
    function) was 3,319,015.  With this commit, that sum was 1,140,359,
    for a 2.9x reduction.  The worst-case variance across the CPUs was less
    than 25%, so this large effect size is statistically significant.
    
    The raw data is available in the Link: URL.
    
    Link: https://lore.kernel.org/all/20220808022626.12825-1-qiang1.zhang@intel.com/
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 27d3e646dd83bafd7094890462eebfce3ac31e4a
Author: Alexander Aring <aahringo@redhat.com>
Date:   Mon Aug 15 15:43:13 2022 -0400

    fs: dlm: fix race in lowcomms
    
    [ Upstream commit 30ea3257e8766027c4d8d609dcbd256ff9a76073 ]
    
    This patch fixes a race between queue_work() in
    _dlm_lowcomms_commit_msg() and srcu_read_unlock(). The queue_work() can
    take the final reference of a dlm_msg and so msg->idx can contain
    garbage which is signaled by the following warning:
    
    [  676.237050] ------------[ cut here ]------------
    [  676.237052] WARNING: CPU: 0 PID: 1060 at include/linux/srcu.h:189 dlm_lowcomms_commit_msg+0x41/0x50
    [  676.238945] Modules linked in: dlm_locktorture torture rpcsec_gss_krb5 intel_rapl_msr intel_rapl_common iTCO_wdt iTCO_vendor_support qxl kvm_intel drm_ttm_helper vmw_vsock_virtio_transport kvm vmw_vsock_virtio_transport_common ttm irqbypass crc32_pclmul joydev crc32c_intel serio_raw drm_kms_helper vsock virtio_scsi virtio_console virtio_balloon snd_pcm drm syscopyarea sysfillrect sysimgblt snd_timer fb_sys_fops i2c_i801 lpc_ich snd i2c_smbus soundcore pcspkr
    [  676.244227] CPU: 0 PID: 1060 Comm: lock_torture_wr Not tainted 5.19.0-rc3+ #1546
    [  676.245216] Hardware name: Red Hat KVM/RHEL-AV, BIOS 1.16.0-2.module+el8.7.0+15506+033991b0 04/01/2014
    [  676.246460] RIP: 0010:dlm_lowcomms_commit_msg+0x41/0x50
    [  676.247132] Code: fe ff ff ff 75 24 48 c7 c6 bd 0f 49 bb 48 c7 c7 38 7c 01 bd e8 00 e7 ca ff 89 de 48 c7 c7 60 78 01 bd e8 42 3d cd ff 5b 5d c3 <0f> 0b eb d8 66 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 55 48
    [  676.249253] RSP: 0018:ffffa401c18ffc68 EFLAGS: 00010282
    [  676.249855] RAX: 0000000000000001 RBX: 00000000ffff8b76 RCX: 0000000000000006
    [  676.250713] RDX: 0000000000000000 RSI: ffffffffbccf3a10 RDI: ffffffffbcc7b62e
    [  676.251610] RBP: ffffa401c18ffc70 R08: 0000000000000001 R09: 0000000000000001
    [  676.252481] R10: 0000000000000001 R11: 0000000000000001 R12: 0000000000000005
    [  676.253421] R13: ffff8b76786ec370 R14: ffff8b76786ec370 R15: ffff8b76786ec480
    [  676.254257] FS:  0000000000000000(0000) GS:ffff8b7777800000(0000) knlGS:0000000000000000
    [  676.255239] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  676.255897] CR2: 00005590205d88b8 CR3: 000000017656c003 CR4: 0000000000770ee0
    [  676.256734] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  676.257567] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  676.258397] PKRU: 55555554
    [  676.258729] Call Trace:
    [  676.259063]  <TASK>
    [  676.259354]  dlm_midcomms_commit_mhandle+0xcc/0x110
    [  676.259964]  queue_bast+0x8b/0xb0
    [  676.260423]  grant_pending_locks+0x166/0x1b0
    [  676.261007]  _unlock_lock+0x75/0x90
    [  676.261469]  unlock_lock.isra.57+0x62/0xa0
    [  676.262009]  dlm_unlock+0x21e/0x330
    [  676.262457]  ? lock_torture_stats+0x80/0x80 [dlm_locktorture]
    [  676.263183]  torture_unlock+0x5a/0x90 [dlm_locktorture]
    [  676.263815]  ? preempt_count_sub+0xba/0x100
    [  676.264361]  ? complete+0x1d/0x60
    [  676.264777]  lock_torture_writer+0xb8/0x150 [dlm_locktorture]
    [  676.265555]  kthread+0x10a/0x130
    [  676.266007]  ? kthread_complete_and_exit+0x20/0x20
    [  676.266616]  ret_from_fork+0x22/0x30
    [  676.267097]  </TASK>
    [  676.267381] irq event stamp: 9579855
    [  676.267824] hardirqs last  enabled at (9579863): [<ffffffffbb14e6f8>] __up_console_sem+0x58/0x60
    [  676.268896] hardirqs last disabled at (9579872): [<ffffffffbb14e6dd>] __up_console_sem+0x3d/0x60
    [  676.270008] softirqs last  enabled at (9579798): [<ffffffffbc200349>] __do_softirq+0x349/0x4c7
    [  676.271438] softirqs last disabled at (9579897): [<ffffffffbb0d54c0>] irq_exit_rcu+0xb0/0xf0
    [  676.272796] ---[ end trace 0000000000000000 ]---
    
    I reproduced this warning with dlm_locktorture test which is currently
    not upstream. However this patch fix the issue by make a additional
    refcount between dlm_lowcomms_new_msg() and dlm_lowcomms_commit_msg().
    In case of the race the kref_put() in dlm_lowcomms_commit_msg() will be
    the final put.
    
    Signed-off-by: Alexander Aring <aahringo@redhat.com>
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1e9c23db31b6a004a04f39f646886d02c944632a
Author: Nico Pache <npache@redhat.com>
Date:   Mon Sep 19 08:49:32 2022 -0600

    tracing/osnoise: Fix possible recursive locking in stop_per_cpu_kthreads
    
    [ Upstream commit 99ee9317a1305cd5626736785c8cb38b0e47686c ]
    
    There is a recursive lock on the cpu_hotplug_lock.
    
    In kernel/trace/trace_osnoise.c:<start/stop>_per_cpu_kthreads:
        - start_per_cpu_kthreads calls cpus_read_lock() and if
            start_kthreads returns a error it will call stop_per_cpu_kthreads.
        - stop_per_cpu_kthreads then calls cpus_read_lock() again causing
          deadlock.
    
    Fix this by calling cpus_read_unlock() before calling
    stop_per_cpu_kthreads. This behavior can also be seen in commit
    f46b16520a08 ("trace/hwlat: Implement the per-cpu mode").
    
    This error was noticed during the LTP ftrace-stress-test:
    
    WARNING: possible recursive locking detected
    --------------------------------------------
    sh/275006 is trying to acquire lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: stop_per_cpu_kthreads
    
    but task is already holding lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
          CPU0
          ----
     lock(cpu_hotplug_lock);
     lock(cpu_hotplug_lock);
    
     *** DEADLOCK ***
    
    May be due to missing lock nesting notation
    
    3 locks held by sh/275006:
     #0: ffff8881023f0470 (sb_writers#24){.+.+}-{0:0}, at: ksys_write
     #1: ffffffffb084f430 (trace_types_lock){+.+.}-{3:3}, at: rb_simple_write
     #2: ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    Link: https://lkml.kernel.org/r/20220919144932.3064014-1-npache@redhat.com
    
    Fixes: c8895e271f79 ("trace/osnoise: Support hotplug operations")
    Signed-off-by: Nico Pache <npache@redhat.com>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit eaa91f54df78bcbafd112ef1babbdf417ff54104
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Mon Aug 8 10:26:26 2022 +0800

    rcu: Avoid triggering strict-GP irq-work when RCU is idle
    
    [ Upstream commit 621189a1fe93cb2b34d62c5cdb9e258bca044813 ]
    
    Kernels built with PREEMPT_RCU=y and RCU_STRICT_GRACE_PERIOD=y trigger
    irq-work from rcu_read_unlock(), and the resulting irq-work handler
    invokes rcu_preempt_deferred_qs_handle().  The point of this triggering
    is to force grace periods to end quickly in order to give tools like KASAN
    a better chance of detecting RCU usage bugs such as leaking RCU-protected
    pointers out of an RCU read-side critical section.
    
    However, this irq-work triggering is unconditional.  This works, but
    there is no point in doing this irq-work unless the current grace period
    is waiting on the running CPU or task, which is not the common case.
    After all, in the common case there are many rcu_read_unlock() calls
    per CPU per grace period.
    
    This commit therefore triggers the irq-work only when the current grace
    period is waiting on the running CPU or task.
    
    This change was tested as follows on a four-CPU system:
    
            echo rcu_preempt_deferred_qs_handler > /sys/kernel/debug/tracing/set_ftrace_filter
            echo 1 > /sys/kernel/debug/tracing/function_profile_enabled
            insmod rcutorture.ko
            sleep 20
            rmmod rcutorture.ko
            echo 0 > /sys/kernel/debug/tracing/function_profile_enabled
            echo > /sys/kernel/debug/tracing/set_ftrace_filter
    
    This procedure produces results in this per-CPU set of files:
    
            /sys/kernel/debug/tracing/trace_stat/function*
    
    Sample output from one of these files is as follows:
    
      Function                               Hit    Time            Avg             s^2
      --------                               ---    ----            ---             ---
      rcu_preempt_deferred_qs_handle      838746    182650.3 us     0.217 us        0.004 us
    
    The baseline sum of the "Hit" values (the number of calls to this
    function) was 3,319,015.  With this commit, that sum was 1,140,359,
    for a 2.9x reduction.  The worst-case variance across the CPUs was less
    than 25%, so this large effect size is statistically significant.
    
    The raw data is available in the Link: URL.
    
    Link: https://lore.kernel.org/all/20220808022626.12825-1-qiang1.zhang@intel.com/
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit eb97e60a9eae632ff9104a580dbc4fdc58dc23cb
Author: Alexander Aring <aahringo@redhat.com>
Date:   Mon Aug 15 15:43:13 2022 -0400

    fs: dlm: fix race in lowcomms
    
    [ Upstream commit 30ea3257e8766027c4d8d609dcbd256ff9a76073 ]
    
    This patch fixes a race between queue_work() in
    _dlm_lowcomms_commit_msg() and srcu_read_unlock(). The queue_work() can
    take the final reference of a dlm_msg and so msg->idx can contain
    garbage which is signaled by the following warning:
    
    [  676.237050] ------------[ cut here ]------------
    [  676.237052] WARNING: CPU: 0 PID: 1060 at include/linux/srcu.h:189 dlm_lowcomms_commit_msg+0x41/0x50
    [  676.238945] Modules linked in: dlm_locktorture torture rpcsec_gss_krb5 intel_rapl_msr intel_rapl_common iTCO_wdt iTCO_vendor_support qxl kvm_intel drm_ttm_helper vmw_vsock_virtio_transport kvm vmw_vsock_virtio_transport_common ttm irqbypass crc32_pclmul joydev crc32c_intel serio_raw drm_kms_helper vsock virtio_scsi virtio_console virtio_balloon snd_pcm drm syscopyarea sysfillrect sysimgblt snd_timer fb_sys_fops i2c_i801 lpc_ich snd i2c_smbus soundcore pcspkr
    [  676.244227] CPU: 0 PID: 1060 Comm: lock_torture_wr Not tainted 5.19.0-rc3+ #1546
    [  676.245216] Hardware name: Red Hat KVM/RHEL-AV, BIOS 1.16.0-2.module+el8.7.0+15506+033991b0 04/01/2014
    [  676.246460] RIP: 0010:dlm_lowcomms_commit_msg+0x41/0x50
    [  676.247132] Code: fe ff ff ff 75 24 48 c7 c6 bd 0f 49 bb 48 c7 c7 38 7c 01 bd e8 00 e7 ca ff 89 de 48 c7 c7 60 78 01 bd e8 42 3d cd ff 5b 5d c3 <0f> 0b eb d8 66 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 55 48
    [  676.249253] RSP: 0018:ffffa401c18ffc68 EFLAGS: 00010282
    [  676.249855] RAX: 0000000000000001 RBX: 00000000ffff8b76 RCX: 0000000000000006
    [  676.250713] RDX: 0000000000000000 RSI: ffffffffbccf3a10 RDI: ffffffffbcc7b62e
    [  676.251610] RBP: ffffa401c18ffc70 R08: 0000000000000001 R09: 0000000000000001
    [  676.252481] R10: 0000000000000001 R11: 0000000000000001 R12: 0000000000000005
    [  676.253421] R13: ffff8b76786ec370 R14: ffff8b76786ec370 R15: ffff8b76786ec480
    [  676.254257] FS:  0000000000000000(0000) GS:ffff8b7777800000(0000) knlGS:0000000000000000
    [  676.255239] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  676.255897] CR2: 00005590205d88b8 CR3: 000000017656c003 CR4: 0000000000770ee0
    [  676.256734] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  676.257567] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  676.258397] PKRU: 55555554
    [  676.258729] Call Trace:
    [  676.259063]  <TASK>
    [  676.259354]  dlm_midcomms_commit_mhandle+0xcc/0x110
    [  676.259964]  queue_bast+0x8b/0xb0
    [  676.260423]  grant_pending_locks+0x166/0x1b0
    [  676.261007]  _unlock_lock+0x75/0x90
    [  676.261469]  unlock_lock.isra.57+0x62/0xa0
    [  676.262009]  dlm_unlock+0x21e/0x330
    [  676.262457]  ? lock_torture_stats+0x80/0x80 [dlm_locktorture]
    [  676.263183]  torture_unlock+0x5a/0x90 [dlm_locktorture]
    [  676.263815]  ? preempt_count_sub+0xba/0x100
    [  676.264361]  ? complete+0x1d/0x60
    [  676.264777]  lock_torture_writer+0xb8/0x150 [dlm_locktorture]
    [  676.265555]  kthread+0x10a/0x130
    [  676.266007]  ? kthread_complete_and_exit+0x20/0x20
    [  676.266616]  ret_from_fork+0x22/0x30
    [  676.267097]  </TASK>
    [  676.267381] irq event stamp: 9579855
    [  676.267824] hardirqs last  enabled at (9579863): [<ffffffffbb14e6f8>] __up_console_sem+0x58/0x60
    [  676.268896] hardirqs last disabled at (9579872): [<ffffffffbb14e6dd>] __up_console_sem+0x3d/0x60
    [  676.270008] softirqs last  enabled at (9579798): [<ffffffffbc200349>] __do_softirq+0x349/0x4c7
    [  676.271438] softirqs last disabled at (9579897): [<ffffffffbb0d54c0>] irq_exit_rcu+0xb0/0xf0
    [  676.272796] ---[ end trace 0000000000000000 ]---
    
    I reproduced this warning with dlm_locktorture test which is currently
    not upstream. However this patch fix the issue by make a additional
    refcount between dlm_lowcomms_new_msg() and dlm_lowcomms_commit_msg().
    In case of the race the kref_put() in dlm_lowcomms_commit_msg() will be
    the final put.
    
    Signed-off-by: Alexander Aring <aahringo@redhat.com>
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fc9a0aa8361433dfd4df216d211ba6f110293ff3
Author: Nico Pache <npache@redhat.com>
Date:   Mon Sep 19 08:49:32 2022 -0600

    tracing/osnoise: Fix possible recursive locking in stop_per_cpu_kthreads
    
    [ Upstream commit 99ee9317a1305cd5626736785c8cb38b0e47686c ]
    
    There is a recursive lock on the cpu_hotplug_lock.
    
    In kernel/trace/trace_osnoise.c:<start/stop>_per_cpu_kthreads:
        - start_per_cpu_kthreads calls cpus_read_lock() and if
            start_kthreads returns a error it will call stop_per_cpu_kthreads.
        - stop_per_cpu_kthreads then calls cpus_read_lock() again causing
          deadlock.
    
    Fix this by calling cpus_read_unlock() before calling
    stop_per_cpu_kthreads. This behavior can also be seen in commit
    f46b16520a08 ("trace/hwlat: Implement the per-cpu mode").
    
    This error was noticed during the LTP ftrace-stress-test:
    
    WARNING: possible recursive locking detected
    --------------------------------------------
    sh/275006 is trying to acquire lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: stop_per_cpu_kthreads
    
    but task is already holding lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
          CPU0
          ----
     lock(cpu_hotplug_lock);
     lock(cpu_hotplug_lock);
    
     *** DEADLOCK ***
    
    May be due to missing lock nesting notation
    
    3 locks held by sh/275006:
     #0: ffff8881023f0470 (sb_writers#24){.+.+}-{0:0}, at: ksys_write
     #1: ffffffffb084f430 (trace_types_lock){+.+.}-{3:3}, at: rb_simple_write
     #2: ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    Link: https://lkml.kernel.org/r/20220919144932.3064014-1-npache@redhat.com
    
    Fixes: c8895e271f79 ("trace/osnoise: Support hotplug operations")
    Signed-off-by: Nico Pache <npache@redhat.com>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 24ab8d9e694c3178a9290831235f28880a40cddd
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Mon Aug 8 10:26:26 2022 +0800

    rcu: Avoid triggering strict-GP irq-work when RCU is idle
    
    [ Upstream commit 621189a1fe93cb2b34d62c5cdb9e258bca044813 ]
    
    Kernels built with PREEMPT_RCU=y and RCU_STRICT_GRACE_PERIOD=y trigger
    irq-work from rcu_read_unlock(), and the resulting irq-work handler
    invokes rcu_preempt_deferred_qs_handle().  The point of this triggering
    is to force grace periods to end quickly in order to give tools like KASAN
    a better chance of detecting RCU usage bugs such as leaking RCU-protected
    pointers out of an RCU read-side critical section.
    
    However, this irq-work triggering is unconditional.  This works, but
    there is no point in doing this irq-work unless the current grace period
    is waiting on the running CPU or task, which is not the common case.
    After all, in the common case there are many rcu_read_unlock() calls
    per CPU per grace period.
    
    This commit therefore triggers the irq-work only when the current grace
    period is waiting on the running CPU or task.
    
    This change was tested as follows on a four-CPU system:
    
            echo rcu_preempt_deferred_qs_handler > /sys/kernel/debug/tracing/set_ftrace_filter
            echo 1 > /sys/kernel/debug/tracing/function_profile_enabled
            insmod rcutorture.ko
            sleep 20
            rmmod rcutorture.ko
            echo 0 > /sys/kernel/debug/tracing/function_profile_enabled
            echo > /sys/kernel/debug/tracing/set_ftrace_filter
    
    This procedure produces results in this per-CPU set of files:
    
            /sys/kernel/debug/tracing/trace_stat/function*
    
    Sample output from one of these files is as follows:
    
      Function                               Hit    Time            Avg             s^2
      --------                               ---    ----            ---             ---
      rcu_preempt_deferred_qs_handle      838746    182650.3 us     0.217 us        0.004 us
    
    The baseline sum of the "Hit" values (the number of calls to this
    function) was 3,319,015.  With this commit, that sum was 1,140,359,
    for a 2.9x reduction.  The worst-case variance across the CPUs was less
    than 25%, so this large effect size is statistically significant.
    
    The raw data is available in the Link: URL.
    
    Link: https://lore.kernel.org/all/20220808022626.12825-1-qiang1.zhang@intel.com/
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit de7fdff754bb4d01e38e19964c309b6df6a79472
Author: Alexander Aring <aahringo@redhat.com>
Date:   Mon Aug 15 15:43:13 2022 -0400

    fs: dlm: fix race in lowcomms
    
    [ Upstream commit 30ea3257e8766027c4d8d609dcbd256ff9a76073 ]
    
    This patch fixes a race between queue_work() in
    _dlm_lowcomms_commit_msg() and srcu_read_unlock(). The queue_work() can
    take the final reference of a dlm_msg and so msg->idx can contain
    garbage which is signaled by the following warning:
    
    [  676.237050] ------------[ cut here ]------------
    [  676.237052] WARNING: CPU: 0 PID: 1060 at include/linux/srcu.h:189 dlm_lowcomms_commit_msg+0x41/0x50
    [  676.238945] Modules linked in: dlm_locktorture torture rpcsec_gss_krb5 intel_rapl_msr intel_rapl_common iTCO_wdt iTCO_vendor_support qxl kvm_intel drm_ttm_helper vmw_vsock_virtio_transport kvm vmw_vsock_virtio_transport_common ttm irqbypass crc32_pclmul joydev crc32c_intel serio_raw drm_kms_helper vsock virtio_scsi virtio_console virtio_balloon snd_pcm drm syscopyarea sysfillrect sysimgblt snd_timer fb_sys_fops i2c_i801 lpc_ich snd i2c_smbus soundcore pcspkr
    [  676.244227] CPU: 0 PID: 1060 Comm: lock_torture_wr Not tainted 5.19.0-rc3+ #1546
    [  676.245216] Hardware name: Red Hat KVM/RHEL-AV, BIOS 1.16.0-2.module+el8.7.0+15506+033991b0 04/01/2014
    [  676.246460] RIP: 0010:dlm_lowcomms_commit_msg+0x41/0x50
    [  676.247132] Code: fe ff ff ff 75 24 48 c7 c6 bd 0f 49 bb 48 c7 c7 38 7c 01 bd e8 00 e7 ca ff 89 de 48 c7 c7 60 78 01 bd e8 42 3d cd ff 5b 5d c3 <0f> 0b eb d8 66 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 55 48
    [  676.249253] RSP: 0018:ffffa401c18ffc68 EFLAGS: 00010282
    [  676.249855] RAX: 0000000000000001 RBX: 00000000ffff8b76 RCX: 0000000000000006
    [  676.250713] RDX: 0000000000000000 RSI: ffffffffbccf3a10 RDI: ffffffffbcc7b62e
    [  676.251610] RBP: ffffa401c18ffc70 R08: 0000000000000001 R09: 0000000000000001
    [  676.252481] R10: 0000000000000001 R11: 0000000000000001 R12: 0000000000000005
    [  676.253421] R13: ffff8b76786ec370 R14: ffff8b76786ec370 R15: ffff8b76786ec480
    [  676.254257] FS:  0000000000000000(0000) GS:ffff8b7777800000(0000) knlGS:0000000000000000
    [  676.255239] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  676.255897] CR2: 00005590205d88b8 CR3: 000000017656c003 CR4: 0000000000770ee0
    [  676.256734] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  676.257567] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  676.258397] PKRU: 55555554
    [  676.258729] Call Trace:
    [  676.259063]  <TASK>
    [  676.259354]  dlm_midcomms_commit_mhandle+0xcc/0x110
    [  676.259964]  queue_bast+0x8b/0xb0
    [  676.260423]  grant_pending_locks+0x166/0x1b0
    [  676.261007]  _unlock_lock+0x75/0x90
    [  676.261469]  unlock_lock.isra.57+0x62/0xa0
    [  676.262009]  dlm_unlock+0x21e/0x330
    [  676.262457]  ? lock_torture_stats+0x80/0x80 [dlm_locktorture]
    [  676.263183]  torture_unlock+0x5a/0x90 [dlm_locktorture]
    [  676.263815]  ? preempt_count_sub+0xba/0x100
    [  676.264361]  ? complete+0x1d/0x60
    [  676.264777]  lock_torture_writer+0xb8/0x150 [dlm_locktorture]
    [  676.265555]  kthread+0x10a/0x130
    [  676.266007]  ? kthread_complete_and_exit+0x20/0x20
    [  676.266616]  ret_from_fork+0x22/0x30
    [  676.267097]  </TASK>
    [  676.267381] irq event stamp: 9579855
    [  676.267824] hardirqs last  enabled at (9579863): [<ffffffffbb14e6f8>] __up_console_sem+0x58/0x60
    [  676.268896] hardirqs last disabled at (9579872): [<ffffffffbb14e6dd>] __up_console_sem+0x3d/0x60
    [  676.270008] softirqs last  enabled at (9579798): [<ffffffffbc200349>] __do_softirq+0x349/0x4c7
    [  676.271438] softirqs last disabled at (9579897): [<ffffffffbb0d54c0>] irq_exit_rcu+0xb0/0xf0
    [  676.272796] ---[ end trace 0000000000000000 ]---
    
    I reproduced this warning with dlm_locktorture test which is currently
    not upstream. However this patch fix the issue by make a additional
    refcount between dlm_lowcomms_new_msg() and dlm_lowcomms_commit_msg().
    In case of the race the kref_put() in dlm_lowcomms_commit_msg() will be
    the final put.
    
    Signed-off-by: Alexander Aring <aahringo@redhat.com>
    Signed-off-by: David Teigland <teigland@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 511b40922cc9fd45805bfd5100812b5b157cc19c
Author: Nico Pache <npache@redhat.com>
Date:   Mon Sep 19 08:49:32 2022 -0600

    tracing/osnoise: Fix possible recursive locking in stop_per_cpu_kthreads
    
    [ Upstream commit 99ee9317a1305cd5626736785c8cb38b0e47686c ]
    
    There is a recursive lock on the cpu_hotplug_lock.
    
    In kernel/trace/trace_osnoise.c:<start/stop>_per_cpu_kthreads:
        - start_per_cpu_kthreads calls cpus_read_lock() and if
            start_kthreads returns a error it will call stop_per_cpu_kthreads.
        - stop_per_cpu_kthreads then calls cpus_read_lock() again causing
          deadlock.
    
    Fix this by calling cpus_read_unlock() before calling
    stop_per_cpu_kthreads. This behavior can also be seen in commit
    f46b16520a08 ("trace/hwlat: Implement the per-cpu mode").
    
    This error was noticed during the LTP ftrace-stress-test:
    
    WARNING: possible recursive locking detected
    --------------------------------------------
    sh/275006 is trying to acquire lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: stop_per_cpu_kthreads
    
    but task is already holding lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
          CPU0
          ----
     lock(cpu_hotplug_lock);
     lock(cpu_hotplug_lock);
    
     *** DEADLOCK ***
    
    May be due to missing lock nesting notation
    
    3 locks held by sh/275006:
     #0: ffff8881023f0470 (sb_writers#24){.+.+}-{0:0}, at: ksys_write
     #1: ffffffffb084f430 (trace_types_lock){+.+.}-{3:3}, at: rb_simple_write
     #2: ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    Link: https://lkml.kernel.org/r/20220919144932.3064014-1-npache@redhat.com
    
    Fixes: c8895e271f79 ("trace/osnoise: Support hotplug operations")
    Signed-off-by: Nico Pache <npache@redhat.com>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2e83b879fb91dafe995967b46a1d38a5b0889242
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Sep 15 14:29:07 2022 -0700

    srcu: Create an srcu_read_lock_nmisafe() and srcu_read_unlock_nmisafe()
    
    On strict load-store architectures, the use of this_cpu_inc() by
    srcu_read_lock() and srcu_read_unlock() is not NMI-safe in TREE SRCU.
    To see this suppose that an NMI arrives in the middle of srcu_read_lock(),
    just after it has read ->srcu_lock_count, but before it has written
    the incremented value back to memory.  If that NMI handler also does
    srcu_read_lock() and srcu_read_lock() on that same srcu_struct structure,
    then upon return from that NMI handler, the interrupted srcu_read_lock()
    will overwrite the NMI handler's update to ->srcu_lock_count, but
    leave unchanged the NMI handler's update by srcu_read_unlock() to
    ->srcu_unlock_count.
    
    This can result in a too-short SRCU grace period, which can in turn
    result in arbitrary memory corruption.
    
    If the NMI handler instead interrupts the srcu_read_unlock(), this
    can result in eternal SRCU grace periods, which is not much better.
    
    This commit therefore creates a pair of new srcu_read_lock_nmisafe()
    and srcu_read_unlock_nmisafe() functions, which allow SRCU readers in
    both NMI handlers and in process and IRQ context.  It is bad practice
    to mix the existing and the new _nmisafe() primitives on the same
    srcu_struct structure.  Use one set or the other, not both.
    
    Just to underline that "bad practice" point, using srcu_read_lock() at
    process level and srcu_read_lock_nmisafe() in your NMI handler will not,
    repeat NOT, work.  If you do not immediately understand why this is the
    case, please review the earlier paragraphs in this commit log.
    
    [ paulmck: Apply kernel test robot feedback. ]
    [ paulmck: Apply feedback from Randy Dunlap. ]
    [ paulmck: Apply feedback from John Ogness. ]
    [ paulmck: Apply feedback from Frederic Weisbecker. ]
    
    Link: https://lore.kernel.org/all/20220910221947.171557773@linutronix.de/
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Randy Dunlap <rdunlap@infradead.org> # build-tested
    Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Ogness <john.ogness@linutronix.de>
    Cc: Petr Mladek <pmladek@suse.com>

commit 5d0f5953b60f5f7a278085b55ddc73e2932f4c33
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Sep 15 12:09:30 2022 -0700

    srcu: Convert ->srcu_lock_count and ->srcu_unlock_count to atomic
    
    NMI-safe variants of srcu_read_lock() and srcu_read_unlock() are needed
    by printk(), which on many architectures entails read-modify-write
    atomic operations.  This commit prepares Tree SRCU for this change by
    making both ->srcu_lock_count and ->srcu_unlock_count by atomic_long_t.
    
    [ paulmck: Apply feedback from John Ogness. ]
    
    Link: https://lore.kernel.org/all/20220910221947.171557773@linutronix.de/
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: John Ogness <john.ogness@linutronix.de>
    Cc: Petr Mladek <pmladek@suse.com>

commit 69421bf98482d089e50799f45e48b25ce4a8d154
Author: Kuniyuki Iwashima <kuniyu@amazon.com>
Date:   Fri Oct 14 11:26:25 2022 -0700

    udp: Update reuse->has_conns under reuseport_lock.
    
    When we call connect() for a UDP socket in a reuseport group, we have
    to update sk->sk_reuseport_cb->has_conns to 1.  Otherwise, the kernel
    could select a unconnected socket wrongly for packets sent to the
    connected socket.
    
    However, the current way to set has_conns is illegal and possible to
    trigger that problem.  reuseport_has_conns() changes has_conns under
    rcu_read_lock(), which upgrades the RCU reader to the updater.  Then,
    it must do the update under the updater's lock, reuseport_lock, but
    it doesn't for now.
    
    For this reason, there is a race below where we fail to set has_conns
    resulting in the wrong socket selection.  To avoid the race, let's split
    the reader and updater with proper locking.
    
     cpu1                               cpu2
    +----+                             +----+
    
    __ip[46]_datagram_connect()        reuseport_grow()
    .                                  .
    |- reuseport_has_conns(sk, true)   |- more_reuse = __reuseport_alloc(more_socks_size)
    |  .                               |
    |  |- rcu_read_lock()
    |  |- reuse = rcu_dereference(sk->sk_reuseport_cb)
    |  |
    |  |                               |  /* reuse->has_conns == 0 here */
    |  |                               |- more_reuse->has_conns = reuse->has_conns
    |  |- reuse->has_conns = 1         |  /* more_reuse->has_conns SHOULD BE 1 HERE */
    |  |                               |
    |  |                               |- rcu_assign_pointer(reuse->socks[i]->sk_reuseport_cb,
    |  |                               |                     more_reuse)
    |  `- rcu_read_unlock()            `- kfree_rcu(reuse, rcu)
    |
    |- sk->sk_state = TCP_ESTABLISHED
    
    Note the likely(reuse) in reuseport_has_conns_set() is always true,
    but we put the test there for ease of review.  [0]
    
    For the record, usually, sk_reuseport_cb is changed under lock_sock().
    The only exception is reuseport_grow() & TCP reqsk migration case.
    
      1) shutdown() TCP listener, which is moved into the latter part of
         reuse->socks[] to migrate reqsk.
    
      2) New listen() overflows reuse->socks[] and call reuseport_grow().
    
      3) reuse->max_socks overflows u16 with the new listener.
    
      4) reuseport_grow() pops the old shutdown()ed listener from the array
         and update its sk->sk_reuseport_cb as NULL without lock_sock().
    
    shutdown()ed TCP sk->sk_reuseport_cb can be changed without lock_sock(),
    but, reuseport_has_conns_set() is called only for UDP under lock_sock(),
    so likely(reuse) never be false in reuseport_has_conns_set().
    
    [0]: https://lore.kernel.org/netdev/CANn89iLja=eQHbsM_Ta2sQF0tOGU8vAGrh_izRuuHjuO1ouUag@mail.gmail.com/
    
    Fixes: acdcecc61285 ("udp: correct reuseport selection with connected sockets")
    Signed-off-by: Kuniyuki Iwashima <kuniyu@amazon.com>
    Link: https://lore.kernel.org/r/20221014182625.89913-1-kuniyu@amazon.com
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>

commit b6702a942a069c2a975478d719e98d83cdae1797
Author: Shigeru Yoshida <syoshida@redhat.com>
Date:   Mon Oct 10 03:32:23 2022 +0900

    wifi: ar5523: Fix use-after-free on ar5523_cmd() timed out
    
    syzkaller reported use-after-free with the stack trace like below [1]:
    
    [   38.960489][    C3] ==================================================================
    [   38.963216][    C3] BUG: KASAN: use-after-free in ar5523_cmd_tx_cb+0x220/0x240
    [   38.964950][    C3] Read of size 8 at addr ffff888048e03450 by task swapper/3/0
    [   38.966363][    C3]
    [   38.967053][    C3] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 6.0.0-09039-ga6afa4199d3d-dirty #18
    [   38.968464][    C3] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    [   38.969959][    C3] Call Trace:
    [   38.970841][    C3]  <IRQ>
    [   38.971663][    C3]  dump_stack_lvl+0xfc/0x174
    [   38.972620][    C3]  print_report.cold+0x2c3/0x752
    [   38.973626][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.974644][    C3]  kasan_report+0xb1/0x1d0
    [   38.975720][    C3]  ? ar5523_cmd_tx_cb+0x220/0x240
    [   38.976831][    C3]  ar5523_cmd_tx_cb+0x220/0x240
    [   38.978412][    C3]  __usb_hcd_giveback_urb+0x353/0x5b0
    [   38.979755][    C3]  usb_hcd_giveback_urb+0x385/0x430
    [   38.981266][    C3]  dummy_timer+0x140c/0x34e0
    [   38.982925][    C3]  ? notifier_call_chain+0xb5/0x1e0
    [   38.984761][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.986242][    C3]  ? lock_release+0x51c/0x790
    [   38.987323][    C3]  ? _raw_read_unlock_irqrestore+0x37/0x70
    [   38.988483][    C3]  ? __wake_up_common_lock+0xde/0x130
    [   38.989621][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   38.990777][    C3]  ? lock_acquire+0x472/0x550
    [   38.991919][    C3]  ? rcu_read_lock_sched_held+0xb/0x60
    [   38.993138][    C3]  ? lock_acquire+0x472/0x550
    [   38.994890][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.996266][    C3]  ? do_raw_spin_unlock+0x16f/0x230
    [   38.997670][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   38.999116][    C3]  call_timer_fn+0x1a0/0x6a0
    [   39.000668][    C3]  ? add_timer_on+0x4a0/0x4a0
    [   39.002137][    C3]  ? reacquire_held_locks+0x4a0/0x4a0
    [   39.003809][    C3]  ? __next_timer_interrupt+0x226/0x2a0
    [   39.005509][    C3]  __run_timers.part.0+0x69a/0xac0
    [   39.007025][    C3]  ? dummy_urb_enqueue+0x860/0x860
    [   39.008716][    C3]  ? call_timer_fn+0x6a0/0x6a0
    [   39.010254][    C3]  ? cpuacct_percpu_seq_show+0x10/0x10
    [   39.011795][    C3]  ? kvm_sched_clock_read+0x14/0x40
    [   39.013277][    C3]  ? sched_clock_cpu+0x69/0x2b0
    [   39.014724][    C3]  run_timer_softirq+0xb6/0x1d0
    [   39.016196][    C3]  __do_softirq+0x1d2/0x9be
    [   39.017616][    C3]  __irq_exit_rcu+0xeb/0x190
    [   39.019004][    C3]  irq_exit_rcu+0x5/0x20
    [   39.020361][    C3]  sysvec_apic_timer_interrupt+0x8f/0xb0
    [   39.021965][    C3]  </IRQ>
    [   39.023237][    C3]  <TASK>
    
    In ar5523_probe(), ar5523_host_available() calls ar5523_cmd() as below
    (there are other functions which finally call ar5523_cmd()):
    
    ar5523_probe()
    -> ar5523_host_available()
       -> ar5523_cmd_read()
          -> ar5523_cmd()
    
    If ar5523_cmd() timed out, then ar5523_host_available() failed and
    ar5523_probe() freed the device structure.  So, ar5523_cmd_tx_cb()
    might touch the freed structure.
    
    This patch fixes this issue by canceling in-flight tx cmd if submitted
    urb timed out.
    
    Link: https://syzkaller.appspot.com/bug?id=9e12b2d54300842b71bdd18b54971385ff0d0d3a [1]
    Reported-by: syzbot+95001b1fd6dfcc716c29@syzkaller.appspotmail.com
    Signed-off-by: Shigeru Yoshida <syoshida@redhat.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20221009183223.420015-1-syoshida@redhat.com

commit 54e45702b648b7c0000e90b3e9b890e367e16ea8
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Fri Sep 23 00:50:23 2022 +0800

    fs/ntfs3: Validate resident attribute name
    
    Though we already have some sanity checks while enumerating attributes,
    resident attribute names aren't included. This patch checks the resident
    attribute names are in the valid ranges.
    
    [  259.209031] BUG: KASAN: slab-out-of-bounds in ni_create_attr_list+0x1e1/0x850
    [  259.210770] Write of size 426 at addr ffff88800632f2b2 by task exp/255
    [  259.211551]
    [  259.212035] CPU: 0 PID: 255 Comm: exp Not tainted 6.0.0-rc6 #37
    [  259.212955] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  259.214387] Call Trace:
    [  259.214640]  <TASK>
    [  259.214895]  dump_stack_lvl+0x49/0x63
    [  259.215284]  print_report.cold+0xf5/0x689
    [  259.215565]  ? kasan_poison+0x3c/0x50
    [  259.215778]  ? kasan_unpoison+0x28/0x60
    [  259.215991]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216270]  kasan_report+0xa7/0x130
    [  259.216481]  ? ni_create_attr_list+0x1e1/0x850
    [  259.216719]  kasan_check_range+0x15a/0x1d0
    [  259.216939]  memcpy+0x3c/0x70
    [  259.217136]  ni_create_attr_list+0x1e1/0x850
    [  259.217945]  ? __rcu_read_unlock+0x5b/0x280
    [  259.218384]  ? ni_remove_attr+0x2e0/0x2e0
    [  259.218712]  ? kernel_text_address+0xcf/0xe0
    [  259.219064]  ? __kernel_text_address+0x12/0x40
    [  259.219434]  ? arch_stack_walk+0x9e/0xf0
    [  259.219668]  ? __this_cpu_preempt_check+0x13/0x20
    [  259.219904]  ? sysvec_apic_timer_interrupt+0x57/0xc0
    [  259.220140]  ? asm_sysvec_apic_timer_interrupt+0x1b/0x20
    [  259.220561]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.220984]  ? ni_create_attr_list+0x850/0x850
    [  259.221532]  ? run_deallocate+0x120/0x120
    [  259.221972]  ? vfs_setxattr+0x128/0x300
    [  259.222688]  ? setxattr+0x126/0x140
    [  259.222921]  ? path_setxattr+0x164/0x180
    [  259.223431]  ? __x64_sys_setxattr+0x6d/0x80
    [  259.223828]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.224417]  ? mi_find_attr+0x3c/0xf0
    [  259.224772]  ni_insert_attr+0x1ba/0x420
    [  259.225216]  ? ni_ins_attr_ext+0x5c0/0x5c0
    [  259.225504]  ? ntfs_read_ea+0x119/0x450
    [  259.225775]  ni_insert_resident+0xc0/0x1c0
    [  259.226316]  ? ni_insert_nonresident+0x400/0x400
    [  259.227001]  ? __kasan_kmalloc+0x88/0xb0
    [  259.227468]  ? __kmalloc+0x192/0x320
    [  259.227773]  ntfs_set_ea+0x6bf/0xb30
    [  259.228216]  ? ftrace_graph_ret_addr+0x2a/0xb0
    [  259.228494]  ? entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.228838]  ? ntfs_read_ea+0x450/0x450
    [  259.229098]  ? is_bpf_text_address+0x24/0x40
    [  259.229418]  ? kernel_text_address+0xcf/0xe0
    [  259.229681]  ? __kernel_text_address+0x12/0x40
    [  259.229948]  ? unwind_get_return_address+0x3a/0x60
    [  259.230271]  ? write_profile+0x270/0x270
    [  259.230537]  ? arch_stack_walk+0x9e/0xf0
    [  259.230836]  ntfs_setxattr+0x114/0x5c0
    [  259.231099]  ? ntfs_set_acl_ex+0x2e0/0x2e0
    [  259.231529]  ? evm_protected_xattr_common+0x6d/0x100
    [  259.231817]  ? posix_xattr_acl+0x13/0x80
    [  259.232073]  ? evm_protect_xattr+0x1f7/0x440
    [  259.232351]  __vfs_setxattr+0xda/0x120
    [  259.232635]  ? xattr_resolve_name+0x180/0x180
    [  259.232912]  __vfs_setxattr_noperm+0x93/0x300
    [  259.233219]  __vfs_setxattr_locked+0x141/0x160
    [  259.233492]  ? kasan_poison+0x3c/0x50
    [  259.233744]  vfs_setxattr+0x128/0x300
    [  259.234002]  ? __vfs_setxattr_locked+0x160/0x160
    [  259.234837]  do_setxattr+0xb8/0x170
    [  259.235567]  ? vmemdup_user+0x53/0x90
    [  259.236212]  setxattr+0x126/0x140
    [  259.236491]  ? do_setxattr+0x170/0x170
    [  259.236791]  ? debug_smp_processor_id+0x17/0x20
    [  259.237232]  ? kasan_quarantine_put+0x57/0x180
    [  259.237605]  ? putname+0x80/0xa0
    [  259.237870]  ? __kasan_slab_free+0x11c/0x1b0
    [  259.238234]  ? putname+0x80/0xa0
    [  259.238500]  ? preempt_count_sub+0x18/0xc0
    [  259.238775]  ? __mnt_want_write+0xaa/0x100
    [  259.238990]  ? mnt_want_write+0x8b/0x150
    [  259.239290]  path_setxattr+0x164/0x180
    [  259.239605]  ? setxattr+0x140/0x140
    [  259.239849]  ? debug_smp_processor_id+0x17/0x20
    [  259.240174]  ? fpregs_assert_state_consistent+0x67/0x80
    [  259.240411]  __x64_sys_setxattr+0x6d/0x80
    [  259.240715]  do_syscall_64+0x3b/0x90
    [  259.240934]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.241697] RIP: 0033:0x7fc6b26e4469
    [  259.242647] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  259.244512] RSP: 002b:00007ffc3c7841f8 EFLAGS: 00000217 ORIG_RAX: 00000000000000bc
    [  259.245086] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007fc6b26e4469
    [  259.246025] RDX: 00007ffc3c784380 RSI: 00007ffc3c7842e0 RDI: 00007ffc3c784238
    [  259.246961] RBP: 00007ffc3c788410 R08: 0000000000000001 R09: 00007ffc3c7884f8
    [  259.247775] R10: 000000000000007f R11: 0000000000000217 R12: 00000000004004e0
    [  259.248534] R13: 00007ffc3c7884f0 R14: 0000000000000000 R15: 0000000000000000
    [  259.249368]  </TASK>
    [  259.249644]
    [  259.249888] Allocated by task 255:
    [  259.250283]  kasan_save_stack+0x26/0x50
    [  259.250957]  __kasan_kmalloc+0x88/0xb0
    [  259.251826]  __kmalloc+0x192/0x320
    [  259.252745]  ni_create_attr_list+0x11e/0x850
    [  259.253298]  ni_ins_attr_ext+0x52c/0x5c0
    [  259.253685]  ni_insert_attr+0x1ba/0x420
    [  259.253974]  ni_insert_resident+0xc0/0x1c0
    [  259.254311]  ntfs_set_ea+0x6bf/0xb30
    [  259.254629]  ntfs_setxattr+0x114/0x5c0
    [  259.254859]  __vfs_setxattr+0xda/0x120
    [  259.255155]  __vfs_setxattr_noperm+0x93/0x300
    [  259.255445]  __vfs_setxattr_locked+0x141/0x160
    [  259.255862]  vfs_setxattr+0x128/0x300
    [  259.256251]  do_setxattr+0xb8/0x170
    [  259.256522]  setxattr+0x126/0x140
    [  259.256911]  path_setxattr+0x164/0x180
    [  259.257308]  __x64_sys_setxattr+0x6d/0x80
    [  259.257637]  do_syscall_64+0x3b/0x90
    [  259.257970]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  259.258550]
    [  259.258772] The buggy address belongs to the object at ffff88800632f000
    [  259.258772]  which belongs to the cache kmalloc-1k of size 1024
    [  259.260190] The buggy address is located 690 bytes inside of
    [  259.260190]  1024-byte region [ffff88800632f000, ffff88800632f400)
    [  259.261412]
    [  259.261743] The buggy address belongs to the physical page:
    [  259.262354] page:0000000081e8cac9 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x632c
    [  259.263722] head:0000000081e8cac9 order:2 compound_mapcount:0 compound_pincount:0
    [  259.264284] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  259.265312] raw: 000fffffc0010200 ffffea0000060d00 dead000000000004 ffff888001041dc0
    [  259.265772] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  259.266305] page dumped because: kasan: bad access detected
    [  259.266588]
    [  259.266728] Memory state around the buggy address:
    [  259.267225]  ffff88800632f300: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.267841]  ffff88800632f380: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  259.269111] >ffff88800632f400: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.269626]                    ^
    [  259.270162]  ffff88800632f480: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  259.270810]  ffff88800632f500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>

commit 4d42ecda239cc13738d6fd84d098a32e67b368b9
Author: Edward Lo <edward.lo@ambergroup.io>
Date:   Thu Sep 22 15:30:44 2022 +0800

    fs/ntfs3: Validate buffer length while parsing index
    
    indx_read is called when we have some NTFS directory operations that
    need more information from the index buffers. This adds a sanity check
    to make sure the returned index buffer length is legit, or we may have
    some out-of-bound memory accesses.
    
    [  560.897595] BUG: KASAN: slab-out-of-bounds in hdr_find_e.isra.0+0x10c/0x320
    [  560.898321] Read of size 2 at addr ffff888009497238 by task exp/245
    [  560.898760]
    [  560.899129] CPU: 0 PID: 245 Comm: exp Not tainted 6.0.0-rc6 #37
    [  560.899505] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.14.0-0-g155821a1990b-prebuilt.qemu.org 04/01/2014
    [  560.900170] Call Trace:
    [  560.900407]  <TASK>
    [  560.900732]  dump_stack_lvl+0x49/0x63
    [  560.901108]  print_report.cold+0xf5/0x689
    [  560.901395]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.901716]  kasan_report+0xa7/0x130
    [  560.901950]  ? hdr_find_e.isra.0+0x10c/0x320
    [  560.902208]  __asan_load2+0x68/0x90
    [  560.902427]  hdr_find_e.isra.0+0x10c/0x320
    [  560.902846]  ? cmp_uints+0xe0/0xe0
    [  560.903363]  ? cmp_sdh+0x90/0x90
    [  560.903883]  ? ntfs_bread_run+0x190/0x190
    [  560.904196]  ? rwsem_down_read_slowpath+0x750/0x750
    [  560.904969]  ? ntfs_fix_post_read+0xe0/0x130
    [  560.905259]  ? __kasan_check_write+0x14/0x20
    [  560.905599]  ? up_read+0x1a/0x90
    [  560.905853]  ? indx_read+0x22c/0x380
    [  560.906096]  indx_find+0x2ef/0x470
    [  560.906352]  ? indx_find_buffer+0x2d0/0x2d0
    [  560.906692]  ? __kasan_kmalloc+0x88/0xb0
    [  560.906977]  dir_search_u+0x196/0x2f0
    [  560.907220]  ? ntfs_nls_to_utf16+0x450/0x450
    [  560.907464]  ? __kasan_check_write+0x14/0x20
    [  560.907747]  ? mutex_lock+0x8f/0xe0
    [  560.907970]  ? __mutex_lock_slowpath+0x20/0x20
    [  560.908214]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.908459]  ntfs_lookup+0xe0/0x100
    [  560.908788]  __lookup_slow+0x116/0x220
    [  560.909050]  ? lookup_fast+0x1b0/0x1b0
    [  560.909309]  ? lookup_fast+0x13f/0x1b0
    [  560.909601]  walk_component+0x187/0x230
    [  560.909944]  link_path_walk.part.0+0x3f0/0x660
    [  560.910285]  ? handle_lookup_down+0x90/0x90
    [  560.910618]  ? path_init+0x642/0x6e0
    [  560.911084]  ? percpu_counter_add_batch+0x6e/0xf0
    [  560.912559]  ? __alloc_file+0x114/0x170
    [  560.913008]  path_openat+0x19c/0x1d10
    [  560.913419]  ? getname_flags+0x73/0x2b0
    [  560.913815]  ? kasan_save_stack+0x3a/0x50
    [  560.914125]  ? kasan_save_stack+0x26/0x50
    [  560.914542]  ? __kasan_slab_alloc+0x6d/0x90
    [  560.914924]  ? kmem_cache_alloc+0x143/0x4b0
    [  560.915339]  ? getname_flags+0x73/0x2b0
    [  560.915647]  ? getname+0x12/0x20
    [  560.916114]  ? __x64_sys_open+0x4c/0x60
    [  560.916460]  ? path_lookupat.isra.0+0x230/0x230
    [  560.916867]  ? __isolate_free_page+0x2e0/0x2e0
    [  560.917194]  do_filp_open+0x15c/0x1f0
    [  560.917448]  ? may_open_dev+0x60/0x60
    [  560.917696]  ? expand_files+0xa4/0x3a0
    [  560.917923]  ? __kasan_check_write+0x14/0x20
    [  560.918185]  ? _raw_spin_lock+0x88/0xdb
    [  560.918409]  ? _raw_spin_lock_irqsave+0x100/0x100
    [  560.918783]  ? _find_next_bit+0x4a/0x130
    [  560.919026]  ? _raw_spin_unlock+0x19/0x40
    [  560.919276]  ? alloc_fd+0x14b/0x2d0
    [  560.919635]  do_sys_openat2+0x32a/0x4b0
    [  560.920035]  ? file_open_root+0x230/0x230
    [  560.920336]  ? __rcu_read_unlock+0x5b/0x280
    [  560.920813]  do_sys_open+0x99/0xf0
    [  560.921208]  ? filp_open+0x60/0x60
    [  560.921482]  ? exit_to_user_mode_prepare+0x49/0x180
    [  560.921867]  __x64_sys_open+0x4c/0x60
    [  560.922128]  do_syscall_64+0x3b/0x90
    [  560.922369]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.923030] RIP: 0033:0x7f7dff2e4469
    [  560.923681] Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 088
    [  560.924451] RSP: 002b:00007ffd41a210b8 EFLAGS: 00000206 ORIG_RAX: 0000000000000002
    [  560.925168] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f7dff2e4469
    [  560.925655] RDX: 0000000000000000 RSI: 0000000000000002 RDI: 00007ffd41a211f0
    [  560.926085] RBP: 00007ffd41a252a0 R08: 00007f7dff60fba0 R09: 00007ffd41a25388
    [  560.926405] R10: 0000000000400b80 R11: 0000000000000206 R12: 00000000004004e0
    [  560.926867] R13: 00007ffd41a25380 R14: 0000000000000000 R15: 0000000000000000
    [  560.927241]  </TASK>
    [  560.927491]
    [  560.927755] Allocated by task 245:
    [  560.928409]  kasan_save_stack+0x26/0x50
    [  560.929271]  __kasan_kmalloc+0x88/0xb0
    [  560.929778]  __kmalloc+0x192/0x320
    [  560.930023]  indx_read+0x249/0x380
    [  560.930224]  indx_find+0x2a2/0x470
    [  560.930695]  dir_search_u+0x196/0x2f0
    [  560.930892]  ntfs_lookup+0xe0/0x100
    [  560.931115]  __lookup_slow+0x116/0x220
    [  560.931323]  walk_component+0x187/0x230
    [  560.931570]  link_path_walk.part.0+0x3f0/0x660
    [  560.931791]  path_openat+0x19c/0x1d10
    [  560.932008]  do_filp_open+0x15c/0x1f0
    [  560.932226]  do_sys_openat2+0x32a/0x4b0
    [  560.932413]  do_sys_open+0x99/0xf0
    [  560.932709]  __x64_sys_open+0x4c/0x60
    [  560.933417]  do_syscall_64+0x3b/0x90
    [  560.933776]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    [  560.934235]
    [  560.934486] The buggy address belongs to the object at ffff888009497000
    [  560.934486]  which belongs to the cache kmalloc-512 of size 512
    [  560.935239] The buggy address is located 56 bytes to the right of
    [  560.935239]  512-byte region [ffff888009497000, ffff888009497200)
    [  560.936153]
    [  560.937326] The buggy address belongs to the physical page:
    [  560.938228] page:0000000062a3dfae refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x9496
    [  560.939616] head:0000000062a3dfae order:1 compound_mapcount:0 compound_pincount:0
    [  560.940219] flags: 0xfffffc0010200(slab|head|node=0|zone=1|lastcpupid=0x1fffff)
    [  560.942702] raw: 000fffffc0010200 ffffea0000164f80 dead000000000005 ffff888001041c80
    [  560.943932] raw: 0000000000000000 0000000080080008 00000001ffffffff 0000000000000000
    [  560.944568] page dumped because: kasan: bad access detected
    [  560.945735]
    [  560.946112] Memory state around the buggy address:
    [  560.946870]  ffff888009497100: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947242]  ffff888009497180: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [  560.947611] >ffff888009497200: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.947915]                                         ^
    [  560.948249]  ffff888009497280: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  560.948687]  ffff888009497300: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    
    Signed-off-by: Edward Lo <edward.lo@ambergroup.io>
    Signed-off-by: Konstantin Komarov <almaz.alexandrovich@paragon-software.com>

commit 2f5e9de15e4f55fbf56f22d4a2ce406246cc462d
Author: Lus Henriques <lhenriques@suse.de>
Date:   Mon Aug 22 10:42:35 2022 +0100

    ext4: fix bug in extents parsing when eh_entries == 0 and eh_depth > 0
    
    commit 29a5b8a137ac8eb410cc823653a29ac0e7b7e1b0 upstream.
    
    When walking through an inode extents, the ext4_ext_binsearch_idx() function
    assumes that the extent header has been previously validated.  However, there
    are no checks that verify that the number of entries (eh->eh_entries) is
    non-zero when depth is > 0.  And this will lead to problems because the
    EXT_FIRST_INDEX() and EXT_LAST_INDEX() will return garbage and result in this:
    
    [  135.245946] ------------[ cut here ]------------
    [  135.247579] kernel BUG at fs/ext4/extents.c:2258!
    [  135.249045] invalid opcode: 0000 [#1] PREEMPT SMP
    [  135.250320] CPU: 2 PID: 238 Comm: tmp118 Not tainted 5.19.0-rc8+ #4
    [  135.252067] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.15.0-0-g2dd4b9b-rebuilt.opensuse.org 04/01/2014
    [  135.255065] RIP: 0010:ext4_ext_map_blocks+0xc20/0xcb0
    [  135.256475] Code:
    [  135.261433] RSP: 0018:ffffc900005939f8 EFLAGS: 00010246
    [  135.262847] RAX: 0000000000000024 RBX: ffffc90000593b70 RCX: 0000000000000023
    [  135.264765] RDX: ffff8880038e5f10 RSI: 0000000000000003 RDI: ffff8880046e922c
    [  135.266670] RBP: ffff8880046e9348 R08: 0000000000000001 R09: ffff888002ca580c
    [  135.268576] R10: 0000000000002602 R11: 0000000000000000 R12: 0000000000000024
    [  135.270477] R13: 0000000000000000 R14: 0000000000000024 R15: 0000000000000000
    [  135.272394] FS:  00007fdabdc56740(0000) GS:ffff88807dd00000(0000) knlGS:0000000000000000
    [  135.274510] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  135.276075] CR2: 00007ffc26bd4f00 CR3: 0000000006261004 CR4: 0000000000170ea0
    [  135.277952] Call Trace:
    [  135.278635]  <TASK>
    [  135.279247]  ? preempt_count_add+0x6d/0xa0
    [  135.280358]  ? percpu_counter_add_batch+0x55/0xb0
    [  135.281612]  ? _raw_read_unlock+0x18/0x30
    [  135.282704]  ext4_map_blocks+0x294/0x5a0
    [  135.283745]  ? xa_load+0x6f/0xa0
    [  135.284562]  ext4_mpage_readpages+0x3d6/0x770
    [  135.285646]  read_pages+0x67/0x1d0
    [  135.286492]  ? folio_add_lru+0x51/0x80
    [  135.287441]  page_cache_ra_unbounded+0x124/0x170
    [  135.288510]  filemap_get_pages+0x23d/0x5a0
    [  135.289457]  ? path_openat+0xa72/0xdd0
    [  135.290332]  filemap_read+0xbf/0x300
    [  135.291158]  ? _raw_spin_lock_irqsave+0x17/0x40
    [  135.292192]  new_sync_read+0x103/0x170
    [  135.293014]  vfs_read+0x15d/0x180
    [  135.293745]  ksys_read+0xa1/0xe0
    [  135.294461]  do_syscall_64+0x3c/0x80
    [  135.295284]  entry_SYSCALL_64_after_hwframe+0x46/0xb0
    
    This patch simply adds an extra check in __ext4_ext_check(), verifying that
    eh_entries is not 0 when eh_depth is > 0.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=215941
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=216283
    Cc: Baokun Li <libaokun1@huawei.com>
    Cc: stable@kernel.org
    Signed-off-by: Lus Henriques <lhenriques@suse.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Baokun Li <libaokun1@huawei.com>
    Link: https://lore.kernel.org/r/20220822094235.2690-1-lhenriques@suse.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit be4df018c0be5ebecf1ca510feacc23be415cefc
Author: Lus Henriques <lhenriques@suse.de>
Date:   Mon Aug 22 10:42:35 2022 +0100

    ext4: fix bug in extents parsing when eh_entries == 0 and eh_depth > 0
    
    commit 29a5b8a137ac8eb410cc823653a29ac0e7b7e1b0 upstream.
    
    When walking through an inode extents, the ext4_ext_binsearch_idx() function
    assumes that the extent header has been previously validated.  However, there
    are no checks that verify that the number of entries (eh->eh_entries) is
    non-zero when depth is > 0.  And this will lead to problems because the
    EXT_FIRST_INDEX() and EXT_LAST_INDEX() will return garbage and result in this:
    
    [  135.245946] ------------[ cut here ]------------
    [  135.247579] kernel BUG at fs/ext4/extents.c:2258!
    [  135.249045] invalid opcode: 0000 [#1] PREEMPT SMP
    [  135.250320] CPU: 2 PID: 238 Comm: tmp118 Not tainted 5.19.0-rc8+ #4
    [  135.252067] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.15.0-0-g2dd4b9b-rebuilt.opensuse.org 04/01/2014
    [  135.255065] RIP: 0010:ext4_ext_map_blocks+0xc20/0xcb0
    [  135.256475] Code:
    [  135.261433] RSP: 0018:ffffc900005939f8 EFLAGS: 00010246
    [  135.262847] RAX: 0000000000000024 RBX: ffffc90000593b70 RCX: 0000000000000023
    [  135.264765] RDX: ffff8880038e5f10 RSI: 0000000000000003 RDI: ffff8880046e922c
    [  135.266670] RBP: ffff8880046e9348 R08: 0000000000000001 R09: ffff888002ca580c
    [  135.268576] R10: 0000000000002602 R11: 0000000000000000 R12: 0000000000000024
    [  135.270477] R13: 0000000000000000 R14: 0000000000000024 R15: 0000000000000000
    [  135.272394] FS:  00007fdabdc56740(0000) GS:ffff88807dd00000(0000) knlGS:0000000000000000
    [  135.274510] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  135.276075] CR2: 00007ffc26bd4f00 CR3: 0000000006261004 CR4: 0000000000170ea0
    [  135.277952] Call Trace:
    [  135.278635]  <TASK>
    [  135.279247]  ? preempt_count_add+0x6d/0xa0
    [  135.280358]  ? percpu_counter_add_batch+0x55/0xb0
    [  135.281612]  ? _raw_read_unlock+0x18/0x30
    [  135.282704]  ext4_map_blocks+0x294/0x5a0
    [  135.283745]  ? xa_load+0x6f/0xa0
    [  135.284562]  ext4_mpage_readpages+0x3d6/0x770
    [  135.285646]  read_pages+0x67/0x1d0
    [  135.286492]  ? folio_add_lru+0x51/0x80
    [  135.287441]  page_cache_ra_unbounded+0x124/0x170
    [  135.288510]  filemap_get_pages+0x23d/0x5a0
    [  135.289457]  ? path_openat+0xa72/0xdd0
    [  135.290332]  filemap_read+0xbf/0x300
    [  135.291158]  ? _raw_spin_lock_irqsave+0x17/0x40
    [  135.292192]  new_sync_read+0x103/0x170
    [  135.293014]  vfs_read+0x15d/0x180
    [  135.293745]  ksys_read+0xa1/0xe0
    [  135.294461]  do_syscall_64+0x3c/0x80
    [  135.295284]  entry_SYSCALL_64_after_hwframe+0x46/0xb0
    
    This patch simply adds an extra check in __ext4_ext_check(), verifying that
    eh_entries is not 0 when eh_depth is > 0.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=215941
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=216283
    Cc: Baokun Li <libaokun1@huawei.com>
    Cc: stable@kernel.org
    Signed-off-by: Lus Henriques <lhenriques@suse.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Baokun Li <libaokun1@huawei.com>
    Link: https://lore.kernel.org/r/20220822094235.2690-1-lhenriques@suse.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 958b0ee23f5ac106e7cc11472b71aa2ea9a033bc
Author: Lus Henriques <lhenriques@suse.de>
Date:   Mon Aug 22 10:42:35 2022 +0100

    ext4: fix bug in extents parsing when eh_entries == 0 and eh_depth > 0
    
    commit 29a5b8a137ac8eb410cc823653a29ac0e7b7e1b0 upstream.
    
    When walking through an inode extents, the ext4_ext_binsearch_idx() function
    assumes that the extent header has been previously validated.  However, there
    are no checks that verify that the number of entries (eh->eh_entries) is
    non-zero when depth is > 0.  And this will lead to problems because the
    EXT_FIRST_INDEX() and EXT_LAST_INDEX() will return garbage and result in this:
    
    [  135.245946] ------------[ cut here ]------------
    [  135.247579] kernel BUG at fs/ext4/extents.c:2258!
    [  135.249045] invalid opcode: 0000 [#1] PREEMPT SMP
    [  135.250320] CPU: 2 PID: 238 Comm: tmp118 Not tainted 5.19.0-rc8+ #4
    [  135.252067] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.15.0-0-g2dd4b9b-rebuilt.opensuse.org 04/01/2014
    [  135.255065] RIP: 0010:ext4_ext_map_blocks+0xc20/0xcb0
    [  135.256475] Code:
    [  135.261433] RSP: 0018:ffffc900005939f8 EFLAGS: 00010246
    [  135.262847] RAX: 0000000000000024 RBX: ffffc90000593b70 RCX: 0000000000000023
    [  135.264765] RDX: ffff8880038e5f10 RSI: 0000000000000003 RDI: ffff8880046e922c
    [  135.266670] RBP: ffff8880046e9348 R08: 0000000000000001 R09: ffff888002ca580c
    [  135.268576] R10: 0000000000002602 R11: 0000000000000000 R12: 0000000000000024
    [  135.270477] R13: 0000000000000000 R14: 0000000000000024 R15: 0000000000000000
    [  135.272394] FS:  00007fdabdc56740(0000) GS:ffff88807dd00000(0000) knlGS:0000000000000000
    [  135.274510] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  135.276075] CR2: 00007ffc26bd4f00 CR3: 0000000006261004 CR4: 0000000000170ea0
    [  135.277952] Call Trace:
    [  135.278635]  <TASK>
    [  135.279247]  ? preempt_count_add+0x6d/0xa0
    [  135.280358]  ? percpu_counter_add_batch+0x55/0xb0
    [  135.281612]  ? _raw_read_unlock+0x18/0x30
    [  135.282704]  ext4_map_blocks+0x294/0x5a0
    [  135.283745]  ? xa_load+0x6f/0xa0
    [  135.284562]  ext4_mpage_readpages+0x3d6/0x770
    [  135.285646]  read_pages+0x67/0x1d0
    [  135.286492]  ? folio_add_lru+0x51/0x80
    [  135.287441]  page_cache_ra_unbounded+0x124/0x170
    [  135.288510]  filemap_get_pages+0x23d/0x5a0
    [  135.289457]  ? path_openat+0xa72/0xdd0
    [  135.290332]  filemap_read+0xbf/0x300
    [  135.291158]  ? _raw_spin_lock_irqsave+0x17/0x40
    [  135.292192]  new_sync_read+0x103/0x170
    [  135.293014]  vfs_read+0x15d/0x180
    [  135.293745]  ksys_read+0xa1/0xe0
    [  135.294461]  do_syscall_64+0x3c/0x80
    [  135.295284]  entry_SYSCALL_64_after_hwframe+0x46/0xb0
    
    This patch simply adds an extra check in __ext4_ext_check(), verifying that
    eh_entries is not 0 when eh_depth is > 0.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=215941
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=216283
    Cc: Baokun Li <libaokun1@huawei.com>
    Cc: stable@kernel.org
    Signed-off-by: Lus Henriques <lhenriques@suse.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Baokun Li <libaokun1@huawei.com>
    Link: https://lore.kernel.org/r/20220822094235.2690-1-lhenriques@suse.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bb7eb3ca4b3b0d2c7872cf1a41c30f5e5bd65df0
Author: Lus Henriques <lhenriques@suse.de>
Date:   Mon Aug 22 10:42:35 2022 +0100

    ext4: fix bug in extents parsing when eh_entries == 0 and eh_depth > 0
    
    commit 29a5b8a137ac8eb410cc823653a29ac0e7b7e1b0 upstream.
    
    When walking through an inode extents, the ext4_ext_binsearch_idx() function
    assumes that the extent header has been previously validated.  However, there
    are no checks that verify that the number of entries (eh->eh_entries) is
    non-zero when depth is > 0.  And this will lead to problems because the
    EXT_FIRST_INDEX() and EXT_LAST_INDEX() will return garbage and result in this:
    
    [  135.245946] ------------[ cut here ]------------
    [  135.247579] kernel BUG at fs/ext4/extents.c:2258!
    [  135.249045] invalid opcode: 0000 [#1] PREEMPT SMP
    [  135.250320] CPU: 2 PID: 238 Comm: tmp118 Not tainted 5.19.0-rc8+ #4
    [  135.252067] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.15.0-0-g2dd4b9b-rebuilt.opensuse.org 04/01/2014
    [  135.255065] RIP: 0010:ext4_ext_map_blocks+0xc20/0xcb0
    [  135.256475] Code:
    [  135.261433] RSP: 0018:ffffc900005939f8 EFLAGS: 00010246
    [  135.262847] RAX: 0000000000000024 RBX: ffffc90000593b70 RCX: 0000000000000023
    [  135.264765] RDX: ffff8880038e5f10 RSI: 0000000000000003 RDI: ffff8880046e922c
    [  135.266670] RBP: ffff8880046e9348 R08: 0000000000000001 R09: ffff888002ca580c
    [  135.268576] R10: 0000000000002602 R11: 0000000000000000 R12: 0000000000000024
    [  135.270477] R13: 0000000000000000 R14: 0000000000000024 R15: 0000000000000000
    [  135.272394] FS:  00007fdabdc56740(0000) GS:ffff88807dd00000(0000) knlGS:0000000000000000
    [  135.274510] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  135.276075] CR2: 00007ffc26bd4f00 CR3: 0000000006261004 CR4: 0000000000170ea0
    [  135.277952] Call Trace:
    [  135.278635]  <TASK>
    [  135.279247]  ? preempt_count_add+0x6d/0xa0
    [  135.280358]  ? percpu_counter_add_batch+0x55/0xb0
    [  135.281612]  ? _raw_read_unlock+0x18/0x30
    [  135.282704]  ext4_map_blocks+0x294/0x5a0
    [  135.283745]  ? xa_load+0x6f/0xa0
    [  135.284562]  ext4_mpage_readpages+0x3d6/0x770
    [  135.285646]  read_pages+0x67/0x1d0
    [  135.286492]  ? folio_add_lru+0x51/0x80
    [  135.287441]  page_cache_ra_unbounded+0x124/0x170
    [  135.288510]  filemap_get_pages+0x23d/0x5a0
    [  135.289457]  ? path_openat+0xa72/0xdd0
    [  135.290332]  filemap_read+0xbf/0x300
    [  135.291158]  ? _raw_spin_lock_irqsave+0x17/0x40
    [  135.292192]  new_sync_read+0x103/0x170
    [  135.293014]  vfs_read+0x15d/0x180
    [  135.293745]  ksys_read+0xa1/0xe0
    [  135.294461]  do_syscall_64+0x3c/0x80
    [  135.295284]  entry_SYSCALL_64_after_hwframe+0x46/0xb0
    
    This patch simply adds an extra check in __ext4_ext_check(), verifying that
    eh_entries is not 0 when eh_depth is > 0.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=215941
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=216283
    Cc: Baokun Li <libaokun1@huawei.com>
    Cc: stable@kernel.org
    Signed-off-by: Lus Henriques <lhenriques@suse.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Baokun Li <libaokun1@huawei.com>
    Link: https://lore.kernel.org/r/20220822094235.2690-1-lhenriques@suse.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 99ee9317a1305cd5626736785c8cb38b0e47686c
Author: Nico Pache <npache@redhat.com>
Date:   Mon Sep 19 08:49:32 2022 -0600

    tracing/osnoise: Fix possible recursive locking in stop_per_cpu_kthreads
    
    There is a recursive lock on the cpu_hotplug_lock.
    
    In kernel/trace/trace_osnoise.c:<start/stop>_per_cpu_kthreads:
        - start_per_cpu_kthreads calls cpus_read_lock() and if
            start_kthreads returns a error it will call stop_per_cpu_kthreads.
        - stop_per_cpu_kthreads then calls cpus_read_lock() again causing
          deadlock.
    
    Fix this by calling cpus_read_unlock() before calling
    stop_per_cpu_kthreads. This behavior can also be seen in commit
    f46b16520a08 ("trace/hwlat: Implement the per-cpu mode").
    
    This error was noticed during the LTP ftrace-stress-test:
    
    WARNING: possible recursive locking detected
    --------------------------------------------
    sh/275006 is trying to acquire lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: stop_per_cpu_kthreads
    
    but task is already holding lock:
    ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
          CPU0
          ----
     lock(cpu_hotplug_lock);
     lock(cpu_hotplug_lock);
    
     *** DEADLOCK ***
    
    May be due to missing lock nesting notation
    
    3 locks held by sh/275006:
     #0: ffff8881023f0470 (sb_writers#24){.+.+}-{0:0}, at: ksys_write
     #1: ffffffffb084f430 (trace_types_lock){+.+.}-{3:3}, at: rb_simple_write
     #2: ffffffffb02f5400 (cpu_hotplug_lock){++++}-{0:0}, at: start_per_cpu_kthreads
    
    Link: https://lkml.kernel.org/r/20220919144932.3064014-1-npache@redhat.com
    
    Fixes: c8895e271f79 ("trace/osnoise: Support hotplug operations")
    Signed-off-by: Nico Pache <npache@redhat.com>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>

commit 29a5b8a137ac8eb410cc823653a29ac0e7b7e1b0
Author: Lus Henriques <lhenriques@suse.de>
Date:   Mon Aug 22 10:42:35 2022 +0100

    ext4: fix bug in extents parsing when eh_entries == 0 and eh_depth > 0
    
    When walking through an inode extents, the ext4_ext_binsearch_idx() function
    assumes that the extent header has been previously validated.  However, there
    are no checks that verify that the number of entries (eh->eh_entries) is
    non-zero when depth is > 0.  And this will lead to problems because the
    EXT_FIRST_INDEX() and EXT_LAST_INDEX() will return garbage and result in this:
    
    [  135.245946] ------------[ cut here ]------------
    [  135.247579] kernel BUG at fs/ext4/extents.c:2258!
    [  135.249045] invalid opcode: 0000 [#1] PREEMPT SMP
    [  135.250320] CPU: 2 PID: 238 Comm: tmp118 Not tainted 5.19.0-rc8+ #4
    [  135.252067] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.15.0-0-g2dd4b9b-rebuilt.opensuse.org 04/01/2014
    [  135.255065] RIP: 0010:ext4_ext_map_blocks+0xc20/0xcb0
    [  135.256475] Code:
    [  135.261433] RSP: 0018:ffffc900005939f8 EFLAGS: 00010246
    [  135.262847] RAX: 0000000000000024 RBX: ffffc90000593b70 RCX: 0000000000000023
    [  135.264765] RDX: ffff8880038e5f10 RSI: 0000000000000003 RDI: ffff8880046e922c
    [  135.266670] RBP: ffff8880046e9348 R08: 0000000000000001 R09: ffff888002ca580c
    [  135.268576] R10: 0000000000002602 R11: 0000000000000000 R12: 0000000000000024
    [  135.270477] R13: 0000000000000000 R14: 0000000000000024 R15: 0000000000000000
    [  135.272394] FS:  00007fdabdc56740(0000) GS:ffff88807dd00000(0000) knlGS:0000000000000000
    [  135.274510] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  135.276075] CR2: 00007ffc26bd4f00 CR3: 0000000006261004 CR4: 0000000000170ea0
    [  135.277952] Call Trace:
    [  135.278635]  <TASK>
    [  135.279247]  ? preempt_count_add+0x6d/0xa0
    [  135.280358]  ? percpu_counter_add_batch+0x55/0xb0
    [  135.281612]  ? _raw_read_unlock+0x18/0x30
    [  135.282704]  ext4_map_blocks+0x294/0x5a0
    [  135.283745]  ? xa_load+0x6f/0xa0
    [  135.284562]  ext4_mpage_readpages+0x3d6/0x770
    [  135.285646]  read_pages+0x67/0x1d0
    [  135.286492]  ? folio_add_lru+0x51/0x80
    [  135.287441]  page_cache_ra_unbounded+0x124/0x170
    [  135.288510]  filemap_get_pages+0x23d/0x5a0
    [  135.289457]  ? path_openat+0xa72/0xdd0
    [  135.290332]  filemap_read+0xbf/0x300
    [  135.291158]  ? _raw_spin_lock_irqsave+0x17/0x40
    [  135.292192]  new_sync_read+0x103/0x170
    [  135.293014]  vfs_read+0x15d/0x180
    [  135.293745]  ksys_read+0xa1/0xe0
    [  135.294461]  do_syscall_64+0x3c/0x80
    [  135.295284]  entry_SYSCALL_64_after_hwframe+0x46/0xb0
    
    This patch simply adds an extra check in __ext4_ext_check(), verifying that
    eh_entries is not 0 when eh_depth is > 0.
    
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=215941
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=216283
    Cc: Baokun Li <libaokun1@huawei.com>
    Cc: stable@kernel.org
    Signed-off-by: Lus Henriques <lhenriques@suse.de>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Reviewed-by: Baokun Li <libaokun1@huawei.com>
    Link: https://lore.kernel.org/r/20220822094235.2690-1-lhenriques@suse.de
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>

commit b07a9b26e2b1aa3711fd6935eccb08a463b1fb11
Author: Ido Schimmel <idosch@nvidia.com>
Date:   Wed Sep 14 10:53:38 2022 +0300

    ipmr: Always call ip{,6}_mr_forward() from RCU read-side critical section
    
    These functions expect to be called from RCU read-side critical section,
    but this only happens when invoked from the data path via
    ip{,6}_mr_input(). They can also be invoked from process context in
    response to user space adding a multicast route which resolves a cache
    entry with queued packets [1][2].
    
    Fix by adding missing rcu_read_lock() / rcu_read_unlock() in these call
    paths.
    
    [1]
    WARNING: suspicious RCU usage
    6.0.0-rc3-custom-15969-g049d233c8bcc-dirty #1387 Not tainted
    -----------------------------
    net/ipv4/ipmr.c:84 suspicious rcu_dereference_check() usage!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    1 lock held by smcrouted/246:
     #0: ffffffff862389b0 (rtnl_mutex){+.+.}-{3:3}, at: ip_mroute_setsockopt+0x11c/0x1420
    
    stack backtrace:
    CPU: 0 PID: 246 Comm: smcrouted Not tainted 6.0.0-rc3-custom-15969-g049d233c8bcc-dirty #1387
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    Call Trace:
     <TASK>
     dump_stack_lvl+0x91/0xb9
     vif_dev_read+0xbf/0xd0
     ipmr_queue_xmit+0x135/0x1ab0
     ip_mr_forward+0xe7b/0x13d0
     ipmr_mfc_add+0x1a06/0x2ad0
     ip_mroute_setsockopt+0x5c1/0x1420
     do_ip_setsockopt+0x23d/0x37f0
     ip_setsockopt+0x56/0x80
     raw_setsockopt+0x219/0x290
     __sys_setsockopt+0x236/0x4d0
     __x64_sys_setsockopt+0xbe/0x160
     do_syscall_64+0x34/0x80
     entry_SYSCALL_64_after_hwframe+0x63/0xcd
    
    [2]
    WARNING: suspicious RCU usage
    6.0.0-rc3-custom-15969-g049d233c8bcc-dirty #1387 Not tainted
    -----------------------------
    net/ipv6/ip6mr.c:69 suspicious rcu_dereference_check() usage!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    1 lock held by smcrouted/246:
     #0: ffffffff862389b0 (rtnl_mutex){+.+.}-{3:3}, at: ip6_mroute_setsockopt+0x6b9/0x2630
    
    stack backtrace:
    CPU: 1 PID: 246 Comm: smcrouted Not tainted 6.0.0-rc3-custom-15969-g049d233c8bcc-dirty #1387
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.0-1.fc36 04/01/2014
    Call Trace:
     <TASK>
     dump_stack_lvl+0x91/0xb9
     vif_dev_read+0xbf/0xd0
     ip6mr_forward2.isra.0+0xc9/0x1160
     ip6_mr_forward+0xef0/0x13f0
     ip6mr_mfc_add+0x1ff2/0x31f0
     ip6_mroute_setsockopt+0x1825/0x2630
     do_ipv6_setsockopt+0x462/0x4440
     ipv6_setsockopt+0x105/0x140
     rawv6_setsockopt+0xd8/0x690
     __sys_setsockopt+0x236/0x4d0
     __x64_sys_setsockopt+0xbe/0x160
     do_syscall_64+0x34/0x80
     entry_SYSCALL_64_after_hwframe+0x63/0xcd
    
    Fixes: ebc3197963fc ("ipmr: add rcu protection over (struct vif_device)->dev")
    Signed-off-by: Ido Schimmel <idosch@nvidia.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit 684c68d92e2e1b97fa2f31c35c1b0f7671a8618a
Author: Michael Ellerman <mpe@ellerman.id.au>
Date:   Wed Aug 31 23:10:52 2022 +1000

    Revert "powerpc/irq: Don't open code irq_soft_mask helpers"
    
    This reverts commit ef5b570d3700fbb8628a58da0487486ceeb713cd.
    
    Zhouyi reported that commit is causing crashes when running rcutorture
    with KASAN enabled:
    
      BUG: using smp_processor_id() in preemptible [00000000] code: rcu_torture_rea/100
      caller is rcu_preempt_deferred_qs_irqrestore+0x74/0xed0
      CPU: 4 PID: 100 Comm: rcu_torture_rea Tainted: G        W          5.19.0-rc5-next-20220708-dirty #253
      Call Trace:
        dump_stack_lvl+0xbc/0x108 (unreliable)
        check_preemption_disabled+0x154/0x160
        rcu_preempt_deferred_qs_irqrestore+0x74/0xed0
        __rcu_read_unlock+0x290/0x3b0
        rcu_torture_read_unlock+0x30/0xb0
        rcutorture_one_extend+0x198/0x810
        rcu_torture_one_read+0x58c/0xc90
        rcu_torture_reader+0x12c/0x360
        kthread+0x1e8/0x220
        ret_from_kernel_thread+0x5c/0x64
    
    KASAN will generate instrumentation instructions around the
    WRITE_ONCE(local_paca->irq_soft_mask, mask):
    
       0xc000000000295cb0 <+0>:     addis   r2,r12,774
       0xc000000000295cb4 <+4>:     addi    r2,r2,16464
       0xc000000000295cb8 <+8>:     mflr    r0
       0xc000000000295cbc <+12>:    bl      0xc00000000008bb4c <mcount>
       0xc000000000295cc0 <+16>:    mflr    r0
       0xc000000000295cc4 <+20>:    std     r31,-8(r1)
       0xc000000000295cc8 <+24>:    addi    r3,r13,2354
       0xc000000000295ccc <+28>:    mr      r31,r13
       0xc000000000295cd0 <+32>:    std     r0,16(r1)
       0xc000000000295cd4 <+36>:    stdu    r1,-48(r1)
       0xc000000000295cd8 <+40>:    bl      0xc000000000609b98 <__asan_store1+8>
       0xc000000000295cdc <+44>:    nop
       0xc000000000295ce0 <+48>:    li      r9,1
       0xc000000000295ce4 <+52>:    stb     r9,2354(r31)
       0xc000000000295ce8 <+56>:    addi    r1,r1,48
       0xc000000000295cec <+60>:    ld      r0,16(r1)
       0xc000000000295cf0 <+64>:    ld      r31,-8(r1)
       0xc000000000295cf4 <+68>:    mtlr    r0
    
    If there is a context switch before "stb     r9,2354(r31)", r31 may
    not equal to r13, in such case, irq soft mask will not work.
    
    The usual solution of marking the code ineligible for instrumentation
    forces the code out-of-line, which we would prefer to avoid. Christophe
    proposed a partial revert, but Nick raised some concerns with that. So
    for now do a full revert.
    
    Reported-by: Zhouyi Zhou <zhouzhouyi@gmail.com>
    [mpe: Construct change log based on Zhouyi's original report]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20220831131052.42250-1-mpe@ellerman.id.au

commit b0faef51599e2e848bce046b7c769a4f8dbeac33
Author: Moshe Shemesh <moshe@nvidia.com>
Date:   Wed Aug 3 10:49:23 2022 +0300

    net/mlx5: Avoid false positive lockdep warning by adding lock_class_key
    
    [ Upstream commit d59b73a66e5e0682442b6d7b4965364e57078b80 ]
    
    Add a lock_class_key per mlx5 device to avoid a false positive
    "possible circular locking dependency" warning by lockdep, on flows
    which lock more than one mlx5 device, such as adding SF.
    
    kernel log:
     ======================================================
     WARNING: possible circular locking dependency detected
     5.19.0-rc8+ #2 Not tainted
     ------------------------------------------------------
     kworker/u20:0/8 is trying to acquire lock:
     ffff88812dfe0d98 (&dev->intf_state_mutex){+.+.}-{3:3}, at: mlx5_init_one+0x2e/0x490 [mlx5_core]
    
     but task is already holding lock:
     ffff888101aa7898 (&(&notifier->n_head)->rwsem){++++}-{3:3}, at: blocking_notifier_call_chain+0x5a/0x130
    
     which lock already depends on the new lock.
    
     the existing dependency chain (in reverse order) is:
    
     -> #1 (&(&notifier->n_head)->rwsem){++++}-{3:3}:
            down_write+0x90/0x150
            blocking_notifier_chain_register+0x53/0xa0
            mlx5_sf_table_init+0x369/0x4a0 [mlx5_core]
            mlx5_init_one+0x261/0x490 [mlx5_core]
            probe_one+0x430/0x680 [mlx5_core]
            local_pci_probe+0xd6/0x170
            work_for_cpu_fn+0x4e/0xa0
            process_one_work+0x7c2/0x1340
            worker_thread+0x6f6/0xec0
            kthread+0x28f/0x330
            ret_from_fork+0x1f/0x30
    
     -> #0 (&dev->intf_state_mutex){+.+.}-{3:3}:
            __lock_acquire+0x2fc7/0x6720
            lock_acquire+0x1c1/0x550
            __mutex_lock+0x12c/0x14b0
            mlx5_init_one+0x2e/0x490 [mlx5_core]
            mlx5_sf_dev_probe+0x29c/0x370 [mlx5_core]
            auxiliary_bus_probe+0x9d/0xe0
            really_probe+0x1e0/0xaa0
            __driver_probe_device+0x219/0x480
            driver_probe_device+0x49/0x130
            __device_attach_driver+0x1b8/0x280
            bus_for_each_drv+0x123/0x1a0
            __device_attach+0x1a3/0x460
            bus_probe_device+0x1a2/0x260
            device_add+0x9b1/0x1b40
            __auxiliary_device_add+0x88/0xc0
            mlx5_sf_dev_state_change_handler+0x67e/0x9d0 [mlx5_core]
            blocking_notifier_call_chain+0xd5/0x130
            mlx5_vhca_state_work_handler+0x2b0/0x3f0 [mlx5_core]
            process_one_work+0x7c2/0x1340
            worker_thread+0x59d/0xec0
            kthread+0x28f/0x330
            ret_from_fork+0x1f/0x30
    
      other info that might help us debug this:
    
      Possible unsafe locking scenario:
    
            CPU0                    CPU1
            ----                    ----
       lock(&(&notifier->n_head)->rwsem);
                                    lock(&dev->intf_state_mutex);
                                    lock(&(&notifier->n_head)->rwsem);
       lock(&dev->intf_state_mutex);
    
      *** DEADLOCK ***
    
     4 locks held by kworker/u20:0/8:
      #0: ffff888150612938 ((wq_completion)mlx5_events){+.+.}-{0:0}, at: process_one_work+0x6e2/0x1340
      #1: ffff888100cafdb8 ((work_completion)(&work->work)#3){+.+.}-{0:0}, at: process_one_work+0x70f/0x1340
      #2: ffff888101aa7898 (&(&notifier->n_head)->rwsem){++++}-{3:3}, at: blocking_notifier_call_chain+0x5a/0x130
      #3: ffff88813682d0e8 (&dev->mutex){....}-{3:3}, at:__device_attach+0x76/0x460
    
     stack backtrace:
     CPU: 6 PID: 8 Comm: kworker/u20:0 Not tainted 5.19.0-rc8+
     Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014
     Workqueue: mlx5_events mlx5_vhca_state_work_handler [mlx5_core]
     Call Trace:
      <TASK>
      dump_stack_lvl+0x57/0x7d
      check_noncircular+0x278/0x300
      ? print_circular_bug+0x460/0x460
      ? lock_chain_count+0x20/0x20
      ? register_lock_class+0x1880/0x1880
      __lock_acquire+0x2fc7/0x6720
      ? register_lock_class+0x1880/0x1880
      ? register_lock_class+0x1880/0x1880
      lock_acquire+0x1c1/0x550
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? lockdep_hardirqs_on_prepare+0x400/0x400
      __mutex_lock+0x12c/0x14b0
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? _raw_read_unlock+0x1f/0x30
      ? mutex_lock_io_nested+0x1320/0x1320
      ? __ioremap_caller.constprop.0+0x306/0x490
      ? mlx5_sf_dev_probe+0x269/0x370 [mlx5_core]
      ? iounmap+0x160/0x160
      mlx5_init_one+0x2e/0x490 [mlx5_core]
      mlx5_sf_dev_probe+0x29c/0x370 [mlx5_core]
      ? mlx5_sf_dev_remove+0x130/0x130 [mlx5_core]
      auxiliary_bus_probe+0x9d/0xe0
      really_probe+0x1e0/0xaa0
      __driver_probe_device+0x219/0x480
      ? auxiliary_match_id+0xe9/0x140
      driver_probe_device+0x49/0x130
      __device_attach_driver+0x1b8/0x280
      ? driver_allows_async_probing+0x140/0x140
      bus_for_each_drv+0x123/0x1a0
      ? bus_for_each_dev+0x1a0/0x1a0
      ? lockdep_hardirqs_on_prepare+0x286/0x400
      ? trace_hardirqs_on+0x2d/0x100
      __device_attach+0x1a3/0x460
      ? device_driver_attach+0x1e0/0x1e0
      ? kobject_uevent_env+0x22d/0xf10
      bus_probe_device+0x1a2/0x260
      device_add+0x9b1/0x1b40
      ? dev_set_name+0xab/0xe0
      ? __fw_devlink_link_to_suppliers+0x260/0x260
      ? memset+0x20/0x40
      ? lockdep_init_map_type+0x21a/0x7d0
      __auxiliary_device_add+0x88/0xc0
      ? auxiliary_device_init+0x86/0xa0
      mlx5_sf_dev_state_change_handler+0x67e/0x9d0 [mlx5_core]
      blocking_notifier_call_chain+0xd5/0x130
      mlx5_vhca_state_work_handler+0x2b0/0x3f0 [mlx5_core]
      ? mlx5_vhca_event_arm+0x100/0x100 [mlx5_core]
      ? lock_downgrade+0x6e0/0x6e0
      ? lockdep_hardirqs_on_prepare+0x286/0x400
      process_one_work+0x7c2/0x1340
      ? lockdep_hardirqs_on_prepare+0x400/0x400
      ? pwq_dec_nr_in_flight+0x230/0x230
      ? rwlock_bug.part.0+0x90/0x90
      worker_thread+0x59d/0xec0
      ? process_one_work+0x1340/0x1340
      kthread+0x28f/0x330
      ? kthread_complete_and_exit+0x20/0x20
      ret_from_fork+0x1f/0x30
      </TASK>
    
    Fixes: 6a3273217469 ("net/mlx5: SF, Port function state change support")
    Signed-off-by: Moshe Shemesh <moshe@nvidia.com>
    Reviewed-by: Shay Drory <shayd@nvidia.com>
    Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e161c24a92efc983233cde901327ec86659280c0
Author: Moshe Shemesh <moshe@nvidia.com>
Date:   Wed Aug 3 10:49:23 2022 +0300

    net/mlx5: Avoid false positive lockdep warning by adding lock_class_key
    
    [ Upstream commit d59b73a66e5e0682442b6d7b4965364e57078b80 ]
    
    Add a lock_class_key per mlx5 device to avoid a false positive
    "possible circular locking dependency" warning by lockdep, on flows
    which lock more than one mlx5 device, such as adding SF.
    
    kernel log:
     ======================================================
     WARNING: possible circular locking dependency detected
     5.19.0-rc8+ #2 Not tainted
     ------------------------------------------------------
     kworker/u20:0/8 is trying to acquire lock:
     ffff88812dfe0d98 (&dev->intf_state_mutex){+.+.}-{3:3}, at: mlx5_init_one+0x2e/0x490 [mlx5_core]
    
     but task is already holding lock:
     ffff888101aa7898 (&(&notifier->n_head)->rwsem){++++}-{3:3}, at: blocking_notifier_call_chain+0x5a/0x130
    
     which lock already depends on the new lock.
    
     the existing dependency chain (in reverse order) is:
    
     -> #1 (&(&notifier->n_head)->rwsem){++++}-{3:3}:
            down_write+0x90/0x150
            blocking_notifier_chain_register+0x53/0xa0
            mlx5_sf_table_init+0x369/0x4a0 [mlx5_core]
            mlx5_init_one+0x261/0x490 [mlx5_core]
            probe_one+0x430/0x680 [mlx5_core]
            local_pci_probe+0xd6/0x170
            work_for_cpu_fn+0x4e/0xa0
            process_one_work+0x7c2/0x1340
            worker_thread+0x6f6/0xec0
            kthread+0x28f/0x330
            ret_from_fork+0x1f/0x30
    
     -> #0 (&dev->intf_state_mutex){+.+.}-{3:3}:
            __lock_acquire+0x2fc7/0x6720
            lock_acquire+0x1c1/0x550
            __mutex_lock+0x12c/0x14b0
            mlx5_init_one+0x2e/0x490 [mlx5_core]
            mlx5_sf_dev_probe+0x29c/0x370 [mlx5_core]
            auxiliary_bus_probe+0x9d/0xe0
            really_probe+0x1e0/0xaa0
            __driver_probe_device+0x219/0x480
            driver_probe_device+0x49/0x130
            __device_attach_driver+0x1b8/0x280
            bus_for_each_drv+0x123/0x1a0
            __device_attach+0x1a3/0x460
            bus_probe_device+0x1a2/0x260
            device_add+0x9b1/0x1b40
            __auxiliary_device_add+0x88/0xc0
            mlx5_sf_dev_state_change_handler+0x67e/0x9d0 [mlx5_core]
            blocking_notifier_call_chain+0xd5/0x130
            mlx5_vhca_state_work_handler+0x2b0/0x3f0 [mlx5_core]
            process_one_work+0x7c2/0x1340
            worker_thread+0x59d/0xec0
            kthread+0x28f/0x330
            ret_from_fork+0x1f/0x30
    
      other info that might help us debug this:
    
      Possible unsafe locking scenario:
    
            CPU0                    CPU1
            ----                    ----
       lock(&(&notifier->n_head)->rwsem);
                                    lock(&dev->intf_state_mutex);
                                    lock(&(&notifier->n_head)->rwsem);
       lock(&dev->intf_state_mutex);
    
      *** DEADLOCK ***
    
     4 locks held by kworker/u20:0/8:
      #0: ffff888150612938 ((wq_completion)mlx5_events){+.+.}-{0:0}, at: process_one_work+0x6e2/0x1340
      #1: ffff888100cafdb8 ((work_completion)(&work->work)#3){+.+.}-{0:0}, at: process_one_work+0x70f/0x1340
      #2: ffff888101aa7898 (&(&notifier->n_head)->rwsem){++++}-{3:3}, at: blocking_notifier_call_chain+0x5a/0x130
      #3: ffff88813682d0e8 (&dev->mutex){....}-{3:3}, at:__device_attach+0x76/0x460
    
     stack backtrace:
     CPU: 6 PID: 8 Comm: kworker/u20:0 Not tainted 5.19.0-rc8+
     Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014
     Workqueue: mlx5_events mlx5_vhca_state_work_handler [mlx5_core]
     Call Trace:
      <TASK>
      dump_stack_lvl+0x57/0x7d
      check_noncircular+0x278/0x300
      ? print_circular_bug+0x460/0x460
      ? lock_chain_count+0x20/0x20
      ? register_lock_class+0x1880/0x1880
      __lock_acquire+0x2fc7/0x6720
      ? register_lock_class+0x1880/0x1880
      ? register_lock_class+0x1880/0x1880
      lock_acquire+0x1c1/0x550
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? lockdep_hardirqs_on_prepare+0x400/0x400
      __mutex_lock+0x12c/0x14b0
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? _raw_read_unlock+0x1f/0x30
      ? mutex_lock_io_nested+0x1320/0x1320
      ? __ioremap_caller.constprop.0+0x306/0x490
      ? mlx5_sf_dev_probe+0x269/0x370 [mlx5_core]
      ? iounmap+0x160/0x160
      mlx5_init_one+0x2e/0x490 [mlx5_core]
      mlx5_sf_dev_probe+0x29c/0x370 [mlx5_core]
      ? mlx5_sf_dev_remove+0x130/0x130 [mlx5_core]
      auxiliary_bus_probe+0x9d/0xe0
      really_probe+0x1e0/0xaa0
      __driver_probe_device+0x219/0x480
      ? auxiliary_match_id+0xe9/0x140
      driver_probe_device+0x49/0x130
      __device_attach_driver+0x1b8/0x280
      ? driver_allows_async_probing+0x140/0x140
      bus_for_each_drv+0x123/0x1a0
      ? bus_for_each_dev+0x1a0/0x1a0
      ? lockdep_hardirqs_on_prepare+0x286/0x400
      ? trace_hardirqs_on+0x2d/0x100
      __device_attach+0x1a3/0x460
      ? device_driver_attach+0x1e0/0x1e0
      ? kobject_uevent_env+0x22d/0xf10
      bus_probe_device+0x1a2/0x260
      device_add+0x9b1/0x1b40
      ? dev_set_name+0xab/0xe0
      ? __fw_devlink_link_to_suppliers+0x260/0x260
      ? memset+0x20/0x40
      ? lockdep_init_map_type+0x21a/0x7d0
      __auxiliary_device_add+0x88/0xc0
      ? auxiliary_device_init+0x86/0xa0
      mlx5_sf_dev_state_change_handler+0x67e/0x9d0 [mlx5_core]
      blocking_notifier_call_chain+0xd5/0x130
      mlx5_vhca_state_work_handler+0x2b0/0x3f0 [mlx5_core]
      ? mlx5_vhca_event_arm+0x100/0x100 [mlx5_core]
      ? lock_downgrade+0x6e0/0x6e0
      ? lockdep_hardirqs_on_prepare+0x286/0x400
      process_one_work+0x7c2/0x1340
      ? lockdep_hardirqs_on_prepare+0x400/0x400
      ? pwq_dec_nr_in_flight+0x230/0x230
      ? rwlock_bug.part.0+0x90/0x90
      worker_thread+0x59d/0xec0
      ? process_one_work+0x1340/0x1340
      kthread+0x28f/0x330
      ? kthread_complete_and_exit+0x20/0x20
      ret_from_fork+0x1f/0x30
      </TASK>
    
    Fixes: 6a3273217469 ("net/mlx5: SF, Port function state change support")
    Signed-off-by: Moshe Shemesh <moshe@nvidia.com>
    Reviewed-by: Shay Drory <shayd@nvidia.com>
    Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1aa262c1d056551dd1246115af8b7e351184deae
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Mon Aug 22 15:07:03 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    commit f7b12a62f008a3041f42f2426983e59a6a0a3c59 upstream
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 621189a1fe93cb2b34d62c5cdb9e258bca044813
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Mon Aug 8 10:26:26 2022 +0800

    rcu: Avoid triggering strict-GP irq-work when RCU is idle
    
    Kernels built with PREEMPT_RCU=y and RCU_STRICT_GRACE_PERIOD=y trigger
    irq-work from rcu_read_unlock(), and the resulting irq-work handler
    invokes rcu_preempt_deferred_qs_handle().  The point of this triggering
    is to force grace periods to end quickly in order to give tools like KASAN
    a better chance of detecting RCU usage bugs such as leaking RCU-protected
    pointers out of an RCU read-side critical section.
    
    However, this irq-work triggering is unconditional.  This works, but
    there is no point in doing this irq-work unless the current grace period
    is waiting on the running CPU or task, which is not the common case.
    After all, in the common case there are many rcu_read_unlock() calls
    per CPU per grace period.
    
    This commit therefore triggers the irq-work only when the current grace
    period is waiting on the running CPU or task.
    
    This change was tested as follows on a four-CPU system:
    
            echo rcu_preempt_deferred_qs_handler > /sys/kernel/debug/tracing/set_ftrace_filter
            echo 1 > /sys/kernel/debug/tracing/function_profile_enabled
            insmod rcutorture.ko
            sleep 20
            rmmod rcutorture.ko
            echo 0 > /sys/kernel/debug/tracing/function_profile_enabled
            echo > /sys/kernel/debug/tracing/set_ftrace_filter
    
    This procedure produces results in this per-CPU set of files:
    
            /sys/kernel/debug/tracing/trace_stat/function*
    
    Sample output from one of these files is as follows:
    
      Function                               Hit    Time            Avg             s^2
      --------                               ---    ----            ---             ---
      rcu_preempt_deferred_qs_handle      838746    182650.3 us     0.217 us        0.004 us
    
    The baseline sum of the "Hit" values (the number of calls to this
    function) was 3,319,015.  With this commit, that sum was 1,140,359,
    for a 2.9x reduction.  The worst-case variance across the CPUs was less
    than 25%, so this large effect size is statistically significant.
    
    The raw data is available in the Link: URL.
    
    Link: https://lore.kernel.org/all/20220808022626.12825-1-qiang1.zhang@intel.com/
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit fcb42c9a77d490ed0974e4d394519481aa06e585
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Tue Jul 5 12:09:51 2022 -0700

    rcu: Add QS check in rcu_exp_handler() for non-preemptible kernels
    
    Kernels built with CONFIG_PREEMPTION=n and CONFIG_PREEMPT_COUNT=y maintain
    preempt_count() state.  Because such kernels map __rcu_read_lock()
    and __rcu_read_unlock() to preempt_disable() and preempt_enable(),
    respectively, this allows the expedited grace period's !CONFIG_PREEMPT_RCU
    version of the rcu_exp_handler() IPI handler function to use
    preempt_count() to detect quiescent states.
    
    This preempt_count() usage might seem to risk failures due to
    use of implicit RCU readers in portions of the kernel under #ifndef
    CONFIG_PREEMPTION, except that rcu_core() already disallows such implicit
    RCU readers.  The moral of this story is that you must use explicit
    read-side markings such as rcu_read_lock() or preempt_disable() even if
    the code knows that this kernel does not support preemption.
    
    This commit therefore adds a preempt_count()-based check for a quiescent
    state in the !CONFIG_PREEMPT_RCU version of the rcu_exp_handler()
    function for kernels built with CONFIG_PREEMPT_COUNT=y, reporting an
    immediate quiescent state when the interrupted code had both preemption
    and softirqs enabled.
    
    This change results in about a 2% reduction in expedited grace-period
    latency in kernels built with both CONFIG_PREEMPT_RCU=n and
    CONFIG_PREEMPT_COUNT=y.
    
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Link: https://lore.kernel.org/all/20220622103549.2840087-1-qiang1.zhang@intel.com/

commit 6d60ea03ac2d3dcf6ddee6b45aa7213d8b0461c5
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Thu Jun 16 21:53:47 2022 +0800

    rcu: Fix rcu_read_unlock_strict() strict QS reporting
    
    Kernels built with CONFIG_PREEMPT=n and CONFIG_RCU_STRICT_GRACE_PERIOD=y
    report the quiescent state directly from the outermost rcu_read_unlock().
    However, the current CPU's rcu_data structure's ->cpu_no_qs.b.norm
    might still be set, in which case rcu_report_qs_rdp() will exit early,
    thus failing to report quiescent state.
    
    This commit therefore causes rcu_read_unlock_strict() to clear
    CPU's rcu_data structure's ->cpu_no_qs.b.norm field before invoking
    rcu_report_qs_rdp().
    
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 36a88efe8747ea90b94519345aa0795350d463f1
Author: Zhang Yi <yi.zhang@huawei.com>
Date:   Sat Jun 11 21:04:26 2022 +0800

    jbd2: fix outstanding credits assert in jbd2_journal_commit_transaction()
    
    [ Upstream commit a89573ce4ad32f19f43ec669771726817e185be0 ]
    
    We catch an assert problem in jbd2_journal_commit_transaction() when
    doing fsstress and request falut injection tests. The problem is
    happened in a race condition between jbd2_journal_commit_transaction()
    and ext4_end_io_end(). Firstly, ext4_writepages() writeback dirty pages
    and start reserved handle, and then the journal was aborted due to some
    previous metadata IO error, jbd2_journal_abort() start to commit current
    running transaction, the committing procedure could be raced by
    ext4_end_io_end() and lead to subtract j_reserved_credits twice from
    commit_transaction->t_outstanding_credits, finally the
    t_outstanding_credits is mistakenly smaller than t_nr_buffers and
    trigger assert.
    
    kjournald2           kworker
    
    jbd2_journal_commit_transaction()
     write_unlock(&journal->j_state_lock);
     atomic_sub(j_reserved_credits, t_outstanding_credits); //sub once
    
                         jbd2_journal_start_reserved()
                          start_this_handle()  //detect aborted journal
                          jbd2_journal_free_reserved()  //get running transaction
                           read_lock(&journal->j_state_lock)
                            __jbd2_journal_unreserve_handle()
                           atomic_sub(j_reserved_credits, t_outstanding_credits);
                           //sub again
                           read_unlock(&journal->j_state_lock);
    
     journal->j_running_transaction = NULL;
     J_ASSERT(t_nr_buffers <= t_outstanding_credits) //bomb!!!
    
    Fix this issue by using journal->j_state_lock to protect the subtraction
    in jbd2_journal_commit_transaction().
    
    Fixes: 96f1e0974575 ("jbd2: avoid long hold times of j_state_lock while committing a transaction")
    Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Link: https://lore.kernel.org/r/20220611130426.2013258-1-yi.zhang@huawei.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 30ea3257e8766027c4d8d609dcbd256ff9a76073
Author: Alexander Aring <aahringo@redhat.com>
Date:   Mon Aug 15 15:43:13 2022 -0400

    fs: dlm: fix race in lowcomms
    
    This patch fixes a race between queue_work() in
    _dlm_lowcomms_commit_msg() and srcu_read_unlock(). The queue_work() can
    take the final reference of a dlm_msg and so msg->idx can contain
    garbage which is signaled by the following warning:
    
    [  676.237050] ------------[ cut here ]------------
    [  676.237052] WARNING: CPU: 0 PID: 1060 at include/linux/srcu.h:189 dlm_lowcomms_commit_msg+0x41/0x50
    [  676.238945] Modules linked in: dlm_locktorture torture rpcsec_gss_krb5 intel_rapl_msr intel_rapl_common iTCO_wdt iTCO_vendor_support qxl kvm_intel drm_ttm_helper vmw_vsock_virtio_transport kvm vmw_vsock_virtio_transport_common ttm irqbypass crc32_pclmul joydev crc32c_intel serio_raw drm_kms_helper vsock virtio_scsi virtio_console virtio_balloon snd_pcm drm syscopyarea sysfillrect sysimgblt snd_timer fb_sys_fops i2c_i801 lpc_ich snd i2c_smbus soundcore pcspkr
    [  676.244227] CPU: 0 PID: 1060 Comm: lock_torture_wr Not tainted 5.19.0-rc3+ #1546
    [  676.245216] Hardware name: Red Hat KVM/RHEL-AV, BIOS 1.16.0-2.module+el8.7.0+15506+033991b0 04/01/2014
    [  676.246460] RIP: 0010:dlm_lowcomms_commit_msg+0x41/0x50
    [  676.247132] Code: fe ff ff ff 75 24 48 c7 c6 bd 0f 49 bb 48 c7 c7 38 7c 01 bd e8 00 e7 ca ff 89 de 48 c7 c7 60 78 01 bd e8 42 3d cd ff 5b 5d c3 <0f> 0b eb d8 66 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 55 48
    [  676.249253] RSP: 0018:ffffa401c18ffc68 EFLAGS: 00010282
    [  676.249855] RAX: 0000000000000001 RBX: 00000000ffff8b76 RCX: 0000000000000006
    [  676.250713] RDX: 0000000000000000 RSI: ffffffffbccf3a10 RDI: ffffffffbcc7b62e
    [  676.251610] RBP: ffffa401c18ffc70 R08: 0000000000000001 R09: 0000000000000001
    [  676.252481] R10: 0000000000000001 R11: 0000000000000001 R12: 0000000000000005
    [  676.253421] R13: ffff8b76786ec370 R14: ffff8b76786ec370 R15: ffff8b76786ec480
    [  676.254257] FS:  0000000000000000(0000) GS:ffff8b7777800000(0000) knlGS:0000000000000000
    [  676.255239] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  676.255897] CR2: 00005590205d88b8 CR3: 000000017656c003 CR4: 0000000000770ee0
    [  676.256734] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  676.257567] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  676.258397] PKRU: 55555554
    [  676.258729] Call Trace:
    [  676.259063]  <TASK>
    [  676.259354]  dlm_midcomms_commit_mhandle+0xcc/0x110
    [  676.259964]  queue_bast+0x8b/0xb0
    [  676.260423]  grant_pending_locks+0x166/0x1b0
    [  676.261007]  _unlock_lock+0x75/0x90
    [  676.261469]  unlock_lock.isra.57+0x62/0xa0
    [  676.262009]  dlm_unlock+0x21e/0x330
    [  676.262457]  ? lock_torture_stats+0x80/0x80 [dlm_locktorture]
    [  676.263183]  torture_unlock+0x5a/0x90 [dlm_locktorture]
    [  676.263815]  ? preempt_count_sub+0xba/0x100
    [  676.264361]  ? complete+0x1d/0x60
    [  676.264777]  lock_torture_writer+0xb8/0x150 [dlm_locktorture]
    [  676.265555]  kthread+0x10a/0x130
    [  676.266007]  ? kthread_complete_and_exit+0x20/0x20
    [  676.266616]  ret_from_fork+0x22/0x30
    [  676.267097]  </TASK>
    [  676.267381] irq event stamp: 9579855
    [  676.267824] hardirqs last  enabled at (9579863): [<ffffffffbb14e6f8>] __up_console_sem+0x58/0x60
    [  676.268896] hardirqs last disabled at (9579872): [<ffffffffbb14e6dd>] __up_console_sem+0x3d/0x60
    [  676.270008] softirqs last  enabled at (9579798): [<ffffffffbc200349>] __do_softirq+0x349/0x4c7
    [  676.271438] softirqs last disabled at (9579897): [<ffffffffbb0d54c0>] irq_exit_rcu+0xb0/0xf0
    [  676.272796] ---[ end trace 0000000000000000 ]---
    
    I reproduced this warning with dlm_locktorture test which is currently
    not upstream. However this patch fix the issue by make a additional
    refcount between dlm_lowcomms_new_msg() and dlm_lowcomms_commit_msg().
    In case of the race the kref_put() in dlm_lowcomms_commit_msg() will be
    the final put.
    
    Signed-off-by: Alexander Aring <aahringo@redhat.com>
    Signed-off-by: David Teigland <teigland@redhat.com>

commit d59b73a66e5e0682442b6d7b4965364e57078b80
Author: Moshe Shemesh <moshe@nvidia.com>
Date:   Wed Aug 3 10:49:23 2022 +0300

    net/mlx5: Avoid false positive lockdep warning by adding lock_class_key
    
    Add a lock_class_key per mlx5 device to avoid a false positive
    "possible circular locking dependency" warning by lockdep, on flows
    which lock more than one mlx5 device, such as adding SF.
    
    kernel log:
     ======================================================
     WARNING: possible circular locking dependency detected
     5.19.0-rc8+ #2 Not tainted
     ------------------------------------------------------
     kworker/u20:0/8 is trying to acquire lock:
     ffff88812dfe0d98 (&dev->intf_state_mutex){+.+.}-{3:3}, at: mlx5_init_one+0x2e/0x490 [mlx5_core]
    
     but task is already holding lock:
     ffff888101aa7898 (&(&notifier->n_head)->rwsem){++++}-{3:3}, at: blocking_notifier_call_chain+0x5a/0x130
    
     which lock already depends on the new lock.
    
     the existing dependency chain (in reverse order) is:
    
     -> #1 (&(&notifier->n_head)->rwsem){++++}-{3:3}:
            down_write+0x90/0x150
            blocking_notifier_chain_register+0x53/0xa0
            mlx5_sf_table_init+0x369/0x4a0 [mlx5_core]
            mlx5_init_one+0x261/0x490 [mlx5_core]
            probe_one+0x430/0x680 [mlx5_core]
            local_pci_probe+0xd6/0x170
            work_for_cpu_fn+0x4e/0xa0
            process_one_work+0x7c2/0x1340
            worker_thread+0x6f6/0xec0
            kthread+0x28f/0x330
            ret_from_fork+0x1f/0x30
    
     -> #0 (&dev->intf_state_mutex){+.+.}-{3:3}:
            __lock_acquire+0x2fc7/0x6720
            lock_acquire+0x1c1/0x550
            __mutex_lock+0x12c/0x14b0
            mlx5_init_one+0x2e/0x490 [mlx5_core]
            mlx5_sf_dev_probe+0x29c/0x370 [mlx5_core]
            auxiliary_bus_probe+0x9d/0xe0
            really_probe+0x1e0/0xaa0
            __driver_probe_device+0x219/0x480
            driver_probe_device+0x49/0x130
            __device_attach_driver+0x1b8/0x280
            bus_for_each_drv+0x123/0x1a0
            __device_attach+0x1a3/0x460
            bus_probe_device+0x1a2/0x260
            device_add+0x9b1/0x1b40
            __auxiliary_device_add+0x88/0xc0
            mlx5_sf_dev_state_change_handler+0x67e/0x9d0 [mlx5_core]
            blocking_notifier_call_chain+0xd5/0x130
            mlx5_vhca_state_work_handler+0x2b0/0x3f0 [mlx5_core]
            process_one_work+0x7c2/0x1340
            worker_thread+0x59d/0xec0
            kthread+0x28f/0x330
            ret_from_fork+0x1f/0x30
    
      other info that might help us debug this:
    
      Possible unsafe locking scenario:
    
            CPU0                    CPU1
            ----                    ----
       lock(&(&notifier->n_head)->rwsem);
                                    lock(&dev->intf_state_mutex);
                                    lock(&(&notifier->n_head)->rwsem);
       lock(&dev->intf_state_mutex);
    
      *** DEADLOCK ***
    
     4 locks held by kworker/u20:0/8:
      #0: ffff888150612938 ((wq_completion)mlx5_events){+.+.}-{0:0}, at: process_one_work+0x6e2/0x1340
      #1: ffff888100cafdb8 ((work_completion)(&work->work)#3){+.+.}-{0:0}, at: process_one_work+0x70f/0x1340
      #2: ffff888101aa7898 (&(&notifier->n_head)->rwsem){++++}-{3:3}, at: blocking_notifier_call_chain+0x5a/0x130
      #3: ffff88813682d0e8 (&dev->mutex){....}-{3:3}, at:__device_attach+0x76/0x460
    
     stack backtrace:
     CPU: 6 PID: 8 Comm: kworker/u20:0 Not tainted 5.19.0-rc8+
     Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS rel-1.13.0-0-gf21b5a4aeb02-prebuilt.qemu.org 04/01/2014
     Workqueue: mlx5_events mlx5_vhca_state_work_handler [mlx5_core]
     Call Trace:
      <TASK>
      dump_stack_lvl+0x57/0x7d
      check_noncircular+0x278/0x300
      ? print_circular_bug+0x460/0x460
      ? lock_chain_count+0x20/0x20
      ? register_lock_class+0x1880/0x1880
      __lock_acquire+0x2fc7/0x6720
      ? register_lock_class+0x1880/0x1880
      ? register_lock_class+0x1880/0x1880
      lock_acquire+0x1c1/0x550
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? lockdep_hardirqs_on_prepare+0x400/0x400
      __mutex_lock+0x12c/0x14b0
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? mlx5_init_one+0x2e/0x490 [mlx5_core]
      ? _raw_read_unlock+0x1f/0x30
      ? mutex_lock_io_nested+0x1320/0x1320
      ? __ioremap_caller.constprop.0+0x306/0x490
      ? mlx5_sf_dev_probe+0x269/0x370 [mlx5_core]
      ? iounmap+0x160/0x160
      mlx5_init_one+0x2e/0x490 [mlx5_core]
      mlx5_sf_dev_probe+0x29c/0x370 [mlx5_core]
      ? mlx5_sf_dev_remove+0x130/0x130 [mlx5_core]
      auxiliary_bus_probe+0x9d/0xe0
      really_probe+0x1e0/0xaa0
      __driver_probe_device+0x219/0x480
      ? auxiliary_match_id+0xe9/0x140
      driver_probe_device+0x49/0x130
      __device_attach_driver+0x1b8/0x280
      ? driver_allows_async_probing+0x140/0x140
      bus_for_each_drv+0x123/0x1a0
      ? bus_for_each_dev+0x1a0/0x1a0
      ? lockdep_hardirqs_on_prepare+0x286/0x400
      ? trace_hardirqs_on+0x2d/0x100
      __device_attach+0x1a3/0x460
      ? device_driver_attach+0x1e0/0x1e0
      ? kobject_uevent_env+0x22d/0xf10
      bus_probe_device+0x1a2/0x260
      device_add+0x9b1/0x1b40
      ? dev_set_name+0xab/0xe0
      ? __fw_devlink_link_to_suppliers+0x260/0x260
      ? memset+0x20/0x40
      ? lockdep_init_map_type+0x21a/0x7d0
      __auxiliary_device_add+0x88/0xc0
      ? auxiliary_device_init+0x86/0xa0
      mlx5_sf_dev_state_change_handler+0x67e/0x9d0 [mlx5_core]
      blocking_notifier_call_chain+0xd5/0x130
      mlx5_vhca_state_work_handler+0x2b0/0x3f0 [mlx5_core]
      ? mlx5_vhca_event_arm+0x100/0x100 [mlx5_core]
      ? lock_downgrade+0x6e0/0x6e0
      ? lockdep_hardirqs_on_prepare+0x286/0x400
      process_one_work+0x7c2/0x1340
      ? lockdep_hardirqs_on_prepare+0x400/0x400
      ? pwq_dec_nr_in_flight+0x230/0x230
      ? rwlock_bug.part.0+0x90/0x90
      worker_thread+0x59d/0xec0
      ? process_one_work+0x1340/0x1340
      kthread+0x28f/0x330
      ? kthread_complete_and_exit+0x20/0x20
      ret_from_fork+0x1f/0x30
      </TASK>
    
    Fixes: 6a3273217469 ("net/mlx5: SF, Port function state change support")
    Signed-off-by: Moshe Shemesh <moshe@nvidia.com>
    Reviewed-by: Shay Drory <shayd@nvidia.com>
    Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>

commit c76b216753c9eb2950a091037c9976f389e73529
Author: Hyunchul Lee <hyc.lee@gmail.com>
Date:   Thu Jul 28 23:41:51 2022 +0900

    ksmbd: prevent out of bound read for SMB2_WRITE
    
    commit ac60778b87e45576d7bfdbd6f53df902654e6f09 upstream.
    
    OOB read memory can be written to a file,
    if DataOffset is 0 and Length is too large
    in SMB2_WRITE request of compound request.
    
    To prevent this, when checking the length of
    the data area of SMB2_WRITE in smb2_get_data_area_len(),
    let the minimum of DataOffset be the size of
    SMB2 header + the size of SMB2_WRITE header.
    
    This bug can lead an oops looking something like:
    
    [  798.008715] BUG: KASAN: slab-out-of-bounds in copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008724] Read of size 252 at addr ffff88800f863e90 by task kworker/0:2/2859
    ...
    [  798.008754] Call Trace:
    [  798.008756]  <TASK>
    [  798.008759]  dump_stack_lvl+0x49/0x5f
    [  798.008764]  print_report.cold+0x5e/0x5cf
    [  798.008768]  ? __filemap_get_folio+0x285/0x6d0
    [  798.008774]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008777]  kasan_report+0xaa/0x120
    [  798.008781]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008784]  kasan_check_range+0x100/0x1e0
    [  798.008788]  memcpy+0x24/0x60
    [  798.008792]  copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008795]  ? pagecache_get_page+0x53/0x160
    [  798.008799]  ? iov_iter_get_pages_alloc+0x1590/0x1590
    [  798.008803]  ? ext4_write_begin+0xfc0/0xfc0
    [  798.008807]  ? current_time+0x72/0x210
    [  798.008811]  generic_perform_write+0x2c8/0x530
    [  798.008816]  ? filemap_fdatawrite_wbc+0x180/0x180
    [  798.008820]  ? down_write+0xb4/0x120
    [  798.008824]  ? down_write_killable+0x130/0x130
    [  798.008829]  ext4_buffered_write_iter+0x137/0x2c0
    [  798.008833]  ext4_file_write_iter+0x40b/0x1490
    [  798.008837]  ? __fsnotify_parent+0x275/0xb20
    [  798.008842]  ? __fsnotify_update_child_dentry_flags+0x2c0/0x2c0
    [  798.008846]  ? ext4_buffered_write_iter+0x2c0/0x2c0
    [  798.008851]  __kernel_write+0x3a1/0xa70
    [  798.008855]  ? __x64_sys_preadv2+0x160/0x160
    [  798.008860]  ? security_file_permission+0x4a/0xa0
    [  798.008865]  kernel_write+0xbb/0x360
    [  798.008869]  ksmbd_vfs_write+0x27e/0xb90 [ksmbd]
    [  798.008881]  ? ksmbd_vfs_read+0x830/0x830 [ksmbd]
    [  798.008892]  ? _raw_read_unlock+0x2a/0x50
    [  798.008896]  smb2_write+0xb45/0x14e0 [ksmbd]
    [  798.008909]  ? __kasan_check_write+0x14/0x20
    [  798.008912]  ? _raw_spin_lock_bh+0xd0/0xe0
    [  798.008916]  ? smb2_read+0x15e0/0x15e0 [ksmbd]
    [  798.008927]  ? memcpy+0x4e/0x60
    [  798.008931]  ? _raw_spin_unlock+0x19/0x30
    [  798.008934]  ? ksmbd_smb2_check_message+0x16af/0x2350 [ksmbd]
    [  798.008946]  ? _raw_spin_lock_bh+0xe0/0xe0
    [  798.008950]  handle_ksmbd_work+0x30e/0x1020 [ksmbd]
    [  798.008962]  process_one_work+0x778/0x11c0
    [  798.008966]  ? _raw_spin_lock_irq+0x8e/0xe0
    [  798.008970]  worker_thread+0x544/0x1180
    [  798.008973]  ? __cpuidle_text_end+0x4/0x4
    [  798.008977]  kthread+0x282/0x320
    [  798.008982]  ? process_one_work+0x11c0/0x11c0
    [  798.008985]  ? kthread_complete_and_exit+0x30/0x30
    [  798.008989]  ret_from_fork+0x1f/0x30
    [  798.008995]  </TASK>
    
    Fixes: e2f34481b24d ("cifsd: add server-side procedures for SMB3")
    Cc: stable@vger.kernel.org
    Reported-by: zdi-disclosures@trendmicro.com # ZDI-CAN-17817
    Signed-off-by: Hyunchul Lee <hyc.lee@gmail.com>
    Acked-by: Namjae Jeon <linkinjeon@kernel.org>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bc8c5b3b3eb9235e26bc31ceef617182c0da41e5
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 4 17:26:29 2022 -0400

    __follow_mount_rcu(): verify that mount_lock remains unchanged
    
    commit 20aac6c60981f5bfacd66661d090d907bf1482f0 upstream.
    
    Validate mount_lock seqcount as soon as we cross into mount in RCU
    mode.  Sure, ->mnt_root is pinned and will remain so until we
    do rcu_read_unlock() anyway, and we will eventually fail to unlazy if
    the mount_lock had been touched, but we might run into a hard error
    (e.g. -ENOENT) before trying to unlazy.  And it's possible to end
    up with RCU pathwalk racing with rename() and umount() in a way
    that would fail with -ENOENT while non-RCU pathwalk would've
    succeeded with any timings.
    
    Once upon a time we hadn't needed that, but analysis had been subtle,
    brittle and went out of window as soon as RENAME_EXCHANGE had been
    added.
    
    It's narrow, hard to hit and won't get you anything other than
    stray -ENOENT that could be arranged in much easier way with the
    same priveleges, but it's a bug all the same.
    
    Cc: stable@kernel.org
    X-sky-is-falling: unlikely
    Fixes: da1ce0670c14 "vfs: add cross-rename"
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 914bf4aa2d5bfc4a83866410dcd661a0fe955cb2
Author: Zhang Yi <yi.zhang@huawei.com>
Date:   Sat Jun 11 21:04:26 2022 +0800

    jbd2: fix outstanding credits assert in jbd2_journal_commit_transaction()
    
    [ Upstream commit a89573ce4ad32f19f43ec669771726817e185be0 ]
    
    We catch an assert problem in jbd2_journal_commit_transaction() when
    doing fsstress and request falut injection tests. The problem is
    happened in a race condition between jbd2_journal_commit_transaction()
    and ext4_end_io_end(). Firstly, ext4_writepages() writeback dirty pages
    and start reserved handle, and then the journal was aborted due to some
    previous metadata IO error, jbd2_journal_abort() start to commit current
    running transaction, the committing procedure could be raced by
    ext4_end_io_end() and lead to subtract j_reserved_credits twice from
    commit_transaction->t_outstanding_credits, finally the
    t_outstanding_credits is mistakenly smaller than t_nr_buffers and
    trigger assert.
    
    kjournald2           kworker
    
    jbd2_journal_commit_transaction()
     write_unlock(&journal->j_state_lock);
     atomic_sub(j_reserved_credits, t_outstanding_credits); //sub once
    
                         jbd2_journal_start_reserved()
                          start_this_handle()  //detect aborted journal
                          jbd2_journal_free_reserved()  //get running transaction
                           read_lock(&journal->j_state_lock)
                            __jbd2_journal_unreserve_handle()
                           atomic_sub(j_reserved_credits, t_outstanding_credits);
                           //sub again
                           read_unlock(&journal->j_state_lock);
    
     journal->j_running_transaction = NULL;
     J_ASSERT(t_nr_buffers <= t_outstanding_credits) //bomb!!!
    
    Fix this issue by using journal->j_state_lock to protect the subtraction
    in jbd2_journal_commit_transaction().
    
    Fixes: 96f1e0974575 ("jbd2: avoid long hold times of j_state_lock while committing a transaction")
    Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Link: https://lore.kernel.org/r/20220611130426.2013258-1-yi.zhang@huawei.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 096e8eb9639b342bc35f9b741cf05e26d0106e92
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Sat Jul 9 08:18:40 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    [ Upstream commit f7b12a62f008a3041f42f2426983e59a6a0a3c59 ]
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6fc0b164bbc3c772152b67038464a6324fb688ce
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 4 17:26:29 2022 -0400

    __follow_mount_rcu(): verify that mount_lock remains unchanged
    
    commit 20aac6c60981f5bfacd66661d090d907bf1482f0 upstream.
    
    Validate mount_lock seqcount as soon as we cross into mount in RCU
    mode.  Sure, ->mnt_root is pinned and will remain so until we
    do rcu_read_unlock() anyway, and we will eventually fail to unlazy if
    the mount_lock had been touched, but we might run into a hard error
    (e.g. -ENOENT) before trying to unlazy.  And it's possible to end
    up with RCU pathwalk racing with rename() and umount() in a way
    that would fail with -ENOENT while non-RCU pathwalk would've
    succeeded with any timings.
    
    Once upon a time we hadn't needed that, but analysis had been subtle,
    brittle and went out of window as soon as RENAME_EXCHANGE had been
    added.
    
    It's narrow, hard to hit and won't get you anything other than
    stray -ENOENT that could be arranged in much easier way with the
    same priveleges, but it's a bug all the same.
    
    Cc: stable@kernel.org
    X-sky-is-falling: unlikely
    Fixes: da1ce0670c14 "vfs: add cross-rename"
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d65c93290045e868e104d2aee781ea36d4356666
Author: Zhang Yi <yi.zhang@huawei.com>
Date:   Sat Jun 11 21:04:26 2022 +0800

    jbd2: fix outstanding credits assert in jbd2_journal_commit_transaction()
    
    [ Upstream commit a89573ce4ad32f19f43ec669771726817e185be0 ]
    
    We catch an assert problem in jbd2_journal_commit_transaction() when
    doing fsstress and request falut injection tests. The problem is
    happened in a race condition between jbd2_journal_commit_transaction()
    and ext4_end_io_end(). Firstly, ext4_writepages() writeback dirty pages
    and start reserved handle, and then the journal was aborted due to some
    previous metadata IO error, jbd2_journal_abort() start to commit current
    running transaction, the committing procedure could be raced by
    ext4_end_io_end() and lead to subtract j_reserved_credits twice from
    commit_transaction->t_outstanding_credits, finally the
    t_outstanding_credits is mistakenly smaller than t_nr_buffers and
    trigger assert.
    
    kjournald2           kworker
    
    jbd2_journal_commit_transaction()
     write_unlock(&journal->j_state_lock);
     atomic_sub(j_reserved_credits, t_outstanding_credits); //sub once
    
                         jbd2_journal_start_reserved()
                          start_this_handle()  //detect aborted journal
                          jbd2_journal_free_reserved()  //get running transaction
                           read_lock(&journal->j_state_lock)
                            __jbd2_journal_unreserve_handle()
                           atomic_sub(j_reserved_credits, t_outstanding_credits);
                           //sub again
                           read_unlock(&journal->j_state_lock);
    
     journal->j_running_transaction = NULL;
     J_ASSERT(t_nr_buffers <= t_outstanding_credits) //bomb!!!
    
    Fix this issue by using journal->j_state_lock to protect the subtraction
    in jbd2_journal_commit_transaction().
    
    Fixes: 96f1e0974575 ("jbd2: avoid long hold times of j_state_lock while committing a transaction")
    Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Link: https://lore.kernel.org/r/20220611130426.2013258-1-yi.zhang@huawei.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0f1c9908c8e18a98b3d6a80bf391bef8001d7fb7
Author: Hyunchul Lee <hyc.lee@gmail.com>
Date:   Thu Jul 28 23:41:51 2022 +0900

    ksmbd: prevent out of bound read for SMB2_WRITE
    
    commit ac60778b87e45576d7bfdbd6f53df902654e6f09 upstream.
    
    OOB read memory can be written to a file,
    if DataOffset is 0 and Length is too large
    in SMB2_WRITE request of compound request.
    
    To prevent this, when checking the length of
    the data area of SMB2_WRITE in smb2_get_data_area_len(),
    let the minimum of DataOffset be the size of
    SMB2 header + the size of SMB2_WRITE header.
    
    This bug can lead an oops looking something like:
    
    [  798.008715] BUG: KASAN: slab-out-of-bounds in copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008724] Read of size 252 at addr ffff88800f863e90 by task kworker/0:2/2859
    ...
    [  798.008754] Call Trace:
    [  798.008756]  <TASK>
    [  798.008759]  dump_stack_lvl+0x49/0x5f
    [  798.008764]  print_report.cold+0x5e/0x5cf
    [  798.008768]  ? __filemap_get_folio+0x285/0x6d0
    [  798.008774]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008777]  kasan_report+0xaa/0x120
    [  798.008781]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008784]  kasan_check_range+0x100/0x1e0
    [  798.008788]  memcpy+0x24/0x60
    [  798.008792]  copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008795]  ? pagecache_get_page+0x53/0x160
    [  798.008799]  ? iov_iter_get_pages_alloc+0x1590/0x1590
    [  798.008803]  ? ext4_write_begin+0xfc0/0xfc0
    [  798.008807]  ? current_time+0x72/0x210
    [  798.008811]  generic_perform_write+0x2c8/0x530
    [  798.008816]  ? filemap_fdatawrite_wbc+0x180/0x180
    [  798.008820]  ? down_write+0xb4/0x120
    [  798.008824]  ? down_write_killable+0x130/0x130
    [  798.008829]  ext4_buffered_write_iter+0x137/0x2c0
    [  798.008833]  ext4_file_write_iter+0x40b/0x1490
    [  798.008837]  ? __fsnotify_parent+0x275/0xb20
    [  798.008842]  ? __fsnotify_update_child_dentry_flags+0x2c0/0x2c0
    [  798.008846]  ? ext4_buffered_write_iter+0x2c0/0x2c0
    [  798.008851]  __kernel_write+0x3a1/0xa70
    [  798.008855]  ? __x64_sys_preadv2+0x160/0x160
    [  798.008860]  ? security_file_permission+0x4a/0xa0
    [  798.008865]  kernel_write+0xbb/0x360
    [  798.008869]  ksmbd_vfs_write+0x27e/0xb90 [ksmbd]
    [  798.008881]  ? ksmbd_vfs_read+0x830/0x830 [ksmbd]
    [  798.008892]  ? _raw_read_unlock+0x2a/0x50
    [  798.008896]  smb2_write+0xb45/0x14e0 [ksmbd]
    [  798.008909]  ? __kasan_check_write+0x14/0x20
    [  798.008912]  ? _raw_spin_lock_bh+0xd0/0xe0
    [  798.008916]  ? smb2_read+0x15e0/0x15e0 [ksmbd]
    [  798.008927]  ? memcpy+0x4e/0x60
    [  798.008931]  ? _raw_spin_unlock+0x19/0x30
    [  798.008934]  ? ksmbd_smb2_check_message+0x16af/0x2350 [ksmbd]
    [  798.008946]  ? _raw_spin_lock_bh+0xe0/0xe0
    [  798.008950]  handle_ksmbd_work+0x30e/0x1020 [ksmbd]
    [  798.008962]  process_one_work+0x778/0x11c0
    [  798.008966]  ? _raw_spin_lock_irq+0x8e/0xe0
    [  798.008970]  worker_thread+0x544/0x1180
    [  798.008973]  ? __cpuidle_text_end+0x4/0x4
    [  798.008977]  kthread+0x282/0x320
    [  798.008982]  ? process_one_work+0x11c0/0x11c0
    [  798.008985]  ? kthread_complete_and_exit+0x30/0x30
    [  798.008989]  ret_from_fork+0x1f/0x30
    [  798.008995]  </TASK>
    
    Fixes: e2f34481b24d ("cifsd: add server-side procedures for SMB3")
    Cc: stable@vger.kernel.org
    Reported-by: zdi-disclosures@trendmicro.com # ZDI-CAN-17817
    Signed-off-by: Hyunchul Lee <hyc.lee@gmail.com>
    Acked-by: Namjae Jeon <linkinjeon@kernel.org>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d3015b3bf4a3a0c5e04edcf8bb941146ce9206fd
Author: Hyunchul Lee <hyc.lee@gmail.com>
Date:   Thu Jul 28 23:41:51 2022 +0900

    ksmbd: prevent out of bound read for SMB2_WRITE
    
    [ Upstream commit ac60778b87e45576d7bfdbd6f53df902654e6f09 ]
    
    OOB read memory can be written to a file,
    if DataOffset is 0 and Length is too large
    in SMB2_WRITE request of compound request.
    
    To prevent this, when checking the length of
    the data area of SMB2_WRITE in smb2_get_data_area_len(),
    let the minimum of DataOffset be the size of
    SMB2 header + the size of SMB2_WRITE header.
    
    This bug can lead an oops looking something like:
    
    [  798.008715] BUG: KASAN: slab-out-of-bounds in copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008724] Read of size 252 at addr ffff88800f863e90 by task kworker/0:2/2859
    ...
    [  798.008754] Call Trace:
    [  798.008756]  <TASK>
    [  798.008759]  dump_stack_lvl+0x49/0x5f
    [  798.008764]  print_report.cold+0x5e/0x5cf
    [  798.008768]  ? __filemap_get_folio+0x285/0x6d0
    [  798.008774]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008777]  kasan_report+0xaa/0x120
    [  798.008781]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008784]  kasan_check_range+0x100/0x1e0
    [  798.008788]  memcpy+0x24/0x60
    [  798.008792]  copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008795]  ? pagecache_get_page+0x53/0x160
    [  798.008799]  ? iov_iter_get_pages_alloc+0x1590/0x1590
    [  798.008803]  ? ext4_write_begin+0xfc0/0xfc0
    [  798.008807]  ? current_time+0x72/0x210
    [  798.008811]  generic_perform_write+0x2c8/0x530
    [  798.008816]  ? filemap_fdatawrite_wbc+0x180/0x180
    [  798.008820]  ? down_write+0xb4/0x120
    [  798.008824]  ? down_write_killable+0x130/0x130
    [  798.008829]  ext4_buffered_write_iter+0x137/0x2c0
    [  798.008833]  ext4_file_write_iter+0x40b/0x1490
    [  798.008837]  ? __fsnotify_parent+0x275/0xb20
    [  798.008842]  ? __fsnotify_update_child_dentry_flags+0x2c0/0x2c0
    [  798.008846]  ? ext4_buffered_write_iter+0x2c0/0x2c0
    [  798.008851]  __kernel_write+0x3a1/0xa70
    [  798.008855]  ? __x64_sys_preadv2+0x160/0x160
    [  798.008860]  ? security_file_permission+0x4a/0xa0
    [  798.008865]  kernel_write+0xbb/0x360
    [  798.008869]  ksmbd_vfs_write+0x27e/0xb90 [ksmbd]
    [  798.008881]  ? ksmbd_vfs_read+0x830/0x830 [ksmbd]
    [  798.008892]  ? _raw_read_unlock+0x2a/0x50
    [  798.008896]  smb2_write+0xb45/0x14e0 [ksmbd]
    [  798.008909]  ? __kasan_check_write+0x14/0x20
    [  798.008912]  ? _raw_spin_lock_bh+0xd0/0xe0
    [  798.008916]  ? smb2_read+0x15e0/0x15e0 [ksmbd]
    [  798.008927]  ? memcpy+0x4e/0x60
    [  798.008931]  ? _raw_spin_unlock+0x19/0x30
    [  798.008934]  ? ksmbd_smb2_check_message+0x16af/0x2350 [ksmbd]
    [  798.008946]  ? _raw_spin_lock_bh+0xe0/0xe0
    [  798.008950]  handle_ksmbd_work+0x30e/0x1020 [ksmbd]
    [  798.008962]  process_one_work+0x778/0x11c0
    [  798.008966]  ? _raw_spin_lock_irq+0x8e/0xe0
    [  798.008970]  worker_thread+0x544/0x1180
    [  798.008973]  ? __cpuidle_text_end+0x4/0x4
    [  798.008977]  kthread+0x282/0x320
    [  798.008982]  ? process_one_work+0x11c0/0x11c0
    [  798.008985]  ? kthread_complete_and_exit+0x30/0x30
    [  798.008989]  ret_from_fork+0x1f/0x30
    [  798.008995]  </TASK>
    
    Fixes: e2f34481b24d ("cifsd: add server-side procedures for SMB3")
    Cc: stable@vger.kernel.org
    Reported-by: zdi-disclosures@trendmicro.com # ZDI-CAN-17817
    Signed-off-by: Hyunchul Lee <hyc.lee@gmail.com>
    Acked-by: Namjae Jeon <linkinjeon@kernel.org>
    Signed-off-by: Steve French <stfrench@microsoft.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6cb4b96df97082a54634ba02196516919cda228c
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Sat Jul 9 08:18:40 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    [ Upstream commit f7b12a62f008a3041f42f2426983e59a6a0a3c59 ]
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c7d87c3080e17b6f21db4d14fcc4adaa8c66d1c3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 4 17:26:29 2022 -0400

    __follow_mount_rcu(): verify that mount_lock remains unchanged
    
    commit 20aac6c60981f5bfacd66661d090d907bf1482f0 upstream.
    
    Validate mount_lock seqcount as soon as we cross into mount in RCU
    mode.  Sure, ->mnt_root is pinned and will remain so until we
    do rcu_read_unlock() anyway, and we will eventually fail to unlazy if
    the mount_lock had been touched, but we might run into a hard error
    (e.g. -ENOENT) before trying to unlazy.  And it's possible to end
    up with RCU pathwalk racing with rename() and umount() in a way
    that would fail with -ENOENT while non-RCU pathwalk would've
    succeeded with any timings.
    
    Once upon a time we hadn't needed that, but analysis had been subtle,
    brittle and went out of window as soon as RENAME_EXCHANGE had been
    added.
    
    It's narrow, hard to hit and won't get you anything other than
    stray -ENOENT that could be arranged in much easier way with the
    same priveleges, but it's a bug all the same.
    
    Cc: stable@kernel.org
    X-sky-is-falling: unlikely
    Fixes: da1ce0670c14 "vfs: add cross-rename"
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 75e1ce13ed632c7a3814cbf6bd41119a31e1c120
Author: Zhang Yi <yi.zhang@huawei.com>
Date:   Sat Jun 11 21:04:26 2022 +0800

    jbd2: fix outstanding credits assert in jbd2_journal_commit_transaction()
    
    [ Upstream commit a89573ce4ad32f19f43ec669771726817e185be0 ]
    
    We catch an assert problem in jbd2_journal_commit_transaction() when
    doing fsstress and request falut injection tests. The problem is
    happened in a race condition between jbd2_journal_commit_transaction()
    and ext4_end_io_end(). Firstly, ext4_writepages() writeback dirty pages
    and start reserved handle, and then the journal was aborted due to some
    previous metadata IO error, jbd2_journal_abort() start to commit current
    running transaction, the committing procedure could be raced by
    ext4_end_io_end() and lead to subtract j_reserved_credits twice from
    commit_transaction->t_outstanding_credits, finally the
    t_outstanding_credits is mistakenly smaller than t_nr_buffers and
    trigger assert.
    
    kjournald2           kworker
    
    jbd2_journal_commit_transaction()
     write_unlock(&journal->j_state_lock);
     atomic_sub(j_reserved_credits, t_outstanding_credits); //sub once
    
                         jbd2_journal_start_reserved()
                          start_this_handle()  //detect aborted journal
                          jbd2_journal_free_reserved()  //get running transaction
                           read_lock(&journal->j_state_lock)
                            __jbd2_journal_unreserve_handle()
                           atomic_sub(j_reserved_credits, t_outstanding_credits);
                           //sub again
                           read_unlock(&journal->j_state_lock);
    
     journal->j_running_transaction = NULL;
     J_ASSERT(t_nr_buffers <= t_outstanding_credits) //bomb!!!
    
    Fix this issue by using journal->j_state_lock to protect the subtraction
    in jbd2_journal_commit_transaction().
    
    Fixes: 96f1e0974575 ("jbd2: avoid long hold times of j_state_lock while committing a transaction")
    Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Link: https://lore.kernel.org/r/20220611130426.2013258-1-yi.zhang@huawei.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8cbc36e7e37a9554602fdfd53bed51d411430c6b
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 4 17:26:29 2022 -0400

    __follow_mount_rcu(): verify that mount_lock remains unchanged
    
    commit 20aac6c60981f5bfacd66661d090d907bf1482f0 upstream.
    
    Validate mount_lock seqcount as soon as we cross into mount in RCU
    mode.  Sure, ->mnt_root is pinned and will remain so until we
    do rcu_read_unlock() anyway, and we will eventually fail to unlazy if
    the mount_lock had been touched, but we might run into a hard error
    (e.g. -ENOENT) before trying to unlazy.  And it's possible to end
    up with RCU pathwalk racing with rename() and umount() in a way
    that would fail with -ENOENT while non-RCU pathwalk would've
    succeeded with any timings.
    
    Once upon a time we hadn't needed that, but analysis had been subtle,
    brittle and went out of window as soon as RENAME_EXCHANGE had been
    added.
    
    It's narrow, hard to hit and won't get you anything other than
    stray -ENOENT that could be arranged in much easier way with the
    same priveleges, but it's a bug all the same.
    
    Cc: stable@kernel.org
    X-sky-is-falling: unlikely
    Fixes: da1ce0670c14 "vfs: add cross-rename"
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b0e1268a8efd48d887e1f1555dd8ee738e3b5ab5
Author: Zhang Yi <yi.zhang@huawei.com>
Date:   Sat Jun 11 21:04:26 2022 +0800

    jbd2: fix outstanding credits assert in jbd2_journal_commit_transaction()
    
    [ Upstream commit a89573ce4ad32f19f43ec669771726817e185be0 ]
    
    We catch an assert problem in jbd2_journal_commit_transaction() when
    doing fsstress and request falut injection tests. The problem is
    happened in a race condition between jbd2_journal_commit_transaction()
    and ext4_end_io_end(). Firstly, ext4_writepages() writeback dirty pages
    and start reserved handle, and then the journal was aborted due to some
    previous metadata IO error, jbd2_journal_abort() start to commit current
    running transaction, the committing procedure could be raced by
    ext4_end_io_end() and lead to subtract j_reserved_credits twice from
    commit_transaction->t_outstanding_credits, finally the
    t_outstanding_credits is mistakenly smaller than t_nr_buffers and
    trigger assert.
    
    kjournald2           kworker
    
    jbd2_journal_commit_transaction()
     write_unlock(&journal->j_state_lock);
     atomic_sub(j_reserved_credits, t_outstanding_credits); //sub once
    
                         jbd2_journal_start_reserved()
                          start_this_handle()  //detect aborted journal
                          jbd2_journal_free_reserved()  //get running transaction
                           read_lock(&journal->j_state_lock)
                            __jbd2_journal_unreserve_handle()
                           atomic_sub(j_reserved_credits, t_outstanding_credits);
                           //sub again
                           read_unlock(&journal->j_state_lock);
    
     journal->j_running_transaction = NULL;
     J_ASSERT(t_nr_buffers <= t_outstanding_credits) //bomb!!!
    
    Fix this issue by using journal->j_state_lock to protect the subtraction
    in jbd2_journal_commit_transaction().
    
    Fixes: 96f1e0974575 ("jbd2: avoid long hold times of j_state_lock while committing a transaction")
    Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Link: https://lore.kernel.org/r/20220611130426.2013258-1-yi.zhang@huawei.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d9395512c5bd326924ba0b36ee0d5d51d763a8d6
Merge: f00654007fe1 3bd8bc897161
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Aug 3 11:31:42 2022 -0700

    Merge tag 'pull-work.namei' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs
    
    Pull vfs namei updates from Al Viro:
     "RCU pathwalk cleanups.
    
      Storing sampled ->d_seq of the next dentry in nameidata simplifies
      life considerably, especially if we delay fetching ->d_inode until
      step_into()"
    
    * tag 'pull-work.namei' of git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs:
      step_into(): move fetching ->d_inode past handle_mounts()
      lookup_fast(): don't bother with inode
      follow_dotdot{,_rcu}(): don't bother with inode
      step_into(): lose inode argument
      namei: stash the sampled ->d_seq into nameidata
      namei: move clearing LOOKUP_RCU towards rcu_read_unlock()
      switch try_to_unlazy_next() to __legitimize_mnt()
      follow_dotdot{,_rcu}(): change calling conventions
      namei: get rid of pointless unlikely(read_seqcount_retry(...))
      __follow_mount_rcu(): verify that mount_lock remains unchanged

commit a89573ce4ad32f19f43ec669771726817e185be0
Author: Zhang Yi <yi.zhang@huawei.com>
Date:   Sat Jun 11 21:04:26 2022 +0800

    jbd2: fix outstanding credits assert in jbd2_journal_commit_transaction()
    
    We catch an assert problem in jbd2_journal_commit_transaction() when
    doing fsstress and request falut injection tests. The problem is
    happened in a race condition between jbd2_journal_commit_transaction()
    and ext4_end_io_end(). Firstly, ext4_writepages() writeback dirty pages
    and start reserved handle, and then the journal was aborted due to some
    previous metadata IO error, jbd2_journal_abort() start to commit current
    running transaction, the committing procedure could be raced by
    ext4_end_io_end() and lead to subtract j_reserved_credits twice from
    commit_transaction->t_outstanding_credits, finally the
    t_outstanding_credits is mistakenly smaller than t_nr_buffers and
    trigger assert.
    
    kjournald2           kworker
    
    jbd2_journal_commit_transaction()
     write_unlock(&journal->j_state_lock);
     atomic_sub(j_reserved_credits, t_outstanding_credits); //sub once
    
                         jbd2_journal_start_reserved()
                          start_this_handle()  //detect aborted journal
                          jbd2_journal_free_reserved()  //get running transaction
                           read_lock(&journal->j_state_lock)
                            __jbd2_journal_unreserve_handle()
                           atomic_sub(j_reserved_credits, t_outstanding_credits);
                           //sub again
                           read_unlock(&journal->j_state_lock);
    
     journal->j_running_transaction = NULL;
     J_ASSERT(t_nr_buffers <= t_outstanding_credits) //bomb!!!
    
    Fix this issue by using journal->j_state_lock to protect the subtraction
    in jbd2_journal_commit_transaction().
    
    Fixes: 96f1e0974575 ("jbd2: avoid long hold times of j_state_lock while committing a transaction")
    Signed-off-by: Zhang Yi <yi.zhang@huawei.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Link: https://lore.kernel.org/r/20220611130426.2013258-1-yi.zhang@huawei.com
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>

commit ac60778b87e45576d7bfdbd6f53df902654e6f09
Author: Hyunchul Lee <hyc.lee@gmail.com>
Date:   Thu Jul 28 23:41:51 2022 +0900

    ksmbd: prevent out of bound read for SMB2_WRITE
    
    OOB read memory can be written to a file,
    if DataOffset is 0 and Length is too large
    in SMB2_WRITE request of compound request.
    
    To prevent this, when checking the length of
    the data area of SMB2_WRITE in smb2_get_data_area_len(),
    let the minimum of DataOffset be the size of
    SMB2 header + the size of SMB2_WRITE header.
    
    This bug can lead an oops looking something like:
    
    [  798.008715] BUG: KASAN: slab-out-of-bounds in copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008724] Read of size 252 at addr ffff88800f863e90 by task kworker/0:2/2859
    ...
    [  798.008754] Call Trace:
    [  798.008756]  <TASK>
    [  798.008759]  dump_stack_lvl+0x49/0x5f
    [  798.008764]  print_report.cold+0x5e/0x5cf
    [  798.008768]  ? __filemap_get_folio+0x285/0x6d0
    [  798.008774]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008777]  kasan_report+0xaa/0x120
    [  798.008781]  ? copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008784]  kasan_check_range+0x100/0x1e0
    [  798.008788]  memcpy+0x24/0x60
    [  798.008792]  copy_page_from_iter_atomic+0xd3d/0x14b0
    [  798.008795]  ? pagecache_get_page+0x53/0x160
    [  798.008799]  ? iov_iter_get_pages_alloc+0x1590/0x1590
    [  798.008803]  ? ext4_write_begin+0xfc0/0xfc0
    [  798.008807]  ? current_time+0x72/0x210
    [  798.008811]  generic_perform_write+0x2c8/0x530
    [  798.008816]  ? filemap_fdatawrite_wbc+0x180/0x180
    [  798.008820]  ? down_write+0xb4/0x120
    [  798.008824]  ? down_write_killable+0x130/0x130
    [  798.008829]  ext4_buffered_write_iter+0x137/0x2c0
    [  798.008833]  ext4_file_write_iter+0x40b/0x1490
    [  798.008837]  ? __fsnotify_parent+0x275/0xb20
    [  798.008842]  ? __fsnotify_update_child_dentry_flags+0x2c0/0x2c0
    [  798.008846]  ? ext4_buffered_write_iter+0x2c0/0x2c0
    [  798.008851]  __kernel_write+0x3a1/0xa70
    [  798.008855]  ? __x64_sys_preadv2+0x160/0x160
    [  798.008860]  ? security_file_permission+0x4a/0xa0
    [  798.008865]  kernel_write+0xbb/0x360
    [  798.008869]  ksmbd_vfs_write+0x27e/0xb90 [ksmbd]
    [  798.008881]  ? ksmbd_vfs_read+0x830/0x830 [ksmbd]
    [  798.008892]  ? _raw_read_unlock+0x2a/0x50
    [  798.008896]  smb2_write+0xb45/0x14e0 [ksmbd]
    [  798.008909]  ? __kasan_check_write+0x14/0x20
    [  798.008912]  ? _raw_spin_lock_bh+0xd0/0xe0
    [  798.008916]  ? smb2_read+0x15e0/0x15e0 [ksmbd]
    [  798.008927]  ? memcpy+0x4e/0x60
    [  798.008931]  ? _raw_spin_unlock+0x19/0x30
    [  798.008934]  ? ksmbd_smb2_check_message+0x16af/0x2350 [ksmbd]
    [  798.008946]  ? _raw_spin_lock_bh+0xe0/0xe0
    [  798.008950]  handle_ksmbd_work+0x30e/0x1020 [ksmbd]
    [  798.008962]  process_one_work+0x778/0x11c0
    [  798.008966]  ? _raw_spin_lock_irq+0x8e/0xe0
    [  798.008970]  worker_thread+0x544/0x1180
    [  798.008973]  ? __cpuidle_text_end+0x4/0x4
    [  798.008977]  kthread+0x282/0x320
    [  798.008982]  ? process_one_work+0x11c0/0x11c0
    [  798.008985]  ? kthread_complete_and_exit+0x30/0x30
    [  798.008989]  ret_from_fork+0x1f/0x30
    [  798.008995]  </TASK>
    
    Fixes: e2f34481b24d ("cifsd: add server-side procedures for SMB3")
    Cc: stable@vger.kernel.org
    Reported-by: zdi-disclosures@trendmicro.com # ZDI-CAN-17817
    Signed-off-by: Hyunchul Lee <hyc.lee@gmail.com>
    Acked-by: Namjae Jeon <linkinjeon@kernel.org>
    Signed-off-by: Steve French <stfrench@microsoft.com>

commit a7e555d4a184d7da72ed6df7d6741dc190b5ca5b
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Jul 25 13:05:54 2022 -0700

    ip6mr: remove stray rcu_read_unlock() from ip6_mr_forward()
    
    One rcu_read_unlock() should have been removed in blamed commit.
    
    Fixes: 9b1c21d898fd ("ip6mr: do not acquire mrt_lock while calling ip6_mr_forward()")
    Reported-by: Vladimir Oltean <olteanv@gmail.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reviewed-by: Vladimir Oltean <olteanv@gmail.com>
    Link: https://lore.kernel.org/r/20220725200554.2563581-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit f7b12a62f008a3041f42f2426983e59a6a0a3c59
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Sat Jul 9 08:18:40 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit 61aee772ebab2a0e9ba79b7ad9891260408fde72
Merge: 502c6f8cedcc 84b9cd389036
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Jul 25 10:38:58 2022 +0100

    Merge branch 'mtk_eth_soc-xdp'
    
    Lorenzo Bianconi says:
    
    ====================
    mtk_eth_soc: add xdp support
    
    Introduce XDP support for mtk_eth_soc driver if rx hwlro is not
    enabled in the chipset (e.g. mt7986).
    Supported XDP verdicts:
    - XDP_PASS
    - XDP_DROP
    - XDP_REDIRECT
    - XDP_TX
    - ndo_xdp_xmit
    Rely on page_pool allocator for single page buffers in order to keep
    them dma mapped and add skb recycling support.
    
    Changes since v3:
    - add missing rcu_read_lock()/rcu_read_unlock()
    - introduce mtk_page_pool_enabled() utility routine
    
    Changes since v2:
    - fix leftover sparse warning
    - add page_pool ethtool stats
    
    Changes since v1:
    - do not allocate mtk_xdp_stats array on the stack in mtk_rx_poll
    - add rcu annotation to bpf program
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6e180327153071281dbbf6a16759e49862debdca
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed Jul 6 12:40:31 2022 -0400

    namei: move clearing LOOKUP_RCU towards rcu_read_unlock()
    
    try_to_unlazy()/try_to_unlazy_next() drop LOOKUP_RCU in the
    very beginning and do rcu_read_unlock() only at the very end.
    However, nothing done in between even looks at the flag in
    question; might as well clear it at the same time we unlock.
    
    Note that try_to_unlazy_next() used to call legitimize_mnt(),
    which might drop/regain rcu_read_lock() in some cases.  This
    is no longer true, so we really have rcu_read_lock() held
    all along until the end.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 20aac6c60981f5bfacd66661d090d907bf1482f0
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Jul 4 17:26:29 2022 -0400

    __follow_mount_rcu(): verify that mount_lock remains unchanged
    
    Validate mount_lock seqcount as soon as we cross into mount in RCU
    mode.  Sure, ->mnt_root is pinned and will remain so until we
    do rcu_read_unlock() anyway, and we will eventually fail to unlazy if
    the mount_lock had been touched, but we might run into a hard error
    (e.g. -ENOENT) before trying to unlazy.  And it's possible to end
    up with RCU pathwalk racing with rename() and umount() in a way
    that would fail with -ENOENT while non-RCU pathwalk would've
    succeeded with any timings.
    
    Once upon a time we hadn't needed that, but analysis had been subtle,
    brittle and went out of window as soon as RENAME_EXCHANGE had been
    added.
    
    It's narrow, hard to hit and won't get you anything other than
    stray -ENOENT that could be arranged in much easier way with the
    same priveleges, but it's a bug all the same.
    
    Cc: stable@kernel.org
    X-sky-is-falling: unlikely
    Fixes: da1ce0670c14 "vfs: add cross-rename"
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 9fadb11f1295289e0da4d3342ecb6b92c1c99540
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed May 18 10:41:48 2022 +0100

    btrfs: fix hang during unmount when block group reclaim task is running
    
    commit 31e70e527806c546a72262f2fc3d982ee23c42d3 upstream.
    
    When we start an unmount, at close_ctree(), if we have the reclaim task
    running and in the middle of a data block group relocation, we can trigger
    a deadlock when stopping an async reclaim task, producing a trace like the
    following:
    
    [629724.498185] task:kworker/u16:7   state:D stack:    0 pid:681170 ppid:     2 flags:0x00004000
    [629724.499760] Workqueue: events_unbound btrfs_async_reclaim_metadata_space [btrfs]
    [629724.501267] Call Trace:
    [629724.501759]  <TASK>
    [629724.502174]  __schedule+0x3cb/0xed0
    [629724.502842]  schedule+0x4e/0xb0
    [629724.503447]  btrfs_wait_on_delayed_iputs+0x7c/0xc0 [btrfs]
    [629724.504534]  ? prepare_to_wait_exclusive+0xc0/0xc0
    [629724.505442]  flush_space+0x423/0x630 [btrfs]
    [629724.506296]  ? rcu_read_unlock_trace_special+0x20/0x50
    [629724.507259]  ? lock_release+0x220/0x4a0
    [629724.507932]  ? btrfs_get_alloc_profile+0xb3/0x290 [btrfs]
    [629724.508940]  ? do_raw_spin_unlock+0x4b/0xa0
    [629724.509688]  btrfs_async_reclaim_metadata_space+0x139/0x320 [btrfs]
    [629724.510922]  process_one_work+0x252/0x5a0
    [629724.511694]  ? process_one_work+0x5a0/0x5a0
    [629724.512508]  worker_thread+0x52/0x3b0
    [629724.513220]  ? process_one_work+0x5a0/0x5a0
    [629724.514021]  kthread+0xf2/0x120
    [629724.514627]  ? kthread_complete_and_exit+0x20/0x20
    [629724.515526]  ret_from_fork+0x22/0x30
    [629724.516236]  </TASK>
    [629724.516694] task:umount          state:D stack:    0 pid:719055 ppid:695412 flags:0x00004000
    [629724.518269] Call Trace:
    [629724.518746]  <TASK>
    [629724.519160]  __schedule+0x3cb/0xed0
    [629724.519835]  schedule+0x4e/0xb0
    [629724.520467]  schedule_timeout+0xed/0x130
    [629724.521221]  ? lock_release+0x220/0x4a0
    [629724.521946]  ? lock_acquired+0x19c/0x420
    [629724.522662]  ? trace_hardirqs_on+0x1b/0xe0
    [629724.523411]  __wait_for_common+0xaf/0x1f0
    [629724.524189]  ? usleep_range_state+0xb0/0xb0
    [629724.524997]  __flush_work+0x26d/0x530
    [629724.525698]  ? flush_workqueue_prep_pwqs+0x140/0x140
    [629724.526580]  ? lock_acquire+0x1a0/0x310
    [629724.527324]  __cancel_work_timer+0x137/0x1c0
    [629724.528190]  close_ctree+0xfd/0x531 [btrfs]
    [629724.529000]  ? evict_inodes+0x166/0x1c0
    [629724.529510]  generic_shutdown_super+0x74/0x120
    [629724.530103]  kill_anon_super+0x14/0x30
    [629724.530611]  btrfs_kill_super+0x12/0x20 [btrfs]
    [629724.531246]  deactivate_locked_super+0x31/0xa0
    [629724.531817]  cleanup_mnt+0x147/0x1c0
    [629724.532319]  task_work_run+0x5c/0xa0
    [629724.532984]  exit_to_user_mode_prepare+0x1a6/0x1b0
    [629724.533598]  syscall_exit_to_user_mode+0x16/0x40
    [629724.534200]  do_syscall_64+0x48/0x90
    [629724.534667]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [629724.535318] RIP: 0033:0x7fa2b90437a7
    [629724.535804] RSP: 002b:00007ffe0b7e4458 EFLAGS: 00000246 ORIG_RAX: 00000000000000a6
    [629724.536912] RAX: 0000000000000000 RBX: 00007fa2b9182264 RCX: 00007fa2b90437a7
    [629724.538156] RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000555d6cf20dd0
    [629724.539053] RBP: 0000555d6cf20ba0 R08: 0000000000000000 R09: 00007ffe0b7e3200
    [629724.539956] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000
    [629724.540883] R13: 0000555d6cf20dd0 R14: 0000555d6cf20cb0 R15: 0000000000000000
    [629724.541796]  </TASK>
    
    This happens because:
    
    1) Before entering close_ctree() we have the async block group reclaim
       task running and relocating a data block group;
    
    2) There's an async metadata (or data) space reclaim task running;
    
    3) We enter close_ctree() and park the cleaner kthread;
    
    4) The async space reclaim task is at flush_space() and runs all the
       existing delayed iputs;
    
    5) Before the async space reclaim task calls
       btrfs_wait_on_delayed_iputs(), the block group reclaim task which is
       doing the data block group relocation, creates a delayed iput at
       replace_file_extents() (called when COWing leaves that have file extent
       items pointing to relocated data extents, during the merging phase
       of relocation roots);
    
    6) The async reclaim space reclaim task blocks at
       btrfs_wait_on_delayed_iputs(), since we have a new delayed iput;
    
    7) The task at close_ctree() then calls cancel_work_sync() to stop the
       async space reclaim task, but it blocks since that task is waiting for
       the delayed iput to be run;
    
    8) The delayed iput is never run because the cleaner kthread is parked,
       and no one else runs delayed iputs, resulting in a hang.
    
    So fix this by stopping the async block group reclaim task before we
    park the cleaner kthread.
    
    Fixes: 18bb8bbf13c183 ("btrfs: zoned: automatically reclaim zones")
    CC: stable@vger.kernel.org # 5.15+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 341d33128a940c6634175dcb6ca92dc454cfa7d2
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed May 18 10:41:48 2022 +0100

    btrfs: fix hang during unmount when block group reclaim task is running
    
    commit 31e70e527806c546a72262f2fc3d982ee23c42d3 upstream.
    
    When we start an unmount, at close_ctree(), if we have the reclaim task
    running and in the middle of a data block group relocation, we can trigger
    a deadlock when stopping an async reclaim task, producing a trace like the
    following:
    
    [629724.498185] task:kworker/u16:7   state:D stack:    0 pid:681170 ppid:     2 flags:0x00004000
    [629724.499760] Workqueue: events_unbound btrfs_async_reclaim_metadata_space [btrfs]
    [629724.501267] Call Trace:
    [629724.501759]  <TASK>
    [629724.502174]  __schedule+0x3cb/0xed0
    [629724.502842]  schedule+0x4e/0xb0
    [629724.503447]  btrfs_wait_on_delayed_iputs+0x7c/0xc0 [btrfs]
    [629724.504534]  ? prepare_to_wait_exclusive+0xc0/0xc0
    [629724.505442]  flush_space+0x423/0x630 [btrfs]
    [629724.506296]  ? rcu_read_unlock_trace_special+0x20/0x50
    [629724.507259]  ? lock_release+0x220/0x4a0
    [629724.507932]  ? btrfs_get_alloc_profile+0xb3/0x290 [btrfs]
    [629724.508940]  ? do_raw_spin_unlock+0x4b/0xa0
    [629724.509688]  btrfs_async_reclaim_metadata_space+0x139/0x320 [btrfs]
    [629724.510922]  process_one_work+0x252/0x5a0
    [629724.511694]  ? process_one_work+0x5a0/0x5a0
    [629724.512508]  worker_thread+0x52/0x3b0
    [629724.513220]  ? process_one_work+0x5a0/0x5a0
    [629724.514021]  kthread+0xf2/0x120
    [629724.514627]  ? kthread_complete_and_exit+0x20/0x20
    [629724.515526]  ret_from_fork+0x22/0x30
    [629724.516236]  </TASK>
    [629724.516694] task:umount          state:D stack:    0 pid:719055 ppid:695412 flags:0x00004000
    [629724.518269] Call Trace:
    [629724.518746]  <TASK>
    [629724.519160]  __schedule+0x3cb/0xed0
    [629724.519835]  schedule+0x4e/0xb0
    [629724.520467]  schedule_timeout+0xed/0x130
    [629724.521221]  ? lock_release+0x220/0x4a0
    [629724.521946]  ? lock_acquired+0x19c/0x420
    [629724.522662]  ? trace_hardirqs_on+0x1b/0xe0
    [629724.523411]  __wait_for_common+0xaf/0x1f0
    [629724.524189]  ? usleep_range_state+0xb0/0xb0
    [629724.524997]  __flush_work+0x26d/0x530
    [629724.525698]  ? flush_workqueue_prep_pwqs+0x140/0x140
    [629724.526580]  ? lock_acquire+0x1a0/0x310
    [629724.527324]  __cancel_work_timer+0x137/0x1c0
    [629724.528190]  close_ctree+0xfd/0x531 [btrfs]
    [629724.529000]  ? evict_inodes+0x166/0x1c0
    [629724.529510]  generic_shutdown_super+0x74/0x120
    [629724.530103]  kill_anon_super+0x14/0x30
    [629724.530611]  btrfs_kill_super+0x12/0x20 [btrfs]
    [629724.531246]  deactivate_locked_super+0x31/0xa0
    [629724.531817]  cleanup_mnt+0x147/0x1c0
    [629724.532319]  task_work_run+0x5c/0xa0
    [629724.532984]  exit_to_user_mode_prepare+0x1a6/0x1b0
    [629724.533598]  syscall_exit_to_user_mode+0x16/0x40
    [629724.534200]  do_syscall_64+0x48/0x90
    [629724.534667]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [629724.535318] RIP: 0033:0x7fa2b90437a7
    [629724.535804] RSP: 002b:00007ffe0b7e4458 EFLAGS: 00000246 ORIG_RAX: 00000000000000a6
    [629724.536912] RAX: 0000000000000000 RBX: 00007fa2b9182264 RCX: 00007fa2b90437a7
    [629724.538156] RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000555d6cf20dd0
    [629724.539053] RBP: 0000555d6cf20ba0 R08: 0000000000000000 R09: 00007ffe0b7e3200
    [629724.539956] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000
    [629724.540883] R13: 0000555d6cf20dd0 R14: 0000555d6cf20cb0 R15: 0000000000000000
    [629724.541796]  </TASK>
    
    This happens because:
    
    1) Before entering close_ctree() we have the async block group reclaim
       task running and relocating a data block group;
    
    2) There's an async metadata (or data) space reclaim task running;
    
    3) We enter close_ctree() and park the cleaner kthread;
    
    4) The async space reclaim task is at flush_space() and runs all the
       existing delayed iputs;
    
    5) Before the async space reclaim task calls
       btrfs_wait_on_delayed_iputs(), the block group reclaim task which is
       doing the data block group relocation, creates a delayed iput at
       replace_file_extents() (called when COWing leaves that have file extent
       items pointing to relocated data extents, during the merging phase
       of relocation roots);
    
    6) The async reclaim space reclaim task blocks at
       btrfs_wait_on_delayed_iputs(), since we have a new delayed iput;
    
    7) The task at close_ctree() then calls cancel_work_sync() to stop the
       async space reclaim task, but it blocks since that task is waiting for
       the delayed iput to be run;
    
    8) The delayed iput is never run because the cleaner kthread is parked,
       and no one else runs delayed iputs, resulting in a hang.
    
    So fix this by stopping the async block group reclaim task before we
    park the cleaner kthread.
    
    Fixes: 18bb8bbf13c183 ("btrfs: zoned: automatically reclaim zones")
    CC: stable@vger.kernel.org # 5.15+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e4cd9868e8ec3691e6d94725c8b10edd1ec6eca2
Author: Eric Dumazet <edumazet@google.com>
Date:   Thu Jun 23 04:34:39 2022 +0000

    ipmr: do not acquire mrt_lock in ipmr_get_route()
    
    mr_fill_mroute() uses standard rcu_read_unlock(),
    no need to grab mrt_lock anymore.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 56096ecd5b04148b6d292e3847c23d4a2a454e94
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Jun 7 17:25:03 2022 -0700

    rcu-tasks: Disable and enable CPU hotplug in same function
    
    The rcu_tasks_trace_pregp_step() function invokes cpus_read_lock() to
    disable CPU hotplug, and a later call to the rcu_tasks_trace_postscan()
    function invokes cpus_read_unlock() to re-enable it.  This was absolutely
    necessary in the past in order to protect the intervening scan of the full
    tasks list, but there is no longer such a scan.  This commit therefore
    improves readability by moving the cpus_read_unlock() call to the end
    of the rcu_tasks_trace_pregp_step() function.  This commit is a pure
    code-motion commit without any (intended) change in functionality.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Cc: Neeraj Upadhyay <quic_neeraju@quicinc.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andrii Nakryiko <andrii@kernel.org>
    Cc: Martin KaFai Lau <kafai@fb.com>
    Cc: KP Singh <kpsingh@kernel.org>

commit 0bcb386857376224b5fd3f38b6e3173ec74d8d36
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue May 17 15:01:14 2022 -0700

    rcu-tasks: Untrack blocked RCU Tasks Trace at reader end
    
    This commit causes rcu_read_unlock_trace() to check for the current
    task being on a per-CPU list within the rcu_tasks_percpu structure,
    and removes it from that list if so.  This has the effect of curtailing
    tracking of a task that blocked within an RCU Tasks Trace read-side
    critical section once it exits that critical section.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Cc: Neeraj Upadhyay <quic_neeraju@quicinc.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andrii Nakryiko <andrii@kernel.org>
    Cc: Martin KaFai Lau <kafai@fb.com>
    Cc: KP Singh <kpsingh@kernel.org>

commit 0968e8920b5b11b7a33982890ad9150e09e1cb1f
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue May 31 21:38:15 2022 -0700

    rcu-tasks: Simplify trc_inspect_reader() QS logic
    
    Currently, trc_inspect_reader() does one check for nesting less than
    or equal to zero, then sorts out the distinctions within this single
    "if" statement.  This commit simplifies the logic by providing one
    "if" statement for quiescent states (nesting of zero) and another "if"
    statement for transitioning from one nesting level to another or the
    outermost rcu_read_unlock_trace() (negative nesting).
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Cc: Neeraj Upadhyay <quic_neeraju@quicinc.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andrii Nakryiko <andrii@kernel.org>
    Cc: Martin KaFai Lau <kafai@fb.com>
    Cc: KP Singh <kpsingh@kernel.org>

commit 550611269b153dc17b44fa2d692c30f628d1c65c
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed May 25 13:37:36 2022 -0700

    rcu-tasks: Remove rcu_tasks_trace_postgp() wait for counter
    
    Now that tasks are not removed from the list until they have responded to
    any needed request for a quiescent state, it is no longer necessary to
    wait for the trc_n_readers_need_end counter to go to zero.  This commit
    therefore removes that waiting code.
    
    It is therefore also no longer necessary for rcu_tasks_trace_postgp() to
    do the final decrement of this counter, so that code is also removed.
    This in turn means that trc_n_readers_need_end counter itself can
    be removed, as can the rcu_tasks_trace_iw irq_work structure and the
    rcu_read_unlock_iw() function.
    
    [ paulmck: Apply feedback from Zqiang. ]
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Cc: Neeraj Upadhyay <quic_neeraju@quicinc.com>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Alexei Starovoitov <ast@kernel.org>
    Cc: Andrii Nakryiko <andrii@kernel.org>
    Cc: Martin KaFai Lau <kafai@fb.com>
    Cc: KP Singh <kpsingh@kernel.org>

commit 31e70e527806c546a72262f2fc3d982ee23c42d3
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed May 18 10:41:48 2022 +0100

    btrfs: fix hang during unmount when block group reclaim task is running
    
    When we start an unmount, at close_ctree(), if we have the reclaim task
    running and in the middle of a data block group relocation, we can trigger
    a deadlock when stopping an async reclaim task, producing a trace like the
    following:
    
    [629724.498185] task:kworker/u16:7   state:D stack:    0 pid:681170 ppid:     2 flags:0x00004000
    [629724.499760] Workqueue: events_unbound btrfs_async_reclaim_metadata_space [btrfs]
    [629724.501267] Call Trace:
    [629724.501759]  <TASK>
    [629724.502174]  __schedule+0x3cb/0xed0
    [629724.502842]  schedule+0x4e/0xb0
    [629724.503447]  btrfs_wait_on_delayed_iputs+0x7c/0xc0 [btrfs]
    [629724.504534]  ? prepare_to_wait_exclusive+0xc0/0xc0
    [629724.505442]  flush_space+0x423/0x630 [btrfs]
    [629724.506296]  ? rcu_read_unlock_trace_special+0x20/0x50
    [629724.507259]  ? lock_release+0x220/0x4a0
    [629724.507932]  ? btrfs_get_alloc_profile+0xb3/0x290 [btrfs]
    [629724.508940]  ? do_raw_spin_unlock+0x4b/0xa0
    [629724.509688]  btrfs_async_reclaim_metadata_space+0x139/0x320 [btrfs]
    [629724.510922]  process_one_work+0x252/0x5a0
    [629724.511694]  ? process_one_work+0x5a0/0x5a0
    [629724.512508]  worker_thread+0x52/0x3b0
    [629724.513220]  ? process_one_work+0x5a0/0x5a0
    [629724.514021]  kthread+0xf2/0x120
    [629724.514627]  ? kthread_complete_and_exit+0x20/0x20
    [629724.515526]  ret_from_fork+0x22/0x30
    [629724.516236]  </TASK>
    [629724.516694] task:umount          state:D stack:    0 pid:719055 ppid:695412 flags:0x00004000
    [629724.518269] Call Trace:
    [629724.518746]  <TASK>
    [629724.519160]  __schedule+0x3cb/0xed0
    [629724.519835]  schedule+0x4e/0xb0
    [629724.520467]  schedule_timeout+0xed/0x130
    [629724.521221]  ? lock_release+0x220/0x4a0
    [629724.521946]  ? lock_acquired+0x19c/0x420
    [629724.522662]  ? trace_hardirqs_on+0x1b/0xe0
    [629724.523411]  __wait_for_common+0xaf/0x1f0
    [629724.524189]  ? usleep_range_state+0xb0/0xb0
    [629724.524997]  __flush_work+0x26d/0x530
    [629724.525698]  ? flush_workqueue_prep_pwqs+0x140/0x140
    [629724.526580]  ? lock_acquire+0x1a0/0x310
    [629724.527324]  __cancel_work_timer+0x137/0x1c0
    [629724.528190]  close_ctree+0xfd/0x531 [btrfs]
    [629724.529000]  ? evict_inodes+0x166/0x1c0
    [629724.529510]  generic_shutdown_super+0x74/0x120
    [629724.530103]  kill_anon_super+0x14/0x30
    [629724.530611]  btrfs_kill_super+0x12/0x20 [btrfs]
    [629724.531246]  deactivate_locked_super+0x31/0xa0
    [629724.531817]  cleanup_mnt+0x147/0x1c0
    [629724.532319]  task_work_run+0x5c/0xa0
    [629724.532984]  exit_to_user_mode_prepare+0x1a6/0x1b0
    [629724.533598]  syscall_exit_to_user_mode+0x16/0x40
    [629724.534200]  do_syscall_64+0x48/0x90
    [629724.534667]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [629724.535318] RIP: 0033:0x7fa2b90437a7
    [629724.535804] RSP: 002b:00007ffe0b7e4458 EFLAGS: 00000246 ORIG_RAX: 00000000000000a6
    [629724.536912] RAX: 0000000000000000 RBX: 00007fa2b9182264 RCX: 00007fa2b90437a7
    [629724.538156] RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000555d6cf20dd0
    [629724.539053] RBP: 0000555d6cf20ba0 R08: 0000000000000000 R09: 00007ffe0b7e3200
    [629724.539956] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000
    [629724.540883] R13: 0000555d6cf20dd0 R14: 0000555d6cf20cb0 R15: 0000000000000000
    [629724.541796]  </TASK>
    
    This happens because:
    
    1) Before entering close_ctree() we have the async block group reclaim
       task running and relocating a data block group;
    
    2) There's an async metadata (or data) space reclaim task running;
    
    3) We enter close_ctree() and park the cleaner kthread;
    
    4) The async space reclaim task is at flush_space() and runs all the
       existing delayed iputs;
    
    5) Before the async space reclaim task calls
       btrfs_wait_on_delayed_iputs(), the block group reclaim task which is
       doing the data block group relocation, creates a delayed iput at
       replace_file_extents() (called when COWing leaves that have file extent
       items pointing to relocated data extents, during the merging phase
       of relocation roots);
    
    6) The async reclaim space reclaim task blocks at
       btrfs_wait_on_delayed_iputs(), since we have a new delayed iput;
    
    7) The task at close_ctree() then calls cancel_work_sync() to stop the
       async space reclaim task, but it blocks since that task is waiting for
       the delayed iput to be run;
    
    8) The delayed iput is never run because the cleaner kthread is parked,
       and no one else runs delayed iputs, resulting in a hang.
    
    So fix this by stopping the async block group reclaim task before we
    park the cleaner kthread.
    
    Fixes: 18bb8bbf13c183 ("btrfs: zoned: automatically reclaim zones")
    CC: stable@vger.kernel.org # 5.15+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit 0aa93f54f4341a40b05ec2ac242109e78661d7aa
Author: Vivek Kasireddy <vivek.kasireddy@intel.com>
Date:   Wed May 25 17:19:39 2022 -0700

    drm/i915/tc: Don't default disconnected legacy Type-C ports to TBT mode (v2)
    
    Commit 30e114ef4b16 ("drm/i915/tc: Check for DP-alt, legacy sinks before
    taking PHY ownership") defaults any disconnected Type-C ports to TBT-alt
    mode which presents a problem (which could most likely result in a system
    hang) when userspace forces a modeset on a Type-C port that is wired for
    legacy HDMI. The following warning is seen when Weston forces a modeset
    on a disconnected legacy Type-C port (HDMI) on a TGL based Gigabyte system:
    (https://www.gigabyte.com/Mini-PcBarebone/GB-BSi3-1115G4-rev-10#ov)
    
    Missing case (clock == 173000)
    WARNING: CPU: 1 PID: 438 at drivers/gpu/drm/i915/display/intel_ddi.c:245
    icl_ddi_tc_enable_clock.cold+0x16a/0x1cf [i915]
    CPU: 1 PID: 438 Comm: kworker/u8:3 Tainted: G     U  W   E
    5.18.0-rc5-drm-tip+ #20
    Hardware name: GIGABYTE GB-BSi3-1115G4/GB-BSi3-1115G4, BIOS F9
    10/16/2021
    Workqueue: i915_modeset intel_atomic_commit_work [i915]
    RIP: 0010:icl_ddi_tc_enable_clock.cold+0x16a/0x1cf [i915]
    Code: 74 6c 7f 10 81 fd d0 78 02 00 74 6d 81 fd b0 1e 04 00 74 70 48 63
    d5 48 c7 c6 c0 7b ab c0 48 c7 c7 20 75 ab c0 e8 b8 b5 c1 f0 <0f> 0b 45
    31 ed e9 fb fe ff ff 49 63 d5
     48 c7 c6 80 7b ab c0 48 c7
    RSP: 0018:ffff8882522c78f0 EFLAGS: 00010282
    RAX: 0000000000000000 RBX: 0000000000000003 RCX: 0000000000000000
    RDX: 0000000000000027 RSI: 0000000000000004 RDI: ffffed104a458f10
    RBP: 0000000000011558 R08: ffffffffb078de4e R09: ffff888269ca748b
    R10: ffffed104d394e91 R11: 0000000000000000 R12: ffff888255a318f8
    R13: 0000000000000002 R14: ffff888255a30000 R15: ffff88823ef00348
    FS:  0000000000000000(0000) GS:ffff888269c80000(0000)
    knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007fd7afa42000 CR3: 0000000255c02004 CR4: 00000000007706e0
    PKRU: 55555554
    Call Trace:
    <TASK>
    intel_ddi_pre_enable.cold+0x96/0x5bf [i915]
    intel_encoders_pre_enable+0x10e/0x140 [i915]
    hsw_crtc_enable+0x207/0x99d [i915]
    ? ilk_crtc_enable.cold+0x2a/0x2a [i915]
    ? prepare_to_wait_exclusive+0x120/0x120
    intel_enable_crtc+0x9a/0xf0 [i915]
    skl_commit_modeset_enables+0x466/0x820 [i915]
    ? intel_commit_modeset_enables+0xd0/0xd0 [i915]
    ? intel_mbus_dbox_update+0x1ed/0x250 [i915]
    intel_atomic_commit_tail+0xf2d/0x3040 [i915]
    _raw_spin_lock_irqsave+0x87/0xe0
    _raw_read_unlock_irqrestore+0x40/0x40
    __update_load_avg_cfs_rq+0x70/0x5c0
    __i915_sw_fence_complete+0x85/0x3b0 [i915]
    ? intel_get_crtc_new_encoder+0x190/0x190 [i915]
    ? sysvec_irq_work+0x13/0x90
    ? asm_sysvec_irq_work+0x12/0x20
    ? _raw_spin_lock_irq+0x82/0xd0
    ? read_word_at_a_time+0xe/0x20
    ? process_one_work+0x393/0x690
    process_one_work+0x393/0x690
    worker_thread+0x2b7/0x620
    ? process_one_work+0x690/0x690
    kthread+0x15a/0x190
    ? kthread_complete_and_exit+0x20/0x20
    ret_from_fork+0x1f/0x30
    
    Continuing with the modeset without setting the DDI clock results in
    more warnings and eventually a system hang. This does not seem to
    happen with disconnected legacy or DP-alt DP ports because the clock
    rate defaults to 162000 (which is a valid TBT clock) during the link
    training process. Therefore, to fix this issue, this patch avoids
    setting disconnected Type-C legacy ports to TBT-alt mode which prevents
    the selection of TBT PLL when a modeset is forced.
    
    v2: (Imre)
    - Retain the check for legacy hotplug live status to account for
    incorrect VBTs.
    
    Cc: Imre Deak <imre.deak@intel.com>
    Cc: Jos Roberto de Souza <jose.souza@intel.com>
    Signed-off-by: Vivek Kasireddy <vivek.kasireddy@intel.com>
    Reviewed-by: Imre Deak <imre.deak@intel.com>
    Signed-off-by: Imre Deak <imre.deak@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20220526001939.4031112-2-vivek.kasireddy@intel.com

commit 5fa45f03a66a42bf73583e6e3078e0e5002d491d
Author: Shay Drory <shayd@nvidia.com>
Date:   Wed Mar 9 14:45:58 2022 +0200

    net/mlx5: Initialize flow steering during driver probe
    
    [ Upstream commit b33886971dbc4a86d1ec5369a2aaefc60a7cd72d ]
    
    Currently, software objects of flow steering are created and destroyed
    during reload flow. In case a device is unloaded, the following error
    is printed during grace period:
    
     mlx5_core 0000:00:0b.0: mlx5_fw_fatal_reporter_err_work:690:(pid 95):
        Driver is in error state. Unloading
    
    As a solution to fix use-after-free bugs, where we try to access
    these objects, when reading the value of flow_steering_mode devlink
    param[1], let's split flow steering creation and destruction into two
    routines:
        * init and cleanup: memory, cache, and pools allocation/free.
        * create and destroy: namespaces initialization and cleanup.
    
    While at it, re-order the cleanup function to mirror the init function.
    
    [1]
    Kasan trace:
    
    [  385.119849 ] BUG: KASAN: use-after-free in mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ] Read of size 4 at addr ffff888104b79308 by task bash/291
    [  385.119849 ]
    [  385.119849 ] CPU: 1 PID: 291 Comm: bash Not tainted 5.17.0-rc1+ #2
    [  385.119849 ] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.13.0-2.fc32 04/01/2014
    [  385.119849 ] Call Trace:
    [  385.119849 ]  <TASK>
    [  385.119849 ]  dump_stack_lvl+0x6e/0x91
    [  385.119849 ]  print_address_description.constprop.0+0x1f/0x160
    [  385.119849 ]  ? mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  ? mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  kasan_report.cold+0x83/0xdf
    [  385.119849 ]  ? devlink_param_notify+0x20/0x190
    [  385.119849 ]  ? mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  devlink_nl_param_fill+0x18a/0xa50
    [  385.119849 ]  ? _raw_spin_lock_irqsave+0x8d/0xe0
    [  385.119849 ]  ? devlink_flash_update_timeout_notify+0xf0/0xf0
    [  385.119849 ]  ? __wake_up_common+0x4b/0x1e0
    [  385.119849 ]  ? preempt_count_sub+0x14/0xc0
    [  385.119849 ]  ? _raw_spin_unlock_irqrestore+0x28/0x40
    [  385.119849 ]  ? __wake_up_common_lock+0xe3/0x140
    [  385.119849 ]  ? __wake_up_common+0x1e0/0x1e0
    [  385.119849 ]  ? __sanitizer_cov_trace_const_cmp8+0x27/0x80
    [  385.119849 ]  ? __rcu_read_unlock+0x48/0x70
    [  385.119849 ]  ? kasan_unpoison+0x23/0x50
    [  385.119849 ]  ? __kasan_slab_alloc+0x2c/0x80
    [  385.119849 ]  ? memset+0x20/0x40
    [  385.119849 ]  ? __sanitizer_cov_trace_const_cmp4+0x25/0x80
    [  385.119849 ]  devlink_param_notify+0xce/0x190
    [  385.119849 ]  devlink_unregister+0x92/0x2b0
    [  385.119849 ]  remove_one+0x41/0x140
    [  385.119849 ]  pci_device_remove+0x68/0x140
    [  385.119849 ]  ? pcibios_free_irq+0x10/0x10
    [  385.119849 ]  __device_release_driver+0x294/0x3f0
    [  385.119849 ]  device_driver_detach+0x82/0x130
    [  385.119849 ]  unbind_store+0x193/0x1b0
    [  385.119849 ]  ? subsys_interface_unregister+0x270/0x270
    [  385.119849 ]  drv_attr_store+0x4e/0x70
    [  385.119849 ]  ? drv_attr_show+0x60/0x60
    [  385.119849 ]  sysfs_kf_write+0xa7/0xc0
    [  385.119849 ]  kernfs_fop_write_iter+0x23a/0x2f0
    [  385.119849 ]  ? sysfs_kf_bin_read+0x160/0x160
    [  385.119849 ]  new_sync_write+0x311/0x430
    [  385.119849 ]  ? new_sync_read+0x480/0x480
    [  385.119849 ]  ? _raw_spin_lock+0x87/0xe0
    [  385.119849 ]  ? __sanitizer_cov_trace_cmp4+0x25/0x80
    [  385.119849 ]  ? security_file_permission+0x94/0xa0
    [  385.119849 ]  vfs_write+0x4c7/0x590
    [  385.119849 ]  ksys_write+0xf6/0x1e0
    [  385.119849 ]  ? __x64_sys_read+0x50/0x50
    [  385.119849 ]  ? fpregs_assert_state_consistent+0x99/0xa0
    [  385.119849 ]  do_syscall_64+0x3d/0x90
    [  385.119849 ]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  385.119849 ] RIP: 0033:0x7fc36ef38504
    [  385.119849 ] Code: 00 f7 d8 64 89 02 48 c7 c0 ff ff ff ff eb b3 0f 1f
    80 00 00 00 00 48 8d 05 f9 61 0d 00 8b 00 85 c0 75 13 b8 01 00 00 00 0f
    05 <48> 3d 00 f0 ff ff 77 54 c3 0f 1f 00 41 54 49 89 d4 55 48 89 f5 53
    [  385.119849 ] RSP: 002b:00007ffde0ff3d08 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
    [  385.119849 ] RAX: ffffffffffffffda RBX: 000000000000000c RCX: 00007fc36ef38504
    [  385.119849 ] RDX: 000000000000000c RSI: 00007fc370521040 RDI: 0000000000000001
    [  385.119849 ] RBP: 00007fc370521040 R08: 00007fc36f00b8c0 R09: 00007fc36ee4b740
    [  385.119849 ] R10: 0000000000000000 R11: 0000000000000246 R12: 00007fc36f00a760
    [  385.119849 ] R13: 000000000000000c R14: 00007fc36f005760 R15: 000000000000000c
    [  385.119849 ]  </TASK>
    [  385.119849 ]
    [  385.119849 ] Allocated by task 65:
    [  385.119849 ]  kasan_save_stack+0x1e/0x40
    [  385.119849 ]  __kasan_kmalloc+0x81/0xa0
    [  385.119849 ]  mlx5_init_fs+0x11b/0x1160
    [  385.119849 ]  mlx5_load+0x13c/0x220
    [  385.119849 ]  mlx5_load_one+0xda/0x160
    [  385.119849 ]  mlx5_recover_device+0xb8/0x100
    [  385.119849 ]  mlx5_health_try_recover+0x2f9/0x3a1
    [  385.119849 ]  devlink_health_reporter_recover+0x75/0x100
    [  385.119849 ]  devlink_health_report+0x26c/0x4b0
    [  385.275909 ]  mlx5_fw_fatal_reporter_err_work+0x11e/0x1b0
    [  385.275909 ]  process_one_work+0x520/0x970
    [  385.275909 ]  worker_thread+0x378/0x950
    [  385.275909 ]  kthread+0x1bb/0x200
    [  385.275909 ]  ret_from_fork+0x1f/0x30
    [  385.275909 ]
    [  385.275909 ] Freed by task 65:
    [  385.275909 ]  kasan_save_stack+0x1e/0x40
    [  385.275909 ]  kasan_set_track+0x21/0x30
    [  385.275909 ]  kasan_set_free_info+0x20/0x30
    [  385.275909 ]  __kasan_slab_free+0xfc/0x140
    [  385.275909 ]  kfree+0xa5/0x3b0
    [  385.275909 ]  mlx5_unload+0x2e/0xb0
    [  385.275909 ]  mlx5_unload_one+0x86/0xb0
    [  385.275909 ]  mlx5_fw_fatal_reporter_err_work.cold+0xca/0xcf
    [  385.275909 ]  process_one_work+0x520/0x970
    [  385.275909 ]  worker_thread+0x378/0x950
    [  385.275909 ]  kthread+0x1bb/0x200
    [  385.275909 ]  ret_from_fork+0x1f/0x30
    [  385.275909 ]
    [  385.275909 ] The buggy address belongs to the object at ffff888104b79300
    [  385.275909 ]  which belongs to the cache kmalloc-128 of size 128
    [  385.275909 ] The buggy address is located 8 bytes inside of
    [  385.275909 ]  128-byte region [ffff888104b79300, ffff888104b79380)
    [  385.275909 ] The buggy address belongs to the page:
    [  385.275909 ] page:00000000de44dd39 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x104b78
    [  385.275909 ] head:00000000de44dd39 order:1 compound_mapcount:0
    [  385.275909 ] flags: 0x8000000000010200(slab|head|zone=2)
    [  385.275909 ] raw: 8000000000010200 0000000000000000 dead000000000122 ffff8881000428c0
    [  385.275909 ] raw: 0000000000000000 0000000080200020 00000001ffffffff 0000000000000000
    [  385.275909 ] page dumped because: kasan: bad access detected
    [  385.275909 ]
    [  385.275909 ] Memory state around the buggy address:
    [  385.275909 ]  ffff888104b79200: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 fc fc
    [  385.275909 ]  ffff888104b79280: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  385.275909 ] >ffff888104b79300: fa fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  385.275909 ]                       ^
    [  385.275909 ]  ffff888104b79380: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  385.275909 ]  ffff888104b79400: fa fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  385.275909 ]]
    
    Fixes: e890acd5ff18 ("net/mlx5: Add devlink flow_steering_mode parameter")
    Signed-off-by: Shay Drory <shayd@nvidia.com>
    Reviewed-by: Mark Bloch <mbloch@nvidia.com>
    Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b33886971dbc4a86d1ec5369a2aaefc60a7cd72d
Author: Shay Drory <shayd@nvidia.com>
Date:   Wed Mar 9 14:45:58 2022 +0200

    net/mlx5: Initialize flow steering during driver probe
    
    Currently, software objects of flow steering are created and destroyed
    during reload flow. In case a device is unloaded, the following error
    is printed during grace period:
    
     mlx5_core 0000:00:0b.0: mlx5_fw_fatal_reporter_err_work:690:(pid 95):
        Driver is in error state. Unloading
    
    As a solution to fix use-after-free bugs, where we try to access
    these objects, when reading the value of flow_steering_mode devlink
    param[1], let's split flow steering creation and destruction into two
    routines:
        * init and cleanup: memory, cache, and pools allocation/free.
        * create and destroy: namespaces initialization and cleanup.
    
    While at it, re-order the cleanup function to mirror the init function.
    
    [1]
    Kasan trace:
    
    [  385.119849 ] BUG: KASAN: use-after-free in mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ] Read of size 4 at addr ffff888104b79308 by task bash/291
    [  385.119849 ]
    [  385.119849 ] CPU: 1 PID: 291 Comm: bash Not tainted 5.17.0-rc1+ #2
    [  385.119849 ] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.13.0-2.fc32 04/01/2014
    [  385.119849 ] Call Trace:
    [  385.119849 ]  <TASK>
    [  385.119849 ]  dump_stack_lvl+0x6e/0x91
    [  385.119849 ]  print_address_description.constprop.0+0x1f/0x160
    [  385.119849 ]  ? mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  ? mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  kasan_report.cold+0x83/0xdf
    [  385.119849 ]  ? devlink_param_notify+0x20/0x190
    [  385.119849 ]  ? mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  mlx5_devlink_fs_mode_get+0x3b/0xa0
    [  385.119849 ]  devlink_nl_param_fill+0x18a/0xa50
    [  385.119849 ]  ? _raw_spin_lock_irqsave+0x8d/0xe0
    [  385.119849 ]  ? devlink_flash_update_timeout_notify+0xf0/0xf0
    [  385.119849 ]  ? __wake_up_common+0x4b/0x1e0
    [  385.119849 ]  ? preempt_count_sub+0x14/0xc0
    [  385.119849 ]  ? _raw_spin_unlock_irqrestore+0x28/0x40
    [  385.119849 ]  ? __wake_up_common_lock+0xe3/0x140
    [  385.119849 ]  ? __wake_up_common+0x1e0/0x1e0
    [  385.119849 ]  ? __sanitizer_cov_trace_const_cmp8+0x27/0x80
    [  385.119849 ]  ? __rcu_read_unlock+0x48/0x70
    [  385.119849 ]  ? kasan_unpoison+0x23/0x50
    [  385.119849 ]  ? __kasan_slab_alloc+0x2c/0x80
    [  385.119849 ]  ? memset+0x20/0x40
    [  385.119849 ]  ? __sanitizer_cov_trace_const_cmp4+0x25/0x80
    [  385.119849 ]  devlink_param_notify+0xce/0x190
    [  385.119849 ]  devlink_unregister+0x92/0x2b0
    [  385.119849 ]  remove_one+0x41/0x140
    [  385.119849 ]  pci_device_remove+0x68/0x140
    [  385.119849 ]  ? pcibios_free_irq+0x10/0x10
    [  385.119849 ]  __device_release_driver+0x294/0x3f0
    [  385.119849 ]  device_driver_detach+0x82/0x130
    [  385.119849 ]  unbind_store+0x193/0x1b0
    [  385.119849 ]  ? subsys_interface_unregister+0x270/0x270
    [  385.119849 ]  drv_attr_store+0x4e/0x70
    [  385.119849 ]  ? drv_attr_show+0x60/0x60
    [  385.119849 ]  sysfs_kf_write+0xa7/0xc0
    [  385.119849 ]  kernfs_fop_write_iter+0x23a/0x2f0
    [  385.119849 ]  ? sysfs_kf_bin_read+0x160/0x160
    [  385.119849 ]  new_sync_write+0x311/0x430
    [  385.119849 ]  ? new_sync_read+0x480/0x480
    [  385.119849 ]  ? _raw_spin_lock+0x87/0xe0
    [  385.119849 ]  ? __sanitizer_cov_trace_cmp4+0x25/0x80
    [  385.119849 ]  ? security_file_permission+0x94/0xa0
    [  385.119849 ]  vfs_write+0x4c7/0x590
    [  385.119849 ]  ksys_write+0xf6/0x1e0
    [  385.119849 ]  ? __x64_sys_read+0x50/0x50
    [  385.119849 ]  ? fpregs_assert_state_consistent+0x99/0xa0
    [  385.119849 ]  do_syscall_64+0x3d/0x90
    [  385.119849 ]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  385.119849 ] RIP: 0033:0x7fc36ef38504
    [  385.119849 ] Code: 00 f7 d8 64 89 02 48 c7 c0 ff ff ff ff eb b3 0f 1f
    80 00 00 00 00 48 8d 05 f9 61 0d 00 8b 00 85 c0 75 13 b8 01 00 00 00 0f
    05 <48> 3d 00 f0 ff ff 77 54 c3 0f 1f 00 41 54 49 89 d4 55 48 89 f5 53
    [  385.119849 ] RSP: 002b:00007ffde0ff3d08 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
    [  385.119849 ] RAX: ffffffffffffffda RBX: 000000000000000c RCX: 00007fc36ef38504
    [  385.119849 ] RDX: 000000000000000c RSI: 00007fc370521040 RDI: 0000000000000001
    [  385.119849 ] RBP: 00007fc370521040 R08: 00007fc36f00b8c0 R09: 00007fc36ee4b740
    [  385.119849 ] R10: 0000000000000000 R11: 0000000000000246 R12: 00007fc36f00a760
    [  385.119849 ] R13: 000000000000000c R14: 00007fc36f005760 R15: 000000000000000c
    [  385.119849 ]  </TASK>
    [  385.119849 ]
    [  385.119849 ] Allocated by task 65:
    [  385.119849 ]  kasan_save_stack+0x1e/0x40
    [  385.119849 ]  __kasan_kmalloc+0x81/0xa0
    [  385.119849 ]  mlx5_init_fs+0x11b/0x1160
    [  385.119849 ]  mlx5_load+0x13c/0x220
    [  385.119849 ]  mlx5_load_one+0xda/0x160
    [  385.119849 ]  mlx5_recover_device+0xb8/0x100
    [  385.119849 ]  mlx5_health_try_recover+0x2f9/0x3a1
    [  385.119849 ]  devlink_health_reporter_recover+0x75/0x100
    [  385.119849 ]  devlink_health_report+0x26c/0x4b0
    [  385.275909 ]  mlx5_fw_fatal_reporter_err_work+0x11e/0x1b0
    [  385.275909 ]  process_one_work+0x520/0x970
    [  385.275909 ]  worker_thread+0x378/0x950
    [  385.275909 ]  kthread+0x1bb/0x200
    [  385.275909 ]  ret_from_fork+0x1f/0x30
    [  385.275909 ]
    [  385.275909 ] Freed by task 65:
    [  385.275909 ]  kasan_save_stack+0x1e/0x40
    [  385.275909 ]  kasan_set_track+0x21/0x30
    [  385.275909 ]  kasan_set_free_info+0x20/0x30
    [  385.275909 ]  __kasan_slab_free+0xfc/0x140
    [  385.275909 ]  kfree+0xa5/0x3b0
    [  385.275909 ]  mlx5_unload+0x2e/0xb0
    [  385.275909 ]  mlx5_unload_one+0x86/0xb0
    [  385.275909 ]  mlx5_fw_fatal_reporter_err_work.cold+0xca/0xcf
    [  385.275909 ]  process_one_work+0x520/0x970
    [  385.275909 ]  worker_thread+0x378/0x950
    [  385.275909 ]  kthread+0x1bb/0x200
    [  385.275909 ]  ret_from_fork+0x1f/0x30
    [  385.275909 ]
    [  385.275909 ] The buggy address belongs to the object at ffff888104b79300
    [  385.275909 ]  which belongs to the cache kmalloc-128 of size 128
    [  385.275909 ] The buggy address is located 8 bytes inside of
    [  385.275909 ]  128-byte region [ffff888104b79300, ffff888104b79380)
    [  385.275909 ] The buggy address belongs to the page:
    [  385.275909 ] page:00000000de44dd39 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x104b78
    [  385.275909 ] head:00000000de44dd39 order:1 compound_mapcount:0
    [  385.275909 ] flags: 0x8000000000010200(slab|head|zone=2)
    [  385.275909 ] raw: 8000000000010200 0000000000000000 dead000000000122 ffff8881000428c0
    [  385.275909 ] raw: 0000000000000000 0000000080200020 00000001ffffffff 0000000000000000
    [  385.275909 ] page dumped because: kasan: bad access detected
    [  385.275909 ]
    [  385.275909 ] Memory state around the buggy address:
    [  385.275909 ]  ffff888104b79200: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 fc fc
    [  385.275909 ]  ffff888104b79280: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  385.275909 ] >ffff888104b79300: fa fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  385.275909 ]                       ^
    [  385.275909 ]  ffff888104b79380: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  385.275909 ]  ffff888104b79400: fa fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  385.275909 ]]
    
    Fixes: e890acd5ff18 ("net/mlx5: Add devlink flow_steering_mode parameter")
    Signed-off-by: Shay Drory <shayd@nvidia.com>
    Reviewed-by: Mark Bloch <mbloch@nvidia.com>
    Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>

commit d7809f64e7a6f76d2937b4712b9a7b63835e7204
Author: Sasha Neftin <sasha.neftin@intel.com>
Date:   Wed Mar 9 08:19:19 2022 +0200

    igc: Fix BUG: scheduling while atomic
    
    [ Upstream commit c80a29f0fe9b6f5457e0788e27d1110577eba99b ]
    
    Replace usleep_range() method with udelay() method to allow atomic contexts
    in low-level MDIO access functions.
    
    The following issue can be seen by doing the following:
    $ modprobe -r bonding
    $ modprobe -v bonding max_bonds=1 mode=1 miimon=100 use_carrier=0
    $ ip link set bond0 up
    $ ifenslave bond0 eth0 eth1
    
    [  982.357308] BUG: scheduling while atomic: kworker/u64:0/9/0x00000002
    [  982.364431] INFO: lockdep is turned off.
    [  982.368824] Modules linked in: bonding sctp ip6_udp_tunnel udp_tunnel mlx4_ib ib_uverbs ib_core mlx4_en mlx4_core nfp tls sunrpc intel_rapl_msr iTCO_wdt iTCO_vendor_support mxm_wmi dcdbas intel_rapl_common sb_edac x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass crct10dif_pclmul crc32_pclmul ghash_clmulni_intel rapl intel_cstate intel_uncore pcspkr lpc_ich mei_me ipmi_ssif mei ipmi_si ipmi_devintf ipmi_msghandler wmi acpi_power_meter xfs libcrc32c sr_mod cdrom sd_mod t10_pi sg mgag200 drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci crc32c_intel libata i2c_algo_bit tg3 megaraid_sas igc dm_mirror dm_region_hash dm_log dm_mod [last unloaded: bonding]
    [  982.437941] CPU: 25 PID: 9 Comm: kworker/u64:0 Kdump: loaded Tainted: G        W        --------- -  - 4.18.0-348.el8.x86_64+debug #1
    [  982.451333] Hardware name: Dell Inc. PowerEdge R730/0H21J3, BIOS 2.7.0 12/005/2017
    [  982.459791] Workqueue: bond0 bond_mii_monitor [bonding]
    [  982.465622] Call Trace:
    [  982.468355]  dump_stack+0x8e/0xd0
    [  982.472056]  __schedule_bug.cold.60+0x3a/0x60
    [  982.476919]  __schedule+0x147b/0x1bc0
    [  982.481007]  ? firmware_map_remove+0x16b/0x16b
    [  982.485967]  ? hrtimer_fixup_init+0x40/0x40
    [  982.490625]  schedule+0xd9/0x250
    [  982.494227]  schedule_hrtimeout_range_clock+0x10d/0x2c0
    [  982.500058]  ? hrtimer_nanosleep_restart+0x130/0x130
    [  982.505598]  ? hrtimer_init_sleeper_on_stack+0x90/0x90
    [  982.511332]  ? usleep_range+0x88/0x130
    [  982.515514]  ? recalibrate_cpu_khz+0x10/0x10
    [  982.520279]  ? ktime_get+0xab/0x1c0
    [  982.524175]  ? usleep_range+0x88/0x130
    [  982.528355]  usleep_range+0xdd/0x130
    [  982.532344]  ? console_conditional_schedule+0x30/0x30
    [  982.537987]  ? igc_put_hw_semaphore+0x17/0x60 [igc]
    [  982.543432]  igc_read_phy_reg_gpy+0x111/0x2b0 [igc]
    [  982.548887]  igc_phy_has_link+0xfa/0x260 [igc]
    [  982.553847]  ? igc_get_phy_id+0x210/0x210 [igc]
    [  982.558894]  ? lock_acquire+0x34d/0x890
    [  982.563187]  ? lock_downgrade+0x710/0x710
    [  982.567659]  ? rcu_read_unlock+0x50/0x50
    [  982.572039]  igc_check_for_copper_link+0x106/0x210 [igc]
    [  982.577970]  ? igc_config_fc_after_link_up+0x840/0x840 [igc]
    [  982.584286]  ? rcu_read_unlock+0x50/0x50
    [  982.588661]  ? lock_release+0x591/0xb80
    [  982.592939]  ? lock_release+0x591/0xb80
    [  982.597220]  igc_has_link+0x113/0x330 [igc]
    [  982.601887]  ? lock_downgrade+0x710/0x710
    [  982.606362]  igc_ethtool_get_link+0x6d/0x90 [igc]
    [  982.611614]  bond_check_dev_link+0x131/0x2c0 [bonding]
    [  982.617350]  ? bond_time_in_interval+0xd0/0xd0 [bonding]
    [  982.623277]  ? rcu_read_lock_held+0x62/0xc0
    [  982.627944]  ? rcu_read_lock_sched_held+0xe0/0xe0
    [  982.633198]  bond_mii_monitor+0x314/0x2500 [bonding]
    [  982.638738]  ? lock_contended+0x880/0x880
    [  982.643214]  ? bond_miimon_link_change+0xa0/0xa0 [bonding]
    [  982.649336]  ? lock_acquire+0x34d/0x890
    [  982.653615]  ? lock_downgrade+0x710/0x710
    [  982.658089]  ? debug_object_deactivate+0x221/0x340
    [  982.663436]  ? rcu_read_unlock+0x50/0x50
    [  982.667811]  ? debug_print_object+0x2b0/0x2b0
    [  982.672672]  ? __switch_to_asm+0x41/0x70
    [  982.677049]  ? __switch_to_asm+0x35/0x70
    [  982.681426]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.686288]  ? trace_hardirqs_on+0x20/0x195
    [  982.690956]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.695818]  process_one_work+0x8f0/0x1770
    [  982.700390]  ? pwq_dec_nr_in_flight+0x320/0x320
    [  982.705443]  ? debug_show_held_locks+0x50/0x50
    [  982.710403]  worker_thread+0x87/0xb40
    [  982.714489]  ? process_one_work+0x1770/0x1770
    [  982.719349]  kthread+0x344/0x410
    [  982.722950]  ? kthread_insert_work_sanity_check+0xd0/0xd0
    [  982.728975]  ret_from_fork+0x3a/0x50
    
    Fixes: 5586838fe9ce ("igc: Add code for PHY support")
    Reported-by: Corinna Vinschen <vinschen@redhat.com>
    Suggested-by: Dima Ruinskiy <dima.ruinskiy@intel.com>
    Signed-off-by: Sasha Neftin <sasha.neftin@intel.com>
    Tested-by: Corinna Vinschen <vinschen@redhat.com>
    Tested-by: Naama Meir <naamax.meir@linux.intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit da323d0d6aaace047f005504273d928078bf3f83
Author: Sasha Neftin <sasha.neftin@intel.com>
Date:   Wed Mar 9 08:19:19 2022 +0200

    igc: Fix BUG: scheduling while atomic
    
    [ Upstream commit c80a29f0fe9b6f5457e0788e27d1110577eba99b ]
    
    Replace usleep_range() method with udelay() method to allow atomic contexts
    in low-level MDIO access functions.
    
    The following issue can be seen by doing the following:
    $ modprobe -r bonding
    $ modprobe -v bonding max_bonds=1 mode=1 miimon=100 use_carrier=0
    $ ip link set bond0 up
    $ ifenslave bond0 eth0 eth1
    
    [  982.357308] BUG: scheduling while atomic: kworker/u64:0/9/0x00000002
    [  982.364431] INFO: lockdep is turned off.
    [  982.368824] Modules linked in: bonding sctp ip6_udp_tunnel udp_tunnel mlx4_ib ib_uverbs ib_core mlx4_en mlx4_core nfp tls sunrpc intel_rapl_msr iTCO_wdt iTCO_vendor_support mxm_wmi dcdbas intel_rapl_common sb_edac x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass crct10dif_pclmul crc32_pclmul ghash_clmulni_intel rapl intel_cstate intel_uncore pcspkr lpc_ich mei_me ipmi_ssif mei ipmi_si ipmi_devintf ipmi_msghandler wmi acpi_power_meter xfs libcrc32c sr_mod cdrom sd_mod t10_pi sg mgag200 drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci crc32c_intel libata i2c_algo_bit tg3 megaraid_sas igc dm_mirror dm_region_hash dm_log dm_mod [last unloaded: bonding]
    [  982.437941] CPU: 25 PID: 9 Comm: kworker/u64:0 Kdump: loaded Tainted: G        W        --------- -  - 4.18.0-348.el8.x86_64+debug #1
    [  982.451333] Hardware name: Dell Inc. PowerEdge R730/0H21J3, BIOS 2.7.0 12/005/2017
    [  982.459791] Workqueue: bond0 bond_mii_monitor [bonding]
    [  982.465622] Call Trace:
    [  982.468355]  dump_stack+0x8e/0xd0
    [  982.472056]  __schedule_bug.cold.60+0x3a/0x60
    [  982.476919]  __schedule+0x147b/0x1bc0
    [  982.481007]  ? firmware_map_remove+0x16b/0x16b
    [  982.485967]  ? hrtimer_fixup_init+0x40/0x40
    [  982.490625]  schedule+0xd9/0x250
    [  982.494227]  schedule_hrtimeout_range_clock+0x10d/0x2c0
    [  982.500058]  ? hrtimer_nanosleep_restart+0x130/0x130
    [  982.505598]  ? hrtimer_init_sleeper_on_stack+0x90/0x90
    [  982.511332]  ? usleep_range+0x88/0x130
    [  982.515514]  ? recalibrate_cpu_khz+0x10/0x10
    [  982.520279]  ? ktime_get+0xab/0x1c0
    [  982.524175]  ? usleep_range+0x88/0x130
    [  982.528355]  usleep_range+0xdd/0x130
    [  982.532344]  ? console_conditional_schedule+0x30/0x30
    [  982.537987]  ? igc_put_hw_semaphore+0x17/0x60 [igc]
    [  982.543432]  igc_read_phy_reg_gpy+0x111/0x2b0 [igc]
    [  982.548887]  igc_phy_has_link+0xfa/0x260 [igc]
    [  982.553847]  ? igc_get_phy_id+0x210/0x210 [igc]
    [  982.558894]  ? lock_acquire+0x34d/0x890
    [  982.563187]  ? lock_downgrade+0x710/0x710
    [  982.567659]  ? rcu_read_unlock+0x50/0x50
    [  982.572039]  igc_check_for_copper_link+0x106/0x210 [igc]
    [  982.577970]  ? igc_config_fc_after_link_up+0x840/0x840 [igc]
    [  982.584286]  ? rcu_read_unlock+0x50/0x50
    [  982.588661]  ? lock_release+0x591/0xb80
    [  982.592939]  ? lock_release+0x591/0xb80
    [  982.597220]  igc_has_link+0x113/0x330 [igc]
    [  982.601887]  ? lock_downgrade+0x710/0x710
    [  982.606362]  igc_ethtool_get_link+0x6d/0x90 [igc]
    [  982.611614]  bond_check_dev_link+0x131/0x2c0 [bonding]
    [  982.617350]  ? bond_time_in_interval+0xd0/0xd0 [bonding]
    [  982.623277]  ? rcu_read_lock_held+0x62/0xc0
    [  982.627944]  ? rcu_read_lock_sched_held+0xe0/0xe0
    [  982.633198]  bond_mii_monitor+0x314/0x2500 [bonding]
    [  982.638738]  ? lock_contended+0x880/0x880
    [  982.643214]  ? bond_miimon_link_change+0xa0/0xa0 [bonding]
    [  982.649336]  ? lock_acquire+0x34d/0x890
    [  982.653615]  ? lock_downgrade+0x710/0x710
    [  982.658089]  ? debug_object_deactivate+0x221/0x340
    [  982.663436]  ? rcu_read_unlock+0x50/0x50
    [  982.667811]  ? debug_print_object+0x2b0/0x2b0
    [  982.672672]  ? __switch_to_asm+0x41/0x70
    [  982.677049]  ? __switch_to_asm+0x35/0x70
    [  982.681426]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.686288]  ? trace_hardirqs_on+0x20/0x195
    [  982.690956]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.695818]  process_one_work+0x8f0/0x1770
    [  982.700390]  ? pwq_dec_nr_in_flight+0x320/0x320
    [  982.705443]  ? debug_show_held_locks+0x50/0x50
    [  982.710403]  worker_thread+0x87/0xb40
    [  982.714489]  ? process_one_work+0x1770/0x1770
    [  982.719349]  kthread+0x344/0x410
    [  982.722950]  ? kthread_insert_work_sanity_check+0xd0/0xd0
    [  982.728975]  ret_from_fork+0x3a/0x50
    
    Fixes: 5586838fe9ce ("igc: Add code for PHY support")
    Reported-by: Corinna Vinschen <vinschen@redhat.com>
    Suggested-by: Dima Ruinskiy <dima.ruinskiy@intel.com>
    Signed-off-by: Sasha Neftin <sasha.neftin@intel.com>
    Tested-by: Corinna Vinschen <vinschen@redhat.com>
    Tested-by: Naama Meir <naamax.meir@linux.intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fc7116a79a86500e15520658f279b6536ff9f700
Author: Sasha Neftin <sasha.neftin@intel.com>
Date:   Wed Mar 9 08:19:19 2022 +0200

    igc: Fix BUG: scheduling while atomic
    
    [ Upstream commit c80a29f0fe9b6f5457e0788e27d1110577eba99b ]
    
    Replace usleep_range() method with udelay() method to allow atomic contexts
    in low-level MDIO access functions.
    
    The following issue can be seen by doing the following:
    $ modprobe -r bonding
    $ modprobe -v bonding max_bonds=1 mode=1 miimon=100 use_carrier=0
    $ ip link set bond0 up
    $ ifenslave bond0 eth0 eth1
    
    [  982.357308] BUG: scheduling while atomic: kworker/u64:0/9/0x00000002
    [  982.364431] INFO: lockdep is turned off.
    [  982.368824] Modules linked in: bonding sctp ip6_udp_tunnel udp_tunnel mlx4_ib ib_uverbs ib_core mlx4_en mlx4_core nfp tls sunrpc intel_rapl_msr iTCO_wdt iTCO_vendor_support mxm_wmi dcdbas intel_rapl_common sb_edac x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass crct10dif_pclmul crc32_pclmul ghash_clmulni_intel rapl intel_cstate intel_uncore pcspkr lpc_ich mei_me ipmi_ssif mei ipmi_si ipmi_devintf ipmi_msghandler wmi acpi_power_meter xfs libcrc32c sr_mod cdrom sd_mod t10_pi sg mgag200 drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci crc32c_intel libata i2c_algo_bit tg3 megaraid_sas igc dm_mirror dm_region_hash dm_log dm_mod [last unloaded: bonding]
    [  982.437941] CPU: 25 PID: 9 Comm: kworker/u64:0 Kdump: loaded Tainted: G        W        --------- -  - 4.18.0-348.el8.x86_64+debug #1
    [  982.451333] Hardware name: Dell Inc. PowerEdge R730/0H21J3, BIOS 2.7.0 12/005/2017
    [  982.459791] Workqueue: bond0 bond_mii_monitor [bonding]
    [  982.465622] Call Trace:
    [  982.468355]  dump_stack+0x8e/0xd0
    [  982.472056]  __schedule_bug.cold.60+0x3a/0x60
    [  982.476919]  __schedule+0x147b/0x1bc0
    [  982.481007]  ? firmware_map_remove+0x16b/0x16b
    [  982.485967]  ? hrtimer_fixup_init+0x40/0x40
    [  982.490625]  schedule+0xd9/0x250
    [  982.494227]  schedule_hrtimeout_range_clock+0x10d/0x2c0
    [  982.500058]  ? hrtimer_nanosleep_restart+0x130/0x130
    [  982.505598]  ? hrtimer_init_sleeper_on_stack+0x90/0x90
    [  982.511332]  ? usleep_range+0x88/0x130
    [  982.515514]  ? recalibrate_cpu_khz+0x10/0x10
    [  982.520279]  ? ktime_get+0xab/0x1c0
    [  982.524175]  ? usleep_range+0x88/0x130
    [  982.528355]  usleep_range+0xdd/0x130
    [  982.532344]  ? console_conditional_schedule+0x30/0x30
    [  982.537987]  ? igc_put_hw_semaphore+0x17/0x60 [igc]
    [  982.543432]  igc_read_phy_reg_gpy+0x111/0x2b0 [igc]
    [  982.548887]  igc_phy_has_link+0xfa/0x260 [igc]
    [  982.553847]  ? igc_get_phy_id+0x210/0x210 [igc]
    [  982.558894]  ? lock_acquire+0x34d/0x890
    [  982.563187]  ? lock_downgrade+0x710/0x710
    [  982.567659]  ? rcu_read_unlock+0x50/0x50
    [  982.572039]  igc_check_for_copper_link+0x106/0x210 [igc]
    [  982.577970]  ? igc_config_fc_after_link_up+0x840/0x840 [igc]
    [  982.584286]  ? rcu_read_unlock+0x50/0x50
    [  982.588661]  ? lock_release+0x591/0xb80
    [  982.592939]  ? lock_release+0x591/0xb80
    [  982.597220]  igc_has_link+0x113/0x330 [igc]
    [  982.601887]  ? lock_downgrade+0x710/0x710
    [  982.606362]  igc_ethtool_get_link+0x6d/0x90 [igc]
    [  982.611614]  bond_check_dev_link+0x131/0x2c0 [bonding]
    [  982.617350]  ? bond_time_in_interval+0xd0/0xd0 [bonding]
    [  982.623277]  ? rcu_read_lock_held+0x62/0xc0
    [  982.627944]  ? rcu_read_lock_sched_held+0xe0/0xe0
    [  982.633198]  bond_mii_monitor+0x314/0x2500 [bonding]
    [  982.638738]  ? lock_contended+0x880/0x880
    [  982.643214]  ? bond_miimon_link_change+0xa0/0xa0 [bonding]
    [  982.649336]  ? lock_acquire+0x34d/0x890
    [  982.653615]  ? lock_downgrade+0x710/0x710
    [  982.658089]  ? debug_object_deactivate+0x221/0x340
    [  982.663436]  ? rcu_read_unlock+0x50/0x50
    [  982.667811]  ? debug_print_object+0x2b0/0x2b0
    [  982.672672]  ? __switch_to_asm+0x41/0x70
    [  982.677049]  ? __switch_to_asm+0x35/0x70
    [  982.681426]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.686288]  ? trace_hardirqs_on+0x20/0x195
    [  982.690956]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.695818]  process_one_work+0x8f0/0x1770
    [  982.700390]  ? pwq_dec_nr_in_flight+0x320/0x320
    [  982.705443]  ? debug_show_held_locks+0x50/0x50
    [  982.710403]  worker_thread+0x87/0xb40
    [  982.714489]  ? process_one_work+0x1770/0x1770
    [  982.719349]  kthread+0x344/0x410
    [  982.722950]  ? kthread_insert_work_sanity_check+0xd0/0xd0
    [  982.728975]  ret_from_fork+0x3a/0x50
    
    Fixes: 5586838fe9ce ("igc: Add code for PHY support")
    Reported-by: Corinna Vinschen <vinschen@redhat.com>
    Suggested-by: Dima Ruinskiy <dima.ruinskiy@intel.com>
    Signed-off-by: Sasha Neftin <sasha.neftin@intel.com>
    Tested-by: Corinna Vinschen <vinschen@redhat.com>
    Tested-by: Naama Meir <naamax.meir@linux.intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9a9c481593650bbe4066e2185de6b68a82a4110f
Author: Sasha Neftin <sasha.neftin@intel.com>
Date:   Wed Mar 9 08:19:19 2022 +0200

    igc: Fix BUG: scheduling while atomic
    
    [ Upstream commit c80a29f0fe9b6f5457e0788e27d1110577eba99b ]
    
    Replace usleep_range() method with udelay() method to allow atomic contexts
    in low-level MDIO access functions.
    
    The following issue can be seen by doing the following:
    $ modprobe -r bonding
    $ modprobe -v bonding max_bonds=1 mode=1 miimon=100 use_carrier=0
    $ ip link set bond0 up
    $ ifenslave bond0 eth0 eth1
    
    [  982.357308] BUG: scheduling while atomic: kworker/u64:0/9/0x00000002
    [  982.364431] INFO: lockdep is turned off.
    [  982.368824] Modules linked in: bonding sctp ip6_udp_tunnel udp_tunnel mlx4_ib ib_uverbs ib_core mlx4_en mlx4_core nfp tls sunrpc intel_rapl_msr iTCO_wdt iTCO_vendor_support mxm_wmi dcdbas intel_rapl_common sb_edac x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass crct10dif_pclmul crc32_pclmul ghash_clmulni_intel rapl intel_cstate intel_uncore pcspkr lpc_ich mei_me ipmi_ssif mei ipmi_si ipmi_devintf ipmi_msghandler wmi acpi_power_meter xfs libcrc32c sr_mod cdrom sd_mod t10_pi sg mgag200 drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci crc32c_intel libata i2c_algo_bit tg3 megaraid_sas igc dm_mirror dm_region_hash dm_log dm_mod [last unloaded: bonding]
    [  982.437941] CPU: 25 PID: 9 Comm: kworker/u64:0 Kdump: loaded Tainted: G        W        --------- -  - 4.18.0-348.el8.x86_64+debug #1
    [  982.451333] Hardware name: Dell Inc. PowerEdge R730/0H21J3, BIOS 2.7.0 12/005/2017
    [  982.459791] Workqueue: bond0 bond_mii_monitor [bonding]
    [  982.465622] Call Trace:
    [  982.468355]  dump_stack+0x8e/0xd0
    [  982.472056]  __schedule_bug.cold.60+0x3a/0x60
    [  982.476919]  __schedule+0x147b/0x1bc0
    [  982.481007]  ? firmware_map_remove+0x16b/0x16b
    [  982.485967]  ? hrtimer_fixup_init+0x40/0x40
    [  982.490625]  schedule+0xd9/0x250
    [  982.494227]  schedule_hrtimeout_range_clock+0x10d/0x2c0
    [  982.500058]  ? hrtimer_nanosleep_restart+0x130/0x130
    [  982.505598]  ? hrtimer_init_sleeper_on_stack+0x90/0x90
    [  982.511332]  ? usleep_range+0x88/0x130
    [  982.515514]  ? recalibrate_cpu_khz+0x10/0x10
    [  982.520279]  ? ktime_get+0xab/0x1c0
    [  982.524175]  ? usleep_range+0x88/0x130
    [  982.528355]  usleep_range+0xdd/0x130
    [  982.532344]  ? console_conditional_schedule+0x30/0x30
    [  982.537987]  ? igc_put_hw_semaphore+0x17/0x60 [igc]
    [  982.543432]  igc_read_phy_reg_gpy+0x111/0x2b0 [igc]
    [  982.548887]  igc_phy_has_link+0xfa/0x260 [igc]
    [  982.553847]  ? igc_get_phy_id+0x210/0x210 [igc]
    [  982.558894]  ? lock_acquire+0x34d/0x890
    [  982.563187]  ? lock_downgrade+0x710/0x710
    [  982.567659]  ? rcu_read_unlock+0x50/0x50
    [  982.572039]  igc_check_for_copper_link+0x106/0x210 [igc]
    [  982.577970]  ? igc_config_fc_after_link_up+0x840/0x840 [igc]
    [  982.584286]  ? rcu_read_unlock+0x50/0x50
    [  982.588661]  ? lock_release+0x591/0xb80
    [  982.592939]  ? lock_release+0x591/0xb80
    [  982.597220]  igc_has_link+0x113/0x330 [igc]
    [  982.601887]  ? lock_downgrade+0x710/0x710
    [  982.606362]  igc_ethtool_get_link+0x6d/0x90 [igc]
    [  982.611614]  bond_check_dev_link+0x131/0x2c0 [bonding]
    [  982.617350]  ? bond_time_in_interval+0xd0/0xd0 [bonding]
    [  982.623277]  ? rcu_read_lock_held+0x62/0xc0
    [  982.627944]  ? rcu_read_lock_sched_held+0xe0/0xe0
    [  982.633198]  bond_mii_monitor+0x314/0x2500 [bonding]
    [  982.638738]  ? lock_contended+0x880/0x880
    [  982.643214]  ? bond_miimon_link_change+0xa0/0xa0 [bonding]
    [  982.649336]  ? lock_acquire+0x34d/0x890
    [  982.653615]  ? lock_downgrade+0x710/0x710
    [  982.658089]  ? debug_object_deactivate+0x221/0x340
    [  982.663436]  ? rcu_read_unlock+0x50/0x50
    [  982.667811]  ? debug_print_object+0x2b0/0x2b0
    [  982.672672]  ? __switch_to_asm+0x41/0x70
    [  982.677049]  ? __switch_to_asm+0x35/0x70
    [  982.681426]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.686288]  ? trace_hardirqs_on+0x20/0x195
    [  982.690956]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.695818]  process_one_work+0x8f0/0x1770
    [  982.700390]  ? pwq_dec_nr_in_flight+0x320/0x320
    [  982.705443]  ? debug_show_held_locks+0x50/0x50
    [  982.710403]  worker_thread+0x87/0xb40
    [  982.714489]  ? process_one_work+0x1770/0x1770
    [  982.719349]  kthread+0x344/0x410
    [  982.722950]  ? kthread_insert_work_sanity_check+0xd0/0xd0
    [  982.728975]  ret_from_fork+0x3a/0x50
    
    Fixes: 5586838fe9ce ("igc: Add code for PHY support")
    Reported-by: Corinna Vinschen <vinschen@redhat.com>
    Suggested-by: Dima Ruinskiy <dima.ruinskiy@intel.com>
    Signed-off-by: Sasha Neftin <sasha.neftin@intel.com>
    Tested-by: Corinna Vinschen <vinschen@redhat.com>
    Tested-by: Naama Meir <naamax.meir@linux.intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f596e2ce1c0f250bb3ecc179f611be37e862635f
Author: Zqiang <qiang1.zhang@intel.com>
Date:   Mon Apr 4 07:59:32 2022 +0800

    rcu: Use IRQ_WORK_INIT_HARD() to avoid rcu_read_unlock() hangs
    
    When booting kernels built with both CONFIG_RCU_STRICT_GRACE_PERIOD=y
    and CONFIG_PREEMPT_RT=y, the rcu_read_unlock_special() function's
    invocation of irq_work_queue_on() the init_irq_work() causes the
    rcu_preempt_deferred_qs_handler() function to work execute in SCHED_FIFO
    irq_work kthreads.  Because rcu_read_unlock_special() is invoked on each
    rcu_read_unlock() in such kernels, the amount of work just keeps piling
    up, resulting in a boot-time hang.
    
    This commit therefore avoids this hang by using IRQ_WORK_INIT_HARD()
    instead of init_irq_work(), but only in kernels built with both
    CONFIG_PREEMPT_RT=y and CONFIG_RCU_STRICT_GRACE_PERIOD=y.
    
    Signed-off-by: Zqiang <qiang1.zhang@intel.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 3989c079e399fb5dc3aa3fcb334637b5801dc888
Author: Matt Johnston <matt@codeconstruct.com.au>
Date:   Tue Feb 22 12:17:38 2022 +0800

    mctp: make __mctp_dev_get() take a refcount hold
    
    [ Upstream commit dc121c0084910db985cf1c8ba6fce5d8c307cc02 ]
    
    Previously there was a race that could allow the mctp_dev refcount
    to hit zero:
    
    rcu_read_lock();
    mdev = __mctp_dev_get(dev);
    // mctp_unregister() happens here, mdev->refs hits zero
    mctp_dev_hold(dev);
    rcu_read_unlock();
    
    Now we make __mctp_dev_get() take the hold itself. It is safe to test
    against the zero refcount because __mctp_dev_get() is called holding
    rcu_read_lock and mctp_dev uses kfree_rcu().
    
    Reported-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Matt Johnston <matt@codeconstruct.com.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c80a29f0fe9b6f5457e0788e27d1110577eba99b
Author: Sasha Neftin <sasha.neftin@intel.com>
Date:   Wed Mar 9 08:19:19 2022 +0200

    igc: Fix BUG: scheduling while atomic
    
    Replace usleep_range() method with udelay() method to allow atomic contexts
    in low-level MDIO access functions.
    
    The following issue can be seen by doing the following:
    $ modprobe -r bonding
    $ modprobe -v bonding max_bonds=1 mode=1 miimon=100 use_carrier=0
    $ ip link set bond0 up
    $ ifenslave bond0 eth0 eth1
    
    [  982.357308] BUG: scheduling while atomic: kworker/u64:0/9/0x00000002
    [  982.364431] INFO: lockdep is turned off.
    [  982.368824] Modules linked in: bonding sctp ip6_udp_tunnel udp_tunnel mlx4_ib ib_uverbs ib_core mlx4_en mlx4_core nfp tls sunrpc intel_rapl_msr iTCO_wdt iTCO_vendor_support mxm_wmi dcdbas intel_rapl_common sb_edac x86_pkg_temp_thermal intel_powerclamp coretemp kvm_intel kvm irqbypass crct10dif_pclmul crc32_pclmul ghash_clmulni_intel rapl intel_cstate intel_uncore pcspkr lpc_ich mei_me ipmi_ssif mei ipmi_si ipmi_devintf ipmi_msghandler wmi acpi_power_meter xfs libcrc32c sr_mod cdrom sd_mod t10_pi sg mgag200 drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops drm ahci libahci crc32c_intel libata i2c_algo_bit tg3 megaraid_sas igc dm_mirror dm_region_hash dm_log dm_mod [last unloaded: bonding]
    [  982.437941] CPU: 25 PID: 9 Comm: kworker/u64:0 Kdump: loaded Tainted: G        W        --------- -  - 4.18.0-348.el8.x86_64+debug #1
    [  982.451333] Hardware name: Dell Inc. PowerEdge R730/0H21J3, BIOS 2.7.0 12/005/2017
    [  982.459791] Workqueue: bond0 bond_mii_monitor [bonding]
    [  982.465622] Call Trace:
    [  982.468355]  dump_stack+0x8e/0xd0
    [  982.472056]  __schedule_bug.cold.60+0x3a/0x60
    [  982.476919]  __schedule+0x147b/0x1bc0
    [  982.481007]  ? firmware_map_remove+0x16b/0x16b
    [  982.485967]  ? hrtimer_fixup_init+0x40/0x40
    [  982.490625]  schedule+0xd9/0x250
    [  982.494227]  schedule_hrtimeout_range_clock+0x10d/0x2c0
    [  982.500058]  ? hrtimer_nanosleep_restart+0x130/0x130
    [  982.505598]  ? hrtimer_init_sleeper_on_stack+0x90/0x90
    [  982.511332]  ? usleep_range+0x88/0x130
    [  982.515514]  ? recalibrate_cpu_khz+0x10/0x10
    [  982.520279]  ? ktime_get+0xab/0x1c0
    [  982.524175]  ? usleep_range+0x88/0x130
    [  982.528355]  usleep_range+0xdd/0x130
    [  982.532344]  ? console_conditional_schedule+0x30/0x30
    [  982.537987]  ? igc_put_hw_semaphore+0x17/0x60 [igc]
    [  982.543432]  igc_read_phy_reg_gpy+0x111/0x2b0 [igc]
    [  982.548887]  igc_phy_has_link+0xfa/0x260 [igc]
    [  982.553847]  ? igc_get_phy_id+0x210/0x210 [igc]
    [  982.558894]  ? lock_acquire+0x34d/0x890
    [  982.563187]  ? lock_downgrade+0x710/0x710
    [  982.567659]  ? rcu_read_unlock+0x50/0x50
    [  982.572039]  igc_check_for_copper_link+0x106/0x210 [igc]
    [  982.577970]  ? igc_config_fc_after_link_up+0x840/0x840 [igc]
    [  982.584286]  ? rcu_read_unlock+0x50/0x50
    [  982.588661]  ? lock_release+0x591/0xb80
    [  982.592939]  ? lock_release+0x591/0xb80
    [  982.597220]  igc_has_link+0x113/0x330 [igc]
    [  982.601887]  ? lock_downgrade+0x710/0x710
    [  982.606362]  igc_ethtool_get_link+0x6d/0x90 [igc]
    [  982.611614]  bond_check_dev_link+0x131/0x2c0 [bonding]
    [  982.617350]  ? bond_time_in_interval+0xd0/0xd0 [bonding]
    [  982.623277]  ? rcu_read_lock_held+0x62/0xc0
    [  982.627944]  ? rcu_read_lock_sched_held+0xe0/0xe0
    [  982.633198]  bond_mii_monitor+0x314/0x2500 [bonding]
    [  982.638738]  ? lock_contended+0x880/0x880
    [  982.643214]  ? bond_miimon_link_change+0xa0/0xa0 [bonding]
    [  982.649336]  ? lock_acquire+0x34d/0x890
    [  982.653615]  ? lock_downgrade+0x710/0x710
    [  982.658089]  ? debug_object_deactivate+0x221/0x340
    [  982.663436]  ? rcu_read_unlock+0x50/0x50
    [  982.667811]  ? debug_print_object+0x2b0/0x2b0
    [  982.672672]  ? __switch_to_asm+0x41/0x70
    [  982.677049]  ? __switch_to_asm+0x35/0x70
    [  982.681426]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.686288]  ? trace_hardirqs_on+0x20/0x195
    [  982.690956]  ? _raw_spin_unlock_irq+0x24/0x40
    [  982.695818]  process_one_work+0x8f0/0x1770
    [  982.700390]  ? pwq_dec_nr_in_flight+0x320/0x320
    [  982.705443]  ? debug_show_held_locks+0x50/0x50
    [  982.710403]  worker_thread+0x87/0xb40
    [  982.714489]  ? process_one_work+0x1770/0x1770
    [  982.719349]  kthread+0x344/0x410
    [  982.722950]  ? kthread_insert_work_sanity_check+0xd0/0xd0
    [  982.728975]  ret_from_fork+0x3a/0x50
    
    Fixes: 5586838fe9ce ("igc: Add code for PHY support")
    Reported-by: Corinna Vinschen <vinschen@redhat.com>
    Suggested-by: Dima Ruinskiy <dima.ruinskiy@intel.com>
    Signed-off-by: Sasha Neftin <sasha.neftin@intel.com>
    Tested-by: Corinna Vinschen <vinschen@redhat.com>
    Tested-by: Naama Meir <naamax.meir@linux.intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>

commit 400705c50bbf184794c885d1efad7fe9ccf1471a
Author: Wen Gong <quic_wgong@quicinc.com>
Date:   Tue Jan 11 16:42:52 2022 +0200

    ath11k: free peer for station when disconnect from AP for QCA6390/WCN6855
    
    [ Upstream commit 212ad7cb7d7592669c067125949e0a8e31ce6a0b ]
    
    Commit b4a0f54156ac ("ath11k: move peer delete after vdev stop of station
    for QCA6390 and WCN6855") is to fix firmware crash by changing the WMI
    command sequence, but actually skip all the peer delete operation, then
    it lead commit 58595c9874c6 ("ath11k: Fixing dangling pointer issue upon
    peer delete failure") not take effect, and then happened a use-after-free
    warning from KASAN. because the peer->sta is not set to NULL and then used
    later.
    
    Change to only skip the WMI_PEER_DELETE_CMDID for QCA6390/WCN6855.
    
    log of user-after-free:
    
    [  534.888665] BUG: KASAN: use-after-free in ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888696] Read of size 8 at addr ffff8881396bb1b8 by task rtcwake/2860
    
    [  534.888705] CPU: 4 PID: 2860 Comm: rtcwake Kdump: loaded Tainted: G        W         5.15.0-wt-ath+ #523
    [  534.888712] Hardware name: Intel(R) Client Systems NUC8i7HVK/NUC8i7HVB, BIOS HNKBLi70.86A.0067.2021.0528.1339 05/28/2021
    [  534.888716] Call Trace:
    [  534.888720]  <IRQ>
    [  534.888726]  dump_stack_lvl+0x57/0x7d
    [  534.888736]  print_address_description.constprop.0+0x1f/0x170
    [  534.888745]  ? ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888771]  kasan_report.cold+0x83/0xdf
    [  534.888783]  ? ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888810]  ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888840]  ath11k_dp_rx_process_mon_status+0x529/0xa70 [ath11k]
    [  534.888874]  ? ath11k_dp_rx_mon_status_bufs_replenish+0x3f0/0x3f0 [ath11k]
    [  534.888897]  ? check_prev_add+0x20f0/0x20f0
    [  534.888922]  ? __lock_acquire+0xb72/0x1870
    [  534.888937]  ? find_held_lock+0x33/0x110
    [  534.888954]  ath11k_dp_rx_process_mon_rings+0x297/0x520 [ath11k]
    [  534.888981]  ? rcu_read_unlock+0x40/0x40
    [  534.888990]  ? ath11k_dp_rx_pdev_alloc+0xd90/0xd90 [ath11k]
    [  534.889026]  ath11k_dp_service_mon_ring+0x67/0xe0 [ath11k]
    [  534.889053]  ? ath11k_dp_rx_process_mon_rings+0x520/0x520 [ath11k]
    [  534.889075]  call_timer_fn+0x167/0x4a0
    [  534.889084]  ? add_timer_on+0x3b0/0x3b0
    [  534.889103]  ? lockdep_hardirqs_on_prepare.part.0+0x18c/0x370
    [  534.889117]  __run_timers.part.0+0x539/0x8b0
    [  534.889123]  ? ath11k_dp_rx_process_mon_rings+0x520/0x520 [ath11k]
    [  534.889157]  ? call_timer_fn+0x4a0/0x4a0
    [  534.889164]  ? mark_lock_irq+0x1c30/0x1c30
    [  534.889173]  ? clockevents_program_event+0xdd/0x280
    [  534.889189]  ? mark_held_locks+0xa5/0xe0
    [  534.889203]  run_timer_softirq+0x97/0x180
    [  534.889213]  __do_softirq+0x276/0x86a
    [  534.889230]  __irq_exit_rcu+0x11c/0x180
    [  534.889238]  irq_exit_rcu+0x5/0x20
    [  534.889244]  sysvec_apic_timer_interrupt+0x8e/0xc0
    [  534.889251]  </IRQ>
    [  534.889254]  <TASK>
    [  534.889259]  asm_sysvec_apic_timer_interrupt+0x12/0x20
    [  534.889265] RIP: 0010:_raw_spin_unlock_irqrestore+0x38/0x70
    [  534.889271] Code: 74 24 10 e8 ea c2 bf fd 48 89 ef e8 12 53 c0 fd 81 e3 00 02 00 00 75 25 9c 58 f6 c4 02 75 2d 48 85 db 74 01 fb bf 01 00 00 00 <e8> 13 a7 b5 fd 65 8b 05 cc d9 9c 5e 85 c0 74 0a 5b 5d c3 e8 a0 ee
    [  534.889276] RSP: 0018:ffffc90002e5f880 EFLAGS: 00000206
    [  534.889284] RAX: 0000000000000006 RBX: 0000000000000200 RCX: ffffffff9f256f10
    [  534.889289] RDX: 0000000000000000 RSI: ffffffffa1c6e420 RDI: 0000000000000001
    [  534.889293] RBP: ffff8881095e6200 R08: 0000000000000001 R09: ffffffffa40d2b8f
    [  534.889298] R10: fffffbfff481a571 R11: 0000000000000001 R12: ffff8881095e6e68
    [  534.889302] R13: ffffc90002e5f908 R14: 0000000000000246 R15: 0000000000000000
    [  534.889316]  ? mark_lock+0xd0/0x14a0
    [  534.889332]  klist_next+0x1d4/0x450
    [  534.889340]  ? dpm_wait_for_subordinate+0x2d0/0x2d0
    [  534.889350]  device_for_each_child+0xa8/0x140
    [  534.889360]  ? device_remove_class_symlinks+0x1b0/0x1b0
    [  534.889370]  ? __lock_release+0x4bd/0x9f0
    [  534.889378]  ? dpm_suspend+0x26b/0x3f0
    [  534.889390]  dpm_wait_for_subordinate+0x82/0x2d0
    [  534.889400]  ? dpm_for_each_dev+0xa0/0xa0
    [  534.889410]  ? dpm_suspend+0x233/0x3f0
    [  534.889427]  __device_suspend+0xd4/0x10c0
    [  534.889440]  ? wait_for_completion_io+0x270/0x270
    [  534.889456]  ? async_suspend_late+0xe0/0xe0
    [  534.889463]  ? async_schedule_node_domain+0x468/0x640
    [  534.889482]  dpm_suspend+0x25a/0x3f0
    [  534.889491]  ? dpm_suspend_end+0x1a0/0x1a0
    [  534.889497]  ? ktime_get+0x214/0x2f0
    [  534.889502]  ? lockdep_hardirqs_on+0x79/0x100
    [  534.889509]  ? recalibrate_cpu_khz+0x10/0x10
    [  534.889516]  ? ktime_get+0x119/0x2f0
    [  534.889528]  dpm_suspend_start+0xab/0xc0
    [  534.889538]  suspend_devices_and_enter+0x1ca/0x350
    [  534.889546]  ? suspend_enter+0x850/0x850
    [  534.889566]  enter_state+0x27c/0x3d7
    [  534.889575]  pm_suspend.cold+0x42/0x189
    [  534.889583]  state_store+0xab/0x160
    [  534.889595]  ? sysfs_file_ops+0x160/0x160
    [  534.889601]  kernfs_fop_write_iter+0x2b5/0x450
    [  534.889615]  new_sync_write+0x36a/0x600
    [  534.889625]  ? new_sync_read+0x600/0x600
    [  534.889639]  ? rcu_read_unlock+0x40/0x40
    [  534.889668]  vfs_write+0x619/0x910
    [  534.889681]  ksys_write+0xf4/0x1d0
    [  534.889689]  ? __ia32_sys_read+0xa0/0xa0
    [  534.889699]  ? lockdep_hardirqs_on_prepare.part.0+0x18c/0x370
    [  534.889707]  ? syscall_enter_from_user_mode+0x1d/0x50
    [  534.889719]  do_syscall_64+0x3b/0x90
    [  534.889725]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  534.889731] RIP: 0033:0x7f0b9bc931e7
    [  534.889736] Code: 64 89 02 48 c7 c0 ff ff ff ff eb bb 0f 1f 80 00 00 00 00 f3 0f 1e fa 64 8b 04 25 18 00 00 00 85 c0 75 10 b8 01 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 51 c3 48 83 ec 28 48 89 54 24 18 48 89 74 24
    [  534.889741] RSP: 002b:00007ffd9d34cc88 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
    [  534.889749] RAX: ffffffffffffffda RBX: 0000000000000004 RCX: 00007f0b9bc931e7
    [  534.889753] RDX: 0000000000000004 RSI: 0000561cd023c5f0 RDI: 0000000000000004
    [  534.889757] RBP: 0000561cd023c5f0 R08: 0000000000000000 R09: 0000000000000004
    [  534.889761] R10: 0000561ccef842a6 R11: 0000000000000246 R12: 0000000000000004
    [  534.889765] R13: 0000561cd0239590 R14: 00007f0b9bd6f4a0 R15: 00007f0b9bd6e8a0
    [  534.889789]  </TASK>
    
    [  534.889796] Allocated by task 2711:
    [  534.889800]  kasan_save_stack+0x1b/0x40
    [  534.889805]  __kasan_kmalloc+0x7c/0x90
    [  534.889810]  sta_info_alloc+0x98/0x1ef0 [mac80211]
    [  534.889874]  ieee80211_prep_connection+0x30b/0x11e0 [mac80211]
    [  534.889950]  ieee80211_mgd_auth+0x529/0xe00 [mac80211]
    [  534.890024]  cfg80211_mlme_auth+0x332/0x6f0 [cfg80211]
    [  534.890090]  nl80211_authenticate+0x839/0xcf0 [cfg80211]
    [  534.890147]  genl_family_rcv_msg_doit+0x1f4/0x2f0
    [  534.890154]  genl_rcv_msg+0x280/0x500
    [  534.890160]  netlink_rcv_skb+0x11c/0x340
    [  534.890165]  genl_rcv+0x1f/0x30
    [  534.890170]  netlink_unicast+0x42b/0x700
    [  534.890176]  netlink_sendmsg+0x71b/0xc60
    [  534.890181]  sock_sendmsg+0xdf/0x110
    [  534.890187]  ____sys_sendmsg+0x5c0/0x850
    [  534.890192]  ___sys_sendmsg+0xe4/0x160
    [  534.890197]  __sys_sendmsg+0xb2/0x140
    [  534.890202]  do_syscall_64+0x3b/0x90
    [  534.890207]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    [  534.890215] Freed by task 2825:
    [  534.890218]  kasan_save_stack+0x1b/0x40
    [  534.890223]  kasan_set_track+0x1c/0x30
    [  534.890227]  kasan_set_free_info+0x20/0x30
    [  534.890232]  __kasan_slab_free+0xce/0x100
    [  534.890237]  slab_free_freelist_hook+0xf0/0x1a0
    [  534.890242]  kfree+0xe5/0x370
    [  534.890248]  __sta_info_flush+0x333/0x4b0 [mac80211]
    [  534.890308]  ieee80211_set_disassoc+0x324/0xd20 [mac80211]
    [  534.890382]  ieee80211_mgd_deauth+0x537/0xee0 [mac80211]
    [  534.890472]  cfg80211_mlme_deauth+0x349/0x810 [cfg80211]
    [  534.890526]  cfg80211_mlme_down+0x1ce/0x270 [cfg80211]
    [  534.890578]  cfg80211_disconnect+0x4f5/0x7b0 [cfg80211]
    [  534.890631]  cfg80211_leave+0x24/0x40 [cfg80211]
    [  534.890677]  wiphy_suspend+0x23d/0x2f0 [cfg80211]
    [  534.890723]  dpm_run_callback+0xf4/0x1b0
    [  534.890728]  __device_suspend+0x648/0x10c0
    [  534.890733]  async_suspend+0x16/0xe0
    [  534.890737]  async_run_entry_fn+0x90/0x4f0
    [  534.890741]  process_one_work+0x866/0x1490
    [  534.890747]  worker_thread+0x596/0x1010
    [  534.890751]  kthread+0x35d/0x420
    [  534.890756]  ret_from_fork+0x22/0x30
    
    [  534.890763] The buggy address belongs to the object at ffff8881396ba000
                    which belongs to the cache kmalloc-8k of size 8192
    [  534.890767] The buggy address is located 4536 bytes inside of
                    8192-byte region [ffff8881396ba000, ffff8881396bc000)
    [  534.890772] The buggy address belongs to the page:
    [  534.890775] page:ffffea0004e5ae00 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x1396b8
    [  534.890780] head:ffffea0004e5ae00 order:3 compound_mapcount:0 compound_pincount:0
    [  534.890784] flags: 0x200000000010200(slab|head|node=0|zone=2)
    [  534.890791] raw: 0200000000010200 ffffea000562be08 ffffea0004b04c08 ffff88810004e340
    [  534.890795] raw: 0000000000000000 0000000000010001 00000001ffffffff 0000000000000000
    [  534.890798] page dumped because: kasan: bad access detected
    
    [  534.890804] Memory state around the buggy address:
    [  534.890807]  ffff8881396bb080: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890811]  ffff8881396bb100: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890814] >ffff8881396bb180: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890817]                                         ^
    [  534.890821]  ffff8881396bb200: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890824]  ffff8881396bb280: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890827] ==================================================================
    [  534.890830] Disabling lock debugging due to kernel taint
    
    Tested-on: WCN6855 hw2.0 PCI WLAN.HSP.1.1-01720.1-QCAHSPSWPL_V1_V2_SILICONZ_LITE-1
    
    Fixes: b4a0f54156ac ("ath11k: move peer delete after vdev stop of station for QCA6390 and WCN6855")
    Signed-off-by: Wen Gong <quic_wgong@quicinc.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20211222070431.29595-1-quic_wgong@quicinc.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1ebdbeb03efe89f01f15df038a589077df3d21f5
Merge: efee6c79298f c9b8fecddb5b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Mar 24 11:58:57 2022 -0700

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull kvm updates from Paolo Bonzini:
     "ARM:
       - Proper emulation of the OSLock feature of the debug architecture
    
       - Scalibility improvements for the MMU lock when dirty logging is on
    
       - New VMID allocator, which will eventually help with SVA in VMs
    
       - Better support for PMUs in heterogenous systems
    
       - PSCI 1.1 support, enabling support for SYSTEM_RESET2
    
       - Implement CONFIG_DEBUG_LIST at EL2
    
       - Make CONFIG_ARM64_ERRATUM_2077057 default y
    
       - Reduce the overhead of VM exit when no interrupt is pending
    
       - Remove traces of 32bit ARM host support from the documentation
    
       - Updated vgic selftests
    
       - Various cleanups, doc updates and spelling fixes
    
      RISC-V:
       - Prevent KVM_COMPAT from being selected
    
       - Optimize __kvm_riscv_switch_to() implementation
    
       - RISC-V SBI v0.3 support
    
      s390:
       - memop selftest
    
       - fix SCK locking
    
       - adapter interruptions virtualization for secure guests
    
       - add Claudio Imbrenda as maintainer
    
       - first step to do proper storage key checking
    
      x86:
       - Continue switching kvm_x86_ops to static_call(); introduce
         static_call_cond() and __static_call_ret0 when applicable.
    
       - Cleanup unused arguments in several functions
    
       - Synthesize AMD 0x80000021 leaf
    
       - Fixes and optimization for Hyper-V sparse-bank hypercalls
    
       - Implement Hyper-V's enlightened MSR bitmap for nested SVM
    
       - Remove MMU auditing
    
       - Eager splitting of page tables (new aka "TDP" MMU only) when dirty
         page tracking is enabled
    
       - Cleanup the implementation of the guest PGD cache
    
       - Preparation for the implementation of Intel IPI virtualization
    
       - Fix some segment descriptor checks in the emulator
    
       - Allow AMD AVIC support on systems with physical APIC ID above 255
    
       - Better API to disable virtualization quirks
    
       - Fixes and optimizations for the zapping of page tables:
    
          - Zap roots in two passes, avoiding RCU read-side critical
            sections that last too long for very large guests backed by 4
            KiB SPTEs.
    
          - Zap invalid and defunct roots asynchronously via
            concurrency-managed work queue.
    
          - Allowing yielding when zapping TDP MMU roots in response to the
            root's last reference being put.
    
          - Batch more TLB flushes with an RCU trick. Whoever frees the
            paging structure now holds RCU as a proxy for all vCPUs running
            in the guest, i.e. to prolongs the grace period on their behalf.
            It then kicks the the vCPUs out of guest mode before doing
            rcu_read_unlock().
    
      Generic:
       - Introduce __vcalloc and use it for very large allocations that need
         memcg accounting"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (246 commits)
      KVM: use kvcalloc for array allocations
      KVM: x86: Introduce KVM_CAP_DISABLE_QUIRKS2
      kvm: x86: Require const tsc for RT
      KVM: x86: synthesize CPUID leaf 0x80000021h if useful
      KVM: x86: add support for CPUID leaf 0x80000021
      KVM: x86: do not use KVM_X86_OP_OPTIONAL_RET0 for get_mt_mask
      Revert "KVM: x86/mmu: Zap only TDP MMU leafs in kvm_zap_gfn_range()"
      kvm: x86/mmu: Flush TLB before zap_gfn_range releases RCU
      KVM: arm64: fix typos in comments
      KVM: arm64: Generalise VM features into a set of flags
      KVM: s390: selftests: Add error memop tests
      KVM: s390: selftests: Add more copy memop tests
      KVM: s390: selftests: Add named stages for memop test
      KVM: s390: selftests: Add macro as abstraction for MEM_OP
      KVM: s390: selftests: Split memop tests
      KVM: s390x: fix SCK locking
      RISC-V: KVM: Implement SBI HSM suspend call
      RISC-V: KVM: Add common kvm_riscv_vcpu_wfi() function
      RISC-V: Add SBI HSM suspend related defines
      RISC-V: KVM: Implement SBI v0.3 SRST extension
      ...

commit d76e75586ddc266bc80867866adb0c2da97c28a2
Author: Nicolas Saenz Julienne <nsaenzju@redhat.com>
Date:   Mon Mar 7 19:07:40 2022 +0100

    tracing/osnoise: Force quiescent states while tracing
    
    commit caf4c86bf136845982c5103b2661751b40c474c0 upstream.
    
    At the moment running osnoise on a nohz_full CPU or uncontested FIFO
    priority and a PREEMPT_RCU kernel might have the side effect of
    extending grace periods too much. This will entice RCU to force a
    context switch on the wayward CPU to end the grace period, all while
    introducing unwarranted noise into the tracer. This behaviour is
    unavoidable as overly extending grace periods might exhaust the system's
    memory.
    
    This same exact problem is what extended quiescent states (EQS) were
    created for, conversely, rcu_momentary_dyntick_idle() emulates them by
    performing a zero duration EQS. So let's make use of it.
    
    In the common case rcu_momentary_dyntick_idle() is fairly inexpensive:
    atomically incrementing a local per-CPU counter and doing a store. So it
    shouldn't affect osnoise's measurements (which has a 1us granularity),
    so we'll call it unanimously.
    
    The uncommon case involve calling rcu_momentary_dyntick_idle() after
    having the osnoise process:
    
     - Receive an expedited quiescent state IPI with preemption disabled or
       during an RCU critical section. (activates rdp->cpu_no_qs.b.exp
       code-path).
    
     - Being preempted within in an RCU critical section and having the
       subsequent outermost rcu_read_unlock() called with interrupts
       disabled. (t->rcu_read_unlock_special.b.blocked code-path).
    
    Neither of those are possible at the moment, and are unlikely to be in
    the future given the osnoise's loop design. On top of this, the noise
    generated by the situations described above is unavoidable, and if not
    exposed by rcu_momentary_dyntick_idle() will be eventually seen in
    subsequent rcu_read_unlock() calls or schedule operations.
    
    Link: https://lkml.kernel.org/r/20220307180740.577607-1-nsaenzju@redhat.com
    
    Cc: stable@vger.kernel.org
    Fixes: bce29ac9ce0b ("trace: Add osnoise tracer")
    Signed-off-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Acked-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 42aaf726c9e9e42521b05d2c5f8e4682efca6835
Author: Nicolas Saenz Julienne <nsaenzju@redhat.com>
Date:   Mon Mar 7 19:07:40 2022 +0100

    tracing/osnoise: Force quiescent states while tracing
    
    commit caf4c86bf136845982c5103b2661751b40c474c0 upstream.
    
    At the moment running osnoise on a nohz_full CPU or uncontested FIFO
    priority and a PREEMPT_RCU kernel might have the side effect of
    extending grace periods too much. This will entice RCU to force a
    context switch on the wayward CPU to end the grace period, all while
    introducing unwarranted noise into the tracer. This behaviour is
    unavoidable as overly extending grace periods might exhaust the system's
    memory.
    
    This same exact problem is what extended quiescent states (EQS) were
    created for, conversely, rcu_momentary_dyntick_idle() emulates them by
    performing a zero duration EQS. So let's make use of it.
    
    In the common case rcu_momentary_dyntick_idle() is fairly inexpensive:
    atomically incrementing a local per-CPU counter and doing a store. So it
    shouldn't affect osnoise's measurements (which has a 1us granularity),
    so we'll call it unanimously.
    
    The uncommon case involve calling rcu_momentary_dyntick_idle() after
    having the osnoise process:
    
     - Receive an expedited quiescent state IPI with preemption disabled or
       during an RCU critical section. (activates rdp->cpu_no_qs.b.exp
       code-path).
    
     - Being preempted within in an RCU critical section and having the
       subsequent outermost rcu_read_unlock() called with interrupts
       disabled. (t->rcu_read_unlock_special.b.blocked code-path).
    
    Neither of those are possible at the moment, and are unlikely to be in
    the future given the osnoise's loop design. On top of this, the noise
    generated by the situations described above is unavoidable, and if not
    exposed by rcu_momentary_dyntick_idle() will be eventually seen in
    subsequent rcu_read_unlock() calls or schedule operations.
    
    Link: https://lkml.kernel.org/r/20220307180740.577607-1-nsaenzju@redhat.com
    
    Cc: stable@vger.kernel.org
    Fixes: bce29ac9ce0b ("trace: Add osnoise tracer")
    Signed-off-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Acked-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit caf4c86bf136845982c5103b2661751b40c474c0
Author: Nicolas Saenz Julienne <nsaenzju@redhat.com>
Date:   Mon Mar 7 19:07:40 2022 +0100

    tracing/osnoise: Force quiescent states while tracing
    
    At the moment running osnoise on a nohz_full CPU or uncontested FIFO
    priority and a PREEMPT_RCU kernel might have the side effect of
    extending grace periods too much. This will entice RCU to force a
    context switch on the wayward CPU to end the grace period, all while
    introducing unwarranted noise into the tracer. This behaviour is
    unavoidable as overly extending grace periods might exhaust the system's
    memory.
    
    This same exact problem is what extended quiescent states (EQS) were
    created for, conversely, rcu_momentary_dyntick_idle() emulates them by
    performing a zero duration EQS. So let's make use of it.
    
    In the common case rcu_momentary_dyntick_idle() is fairly inexpensive:
    atomically incrementing a local per-CPU counter and doing a store. So it
    shouldn't affect osnoise's measurements (which has a 1us granularity),
    so we'll call it unanimously.
    
    The uncommon case involve calling rcu_momentary_dyntick_idle() after
    having the osnoise process:
    
     - Receive an expedited quiescent state IPI with preemption disabled or
       during an RCU critical section. (activates rdp->cpu_no_qs.b.exp
       code-path).
    
     - Being preempted within in an RCU critical section and having the
       subsequent outermost rcu_read_unlock() called with interrupts
       disabled. (t->rcu_read_unlock_special.b.blocked code-path).
    
    Neither of those are possible at the moment, and are unlikely to be in
    the future given the osnoise's loop design. On top of this, the noise
    generated by the situations described above is unavoidable, and if not
    exposed by rcu_momentary_dyntick_idle() will be eventually seen in
    subsequent rcu_read_unlock() calls or schedule operations.
    
    Link: https://lkml.kernel.org/r/20220307180740.577607-1-nsaenzju@redhat.com
    
    Cc: stable@vger.kernel.org
    Fixes: bce29ac9ce0b ("trace: Add osnoise tracer")
    Signed-off-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Acked-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>

commit e9c478014b602fda2a99a6370d9eb2e5d7355246
Author: Damien Le Moal <damien.lemoal@opensource.wdc.com>
Date:   Tue Mar 1 20:30:08 2022 +0900

    scsi: scsi_debug: Silence unexpected unlock warnings
    
    The return statement inside the sdeb_read_lock(), sdeb_read_unlock(),
    sdeb_write_lock() and sdeb_write_unlock() confuse sparse, leading to many
    warnings about unexpected unlocks in the resp_xxx() functions.
    
    Modify the lock/unlock functions using the __acquire() and __release()
    inline annotations for the sdebug_no_rwlock == true case to avoid these
    warnings.
    
    Link: https://lore.kernel.org/r/20220301113009.595857-2-damien.lemoal@opensource.wdc.com
    Acked-by: Douglas Gilbert <dgilbert@interlog.com>
    Signed-off-by: Damien Le Moal <damien.lemoal@opensource.wdc.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

commit dc121c0084910db985cf1c8ba6fce5d8c307cc02
Author: Matt Johnston <matt@codeconstruct.com.au>
Date:   Tue Feb 22 12:17:38 2022 +0800

    mctp: make __mctp_dev_get() take a refcount hold
    
    Previously there was a race that could allow the mctp_dev refcount
    to hit zero:
    
    rcu_read_lock();
    mdev = __mctp_dev_get(dev);
    // mctp_unregister() happens here, mdev->refs hits zero
    mctp_dev_hold(dev);
    rcu_read_unlock();
    
    Now we make __mctp_dev_get() take the hold itself. It is safe to test
    against the zero refcount because __mctp_dev_get() is called holding
    rcu_read_lock and mctp_dev uses kfree_rcu().
    
    Reported-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Matt Johnston <matt@codeconstruct.com.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 657991fb06a4a1e423d1e9e82514dd35b8caccd8
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Oct 30 13:11:24 2020 -0700

    rcu: Do not report strict GPs for outgoing CPUs
    
    commit bfb3aa735f82c8d98b32a669934ee7d6b346264d upstream.
    
    An outgoing CPU is marked offline in a stop-machine handler and most
    of that CPU's services stop at that point, including IRQ work queues.
    However, that CPU must take another pass through the scheduler and through
    a number of CPU-hotplug notifiers, many of which contain RCU readers.
    In the past, these readers were not a problem because the outgoing CPU
    has interrupts disabled, so that rcu_read_unlock_special() would not
    be invoked, and thus RCU would never attempt to queue IRQ work on the
    outgoing CPU.
    
    This changed with the advent of the CONFIG_RCU_STRICT_GRACE_PERIOD
    Kconfig option, in which rcu_read_unlock_special() is invoked upon exit
    from almost all RCU read-side critical sections.  Worse yet, because
    interrupts are disabled, rcu_read_unlock_special() cannot immediately
    report a quiescent state and will therefore attempt to defer this
    reporting, for example, by queueing IRQ work.  Which fails with a splat
    because the CPU is already marked as being offline.
    
    But it turns out that there is no need to report this quiescent state
    because rcu_report_dead() will do this job shortly after the outgoing
    CPU makes its final dive into the idle loop.  This commit therefore
    makes rcu_read_unlock_special() refrain from queuing IRQ work onto
    outgoing CPUs.
    
    Fixes: 44bad5b3cca2 ("rcu: Do full report for .need_qs for strict GPs")
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Cc: Jann Horn <jannh@google.com>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 80b3fd474c91b3ecfd845b4a0bfb58706b877ba5
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Dec 14 13:35:17 2021 -0800

    rcu: Make rcu_barrier() no longer block CPU-hotplug operations
    
    This commit removes the cpus_read_lock() and cpus_read_unlock() calls
    from rcu_barrier(), thus allowing CPUs to come and go during the course
    of rcu_barrier() execution.  Posting of the ->barrier_head callbacks does
    synchronize with portions of RCU's CPU-hotplug notifiers, but these locks
    are held for short time periods on both sides.  Thus, full CPU-hotplug
    operations could both start and finish during the execution of a given
    rcu_barrier() invocation.
    
    Additional synchronization is provided by a global ->barrier_lock.
    Since the ->barrier_lock is only used during rcu_barrier() execution and
    during onlining/offlining a CPU, the contention for this lock should
    be low.  It might be tempting to make use of a per-CPU lock just on
    general principles, but straightforward attempts to do this have the
    problems shown below.
    
    Initial state: 3 CPUs present, CPU 0 and CPU1 do not have
    any callback and CPU2 has callbacks.
    
    1. CPU0 calls rcu_barrier().
    
    2. CPU1 starts offlining for CPU2. CPU1 calls
       rcutree_migrate_callbacks(). rcu_barrier_entrain() is called
       from rcutree_migrate_callbacks(), with CPU2's rdp->barrier_lock.
       It does not entrain ->barrier_head for CPU2, as rcu_barrier()
       on CPU0 hasn't started the barrier sequence (by calling
       rcu_seq_start(&rcu_state.barrier_sequence)) yet.
    
    3. CPU0 starts new barrier sequence. It iterates over
       CPU0 and CPU1, after acquiring their per-cpu ->barrier_lock
       and finds 0 segcblist length. It updates ->barrier_seq_snap
       for CPU0 and CPU1 and continues loop iteration to CPU2.
    
        for_each_possible_cpu(cpu) {
            raw_spin_lock_irqsave(&rdp->barrier_lock, flags);
            if (!rcu_segcblist_n_cbs(&rdp->cblist)) {
                WRITE_ONCE(rdp->barrier_seq_snap, gseq);
                raw_spin_unlock_irqrestore(&rdp->barrier_lock, flags);
                rcu_barrier_trace(TPS("NQ"), cpu, rcu_state.barrier_sequence);
                continue;
            }
    
    4. rcutree_migrate_callbacks() completes execution on CPU1.
       Segcblist len for CPU2 becomes 0.
    
    5. The loop iteration on CPU0, checks rcu_segcblist_n_cbs(&rdp->cblist)
       for CPU2 and completes the loop iteration after setting
       ->barrier_seq_snap.
    
    6. As there isn't any ->barrier_head callback entrained; at
       this point, rcu_barrier() in CPU0 returns.
    
    7. The callbacks, which migrated from CPU2 to CPU1, execute.
    
    Straightforward per-CPU locking is also subject to the following race
    condition noted by Boqun Feng:
    
    1. CPU0 calls rcu_barrier(), starting a new barrier sequence by invoking
       rcu_seq_start() and init_completion(), but does not yet initialize
       rcu_state.barrier_cpu_count.
    
    2. CPU1 starts offlining for CPU2, calling rcutree_migrate_callbacks(),
       which in turn calls rcu_barrier_entrain() holding CPU2's.
       rdp->barrier_lock.  It then entrains ->barrier_head for CPU2
       and atomically increments rcu_state.barrier_cpu_count, which is
       unfortunately not yet initialized to the value 2.
    
    3. The just-entrained RCU callback is invoked.  It atomically
       decrements rcu_state.barrier_cpu_count and sees that it is
       now zero.  This callback therefore invokes complete().
    
    4. CPU0 continues executing rcu_barrier(), but is not blocked
       by its call to wait_for_completion().  This results in rcu_barrier()
       returning before all pre-existing callbacks have been invoked,
       which is a bug.
    
    Therefore, synchronization is provided by rcu_state.barrier_lock,
    which is also held across the initialization sequence, especially the
    rcu_seq_start() and the atomic_set() that sets rcu_state.barrier_cpu_count
    to the value 2.  In addition, this lock is held when entraining the
    rcu_barrier() callback, when deciding whether or not a CPU has callbacks
    that rcu_barrier() must wait on, when setting the ->qsmaskinitnext for
    incoming CPUs, and when migrating callbacks from a CPU that is going
    offline.
    
    Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
    Co-developed-by: Neeraj Upadhyay <quic_neeraju@quicinc.com>
    Signed-off-by: Neeraj Upadhyay <quic_neeraju@quicinc.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit a16578dd5e3a44b53ca0699ac2971679dab97484
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Dec 14 13:15:18 2021 -0800

    rcu: Rework rcu_barrier() and callback-migration logic
    
    This commit reworks rcu_barrier() and callback-migration logic to
    permit allowing rcu_barrier() to run concurrently with CPU-hotplug
    operations.  The key trick is for callback migration to check to see if
    an rcu_barrier() is in flight, and, if so, enqueue the ->barrier_head
    callback on its behalf.
    
    This commit adds synchronization with RCU's CPU-hotplug notifiers.  Taken
    together, this will permit a later commit to remove the cpus_read_lock()
    and cpus_read_unlock() calls from rcu_barrier().
    
    [ paulmck: Updated per kbuild test robot feedback. ]
    [ paulmck: Updated per reviews session with Neeraj, Frederic, Uladzislau, and Boqun. ]
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 215a90ce3754fe509efbce6b73a4bb643c7e7528
Author: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Date:   Wed Jul 21 01:48:29 2021 -0400

    powerpc/perf: Fix PMU callbacks to clear pending PMI before resetting an overflown PMC
    
    [ Upstream commit 2c9ac51b850d84ee496b0a5d832ce66d411ae552 ]
    
    Running perf fuzzer showed below in dmesg logs:
      "Can't find PMC that caused IRQ"
    
    This means a PMU exception happened, but none of the PMC's (Performance
    Monitor Counter) were found to be overflown. There are some corner cases
    that clears the PMCs after PMI gets masked. In such cases, the perf
    interrupt handler will not find the active PMC values that had caused
    the overflow and thus leads to this message while replaying.
    
    Case 1: PMU Interrupt happens during replay of other interrupts and
    counter values gets cleared by PMU callbacks before replay:
    
    During replay of interrupts like timer, __do_irq() and doorbell
    exception, we conditionally enable interrupts via may_hard_irq_enable().
    This could potentially create a window to generate a PMI. Since irq soft
    mask is set to ALL_DISABLED, the PMI will get masked here. We could get
    IPIs run before perf interrupt is replayed and the PMU events could
    be deleted or stopped. This will change the PMU SPR values and resets
    the counters. Snippet of ftrace log showing PMU callbacks invoked in
    __do_irq():
    
      <idle>-0 [051] dns. 132025441306354: __do_irq <-call_do_irq
      <idle>-0 [051] dns. 132025441306430: irq_enter <-__do_irq
      <idle>-0 [051] dns. 132025441306503: irq_enter_rcu <-__do_irq
      <idle>-0 [051] dnH. 132025441306599: xive_get_irq <-__do_irq
      <<>>
      <idle>-0 [051] dnH. 132025441307770: generic_smp_call_function_single_interrupt <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441307839: flush_smp_call_function_queue <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441308057: _raw_spin_lock <-event_function
      <idle>-0 [051] dnH. 132025441308206: power_pmu_disable <-perf_pmu_disable
      <idle>-0 [051] dnH. 132025441308337: power_pmu_del <-event_sched_out
      <idle>-0 [051] dnH. 132025441308407: power_pmu_read <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308477: read_pmc <-power_pmu_read
      <idle>-0 [051] dnH. 132025441308590: isa207_disable_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308663: write_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308787: power_pmu_event_idx <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308859: rcu_read_unlock_strict <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308975: power_pmu_enable <-perf_pmu_enable
      <<>>
      <idle>-0 [051] dnH. 132025441311108: irq_exit <-__do_irq
      <idle>-0 [051] dns. 132025441311319: performance_monitor_exception <-replay_soft_interrupts
    
    Case 2: PMI's masked during local_* operations, example local_add(). If
    the local_add() operation happens within a local_irq_save(), replay of
    PMI will be during local_irq_restore(). Similar to case 1, this could
    also create a window before replay where PMU events gets deleted or
    stopped.
    
    Fix it by updating the PMU callback function power_pmu_disable() to
    check for pending perf interrupt. If there is an overflown PMC and
    pending perf interrupt indicated in paca, clear the PMI bit in paca to
    drop that sample. Clearing of PMI bit is done in power_pmu_disable()
    since disable is invoked before any event gets deleted/stopped. With
    this fix, if there are more than one event running in the PMU, there is
    a chance that we clear the PMI bit for the event which is not getting
    deleted/stopped. The other events may still remain active. Hence to make
    sure we don't drop valid sample in such cases, another check is added in
    power_pmu_enable. This checks if there is an overflown PMC found among
    the active events and if so enable back the PMI bit. Two new helper
    functions are introduced to clear/set the PMI, ie
    clear_pmi_irq_pending() and set_pmi_irq_pending(). Helper function
    pmi_irq_pending() is introduced to give a warning if there is pending
    PMI bit in paca, but no PMC is overflown.
    
    Also there are corner cases which result in performance monitor
    interrupts being triggered during power_pmu_disable(). This happens
    since PMXE bit is not cleared along with disabling of other MMCR0 bits
    in the pmu_disable. Such PMI's could leave the PMU running and could
    trigger PMI again which will set MMCR0 PMAO bit. This could lead to
    spurious interrupts in some corner cases. Example, a timer after
    power_pmu_del() which will re-enable interrupts and triggers a PMI again
    since PMAO bit is still set. But fails to find valid overflow since PMC
    was cleared in power_pmu_del(). Fix that by disabling PMXE along with
    disabling of other MMCR0 bits in power_pmu_disable().
    
    We can't just replay PMI any time. Hence this approach is preferred
    rather than replaying PMI before resetting overflown PMC. Patch also
    documents core-book3s on a race condition which can trigger these PMC
    messages during idle path in PowerNV.
    
    Fixes: f442d004806e ("powerpc/64s: Add support to mask perf interrupts and replay them")
    Reported-by: Nageswara R Sastry <nasastry@in.ibm.com>
    Suggested-by: Nicholas Piggin <npiggin@gmail.com>
    Suggested-by: Madhavan Srinivasan <maddy@linux.ibm.com>
    Signed-off-by: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
    Tested-by: Nageswara R Sastry <rnsastry@linux.ibm.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make pmi_irq_pending() return bool, reflow/reword some comments]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1626846509-1350-2-git-send-email-atrajeev@linux.vnet.ibm.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fadcafa3959281ce2d96feedece8c75c3f95f8a5
Author: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Date:   Wed Jul 21 01:48:29 2021 -0400

    powerpc/perf: Fix PMU callbacks to clear pending PMI before resetting an overflown PMC
    
    [ Upstream commit 2c9ac51b850d84ee496b0a5d832ce66d411ae552 ]
    
    Running perf fuzzer showed below in dmesg logs:
      "Can't find PMC that caused IRQ"
    
    This means a PMU exception happened, but none of the PMC's (Performance
    Monitor Counter) were found to be overflown. There are some corner cases
    that clears the PMCs after PMI gets masked. In such cases, the perf
    interrupt handler will not find the active PMC values that had caused
    the overflow and thus leads to this message while replaying.
    
    Case 1: PMU Interrupt happens during replay of other interrupts and
    counter values gets cleared by PMU callbacks before replay:
    
    During replay of interrupts like timer, __do_irq() and doorbell
    exception, we conditionally enable interrupts via may_hard_irq_enable().
    This could potentially create a window to generate a PMI. Since irq soft
    mask is set to ALL_DISABLED, the PMI will get masked here. We could get
    IPIs run before perf interrupt is replayed and the PMU events could
    be deleted or stopped. This will change the PMU SPR values and resets
    the counters. Snippet of ftrace log showing PMU callbacks invoked in
    __do_irq():
    
      <idle>-0 [051] dns. 132025441306354: __do_irq <-call_do_irq
      <idle>-0 [051] dns. 132025441306430: irq_enter <-__do_irq
      <idle>-0 [051] dns. 132025441306503: irq_enter_rcu <-__do_irq
      <idle>-0 [051] dnH. 132025441306599: xive_get_irq <-__do_irq
      <<>>
      <idle>-0 [051] dnH. 132025441307770: generic_smp_call_function_single_interrupt <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441307839: flush_smp_call_function_queue <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441308057: _raw_spin_lock <-event_function
      <idle>-0 [051] dnH. 132025441308206: power_pmu_disable <-perf_pmu_disable
      <idle>-0 [051] dnH. 132025441308337: power_pmu_del <-event_sched_out
      <idle>-0 [051] dnH. 132025441308407: power_pmu_read <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308477: read_pmc <-power_pmu_read
      <idle>-0 [051] dnH. 132025441308590: isa207_disable_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308663: write_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308787: power_pmu_event_idx <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308859: rcu_read_unlock_strict <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308975: power_pmu_enable <-perf_pmu_enable
      <<>>
      <idle>-0 [051] dnH. 132025441311108: irq_exit <-__do_irq
      <idle>-0 [051] dns. 132025441311319: performance_monitor_exception <-replay_soft_interrupts
    
    Case 2: PMI's masked during local_* operations, example local_add(). If
    the local_add() operation happens within a local_irq_save(), replay of
    PMI will be during local_irq_restore(). Similar to case 1, this could
    also create a window before replay where PMU events gets deleted or
    stopped.
    
    Fix it by updating the PMU callback function power_pmu_disable() to
    check for pending perf interrupt. If there is an overflown PMC and
    pending perf interrupt indicated in paca, clear the PMI bit in paca to
    drop that sample. Clearing of PMI bit is done in power_pmu_disable()
    since disable is invoked before any event gets deleted/stopped. With
    this fix, if there are more than one event running in the PMU, there is
    a chance that we clear the PMI bit for the event which is not getting
    deleted/stopped. The other events may still remain active. Hence to make
    sure we don't drop valid sample in such cases, another check is added in
    power_pmu_enable. This checks if there is an overflown PMC found among
    the active events and if so enable back the PMI bit. Two new helper
    functions are introduced to clear/set the PMI, ie
    clear_pmi_irq_pending() and set_pmi_irq_pending(). Helper function
    pmi_irq_pending() is introduced to give a warning if there is pending
    PMI bit in paca, but no PMC is overflown.
    
    Also there are corner cases which result in performance monitor
    interrupts being triggered during power_pmu_disable(). This happens
    since PMXE bit is not cleared along with disabling of other MMCR0 bits
    in the pmu_disable. Such PMI's could leave the PMU running and could
    trigger PMI again which will set MMCR0 PMAO bit. This could lead to
    spurious interrupts in some corner cases. Example, a timer after
    power_pmu_del() which will re-enable interrupts and triggers a PMI again
    since PMAO bit is still set. But fails to find valid overflow since PMC
    was cleared in power_pmu_del(). Fix that by disabling PMXE along with
    disabling of other MMCR0 bits in power_pmu_disable().
    
    We can't just replay PMI any time. Hence this approach is preferred
    rather than replaying PMI before resetting overflown PMC. Patch also
    documents core-book3s on a race condition which can trigger these PMC
    messages during idle path in PowerNV.
    
    Fixes: f442d004806e ("powerpc/64s: Add support to mask perf interrupts and replay them")
    Reported-by: Nageswara R Sastry <nasastry@in.ibm.com>
    Suggested-by: Nicholas Piggin <npiggin@gmail.com>
    Suggested-by: Madhavan Srinivasan <maddy@linux.ibm.com>
    Signed-off-by: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
    Tested-by: Nageswara R Sastry <rnsastry@linux.ibm.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make pmi_irq_pending() return bool, reflow/reword some comments]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1626846509-1350-2-git-send-email-atrajeev@linux.vnet.ibm.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ef798cd035f316a537fee8ed170c127f12407085
Author: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Date:   Wed Jul 21 01:48:29 2021 -0400

    powerpc/perf: Fix PMU callbacks to clear pending PMI before resetting an overflown PMC
    
    [ Upstream commit 2c9ac51b850d84ee496b0a5d832ce66d411ae552 ]
    
    Running perf fuzzer showed below in dmesg logs:
      "Can't find PMC that caused IRQ"
    
    This means a PMU exception happened, but none of the PMC's (Performance
    Monitor Counter) were found to be overflown. There are some corner cases
    that clears the PMCs after PMI gets masked. In such cases, the perf
    interrupt handler will not find the active PMC values that had caused
    the overflow and thus leads to this message while replaying.
    
    Case 1: PMU Interrupt happens during replay of other interrupts and
    counter values gets cleared by PMU callbacks before replay:
    
    During replay of interrupts like timer, __do_irq() and doorbell
    exception, we conditionally enable interrupts via may_hard_irq_enable().
    This could potentially create a window to generate a PMI. Since irq soft
    mask is set to ALL_DISABLED, the PMI will get masked here. We could get
    IPIs run before perf interrupt is replayed and the PMU events could
    be deleted or stopped. This will change the PMU SPR values and resets
    the counters. Snippet of ftrace log showing PMU callbacks invoked in
    __do_irq():
    
      <idle>-0 [051] dns. 132025441306354: __do_irq <-call_do_irq
      <idle>-0 [051] dns. 132025441306430: irq_enter <-__do_irq
      <idle>-0 [051] dns. 132025441306503: irq_enter_rcu <-__do_irq
      <idle>-0 [051] dnH. 132025441306599: xive_get_irq <-__do_irq
      <<>>
      <idle>-0 [051] dnH. 132025441307770: generic_smp_call_function_single_interrupt <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441307839: flush_smp_call_function_queue <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441308057: _raw_spin_lock <-event_function
      <idle>-0 [051] dnH. 132025441308206: power_pmu_disable <-perf_pmu_disable
      <idle>-0 [051] dnH. 132025441308337: power_pmu_del <-event_sched_out
      <idle>-0 [051] dnH. 132025441308407: power_pmu_read <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308477: read_pmc <-power_pmu_read
      <idle>-0 [051] dnH. 132025441308590: isa207_disable_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308663: write_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308787: power_pmu_event_idx <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308859: rcu_read_unlock_strict <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308975: power_pmu_enable <-perf_pmu_enable
      <<>>
      <idle>-0 [051] dnH. 132025441311108: irq_exit <-__do_irq
      <idle>-0 [051] dns. 132025441311319: performance_monitor_exception <-replay_soft_interrupts
    
    Case 2: PMI's masked during local_* operations, example local_add(). If
    the local_add() operation happens within a local_irq_save(), replay of
    PMI will be during local_irq_restore(). Similar to case 1, this could
    also create a window before replay where PMU events gets deleted or
    stopped.
    
    Fix it by updating the PMU callback function power_pmu_disable() to
    check for pending perf interrupt. If there is an overflown PMC and
    pending perf interrupt indicated in paca, clear the PMI bit in paca to
    drop that sample. Clearing of PMI bit is done in power_pmu_disable()
    since disable is invoked before any event gets deleted/stopped. With
    this fix, if there are more than one event running in the PMU, there is
    a chance that we clear the PMI bit for the event which is not getting
    deleted/stopped. The other events may still remain active. Hence to make
    sure we don't drop valid sample in such cases, another check is added in
    power_pmu_enable. This checks if there is an overflown PMC found among
    the active events and if so enable back the PMI bit. Two new helper
    functions are introduced to clear/set the PMI, ie
    clear_pmi_irq_pending() and set_pmi_irq_pending(). Helper function
    pmi_irq_pending() is introduced to give a warning if there is pending
    PMI bit in paca, but no PMC is overflown.
    
    Also there are corner cases which result in performance monitor
    interrupts being triggered during power_pmu_disable(). This happens
    since PMXE bit is not cleared along with disabling of other MMCR0 bits
    in the pmu_disable. Such PMI's could leave the PMU running and could
    trigger PMI again which will set MMCR0 PMAO bit. This could lead to
    spurious interrupts in some corner cases. Example, a timer after
    power_pmu_del() which will re-enable interrupts and triggers a PMI again
    since PMAO bit is still set. But fails to find valid overflow since PMC
    was cleared in power_pmu_del(). Fix that by disabling PMXE along with
    disabling of other MMCR0 bits in power_pmu_disable().
    
    We can't just replay PMI any time. Hence this approach is preferred
    rather than replaying PMI before resetting overflown PMC. Patch also
    documents core-book3s on a race condition which can trigger these PMC
    messages during idle path in PowerNV.
    
    Fixes: f442d004806e ("powerpc/64s: Add support to mask perf interrupts and replay them")
    Reported-by: Nageswara R Sastry <nasastry@in.ibm.com>
    Suggested-by: Nicholas Piggin <npiggin@gmail.com>
    Suggested-by: Madhavan Srinivasan <maddy@linux.ibm.com>
    Signed-off-by: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
    Tested-by: Nageswara R Sastry <rnsastry@linux.ibm.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make pmi_irq_pending() return bool, reflow/reword some comments]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1626846509-1350-2-git-send-email-atrajeev@linux.vnet.ibm.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 212ad7cb7d7592669c067125949e0a8e31ce6a0b
Author: Wen Gong <quic_wgong@quicinc.com>
Date:   Tue Jan 11 16:42:52 2022 +0200

    ath11k: free peer for station when disconnect from AP for QCA6390/WCN6855
    
    Commit b4a0f54156ac ("ath11k: move peer delete after vdev stop of station
    for QCA6390 and WCN6855") is to fix firmware crash by changing the WMI
    command sequence, but actually skip all the peer delete operation, then
    it lead commit 58595c9874c6 ("ath11k: Fixing dangling pointer issue upon
    peer delete failure") not take effect, and then happened a use-after-free
    warning from KASAN. because the peer->sta is not set to NULL and then used
    later.
    
    Change to only skip the WMI_PEER_DELETE_CMDID for QCA6390/WCN6855.
    
    log of user-after-free:
    
    [  534.888665] BUG: KASAN: use-after-free in ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888696] Read of size 8 at addr ffff8881396bb1b8 by task rtcwake/2860
    
    [  534.888705] CPU: 4 PID: 2860 Comm: rtcwake Kdump: loaded Tainted: G        W         5.15.0-wt-ath+ #523
    [  534.888712] Hardware name: Intel(R) Client Systems NUC8i7HVK/NUC8i7HVB, BIOS HNKBLi70.86A.0067.2021.0528.1339 05/28/2021
    [  534.888716] Call Trace:
    [  534.888720]  <IRQ>
    [  534.888726]  dump_stack_lvl+0x57/0x7d
    [  534.888736]  print_address_description.constprop.0+0x1f/0x170
    [  534.888745]  ? ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888771]  kasan_report.cold+0x83/0xdf
    [  534.888783]  ? ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888810]  ath11k_dp_rx_update_peer_stats+0x912/0xc10 [ath11k]
    [  534.888840]  ath11k_dp_rx_process_mon_status+0x529/0xa70 [ath11k]
    [  534.888874]  ? ath11k_dp_rx_mon_status_bufs_replenish+0x3f0/0x3f0 [ath11k]
    [  534.888897]  ? check_prev_add+0x20f0/0x20f0
    [  534.888922]  ? __lock_acquire+0xb72/0x1870
    [  534.888937]  ? find_held_lock+0x33/0x110
    [  534.888954]  ath11k_dp_rx_process_mon_rings+0x297/0x520 [ath11k]
    [  534.888981]  ? rcu_read_unlock+0x40/0x40
    [  534.888990]  ? ath11k_dp_rx_pdev_alloc+0xd90/0xd90 [ath11k]
    [  534.889026]  ath11k_dp_service_mon_ring+0x67/0xe0 [ath11k]
    [  534.889053]  ? ath11k_dp_rx_process_mon_rings+0x520/0x520 [ath11k]
    [  534.889075]  call_timer_fn+0x167/0x4a0
    [  534.889084]  ? add_timer_on+0x3b0/0x3b0
    [  534.889103]  ? lockdep_hardirqs_on_prepare.part.0+0x18c/0x370
    [  534.889117]  __run_timers.part.0+0x539/0x8b0
    [  534.889123]  ? ath11k_dp_rx_process_mon_rings+0x520/0x520 [ath11k]
    [  534.889157]  ? call_timer_fn+0x4a0/0x4a0
    [  534.889164]  ? mark_lock_irq+0x1c30/0x1c30
    [  534.889173]  ? clockevents_program_event+0xdd/0x280
    [  534.889189]  ? mark_held_locks+0xa5/0xe0
    [  534.889203]  run_timer_softirq+0x97/0x180
    [  534.889213]  __do_softirq+0x276/0x86a
    [  534.889230]  __irq_exit_rcu+0x11c/0x180
    [  534.889238]  irq_exit_rcu+0x5/0x20
    [  534.889244]  sysvec_apic_timer_interrupt+0x8e/0xc0
    [  534.889251]  </IRQ>
    [  534.889254]  <TASK>
    [  534.889259]  asm_sysvec_apic_timer_interrupt+0x12/0x20
    [  534.889265] RIP: 0010:_raw_spin_unlock_irqrestore+0x38/0x70
    [  534.889271] Code: 74 24 10 e8 ea c2 bf fd 48 89 ef e8 12 53 c0 fd 81 e3 00 02 00 00 75 25 9c 58 f6 c4 02 75 2d 48 85 db 74 01 fb bf 01 00 00 00 <e8> 13 a7 b5 fd 65 8b 05 cc d9 9c 5e 85 c0 74 0a 5b 5d c3 e8 a0 ee
    [  534.889276] RSP: 0018:ffffc90002e5f880 EFLAGS: 00000206
    [  534.889284] RAX: 0000000000000006 RBX: 0000000000000200 RCX: ffffffff9f256f10
    [  534.889289] RDX: 0000000000000000 RSI: ffffffffa1c6e420 RDI: 0000000000000001
    [  534.889293] RBP: ffff8881095e6200 R08: 0000000000000001 R09: ffffffffa40d2b8f
    [  534.889298] R10: fffffbfff481a571 R11: 0000000000000001 R12: ffff8881095e6e68
    [  534.889302] R13: ffffc90002e5f908 R14: 0000000000000246 R15: 0000000000000000
    [  534.889316]  ? mark_lock+0xd0/0x14a0
    [  534.889332]  klist_next+0x1d4/0x450
    [  534.889340]  ? dpm_wait_for_subordinate+0x2d0/0x2d0
    [  534.889350]  device_for_each_child+0xa8/0x140
    [  534.889360]  ? device_remove_class_symlinks+0x1b0/0x1b0
    [  534.889370]  ? __lock_release+0x4bd/0x9f0
    [  534.889378]  ? dpm_suspend+0x26b/0x3f0
    [  534.889390]  dpm_wait_for_subordinate+0x82/0x2d0
    [  534.889400]  ? dpm_for_each_dev+0xa0/0xa0
    [  534.889410]  ? dpm_suspend+0x233/0x3f0
    [  534.889427]  __device_suspend+0xd4/0x10c0
    [  534.889440]  ? wait_for_completion_io+0x270/0x270
    [  534.889456]  ? async_suspend_late+0xe0/0xe0
    [  534.889463]  ? async_schedule_node_domain+0x468/0x640
    [  534.889482]  dpm_suspend+0x25a/0x3f0
    [  534.889491]  ? dpm_suspend_end+0x1a0/0x1a0
    [  534.889497]  ? ktime_get+0x214/0x2f0
    [  534.889502]  ? lockdep_hardirqs_on+0x79/0x100
    [  534.889509]  ? recalibrate_cpu_khz+0x10/0x10
    [  534.889516]  ? ktime_get+0x119/0x2f0
    [  534.889528]  dpm_suspend_start+0xab/0xc0
    [  534.889538]  suspend_devices_and_enter+0x1ca/0x350
    [  534.889546]  ? suspend_enter+0x850/0x850
    [  534.889566]  enter_state+0x27c/0x3d7
    [  534.889575]  pm_suspend.cold+0x42/0x189
    [  534.889583]  state_store+0xab/0x160
    [  534.889595]  ? sysfs_file_ops+0x160/0x160
    [  534.889601]  kernfs_fop_write_iter+0x2b5/0x450
    [  534.889615]  new_sync_write+0x36a/0x600
    [  534.889625]  ? new_sync_read+0x600/0x600
    [  534.889639]  ? rcu_read_unlock+0x40/0x40
    [  534.889668]  vfs_write+0x619/0x910
    [  534.889681]  ksys_write+0xf4/0x1d0
    [  534.889689]  ? __ia32_sys_read+0xa0/0xa0
    [  534.889699]  ? lockdep_hardirqs_on_prepare.part.0+0x18c/0x370
    [  534.889707]  ? syscall_enter_from_user_mode+0x1d/0x50
    [  534.889719]  do_syscall_64+0x3b/0x90
    [  534.889725]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  534.889731] RIP: 0033:0x7f0b9bc931e7
    [  534.889736] Code: 64 89 02 48 c7 c0 ff ff ff ff eb bb 0f 1f 80 00 00 00 00 f3 0f 1e fa 64 8b 04 25 18 00 00 00 85 c0 75 10 b8 01 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 51 c3 48 83 ec 28 48 89 54 24 18 48 89 74 24
    [  534.889741] RSP: 002b:00007ffd9d34cc88 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
    [  534.889749] RAX: ffffffffffffffda RBX: 0000000000000004 RCX: 00007f0b9bc931e7
    [  534.889753] RDX: 0000000000000004 RSI: 0000561cd023c5f0 RDI: 0000000000000004
    [  534.889757] RBP: 0000561cd023c5f0 R08: 0000000000000000 R09: 0000000000000004
    [  534.889761] R10: 0000561ccef842a6 R11: 0000000000000246 R12: 0000000000000004
    [  534.889765] R13: 0000561cd0239590 R14: 00007f0b9bd6f4a0 R15: 00007f0b9bd6e8a0
    [  534.889789]  </TASK>
    
    [  534.889796] Allocated by task 2711:
    [  534.889800]  kasan_save_stack+0x1b/0x40
    [  534.889805]  __kasan_kmalloc+0x7c/0x90
    [  534.889810]  sta_info_alloc+0x98/0x1ef0 [mac80211]
    [  534.889874]  ieee80211_prep_connection+0x30b/0x11e0 [mac80211]
    [  534.889950]  ieee80211_mgd_auth+0x529/0xe00 [mac80211]
    [  534.890024]  cfg80211_mlme_auth+0x332/0x6f0 [cfg80211]
    [  534.890090]  nl80211_authenticate+0x839/0xcf0 [cfg80211]
    [  534.890147]  genl_family_rcv_msg_doit+0x1f4/0x2f0
    [  534.890154]  genl_rcv_msg+0x280/0x500
    [  534.890160]  netlink_rcv_skb+0x11c/0x340
    [  534.890165]  genl_rcv+0x1f/0x30
    [  534.890170]  netlink_unicast+0x42b/0x700
    [  534.890176]  netlink_sendmsg+0x71b/0xc60
    [  534.890181]  sock_sendmsg+0xdf/0x110
    [  534.890187]  ____sys_sendmsg+0x5c0/0x850
    [  534.890192]  ___sys_sendmsg+0xe4/0x160
    [  534.890197]  __sys_sendmsg+0xb2/0x140
    [  534.890202]  do_syscall_64+0x3b/0x90
    [  534.890207]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    [  534.890215] Freed by task 2825:
    [  534.890218]  kasan_save_stack+0x1b/0x40
    [  534.890223]  kasan_set_track+0x1c/0x30
    [  534.890227]  kasan_set_free_info+0x20/0x30
    [  534.890232]  __kasan_slab_free+0xce/0x100
    [  534.890237]  slab_free_freelist_hook+0xf0/0x1a0
    [  534.890242]  kfree+0xe5/0x370
    [  534.890248]  __sta_info_flush+0x333/0x4b0 [mac80211]
    [  534.890308]  ieee80211_set_disassoc+0x324/0xd20 [mac80211]
    [  534.890382]  ieee80211_mgd_deauth+0x537/0xee0 [mac80211]
    [  534.890472]  cfg80211_mlme_deauth+0x349/0x810 [cfg80211]
    [  534.890526]  cfg80211_mlme_down+0x1ce/0x270 [cfg80211]
    [  534.890578]  cfg80211_disconnect+0x4f5/0x7b0 [cfg80211]
    [  534.890631]  cfg80211_leave+0x24/0x40 [cfg80211]
    [  534.890677]  wiphy_suspend+0x23d/0x2f0 [cfg80211]
    [  534.890723]  dpm_run_callback+0xf4/0x1b0
    [  534.890728]  __device_suspend+0x648/0x10c0
    [  534.890733]  async_suspend+0x16/0xe0
    [  534.890737]  async_run_entry_fn+0x90/0x4f0
    [  534.890741]  process_one_work+0x866/0x1490
    [  534.890747]  worker_thread+0x596/0x1010
    [  534.890751]  kthread+0x35d/0x420
    [  534.890756]  ret_from_fork+0x22/0x30
    
    [  534.890763] The buggy address belongs to the object at ffff8881396ba000
                    which belongs to the cache kmalloc-8k of size 8192
    [  534.890767] The buggy address is located 4536 bytes inside of
                    8192-byte region [ffff8881396ba000, ffff8881396bc000)
    [  534.890772] The buggy address belongs to the page:
    [  534.890775] page:ffffea0004e5ae00 refcount:1 mapcount:0 mapping:0000000000000000 index:0x0 pfn:0x1396b8
    [  534.890780] head:ffffea0004e5ae00 order:3 compound_mapcount:0 compound_pincount:0
    [  534.890784] flags: 0x200000000010200(slab|head|node=0|zone=2)
    [  534.890791] raw: 0200000000010200 ffffea000562be08 ffffea0004b04c08 ffff88810004e340
    [  534.890795] raw: 0000000000000000 0000000000010001 00000001ffffffff 0000000000000000
    [  534.890798] page dumped because: kasan: bad access detected
    
    [  534.890804] Memory state around the buggy address:
    [  534.890807]  ffff8881396bb080: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890811]  ffff8881396bb100: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890814] >ffff8881396bb180: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890817]                                         ^
    [  534.890821]  ffff8881396bb200: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890824]  ffff8881396bb280: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  534.890827] ==================================================================
    [  534.890830] Disabling lock debugging due to kernel taint
    
    Tested-on: WCN6855 hw2.0 PCI WLAN.HSP.1.1-01720.1-QCAHSPSWPL_V1_V2_SILICONZ_LITE-1
    
    Fixes: b4a0f54156ac ("ath11k: move peer delete after vdev stop of station for QCA6390 and WCN6855")
    Signed-off-by: Wen Gong <quic_wgong@quicinc.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20211222070431.29595-1-quic_wgong@quicinc.com

commit 75799e71df1da11394740b43ae5686646179561d
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 23 13:04:30 2021 -0500

    sctp: use call_rcu to free endpoint
    
    [ Upstream commit 5ec7d18d1813a5bead0b495045606c93873aecbb ]
    
    This patch is to delay the endpoint free by calling call_rcu() to fix
    another use-after-free issue in sctp_sock_dump():
    
      BUG: KASAN: use-after-free in __lock_acquire+0x36d9/0x4c20
      Call Trace:
        __lock_acquire+0x36d9/0x4c20 kernel/locking/lockdep.c:3218
        lock_acquire+0x1ed/0x520 kernel/locking/lockdep.c:3844
        __raw_spin_lock_bh include/linux/spinlock_api_smp.h:135 [inline]
        _raw_spin_lock_bh+0x31/0x40 kernel/locking/spinlock.c:168
        spin_lock_bh include/linux/spinlock.h:334 [inline]
        __lock_sock+0x203/0x350 net/core/sock.c:2253
        lock_sock_nested+0xfe/0x120 net/core/sock.c:2774
        lock_sock include/net/sock.h:1492 [inline]
        sctp_sock_dump+0x122/0xb20 net/sctp/diag.c:324
        sctp_for_each_transport+0x2b5/0x370 net/sctp/socket.c:5091
        sctp_diag_dump+0x3ac/0x660 net/sctp/diag.c:527
        __inet_diag_dump+0xa8/0x140 net/ipv4/inet_diag.c:1049
        inet_diag_dump+0x9b/0x110 net/ipv4/inet_diag.c:1065
        netlink_dump+0x606/0x1080 net/netlink/af_netlink.c:2244
        __netlink_dump_start+0x59a/0x7c0 net/netlink/af_netlink.c:2352
        netlink_dump_start include/linux/netlink.h:216 [inline]
        inet_diag_handler_cmd+0x2ce/0x3f0 net/ipv4/inet_diag.c:1170
        __sock_diag_cmd net/core/sock_diag.c:232 [inline]
        sock_diag_rcv_msg+0x31d/0x410 net/core/sock_diag.c:263
        netlink_rcv_skb+0x172/0x440 net/netlink/af_netlink.c:2477
        sock_diag_rcv+0x2a/0x40 net/core/sock_diag.c:274
    
    This issue occurs when asoc is peeled off and the old sk is freed after
    getting it by asoc->base.sk and before calling lock_sock(sk).
    
    To prevent the sk free, as a holder of the sk, ep should be alive when
    calling lock_sock(). This patch uses call_rcu() and moves sock_put and
    ep free into sctp_endpoint_destroy_rcu(), so that it's safe to try to
    hold the ep under rcu_read_lock in sctp_transport_traverse_process().
    
    If sctp_endpoint_hold() returns true, it means this ep is still alive
    and we have held it and can continue to dump it; If it returns false,
    it means this ep is dead and can be freed after rcu_read_unlock, and
    we should skip it.
    
    In sctp_sock_dump(), after locking the sk, if this ep is different from
    tsp->asoc->ep, it means during this dumping, this asoc was peeled off
    before calling lock_sock(), and the sk should be skipped; If this ep is
    the same with tsp->asoc->ep, it means no peeloff happens on this asoc,
    and due to lock_sock, no peeloff will happen either until release_sock.
    
    Note that delaying endpoint free won't delay the port release, as the
    port release happens in sctp_endpoint_destroy() before calling call_rcu().
    Also, freeing endpoint by call_rcu() makes it safe to access the sk by
    asoc->base.sk in sctp_assocs_seq_show() and sctp_rcv().
    
    Thanks Jones to bring this issue up.
    
    v1->v2:
      - improve the changelog.
      - add kfree(ep) into sctp_endpoint_destroy_rcu(), as Jakub noticed.
    
    Reported-by: syzbot+9276d76e83e3bcde6c99@syzkaller.appspotmail.com
    Reported-by: Lee Jones <lee.jones@linaro.org>
    Fixes: d25adbeb0cdb ("sctp: fix an use-after-free issue in sctp_sock_dump")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 769d14abd35e0e153b5149c3e1e989a9d719e3ff
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 23 13:04:30 2021 -0500

    sctp: use call_rcu to free endpoint
    
    [ Upstream commit 5ec7d18d1813a5bead0b495045606c93873aecbb ]
    
    This patch is to delay the endpoint free by calling call_rcu() to fix
    another use-after-free issue in sctp_sock_dump():
    
      BUG: KASAN: use-after-free in __lock_acquire+0x36d9/0x4c20
      Call Trace:
        __lock_acquire+0x36d9/0x4c20 kernel/locking/lockdep.c:3218
        lock_acquire+0x1ed/0x520 kernel/locking/lockdep.c:3844
        __raw_spin_lock_bh include/linux/spinlock_api_smp.h:135 [inline]
        _raw_spin_lock_bh+0x31/0x40 kernel/locking/spinlock.c:168
        spin_lock_bh include/linux/spinlock.h:334 [inline]
        __lock_sock+0x203/0x350 net/core/sock.c:2253
        lock_sock_nested+0xfe/0x120 net/core/sock.c:2774
        lock_sock include/net/sock.h:1492 [inline]
        sctp_sock_dump+0x122/0xb20 net/sctp/diag.c:324
        sctp_for_each_transport+0x2b5/0x370 net/sctp/socket.c:5091
        sctp_diag_dump+0x3ac/0x660 net/sctp/diag.c:527
        __inet_diag_dump+0xa8/0x140 net/ipv4/inet_diag.c:1049
        inet_diag_dump+0x9b/0x110 net/ipv4/inet_diag.c:1065
        netlink_dump+0x606/0x1080 net/netlink/af_netlink.c:2244
        __netlink_dump_start+0x59a/0x7c0 net/netlink/af_netlink.c:2352
        netlink_dump_start include/linux/netlink.h:216 [inline]
        inet_diag_handler_cmd+0x2ce/0x3f0 net/ipv4/inet_diag.c:1170
        __sock_diag_cmd net/core/sock_diag.c:232 [inline]
        sock_diag_rcv_msg+0x31d/0x410 net/core/sock_diag.c:263
        netlink_rcv_skb+0x172/0x440 net/netlink/af_netlink.c:2477
        sock_diag_rcv+0x2a/0x40 net/core/sock_diag.c:274
    
    This issue occurs when asoc is peeled off and the old sk is freed after
    getting it by asoc->base.sk and before calling lock_sock(sk).
    
    To prevent the sk free, as a holder of the sk, ep should be alive when
    calling lock_sock(). This patch uses call_rcu() and moves sock_put and
    ep free into sctp_endpoint_destroy_rcu(), so that it's safe to try to
    hold the ep under rcu_read_lock in sctp_transport_traverse_process().
    
    If sctp_endpoint_hold() returns true, it means this ep is still alive
    and we have held it and can continue to dump it; If it returns false,
    it means this ep is dead and can be freed after rcu_read_unlock, and
    we should skip it.
    
    In sctp_sock_dump(), after locking the sk, if this ep is different from
    tsp->asoc->ep, it means during this dumping, this asoc was peeled off
    before calling lock_sock(), and the sk should be skipped; If this ep is
    the same with tsp->asoc->ep, it means no peeloff happens on this asoc,
    and due to lock_sock, no peeloff will happen either until release_sock.
    
    Note that delaying endpoint free won't delay the port release, as the
    port release happens in sctp_endpoint_destroy() before calling call_rcu().
    Also, freeing endpoint by call_rcu() makes it safe to access the sk by
    asoc->base.sk in sctp_assocs_seq_show() and sctp_rcv().
    
    Thanks Jones to bring this issue up.
    
    v1->v2:
      - improve the changelog.
      - add kfree(ep) into sctp_endpoint_destroy_rcu(), as Jakub noticed.
    
    Reported-by: syzbot+9276d76e83e3bcde6c99@syzkaller.appspotmail.com
    Reported-by: Lee Jones <lee.jones@linaro.org>
    Fixes: d25adbeb0cdb ("sctp: fix an use-after-free issue in sctp_sock_dump")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 831de271452b87657fcf8d715ee20519b79caef5
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 23 13:04:30 2021 -0500

    sctp: use call_rcu to free endpoint
    
    [ Upstream commit 5ec7d18d1813a5bead0b495045606c93873aecbb ]
    
    This patch is to delay the endpoint free by calling call_rcu() to fix
    another use-after-free issue in sctp_sock_dump():
    
      BUG: KASAN: use-after-free in __lock_acquire+0x36d9/0x4c20
      Call Trace:
        __lock_acquire+0x36d9/0x4c20 kernel/locking/lockdep.c:3218
        lock_acquire+0x1ed/0x520 kernel/locking/lockdep.c:3844
        __raw_spin_lock_bh include/linux/spinlock_api_smp.h:135 [inline]
        _raw_spin_lock_bh+0x31/0x40 kernel/locking/spinlock.c:168
        spin_lock_bh include/linux/spinlock.h:334 [inline]
        __lock_sock+0x203/0x350 net/core/sock.c:2253
        lock_sock_nested+0xfe/0x120 net/core/sock.c:2774
        lock_sock include/net/sock.h:1492 [inline]
        sctp_sock_dump+0x122/0xb20 net/sctp/diag.c:324
        sctp_for_each_transport+0x2b5/0x370 net/sctp/socket.c:5091
        sctp_diag_dump+0x3ac/0x660 net/sctp/diag.c:527
        __inet_diag_dump+0xa8/0x140 net/ipv4/inet_diag.c:1049
        inet_diag_dump+0x9b/0x110 net/ipv4/inet_diag.c:1065
        netlink_dump+0x606/0x1080 net/netlink/af_netlink.c:2244
        __netlink_dump_start+0x59a/0x7c0 net/netlink/af_netlink.c:2352
        netlink_dump_start include/linux/netlink.h:216 [inline]
        inet_diag_handler_cmd+0x2ce/0x3f0 net/ipv4/inet_diag.c:1170
        __sock_diag_cmd net/core/sock_diag.c:232 [inline]
        sock_diag_rcv_msg+0x31d/0x410 net/core/sock_diag.c:263
        netlink_rcv_skb+0x172/0x440 net/netlink/af_netlink.c:2477
        sock_diag_rcv+0x2a/0x40 net/core/sock_diag.c:274
    
    This issue occurs when asoc is peeled off and the old sk is freed after
    getting it by asoc->base.sk and before calling lock_sock(sk).
    
    To prevent the sk free, as a holder of the sk, ep should be alive when
    calling lock_sock(). This patch uses call_rcu() and moves sock_put and
    ep free into sctp_endpoint_destroy_rcu(), so that it's safe to try to
    hold the ep under rcu_read_lock in sctp_transport_traverse_process().
    
    If sctp_endpoint_hold() returns true, it means this ep is still alive
    and we have held it and can continue to dump it; If it returns false,
    it means this ep is dead and can be freed after rcu_read_unlock, and
    we should skip it.
    
    In sctp_sock_dump(), after locking the sk, if this ep is different from
    tsp->asoc->ep, it means during this dumping, this asoc was peeled off
    before calling lock_sock(), and the sk should be skipped; If this ep is
    the same with tsp->asoc->ep, it means no peeloff happens on this asoc,
    and due to lock_sock, no peeloff will happen either until release_sock.
    
    Note that delaying endpoint free won't delay the port release, as the
    port release happens in sctp_endpoint_destroy() before calling call_rcu().
    Also, freeing endpoint by call_rcu() makes it safe to access the sk by
    asoc->base.sk in sctp_assocs_seq_show() and sctp_rcv().
    
    Thanks Jones to bring this issue up.
    
    v1->v2:
      - improve the changelog.
      - add kfree(ep) into sctp_endpoint_destroy_rcu(), as Jakub noticed.
    
    Reported-by: syzbot+9276d76e83e3bcde6c99@syzkaller.appspotmail.com
    Reported-by: Lee Jones <lee.jones@linaro.org>
    Fixes: d25adbeb0cdb ("sctp: fix an use-after-free issue in sctp_sock_dump")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit af6e6e58f7ebf86b4e7201694b1e4f3a62cbc3ec
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 23 13:04:30 2021 -0500

    sctp: use call_rcu to free endpoint
    
    [ Upstream commit 5ec7d18d1813a5bead0b495045606c93873aecbb ]
    
    This patch is to delay the endpoint free by calling call_rcu() to fix
    another use-after-free issue in sctp_sock_dump():
    
      BUG: KASAN: use-after-free in __lock_acquire+0x36d9/0x4c20
      Call Trace:
        __lock_acquire+0x36d9/0x4c20 kernel/locking/lockdep.c:3218
        lock_acquire+0x1ed/0x520 kernel/locking/lockdep.c:3844
        __raw_spin_lock_bh include/linux/spinlock_api_smp.h:135 [inline]
        _raw_spin_lock_bh+0x31/0x40 kernel/locking/spinlock.c:168
        spin_lock_bh include/linux/spinlock.h:334 [inline]
        __lock_sock+0x203/0x350 net/core/sock.c:2253
        lock_sock_nested+0xfe/0x120 net/core/sock.c:2774
        lock_sock include/net/sock.h:1492 [inline]
        sctp_sock_dump+0x122/0xb20 net/sctp/diag.c:324
        sctp_for_each_transport+0x2b5/0x370 net/sctp/socket.c:5091
        sctp_diag_dump+0x3ac/0x660 net/sctp/diag.c:527
        __inet_diag_dump+0xa8/0x140 net/ipv4/inet_diag.c:1049
        inet_diag_dump+0x9b/0x110 net/ipv4/inet_diag.c:1065
        netlink_dump+0x606/0x1080 net/netlink/af_netlink.c:2244
        __netlink_dump_start+0x59a/0x7c0 net/netlink/af_netlink.c:2352
        netlink_dump_start include/linux/netlink.h:216 [inline]
        inet_diag_handler_cmd+0x2ce/0x3f0 net/ipv4/inet_diag.c:1170
        __sock_diag_cmd net/core/sock_diag.c:232 [inline]
        sock_diag_rcv_msg+0x31d/0x410 net/core/sock_diag.c:263
        netlink_rcv_skb+0x172/0x440 net/netlink/af_netlink.c:2477
        sock_diag_rcv+0x2a/0x40 net/core/sock_diag.c:274
    
    This issue occurs when asoc is peeled off and the old sk is freed after
    getting it by asoc->base.sk and before calling lock_sock(sk).
    
    To prevent the sk free, as a holder of the sk, ep should be alive when
    calling lock_sock(). This patch uses call_rcu() and moves sock_put and
    ep free into sctp_endpoint_destroy_rcu(), so that it's safe to try to
    hold the ep under rcu_read_lock in sctp_transport_traverse_process().
    
    If sctp_endpoint_hold() returns true, it means this ep is still alive
    and we have held it and can continue to dump it; If it returns false,
    it means this ep is dead and can be freed after rcu_read_unlock, and
    we should skip it.
    
    In sctp_sock_dump(), after locking the sk, if this ep is different from
    tsp->asoc->ep, it means during this dumping, this asoc was peeled off
    before calling lock_sock(), and the sk should be skipped; If this ep is
    the same with tsp->asoc->ep, it means no peeloff happens on this asoc,
    and due to lock_sock, no peeloff will happen either until release_sock.
    
    Note that delaying endpoint free won't delay the port release, as the
    port release happens in sctp_endpoint_destroy() before calling call_rcu().
    Also, freeing endpoint by call_rcu() makes it safe to access the sk by
    asoc->base.sk in sctp_assocs_seq_show() and sctp_rcv().
    
    Thanks Jones to bring this issue up.
    
    v1->v2:
      - improve the changelog.
      - add kfree(ep) into sctp_endpoint_destroy_rcu(), as Jakub noticed.
    
    Reported-by: syzbot+9276d76e83e3bcde6c99@syzkaller.appspotmail.com
    Reported-by: Lee Jones <lee.jones@linaro.org>
    Fixes: d25adbeb0cdb ("sctp: fix an use-after-free issue in sctp_sock_dump")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8873140f95d4977bf37e4cf0d5c5e3f6e34cdd3e
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 23 13:04:30 2021 -0500

    sctp: use call_rcu to free endpoint
    
    commit 5ec7d18d1813a5bead0b495045606c93873aecbb upstream.
    
    This patch is to delay the endpoint free by calling call_rcu() to fix
    another use-after-free issue in sctp_sock_dump():
    
      BUG: KASAN: use-after-free in __lock_acquire+0x36d9/0x4c20
      Call Trace:
        __lock_acquire+0x36d9/0x4c20 kernel/locking/lockdep.c:3218
        lock_acquire+0x1ed/0x520 kernel/locking/lockdep.c:3844
        __raw_spin_lock_bh include/linux/spinlock_api_smp.h:135 [inline]
        _raw_spin_lock_bh+0x31/0x40 kernel/locking/spinlock.c:168
        spin_lock_bh include/linux/spinlock.h:334 [inline]
        __lock_sock+0x203/0x350 net/core/sock.c:2253
        lock_sock_nested+0xfe/0x120 net/core/sock.c:2774
        lock_sock include/net/sock.h:1492 [inline]
        sctp_sock_dump+0x122/0xb20 net/sctp/diag.c:324
        sctp_for_each_transport+0x2b5/0x370 net/sctp/socket.c:5091
        sctp_diag_dump+0x3ac/0x660 net/sctp/diag.c:527
        __inet_diag_dump+0xa8/0x140 net/ipv4/inet_diag.c:1049
        inet_diag_dump+0x9b/0x110 net/ipv4/inet_diag.c:1065
        netlink_dump+0x606/0x1080 net/netlink/af_netlink.c:2244
        __netlink_dump_start+0x59a/0x7c0 net/netlink/af_netlink.c:2352
        netlink_dump_start include/linux/netlink.h:216 [inline]
        inet_diag_handler_cmd+0x2ce/0x3f0 net/ipv4/inet_diag.c:1170
        __sock_diag_cmd net/core/sock_diag.c:232 [inline]
        sock_diag_rcv_msg+0x31d/0x410 net/core/sock_diag.c:263
        netlink_rcv_skb+0x172/0x440 net/netlink/af_netlink.c:2477
        sock_diag_rcv+0x2a/0x40 net/core/sock_diag.c:274
    
    This issue occurs when asoc is peeled off and the old sk is freed after
    getting it by asoc->base.sk and before calling lock_sock(sk).
    
    To prevent the sk free, as a holder of the sk, ep should be alive when
    calling lock_sock(). This patch uses call_rcu() and moves sock_put and
    ep free into sctp_endpoint_destroy_rcu(), so that it's safe to try to
    hold the ep under rcu_read_lock in sctp_transport_traverse_process().
    
    If sctp_endpoint_hold() returns true, it means this ep is still alive
    and we have held it and can continue to dump it; If it returns false,
    it means this ep is dead and can be freed after rcu_read_unlock, and
    we should skip it.
    
    In sctp_sock_dump(), after locking the sk, if this ep is different from
    tsp->asoc->ep, it means during this dumping, this asoc was peeled off
    before calling lock_sock(), and the sk should be skipped; If this ep is
    the same with tsp->asoc->ep, it means no peeloff happens on this asoc,
    and due to lock_sock, no peeloff will happen either until release_sock.
    
    Note that delaying endpoint free won't delay the port release, as the
    port release happens in sctp_endpoint_destroy() before calling call_rcu().
    Also, freeing endpoint by call_rcu() makes it safe to access the sk by
    asoc->base.sk in sctp_assocs_seq_show() and sctp_rcv().
    
    Thanks Jones to bring this issue up.
    
    v1->v2:
      - improve the changelog.
      - add kfree(ep) into sctp_endpoint_destroy_rcu(), as Jakub noticed.
    
    Reported-by: syzbot+9276d76e83e3bcde6c99@syzkaller.appspotmail.com
    Reported-by: Lee Jones <lee.jones@linaro.org>
    Fixes: d25adbeb0cdb ("sctp: fix an use-after-free issue in sctp_sock_dump")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5ec7d18d1813a5bead0b495045606c93873aecbb
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 23 13:04:30 2021 -0500

    sctp: use call_rcu to free endpoint
    
    This patch is to delay the endpoint free by calling call_rcu() to fix
    another use-after-free issue in sctp_sock_dump():
    
      BUG: KASAN: use-after-free in __lock_acquire+0x36d9/0x4c20
      Call Trace:
        __lock_acquire+0x36d9/0x4c20 kernel/locking/lockdep.c:3218
        lock_acquire+0x1ed/0x520 kernel/locking/lockdep.c:3844
        __raw_spin_lock_bh include/linux/spinlock_api_smp.h:135 [inline]
        _raw_spin_lock_bh+0x31/0x40 kernel/locking/spinlock.c:168
        spin_lock_bh include/linux/spinlock.h:334 [inline]
        __lock_sock+0x203/0x350 net/core/sock.c:2253
        lock_sock_nested+0xfe/0x120 net/core/sock.c:2774
        lock_sock include/net/sock.h:1492 [inline]
        sctp_sock_dump+0x122/0xb20 net/sctp/diag.c:324
        sctp_for_each_transport+0x2b5/0x370 net/sctp/socket.c:5091
        sctp_diag_dump+0x3ac/0x660 net/sctp/diag.c:527
        __inet_diag_dump+0xa8/0x140 net/ipv4/inet_diag.c:1049
        inet_diag_dump+0x9b/0x110 net/ipv4/inet_diag.c:1065
        netlink_dump+0x606/0x1080 net/netlink/af_netlink.c:2244
        __netlink_dump_start+0x59a/0x7c0 net/netlink/af_netlink.c:2352
        netlink_dump_start include/linux/netlink.h:216 [inline]
        inet_diag_handler_cmd+0x2ce/0x3f0 net/ipv4/inet_diag.c:1170
        __sock_diag_cmd net/core/sock_diag.c:232 [inline]
        sock_diag_rcv_msg+0x31d/0x410 net/core/sock_diag.c:263
        netlink_rcv_skb+0x172/0x440 net/netlink/af_netlink.c:2477
        sock_diag_rcv+0x2a/0x40 net/core/sock_diag.c:274
    
    This issue occurs when asoc is peeled off and the old sk is freed after
    getting it by asoc->base.sk and before calling lock_sock(sk).
    
    To prevent the sk free, as a holder of the sk, ep should be alive when
    calling lock_sock(). This patch uses call_rcu() and moves sock_put and
    ep free into sctp_endpoint_destroy_rcu(), so that it's safe to try to
    hold the ep under rcu_read_lock in sctp_transport_traverse_process().
    
    If sctp_endpoint_hold() returns true, it means this ep is still alive
    and we have held it and can continue to dump it; If it returns false,
    it means this ep is dead and can be freed after rcu_read_unlock, and
    we should skip it.
    
    In sctp_sock_dump(), after locking the sk, if this ep is different from
    tsp->asoc->ep, it means during this dumping, this asoc was peeled off
    before calling lock_sock(), and the sk should be skipped; If this ep is
    the same with tsp->asoc->ep, it means no peeloff happens on this asoc,
    and due to lock_sock, no peeloff will happen either until release_sock.
    
    Note that delaying endpoint free won't delay the port release, as the
    port release happens in sctp_endpoint_destroy() before calling call_rcu().
    Also, freeing endpoint by call_rcu() makes it safe to access the sk by
    asoc->base.sk in sctp_assocs_seq_show() and sctp_rcv().
    
    Thanks Jones to bring this issue up.
    
    v1->v2:
      - improve the changelog.
      - add kfree(ep) into sctp_endpoint_destroy_rcu(), as Jakub noticed.
    
    Reported-by: syzbot+9276d76e83e3bcde6c99@syzkaller.appspotmail.com
    Reported-by: Lee Jones <lee.jones@linaro.org>
    Fixes: d25adbeb0cdb ("sctp: fix an use-after-free issue in sctp_sock_dump")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 01e782c891083f1847c0b62902bfe3c2812566c6
Author: Wen Gong <quic_wgong@quicinc.com>
Date:   Fri Dec 17 20:27:21 2021 +0200

    ath11k: fix warning of RCU usage for ath11k_mac_get_arvif_by_vdev_id()
    
    When enable more debug config, it happen below warning. It is because
    the caller does not add rcu_read_lock()/rcu_read_unlock() to wrap the
    rcu_dereference().
    
    Add rcu_read_lock()/rcu_read_unlock() to wrap rcu_dereference(), then
    fixed it.
    
    [ 180.716604] =============================
    [ 180.716670] WARNING: suspicious RCU usage
    [ 180.716734] 5.16.0-rc4-wt-ath+ #542 Not tainted
    [ 180.716895] -----------------------------
    [ 180.716957] drivers/net/wireless/ath/ath11k/mac.c:506 suspicious rcu_dereference_check() usage!
    [ 180.717023]
                   other info that might help us debug this:
    
    [ 180.717087]
                   rcu_scheduler_active = 2, debug_locks = 1
    [ 180.717151] no locks held by swapper/0/0.
    [ 180.717215]
                   stack backtrace:
    [ 180.717279] CPU: 0 PID: 0 Comm: swapper/0 Kdump: loaded Not tainted 5.16.0-rc4-wt-ath+ #542
    [ 180.717346] Hardware name: Intel(R) Client Systems NUC8i7HVK/NUC8i7HVB, BIOS HNKBLi70.86A.0067.2021.0528.1339 05/28/2021
    [ 180.717411] Call Trace:
    [ 180.717475] <IRQ>
    [ 180.717541] dump_stack_lvl+0x57/0x7d
    [ 180.717610] ath11k_mac_get_arvif_by_vdev_id+0x1ab/0x2d0 [ath11k]
    [ 180.717694] ? ath11k_mac_get_arvif+0x140/0x140 [ath11k]
    [ 180.717798] ? ath11k_wmi_tlv_op_rx+0xc1b/0x2520 [ath11k]
    [ 180.717888] ? kfree+0xe8/0x2c0
    [ 180.717959] ath11k_wmi_tlv_op_rx+0xc27/0x2520 [ath11k]
    [ 180.718038] ? ath11k_mgmt_rx_event+0xda0/0xda0 [ath11k]
    [ 180.718113] ? __lock_acquire+0xb72/0x1870
    [ 180.718182] ? lockdep_hardirqs_on_prepare.part.0+0x18c/0x370
    [ 180.718250] ? sched_clock_cpu+0x15/0x1b0
    [ 180.718314] ? find_held_lock+0x33/0x110
    [ 180.718381] ? __lock_release+0x4bd/0x9f0
    [ 180.718447] ? lock_downgrade+0x130/0x130
    [ 180.718517] ath11k_htc_rx_completion_handler+0x38f/0x5b0 [ath11k]
    [ 180.718596] ? __local_bh_enable_ip+0xa0/0x110
    [ 180.718662] ath11k_ce_recv_process_cb+0x5ac/0x920 [ath11k]
    [ 180.718783] ? __lock_acquired+0x205/0x890
    [ 180.718864] ? ath11k_ce_rx_post_pipe+0x970/0x970 [ath11k]
    [ 180.718949] ? __wake_up_bit+0x100/0x100
    [ 180.719020] ath11k_pci_ce_tasklet+0x5f/0xf0 [ath11k_pci]
    [ 180.719085] ? tasklet_clear_sched+0x42/0xe0
    [ 180.719148] tasklet_action_common.constprop.0+0x204/0x2f0
    [ 180.719217] __do_softirq+0x276/0x86a
    [ 180.719281] ? __common_interrupt+0x92/0x1d0
    [ 180.719350] __irq_exit_rcu+0x11c/0x180
    [ 180.719418] irq_exit_rcu+0x5/0x20
    [ 180.719482] common_interrupt+0xa4/0xc0
    [ 180.719547] </IRQ>
    [ 180.719609] <TASK>
    [ 180.719671] asm_common_interrupt+0x1e/0x40
    [ 180.719772] RIP: 0010:cpuidle_enter_state+0x1f3/0x8d0
    [ 180.719838] Code: 00 41 8b 77 04 bf ff ff ff ff e8 78 f1 ff ff 31 ff e8 81 fa 52 fe 80 7c 24 08 00 0f 85 9e 01 00 00 e8 11 13 78 fe fb 45 85 e4 <0f> 88 8c 02 00 00 49 63 ec 48 8d 44 6d 00 48 8d 44 85 00 48 8d 7c
    [ 180.719909] RSP: 0018:ffffffffa4607dd0 EFLAGS: 00000202
    [ 180.719982] RAX: 00000000002aea91 RBX: ffffffffa4a5fec0 RCX: 1ffffffff49ca501
    [ 180.720047] RDX: 0000000000000000 RSI: ffffffffa3c6e4e0 RDI: ffffffffa3dcf2a0
    [ 180.720110] RBP: 0000000000000002 R08: 0000000000000001 R09: ffffffffa4e54d17
    [ 180.720173] R10: fffffbfff49ca9a2 R11: 0000000000000001 R12: 0000000000000002
    [ 180.720236] R13: ffff8881169ccc04 R14: 0000002a13899598 R15: ffff8881169ccc00
    [ 180.720321] cpuidle_enter+0x45/0xa0
    [ 180.720413] cpuidle_idle_call+0x274/0x3f0
    [ 180.720503] ? arch_cpu_idle_exit+0x30/0x30
    [ 180.720869] ? tsc_verify_tsc_adjust+0x97/0x2e0
    [ 180.720935] ? lockdep_hardirqs_off+0x90/0xd0
    [ 180.721002] do_idle+0xe0/0x150
    [ 180.721069] cpu_startup_entry+0x14/0x20
    [ 180.721134] start_kernel+0x3a2/0x3c2
    [ 180.721200] secondary_startup_64_no_verify+0xb0/0xbb
    [ 180.721274] </TASK>
    
    Tested-on: WCN6855 hw2.0 PCI WLAN.HSP.1.1-02892.1-QCAHSPSWPL_V1_V2_SILICONZ_LITE-1
    
    Signed-off-by: Wen Gong <quic_wgong@quicinc.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/20211217064132.30911-1-quic_wgong@quicinc.com

commit 1ac287b7b61520d00255b4ec8c8e2dd5f0277169
Author: David Howells <dhowells@redhat.com>
Date:   Tue Dec 7 09:53:24 2021 +0000

    netfs: Fix lockdep warning from taking sb_writers whilst holding mmap_lock
    
    [ Upstream commit 598ad0bd09329818ee041cb3e4b60ba0a70cb1ee ]
    
    Taking sb_writers whilst holding mmap_lock isn't allowed and will result in
    a lockdep warning like that below.  The problem comes from cachefiles
    needing to take the sb_writers lock in order to do a write to the cache,
    but being asked to do this by netfslib called from readpage, readahead or
    write_begin[1].
    
    Fix this by always offloading the write to the cache off to a worker
    thread.  The main thread doesn't need to wait for it, so deadlock can be
    avoided.
    
    This can be tested by running the quick xfstests on something like afs or
    ceph with lockdep enabled.
    
    WARNING: possible circular locking dependency detected
    5.15.0-rc1-build2+ #292 Not tainted
    ------------------------------------------------------
    holetest/65517 is trying to acquire lock:
    ffff88810c81d730 (mapping.invalidate_lock#3){.+.+}-{3:3}, at: filemap_fault+0x276/0x7a5
    
    but task is already holding lock:
    ffff8881595b53e8 (&mm->mmap_lock#2){++++}-{3:3}, at: do_user_addr_fault+0x28d/0x59c
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #2 (&mm->mmap_lock#2){++++}-{3:3}:
           validate_chain+0x3c4/0x4a8
           __lock_acquire+0x89d/0x949
           lock_acquire+0x2dc/0x34b
           __might_fault+0x87/0xb1
           strncpy_from_user+0x25/0x18c
           removexattr+0x7c/0xe5
           __do_sys_fremovexattr+0x73/0x96
           do_syscall_64+0x67/0x7a
           entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    -> #1 (sb_writers#10){.+.+}-{0:0}:
           validate_chain+0x3c4/0x4a8
           __lock_acquire+0x89d/0x949
           lock_acquire+0x2dc/0x34b
           cachefiles_write+0x2b3/0x4bb
           netfs_rreq_do_write_to_cache+0x3b5/0x432
           netfs_readpage+0x2de/0x39d
           filemap_read_page+0x51/0x94
           filemap_get_pages+0x26f/0x413
           filemap_read+0x182/0x427
           new_sync_read+0xf0/0x161
           vfs_read+0x118/0x16e
           ksys_read+0xb8/0x12e
           do_syscall_64+0x67/0x7a
           entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    -> #0 (mapping.invalidate_lock#3){.+.+}-{3:3}:
           check_noncircular+0xe4/0x129
           check_prev_add+0x16b/0x3a4
           validate_chain+0x3c4/0x4a8
           __lock_acquire+0x89d/0x949
           lock_acquire+0x2dc/0x34b
           down_read+0x40/0x4a
           filemap_fault+0x276/0x7a5
           __do_fault+0x96/0xbf
           do_fault+0x262/0x35a
           __handle_mm_fault+0x171/0x1b5
           handle_mm_fault+0x12a/0x233
           do_user_addr_fault+0x3d2/0x59c
           exc_page_fault+0x85/0xa5
           asm_exc_page_fault+0x1e/0x30
    
    other info that might help us debug this:
    
    Chain exists of:
      mapping.invalidate_lock#3 --> sb_writers#10 --> &mm->mmap_lock#2
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&mm->mmap_lock#2);
                                   lock(sb_writers#10);
                                   lock(&mm->mmap_lock#2);
      lock(mapping.invalidate_lock#3);
    
     *** DEADLOCK ***
    
    1 lock held by holetest/65517:
     #0: ffff8881595b53e8 (&mm->mmap_lock#2){++++}-{3:3}, at: do_user_addr_fault+0x28d/0x59c
    
    stack backtrace:
    CPU: 0 PID: 65517 Comm: holetest Not tainted 5.15.0-rc1-build2+ #292
    Hardware name: ASUS All Series/H97-PLUS, BIOS 2306 10/09/2014
    Call Trace:
     dump_stack_lvl+0x45/0x59
     check_noncircular+0xe4/0x129
     ? print_circular_bug+0x207/0x207
     ? validate_chain+0x461/0x4a8
     ? add_chain_block+0x88/0xd9
     ? hlist_add_head_rcu+0x49/0x53
     check_prev_add+0x16b/0x3a4
     validate_chain+0x3c4/0x4a8
     ? check_prev_add+0x3a4/0x3a4
     ? mark_lock+0xa5/0x1c6
     __lock_acquire+0x89d/0x949
     lock_acquire+0x2dc/0x34b
     ? filemap_fault+0x276/0x7a5
     ? rcu_read_unlock+0x59/0x59
     ? add_to_page_cache_lru+0x13c/0x13c
     ? lock_is_held_type+0x7b/0xd3
     down_read+0x40/0x4a
     ? filemap_fault+0x276/0x7a5
     filemap_fault+0x276/0x7a5
     ? pagecache_get_page+0x2dd/0x2dd
     ? __lock_acquire+0x8bc/0x949
     ? pte_offset_kernel.isra.0+0x6d/0xc3
     __do_fault+0x96/0xbf
     ? do_fault+0x124/0x35a
     do_fault+0x262/0x35a
     ? handle_pte_fault+0x1c1/0x20d
     __handle_mm_fault+0x171/0x1b5
     ? handle_pte_fault+0x20d/0x20d
     ? __lock_release+0x151/0x254
     ? mark_held_locks+0x1f/0x78
     ? rcu_read_unlock+0x3a/0x59
     handle_mm_fault+0x12a/0x233
     do_user_addr_fault+0x3d2/0x59c
     ? pgtable_bad+0x70/0x70
     ? rcu_read_lock_bh_held+0xab/0xab
     exc_page_fault+0x85/0xa5
     ? asm_exc_page_fault+0x8/0x30
     asm_exc_page_fault+0x1e/0x30
    RIP: 0033:0x40192f
    Code: ff 48 89 c3 48 8b 05 50 28 00 00 48 85 ed 7e 23 31 d2 4b 8d 0c 2f eb 0a 0f 1f 00 48 8b 05 39 28 00 00 48 0f af c2 48 83 c2 01 <48> 89 1c 01 48 39 d5 7f e8 8b 0d f2 27 00 00 31 c0 85 c9 74 0e 8b
    RSP: 002b:00007f9931867eb0 EFLAGS: 00010202
    RAX: 0000000000000000 RBX: 00007f9931868700 RCX: 00007f993206ac00
    RDX: 0000000000000001 RSI: 0000000000000000 RDI: 00007ffc13e06ee0
    RBP: 0000000000000100 R08: 0000000000000000 R09: 00007f9931868700
    R10: 00007f99318689d0 R11: 0000000000000202 R12: 00007ffc13e06ee0
    R13: 0000000000000c00 R14: 00007ffc13e06e00 R15: 00007f993206a000
    
    Fixes: 726218fdc22c ("netfs: Define an interface to talk to a cache")
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Jeff Layton <jlayton@kernel.org>
    cc: Jan Kara <jack@suse.cz>
    cc: linux-cachefs@redhat.com
    cc: linux-fsdevel@vger.kernel.org
    Link: https://lore.kernel.org/r/20210922110420.GA21576@quack2.suse.cz/ [1]
    Link: https://lore.kernel.org/r/163887597541.1596626.2668163316598972956.stgit@warthog.procyon.org.uk/ # v1
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 598ad0bd09329818ee041cb3e4b60ba0a70cb1ee
Author: David Howells <dhowells@redhat.com>
Date:   Tue Dec 7 09:53:24 2021 +0000

    netfs: Fix lockdep warning from taking sb_writers whilst holding mmap_lock
    
    Taking sb_writers whilst holding mmap_lock isn't allowed and will result in
    a lockdep warning like that below.  The problem comes from cachefiles
    needing to take the sb_writers lock in order to do a write to the cache,
    but being asked to do this by netfslib called from readpage, readahead or
    write_begin[1].
    
    Fix this by always offloading the write to the cache off to a worker
    thread.  The main thread doesn't need to wait for it, so deadlock can be
    avoided.
    
    This can be tested by running the quick xfstests on something like afs or
    ceph with lockdep enabled.
    
    WARNING: possible circular locking dependency detected
    5.15.0-rc1-build2+ #292 Not tainted
    ------------------------------------------------------
    holetest/65517 is trying to acquire lock:
    ffff88810c81d730 (mapping.invalidate_lock#3){.+.+}-{3:3}, at: filemap_fault+0x276/0x7a5
    
    but task is already holding lock:
    ffff8881595b53e8 (&mm->mmap_lock#2){++++}-{3:3}, at: do_user_addr_fault+0x28d/0x59c
    
    which lock already depends on the new lock.
    
    
    the existing dependency chain (in reverse order) is:
    
    -> #2 (&mm->mmap_lock#2){++++}-{3:3}:
           validate_chain+0x3c4/0x4a8
           __lock_acquire+0x89d/0x949
           lock_acquire+0x2dc/0x34b
           __might_fault+0x87/0xb1
           strncpy_from_user+0x25/0x18c
           removexattr+0x7c/0xe5
           __do_sys_fremovexattr+0x73/0x96
           do_syscall_64+0x67/0x7a
           entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    -> #1 (sb_writers#10){.+.+}-{0:0}:
           validate_chain+0x3c4/0x4a8
           __lock_acquire+0x89d/0x949
           lock_acquire+0x2dc/0x34b
           cachefiles_write+0x2b3/0x4bb
           netfs_rreq_do_write_to_cache+0x3b5/0x432
           netfs_readpage+0x2de/0x39d
           filemap_read_page+0x51/0x94
           filemap_get_pages+0x26f/0x413
           filemap_read+0x182/0x427
           new_sync_read+0xf0/0x161
           vfs_read+0x118/0x16e
           ksys_read+0xb8/0x12e
           do_syscall_64+0x67/0x7a
           entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    -> #0 (mapping.invalidate_lock#3){.+.+}-{3:3}:
           check_noncircular+0xe4/0x129
           check_prev_add+0x16b/0x3a4
           validate_chain+0x3c4/0x4a8
           __lock_acquire+0x89d/0x949
           lock_acquire+0x2dc/0x34b
           down_read+0x40/0x4a
           filemap_fault+0x276/0x7a5
           __do_fault+0x96/0xbf
           do_fault+0x262/0x35a
           __handle_mm_fault+0x171/0x1b5
           handle_mm_fault+0x12a/0x233
           do_user_addr_fault+0x3d2/0x59c
           exc_page_fault+0x85/0xa5
           asm_exc_page_fault+0x1e/0x30
    
    other info that might help us debug this:
    
    Chain exists of:
      mapping.invalidate_lock#3 --> sb_writers#10 --> &mm->mmap_lock#2
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&mm->mmap_lock#2);
                                   lock(sb_writers#10);
                                   lock(&mm->mmap_lock#2);
      lock(mapping.invalidate_lock#3);
    
     *** DEADLOCK ***
    
    1 lock held by holetest/65517:
     #0: ffff8881595b53e8 (&mm->mmap_lock#2){++++}-{3:3}, at: do_user_addr_fault+0x28d/0x59c
    
    stack backtrace:
    CPU: 0 PID: 65517 Comm: holetest Not tainted 5.15.0-rc1-build2+ #292
    Hardware name: ASUS All Series/H97-PLUS, BIOS 2306 10/09/2014
    Call Trace:
     dump_stack_lvl+0x45/0x59
     check_noncircular+0xe4/0x129
     ? print_circular_bug+0x207/0x207
     ? validate_chain+0x461/0x4a8
     ? add_chain_block+0x88/0xd9
     ? hlist_add_head_rcu+0x49/0x53
     check_prev_add+0x16b/0x3a4
     validate_chain+0x3c4/0x4a8
     ? check_prev_add+0x3a4/0x3a4
     ? mark_lock+0xa5/0x1c6
     __lock_acquire+0x89d/0x949
     lock_acquire+0x2dc/0x34b
     ? filemap_fault+0x276/0x7a5
     ? rcu_read_unlock+0x59/0x59
     ? add_to_page_cache_lru+0x13c/0x13c
     ? lock_is_held_type+0x7b/0xd3
     down_read+0x40/0x4a
     ? filemap_fault+0x276/0x7a5
     filemap_fault+0x276/0x7a5
     ? pagecache_get_page+0x2dd/0x2dd
     ? __lock_acquire+0x8bc/0x949
     ? pte_offset_kernel.isra.0+0x6d/0xc3
     __do_fault+0x96/0xbf
     ? do_fault+0x124/0x35a
     do_fault+0x262/0x35a
     ? handle_pte_fault+0x1c1/0x20d
     __handle_mm_fault+0x171/0x1b5
     ? handle_pte_fault+0x20d/0x20d
     ? __lock_release+0x151/0x254
     ? mark_held_locks+0x1f/0x78
     ? rcu_read_unlock+0x3a/0x59
     handle_mm_fault+0x12a/0x233
     do_user_addr_fault+0x3d2/0x59c
     ? pgtable_bad+0x70/0x70
     ? rcu_read_lock_bh_held+0xab/0xab
     exc_page_fault+0x85/0xa5
     ? asm_exc_page_fault+0x8/0x30
     asm_exc_page_fault+0x1e/0x30
    RIP: 0033:0x40192f
    Code: ff 48 89 c3 48 8b 05 50 28 00 00 48 85 ed 7e 23 31 d2 4b 8d 0c 2f eb 0a 0f 1f 00 48 8b 05 39 28 00 00 48 0f af c2 48 83 c2 01 <48> 89 1c 01 48 39 d5 7f e8 8b 0d f2 27 00 00 31 c0 85 c9 74 0e 8b
    RSP: 002b:00007f9931867eb0 EFLAGS: 00010202
    RAX: 0000000000000000 RBX: 00007f9931868700 RCX: 00007f993206ac00
    RDX: 0000000000000001 RSI: 0000000000000000 RDI: 00007ffc13e06ee0
    RBP: 0000000000000100 R08: 0000000000000000 R09: 00007f9931868700
    R10: 00007f99318689d0 R11: 0000000000000202 R12: 00007ffc13e06ee0
    R13: 0000000000000c00 R14: 00007ffc13e06e00 R15: 00007f993206a000
    
    Fixes: 726218fdc22c ("netfs: Define an interface to talk to a cache")
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Jeff Layton <jlayton@kernel.org>
    cc: Jan Kara <jack@suse.cz>
    cc: linux-cachefs@redhat.com
    cc: linux-fsdevel@vger.kernel.org
    Link: https://lore.kernel.org/r/20210922110420.GA21576@quack2.suse.cz/ [1]
    Link: https://lore.kernel.org/r/163887597541.1596626.2668163316598972956.stgit@warthog.procyon.org.uk/ # v1

commit 704b914f15fb7daaf517e3acc4bed472b50ca19e
Author: Ming Lei <ming.lei@redhat.com>
Date:   Fri Dec 3 21:15:32 2021 +0800

    blk-mq: move srcu from blk_mq_hw_ctx to request_queue
    
    In case of BLK_MQ_F_BLOCKING, per-hctx srcu is used to protect dispatch
    critical area. However, this srcu instance stays at the end of hctx, and
    it often takes standalone cacheline, often cold.
    
    Inside srcu_read_lock() and srcu_read_unlock(), WRITE is always done on
    the indirect percpu variable which is allocated from heap instead of
    being embedded, srcu->srcu_idx is read only in srcu_read_lock(). It
    doesn't matter if srcu structure stays in hctx or request queue.
    
    So switch to per-request-queue srcu for protecting dispatch, and this
    way simplifies quiesce a lot, not mention quiesce is always done on the
    request queue wide.
    
    Signed-off-by: Ming Lei <ming.lei@redhat.com>
    Link: https://lore.kernel.org/r/20211203131534.3668411-3-ming.lei@redhat.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 340170fef01b18631128006de03522b671e6e2b5
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Sep 24 21:30:26 2021 -0700

    rcutorture: Suppress pi-lock-across read-unlock testing for Tiny SRCU
    
    Because Tiny srcu_read_unlock() directly calls swake_up_one(), lockdep
    complains when a pi lock is held across that srcu_read_unlock().
    Although this is a lockdep false positive (there is no other CPU to
    complete the deadlock cycle), lockdep is what it is at the moment.
    This commit therefore prevents rcutorture from holding pi lock across
    a Tiny srcu_read_unlock().
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 1f8da406a964dcc01121385a54fafd28e1c6a796
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Sep 23 10:07:14 2021 -0700

    srcu: Prevent redundant __srcu_read_unlock() wakeup
    
    Tiny SRCU readers can appear at task level, but also in interrupt and
    softirq handlers.  Because Tiny SRCU is selected only in kernels built
    with CONFIG_SMP=n and CONFIG_PREEMPTION=n, it is not possible for a grace
    period to start while there is a non-task-level SRCU reader executing.
    This means that it does not make sense for __srcu_read_unlock() to awaken
    the Tiny SRCU grace period, because that can only happen when the grace
    period is waiting for one value of ->srcu_idx and __srcu_read_unlock()
    is ending the last reader for some other value of ->srcu_idx.  After all,
    any such wakeup will be redundant.
    
    Worse yet, in some cases, such wakeups generate lockdep splats:
    
            ======================================================
            WARNING: possible circular locking dependency detected
            5.15.0-rc1+ #3758 Not tainted
            ------------------------------------------------------
            rcu_torture_rea/53 is trying to acquire lock:
            ffffffff9514e6a8 (srcu_ctl.srcu_wq.lock){..-.}-{2:2}, at:
            xa/0x30
    
            but task is already holding lock:
            ffff95c642479d80 (&p->pi_lock){-.-.}-{2:2}, at:
            _extend+0x370/0x400
    
            which lock already depends on the new lock.
    
            the existing dependency chain (in reverse order) is:
    
            -> #1 (&p->pi_lock){-.-.}-{2:2}:
                   _raw_spin_lock_irqsave+0x2f/0x50
                   try_to_wake_up+0x50/0x580
                   swake_up_locked.part.7+0xe/0x30
                   swake_up_one+0x22/0x30
                   rcutorture_one_extend+0x1b6/0x400
                   rcu_torture_one_read+0x290/0x5d0
                   rcu_torture_timer+0x1a/0x70
                   call_timer_fn+0xa6/0x230
                   run_timer_softirq+0x493/0x4c0
                   __do_softirq+0xc0/0x371
                   irq_exit+0x73/0x90
                   sysvec_apic_timer_interrupt+0x63/0x80
                   asm_sysvec_apic_timer_interrupt+0x12/0x20
                   default_idle+0xb/0x10
                   default_idle_call+0x5e/0x170
                   do_idle+0x18a/0x1f0
                   cpu_startup_entry+0xa/0x10
                   start_kernel+0x678/0x69f
                   secondary_startup_64_no_verify+0xc2/0xcb
    
            -> #0 (srcu_ctl.srcu_wq.lock){..-.}-{2:2}:
                   __lock_acquire+0x130c/0x2440
                   lock_acquire+0xc2/0x270
                   _raw_spin_lock_irqsave+0x2f/0x50
                   swake_up_one+0xa/0x30
                   rcutorture_one_extend+0x387/0x400
                   rcu_torture_one_read+0x290/0x5d0
                   rcu_torture_reader+0xac/0x200
                   kthread+0x12d/0x150
                   ret_from_fork+0x22/0x30
    
            other info that might help us debug this:
    
             Possible unsafe locking scenario:
    
                   CPU0                    CPU1
                   ----                    ----
              lock(&p->pi_lock);
                                           lock(srcu_ctl.srcu_wq.lock);
                                           lock(&p->pi_lock);
              lock(srcu_ctl.srcu_wq.lock);
    
             *** DEADLOCK ***
    
            1 lock held by rcu_torture_rea/53:
             #0: ffff95c642479d80 (&p->pi_lock){-.-.}-{2:2}, at:
            _extend+0x370/0x400
    
            stack backtrace:
            CPU: 0 PID: 53 Comm: rcu_torture_rea Not tainted 5.15.0-rc1+
    
            Hardware name: Red Hat KVM/RHEL-AV, BIOS
            e_el8.5.0+746+bbd5d70c 04/01/2014
            Call Trace:
             check_noncircular+0xfe/0x110
             ? find_held_lock+0x2d/0x90
             __lock_acquire+0x130c/0x2440
             lock_acquire+0xc2/0x270
             ? swake_up_one+0xa/0x30
             ? find_held_lock+0x72/0x90
             _raw_spin_lock_irqsave+0x2f/0x50
             ? swake_up_one+0xa/0x30
             swake_up_one+0xa/0x30
             rcutorture_one_extend+0x387/0x400
             rcu_torture_one_read+0x290/0x5d0
             rcu_torture_reader+0xac/0x200
             ? rcutorture_oom_notify+0xf0/0xf0
             ? __kthread_parkme+0x61/0x90
             ? rcu_torture_one_read+0x5d0/0x5d0
             kthread+0x12d/0x150
             ? set_kthread_struct+0x40/0x40
             ret_from_fork+0x22/0x30
    
    This is a false positive because there is only one CPU, and both locks
    are raw (non-preemptible) spinlocks.  However, it is worthwhile getting
    rid of the redundant wakeup, which has the side effect of breaking
    the theoretical deadlock cycle.  This commit therefore eliminates the
    redundant wakeups.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 2c9ac51b850d84ee496b0a5d832ce66d411ae552
Author: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
Date:   Wed Jul 21 01:48:29 2021 -0400

    powerpc/perf: Fix PMU callbacks to clear pending PMI before resetting an overflown PMC
    
    Running perf fuzzer showed below in dmesg logs:
      "Can't find PMC that caused IRQ"
    
    This means a PMU exception happened, but none of the PMC's (Performance
    Monitor Counter) were found to be overflown. There are some corner cases
    that clears the PMCs after PMI gets masked. In such cases, the perf
    interrupt handler will not find the active PMC values that had caused
    the overflow and thus leads to this message while replaying.
    
    Case 1: PMU Interrupt happens during replay of other interrupts and
    counter values gets cleared by PMU callbacks before replay:
    
    During replay of interrupts like timer, __do_irq() and doorbell
    exception, we conditionally enable interrupts via may_hard_irq_enable().
    This could potentially create a window to generate a PMI. Since irq soft
    mask is set to ALL_DISABLED, the PMI will get masked here. We could get
    IPIs run before perf interrupt is replayed and the PMU events could
    be deleted or stopped. This will change the PMU SPR values and resets
    the counters. Snippet of ftrace log showing PMU callbacks invoked in
    __do_irq():
    
      <idle>-0 [051] dns. 132025441306354: __do_irq <-call_do_irq
      <idle>-0 [051] dns. 132025441306430: irq_enter <-__do_irq
      <idle>-0 [051] dns. 132025441306503: irq_enter_rcu <-__do_irq
      <idle>-0 [051] dnH. 132025441306599: xive_get_irq <-__do_irq
      <<>>
      <idle>-0 [051] dnH. 132025441307770: generic_smp_call_function_single_interrupt <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441307839: flush_smp_call_function_queue <-smp_ipi_demux_relaxed
      <idle>-0 [051] dnH. 132025441308057: _raw_spin_lock <-event_function
      <idle>-0 [051] dnH. 132025441308206: power_pmu_disable <-perf_pmu_disable
      <idle>-0 [051] dnH. 132025441308337: power_pmu_del <-event_sched_out
      <idle>-0 [051] dnH. 132025441308407: power_pmu_read <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308477: read_pmc <-power_pmu_read
      <idle>-0 [051] dnH. 132025441308590: isa207_disable_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308663: write_pmc <-power_pmu_del
      <idle>-0 [051] dnH. 132025441308787: power_pmu_event_idx <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308859: rcu_read_unlock_strict <-perf_event_update_userpage
      <idle>-0 [051] dnH. 132025441308975: power_pmu_enable <-perf_pmu_enable
      <<>>
      <idle>-0 [051] dnH. 132025441311108: irq_exit <-__do_irq
      <idle>-0 [051] dns. 132025441311319: performance_monitor_exception <-replay_soft_interrupts
    
    Case 2: PMI's masked during local_* operations, example local_add(). If
    the local_add() operation happens within a local_irq_save(), replay of
    PMI will be during local_irq_restore(). Similar to case 1, this could
    also create a window before replay where PMU events gets deleted or
    stopped.
    
    Fix it by updating the PMU callback function power_pmu_disable() to
    check for pending perf interrupt. If there is an overflown PMC and
    pending perf interrupt indicated in paca, clear the PMI bit in paca to
    drop that sample. Clearing of PMI bit is done in power_pmu_disable()
    since disable is invoked before any event gets deleted/stopped. With
    this fix, if there are more than one event running in the PMU, there is
    a chance that we clear the PMI bit for the event which is not getting
    deleted/stopped. The other events may still remain active. Hence to make
    sure we don't drop valid sample in such cases, another check is added in
    power_pmu_enable. This checks if there is an overflown PMC found among
    the active events and if so enable back the PMI bit. Two new helper
    functions are introduced to clear/set the PMI, ie
    clear_pmi_irq_pending() and set_pmi_irq_pending(). Helper function
    pmi_irq_pending() is introduced to give a warning if there is pending
    PMI bit in paca, but no PMC is overflown.
    
    Also there are corner cases which result in performance monitor
    interrupts being triggered during power_pmu_disable(). This happens
    since PMXE bit is not cleared along with disabling of other MMCR0 bits
    in the pmu_disable. Such PMI's could leave the PMU running and could
    trigger PMI again which will set MMCR0 PMAO bit. This could lead to
    spurious interrupts in some corner cases. Example, a timer after
    power_pmu_del() which will re-enable interrupts and triggers a PMI again
    since PMAO bit is still set. But fails to find valid overflow since PMC
    was cleared in power_pmu_del(). Fix that by disabling PMXE along with
    disabling of other MMCR0 bits in power_pmu_disable().
    
    We can't just replay PMI any time. Hence this approach is preferred
    rather than replaying PMI before resetting overflown PMC. Patch also
    documents core-book3s on a race condition which can trigger these PMC
    messages during idle path in PowerNV.
    
    Fixes: f442d004806e ("powerpc/64s: Add support to mask perf interrupts and replay them")
    Reported-by: Nageswara R Sastry <nasastry@in.ibm.com>
    Suggested-by: Nicholas Piggin <npiggin@gmail.com>
    Suggested-by: Madhavan Srinivasan <maddy@linux.ibm.com>
    Signed-off-by: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
    Tested-by: Nageswara R Sastry <rnsastry@linux.ibm.com>
    Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
    [mpe: Make pmi_irq_pending() return bool, reflow/reword some comments]
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/1626846509-1350-2-git-send-email-atrajeev@linux.vnet.ibm.com

commit 0757ca01d944001254a94ac1b25ced702a1e9ac5
Merge: 3498e7f2bb41 86dc40c7ea9c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Nov 28 07:17:38 2021 -0800

    Merge tag 'iommu-fixes-v5.16-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu
    
    Pull iommu fixes from Joerg Roedel:
    
     - Intel VT-d fixes:
         - Remove unused PASID_DISABLED
         - Fix RCU locking
         - Fix for the unmap_pages call-back
    
     - Rockchip RK3568 address mask fix
    
     - AMD IOMMUv2 log message clarification
    
    * tag 'iommu-fixes-v5.16-rc2' of git://git.kernel.org/pub/scm/linux/kernel/git/joro/iommu:
      iommu/vt-d: Fix unmap_pages support
      iommu/vt-d: Fix an unbalanced rcu_read_lock/rcu_read_unlock()
      iommu/rockchip: Fix PAGE_DESC_HI_MASKs for RK3568
      iommu/amd: Clarify AMD IOMMUv2 initialization messages
      iommu/vt-d: Remove unused PASID_DISABLED

commit 4e5973dd2725bb30c3db622f7d73f7a5864ce718
Author: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
Date:   Fri Nov 26 21:55:55 2021 +0800

    iommu/vt-d: Fix an unbalanced rcu_read_lock/rcu_read_unlock()
    
    If we return -EOPNOTSUPP, the rcu lock remains lock. This is spurious.
    Go through the end of the function instead. This way, the missing
    'rcu_read_unlock()' is called.
    
    Fixes: 7afd7f6aa21a ("iommu/vt-d: Check FL and SL capability sanity in scalable mode")
    Signed-off-by: Christophe JAILLET <christophe.jaillet@wanadoo.fr>
    Link: https://lore.kernel.org/r/40cc077ca5f543614eab2a10e84d29dd190273f6.1636217517.git.christophe.jaillet@wanadoo.fr
    Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
    Link: https://lore.kernel.org/r/20211126135556.397932-2-baolu.lu@linux.intel.com
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

commit 512e21c150c1c3ee298852660f3a796e267e62ec
Author: Mathias Krause <minipli@grsecurity.net>
Date:   Wed Nov 3 20:06:13 2021 +0100

    sched/fair: Prevent dead task groups from regaining cfs_rq's
    
    [ Upstream commit b027789e5e50494c2325cc70c8642e7fd6059479 ]
    
    Kevin is reporting crashes which point to a use-after-free of a cfs_rq
    in update_blocked_averages(). Initial debugging revealed that we've
    live cfs_rq's (on_list=1) in an about to be kfree()'d task group in
    free_fair_sched_group(). However, it was unclear how that can happen.
    
    His kernel config happened to lead to a layout of struct sched_entity
    that put the 'my_q' member directly into the middle of the object
    which makes it incidentally overlap with SLUB's freelist pointer.
    That, in combination with SLAB_FREELIST_HARDENED's freelist pointer
    mangling, leads to a reliable access violation in form of a #GP which
    made the UAF fail fast.
    
    Michal seems to have run into the same issue[1]. He already correctly
    diagnosed that commit a7b359fc6a37 ("sched/fair: Correctly insert
    cfs_rq's to list on unthrottle") is causing the preconditions for the
    UAF to happen by re-adding cfs_rq's also to task groups that have no
    more running tasks, i.e. also to dead ones. His analysis, however,
    misses the real root cause and it cannot be seen from the crash
    backtrace only, as the real offender is tg_unthrottle_up() getting
    called via sched_cfs_period_timer() via the timer interrupt at an
    inconvenient time.
    
    When unregister_fair_sched_group() unlinks all cfs_rq's from the dying
    task group, it doesn't protect itself from getting interrupted. If the
    timer interrupt triggers while we iterate over all CPUs or after
    unregister_fair_sched_group() has finished but prior to unlinking the
    task group, sched_cfs_period_timer() will execute and walk the list of
    task groups, trying to unthrottle cfs_rq's, i.e. re-add them to the
    dying task group. These will later -- in free_fair_sched_group() -- be
    kfree()'ed while still being linked, leading to the fireworks Kevin
    and Michal are seeing.
    
    To fix this race, ensure the dying task group gets unlinked first.
    However, simply switching the order of unregistering and unlinking the
    task group isn't sufficient, as concurrent RCU walkers might still see
    it, as can be seen below:
    
        CPU1:                                      CPU2:
          :                                        timer IRQ:
          :                                          do_sched_cfs_period_timer():
          :                                            :
          :                                            distribute_cfs_runtime():
          :                                              rcu_read_lock();
          :                                              :
          :                                              unthrottle_cfs_rq():
        sched_offline_group():                             :
          :                                                walk_tg_tree_from(,tg_unthrottle_up,):
          list_del_rcu(&tg->list);                           :
     (1)  :                                                  list_for_each_entry_rcu(child, &parent->children, siblings)
          :                                                    :
     (2)  list_del_rcu(&tg->siblings);                         :
          :                                                    tg_unthrottle_up():
          unregister_fair_sched_group():                         struct cfs_rq *cfs_rq = tg->cfs_rq[cpu_of(rq)];
            :                                                    :
            list_del_leaf_cfs_rq(tg->cfs_rq[cpu]);               :
            :                                                    :
            :                                                    if (!cfs_rq_is_decayed(cfs_rq) || cfs_rq->nr_running)
     (3)    :                                                        list_add_leaf_cfs_rq(cfs_rq);
          :                                                      :
          :                                                    :
          :                                                  :
          :                                                :
          :                                              :
     (4)  :                                              rcu_read_unlock();
    
    CPU 2 walks the task group list in parallel to sched_offline_group(),
    specifically, it'll read the soon to be unlinked task group entry at
    (1). Unlinking it on CPU 1 at (2) therefore won't prevent CPU 2 from
    still passing it on to tg_unthrottle_up(). CPU 1 now tries to unlink
    all cfs_rq's via list_del_leaf_cfs_rq() in
    unregister_fair_sched_group().  Meanwhile CPU 2 will re-add some of
    these at (3), which is the cause of the UAF later on.
    
    To prevent this additional race from happening, we need to wait until
    walk_tg_tree_from() has finished traversing the task groups, i.e.
    after the RCU read critical section ends in (4). Afterwards we're safe
    to call unregister_fair_sched_group(), as each new walk won't see the
    dying task group any more.
    
    On top of that, we need to wait yet another RCU grace period after
    unregister_fair_sched_group() to ensure print_cfs_stats(), which might
    run concurrently, always sees valid objects, i.e. not already free'd
    ones.
    
    This patch survives Michal's reproducer[2] for 8h+ now, which used to
    trigger within minutes before.
    
      [1] https://lore.kernel.org/lkml/20211011172236.11223-1-mkoutny@suse.com/
      [2] https://lore.kernel.org/lkml/20211102160228.GA57072@blackbody.suse.cz/
    
    Fixes: a7b359fc6a37 ("sched/fair: Correctly insert cfs_rq's to list on unthrottle")
    [peterz: shuffle code around a bit]
    Reported-by: Kevin Tanguy <kevin.tanguy@corp.ovh.com>
    Signed-off-by: Mathias Krause <minipli@grsecurity.net>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 627b94f75b82d13d1530b59155a545fd99d807db
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Nov 23 14:56:08 2021 -0800

    gro: remove rcu_read_lock/rcu_read_unlock from gro_complete handlers
    
    All gro_complete() handlers are called from napi_gro_complete()
    while rcu_read_lock() has been called.
    
    There is no point stacking more rcu_read_lock()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit fc1ca3348a74a1afaa7ffebc2b2f2cc149e11278
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Nov 23 14:56:07 2021 -0800

    gro: remove rcu_read_lock/rcu_read_unlock from gro_receive handlers
    
    All gro_receive() handlers are called from dev_gro_receive()
    while rcu_read_lock() has been called.
    
    There is no point stacking more rcu_read_lock()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit 9508ee70d138a11895f6308b1db69ed06fb4ebc4
Author: Scott Wood <swood@redhat.com>
Date:   Fri Aug 20 09:42:36 2021 +0200

    rcutorture: Avoid problematic critical section nesting on PREEMPT_RT
    
    [ Upstream commit 71921a9606ddbcc1d98c00eca7ae82c373d1fecd ]
    
    rcutorture is generating some nesting scenarios that are not compatible on PREEMPT_RT.
    For example:
            preempt_disable();
            rcu_read_lock_bh();
            preempt_enable();
            rcu_read_unlock_bh();
    
    The problem here is that on PREEMPT_RT the bottom halves have to be
    disabled and enabled in preemptible context.
    
    Reorder locking: start with BH locking and continue with then with
    disabling preemption or interrupts. In the unlocking do it reverse by
    first enabling interrupts and preemption and BH at the very end.
    Ensure that on PREEMPT_RT BH locking remains unchanged if in
    non-preemptible context.
    
    Link: https://lkml.kernel.org/r/20190911165729.11178-6-swood@redhat.com
    Link: https://lkml.kernel.org/r/20210819182035.GF4126399@paulmck-ThinkPad-P17-Gen-1
    Signed-off-by: Scott Wood <swood@redhat.com>
    [bigeasy: Drop ATOM_BH, make it only about changing BH in atomic
    context. Allow enabling RCU in IRQ-off section. Reword commit message.]
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7f43cda650d5ca7cac9ced26bb2f3f64643ddb9d
Author: Scott Wood <swood@redhat.com>
Date:   Fri Aug 20 09:42:36 2021 +0200

    rcutorture: Avoid problematic critical section nesting on PREEMPT_RT
    
    [ Upstream commit 71921a9606ddbcc1d98c00eca7ae82c373d1fecd ]
    
    rcutorture is generating some nesting scenarios that are not compatible on PREEMPT_RT.
    For example:
            preempt_disable();
            rcu_read_lock_bh();
            preempt_enable();
            rcu_read_unlock_bh();
    
    The problem here is that on PREEMPT_RT the bottom halves have to be
    disabled and enabled in preemptible context.
    
    Reorder locking: start with BH locking and continue with then with
    disabling preemption or interrupts. In the unlocking do it reverse by
    first enabling interrupts and preemption and BH at the very end.
    Ensure that on PREEMPT_RT BH locking remains unchanged if in
    non-preemptible context.
    
    Link: https://lkml.kernel.org/r/20190911165729.11178-6-swood@redhat.com
    Link: https://lkml.kernel.org/r/20210819182035.GF4126399@paulmck-ThinkPad-P17-Gen-1
    Signed-off-by: Scott Wood <swood@redhat.com>
    [bigeasy: Drop ATOM_BH, make it only about changing BH in atomic
    context. Allow enabling RCU in IRQ-off section. Reword commit message.]
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d50100c17038d5448dcf959ba6853f0d61a4c65d
Author: Scott Wood <swood@redhat.com>
Date:   Fri Aug 20 09:42:36 2021 +0200

    rcutorture: Avoid problematic critical section nesting on PREEMPT_RT
    
    [ Upstream commit 71921a9606ddbcc1d98c00eca7ae82c373d1fecd ]
    
    rcutorture is generating some nesting scenarios that are not compatible on PREEMPT_RT.
    For example:
            preempt_disable();
            rcu_read_lock_bh();
            preempt_enable();
            rcu_read_unlock_bh();
    
    The problem here is that on PREEMPT_RT the bottom halves have to be
    disabled and enabled in preemptible context.
    
    Reorder locking: start with BH locking and continue with then with
    disabling preemption or interrupts. In the unlocking do it reverse by
    first enabling interrupts and preemption and BH at the very end.
    Ensure that on PREEMPT_RT BH locking remains unchanged if in
    non-preemptible context.
    
    Link: https://lkml.kernel.org/r/20190911165729.11178-6-swood@redhat.com
    Link: https://lkml.kernel.org/r/20210819182035.GF4126399@paulmck-ThinkPad-P17-Gen-1
    Signed-off-by: Scott Wood <swood@redhat.com>
    [bigeasy: Drop ATOM_BH, make it only about changing BH in atomic
    context. Allow enabling RCU in IRQ-off section. Reword commit message.]
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b027789e5e50494c2325cc70c8642e7fd6059479
Author: Mathias Krause <minipli@grsecurity.net>
Date:   Wed Nov 3 20:06:13 2021 +0100

    sched/fair: Prevent dead task groups from regaining cfs_rq's
    
    Kevin is reporting crashes which point to a use-after-free of a cfs_rq
    in update_blocked_averages(). Initial debugging revealed that we've
    live cfs_rq's (on_list=1) in an about to be kfree()'d task group in
    free_fair_sched_group(). However, it was unclear how that can happen.
    
    His kernel config happened to lead to a layout of struct sched_entity
    that put the 'my_q' member directly into the middle of the object
    which makes it incidentally overlap with SLUB's freelist pointer.
    That, in combination with SLAB_FREELIST_HARDENED's freelist pointer
    mangling, leads to a reliable access violation in form of a #GP which
    made the UAF fail fast.
    
    Michal seems to have run into the same issue[1]. He already correctly
    diagnosed that commit a7b359fc6a37 ("sched/fair: Correctly insert
    cfs_rq's to list on unthrottle") is causing the preconditions for the
    UAF to happen by re-adding cfs_rq's also to task groups that have no
    more running tasks, i.e. also to dead ones. His analysis, however,
    misses the real root cause and it cannot be seen from the crash
    backtrace only, as the real offender is tg_unthrottle_up() getting
    called via sched_cfs_period_timer() via the timer interrupt at an
    inconvenient time.
    
    When unregister_fair_sched_group() unlinks all cfs_rq's from the dying
    task group, it doesn't protect itself from getting interrupted. If the
    timer interrupt triggers while we iterate over all CPUs or after
    unregister_fair_sched_group() has finished but prior to unlinking the
    task group, sched_cfs_period_timer() will execute and walk the list of
    task groups, trying to unthrottle cfs_rq's, i.e. re-add them to the
    dying task group. These will later -- in free_fair_sched_group() -- be
    kfree()'ed while still being linked, leading to the fireworks Kevin
    and Michal are seeing.
    
    To fix this race, ensure the dying task group gets unlinked first.
    However, simply switching the order of unregistering and unlinking the
    task group isn't sufficient, as concurrent RCU walkers might still see
    it, as can be seen below:
    
        CPU1:                                      CPU2:
          :                                        timer IRQ:
          :                                          do_sched_cfs_period_timer():
          :                                            :
          :                                            distribute_cfs_runtime():
          :                                              rcu_read_lock();
          :                                              :
          :                                              unthrottle_cfs_rq():
        sched_offline_group():                             :
          :                                                walk_tg_tree_from(,tg_unthrottle_up,):
          list_del_rcu(&tg->list);                           :
     (1)  :                                                  list_for_each_entry_rcu(child, &parent->children, siblings)
          :                                                    :
     (2)  list_del_rcu(&tg->siblings);                         :
          :                                                    tg_unthrottle_up():
          unregister_fair_sched_group():                         struct cfs_rq *cfs_rq = tg->cfs_rq[cpu_of(rq)];
            :                                                    :
            list_del_leaf_cfs_rq(tg->cfs_rq[cpu]);               :
            :                                                    :
            :                                                    if (!cfs_rq_is_decayed(cfs_rq) || cfs_rq->nr_running)
     (3)    :                                                        list_add_leaf_cfs_rq(cfs_rq);
          :                                                      :
          :                                                    :
          :                                                  :
          :                                                :
          :                                              :
     (4)  :                                              rcu_read_unlock();
    
    CPU 2 walks the task group list in parallel to sched_offline_group(),
    specifically, it'll read the soon to be unlinked task group entry at
    (1). Unlinking it on CPU 1 at (2) therefore won't prevent CPU 2 from
    still passing it on to tg_unthrottle_up(). CPU 1 now tries to unlink
    all cfs_rq's via list_del_leaf_cfs_rq() in
    unregister_fair_sched_group().  Meanwhile CPU 2 will re-add some of
    these at (3), which is the cause of the UAF later on.
    
    To prevent this additional race from happening, we need to wait until
    walk_tg_tree_from() has finished traversing the task groups, i.e.
    after the RCU read critical section ends in (4). Afterwards we're safe
    to call unregister_fair_sched_group(), as each new walk won't see the
    dying task group any more.
    
    On top of that, we need to wait yet another RCU grace period after
    unregister_fair_sched_group() to ensure print_cfs_stats(), which might
    run concurrently, always sees valid objects, i.e. not already free'd
    ones.
    
    This patch survives Michal's reproducer[2] for 8h+ now, which used to
    trigger within minutes before.
    
      [1] https://lore.kernel.org/lkml/20211011172236.11223-1-mkoutny@suse.com/
      [2] https://lore.kernel.org/lkml/20211102160228.GA57072@blackbody.suse.cz/
    
    Fixes: a7b359fc6a37 ("sched/fair: Correctly insert cfs_rq's to list on unthrottle")
    [peterz: shuffle code around a bit]
    Reported-by: Kevin Tanguy <kevin.tanguy@corp.ovh.com>
    Signed-off-by: Mathias Krause <minipli@grsecurity.net>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>

commit 6fedc28076bbbb32edb722e80f9406a3d1d668a8
Merge: 79ef0c001425 dd1277d2ad95
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Nov 1 20:25:38 2021 -0700

    Merge tag 'rcu.2021.11.01a' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu
    
    Pull RCU updates from Paul McKenney:
    
     - Miscellaneous fixes
    
     - Torture-test updates for smp_call_function(), most notably improved
       checking of module parameters.
    
     - Tasks-trace RCU updates that fix a number of rare but important
       race-condition bugs.
    
     - Other torture-test updates, most notably better checking of module
       parameters. In addition, rcutorture may once again be run on
       CONFIG_PREEMPT_RT kernels.
    
     - Torture-test scripting updates, most notably specifying the new
       CONFIG_KCSAN_STRICT kconfig option rather than maintaining an
       ever-changing list of individual KCSAN kconfig options.
    
    * tag 'rcu.2021.11.01a' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu: (46 commits)
      rcu: Fix rcu_dynticks_curr_cpu_in_eqs() vs noinstr
      rcu: Always inline rcu_dynticks_task*_{enter,exit}()
      torture: Make kvm-remote.sh print size of downloaded tarball
      torture: Allot 1G of memory for scftorture runs
      tools/rcu: Add an extract-stall script
      scftorture: Warn on individual scf_torture_init() error conditions
      scftorture: Count reschedule IPIs
      scftorture: Account for weight_resched when checking for all zeroes
      scftorture: Shut down if nonsensical arguments given
      scftorture: Allow zero weight to exclude an smp_call_function*() category
      rcu: Avoid unneeded function call in rcu_read_unlock()
      rcu-tasks: Update comments to cond_resched_tasks_rcu_qs()
      rcu-tasks: Fix IPI failure handling in trc_wait_for_one_reader
      rcu-tasks: Fix read-side primitives comment for call_rcu_tasks_trace
      rcu-tasks: Clarify read side section info for rcu_tasks_rude GP primitives
      rcu-tasks: Correct comparisons for CPU numbers in show_stalled_task_trace
      rcu-tasks: Correct firstreport usage in check_all_holdout_tasks_trace
      rcu-tasks: Fix s/rcu_add_holdout/trc_add_holdout/ typo in comment
      rcu-tasks: Move RTGS_WAIT_CBS to beginning of rcu_tasks_kthread() loop
      rcu-tasks: Fix s/instruction/instructions/ typo in comment
      ...

commit e94f68527a35271131cdf9d3fb4eb3c2513dc3d0
Author: Pavel Begunkov <asml.silence@gmail.com>
Date:   Thu Oct 21 14:30:52 2021 +0100

    block: kill extra rcu lock/unlock in queue enter
    
    blk_try_enter_queue() already takes rcu_read_lock/unlock, so we can
    avoid the second pair in percpu_ref_tryget_live(), use a newly added
    percpu_ref_tryget_live_rcu().
    
    As rcu_read_lock/unlock imply barrier()s, it's pretty noticeable,
    especially for for !CONFIG_PREEMPT_RCU (default for some distributions),
    where __rcu_read_lock/unlock() are not inlined.
    
    3.20%  io_uring  [kernel.vmlinux]  [k] __rcu_read_unlock
    3.05%  io_uring  [kernel.vmlinux]  [k] __rcu_read_lock
    
    2.52%  io_uring  [kernel.vmlinux]  [k] __rcu_read_unlock
    2.28%  io_uring  [kernel.vmlinux]  [k] __rcu_read_lock
    
    Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
    Link: https://lore.kernel.org/r/6b11c67ea495ed9d44f067622d852de4a510ce65.1634822969.git.asml.silence@gmail.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 6213f07cb542c9651ba614e784bf58ed41354936
Author: Li RongQing <lirongqing@baidu.com>
Date:   Sat Oct 9 17:32:43 2021 +0800

    virtio_net: skip RCU read lock by checking xdp_enabled of vi
    
    networking benchmark shows that __rcu_read_lock and
    __rcu_read_unlock takes some cpu cycles, and we can avoid
    calling them partially in virtio rx path by check xdp_enabled
    of vi, and xdp is disabled most of time
    
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a585070f268223766fcab4b9eb9eade28381eb48
Author: Christian Knig <christian.koenig@amd.com>
Date:   Mon Sep 13 12:36:42 2021 +0200

    drm/i915: use the new iterator in i915_request_await_object v2
    
    Simplifying the code a bit.
    
    v2: add missing rcu_read_lock()/rcu_read_unlock()
    v3: use dma_resv_for_each_fence instead
    
    Signed-off-by: Christian Knig <christian.koenig@amd.com>
    Reviewed-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20211005113742.1101-20-christian.koenig@amd.com

commit 677e362ba807f3aafe6f405c07e0b37244da5222
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d56171d9360c0170c5c5f8f7e2362a2e999eca40
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit dacfd5e4d1142bfb3809aab3634a375f6f373269
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 488da313edf3abea7f7733efe011c96b23740ab5
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9321f8152d9a764208c3f0dad49e0c55f293b7ab
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Sep 28 17:00:06 2021 +0200

    rtmutex: Wake up the waiters lockless while dropping the read lock.
    
    The rw_semaphore and rwlock_t implementation both wake the waiter while
    holding the rt_mutex_base::wait_lock acquired.
    This can be optimized by waking the waiter lockless outside of the
    locked section to avoid a needless contention on the
    rt_mutex_base::wait_lock lock.
    
    Extend rt_mutex_wake_q_add() to also accept task and state and use it in
    __rwbase_read_unlock().
    
    Suggested-by: Davidlohr Bueso <dave@stgolabs.net>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20210928150006.597310-3-bigeasy@linutronix.de

commit a5f8e86192612d0183047448d8bbe7918b3f1a26
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3815fe7371d2411ce164281cef40d9fc7b323dee
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ebb8d26d93c3ec3c7576c52a8373a2309423c069
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    [ Upstream commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9 ]
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5afedf670caf30a2b5a52da96eb7eac7dee6a9c9
Author: Zhihao Cheng <chengzhihao1@huawei.com>
Date:   Thu Sep 23 21:49:21 2021 +0800

    blktrace: Fix uaf in blk_trace access after removing by sysfs
    
    There is an use-after-free problem triggered by following process:
    
          P1(sda)                           P2(sdb)
                            echo 0 > /sys/block/sdb/trace/enable
                              blk_trace_remove_queue
                                synchronize_rcu
                                blk_trace_free
                                  relay_close
    rcu_read_lock
    __blk_add_trace
      trace_note_tsk
      (Iterate running_trace_list)
                                    relay_close_buf
                                      relay_destroy_buf
                                        kfree(buf)
        trace_note(sdb's bt)
          relay_reserve
            buf->offset <- nullptr deference (use-after-free) !!!
    rcu_read_unlock
    
    [  502.714379] BUG: kernel NULL pointer dereference, address:
    0000000000000010
    [  502.715260] #PF: supervisor read access in kernel mode
    [  502.715903] #PF: error_code(0x0000) - not-present page
    [  502.716546] PGD 103984067 P4D 103984067 PUD 17592b067 PMD 0
    [  502.717252] Oops: 0000 [#1] SMP
    [  502.720308] RIP: 0010:trace_note.isra.0+0x86/0x360
    [  502.732872] Call Trace:
    [  502.733193]  __blk_add_trace.cold+0x137/0x1a3
    [  502.733734]  blk_add_trace_rq+0x7b/0xd0
    [  502.734207]  blk_add_trace_rq_issue+0x54/0xa0
    [  502.734755]  blk_mq_start_request+0xde/0x1b0
    [  502.735287]  scsi_queue_rq+0x528/0x1140
    ...
    [  502.742704]  sg_new_write.isra.0+0x16e/0x3e0
    [  502.747501]  sg_ioctl+0x466/0x1100
    
    Reproduce method:
      ioctl(/dev/sda, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sda, BLKTRACESTART)
      ioctl(/dev/sdb, BLKTRACESETUP, blk_user_trace_setup[buf_size=127])
      ioctl(/dev/sdb, BLKTRACESTART)
    
      echo 0 > /sys/block/sdb/trace/enable &
      // Add delay(mdelay/msleep) before kernel enters blk_trace_free()
    
      ioctl$SG_IO(/dev/sda, SG_IO, ...)
      // Enters trace_note_tsk() after blk_trace_free() returned
      // Use mdelay in rcu region rather than msleep(which may schedule out)
    
    Remove blk_trace from running_list before calling blk_trace_free() by
    sysfs if blk_trace is at Blktrace_running state.
    
    Fixes: c71a896154119f ("blktrace: add ftrace plugin")
    Signed-off-by: Zhihao Cheng <chengzhihao1@huawei.com>
    Link: https://lore.kernel.org/r/20210923134921.109194-1-chengzhihao1@huawei.com
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit b2fe31cf648156331991333c1d87346321cab056
Author: xinhui pan <xinhui.pan@amd.com>
Date:   Wed Sep 15 09:08:28 2021 +0800

    drm/amdgpu: Put drm_dev_enter/exit outside hot codepath
    
    We hit soft hang while doing memory pressure test on one numa system.
    After a qucik look, this is because kfd invalid/valid userptr memory
    frequently with process_info lock hold.
    Looks like update page table mapping use too much cpu time.
    
    perf top says below,
    75.81%  [kernel]       [k] __srcu_read_unlock
     6.19%  [amdgpu]       [k] amdgpu_gmc_set_pte_pde
     3.56%  [kernel]       [k] __srcu_read_lock
     2.20%  [amdgpu]       [k] amdgpu_vm_cpu_update
     2.20%  [kernel]       [k] __sg_page_iter_dma_next
     2.15%  [drm]          [k] drm_dev_enter
     1.70%  [drm]          [k] drm_prime_sg_to_dma_addr_array
     1.18%  [kernel]       [k] __sg_alloc_table_from_pages
     1.09%  [drm]          [k] drm_dev_exit
    
    So move drm_dev_enter/exit outside gmc code, instead let caller do it.
    They are gart_unbind, gart_map, vm_clear_bo, vm_update_pdes and
    gmc_init_pdb0. vm_bo_update_mapping already calls it.
    
    Signed-off-by: xinhui pan <xinhui.pan@amd.com>
    Reviewed-and-tested-by: Andrey Grodzovsky <andrey.grodzovsky@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

commit 64dd1fbb0bb743ccd2fb420c441f4ca9732f598f
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:31 2021 +0800

    fcntl: fix potential deadlock for &fasync_struct.fa_lock
    
    [ Upstream commit 2f488f698fda820f8e6fa0407630154eceb145d6 ]
    
    There is an existing lock hierarchy of
    &dev->event_lock --> &fasync_struct.fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    &dev->event_lock is HARDIRQ-safe, so interrupts have to be disabled
    while grabbing &fasync_struct.fa_lock, otherwise we invert the lock
    hierarchy. However, since kill_fasync which calls kill_fasync_rcu is
    an exported symbol, it may not necessarily be called with interrupts
    disabled.
    
    As kill_fasync_rcu may be called with interrupts disabled (for
    example, in the call chain above), we replace calls to
    read_lock/read_unlock on &fasync_struct.fa_lock in kill_fasync_rcu
    with read_lock_irqsave/read_unlock_irqrestore.
    
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5ecb17485abe61a4feb62c7dd76d0eb7b8475273
Author: Qiang.Zhang <qiang.zhang@windriver.com>
Date:   Tue Aug 31 10:29:19 2021 +0800

    tracing/osnoise: Fix missed cpus_read_unlock() in start_per_cpu_kthreads()
    
    commit 4b6b08f2e45edda4c067ac40833e3c1f84383c0b upstream.
    
    When start_kthread() return error, the cpus_read_unlock() need
    to be called.
    
    Link: https://lkml.kernel.org/r/20210831022919.27630-1-qiang.zhang@windriver.com
    
    Cc: <stable@vger.kernel.org>
    Fixes: c8895e271f79 ("trace/osnoise: Support hotplug operations")
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Qiang.Zhang <qiang.zhang@windriver.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 925da92ba5cb0c82d07cdd5049a07e40f54e9c44
Author: Waiman Long <longman@redhat.com>
Date:   Thu Aug 26 22:21:22 2021 -0400

    rcu: Avoid unneeded function call in rcu_read_unlock()
    
    Since commit aa40c138cc8f3 ("rcu: Report QS for outermost PREEMPT=n
    rcu_read_unlock() for strict GPs") the function rcu_read_unlock_strict()
    is invoked by the inlined rcu_read_unlock() function.  However,
    rcu_read_unlock_strict() is an empty function in production kernels,
    which are built with CONFIG_RCU_STRICT_GRACE_PERIOD=n.
    
    There is a mention of rcu_read_unlock_strict() in the BPF verifier,
    but this is in a deny-list, meaning that BPF does not care whether
    rcu_read_unlock_strict() is ever called.
    
    This commit therefore provides a slight performance improvement
    by hoisting the check of CONFIG_RCU_STRICT_GRACE_PERIOD from
    rcu_read_unlock_strict() into rcu_read_unlock(), thus avoiding the
    pointless call to an empty function.
    
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Acked-by: Andrii Nakryiko <andrii@kernel.org>
    Signed-off-by: Waiman Long <longman@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit ed42c38067129c85ab1bda39f2fd91924a432dc0
Author: Neeraj Upadhyay <neeraju@codeaurora.org>
Date:   Wed Aug 25 12:40:50 2021 +0530

    rcu-tasks: Fix read-side primitives comment for call_rcu_tasks_trace
    
    call_rcu_tasks_trace() does have read-side primitives - rcu_read_lock_trace()
    and rcu_read_unlock_trace(). Fix this information in the comments.
    
    Signed-off-by: Neeraj Upadhyay <neeraju@codeaurora.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit a5c071ccfa1728508f31e61213ee795e4529d0d4
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Jul 28 12:28:27 2021 -0700

    rcu-tasks: Remove second argument of rcu_read_unlock_trace_special()
    
    The second argument of rcu_read_unlock_trace_special() is always zero.
    When called from exit_tasks_rcu_finish_trace(), it is the constant
    zero, and rcu_read_unlock_trace_special() doesn't get called from
    rcu_read_unlock_trace() unless the value of local variable "nesting"
    is zero because in that case the early return is taken instead.
    
    This commit therefore removes the "nesting" argument from the
    rcu_read_unlock_trace_special() function, substituting the constant
    zero within that function.  This commit also adds a WARN_ON_ONCE()
    to rcu_read_lock_trace_held() in case non-zeroness some day appears.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 3511a749b9d37e9ffee8fb35d3abea49595cdef6
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:31 2021 +0800

    fcntl: fix potential deadlock for &fasync_struct.fa_lock
    
    [ Upstream commit 2f488f698fda820f8e6fa0407630154eceb145d6 ]
    
    There is an existing lock hierarchy of
    &dev->event_lock --> &fasync_struct.fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    &dev->event_lock is HARDIRQ-safe, so interrupts have to be disabled
    while grabbing &fasync_struct.fa_lock, otherwise we invert the lock
    hierarchy. However, since kill_fasync which calls kill_fasync_rcu is
    an exported symbol, it may not necessarily be called with interrupts
    disabled.
    
    As kill_fasync_rcu may be called with interrupts disabled (for
    example, in the call chain above), we replace calls to
    read_lock/read_unlock on &fasync_struct.fa_lock in kill_fasync_rcu
    with read_lock_irqsave/read_unlock_irqrestore.
    
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d633a4b724423438de294637574a51cb2b4a86ec
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:30 2021 +0800

    fcntl: fix potential deadlocks for &fown_struct.lock
    
    [ Upstream commit f671a691e299f58835d4660d642582bf0e8f6fda ]
    
    Syzbot reports a potential deadlock in do_fcntl:
    
    ========================================================
    WARNING: possible irq lock inversion dependency detected
    5.12.0-syzkaller #0 Not tainted
    --------------------------------------------------------
    syz-executor132/8391 just changed the state of lock:
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: f_getown_ex fs/fcntl.c:211 [inline]
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: do_fcntl+0x8b4/0x1200 fs/fcntl.c:395
    but this lock was taken by another, HARDIRQ-safe lock in the past:
     (&dev->event_lock){-...}-{2:2}
    
    and interrupts could create inverse lock ordering between them.
    
    other info that might help us debug this:
    Chain exists of:
      &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&f->f_owner.lock);
                                   local_irq_disable();
                                   lock(&dev->event_lock);
                                   lock(&new->fa_lock);
      <Interrupt>
        lock(&dev->event_lock);
    
     *** DEADLOCK ***
    
    This happens because there is a lock hierarchy of
    &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    However, since &dev->event_lock is HARDIRQ-safe, interrupts have to be
    disabled while grabbing &f->f_owner.lock, otherwise we invert the lock
    hierarchy.
    
    Hence, we replace calls to read_lock/read_unlock on &f->f_owner.lock,
    with read_lock_irq/read_unlock_irq.
    
    Reported-and-tested-by: syzbot+e6d5398a02c516ce5e70@syzkaller.appspotmail.com
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f272a15a67466bf02924cd46e74584b19d416603
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:31 2021 +0800

    fcntl: fix potential deadlock for &fasync_struct.fa_lock
    
    [ Upstream commit 2f488f698fda820f8e6fa0407630154eceb145d6 ]
    
    There is an existing lock hierarchy of
    &dev->event_lock --> &fasync_struct.fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    &dev->event_lock is HARDIRQ-safe, so interrupts have to be disabled
    while grabbing &fasync_struct.fa_lock, otherwise we invert the lock
    hierarchy. However, since kill_fasync which calls kill_fasync_rcu is
    an exported symbol, it may not necessarily be called with interrupts
    disabled.
    
    As kill_fasync_rcu may be called with interrupts disabled (for
    example, in the call chain above), we replace calls to
    read_lock/read_unlock on &fasync_struct.fa_lock in kill_fasync_rcu
    with read_lock_irqsave/read_unlock_irqrestore.
    
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 98ce2662c0affebcc4f4eac987de682cd366aa03
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:30 2021 +0800

    fcntl: fix potential deadlocks for &fown_struct.lock
    
    [ Upstream commit f671a691e299f58835d4660d642582bf0e8f6fda ]
    
    Syzbot reports a potential deadlock in do_fcntl:
    
    ========================================================
    WARNING: possible irq lock inversion dependency detected
    5.12.0-syzkaller #0 Not tainted
    --------------------------------------------------------
    syz-executor132/8391 just changed the state of lock:
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: f_getown_ex fs/fcntl.c:211 [inline]
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: do_fcntl+0x8b4/0x1200 fs/fcntl.c:395
    but this lock was taken by another, HARDIRQ-safe lock in the past:
     (&dev->event_lock){-...}-{2:2}
    
    and interrupts could create inverse lock ordering between them.
    
    other info that might help us debug this:
    Chain exists of:
      &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&f->f_owner.lock);
                                   local_irq_disable();
                                   lock(&dev->event_lock);
                                   lock(&new->fa_lock);
      <Interrupt>
        lock(&dev->event_lock);
    
     *** DEADLOCK ***
    
    This happens because there is a lock hierarchy of
    &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    However, since &dev->event_lock is HARDIRQ-safe, interrupts have to be
    disabled while grabbing &f->f_owner.lock, otherwise we invert the lock
    hierarchy.
    
    Hence, we replace calls to read_lock/read_unlock on &f->f_owner.lock,
    with read_lock_irq/read_unlock_irq.
    
    Reported-and-tested-by: syzbot+e6d5398a02c516ce5e70@syzkaller.appspotmail.com
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit db2f238d8d12569b92f74ba89b7f2ad79fc4bd1a
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:31 2021 +0800

    fcntl: fix potential deadlock for &fasync_struct.fa_lock
    
    [ Upstream commit 2f488f698fda820f8e6fa0407630154eceb145d6 ]
    
    There is an existing lock hierarchy of
    &dev->event_lock --> &fasync_struct.fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    &dev->event_lock is HARDIRQ-safe, so interrupts have to be disabled
    while grabbing &fasync_struct.fa_lock, otherwise we invert the lock
    hierarchy. However, since kill_fasync which calls kill_fasync_rcu is
    an exported symbol, it may not necessarily be called with interrupts
    disabled.
    
    As kill_fasync_rcu may be called with interrupts disabled (for
    example, in the call chain above), we replace calls to
    read_lock/read_unlock on &fasync_struct.fa_lock in kill_fasync_rcu
    with read_lock_irqsave/read_unlock_irqrestore.
    
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ae4240d1f4bf3e253bd3c429d54de9975595f7da
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:31 2021 +0800

    fcntl: fix potential deadlock for &fasync_struct.fa_lock
    
    [ Upstream commit 2f488f698fda820f8e6fa0407630154eceb145d6 ]
    
    There is an existing lock hierarchy of
    &dev->event_lock --> &fasync_struct.fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    &dev->event_lock is HARDIRQ-safe, so interrupts have to be disabled
    while grabbing &fasync_struct.fa_lock, otherwise we invert the lock
    hierarchy. However, since kill_fasync which calls kill_fasync_rcu is
    an exported symbol, it may not necessarily be called with interrupts
    disabled.
    
    As kill_fasync_rcu may be called with interrupts disabled (for
    example, in the call chain above), we replace calls to
    read_lock/read_unlock on &fasync_struct.fa_lock in kill_fasync_rcu
    with read_lock_irqsave/read_unlock_irqrestore.
    
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 71921a9606ddbcc1d98c00eca7ae82c373d1fecd
Author: Scott Wood <swood@redhat.com>
Date:   Fri Aug 20 09:42:36 2021 +0200

    rcutorture: Avoid problematic critical section nesting on PREEMPT_RT
    
    rcutorture is generating some nesting scenarios that are not compatible on PREEMPT_RT.
    For example:
            preempt_disable();
            rcu_read_lock_bh();
            preempt_enable();
            rcu_read_unlock_bh();
    
    The problem here is that on PREEMPT_RT the bottom halves have to be
    disabled and enabled in preemptible context.
    
    Reorder locking: start with BH locking and continue with then with
    disabling preemption or interrupts. In the unlocking do it reverse by
    first enabling interrupts and preemption and BH at the very end.
    Ensure that on PREEMPT_RT BH locking remains unchanged if in
    non-preemptible context.
    
    Link: https://lkml.kernel.org/r/20190911165729.11178-6-swood@redhat.com
    Link: https://lkml.kernel.org/r/20210819182035.GF4126399@paulmck-ThinkPad-P17-Gen-1
    Signed-off-by: Scott Wood <swood@redhat.com>
    [bigeasy: Drop ATOM_BH, make it only about changing BH in atomic
    context. Allow enabling RCU in IRQ-off section. Reword commit message.]
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit c122358ea1e510d3def876abb7872f1b2b7365c9
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:02 2021 +0200

    thermal: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-20-bigeasy@linutronix.de

commit 43175623dd0dffccacbf014e368ee77f77c73898
Merge: f154c806676a cfd799837dbc
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Sep 9 13:11:15 2021 -0700

    Merge tag 'trace-v5.15-2' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace
    
    Pull more tracing updates from Steven Rostedt:
    
     - Add migrate-disable counter to tracing header
    
     - Fix error handling in event probes
    
     - Fix missed unlock in osnoise in error path
    
     - Fix merge issue with tools/bootconfig
    
     - Clean up bootconfig data when init memory is removed
    
     - Fix bootconfig to loop only on subkeys
    
     - Have kernel command lines override bootconfig options
    
     - Increase field counts for synthetic events
    
     - Have histograms dynamic allocate event elements to save space
    
     - Fixes in testing and documentation
    
    * tag 'trace-v5.15-2' of git://git.kernel.org/pub/scm/linux/kernel/git/rostedt/linux-trace:
      tracing/boot: Fix to loop on only subkeys
      selftests/ftrace: Exclude "(fault)" in testing add/remove eprobe events
      tracing: Dynamically allocate the per-elt hist_elt_data array
      tracing: synth events: increase max fields count
      tools/bootconfig: Show whole test command for each test case
      bootconfig: Fix missing return check of xbc_node_compose_key function
      tools/bootconfig: Fix tracing_on option checking in ftrace2bconf.sh
      docs: bootconfig: Add how to use bootconfig for kernel parameters
      init/bootconfig: Reorder init parameter from bootconfig and cmdline
      init: bootconfig: Remove all bootconfig data when the init memory is removed
      tracing/osnoise: Fix missed cpus_read_unlock() in start_per_cpu_kthreads()
      tracing: Fix some alloc_event_probe() error handling bugs
      tracing: Add migrate-disabled counter to tracing output.

commit 4b6b08f2e45edda4c067ac40833e3c1f84383c0b
Author: Qiang.Zhang <qiang.zhang@windriver.com>
Date:   Tue Aug 31 10:29:19 2021 +0800

    tracing/osnoise: Fix missed cpus_read_unlock() in start_per_cpu_kthreads()
    
    When start_kthread() return error, the cpus_read_unlock() need
    to be called.
    
    Link: https://lkml.kernel.org/r/20210831022919.27630-1-qiang.zhang@windriver.com
    
    Cc: <stable@vger.kernel.org>
    Fixes: c8895e271f79 ("trace/osnoise: Support hotplug operations")
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Qiang.Zhang <qiang.zhang@windriver.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

commit 7625eccd1852ac84d3aa6a06ffc2f710e683b3fe
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:03 2021 +0200

    mm: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-21-bigeasy@linutronix.de

commit 252034e03f04e54acfb5f5924dd26ae638e3215e
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:58 2021 +0200

    md/raid5: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Song Liu <song@kernel.org>
    Link: https://lore.kernel.org/r/20210803141621.780504-16-bigeasy@linutronix.de

commit c7483d823ee0da31e42d32e51a752f667a059735
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:44 2021 +0200

    Documentation: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Update the documentation accordingly.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-2-bigeasy@linutronix.de

commit 425bec0032f59eeee12520085cd054fac09cc66e
Author: David Hildenbrand <david@redhat.com>
Date:   Wed Aug 25 12:24:15 2021 +0200

    virtio-mem: fix sleeping in RCU read side section in virtio_mem_online_page_cb()
    
    virtio_mem_set_fake_offline() might sleep now, and we call it under
    rcu_read_lock(). To fix it, simply move the rcu_read_unlock() further
    up, as we're done with the device.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Fixes: 6cc26d77613a: "virtio-mem: use page_offline_(start|end) when setting PageOffline()
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: virtualization@lists.linux-foundation.org
    Signed-off-by: David Hildenbrand <david@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 673a0658f6ac359131a881c0dcf1b91c2500ab9c
Author: Christoph Hellwig <hch@lst.de>
Date:   Thu Aug 26 15:55:06 2021 +0200

    dax: move the dax_read_lock() locking into dax_supported
    
    Move the dax_read_lock/dax_read_unlock pair from the callers into
    dax_supported to make it a little easier to use.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Dan Williams <dan.j.williams@intel.com>
    Link: https://lore.kernel.org/r/20210826135510.6293-6-hch@lst.de
    Signed-off-by: Dan Williams <dan.j.williams@intel.com>

commit 28c2d83c479c33766bec28772855169fb0bbe0cd
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2d661ed3573c9ba0a1f75b5587974a054ed8a142
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a0d5422c673a0992ec48e6285c3bc97b0acf92e4
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7da72e2db1b36c3138aff542622123c030344254
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ffec09f9c7d7b21b0aff29dd5c3972f4631c0b6b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:54 2021 +0200

    perf/hw_breakpoint: Replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20210803141621.780504-12-bigeasy@linutronix.de

commit eda8a2c599d1ff874a63de7684b430740e747dea
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:53 2021 +0200

    perf/x86/intel: Replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/20210803141621.780504-11-bigeasy@linutronix.de

commit 2f488f698fda820f8e6fa0407630154eceb145d6
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:31 2021 +0800

    fcntl: fix potential deadlock for &fasync_struct.fa_lock
    
    There is an existing lock hierarchy of
    &dev->event_lock --> &fasync_struct.fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    &dev->event_lock is HARDIRQ-safe, so interrupts have to be disabled
    while grabbing &fasync_struct.fa_lock, otherwise we invert the lock
    hierarchy. However, since kill_fasync which calls kill_fasync_rcu is
    an exported symbol, it may not necessarily be called with interrupts
    disabled.
    
    As kill_fasync_rcu may be called with interrupts disabled (for
    example, in the call chain above), we replace calls to
    read_lock/read_unlock on &fasync_struct.fa_lock in kill_fasync_rcu
    with read_lock_irqsave/read_unlock_irqrestore.
    
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>

commit f671a691e299f58835d4660d642582bf0e8f6fda
Author: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
Date:   Fri Jul 2 17:18:30 2021 +0800

    fcntl: fix potential deadlocks for &fown_struct.lock
    
    Syzbot reports a potential deadlock in do_fcntl:
    
    ========================================================
    WARNING: possible irq lock inversion dependency detected
    5.12.0-syzkaller #0 Not tainted
    --------------------------------------------------------
    syz-executor132/8391 just changed the state of lock:
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: f_getown_ex fs/fcntl.c:211 [inline]
    ffff888015967bf8 (&f->f_owner.lock){.+..}-{2:2}, at: do_fcntl+0x8b4/0x1200 fs/fcntl.c:395
    but this lock was taken by another, HARDIRQ-safe lock in the past:
     (&dev->event_lock){-...}-{2:2}
    
    and interrupts could create inverse lock ordering between them.
    
    other info that might help us debug this:
    Chain exists of:
      &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&f->f_owner.lock);
                                   local_irq_disable();
                                   lock(&dev->event_lock);
                                   lock(&new->fa_lock);
      <Interrupt>
        lock(&dev->event_lock);
    
     *** DEADLOCK ***
    
    This happens because there is a lock hierarchy of
    &dev->event_lock --> &new->fa_lock --> &f->f_owner.lock
    from the following call chain:
    
      input_inject_event():
        spin_lock_irqsave(&dev->event_lock,...);
        input_handle_event():
          input_pass_values():
            input_to_handler():
              evdev_events():
                evdev_pass_values():
                  spin_lock(&client->buffer_lock);
                  __pass_event():
                    kill_fasync():
                      kill_fasync_rcu():
                        read_lock(&fa->fa_lock);
                        send_sigio():
                          read_lock_irqsave(&fown->lock,...);
    
    However, since &dev->event_lock is HARDIRQ-safe, interrupts have to be
    disabled while grabbing &f->f_owner.lock, otherwise we invert the lock
    hierarchy.
    
    Hence, we replace calls to read_lock/read_unlock on &f->f_owner.lock,
    with read_lock_irq/read_unlock_irq.
    
    Reported-and-tested-by: syzbot+e6d5398a02c516ce5e70@syzkaller.appspotmail.com
    Signed-off-by: Desmond Cheong Zhi Xi <desmondcheongzx@gmail.com>
    Signed-off-by: Jeff Layton <jlayton@kernel.org>

commit 1daf08a066cfe500587affd3fa3be8c13b8ff007
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:09 2021 +0200

    livepatch: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Jiri Kosina <jikos@kernel.org>
    Cc: Miroslav Benes <mbenes@suse.cz>
    Cc: Petr Mladek <pmladek@suse.com>
    Cc: Joe Lawrence <joe.lawrence@redhat.com>
    Cc: live-patching@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Reviewed-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

commit 5353dd72f99207e8118a766847df8d60bb559940
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Aug 18 13:40:22 2021 -0600

    coresight: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Link: https://lore.kernel.org/r/20210803141621.780504-15-bigeasy@linutronix.de
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
    Cc: Mike Leach <mike.leach@linaro.org>
    Cc: Leo Yan <leo.yan@linaro.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: coresight@lists.linaro.org
    Cc: linux-arm-kernel@lists.infradead.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Mathieu Poirier <mathieu.poirier@linaro.org>
    Link: https://lore.kernel.org/r/20210818194022.379573-12-mathieu.poirier@linaro.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 44c8aa99691174b990469b319197940f7995ddd2
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 69b13167a636c737475a749e035fa3325558a252
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ed957c77b391fe0e642486902002772d9acf8e5f
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    [ Upstream commit 1090340f7ee53e824fd4eef66a4855d548110c5b ]
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e104d530f3734c7666edf86bbf1b83b1bfafe6ee
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:56 2021 +0200

    hwmon: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Jean Delvare <jdelvare@suse.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Cc: linux-hwmon@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-14-bigeasy@linutronix.de
    Signed-off-by: Guenter Roeck <linux@roeck-us.net>

commit 99c37d1a63eafcd3673302a7953df760b46d0f6f
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:19 2021 +0200

    tracing: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Link: https://lkml.kernel.org/r/20210803141621.780504-37-bigeasy@linutronix.de
    
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ingo Molnar <mingo@redhat.com>
    Acked-by: Daniel Bristot de Oliveira <bristot@kernel.org>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

commit d31eb7c1a2288f61df75558f59328be01a264300
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:02 2021 +0200

    thermal/drivers/intel_powerclamp: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Zhang Rui <rui.zhang@intel.com>
    Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
    Cc: Amit Kucheria <amitk@kernel.org>
    Cc: linux-pm@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Daniel Lezcano <daniel.lezcano@linaro.org>
    Link: https://lore.kernel.org/r/20210803141621.780504-20-bigeasy@linutronix.de

commit 80771c8228029daff4b3402e00883cde06e07d46
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:10 2021 +0200

    padata: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Steffen Klassert <steffen.klassert@secunet.com>
    Cc: Daniel Jordan <daniel.m.jordan@oracle.com>
    Cc: linux-crypto@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Acked-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

commit d01a9f7009c3812a8955b7ae5798470cd6ab3590
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:55 2021 +0200

    crypto: virtio - Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Gonglei <arei.gonglei@huawei.com>
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: virtualization@lists.linux-foundation.org
    Cc: linux-crypto@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>

commit 560c71d4250f5f32b7952c290ddaf3cd4548a3ec
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:00 2021 +0200

    platform/x86: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Stuart Hayes <stuart.w.hayes@gmail.com>
    Cc: Hans de Goede <hdegoede@redhat.com>
    Cc: Mark Gross <mgross@linux.intel.com>
    Cc: platform-driver-x86@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-18-bigeasy@linutronix.de
    Signed-off-by: Hans de Goede <hdegoede@redhat.com>

commit ed4fa2442e87bf9143d608473df117589e4bfc70
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:18 2021 +0200

    torture: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: "Paul E. McKenney" <paulmck@kernel.org>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit d3dd95a8853f1d588e38e9d9d7c8cc2da412cc36
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:14 2021 +0200

    rcu: Replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: "Paul E. McKenney" <paulmck@kernel.org>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Lai Jiangshan <jiangshanlai@gmail.com>
    Cc: Joel Fernandes <joel@joelfernandes.org>
    Cc: rcu@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit a75966d76de46cb6af37921fa71bc99659fd946f
Author: Anna-Maria Gleixner <anna-maria@linutronix.de>
Date:   Mon Aug 2 21:46:24 2021 +0800

    rcu: Update documentation of rcu_read_unlock()
    
    [ Upstream commit ec84b27f9b3b569f9235413d1945a2006b97b0aa ]
    
    Since commit b4abf91047cf ("rtmutex: Make wait_lock irq safe") the
    explanation in rcu_read_unlock() documentation about irq unsafe rtmutex
    wait_lock is no longer valid.
    
    Remove it to prevent kernel developers reading the documentation to rely on
    it.
    
    Suggested-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Anna-Maria Gleixner <anna-maria@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: bigeasy@linutronix.de
    Link: https://lkml.kernel.org/r/20180525090507.22248-2-anna-maria@linutronix.de
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6ef8ca1e4f08745b1e56b289bf418474becc937b
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Mon Aug 2 21:46:20 2021 +0800

    rtmutex: Make wait_lock irq safe
    
    [ Upstream commit b4abf91047cf054f203dcfac97e1038388826937 ]
    
    Sasha reported a lockdep splat about a potential deadlock between RCU boosting
    rtmutex and the posix timer it_lock.
    
    CPU0                                    CPU1
    
    rtmutex_lock(&rcu->rt_mutex)
      spin_lock(&rcu->rt_mutex.wait_lock)
                                            local_irq_disable()
                                            spin_lock(&timer->it_lock)
                                            spin_lock(&rcu->mutex.wait_lock)
    --> Interrupt
        spin_lock(&timer->it_lock)
    
    This is caused by the following code sequence on CPU1
    
         rcu_read_lock()
         x = lookup();
         if (x)
            spin_lock_irqsave(&x->it_lock);
         rcu_read_unlock();
         return x;
    
    We could fix that in the posix timer code by keeping rcu read locked across
    the spinlocked and irq disabled section, but the above sequence is common and
    there is no reason not to support it.
    
    Taking rt_mutex.wait_lock irq safe prevents the deadlock.
    
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Zhen Lei <thunder.leizhen@huawei.com>
    Acked-by: Joe Korty <joe.korty@concurrent-rt.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5ae36401ca4ea2737d779ce7c267444b16530001
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:46 2021 +0200

    powerpc: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20210803141621.780504-4-bigeasy@linutronix.de

commit 844d87871b6e0ac3ceb177535dcdf6e6a9f1fd4b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:16 2021 +0200

    smpboot: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-34-bigeasy@linutronix.de

commit 698429f9d0e54ce3964151adff886ee5fc59714b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:17 2021 +0200

    clocksource: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-35-bigeasy@linutronix.de

commit 746f5ea9c4283d98353c1cd41864aec475e0edbd
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:15 2021 +0200

    sched: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-33-bigeasy@linutronix.de

commit 428e211641ed808b55cdc7d880a0ee349eff354b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:08 2021 +0200

    genirq/affinity: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-26-bigeasy@linutronix.de

commit 8ae9e3f63865bc067c144817da9df025dbb667f2
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:52 2021 +0200

    x86/mce/inject: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-10-bigeasy@linutronix.de

commit 2089f34f8c5b91f7235023ec72e71e3247261ecc
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:51 2021 +0200

    x86/microcode: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-9-bigeasy@linutronix.de

commit 1a351eefd4acc97145903b1c07e4d8b626854b82
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:50 2021 +0200

    x86/mtrr: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-8-bigeasy@linutronix.de

commit 77ad320cfb2ac172eeba32a77a388281b003ec17
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:49 2021 +0200

    x86/mmiotrace: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Karol Herbst <kherbst@redhat.com>
    Reviewed-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Link: https://lore.kernel.org/r/20210803141621.780504-7-bigeasy@linutronix.de

commit 1090340f7ee53e824fd4eef66a4855d548110c5b
Author: Takeshi Misawa <jeliantsurux@gmail.com>
Date:   Thu Aug 5 16:54:14 2021 +0900

    net: Fix memory leak in ieee802154_raw_deliver
    
    If IEEE-802.15.4-RAW is closed before receive skb, skb is leaked.
    Fix this, by freeing sk_receive_queue in sk->sk_destruct().
    
    syzbot report:
    BUG: memory leak
    unreferenced object 0xffff88810f644600 (size 232):
      comm "softirq", pid 0, jiffies 4294967032 (age 81.270s)
      hex dump (first 32 bytes):
        10 7d 4b 12 81 88 ff ff 10 7d 4b 12 81 88 ff ff  .}K......}K.....
        00 00 00 00 00 00 00 00 40 7c 4b 12 81 88 ff ff  ........@|K.....
      backtrace:
        [<ffffffff83651d4a>] skb_clone+0xaa/0x2b0 net/core/skbuff.c:1496
        [<ffffffff83fe1b80>] ieee802154_raw_deliver net/ieee802154/socket.c:369 [inline]
        [<ffffffff83fe1b80>] ieee802154_rcv+0x100/0x340 net/ieee802154/socket.c:1070
        [<ffffffff8367cc7a>] __netif_receive_skb_one_core+0x6a/0xa0 net/core/dev.c:5384
        [<ffffffff8367cd07>] __netif_receive_skb+0x27/0xa0 net/core/dev.c:5498
        [<ffffffff8367cdd9>] netif_receive_skb_internal net/core/dev.c:5603 [inline]
        [<ffffffff8367cdd9>] netif_receive_skb+0x59/0x260 net/core/dev.c:5662
        [<ffffffff83fe6302>] ieee802154_deliver_skb net/mac802154/rx.c:29 [inline]
        [<ffffffff83fe6302>] ieee802154_subif_frame net/mac802154/rx.c:102 [inline]
        [<ffffffff83fe6302>] __ieee802154_rx_handle_packet net/mac802154/rx.c:212 [inline]
        [<ffffffff83fe6302>] ieee802154_rx+0x612/0x620 net/mac802154/rx.c:284
        [<ffffffff83fe59a6>] ieee802154_tasklet_handler+0x86/0xa0 net/mac802154/main.c:35
        [<ffffffff81232aab>] tasklet_action_common.constprop.0+0x5b/0x100 kernel/softirq.c:557
        [<ffffffff846000bf>] __do_softirq+0xbf/0x2ab kernel/softirq.c:345
        [<ffffffff81232f4c>] do_softirq kernel/softirq.c:248 [inline]
        [<ffffffff81232f4c>] do_softirq+0x5c/0x80 kernel/softirq.c:235
        [<ffffffff81232fc1>] __local_bh_enable_ip+0x51/0x60 kernel/softirq.c:198
        [<ffffffff8367a9a4>] local_bh_enable include/linux/bottom_half.h:32 [inline]
        [<ffffffff8367a9a4>] rcu_read_unlock_bh include/linux/rcupdate.h:745 [inline]
        [<ffffffff8367a9a4>] __dev_queue_xmit+0x7f4/0xf60 net/core/dev.c:4221
        [<ffffffff83fe2db4>] raw_sendmsg+0x1f4/0x2b0 net/ieee802154/socket.c:295
        [<ffffffff8363af16>] sock_sendmsg_nosec net/socket.c:654 [inline]
        [<ffffffff8363af16>] sock_sendmsg+0x56/0x80 net/socket.c:674
        [<ffffffff8363deec>] __sys_sendto+0x15c/0x200 net/socket.c:1977
        [<ffffffff8363dfb6>] __do_sys_sendto net/socket.c:1989 [inline]
        [<ffffffff8363dfb6>] __se_sys_sendto net/socket.c:1985 [inline]
        [<ffffffff8363dfb6>] __x64_sys_sendto+0x26/0x30 net/socket.c:1985
    
    Fixes: 9ec767160357 ("net: add IEEE 802.15.4 socket family implementation")
    Reported-and-tested-by: syzbot+1f68113fa907bf0695a8@syzkaller.appspotmail.com
    Signed-off-by: Takeshi Misawa <jeliantsurux@gmail.com>
    Acked-by: Alexander Aring <aahringo@redhat.com>
    Link: https://lore.kernel.org/r/20210805075414.GA15796@DESKTOP
    Signed-off-by: Stefan Schmidt <stefan@datenfreihafen.org>

commit 87b7b5335e6995a6d64fca98fc67b92b29caac9c
Author: Yonghong Song <yhs@fb.com>
Date:   Mon Aug 9 16:51:51 2021 -0700

    bpf: Add missing bpf_read_[un]lock_trace() for syscall program
    
    Commit 79a7f8bdb159d ("bpf: Introduce bpf_sys_bpf() helper and program type.")
    added support for syscall program, which is a sleepable program.
    
    But the program run missed bpf_read_lock_trace()/bpf_read_unlock_trace(),
    which is needed to ensure proper rcu callback invocations. This patch adds
    bpf_read_[un]lock_trace() properly.
    
    Fixes: 79a7f8bdb159d ("bpf: Introduce bpf_sys_bpf() helper and program type.")
    Signed-off-by: Yonghong Song <yhs@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Andrii Nakryiko <andrii@kernel.org>
    Link: https://lore.kernel.org/bpf/20210809235151.1663680-1-yhs@fb.com

commit c5c63b9a6a2e53757b598485b8adbafa56d6d9ee
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:07 2021 +0200

    cgroup: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Zefan Li <lizefan.x@bytedance.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: cgroups@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit ffd8bea81fbb5abe6518bce8d6297a149b935cf7
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:20 2021 +0200

    workqueue: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Tejun Heo <tj@kernel.org>
    Reviewed-by: Lai Jiangshan <jiangshanlai@gmail.com>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>

commit 8c39ed4876d4e541e2044f313c56b1eb20810fe1
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Mon Aug 9 10:30:50 2021 +0200

    net/iucv: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Julian Wiedmann <jwi@linux.ibm.com>
    Cc: Karsten Graul <kgraul@linux.ibm.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jakub Kicinski <kuba@kernel.org>
    Cc: linux-s390@vger.kernel.org
    Cc: netdev@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
    Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 65bfdd36c113f5d579a382d8f2847210ea4cdca6
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Jun 2 16:31:38 2021 -0700

    srcutiny: Mark read-side data races
    
    This commit marks some interrupt-induced read-side data races in
    __srcu_read_lock(), __srcu_read_unlock(), and srcu_torture_stats_print().
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 52b6defae7de31aaa960e78e506f882c12b4af53
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:48 2021 +0200

    s390/sclp: replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-6-bigeasy@linutronix.de
    Signed-off-by: Heiko Carstens <hca@linux.ibm.com>

commit a73de29320287d0e72b9e158879cb047e226ec2b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:47 2021 +0200

    s390: replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-5-bigeasy@linutronix.de
    Signed-off-by: Heiko Carstens <hca@linux.ibm.com>

commit 730d070ae9f12fff5d44fe8fb0547ae37d100da8
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:45 2021 +0200

    MIPS: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
    Cc: linux-mips@vger.kernel.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Thomas Bogendoerfer <tsbogend@alpha.franken.de>

commit 372bbdd5bb3fc454d9c280dc0914486a3c7419d5
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:06 2021 +0200

    net: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit a0d1d0f47e3193d6188869ae6bcf08a792f63cf6
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:04 2021 +0200

    virtio_net: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: "Michael S. Tsirkin" <mst@redhat.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Cc: virtualization@lists.linux-foundation.org
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit 95ac706744de78a93a7ec98d603c35fb21de8400
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:12 2021 +0200

    ACPI: processor: Replace deprecated CPU-hotplug functions
    
    The functions cpu_hotplug_begin, cpu_hotplug_done, get_online_cpus() and
    put_online_cpus() have been deprecated during the CPU hotplug rework. They map
    directly to cpus_write_lock(), cpus_write_unlock, cpus_read_lock() and
    cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit d2c8cce647f3022d5960a3bf2b50a2da341d9c8b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:13 2021 +0200

    PM: sleep: s2idle: Replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit 09681a0772f773dddffd3c2d1796c87bd0d903b9
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:11 2021 +0200

    cpufreq: Replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit 5d4c779cb62e676aedc278de910b4bb8ef65a5cc
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:16:01 2021 +0200

    powercap: intel_rapl: Replace deprecated CPU-hotplug functions
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit e67adaa1754d5383583c35a703518507e457482b
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Tue Aug 3 16:15:59 2021 +0200

    sgi-xpc: Replace deprecated CPU-hotplug functions.
    
    The functions get_online_cpus() and put_online_cpus() have been
    deprecated during the CPU hotplug rework. They map directly to
    cpus_read_lock() and cpus_read_unlock().
    
    Replace deprecated CPU-hotplug functions with the official version.
    The behavior remains unchanged.
    
    Cc: Robin Holt <robinmholt@gmail.com>
    Cc: Steve Wahl <steve.wahl@hpe.com>
    Cc: Mike Travis <mike.travis@hpe.com>
    Cc: Arnd Bergmann <arnd@arndb.de>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Link: https://lore.kernel.org/r/20210803141621.780504-17-bigeasy@linutronix.de
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e5fe3a5fe333b9967eeb99966bcf3ec710318554
Merge: 658e6b1612c6 6a2d98b18900
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Jul 29 15:06:50 2021 +0100

    Merge branch 'mctp'
    
    Jeremy Kerr says:
    
    ====================
    Add Management Component Transport Protocol support
    
    This series adds core MCTP support to the kernel. From the Kconfig
    description:
    
      Management Component Transport Protocol (MCTP) is an in-system
      protocol for communicating between management controllers and
      their managed devices (peripherals, host processors, etc.). The
      protocol is defined by DMTF specification DSP0236.
    
      This option enables core MCTP support. For communicating with other
      devices, you'll want to enable a driver for a specific hardware
      channel.
    
    This implementation allows a sockets-based API for sending and receiving
    MCTP messages via sendmsg/recvmsg on SOCK_DGRAM sockets. Kernel stack
    control is all via netlink, using existing RTM_* messages. The userspace
    ABI change is fairly small; just the necessary AF_/ETH_P_/ARPHDR_
    constants, a new sockaddr, and a new netlink attribute.
    
    For MAINTAINERS, I've just included netdev@ as the list entry. I'm happy
    to alter this based on preferences here - an alternative would be the
    OpenBMC list (the main user of the MCTP interface), or we can create a
    new list entirely.
    
    We have a couple of interface drivers almost ready to go at the moment,
    but those can wait until the core code has some review.
    
    This is v4 of the series; v1 and v2 were both RFC.
    
    selinux folks: CCing 01/15 due to the new PF_MCTP protocol family.
    
    linux-doc folks: CCing 15/15 for the new MCTP overview document.
    
    Review, comments, questions etc. are most welcome.
    
    Cheers,
    
    Jeremy
    
    v2:
     - change to match spec terminology: controller -> component
     - require specific capabilities for bind() & sendmsg()
     - add address and tag defintions to uapi
     - add selinux AF_MCTP table definitions
     - remove strict cflags; warnings are present in common headers
    
    v3:
     - require caps for MCTP bind() & send()
     - comment typo fixes
     - switch to an array for local EIDs
     - fix addrinfo dump iteration & error path
     - add RTM_DELADDR
     - remove GENMASK() and BIT() from uapi
    
    v4:
     - drop tun patch; that can be submitted separately
     - keep nipa happy: add maintainer CCs, including doc and selinux
     - net-next rebase
     - Include AF_MCTP in af_family_slock_keys and pf_family_names
     - Introduce MODULE_ definitions earlier
     - upstream change: set_link_af no longer called with RTNL held
     - add kdoc for net_device.mctp_ptr
     - don't inline mctp_rt_match_eid
     - require rtm_type == RTN_UNICAST in route management handlers
     - remove unused RTAX policy table
     - fix mctp_sock->keys rcu annotations
     - fix spurious rcu_read_unlock in route input
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a86aef787c205217165f131f11a0fe1d0fbd808d
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 91f805f97bd97cf9ff84199c0b170cd1911e17fd
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a6edc1d9085c802ab325ef577c5811c450900df3
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fdf3ef3f66cb88f30fbf9396f876937b29506d9b
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit cae2f265c5a94019caf25019be946fd46a11aeff
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3ee7e6cf9fe8ceb6f95de855ab04c52c21f71810
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6939c39a4106199877f93c96d931cff45c0d1dad
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5c93fc46682c18c0cac60e09d1e6d375a30c7a85
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    [ Upstream commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4 ]
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 28e92f990337b8b4c5fdec47667f8b96089c503e
Merge: da803f82faa5 641faf1b9064
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jul 4 12:58:33 2021 -0700

    Merge branch 'core-rcu-2021.07.04' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu
    
    Pull RCU updates from Paul McKenney:
    
     - Bitmap parsing support for "all" as an alias for all bits
    
     - Documentation updates
    
     - Miscellaneous fixes, including some that overlap into mm and lockdep
    
     - kvfree_rcu() updates
    
     - mem_dump_obj() updates, with acks from one of the slab-allocator
       maintainers
    
     - RCU NOCB CPU updates, including limited deoffloading
    
     - SRCU updates
    
     - Tasks-RCU updates
    
     - Torture-test updates
    
    * 'core-rcu-2021.07.04' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu: (78 commits)
      tasks-rcu: Make show_rcu_tasks_gp_kthreads() be static inline
      rcu-tasks: Make ksoftirqd provide RCU Tasks quiescent states
      rcu: Add missing __releases() annotation
      rcu: Remove obsolete rcu_read_unlock() deadlock commentary
      rcu: Improve comments describing RCU read-side critical sections
      rcu: Create an unrcu_pointer() to remove __rcu from a pointer
      srcu: Early test SRCU polling start
      rcu: Fix various typos in comments
      rcu/nocb: Unify timers
      rcu/nocb: Prepare for fine-grained deferred wakeup
      rcu/nocb: Only cancel nocb timer if not polling
      rcu/nocb: Delete bypass_timer upon nocb_gp wakeup
      rcu/nocb: Cancel nocb_timer upon nocb_gp wakeup
      rcu/nocb: Allow de-offloading rdp leader
      rcu/nocb: Directly call __wake_nocb_gp() from bypass timer
      rcu: Don't penalize priority boosting when there is nothing to boost
      rcu: Point to documentation of ordering guarantees
      rcu: Make rcu_gp_cleanup() be noinline for tracing
      rcu: Restrict RCU_STRICT_GRACE_PERIOD to at most four CPUs
      rcu: Make show_rcu_gp_kthreads() dump rcu_node structures blocking GP
      ...

commit 8b0ed8443ae6458786580d36b7d5f8125535c5d4
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Fri Apr 2 17:11:45 2021 +0800

    writeback: fix obtain a reference to a freeing memcg css
    
    The caller of wb_get_create() should pin the memcg, because
    wb_get_create() relies on this guarantee. The rcu read lock
    only can guarantee that the memcg css returned by css_from_id()
    cannot be released, but the reference of the memcg can be zero.
    
      rcu_read_lock()
      memcg_css = css_from_id()
      wb_get_create(memcg_css)
          cgwb_create(memcg_css)
              // css_get can change the ref counter from 0 back to 1
              css_get(memcg_css)
      rcu_read_unlock()
    
    Fix it by holding a reference to the css before calling
    wb_get_create(). This is not a problem I encountered in the
    real world. Just the result of a code review.
    
    Fixes: 682aa8e1a6a1 ("writeback: implement unlocked_inode_to_wb transaction and use it for stat updates")
    Link: https://lore.kernel.org/r/20210402091145.80635-1-songmuchun@bytedance.com
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jan Kara <jack@suse.cz>

commit 031e3bd8986fffe31e1ddbf5264cccfe30c9abd7
Author: Yuan ZhaoXiong <yuanzhaoxiong@baidu.com>
Date:   Sun Jun 6 21:11:55 2021 +0800

    sched: Optimize housekeeping_cpumask() in for_each_cpu_and()
    
    On a 128 cores AMD machine, there are 8 cores in nohz_full mode, and
    the others are used for housekeeping. When many housekeeping cpus are
    in idle state, we can observe huge time burn in the loop for searching
    nearest busy housekeeper cpu by ftrace.
    
       9)               |              get_nohz_timer_target() {
       9)               |                housekeeping_test_cpu() {
       9)   0.390 us    |                  housekeeping_get_mask.part.1();
       9)   0.561 us    |                }
       9)   0.090 us    |                __rcu_read_lock();
       9)   0.090 us    |                housekeeping_cpumask();
       9)   0.521 us    |                housekeeping_cpumask();
       9)   0.140 us    |                housekeeping_cpumask();
    
       ...
    
       9)   0.500 us    |                housekeeping_cpumask();
       9)               |                housekeeping_any_cpu() {
       9)   0.090 us    |                  housekeeping_get_mask.part.1();
       9)   0.100 us    |                  sched_numa_find_closest();
       9)   0.491 us    |                }
       9)   0.100 us    |                __rcu_read_unlock();
       9) + 76.163 us   |              }
    
    for_each_cpu_and() is a micro function, so in get_nohz_timer_target()
    function the
            for_each_cpu_and(i, sched_domain_span(sd),
                    housekeeping_cpumask(HK_FLAG_TIMER))
    equals to below:
            for (i = -1; i = cpumask_next_and(i, sched_domain_span(sd),
                    housekeeping_cpumask(HK_FLAG_TIMER)), i < nr_cpu_ids;)
    That will cause that housekeeping_cpumask() will be invoked many times.
    The housekeeping_cpumask() function returns a const value, so it is
    unnecessary to invoke it every time. This patch can minimize the worst
    searching time from ~76us to ~16us in my testing.
    
    Similarly, the find_new_ilb() function has the same problem.
    
    Co-developed-by: Li RongQing <lirongqing@baidu.com>
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Signed-off-by: Yuan ZhaoXiong <yuanzhaoxiong@baidu.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/1622985115-51007-1-git-send-email-yuanzhaoxiong@baidu.com

commit 0cc84b9a6003fa7f6ef5d19e7c8532a01cd41776
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:09 2021 +0200

    ti: Remove rcu_read_lock() around XDP program invocation
    
    The cpsw driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Tested-by: Grygorii Strashko <grygorii.strashko@ti.com>
    Reviewed-by: Grygorii Strashko <grygorii.strashko@ti.com>
    Cc: linux-omap@vger.kernel.org
    Link: https://lore.kernel.org/bpf/20210624160609.292325-20-toke@redhat.com

commit 2f1e432d339c5fed435adf521cae392755721050
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:08 2021 +0200

    stmmac: Remove rcu_read_lock() around XDP program invocation
    
    The stmmac driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Giuseppe Cavallaro <peppe.cavallaro@st.com>
    Cc: Alexandre Torgue <alexandre.torgue@foss.st.com>
    Cc: Jose Abreu <joabreu@synopsys.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-19-toke@redhat.com

commit 7b6ee873ff20c22af355661b241defa7f6ed7582
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:07 2021 +0200

    netsec: Remove rcu_read_lock() around XDP program invocation
    
    The netsec driver has a rcu_read_lock()/rcu_read_unlock() pair around the
    full RX loop, covering everything up to and including xdp_do_flush(). This
    is actually the correct behaviour, but because it all happens in a single
    NAPI poll cycle (and thus under local_bh_disable()), it is also technically
    redundant.
    
    With the addition of RCU annotations to the XDP_REDIRECT map types that
    take bh execution into account, lockdep even understands this to be safe,
    so there's really no reason to keep the rcu_read_lock() around anymore, so
    let's just remove it.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Ilias Apalodimas <ilias.apalodimas@linaro.org>
    Cc: Jassi Brar <jaswinder.singh@linaro.org>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-18-toke@redhat.com

commit 4eb14e3fc6197b7205069ed4e2b31eafa11a0697
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:06 2021 +0200

    sfc: Remove rcu_read_lock() around XDP program invocation
    
    The sfc driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Edward Cree <ecree.xilinx@gmail.com>
    Cc: Martin Habets <habetsm.xilinx@gmail.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-17-toke@redhat.com

commit 4415db6ca85ae57830a83290388f2b9dfa5f237f
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:05 2021 +0200

    qede: Remove rcu_read_lock() around XDP program invocation
    
    The qede driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Ariel Elior <aelior@marvell.com>
    Cc: gr-everest-linux-l2@marvell.com
    Link: https://lore.kernel.org/bpf/20210624160609.292325-16-toke@redhat.com

commit d5789621b658369b21bd13446bab8102cf75df65
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:04 2021 +0200

    nfp: Remove rcu_read_lock() around XDP program invocation
    
    The nfp driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small.
    
    While this is not actually an issue for the nfp driver because it doesn't
    support XDP_REDIRECT (and thus doesn't call xdp_do_flush()), the
    rcu_read_lock() is still unneeded. And With the addition of RCU annotations
    to the XDP_REDIRECT map types that take bh execution into account, lockdep
    even understands this to be safe, so there's really no reason to keep it
    around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: Simon Horman <simon.horman@netronome.com>
    Cc: oss-drivers@netronome.com
    Link: https://lore.kernel.org/bpf/20210624160609.292325-15-toke@redhat.com

commit c4411b371c104e65efb531ebd4d8892c568e3a29
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:03 2021 +0200

    mlx4: Remove rcu_read_lock() around XDP program invocation
    
    The mlx4 driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around. Also switch the RCU
    dereferences in the driver loop itself to the _bh variants.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: Tariq Toukan <tariqt@nvidia.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-14-toke@redhat.com

commit 959ad7ec066d9a61557ad6aedf77ea9b54c82df0
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:02 2021 +0200

    marvell: Remove rcu_read_lock() around XDP program invocation
    
    The mvneta and mvpp2 drivers have rcu_read_lock()/rcu_read_unlock() pairs
    around XDP program invocations. However, the actual lifetime of the objects
    referred by the XDP program invocation is longer, all the way through to
    the call to xdp_do_flush(), making the scope of the rcu_read_lock() too
    small. This turns out to be harmless because it all happens in a single
    NAPI poll cycle (and thus under local_bh_disable()), but it makes the
    rcu_read_lock() misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Thomas Petazzoni <thomas.petazzoni@bootlin.com>
    Cc: Russell King <linux@armlinux.org.uk>
    Cc: Marcin Wojtas <mw@semihalf.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-13-toke@redhat.com

commit 49589b23d5a92dff4a7cb705608dff7dd13ef709
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:01 2021 +0200

    intel: Remove rcu_read_lock() around XDP program invocation
    
    The Intel drivers all have rcu_read_lock()/rcu_read_unlock() pairs around
    XDP program invocations. However, the actual lifetime of the objects
    referred by the XDP program invocation is longer, all the way through to
    the call to xdp_do_flush(), making the scope of the rcu_read_lock() too
    small. This turns out to be harmless because it all happens in a single
    NAPI poll cycle (and thus under local_bh_disable()), but it makes the
    rcu_read_lock() misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Tested-by: Jesper Dangaard Brouer <brouer@redhat.com> # i40e
    Cc: Jesse Brandeburg <jesse.brandeburg@intel.com>
    Cc: Tony Nguyen <anthony.l.nguyen@intel.com>
    Cc: intel-wired-lan@lists.osuosl.org
    Link: https://lore.kernel.org/bpf/20210624160609.292325-12-toke@redhat.com

commit 547aabcac3251c40e4cd09d79dba70f7eab8cca2
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:06:00 2021 +0200

    freescale: Remove rcu_read_lock() around XDP program invocation
    
    The dpaa and dpaa2 drivers have rcu_read_lock()/rcu_read_unlock() pairs
    around XDP program invocations. However, the actual lifetime of the objects
    referred by the XDP program invocation is longer, all the way through to
    the call to xdp_do_flush(), making the scope of the rcu_read_lock() too
    small. This turns out to be harmless because it all happens in a single
    NAPI poll cycle (and thus under local_bh_disable()), but it makes the
    rcu_read_lock() misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Reviewed-by: Camelia Groza <camelia.groza@nxp.com>
    Cc: Ioana Radulescu <ruxandra.radulescu@nxp.com>
    Cc: Madalin Bucur <madalin.bucur@nxp.com>
    Cc: Ioana Ciornei <ioana.ciornei@nxp.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-11-toke@redhat.com

commit 36baafe347a85a9d85f61aac0a9b53c53635829e
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:05:59 2021 +0200

    thunderx: Remove rcu_read_lock() around XDP program invocation
    
    The thunderx driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Sunil Goutham <sgoutham@marvell.com>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: https://lore.kernel.org/bpf/20210624160609.292325-10-toke@redhat.com

commit 158c1399fc45c5178a3f2b8b68ff2faa2e36a52d
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:05:58 2021 +0200

    bnxt: Remove rcu_read_lock() around XDP program invocation
    
    The bnxt driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Michael Chan <michael.chan@broadcom.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-9-toke@redhat.com

commit 0939e0537896e421e391fa4b1a0b052907808e0d
Author: Toke Hiland-Jrgensen <toke@redhat.com>
Date:   Thu Jun 24 18:05:57 2021 +0200

    ena: Remove rcu_read_lock() around XDP program invocation
    
    The ena driver has rcu_read_lock()/rcu_read_unlock() pairs around XDP
    program invocations. However, the actual lifetime of the objects referred
    by the XDP program invocation is longer, all the way through to the call to
    xdp_do_flush(), making the scope of the rcu_read_lock() too small. This
    turns out to be harmless because it all happens in a single NAPI poll
    cycle (and thus under local_bh_disable()), but it makes the rcu_read_lock()
    misleading.
    
    Rather than extend the scope of the rcu_read_lock(), just get rid of it
    entirely. With the addition of RCU annotations to the XDP_REDIRECT map
    types that take bh execution into account, lockdep even understands this to
    be safe, so there's really no reason to keep it around.
    
    Signed-off-by: Toke Hiland-Jrgensen <toke@redhat.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Saeed Bishara <saeedb@amazon.com>
    Cc: Guy Tzalik <gtzalik@amazon.com>
    Link: https://lore.kernel.org/bpf/20210624160609.292325-8-toke@redhat.com

commit f5e770c0c60ab8812574a2e0d163b0efa816a825
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Apr 29 13:47:12 2021 +0200

    bpf: Add deny list of btf ids check for tracing programs
    
    [ Upstream commit 35e3815fa8102fab4dee75f3547472c66581125d ]
    
    The recursion check in __bpf_prog_enter and __bpf_prog_exit
    leaves some (not inlined) functions unprotected:
    
    In __bpf_prog_enter:
      - migrate_disable is called before prog->active is checked
    
    In __bpf_prog_exit:
      - migrate_enable,rcu_read_unlock_strict are called after
        prog->active is decreased
    
    When attaching trampoline to them we get panic like:
    
      traps: PANIC: double fault, error_code: 0x0
      double fault: 0000 [#1] SMP PTI
      RIP: 0010:__bpf_prog_enter+0x4/0x50
      ...
      Call Trace:
       <IRQ>
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       __bpf_prog_enter+0x9/0x50
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       __bpf_prog_enter+0x9/0x50
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       __bpf_prog_enter+0x9/0x50
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       ...
    
    Fixing this by adding deny list of btf ids for tracing
    programs and checking btf id during program verification.
    Adding above functions to this list.
    
    Suggested-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20210429114712.43783-1-jolsa@kernel.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3e7d1a55165bdce2aaf1139ee8889e68eb29c263
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 19 09:08:41 2021 +0200

    nvme: open code nvme_put_ns_from_disk in nvme_ns_head_ctrl_ioctl
    
    nvme_ns_head_ctrl_ioctl is always used on multipath nodes, so just call
    srcu_read_unlock directly.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <kbusch@kernel.org>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>

commit f423c85cd392241f1521887b1396038cd1e4c68e
Author: Christoph Hellwig <hch@lst.de>
Date:   Wed May 19 09:02:59 2021 +0200

    nvme: open code nvme_put_ns_from_disk in nvme_ns_head_chr_ioctl
    
    nvme_ns_head_chr_ioctl is always used on multipath nodes, so just call
    srcu_read_unlock and consolidate the two unlock paths.
    
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Reviewed-by: Keith Busch <kbusch@kernel.org>
    Reviewed-by: Sagi Grimberg <sagi@grimberg.me>

commit d7b0408934c749f546b01f2b33d07421a49b6f3e
Author: Varad Gautam <varad.gautam@suse.com>
Date:   Fri May 28 18:04:06 2021 +0200

    xfrm: policy: Read seqcount outside of rcu-read side in xfrm_policy_lookup_bytype
    
    xfrm_policy_lookup_bytype loops on seqcount mutex xfrm_policy_hash_generation
    within an RCU read side critical section. Although ill advised, this is fine if
    the loop is bounded.
    
    xfrm_policy_hash_generation wraps mutex hash_resize_mutex, which is used to
    serialize writers (xfrm_hash_resize, xfrm_hash_rebuild). This is fine too.
    
    On PREEMPT_RT=y, the read_seqcount_begin call within xfrm_policy_lookup_bytype
    emits a mutex lock/unlock for hash_resize_mutex. Mutex locking is fine, since
    RCU read side critical sections are allowed to sleep with PREEMPT_RT.
    
    xfrm_hash_resize can, however, block on synchronize_rcu while holding
    hash_resize_mutex.
    
    This leads to the following situation on PREEMPT_RT, where the writer is
    blocked on RCU grace period expiry, while the reader is blocked on a lock held
    by the writer:
    
    Thead 1 (xfrm_hash_resize)      Thread 2 (xfrm_policy_lookup_bytype)
    
                                    rcu_read_lock();
    mutex_lock(&hash_resize_mutex);
                                    read_seqcount_begin(&xfrm_policy_hash_generation);
                                    mutex_lock(&hash_resize_mutex); // block
    xfrm_bydst_resize();
    synchronize_rcu(); // block
                    <RCU stalls in xfrm_policy_lookup_bytype>
    
    Move the read_seqcount_begin call outside of the RCU read side critical section,
    and do an rcu_read_unlock/retry if we got stale data within the critical section.
    
    On non-PREEMPT_RT, this shortens the time spent within RCU read side critical
    section in case the seqcount needs a retry, and avoids unbounded looping.
    
    Fixes: 77cc278f7b20 ("xfrm: policy: Use sequence counters with associated lock")
    Signed-off-by: Varad Gautam <varad.gautam@suse.com>
    Cc: linux-rt-users <linux-rt-users@vger.kernel.org>
    Cc: netdev@vger.kernel.org
    Cc: stable@vger.kernel.org # v4.9
    Cc: Steffen Klassert <steffen.klassert@secunet.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Jakub Kicinski <kuba@kernel.org>
    Cc: Florian Westphal <fw@strlen.de>
    Cc: "Ahmed S. Darwish" <a.darwish@linutronix.de>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Acked-by: Ahmed S. Darwish <a.darwish@linutronix.de>

commit c3ae6a3f3ca4f02f6ccddf213c027302586580d0
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Thu Apr 29 22:56:39 2021 -0700

    mm: memcontrol: slab: fix obtain a reference to a freeing memcg
    
    [ Upstream commit 9f38f03ae8d5f57371b71aa6b4275765b65454fd ]
    
    Patch series "Use obj_cgroup APIs to charge kmem pages", v5.
    
    Since Roman's series "The new cgroup slab memory controller" applied.
    All slab objects are charged with the new APIs of obj_cgroup.  The new
    APIs introduce a struct obj_cgroup to charge slab objects.  It prevents
    long-living objects from pinning the original memory cgroup in the
    memory.  But there are still some corner objects (e.g.  allocations
    larger than order-1 page on SLUB) which are not charged with the new
    APIs.  Those objects (include the pages which are allocated from buddy
    allocator directly) are charged as kmem pages which still hold a
    reference to the memory cgroup.
    
    E.g.  We know that the kernel stack is charged as kmem pages because the
    size of the kernel stack can be greater than 2 pages (e.g.  16KB on
    x86_64 or arm64).  If we create a thread (suppose the thread stack is
    charged to memory cgroup A) and then move it from memory cgroup A to
    memory cgroup B.  Because the kernel stack of the thread hold a
    reference to the memory cgroup A.  The thread can pin the memory cgroup
    A in the memory even if we remove the cgroup A.  If we want to see this
    scenario by using the following script.  We can see that the system has
    added 500 dying cgroups (This is not a real world issue, just a script
    to show that the large kmallocs are charged as kmem pages which can pin
    the memory cgroup in the memory).
    
            #!/bin/bash
    
            cat /proc/cgroups | grep memory
    
            cd /sys/fs/cgroup/memory
            echo 1 > memory.move_charge_at_immigrate
    
            for i in range{1..500}
            do
                    mkdir kmem_test
                    echo $$ > kmem_test/cgroup.procs
                    sleep 3600 &
                    echo $$ > cgroup.procs
                    echo `cat kmem_test/cgroup.procs` > cgroup.procs
                    rmdir kmem_test
            done
    
            cat /proc/cgroups | grep memory
    
    This patchset aims to make those kmem pages to drop the reference to
    memory cgroup by using the APIs of obj_cgroup.  Finally, we can see that
    the number of the dying cgroups will not increase if we run the above test
    script.
    
    This patch (of 7):
    
    The rcu_read_lock/unlock only can guarantee that the memcg will not be
    freed, but it cannot guarantee the success of css_get (which is in the
    refill_stock when cached memcg changed) to memcg.
    
      rcu_read_lock()
      memcg = obj_cgroup_memcg(old)
      __memcg_kmem_uncharge(memcg)
          refill_stock(memcg)
              if (stock->cached != memcg)
                  // css_get can change the ref counter from 0 back to 1.
                  css_get(&memcg->css)
      rcu_read_unlock()
    
    This fix is very like the commit:
    
      eefbfa7fd678 ("mm: memcg/slab: fix use after free in obj_cgroup_charge")
    
    Fix this by holding a reference to the memcg which is passed to the
    __memcg_kmem_uncharge() before calling __memcg_kmem_uncharge().
    
    Link: https://lkml.kernel.org/r/20210319163821.20704-1-songmuchun@bytedance.com
    Link: https://lkml.kernel.org/r/20210319163821.20704-2-songmuchun@bytedance.com
    Fixes: 3de7d4f25a74 ("mm: memcg/slab: optimize objcg stock draining")
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Roman Gushchin <guro@fb.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: Xiongchun Duan <duanxiongchun@bytedance.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 906c538340dde6d891df89fe7dac8eaa724e40da
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Mar 21 00:08:49 2021 -0700

    nvmet-tcp: fix incorrect locking in state_change sk callback
    
    [ Upstream commit b5332a9f3f3d884a1b646ce155e664cc558c1722 ]
    
    We are not changing anything in the TCP connection state so
    we should not take a write_lock but rather a read lock.
    
    This caused a deadlock when running nvmet-tcp and nvme-tcp
    on the same system, where state_change callbacks on the
    host and on the controller side have causal relationship
    and made lockdep report on this with blktests:
    
    ================================
    WARNING: inconsistent lock state
    5.12.0-rc3 #1 Tainted: G          I
    --------------------------------
    inconsistent {IN-SOFTIRQ-W} -> {SOFTIRQ-ON-R} usage.
    nvme/1324 [HC0[0]:SC0[0]:HE1:SE1] takes:
    ffff888363151000 (clock-AF_INET){++-?}-{2:2}, at: nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
    {IN-SOFTIRQ-W} state was registered at:
      __lock_acquire+0x79b/0x18d0
      lock_acquire+0x1ca/0x480
      _raw_write_lock_bh+0x39/0x80
      nvmet_tcp_state_change+0x21/0x170 [nvmet_tcp]
      tcp_fin+0x2a8/0x780
      tcp_data_queue+0xf94/0x1f20
      tcp_rcv_established+0x6ba/0x1f00
      tcp_v4_do_rcv+0x502/0x760
      tcp_v4_rcv+0x257e/0x3430
      ip_protocol_deliver_rcu+0x69/0x6a0
      ip_local_deliver_finish+0x1e2/0x2f0
      ip_local_deliver+0x1a2/0x420
      ip_rcv+0x4fb/0x6b0
      __netif_receive_skb_one_core+0x162/0x1b0
      process_backlog+0x1ff/0x770
      __napi_poll.constprop.0+0xa9/0x5c0
      net_rx_action+0x7b3/0xb30
      __do_softirq+0x1f0/0x940
      do_softirq+0xa1/0xd0
      __local_bh_enable_ip+0xd8/0x100
      ip_finish_output2+0x6b7/0x18a0
      __ip_queue_xmit+0x706/0x1aa0
      __tcp_transmit_skb+0x2068/0x2e20
      tcp_write_xmit+0xc9e/0x2bb0
      __tcp_push_pending_frames+0x92/0x310
      inet_shutdown+0x158/0x300
      __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
      nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
      nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
      nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
      nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
      kernfs_fop_write_iter+0x2c7/0x460
      new_sync_write+0x36c/0x610
      vfs_write+0x5c0/0x870
      ksys_write+0xf9/0x1d0
      do_syscall_64+0x33/0x40
      entry_SYSCALL_64_after_hwframe+0x44/0xae
    irq event stamp: 10687
    hardirqs last  enabled at (10687): [<ffffffff9ec376bd>] _raw_spin_unlock_irqrestore+0x2d/0x40
    hardirqs last disabled at (10686): [<ffffffff9ec374d8>] _raw_spin_lock_irqsave+0x68/0x90
    softirqs last  enabled at (10684): [<ffffffff9f000608>] __do_softirq+0x608/0x940
    softirqs last disabled at (10649): [<ffffffff9cdedd31>] do_softirq+0xa1/0xd0
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
           CPU0
           ----
      lock(clock-AF_INET);
      <Interrupt>
        lock(clock-AF_INET);
    
     *** DEADLOCK ***
    
    5 locks held by nvme/1324:
     #0: ffff8884a01fe470 (sb_writers#4){.+.+}-{0:0}, at: ksys_write+0xf9/0x1d0
     #1: ffff8886e435c090 (&of->mutex){+.+.}-{3:3}, at: kernfs_fop_write_iter+0x216/0x460
     #2: ffff888104d90c38 (kn->active#255){++++}-{0:0}, at: kernfs_remove_self+0x22d/0x330
     #3: ffff8884634538d0 (&queue->queue_lock){+.+.}-{3:3}, at: nvme_tcp_stop_queue+0x52/0xb0 [nvme_tcp]
     #4: ffff888363150d30 (sk_lock-AF_INET){+.+.}-{0:0}, at: inet_shutdown+0x59/0x300
    
    stack backtrace:
    CPU: 26 PID: 1324 Comm: nvme Tainted: G          I       5.12.0-rc3 #1
    Hardware name: Dell Inc. PowerEdge R640/06NR82, BIOS 2.10.0 11/12/2020
    Call Trace:
     dump_stack+0x93/0xc2
     mark_lock_irq.cold+0x2c/0xb3
     ? verify_lock_unused+0x390/0x390
     ? stack_trace_consume_entry+0x160/0x160
     ? lock_downgrade+0x100/0x100
     ? save_trace+0x88/0x5e0
     ? _raw_spin_unlock_irqrestore+0x2d/0x40
     mark_lock+0x530/0x1470
     ? mark_lock_irq+0x1d10/0x1d10
     ? enqueue_timer+0x660/0x660
     mark_usage+0x215/0x2a0
     __lock_acquire+0x79b/0x18d0
     ? tcp_schedule_loss_probe.part.0+0x38c/0x520
     lock_acquire+0x1ca/0x480
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? rcu_read_unlock+0x40/0x40
     ? tcp_mtu_probe+0x1ae0/0x1ae0
     ? kmalloc_reserve+0xa0/0xa0
     ? sysfs_file_ops+0x170/0x170
     _raw_read_lock+0x3d/0xa0
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? sysfs_file_ops+0x170/0x170
     inet_shutdown+0x189/0x300
     __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
     nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
     nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
     nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
     nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
     kernfs_fop_write_iter+0x2c7/0x460
     new_sync_write+0x36c/0x610
     ? new_sync_read+0x600/0x600
     ? lock_acquire+0x1ca/0x480
     ? rcu_read_unlock+0x40/0x40
     ? lock_is_held_type+0x9a/0x110
     vfs_write+0x5c0/0x870
     ksys_write+0xf9/0x1d0
     ? __ia32_sys_read+0xa0/0xa0
     ? lockdep_hardirqs_on_prepare.part.0+0x198/0x340
     ? syscall_enter_from_user_mode+0x27/0x70
     do_syscall_64+0x33/0x40
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    Fixes: 872d26a391da ("nvmet-tcp: add NVMe over TCP target driver")
    Reported-by: Yi Zhang <yi.zhang@redhat.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 143f627f1979a866a88348d6961176b0c6cdb5f0
Author: Liam Howlett <liam.howlett@oracle.com>
Date:   Wed Apr 7 20:00:45 2021 +0000

    m68k: Add missing mmap_read_lock() to sys_cacheflush()
    
    [ Upstream commit f829b4b212a315b912cb23fd10aaf30534bb5ce9 ]
    
    When the superuser flushes the entire cache, the mmap_read_lock() is not
    taken, but mmap_read_unlock() is called.  Add the missing
    mmap_read_lock() call.
    
    Fixes: cd2567b6850b1648 ("m68k: call find_vma with the mmap_sem held in sys_cacheflush()")
    Signed-off-by: Liam R. Howlett <Liam.Howlett@Oracle.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Link: https://lore.kernel.org/r/20210407200032.764445-1-Liam.Howlett@Oracle.com
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 89b1ed358e01e1b0417f5d3b0082359a23355552
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Thu Apr 29 22:56:39 2021 -0700

    mm: memcontrol: slab: fix obtain a reference to a freeing memcg
    
    [ Upstream commit 9f38f03ae8d5f57371b71aa6b4275765b65454fd ]
    
    Patch series "Use obj_cgroup APIs to charge kmem pages", v5.
    
    Since Roman's series "The new cgroup slab memory controller" applied.
    All slab objects are charged with the new APIs of obj_cgroup.  The new
    APIs introduce a struct obj_cgroup to charge slab objects.  It prevents
    long-living objects from pinning the original memory cgroup in the
    memory.  But there are still some corner objects (e.g.  allocations
    larger than order-1 page on SLUB) which are not charged with the new
    APIs.  Those objects (include the pages which are allocated from buddy
    allocator directly) are charged as kmem pages which still hold a
    reference to the memory cgroup.
    
    E.g.  We know that the kernel stack is charged as kmem pages because the
    size of the kernel stack can be greater than 2 pages (e.g.  16KB on
    x86_64 or arm64).  If we create a thread (suppose the thread stack is
    charged to memory cgroup A) and then move it from memory cgroup A to
    memory cgroup B.  Because the kernel stack of the thread hold a
    reference to the memory cgroup A.  The thread can pin the memory cgroup
    A in the memory even if we remove the cgroup A.  If we want to see this
    scenario by using the following script.  We can see that the system has
    added 500 dying cgroups (This is not a real world issue, just a script
    to show that the large kmallocs are charged as kmem pages which can pin
    the memory cgroup in the memory).
    
            #!/bin/bash
    
            cat /proc/cgroups | grep memory
    
            cd /sys/fs/cgroup/memory
            echo 1 > memory.move_charge_at_immigrate
    
            for i in range{1..500}
            do
                    mkdir kmem_test
                    echo $$ > kmem_test/cgroup.procs
                    sleep 3600 &
                    echo $$ > cgroup.procs
                    echo `cat kmem_test/cgroup.procs` > cgroup.procs
                    rmdir kmem_test
            done
    
            cat /proc/cgroups | grep memory
    
    This patchset aims to make those kmem pages to drop the reference to
    memory cgroup by using the APIs of obj_cgroup.  Finally, we can see that
    the number of the dying cgroups will not increase if we run the above test
    script.
    
    This patch (of 7):
    
    The rcu_read_lock/unlock only can guarantee that the memcg will not be
    freed, but it cannot guarantee the success of css_get (which is in the
    refill_stock when cached memcg changed) to memcg.
    
      rcu_read_lock()
      memcg = obj_cgroup_memcg(old)
      __memcg_kmem_uncharge(memcg)
          refill_stock(memcg)
              if (stock->cached != memcg)
                  // css_get can change the ref counter from 0 back to 1.
                  css_get(&memcg->css)
      rcu_read_unlock()
    
    This fix is very like the commit:
    
      eefbfa7fd678 ("mm: memcg/slab: fix use after free in obj_cgroup_charge")
    
    Fix this by holding a reference to the memcg which is passed to the
    __memcg_kmem_uncharge() before calling __memcg_kmem_uncharge().
    
    Link: https://lkml.kernel.org/r/20210319163821.20704-1-songmuchun@bytedance.com
    Link: https://lkml.kernel.org/r/20210319163821.20704-2-songmuchun@bytedance.com
    Fixes: 3de7d4f25a74 ("mm: memcg/slab: optimize objcg stock draining")
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Roman Gushchin <guro@fb.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: Xiongchun Duan <duanxiongchun@bytedance.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 06beaa1a9f6e501213195e47c30416032fd2bbd5
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Mar 21 00:08:49 2021 -0700

    nvmet-tcp: fix incorrect locking in state_change sk callback
    
    [ Upstream commit b5332a9f3f3d884a1b646ce155e664cc558c1722 ]
    
    We are not changing anything in the TCP connection state so
    we should not take a write_lock but rather a read lock.
    
    This caused a deadlock when running nvmet-tcp and nvme-tcp
    on the same system, where state_change callbacks on the
    host and on the controller side have causal relationship
    and made lockdep report on this with blktests:
    
    ================================
    WARNING: inconsistent lock state
    5.12.0-rc3 #1 Tainted: G          I
    --------------------------------
    inconsistent {IN-SOFTIRQ-W} -> {SOFTIRQ-ON-R} usage.
    nvme/1324 [HC0[0]:SC0[0]:HE1:SE1] takes:
    ffff888363151000 (clock-AF_INET){++-?}-{2:2}, at: nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
    {IN-SOFTIRQ-W} state was registered at:
      __lock_acquire+0x79b/0x18d0
      lock_acquire+0x1ca/0x480
      _raw_write_lock_bh+0x39/0x80
      nvmet_tcp_state_change+0x21/0x170 [nvmet_tcp]
      tcp_fin+0x2a8/0x780
      tcp_data_queue+0xf94/0x1f20
      tcp_rcv_established+0x6ba/0x1f00
      tcp_v4_do_rcv+0x502/0x760
      tcp_v4_rcv+0x257e/0x3430
      ip_protocol_deliver_rcu+0x69/0x6a0
      ip_local_deliver_finish+0x1e2/0x2f0
      ip_local_deliver+0x1a2/0x420
      ip_rcv+0x4fb/0x6b0
      __netif_receive_skb_one_core+0x162/0x1b0
      process_backlog+0x1ff/0x770
      __napi_poll.constprop.0+0xa9/0x5c0
      net_rx_action+0x7b3/0xb30
      __do_softirq+0x1f0/0x940
      do_softirq+0xa1/0xd0
      __local_bh_enable_ip+0xd8/0x100
      ip_finish_output2+0x6b7/0x18a0
      __ip_queue_xmit+0x706/0x1aa0
      __tcp_transmit_skb+0x2068/0x2e20
      tcp_write_xmit+0xc9e/0x2bb0
      __tcp_push_pending_frames+0x92/0x310
      inet_shutdown+0x158/0x300
      __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
      nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
      nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
      nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
      nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
      kernfs_fop_write_iter+0x2c7/0x460
      new_sync_write+0x36c/0x610
      vfs_write+0x5c0/0x870
      ksys_write+0xf9/0x1d0
      do_syscall_64+0x33/0x40
      entry_SYSCALL_64_after_hwframe+0x44/0xae
    irq event stamp: 10687
    hardirqs last  enabled at (10687): [<ffffffff9ec376bd>] _raw_spin_unlock_irqrestore+0x2d/0x40
    hardirqs last disabled at (10686): [<ffffffff9ec374d8>] _raw_spin_lock_irqsave+0x68/0x90
    softirqs last  enabled at (10684): [<ffffffff9f000608>] __do_softirq+0x608/0x940
    softirqs last disabled at (10649): [<ffffffff9cdedd31>] do_softirq+0xa1/0xd0
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
           CPU0
           ----
      lock(clock-AF_INET);
      <Interrupt>
        lock(clock-AF_INET);
    
     *** DEADLOCK ***
    
    5 locks held by nvme/1324:
     #0: ffff8884a01fe470 (sb_writers#4){.+.+}-{0:0}, at: ksys_write+0xf9/0x1d0
     #1: ffff8886e435c090 (&of->mutex){+.+.}-{3:3}, at: kernfs_fop_write_iter+0x216/0x460
     #2: ffff888104d90c38 (kn->active#255){++++}-{0:0}, at: kernfs_remove_self+0x22d/0x330
     #3: ffff8884634538d0 (&queue->queue_lock){+.+.}-{3:3}, at: nvme_tcp_stop_queue+0x52/0xb0 [nvme_tcp]
     #4: ffff888363150d30 (sk_lock-AF_INET){+.+.}-{0:0}, at: inet_shutdown+0x59/0x300
    
    stack backtrace:
    CPU: 26 PID: 1324 Comm: nvme Tainted: G          I       5.12.0-rc3 #1
    Hardware name: Dell Inc. PowerEdge R640/06NR82, BIOS 2.10.0 11/12/2020
    Call Trace:
     dump_stack+0x93/0xc2
     mark_lock_irq.cold+0x2c/0xb3
     ? verify_lock_unused+0x390/0x390
     ? stack_trace_consume_entry+0x160/0x160
     ? lock_downgrade+0x100/0x100
     ? save_trace+0x88/0x5e0
     ? _raw_spin_unlock_irqrestore+0x2d/0x40
     mark_lock+0x530/0x1470
     ? mark_lock_irq+0x1d10/0x1d10
     ? enqueue_timer+0x660/0x660
     mark_usage+0x215/0x2a0
     __lock_acquire+0x79b/0x18d0
     ? tcp_schedule_loss_probe.part.0+0x38c/0x520
     lock_acquire+0x1ca/0x480
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? rcu_read_unlock+0x40/0x40
     ? tcp_mtu_probe+0x1ae0/0x1ae0
     ? kmalloc_reserve+0xa0/0xa0
     ? sysfs_file_ops+0x170/0x170
     _raw_read_lock+0x3d/0xa0
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? sysfs_file_ops+0x170/0x170
     inet_shutdown+0x189/0x300
     __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
     nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
     nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
     nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
     nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
     kernfs_fop_write_iter+0x2c7/0x460
     new_sync_write+0x36c/0x610
     ? new_sync_read+0x600/0x600
     ? lock_acquire+0x1ca/0x480
     ? rcu_read_unlock+0x40/0x40
     ? lock_is_held_type+0x9a/0x110
     vfs_write+0x5c0/0x870
     ksys_write+0xf9/0x1d0
     ? __ia32_sys_read+0xa0/0xa0
     ? lockdep_hardirqs_on_prepare.part.0+0x198/0x340
     ? syscall_enter_from_user_mode+0x27/0x70
     do_syscall_64+0x33/0x40
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    Fixes: 872d26a391da ("nvmet-tcp: add NVMe over TCP target driver")
    Reported-by: Yi Zhang <yi.zhang@redhat.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b9fe332957287816f740064fa811fd954b9b2d20
Author: Liam Howlett <liam.howlett@oracle.com>
Date:   Wed Apr 7 20:00:45 2021 +0000

    m68k: Add missing mmap_read_lock() to sys_cacheflush()
    
    [ Upstream commit f829b4b212a315b912cb23fd10aaf30534bb5ce9 ]
    
    When the superuser flushes the entire cache, the mmap_read_lock() is not
    taken, but mmap_read_unlock() is called.  Add the missing
    mmap_read_lock() call.
    
    Fixes: cd2567b6850b1648 ("m68k: call find_vma with the mmap_sem held in sys_cacheflush()")
    Signed-off-by: Liam R. Howlett <Liam.Howlett@Oracle.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Link: https://lore.kernel.org/r/20210407200032.764445-1-Liam.Howlett@Oracle.com
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 31df8bc4d3feca9f9c6b2cd06fd64a111ae1a0e6
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Thu Apr 29 22:56:39 2021 -0700

    mm: memcontrol: slab: fix obtain a reference to a freeing memcg
    
    [ Upstream commit 9f38f03ae8d5f57371b71aa6b4275765b65454fd ]
    
    Patch series "Use obj_cgroup APIs to charge kmem pages", v5.
    
    Since Roman's series "The new cgroup slab memory controller" applied.
    All slab objects are charged with the new APIs of obj_cgroup.  The new
    APIs introduce a struct obj_cgroup to charge slab objects.  It prevents
    long-living objects from pinning the original memory cgroup in the
    memory.  But there are still some corner objects (e.g.  allocations
    larger than order-1 page on SLUB) which are not charged with the new
    APIs.  Those objects (include the pages which are allocated from buddy
    allocator directly) are charged as kmem pages which still hold a
    reference to the memory cgroup.
    
    E.g.  We know that the kernel stack is charged as kmem pages because the
    size of the kernel stack can be greater than 2 pages (e.g.  16KB on
    x86_64 or arm64).  If we create a thread (suppose the thread stack is
    charged to memory cgroup A) and then move it from memory cgroup A to
    memory cgroup B.  Because the kernel stack of the thread hold a
    reference to the memory cgroup A.  The thread can pin the memory cgroup
    A in the memory even if we remove the cgroup A.  If we want to see this
    scenario by using the following script.  We can see that the system has
    added 500 dying cgroups (This is not a real world issue, just a script
    to show that the large kmallocs are charged as kmem pages which can pin
    the memory cgroup in the memory).
    
            #!/bin/bash
    
            cat /proc/cgroups | grep memory
    
            cd /sys/fs/cgroup/memory
            echo 1 > memory.move_charge_at_immigrate
    
            for i in range{1..500}
            do
                    mkdir kmem_test
                    echo $$ > kmem_test/cgroup.procs
                    sleep 3600 &
                    echo $$ > cgroup.procs
                    echo `cat kmem_test/cgroup.procs` > cgroup.procs
                    rmdir kmem_test
            done
    
            cat /proc/cgroups | grep memory
    
    This patchset aims to make those kmem pages to drop the reference to
    memory cgroup by using the APIs of obj_cgroup.  Finally, we can see that
    the number of the dying cgroups will not increase if we run the above test
    script.
    
    This patch (of 7):
    
    The rcu_read_lock/unlock only can guarantee that the memcg will not be
    freed, but it cannot guarantee the success of css_get (which is in the
    refill_stock when cached memcg changed) to memcg.
    
      rcu_read_lock()
      memcg = obj_cgroup_memcg(old)
      __memcg_kmem_uncharge(memcg)
          refill_stock(memcg)
              if (stock->cached != memcg)
                  // css_get can change the ref counter from 0 back to 1.
                  css_get(&memcg->css)
      rcu_read_unlock()
    
    This fix is very like the commit:
    
      eefbfa7fd678 ("mm: memcg/slab: fix use after free in obj_cgroup_charge")
    
    Fix this by holding a reference to the memcg which is passed to the
    __memcg_kmem_uncharge() before calling __memcg_kmem_uncharge().
    
    Link: https://lkml.kernel.org/r/20210319163821.20704-1-songmuchun@bytedance.com
    Link: https://lkml.kernel.org/r/20210319163821.20704-2-songmuchun@bytedance.com
    Fixes: 3de7d4f25a74 ("mm: memcg/slab: optimize objcg stock draining")
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Roman Gushchin <guro@fb.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: Xiongchun Duan <duanxiongchun@bytedance.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 60ade0d56b06537a28884745059b3801c78e03bc
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Mar 21 00:08:49 2021 -0700

    nvmet-tcp: fix incorrect locking in state_change sk callback
    
    [ Upstream commit b5332a9f3f3d884a1b646ce155e664cc558c1722 ]
    
    We are not changing anything in the TCP connection state so
    we should not take a write_lock but rather a read lock.
    
    This caused a deadlock when running nvmet-tcp and nvme-tcp
    on the same system, where state_change callbacks on the
    host and on the controller side have causal relationship
    and made lockdep report on this with blktests:
    
    ================================
    WARNING: inconsistent lock state
    5.12.0-rc3 #1 Tainted: G          I
    --------------------------------
    inconsistent {IN-SOFTIRQ-W} -> {SOFTIRQ-ON-R} usage.
    nvme/1324 [HC0[0]:SC0[0]:HE1:SE1] takes:
    ffff888363151000 (clock-AF_INET){++-?}-{2:2}, at: nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
    {IN-SOFTIRQ-W} state was registered at:
      __lock_acquire+0x79b/0x18d0
      lock_acquire+0x1ca/0x480
      _raw_write_lock_bh+0x39/0x80
      nvmet_tcp_state_change+0x21/0x170 [nvmet_tcp]
      tcp_fin+0x2a8/0x780
      tcp_data_queue+0xf94/0x1f20
      tcp_rcv_established+0x6ba/0x1f00
      tcp_v4_do_rcv+0x502/0x760
      tcp_v4_rcv+0x257e/0x3430
      ip_protocol_deliver_rcu+0x69/0x6a0
      ip_local_deliver_finish+0x1e2/0x2f0
      ip_local_deliver+0x1a2/0x420
      ip_rcv+0x4fb/0x6b0
      __netif_receive_skb_one_core+0x162/0x1b0
      process_backlog+0x1ff/0x770
      __napi_poll.constprop.0+0xa9/0x5c0
      net_rx_action+0x7b3/0xb30
      __do_softirq+0x1f0/0x940
      do_softirq+0xa1/0xd0
      __local_bh_enable_ip+0xd8/0x100
      ip_finish_output2+0x6b7/0x18a0
      __ip_queue_xmit+0x706/0x1aa0
      __tcp_transmit_skb+0x2068/0x2e20
      tcp_write_xmit+0xc9e/0x2bb0
      __tcp_push_pending_frames+0x92/0x310
      inet_shutdown+0x158/0x300
      __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
      nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
      nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
      nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
      nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
      kernfs_fop_write_iter+0x2c7/0x460
      new_sync_write+0x36c/0x610
      vfs_write+0x5c0/0x870
      ksys_write+0xf9/0x1d0
      do_syscall_64+0x33/0x40
      entry_SYSCALL_64_after_hwframe+0x44/0xae
    irq event stamp: 10687
    hardirqs last  enabled at (10687): [<ffffffff9ec376bd>] _raw_spin_unlock_irqrestore+0x2d/0x40
    hardirqs last disabled at (10686): [<ffffffff9ec374d8>] _raw_spin_lock_irqsave+0x68/0x90
    softirqs last  enabled at (10684): [<ffffffff9f000608>] __do_softirq+0x608/0x940
    softirqs last disabled at (10649): [<ffffffff9cdedd31>] do_softirq+0xa1/0xd0
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
           CPU0
           ----
      lock(clock-AF_INET);
      <Interrupt>
        lock(clock-AF_INET);
    
     *** DEADLOCK ***
    
    5 locks held by nvme/1324:
     #0: ffff8884a01fe470 (sb_writers#4){.+.+}-{0:0}, at: ksys_write+0xf9/0x1d0
     #1: ffff8886e435c090 (&of->mutex){+.+.}-{3:3}, at: kernfs_fop_write_iter+0x216/0x460
     #2: ffff888104d90c38 (kn->active#255){++++}-{0:0}, at: kernfs_remove_self+0x22d/0x330
     #3: ffff8884634538d0 (&queue->queue_lock){+.+.}-{3:3}, at: nvme_tcp_stop_queue+0x52/0xb0 [nvme_tcp]
     #4: ffff888363150d30 (sk_lock-AF_INET){+.+.}-{0:0}, at: inet_shutdown+0x59/0x300
    
    stack backtrace:
    CPU: 26 PID: 1324 Comm: nvme Tainted: G          I       5.12.0-rc3 #1
    Hardware name: Dell Inc. PowerEdge R640/06NR82, BIOS 2.10.0 11/12/2020
    Call Trace:
     dump_stack+0x93/0xc2
     mark_lock_irq.cold+0x2c/0xb3
     ? verify_lock_unused+0x390/0x390
     ? stack_trace_consume_entry+0x160/0x160
     ? lock_downgrade+0x100/0x100
     ? save_trace+0x88/0x5e0
     ? _raw_spin_unlock_irqrestore+0x2d/0x40
     mark_lock+0x530/0x1470
     ? mark_lock_irq+0x1d10/0x1d10
     ? enqueue_timer+0x660/0x660
     mark_usage+0x215/0x2a0
     __lock_acquire+0x79b/0x18d0
     ? tcp_schedule_loss_probe.part.0+0x38c/0x520
     lock_acquire+0x1ca/0x480
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? rcu_read_unlock+0x40/0x40
     ? tcp_mtu_probe+0x1ae0/0x1ae0
     ? kmalloc_reserve+0xa0/0xa0
     ? sysfs_file_ops+0x170/0x170
     _raw_read_lock+0x3d/0xa0
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? sysfs_file_ops+0x170/0x170
     inet_shutdown+0x189/0x300
     __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
     nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
     nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
     nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
     nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
     kernfs_fop_write_iter+0x2c7/0x460
     new_sync_write+0x36c/0x610
     ? new_sync_read+0x600/0x600
     ? lock_acquire+0x1ca/0x480
     ? rcu_read_unlock+0x40/0x40
     ? lock_is_held_type+0x9a/0x110
     vfs_write+0x5c0/0x870
     ksys_write+0xf9/0x1d0
     ? __ia32_sys_read+0xa0/0xa0
     ? lockdep_hardirqs_on_prepare.part.0+0x198/0x340
     ? syscall_enter_from_user_mode+0x27/0x70
     do_syscall_64+0x33/0x40
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    Fixes: 872d26a391da ("nvmet-tcp: add NVMe over TCP target driver")
    Reported-by: Yi Zhang <yi.zhang@redhat.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 58ee5a0de192f698b136128154b32773d946ec47
Author: Liam Howlett <liam.howlett@oracle.com>
Date:   Wed Apr 7 20:00:45 2021 +0000

    m68k: Add missing mmap_read_lock() to sys_cacheflush()
    
    [ Upstream commit f829b4b212a315b912cb23fd10aaf30534bb5ce9 ]
    
    When the superuser flushes the entire cache, the mmap_read_lock() is not
    taken, but mmap_read_unlock() is called.  Add the missing
    mmap_read_lock() call.
    
    Fixes: cd2567b6850b1648 ("m68k: call find_vma with the mmap_sem held in sys_cacheflush()")
    Signed-off-by: Liam R. Howlett <Liam.Howlett@Oracle.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Link: https://lore.kernel.org/r/20210407200032.764445-1-Liam.Howlett@Oracle.com
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 999d606a820c36ae9b9e9611360c8b3d8d4bb777
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Mar 21 00:08:49 2021 -0700

    nvmet-tcp: fix incorrect locking in state_change sk callback
    
    [ Upstream commit b5332a9f3f3d884a1b646ce155e664cc558c1722 ]
    
    We are not changing anything in the TCP connection state so
    we should not take a write_lock but rather a read lock.
    
    This caused a deadlock when running nvmet-tcp and nvme-tcp
    on the same system, where state_change callbacks on the
    host and on the controller side have causal relationship
    and made lockdep report on this with blktests:
    
    ================================
    WARNING: inconsistent lock state
    5.12.0-rc3 #1 Tainted: G          I
    --------------------------------
    inconsistent {IN-SOFTIRQ-W} -> {SOFTIRQ-ON-R} usage.
    nvme/1324 [HC0[0]:SC0[0]:HE1:SE1] takes:
    ffff888363151000 (clock-AF_INET){++-?}-{2:2}, at: nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
    {IN-SOFTIRQ-W} state was registered at:
      __lock_acquire+0x79b/0x18d0
      lock_acquire+0x1ca/0x480
      _raw_write_lock_bh+0x39/0x80
      nvmet_tcp_state_change+0x21/0x170 [nvmet_tcp]
      tcp_fin+0x2a8/0x780
      tcp_data_queue+0xf94/0x1f20
      tcp_rcv_established+0x6ba/0x1f00
      tcp_v4_do_rcv+0x502/0x760
      tcp_v4_rcv+0x257e/0x3430
      ip_protocol_deliver_rcu+0x69/0x6a0
      ip_local_deliver_finish+0x1e2/0x2f0
      ip_local_deliver+0x1a2/0x420
      ip_rcv+0x4fb/0x6b0
      __netif_receive_skb_one_core+0x162/0x1b0
      process_backlog+0x1ff/0x770
      __napi_poll.constprop.0+0xa9/0x5c0
      net_rx_action+0x7b3/0xb30
      __do_softirq+0x1f0/0x940
      do_softirq+0xa1/0xd0
      __local_bh_enable_ip+0xd8/0x100
      ip_finish_output2+0x6b7/0x18a0
      __ip_queue_xmit+0x706/0x1aa0
      __tcp_transmit_skb+0x2068/0x2e20
      tcp_write_xmit+0xc9e/0x2bb0
      __tcp_push_pending_frames+0x92/0x310
      inet_shutdown+0x158/0x300
      __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
      nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
      nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
      nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
      nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
      kernfs_fop_write_iter+0x2c7/0x460
      new_sync_write+0x36c/0x610
      vfs_write+0x5c0/0x870
      ksys_write+0xf9/0x1d0
      do_syscall_64+0x33/0x40
      entry_SYSCALL_64_after_hwframe+0x44/0xae
    irq event stamp: 10687
    hardirqs last  enabled at (10687): [<ffffffff9ec376bd>] _raw_spin_unlock_irqrestore+0x2d/0x40
    hardirqs last disabled at (10686): [<ffffffff9ec374d8>] _raw_spin_lock_irqsave+0x68/0x90
    softirqs last  enabled at (10684): [<ffffffff9f000608>] __do_softirq+0x608/0x940
    softirqs last disabled at (10649): [<ffffffff9cdedd31>] do_softirq+0xa1/0xd0
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
           CPU0
           ----
      lock(clock-AF_INET);
      <Interrupt>
        lock(clock-AF_INET);
    
     *** DEADLOCK ***
    
    5 locks held by nvme/1324:
     #0: ffff8884a01fe470 (sb_writers#4){.+.+}-{0:0}, at: ksys_write+0xf9/0x1d0
     #1: ffff8886e435c090 (&of->mutex){+.+.}-{3:3}, at: kernfs_fop_write_iter+0x216/0x460
     #2: ffff888104d90c38 (kn->active#255){++++}-{0:0}, at: kernfs_remove_self+0x22d/0x330
     #3: ffff8884634538d0 (&queue->queue_lock){+.+.}-{3:3}, at: nvme_tcp_stop_queue+0x52/0xb0 [nvme_tcp]
     #4: ffff888363150d30 (sk_lock-AF_INET){+.+.}-{0:0}, at: inet_shutdown+0x59/0x300
    
    stack backtrace:
    CPU: 26 PID: 1324 Comm: nvme Tainted: G          I       5.12.0-rc3 #1
    Hardware name: Dell Inc. PowerEdge R640/06NR82, BIOS 2.10.0 11/12/2020
    Call Trace:
     dump_stack+0x93/0xc2
     mark_lock_irq.cold+0x2c/0xb3
     ? verify_lock_unused+0x390/0x390
     ? stack_trace_consume_entry+0x160/0x160
     ? lock_downgrade+0x100/0x100
     ? save_trace+0x88/0x5e0
     ? _raw_spin_unlock_irqrestore+0x2d/0x40
     mark_lock+0x530/0x1470
     ? mark_lock_irq+0x1d10/0x1d10
     ? enqueue_timer+0x660/0x660
     mark_usage+0x215/0x2a0
     __lock_acquire+0x79b/0x18d0
     ? tcp_schedule_loss_probe.part.0+0x38c/0x520
     lock_acquire+0x1ca/0x480
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? rcu_read_unlock+0x40/0x40
     ? tcp_mtu_probe+0x1ae0/0x1ae0
     ? kmalloc_reserve+0xa0/0xa0
     ? sysfs_file_ops+0x170/0x170
     _raw_read_lock+0x3d/0xa0
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? sysfs_file_ops+0x170/0x170
     inet_shutdown+0x189/0x300
     __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
     nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
     nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
     nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
     nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
     kernfs_fop_write_iter+0x2c7/0x460
     new_sync_write+0x36c/0x610
     ? new_sync_read+0x600/0x600
     ? lock_acquire+0x1ca/0x480
     ? rcu_read_unlock+0x40/0x40
     ? lock_is_held_type+0x9a/0x110
     vfs_write+0x5c0/0x870
     ksys_write+0xf9/0x1d0
     ? __ia32_sys_read+0xa0/0xa0
     ? lockdep_hardirqs_on_prepare.part.0+0x198/0x340
     ? syscall_enter_from_user_mode+0x27/0x70
     do_syscall_64+0x33/0x40
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    Fixes: 872d26a391da ("nvmet-tcp: add NVMe over TCP target driver")
    Reported-by: Yi Zhang <yi.zhang@redhat.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0223846010750e28e4330f1beefb5564ba406ef7
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Apr 29 11:30:49 2021 -0700

    rcu: Remove obsolete rcu_read_unlock() deadlock commentary
    
    The deferred quiescent states resulting from the consolidation of RCU-bh
    and RCU-sched into RCU means that rcu_read_unlock() will no longer attempt
    to acquire scheduler locks if interrupts were disabled across that call
    to rcu_read_unlock().  The cautions in the rcu_read_unlock() header
    comment are therefore obsolete.  This commit therefore removes them.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit d2dfa17bc7de67e99685c4d6557837bf801a102c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Nov 17 18:19:43 2020 -0500

    sched: Trivial forced-newidle balancer
    
    When a sibling is forced-idle to match the core-cookie; search for
    matching tasks to fill the core.
    
    rcu_read_unlock() can incur an infrequent deadlock in
    sched_core_balance(). Fix this by using the RCU-sched flavor instead.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Don Hiatt <dhiatt@digitalocean.com>
    Tested-by: Hongyu Ning <hongyu.ning@linux.intel.com>
    Tested-by: Vincent Guittot <vincent.guittot@linaro.org>
    Link: https://lkml.kernel.org/r/20210422123308.800048269@infradead.org

commit 35e3815fa8102fab4dee75f3547472c66581125d
Author: Jiri Olsa <jolsa@kernel.org>
Date:   Thu Apr 29 13:47:12 2021 +0200

    bpf: Add deny list of btf ids check for tracing programs
    
    The recursion check in __bpf_prog_enter and __bpf_prog_exit
    leaves some (not inlined) functions unprotected:
    
    In __bpf_prog_enter:
      - migrate_disable is called before prog->active is checked
    
    In __bpf_prog_exit:
      - migrate_enable,rcu_read_unlock_strict are called after
        prog->active is decreased
    
    When attaching trampoline to them we get panic like:
    
      traps: PANIC: double fault, error_code: 0x0
      double fault: 0000 [#1] SMP PTI
      RIP: 0010:__bpf_prog_enter+0x4/0x50
      ...
      Call Trace:
       <IRQ>
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       __bpf_prog_enter+0x9/0x50
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       __bpf_prog_enter+0x9/0x50
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       __bpf_prog_enter+0x9/0x50
       bpf_trampoline_6442466513_0+0x18/0x1000
       migrate_disable+0x5/0x50
       ...
    
    Fixing this by adding deny list of btf ids for tracing
    programs and checking btf id during program verification.
    Adding above functions to this list.
    
    Suggested-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Jiri Olsa <jolsa@kernel.org>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20210429114712.43783-1-jolsa@kernel.org

commit 55bc1af3d9115d669570aa633e5428d6e2302e8f
Merge: e4d4a27220a3 6c8774a94e6a
Author: Jakub Kicinski <kuba@kernel.org>
Date:   Fri May 7 16:10:12 2021 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/pablo/nf
    
    Pablo Neira Ayuso says:
    
    ====================
    Netfilter fixes for net
    
    1) Add SECMARK revision 1 to fix incorrect layout that prevents
       from remove rule with this target, from Phil Sutter.
    
    2) Fix pernet exit path spat in arptables, from Florian Westphal.
    
    3) Missing rcu_read_unlock() for unknown nfnetlink callbacks,
       reported by syzbot, from Eric Dumazet.
    
    4) Missing check for skb_header_pointer() NULL pointer in
       nfnetlink_osf.
    
    5) Remove BUG_ON() after skb_header_pointer() from packet path
       in several conntrack helper and the TCP tracker.
    
    6) Fix memleak in the new object error path of userdata.
    
    7) Avoid overflows in nft_hash_buckets(), reported by syzbot,
       also from Eric.
    
    8) Avoid overflows in 32bit arches, from Eric.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/pablo/nf:
      netfilter: nftables: avoid potential overflows on 32bit arches
      netfilter: nftables: avoid overflows in nft_hash_buckets()
      netfilter: nftables: Fix a memleak from userdata error path in new objects
      netfilter: remove BUG_ON() after skb_header_pointer()
      netfilter: nfnetlink_osf: Fix a missing skb_header_pointer() NULL check
      netfilter: nfnetlink: add a missing rcu_read_unlock()
      netfilter: arptables: use pernet ops struct during unregister
      netfilter: xt_SECMARK: add new revision to fix structure layout
    ====================
    
    Link: https://lore.kernel.org/r/20210507174739.1850-1-pablo@netfilter.org
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit 7072a355ba191c08b0579f0f66e3eba0e28bf818
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 5 00:33:24 2021 -0700

    netfilter: nfnetlink: add a missing rcu_read_unlock()
    
    Reported by syzbot :
    BUG: sleeping function called from invalid context at include/linux/sched/mm.h:201
    in_atomic(): 0, irqs_disabled(): 0, non_block: 0, pid: 26899, name: syz-executor.5
    1 lock held by syz-executor.5/26899:
     #0: ffffffff8bf797a0 (rcu_read_lock){....}-{1:2}, at: nfnetlink_get_subsys net/netfilter/nfnetlink.c:148 [inline]
     #0: ffffffff8bf797a0 (rcu_read_lock){....}-{1:2}, at: nfnetlink_rcv_msg+0x1da/0x1300 net/netfilter/nfnetlink.c:226
    Preemption disabled at:
    [<ffffffff8917799e>] preempt_schedule_irq+0x3e/0x90 kernel/sched/core.c:5533
    CPU: 1 PID: 26899 Comm: syz-executor.5 Not tainted 5.12.0-next-20210504-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:79 [inline]
     dump_stack+0x141/0x1d7 lib/dump_stack.c:120
     ___might_sleep.cold+0x1f1/0x237 kernel/sched/core.c:8338
     might_alloc include/linux/sched/mm.h:201 [inline]
     slab_pre_alloc_hook mm/slab.h:500 [inline]
     slab_alloc_node mm/slub.c:2845 [inline]
     kmem_cache_alloc_node+0x33d/0x3e0 mm/slub.c:2960
     __alloc_skb+0x20b/0x340 net/core/skbuff.c:413
     alloc_skb include/linux/skbuff.h:1107 [inline]
     nlmsg_new include/net/netlink.h:953 [inline]
     netlink_ack+0x1ed/0xaa0 net/netlink/af_netlink.c:2437
     netlink_rcv_skb+0x33d/0x420 net/netlink/af_netlink.c:2508
     nfnetlink_rcv+0x1ac/0x420 net/netfilter/nfnetlink.c:650
     netlink_unicast_kernel net/netlink/af_netlink.c:1312 [inline]
     netlink_unicast+0x533/0x7d0 net/netlink/af_netlink.c:1338
     netlink_sendmsg+0x856/0xd90 net/netlink/af_netlink.c:1927
     sock_sendmsg_nosec net/socket.c:654 [inline]
     sock_sendmsg+0xcf/0x120 net/socket.c:674
     ____sys_sendmsg+0x6e8/0x810 net/socket.c:2350
     ___sys_sendmsg+0xf3/0x170 net/socket.c:2404
     __sys_sendmsg+0xe5/0x1b0 net/socket.c:2433
     do_syscall_64+0x3a/0xb0 arch/x86/entry/common.c:47
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    RIP: 0033:0x4665f9
    Code: ff ff c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 c7 c1 bc ff ff ff f7 d8 64 89 01 48
    RSP: 002b:00007fa8a03ee188 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    RAX: ffffffffffffffda RBX: 000000000056bf60 RCX: 00000000004665f9
    RDX: 0000000000000000 RSI: 0000000020000480 RDI: 0000000000000004
    RBP: 00000000004bfce1 R08: 0000000000000000 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000246 R12: 000000000056bf60
    R13: 00007fffe864480f R14: 00007fa8a03ee300 R15: 0000000000022000
    
    ================================================
    WARNING: lock held when returning to user space!
    5.12.0-next-20210504-syzkaller #0 Tainted: G        W
    ------------------------------------------------
    syz-executor.5/26899 is leaving the kernel with locks still held!
    1 lock held by syz-executor.5/26899:
     #0: ffffffff8bf797a0 (rcu_read_lock){....}-{1:2}, at: nfnetlink_get_subsys net/netfilter/nfnetlink.c:148 [inline]
     #0: ffffffff8bf797a0 (rcu_read_lock){....}-{1:2}, at: nfnetlink_rcv_msg+0x1da/0x1300 net/netfilter/nfnetlink.c:226
    ------------[ cut here ]------------
    WARNING: CPU: 0 PID: 26899 at kernel/rcu/tree_plugin.h:359 rcu_note_context_switch+0xfd/0x16e0 kernel/rcu/tree_plugin.h:359
    Modules linked in:
    CPU: 0 PID: 26899 Comm: syz-executor.5 Tainted: G        W         5.12.0-next-20210504-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    RIP: 0010:rcu_note_context_switch+0xfd/0x16e0 kernel/rcu/tree_plugin.h:359
    Code: 48 89 fa 48 c1 ea 03 0f b6 14 02 48 89 f8 83 e0 07 83 c0 03 38 d0 7c 08 84 d2 0f 85 2e 0d 00 00 8b bd cc 03 00 00 85 ff 7e 02 <0f> 0b 65 48 8b 2c 25 00 f0 01 00 48 8d bd cc 03 00 00 48 b8 00 00
    RSP: 0000:ffffc90002fffdb0 EFLAGS: 00010002
    RAX: 0000000000000007 RBX: ffff8880b9c36080 RCX: ffffffff8dc99bac
    RDX: 0000000000000000 RSI: 0000000000000008 RDI: 0000000000000001
    RBP: ffff88808b9d1c80 R08: 0000000000000000 R09: ffffffff8dc96917
    R10: fffffbfff1b92d22 R11: 0000000000000000 R12: 0000000000000000
    R13: ffff88808b9d1c80 R14: ffff88808b9d1c80 R15: ffffc90002ff8000
    FS:  00007fa8a03ee700(0000) GS:ffff8880b9c00000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f09896ed000 CR3: 0000000032070000 CR4: 00000000001526f0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    Call Trace:
     __schedule+0x214/0x23e0 kernel/sched/core.c:5044
     schedule+0xcf/0x270 kernel/sched/core.c:5226
     exit_to_user_mode_loop kernel/entry/common.c:162 [inline]
     exit_to_user_mode_prepare+0x13e/0x280 kernel/entry/common.c:208
     irqentry_exit_to_user_mode+0x5/0x40 kernel/entry/common.c:314
     asm_sysvec_reschedule_ipi+0x12/0x20 arch/x86/include/asm/idtentry.h:637
    RIP: 0033:0x4665f9
    
    Fixes: 50f2db9e368f ("netfilter: nfnetlink: consolidate callback types")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 9f38f03ae8d5f57371b71aa6b4275765b65454fd
Author: Muchun Song <songmuchun@bytedance.com>
Date:   Thu Apr 29 22:56:39 2021 -0700

    mm: memcontrol: slab: fix obtain a reference to a freeing memcg
    
    Patch series "Use obj_cgroup APIs to charge kmem pages", v5.
    
    Since Roman's series "The new cgroup slab memory controller" applied.
    All slab objects are charged with the new APIs of obj_cgroup.  The new
    APIs introduce a struct obj_cgroup to charge slab objects.  It prevents
    long-living objects from pinning the original memory cgroup in the
    memory.  But there are still some corner objects (e.g.  allocations
    larger than order-1 page on SLUB) which are not charged with the new
    APIs.  Those objects (include the pages which are allocated from buddy
    allocator directly) are charged as kmem pages which still hold a
    reference to the memory cgroup.
    
    E.g.  We know that the kernel stack is charged as kmem pages because the
    size of the kernel stack can be greater than 2 pages (e.g.  16KB on
    x86_64 or arm64).  If we create a thread (suppose the thread stack is
    charged to memory cgroup A) and then move it from memory cgroup A to
    memory cgroup B.  Because the kernel stack of the thread hold a
    reference to the memory cgroup A.  The thread can pin the memory cgroup
    A in the memory even if we remove the cgroup A.  If we want to see this
    scenario by using the following script.  We can see that the system has
    added 500 dying cgroups (This is not a real world issue, just a script
    to show that the large kmallocs are charged as kmem pages which can pin
    the memory cgroup in the memory).
    
            #!/bin/bash
    
            cat /proc/cgroups | grep memory
    
            cd /sys/fs/cgroup/memory
            echo 1 > memory.move_charge_at_immigrate
    
            for i in range{1..500}
            do
                    mkdir kmem_test
                    echo $$ > kmem_test/cgroup.procs
                    sleep 3600 &
                    echo $$ > cgroup.procs
                    echo `cat kmem_test/cgroup.procs` > cgroup.procs
                    rmdir kmem_test
            done
    
            cat /proc/cgroups | grep memory
    
    This patchset aims to make those kmem pages to drop the reference to
    memory cgroup by using the APIs of obj_cgroup.  Finally, we can see that
    the number of the dying cgroups will not increase if we run the above test
    script.
    
    This patch (of 7):
    
    The rcu_read_lock/unlock only can guarantee that the memcg will not be
    freed, but it cannot guarantee the success of css_get (which is in the
    refill_stock when cached memcg changed) to memcg.
    
      rcu_read_lock()
      memcg = obj_cgroup_memcg(old)
      __memcg_kmem_uncharge(memcg)
          refill_stock(memcg)
              if (stock->cached != memcg)
                  // css_get can change the ref counter from 0 back to 1.
                  css_get(&memcg->css)
      rcu_read_unlock()
    
    This fix is very like the commit:
    
      eefbfa7fd678 ("mm: memcg/slab: fix use after free in obj_cgroup_charge")
    
    Fix this by holding a reference to the memcg which is passed to the
    __memcg_kmem_uncharge() before calling __memcg_kmem_uncharge().
    
    Link: https://lkml.kernel.org/r/20210319163821.20704-1-songmuchun@bytedance.com
    Link: https://lkml.kernel.org/r/20210319163821.20704-2-songmuchun@bytedance.com
    Fixes: 3de7d4f25a74 ("mm: memcg/slab: optimize objcg stock draining")
    Signed-off-by: Muchun Song <songmuchun@bytedance.com>
    Reviewed-by: Shakeel Butt <shakeelb@google.com>
    Acked-by: Roman Gushchin <guro@fb.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: Xiongchun Duan <duanxiongchun@bytedance.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit d558fcdb17139728347bccc60a16af3e639649d2
Author: Ali Saidi <alisaidi@amazon.com>
Date:   Thu Apr 15 17:27:11 2021 +0000

    locking/qrwlock: Fix ordering in queued_write_lock_slowpath()
    
    [ Upstream commit 84a24bf8c52e66b7ac89ada5e3cfbe72d65c1896 ]
    
    While this code is executed with the wait_lock held, a reader can
    acquire the lock without holding wait_lock.  The writer side loops
    checking the value with the atomic_cond_read_acquire(), but only truly
    acquires the lock when the compare-and-exchange is completed
    successfully which isnt ordered. This exposes the window between the
    acquire and the cmpxchg to an A-B-A problem which allows reads
    following the lock acquisition to observe values speculatively before
    the write lock is truly acquired.
    
    We've seen a problem in epoll where the reader does a xchg while
    holding the read lock, but the writer can see a value change out from
    under it.
    
      Writer                                | Reader
      --------------------------------------------------------------------------------
      ep_scan_ready_list()                  |
      |- write_lock_irq()                   |
          |- queued_write_lock_slowpath()   |
            |- atomic_cond_read_acquire()   |
                                            | read_lock_irqsave(&ep->lock, flags);
         --> (observes value before unlock) |  chain_epi_lockless()
         |                                  |    epi->next = xchg(&ep->ovflist, epi);
         |                                  | read_unlock_irqrestore(&ep->lock, flags);
         |                                  |
         |     atomic_cmpxchg_relaxed()     |
         |-- READ_ONCE(ep->ovflist);        |
    
    A core can order the read of the ovflist ahead of the
    atomic_cmpxchg_relaxed(). Switching the cmpxchg to use acquire
    semantics addresses this issue at which point the atomic_cond_read can
    be switched to use relaxed semantics.
    
    Fixes: b519b56e378ee ("locking/qrwlock: Use atomic_cond_read_acquire() when spinning in qrwlock")
    Signed-off-by: Ali Saidi <alisaidi@amazon.com>
    [peterz: use try_cmpxchg()]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Acked-by: Will Deacon <will@kernel.org>
    Acked-by: Waiman Long <longman@redhat.com>
    Tested-by: Steve Capper <steve.capper@arm.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 82fa9ced35d88581cffa4a1c856fc41fca96d80a
Author: Ali Saidi <alisaidi@amazon.com>
Date:   Thu Apr 15 17:27:11 2021 +0000

    locking/qrwlock: Fix ordering in queued_write_lock_slowpath()
    
    [ Upstream commit 84a24bf8c52e66b7ac89ada5e3cfbe72d65c1896 ]
    
    While this code is executed with the wait_lock held, a reader can
    acquire the lock without holding wait_lock.  The writer side loops
    checking the value with the atomic_cond_read_acquire(), but only truly
    acquires the lock when the compare-and-exchange is completed
    successfully which isnt ordered. This exposes the window between the
    acquire and the cmpxchg to an A-B-A problem which allows reads
    following the lock acquisition to observe values speculatively before
    the write lock is truly acquired.
    
    We've seen a problem in epoll where the reader does a xchg while
    holding the read lock, but the writer can see a value change out from
    under it.
    
      Writer                                | Reader
      --------------------------------------------------------------------------------
      ep_scan_ready_list()                  |
      |- write_lock_irq()                   |
          |- queued_write_lock_slowpath()   |
            |- atomic_cond_read_acquire()   |
                                            | read_lock_irqsave(&ep->lock, flags);
         --> (observes value before unlock) |  chain_epi_lockless()
         |                                  |    epi->next = xchg(&ep->ovflist, epi);
         |                                  | read_unlock_irqrestore(&ep->lock, flags);
         |                                  |
         |     atomic_cmpxchg_relaxed()     |
         |-- READ_ONCE(ep->ovflist);        |
    
    A core can order the read of the ovflist ahead of the
    atomic_cmpxchg_relaxed(). Switching the cmpxchg to use acquire
    semantics addresses this issue at which point the atomic_cond_read can
    be switched to use relaxed semantics.
    
    Fixes: b519b56e378ee ("locking/qrwlock: Use atomic_cond_read_acquire() when spinning in qrwlock")
    Signed-off-by: Ali Saidi <alisaidi@amazon.com>
    [peterz: use try_cmpxchg()]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Acked-by: Will Deacon <will@kernel.org>
    Acked-by: Waiman Long <longman@redhat.com>
    Tested-by: Steve Capper <steve.capper@arm.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 82808cc026811fbc3ecf0c0b267a12a339eead56
Author: Ali Saidi <alisaidi@amazon.com>
Date:   Thu Apr 15 17:27:11 2021 +0000

    locking/qrwlock: Fix ordering in queued_write_lock_slowpath()
    
    [ Upstream commit 84a24bf8c52e66b7ac89ada5e3cfbe72d65c1896 ]
    
    While this code is executed with the wait_lock held, a reader can
    acquire the lock without holding wait_lock.  The writer side loops
    checking the value with the atomic_cond_read_acquire(), but only truly
    acquires the lock when the compare-and-exchange is completed
    successfully which isnt ordered. This exposes the window between the
    acquire and the cmpxchg to an A-B-A problem which allows reads
    following the lock acquisition to observe values speculatively before
    the write lock is truly acquired.
    
    We've seen a problem in epoll where the reader does a xchg while
    holding the read lock, but the writer can see a value change out from
    under it.
    
      Writer                                | Reader
      --------------------------------------------------------------------------------
      ep_scan_ready_list()                  |
      |- write_lock_irq()                   |
          |- queued_write_lock_slowpath()   |
            |- atomic_cond_read_acquire()   |
                                            | read_lock_irqsave(&ep->lock, flags);
         --> (observes value before unlock) |  chain_epi_lockless()
         |                                  |    epi->next = xchg(&ep->ovflist, epi);
         |                                  | read_unlock_irqrestore(&ep->lock, flags);
         |                                  |
         |     atomic_cmpxchg_relaxed()     |
         |-- READ_ONCE(ep->ovflist);        |
    
    A core can order the read of the ovflist ahead of the
    atomic_cmpxchg_relaxed(). Switching the cmpxchg to use acquire
    semantics addresses this issue at which point the atomic_cond_read can
    be switched to use relaxed semantics.
    
    Fixes: b519b56e378ee ("locking/qrwlock: Use atomic_cond_read_acquire() when spinning in qrwlock")
    Signed-off-by: Ali Saidi <alisaidi@amazon.com>
    [peterz: use try_cmpxchg()]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Acked-by: Will Deacon <will@kernel.org>
    Acked-by: Waiman Long <longman@redhat.com>
    Tested-by: Steve Capper <steve.capper@arm.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5902f9453a313be8fe78cbd7e7ca9dba9319fc6e
Author: Ali Saidi <alisaidi@amazon.com>
Date:   Thu Apr 15 17:27:11 2021 +0000

    locking/qrwlock: Fix ordering in queued_write_lock_slowpath()
    
    [ Upstream commit 84a24bf8c52e66b7ac89ada5e3cfbe72d65c1896 ]
    
    While this code is executed with the wait_lock held, a reader can
    acquire the lock without holding wait_lock.  The writer side loops
    checking the value with the atomic_cond_read_acquire(), but only truly
    acquires the lock when the compare-and-exchange is completed
    successfully which isnt ordered. This exposes the window between the
    acquire and the cmpxchg to an A-B-A problem which allows reads
    following the lock acquisition to observe values speculatively before
    the write lock is truly acquired.
    
    We've seen a problem in epoll where the reader does a xchg while
    holding the read lock, but the writer can see a value change out from
    under it.
    
      Writer                                | Reader
      --------------------------------------------------------------------------------
      ep_scan_ready_list()                  |
      |- write_lock_irq()                   |
          |- queued_write_lock_slowpath()   |
            |- atomic_cond_read_acquire()   |
                                            | read_lock_irqsave(&ep->lock, flags);
         --> (observes value before unlock) |  chain_epi_lockless()
         |                                  |    epi->next = xchg(&ep->ovflist, epi);
         |                                  | read_unlock_irqrestore(&ep->lock, flags);
         |                                  |
         |     atomic_cmpxchg_relaxed()     |
         |-- READ_ONCE(ep->ovflist);        |
    
    A core can order the read of the ovflist ahead of the
    atomic_cmpxchg_relaxed(). Switching the cmpxchg to use acquire
    semantics addresses this issue at which point the atomic_cond_read can
    be switched to use relaxed semantics.
    
    Fixes: b519b56e378ee ("locking/qrwlock: Use atomic_cond_read_acquire() when spinning in qrwlock")
    Signed-off-by: Ali Saidi <alisaidi@amazon.com>
    [peterz: use try_cmpxchg()]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Acked-by: Will Deacon <will@kernel.org>
    Acked-by: Waiman Long <longman@redhat.com>
    Tested-by: Steve Capper <steve.capper@arm.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 84a24bf8c52e66b7ac89ada5e3cfbe72d65c1896
Author: Ali Saidi <alisaidi@amazon.com>
Date:   Thu Apr 15 17:27:11 2021 +0000

    locking/qrwlock: Fix ordering in queued_write_lock_slowpath()
    
    While this code is executed with the wait_lock held, a reader can
    acquire the lock without holding wait_lock.  The writer side loops
    checking the value with the atomic_cond_read_acquire(), but only truly
    acquires the lock when the compare-and-exchange is completed
    successfully which isnt ordered. This exposes the window between the
    acquire and the cmpxchg to an A-B-A problem which allows reads
    following the lock acquisition to observe values speculatively before
    the write lock is truly acquired.
    
    We've seen a problem in epoll where the reader does a xchg while
    holding the read lock, but the writer can see a value change out from
    under it.
    
      Writer                                | Reader
      --------------------------------------------------------------------------------
      ep_scan_ready_list()                  |
      |- write_lock_irq()                   |
          |- queued_write_lock_slowpath()   |
            |- atomic_cond_read_acquire()   |
                                            | read_lock_irqsave(&ep->lock, flags);
         --> (observes value before unlock) |  chain_epi_lockless()
         |                                  |    epi->next = xchg(&ep->ovflist, epi);
         |                                  | read_unlock_irqrestore(&ep->lock, flags);
         |                                  |
         |     atomic_cmpxchg_relaxed()     |
         |-- READ_ONCE(ep->ovflist);        |
    
    A core can order the read of the ovflist ahead of the
    atomic_cmpxchg_relaxed(). Switching the cmpxchg to use acquire
    semantics addresses this issue at which point the atomic_cond_read can
    be switched to use relaxed semantics.
    
    Fixes: b519b56e378ee ("locking/qrwlock: Use atomic_cond_read_acquire() when spinning in qrwlock")
    Signed-off-by: Ali Saidi <alisaidi@amazon.com>
    [peterz: use try_cmpxchg()]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Steve Capper <steve.capper@arm.com>
    Acked-by: Will Deacon <will@kernel.org>
    Acked-by: Waiman Long <longman@redhat.com>
    Tested-by: Steve Capper <steve.capper@arm.com>

commit aa8caa767e319bad34a82bfce7da1ed2b9c0ed6f
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Fri Apr 16 14:16:06 2021 +0000

    mld: fix suspicious RCU usage in __ipv6_dev_mc_dec()
    
    __ipv6_dev_mc_dec() internally uses sleepable functions so that caller
    must not acquire atomic locks. But caller, which is addrconf_verify_rtnl()
    acquires rcu_read_lock_bh().
    So this warning occurs in the __ipv6_dev_mc_dec().
    
    Test commands:
        ip netns add A
        ip link add veth0 type veth peer name veth1
        ip link set veth1 netns A
        ip link set veth0 up
        ip netns exec A ip link set veth1 up
        ip a a 2001:db8::1/64 dev veth0 valid_lft 2 preferred_lft 1
    
    Splat looks like:
    ============================
    WARNING: suspicious RCU usage
    5.12.0-rc6+ #515 Not tainted
    -----------------------------
    kernel/sched/core.c:8294 Illegal context switch in RCU-bh read-side
    critical section!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    4 locks held by kworker/4:0/1997:
     #0: ffff88810bd72d48 ((wq_completion)ipv6_addrconf){+.+.}-{0:0}, at:
    process_one_work+0x761/0x1440
     #1: ffff888105c8fe00 ((addr_chk_work).work){+.+.}-{0:0}, at:
    process_one_work+0x795/0x1440
     #2: ffffffffb9279fb0 (rtnl_mutex){+.+.}-{3:3}, at:
    addrconf_verify_work+0xa/0x20
     #3: ffffffffb8e30860 (rcu_read_lock_bh){....}-{1:2}, at:
    addrconf_verify_rtnl+0x23/0xc60
    
    stack backtrace:
    CPU: 4 PID: 1997 Comm: kworker/4:0 Not tainted 5.12.0-rc6+ #515
    Workqueue: ipv6_addrconf addrconf_verify_work
    Call Trace:
     dump_stack+0xa4/0xe5
     ___might_sleep+0x27d/0x2b0
     __mutex_lock+0xc8/0x13f0
     ? lock_downgrade+0x690/0x690
     ? __ipv6_dev_mc_dec+0x49/0x2a0
     ? mark_held_locks+0xb7/0x120
     ? mutex_lock_io_nested+0x1270/0x1270
     ? lockdep_hardirqs_on_prepare+0x12c/0x3e0
     ? _raw_spin_unlock_irqrestore+0x47/0x50
     ? trace_hardirqs_on+0x41/0x120
     ? __wake_up_common_lock+0xc9/0x100
     ? __wake_up_common+0x620/0x620
     ? memset+0x1f/0x40
     ? netlink_broadcast_filtered+0x2c4/0xa70
     ? __ipv6_dev_mc_dec+0x49/0x2a0
     __ipv6_dev_mc_dec+0x49/0x2a0
     ? netlink_broadcast_filtered+0x2f6/0xa70
     addrconf_leave_solict.part.64+0xad/0xf0
     ? addrconf_join_solict.part.63+0xf0/0xf0
     ? nlmsg_notify+0x63/0x1b0
     __ipv6_ifa_notify+0x22c/0x9c0
     ? inet6_fill_ifaddr+0xbe0/0xbe0
     ? lockdep_hardirqs_on_prepare+0x12c/0x3e0
     ? __local_bh_enable_ip+0xa5/0xf0
     ? ipv6_del_addr+0x347/0x870
     ipv6_del_addr+0x3b1/0x870
     ? addrconf_ifdown+0xfe0/0xfe0
     ? rcu_read_lock_any_held.part.27+0x20/0x20
     addrconf_verify_rtnl+0x8a9/0xc60
     addrconf_verify_work+0xf/0x20
     process_one_work+0x84c/0x1440
    
    In order to avoid this problem, it uses rcu_read_unlock_bh() for
    a short time. RCU is used for avoiding freeing
    ifp(struct *inet6_ifaddr) while ifp is being used. But this will
    not be released even if rcu_read_unlock_bh() is used.
    Because before rcu_read_unlock_bh(), it uses in6_ifa_hold(ifp).
    So this is safe.
    
    Fixes: 63ed8de4be81 ("mld: add mc_lock for protecting per-interface mld data")
    Suggested-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f415b3c981dee376dd3745208c7c93d1201039cc
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Apr 1 15:00:19 2021 -0700

    bpf, sockmap: Fix sk->prot unhash op reset
    
    commit 1c84b33101c82683dee8b06761ca1f69e78c8ee7 upstream.
    
    In '4da6a196f93b1' we fixed a potential unhash loop caused when
    a TLS socket in a sockmap was removed from the sockmap. This
    happened because the unhash operation on the TLS ctx continued
    to point at the sockmap implementation of unhash even though the
    psock has already been removed. The sockmap unhash handler when a
    psock is removed does the following,
    
     void sock_map_unhash(struct sock *sk)
     {
            void (*saved_unhash)(struct sock *sk);
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (unlikely(!psock)) {
                    rcu_read_unlock();
                    if (sk->sk_prot->unhash)
                            sk->sk_prot->unhash(sk);
                    return;
            }
            [...]
     }
    
    The unlikely() case is there to handle the case where psock is detached
    but the proto ops have not been updated yet. But, in the above case
    with TLS and removed psock we never fixed sk_prot->unhash() and unhash()
    points back to sock_map_unhash resulting in a loop. To fix this we added
    this bit of code,
    
     static inline void sk_psock_restore_proto(struct sock *sk,
                                              struct sk_psock *psock)
     {
           sk->sk_prot->unhash = psock->saved_unhash;
    
    This will set the sk_prot->unhash back to its saved value. This is the
    correct callback for a TLS socket that has been removed from the sock_map.
    Unfortunately, this also overwrites the unhash pointer for all psocks.
    We effectively break sockmap unhash handling for any future socks.
    Omitting the unhash operation will leave stale entries in the map if
    a socket transition through unhash, but does not do close() op.
    
    To fix set unhash correctly before calling into tls_update. This way the
    TLS enabled socket will point to the saved unhash() handler.
    
    Fixes: 4da6a196f93b1 ("bpf: Sockmap/tls, during free we may call tcp_bpf_unhash() in loop")
    Reported-by: Cong Wang <xiyou.wangcong@gmail.com>
    Reported-by: Lorenz Bauer <lmb@cloudflare.com>
    Suggested-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/161731441904.68884.15593917809745631972.stgit@john-XPS-13-9370
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 00c01de1a994ed0689c7cb30049fdb5dbde348e2
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Apr 1 15:00:19 2021 -0700

    bpf, sockmap: Fix sk->prot unhash op reset
    
    commit 1c84b33101c82683dee8b06761ca1f69e78c8ee7 upstream.
    
    In '4da6a196f93b1' we fixed a potential unhash loop caused when
    a TLS socket in a sockmap was removed from the sockmap. This
    happened because the unhash operation on the TLS ctx continued
    to point at the sockmap implementation of unhash even though the
    psock has already been removed. The sockmap unhash handler when a
    psock is removed does the following,
    
     void sock_map_unhash(struct sock *sk)
     {
            void (*saved_unhash)(struct sock *sk);
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (unlikely(!psock)) {
                    rcu_read_unlock();
                    if (sk->sk_prot->unhash)
                            sk->sk_prot->unhash(sk);
                    return;
            }
            [...]
     }
    
    The unlikely() case is there to handle the case where psock is detached
    but the proto ops have not been updated yet. But, in the above case
    with TLS and removed psock we never fixed sk_prot->unhash() and unhash()
    points back to sock_map_unhash resulting in a loop. To fix this we added
    this bit of code,
    
     static inline void sk_psock_restore_proto(struct sock *sk,
                                              struct sk_psock *psock)
     {
           sk->sk_prot->unhash = psock->saved_unhash;
    
    This will set the sk_prot->unhash back to its saved value. This is the
    correct callback for a TLS socket that has been removed from the sock_map.
    Unfortunately, this also overwrites the unhash pointer for all psocks.
    We effectively break sockmap unhash handling for any future socks.
    Omitting the unhash operation will leave stale entries in the map if
    a socket transition through unhash, but does not do close() op.
    
    To fix set unhash correctly before calling into tls_update. This way the
    TLS enabled socket will point to the saved unhash() handler.
    
    Fixes: 4da6a196f93b1 ("bpf: Sockmap/tls, during free we may call tcp_bpf_unhash() in loop")
    Reported-by: Cong Wang <xiyou.wangcong@gmail.com>
    Reported-by: Lorenz Bauer <lmb@cloudflare.com>
    Suggested-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/161731441904.68884.15593917809745631972.stgit@john-XPS-13-9370
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 158a9b815c54ccb7900b81e7fc09db46bab298c6
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Apr 1 15:00:19 2021 -0700

    bpf, sockmap: Fix sk->prot unhash op reset
    
    commit 1c84b33101c82683dee8b06761ca1f69e78c8ee7 upstream.
    
    In '4da6a196f93b1' we fixed a potential unhash loop caused when
    a TLS socket in a sockmap was removed from the sockmap. This
    happened because the unhash operation on the TLS ctx continued
    to point at the sockmap implementation of unhash even though the
    psock has already been removed. The sockmap unhash handler when a
    psock is removed does the following,
    
     void sock_map_unhash(struct sock *sk)
     {
            void (*saved_unhash)(struct sock *sk);
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (unlikely(!psock)) {
                    rcu_read_unlock();
                    if (sk->sk_prot->unhash)
                            sk->sk_prot->unhash(sk);
                    return;
            }
            [...]
     }
    
    The unlikely() case is there to handle the case where psock is detached
    but the proto ops have not been updated yet. But, in the above case
    with TLS and removed psock we never fixed sk_prot->unhash() and unhash()
    points back to sock_map_unhash resulting in a loop. To fix this we added
    this bit of code,
    
     static inline void sk_psock_restore_proto(struct sock *sk,
                                              struct sk_psock *psock)
     {
           sk->sk_prot->unhash = psock->saved_unhash;
    
    This will set the sk_prot->unhash back to its saved value. This is the
    correct callback for a TLS socket that has been removed from the sock_map.
    Unfortunately, this also overwrites the unhash pointer for all psocks.
    We effectively break sockmap unhash handling for any future socks.
    Omitting the unhash operation will leave stale entries in the map if
    a socket transition through unhash, but does not do close() op.
    
    To fix set unhash correctly before calling into tls_update. This way the
    TLS enabled socket will point to the saved unhash() handler.
    
    Fixes: 4da6a196f93b1 ("bpf: Sockmap/tls, during free we may call tcp_bpf_unhash() in loop")
    Reported-by: Cong Wang <xiyou.wangcong@gmail.com>
    Reported-by: Lorenz Bauer <lmb@cloudflare.com>
    Suggested-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/161731441904.68884.15593917809745631972.stgit@john-XPS-13-9370
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f829b4b212a315b912cb23fd10aaf30534bb5ce9
Author: Liam Howlett <liam.howlett@oracle.com>
Date:   Wed Apr 7 20:00:45 2021 +0000

    m68k: Add missing mmap_read_lock() to sys_cacheflush()
    
    When the superuser flushes the entire cache, the mmap_read_lock() is not
    taken, but mmap_read_unlock() is called.  Add the missing
    mmap_read_lock() call.
    
    Fixes: cd2567b6850b1648 ("m68k: call find_vma with the mmap_sem held in sys_cacheflush()")
    Signed-off-by: Liam R. Howlett <Liam.Howlett@Oracle.com>
    Reviewed-by: Matthew Wilcox (Oracle) <willy@infradead.org>
    Link: https://lore.kernel.org/r/20210407200032.764445-1-Liam.Howlett@Oracle.com
    Signed-off-by: Geert Uytterhoeven <geert@linux-m68k.org>

commit 1c84b33101c82683dee8b06761ca1f69e78c8ee7
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Apr 1 15:00:19 2021 -0700

    bpf, sockmap: Fix sk->prot unhash op reset
    
    In '4da6a196f93b1' we fixed a potential unhash loop caused when
    a TLS socket in a sockmap was removed from the sockmap. This
    happened because the unhash operation on the TLS ctx continued
    to point at the sockmap implementation of unhash even though the
    psock has already been removed. The sockmap unhash handler when a
    psock is removed does the following,
    
     void sock_map_unhash(struct sock *sk)
     {
            void (*saved_unhash)(struct sock *sk);
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (unlikely(!psock)) {
                    rcu_read_unlock();
                    if (sk->sk_prot->unhash)
                            sk->sk_prot->unhash(sk);
                    return;
            }
            [...]
     }
    
    The unlikely() case is there to handle the case where psock is detached
    but the proto ops have not been updated yet. But, in the above case
    with TLS and removed psock we never fixed sk_prot->unhash() and unhash()
    points back to sock_map_unhash resulting in a loop. To fix this we added
    this bit of code,
    
     static inline void sk_psock_restore_proto(struct sock *sk,
                                              struct sk_psock *psock)
     {
           sk->sk_prot->unhash = psock->saved_unhash;
    
    This will set the sk_prot->unhash back to its saved value. This is the
    correct callback for a TLS socket that has been removed from the sock_map.
    Unfortunately, this also overwrites the unhash pointer for all psocks.
    We effectively break sockmap unhash handling for any future socks.
    Omitting the unhash operation will leave stale entries in the map if
    a socket transition through unhash, but does not do close() op.
    
    To fix set unhash correctly before calling into tls_update. This way the
    TLS enabled socket will point to the saved unhash() handler.
    
    Fixes: 4da6a196f93b1 ("bpf: Sockmap/tls, during free we may call tcp_bpf_unhash() in loop")
    Reported-by: Cong Wang <xiyou.wangcong@gmail.com>
    Reported-by: Lorenz Bauer <lmb@cloudflare.com>
    Suggested-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Link: https://lore.kernel.org/bpf/161731441904.68884.15593917809745631972.stgit@john-XPS-13-9370

commit b5332a9f3f3d884a1b646ce155e664cc558c1722
Author: Sagi Grimberg <sagi@grimberg.me>
Date:   Sun Mar 21 00:08:49 2021 -0700

    nvmet-tcp: fix incorrect locking in state_change sk callback
    
    We are not changing anything in the TCP connection state so
    we should not take a write_lock but rather a read lock.
    
    This caused a deadlock when running nvmet-tcp and nvme-tcp
    on the same system, where state_change callbacks on the
    host and on the controller side have causal relationship
    and made lockdep report on this with blktests:
    
    ================================
    WARNING: inconsistent lock state
    5.12.0-rc3 #1 Tainted: G          I
    --------------------------------
    inconsistent {IN-SOFTIRQ-W} -> {SOFTIRQ-ON-R} usage.
    nvme/1324 [HC0[0]:SC0[0]:HE1:SE1] takes:
    ffff888363151000 (clock-AF_INET){++-?}-{2:2}, at: nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
    {IN-SOFTIRQ-W} state was registered at:
      __lock_acquire+0x79b/0x18d0
      lock_acquire+0x1ca/0x480
      _raw_write_lock_bh+0x39/0x80
      nvmet_tcp_state_change+0x21/0x170 [nvmet_tcp]
      tcp_fin+0x2a8/0x780
      tcp_data_queue+0xf94/0x1f20
      tcp_rcv_established+0x6ba/0x1f00
      tcp_v4_do_rcv+0x502/0x760
      tcp_v4_rcv+0x257e/0x3430
      ip_protocol_deliver_rcu+0x69/0x6a0
      ip_local_deliver_finish+0x1e2/0x2f0
      ip_local_deliver+0x1a2/0x420
      ip_rcv+0x4fb/0x6b0
      __netif_receive_skb_one_core+0x162/0x1b0
      process_backlog+0x1ff/0x770
      __napi_poll.constprop.0+0xa9/0x5c0
      net_rx_action+0x7b3/0xb30
      __do_softirq+0x1f0/0x940
      do_softirq+0xa1/0xd0
      __local_bh_enable_ip+0xd8/0x100
      ip_finish_output2+0x6b7/0x18a0
      __ip_queue_xmit+0x706/0x1aa0
      __tcp_transmit_skb+0x2068/0x2e20
      tcp_write_xmit+0xc9e/0x2bb0
      __tcp_push_pending_frames+0x92/0x310
      inet_shutdown+0x158/0x300
      __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
      nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
      nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
      nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
      nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
      kernfs_fop_write_iter+0x2c7/0x460
      new_sync_write+0x36c/0x610
      vfs_write+0x5c0/0x870
      ksys_write+0xf9/0x1d0
      do_syscall_64+0x33/0x40
      entry_SYSCALL_64_after_hwframe+0x44/0xae
    irq event stamp: 10687
    hardirqs last  enabled at (10687): [<ffffffff9ec376bd>] _raw_spin_unlock_irqrestore+0x2d/0x40
    hardirqs last disabled at (10686): [<ffffffff9ec374d8>] _raw_spin_lock_irqsave+0x68/0x90
    softirqs last  enabled at (10684): [<ffffffff9f000608>] __do_softirq+0x608/0x940
    softirqs last disabled at (10649): [<ffffffff9cdedd31>] do_softirq+0xa1/0xd0
    
    other info that might help us debug this:
     Possible unsafe locking scenario:
    
           CPU0
           ----
      lock(clock-AF_INET);
      <Interrupt>
        lock(clock-AF_INET);
    
     *** DEADLOCK ***
    
    5 locks held by nvme/1324:
     #0: ffff8884a01fe470 (sb_writers#4){.+.+}-{0:0}, at: ksys_write+0xf9/0x1d0
     #1: ffff8886e435c090 (&of->mutex){+.+.}-{3:3}, at: kernfs_fop_write_iter+0x216/0x460
     #2: ffff888104d90c38 (kn->active#255){++++}-{0:0}, at: kernfs_remove_self+0x22d/0x330
     #3: ffff8884634538d0 (&queue->queue_lock){+.+.}-{3:3}, at: nvme_tcp_stop_queue+0x52/0xb0 [nvme_tcp]
     #4: ffff888363150d30 (sk_lock-AF_INET){+.+.}-{0:0}, at: inet_shutdown+0x59/0x300
    
    stack backtrace:
    CPU: 26 PID: 1324 Comm: nvme Tainted: G          I       5.12.0-rc3 #1
    Hardware name: Dell Inc. PowerEdge R640/06NR82, BIOS 2.10.0 11/12/2020
    Call Trace:
     dump_stack+0x93/0xc2
     mark_lock_irq.cold+0x2c/0xb3
     ? verify_lock_unused+0x390/0x390
     ? stack_trace_consume_entry+0x160/0x160
     ? lock_downgrade+0x100/0x100
     ? save_trace+0x88/0x5e0
     ? _raw_spin_unlock_irqrestore+0x2d/0x40
     mark_lock+0x530/0x1470
     ? mark_lock_irq+0x1d10/0x1d10
     ? enqueue_timer+0x660/0x660
     mark_usage+0x215/0x2a0
     __lock_acquire+0x79b/0x18d0
     ? tcp_schedule_loss_probe.part.0+0x38c/0x520
     lock_acquire+0x1ca/0x480
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? rcu_read_unlock+0x40/0x40
     ? tcp_mtu_probe+0x1ae0/0x1ae0
     ? kmalloc_reserve+0xa0/0xa0
     ? sysfs_file_ops+0x170/0x170
     _raw_read_lock+0x3d/0xa0
     ? nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     nvme_tcp_state_change+0x21/0x150 [nvme_tcp]
     ? sysfs_file_ops+0x170/0x170
     inet_shutdown+0x189/0x300
     __nvme_tcp_stop_queue+0x36/0x270 [nvme_tcp]
     nvme_tcp_stop_queue+0x87/0xb0 [nvme_tcp]
     nvme_tcp_teardown_admin_queue+0x69/0xe0 [nvme_tcp]
     nvme_do_delete_ctrl+0x100/0x10c [nvme_core]
     nvme_sysfs_delete.cold+0x8/0xd [nvme_core]
     kernfs_fop_write_iter+0x2c7/0x460
     new_sync_write+0x36c/0x610
     ? new_sync_read+0x600/0x600
     ? lock_acquire+0x1ca/0x480
     ? rcu_read_unlock+0x40/0x40
     ? lock_is_held_type+0x9a/0x110
     vfs_write+0x5c0/0x870
     ksys_write+0xf9/0x1d0
     ? __ia32_sys_read+0xa0/0xa0
     ? lockdep_hardirqs_on_prepare.part.0+0x198/0x340
     ? syscall_enter_from_user_mode+0x27/0x70
     do_syscall_64+0x33/0x40
     entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    Fixes: 872d26a391da ("nvmet-tcp: add NVMe over TCP target driver")
    Reported-by: Yi Zhang <yi.zhang@redhat.com>
    Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
    Signed-off-by: Christoph Hellwig <hch@lst.de>

commit 32bc7a2cca4d748e434702378ec1c728a2387e04
Merge: 6e2751433490 63ed8de4be81
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Mar 26 15:14:57 2021 -0700

    Merge branch 'mld-sleepable'
    
    Taehee Yoo says:
    
    ====================
    mld: change context from atomic to sleepable
    
    This patchset changes the context of MLD module.
    Before this patchset, MLD functions are atomic context so it couldn't use
    sleepable functions and flags.
    
    There are several reasons why MLD functions are under atomic context.
    1. It uses timer API.
    Timer expiration functions are executed in the atomic context.
    2. atomic locks
    MLD functions use rwlock and spinlock to protect their own resources.
    
    So, in order to switch context, this patchset converts resources to use
    RCU and removes atomic locks and timer API.
    
    1. The first patch convert from the timer API to delayed work.
    Timer API is used for delaying some works.
    MLD protocol has a delay mechanism, which is used for replying to a query.
    If a listener receives a query from a router, it should send a response
    after some delay. But because of timer expire function is executed in
    the atomic context, this patch convert from timer API to the delayed work.
    
    2. The fourth patch deletes inet6_dev->mc_lock.
    The mc_lock has protected inet6_dev->mc_tomb pointer.
    But this pointer is already protected by RTNL and it isn't be used by
    datapath. So, it isn't be needed and because of this, many atomic context
    critical sections are deleted.
    
    3. The fifth patch convert ip6_sf_socklist to RCU.
    ip6_sf_socklist has been protected by ipv6_mc_socklist->sflock(rwlock).
    But this is already protected by RTNL So if it is converted to use RCU
    in order to be used in the datapath, the sflock is no more needed.
    So, its control path context can be switched to sleepable.
    
    4. The sixth patch convert ip6_sf_list to RCU.
    The reason for this patch is the same as the previous patch.
    
    5. The seventh patch convert ifmcaddr6 to RCU.
    The reason for this patch is the same as the previous patch.
    
    6. Add new workqueues for processing query/report event.
    By this patch, query and report events are processed by workqueue
    So context is sleepable, not atomic.
    While this logic, it acquires RTNL.
    
    7. Add new mc_lock.
    The purpose of this lock is to protect per-interface mld data.
    Per-interface mld data is usually used by query/report event handler.
    So, query/report event workers need only this lock instead of RTNL.
    Therefore, it could reduce bottleneck.
    
    Changelog:
    v2 -> v3:
    1. Do not use msecs_to_jiffies().
    (by Cong Wang)
    2. Do not add unnecessary rtnl_lock() and rtnl_unlock().
    (by Cong Wang)
    3. Fix sparse warnings because of rcu annotation.
    (by kernel test robot)
       - Remove some rcu_assign_pointer(), which was used for non-rcu pointer.
       - Add union for rcu pointer.
       - Use rcu API in mld_clear_zeros().
       - Remove remained rcu_read_unlock().
       - Use rcu API for tomb resources.
    4. withdraw prevopus 2nd and 3rd patch.
       - "separate two flags from ifmcaddr6->mca_flags"
       - "add a new delayed_work, mc_delrec_work"
    5. Add 6th and 7th patch.
    
    v1 -> v2:
    1. Withdraw unnecessary refactoring patches.
    (by Cong Wang, Eric Dumazet, David Ahern)
        a) convert from array to list.
        b) function rename.
    2. Separate big one patch into small several patches.
    3. Do not rename 'ifmcaddr6->mca_lock'.
    In the v1 patch, this variable was changed to 'ifmcaddr6->mca_work_lock'.
    But this is actually not needed.
    4. Do not use atomic_t for 'ifmcaddr6->mca_sfcount' and
    'ipv6_mc_socklist'->sf_count'.
    5. Do not add mld_check_leave_group() function.
    6. Do not add ip6_mc_del_src_bulk() function.
    7. Do not add ip6_mc_add_src_bulk() function.
    8. Do not use rcu_read_lock() in the qeth_l3_add_mcast_rtnl().
    (by Julian Wiedmann)
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 7e937220afa3eada0d4611b31e4e3c60770e39b4
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Feb 26 11:25:29 2021 -0800

    rcu: Add explicit barrier() to __rcu_read_unlock()
    
    Because preemptible RCU's __rcu_read_unlock() is an external function,
    the rough equivalent of an implicit barrier() is inserted by the compiler.
    Except that there is a direct call to __rcu_read_unlock() in that same
    file, and compilers are getting to the point where they might choose to
    inline the fastpath of the __rcu_read_unlock() function.
    
    This commit therefore adds an explicit barrier() to the very beginning
    of __rcu_read_unlock().
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit e1f78ecdfd59d560c42bc04b9bfb746ef8a9dfb1
Author: Ido Schimmel <idosch@nvidia.com>
Date:   Sun Mar 14 14:19:37 2021 +0200

    mlxsw: spectrum: Remove unnecessary RCU read-side critical section
    
    Since commit 7d8e8f3433dc ("mlxsw: core: Increase scope of RCU read-side
    critical section"), all Rx handlers are called from an RCU read-side
    critical section.
    
    Remove the unnecessary rcu_read_lock() / rcu_read_unlock().
    
    Signed-off-by: Ido Schimmel <idosch@nvidia.com>
    Reviewed-by: Jiri Pirko <jiri@nvidia.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 97bc84bbd4de3c060b68aea4d546c7f21c4d6814
Author: Hoang Huu Le <hoang.h.le@dektech.com.au>
Date:   Thu Mar 11 10:33:23 2021 +0700

    tipc: clean up warnings detected by sparse
    
    This patch fixes the following warning from sparse:
    
    net/tipc/monitor.c:263:35: warning: incorrect type in assignment (different base types)
    net/tipc/monitor.c:263:35:    expected unsigned int
    net/tipc/monitor.c:263:35:    got restricted __be32 [usertype]
    [...]
    net/tipc/node.c:374:13: warning: context imbalance in 'tipc_node_read_lock' - wrong count at exit
    net/tipc/node.c:379:13: warning: context imbalance in 'tipc_node_read_unlock' - unexpected unlock
    net/tipc/node.c:384:13: warning: context imbalance in 'tipc_node_write_lock' - wrong count at exit
    net/tipc/node.c:389:13: warning: context imbalance in 'tipc_node_write_unlock_fast' - unexpected unlock
    net/tipc/node.c:404:17: warning: context imbalance in 'tipc_node_write_unlock' - unexpected unlock
    [...]
    net/tipc/crypto.c:1201:9: warning: incorrect type in initializer (different address spaces)
    net/tipc/crypto.c:1201:9:    expected struct tipc_aead [noderef] __rcu *__tmp
    net/tipc/crypto.c:1201:9:    got struct tipc_aead *
    [...]
    
    Acked-by: Jon Maloy <jmaloy@redhat.com>
    Signed-off-by: Hoang Huu Le <hoang.h.le@dektech.com.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 7308e0240410d3644c9d7cc6263079a58e3effeb
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Jan 27 13:57:16 2021 -0800

    rcu: Make rcu_read_unlock_special() expedite strict grace periods
    
    In kernels built with CONFIG_RCU_STRICT_GRACE_PERIOD=y, every grace
    period is an expedited grace period.  However, rcu_read_unlock_special()
    does not treat them that way, instead allowing the deferred quiescent
    state to be reported whenever.  This commit therefore adds a check of
    this Kconfig option that causes rcu_read_unlock_special() to treat all
    grace periods as expedited for CONFIG_RCU_STRICT_GRACE_PERIOD=y kernels.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 39bbfc62cc90d33f8f5f940464d08075e0275f8a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Jan 14 10:39:31 2021 -0800

    rcu: Expedite deboost in case of deferred quiescent state
    
    Historically, a task that has been subjected to RCU priority boosting is
    deboosted at rcu_read_unlock() time.  However, with the advent of deferred
    quiescent states, if the outermost rcu_read_unlock() was invoked with
    either bottom halves, interrupts, or preemption disabled, the deboosting
    will be delayed for some time.  During this time, a low-priority process
    might be incorrectly running at a high real-time priority level.
    
    Fortunately, rcu_read_unlock_special() already provides mechanisms for
    forcing a minimal deferral of quiescent states, at least for kernels
    built with CONFIG_IRQ_WORK=y.  These mechanisms are currently used
    when expedited grace periods are pending that might be blocked by the
    current task.  This commit therefore causes those mechanisms to also be
    used in cases where the current task has been or might soon be subjected
    to RCU priority boosting.  Note that this applies to all kernels built
    with CONFIG_RCU_BOOST=y, regardless of whether or not they are also
    built with CONFIG_PREEMPT_RT=y.
    
    This approach assumes that kernels build for use with aggressive real-time
    applications are built with CONFIG_IRQ_WORK=y.  It is likely to be far
    simpler to enable CONFIG_IRQ_WORK=y than to implement a fast-deboosting
    scheme that works correctly in its absence.
    
    While in the area, alphabetize the rcu_preempt_deferred_qs_handler()
    function's local variables.
    
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Cc: Scott Wood <swood@redhat.com>
    Cc: Lai Jiangshan <jiangshanlai@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 8727884b7f80ed5b99b48141def9b3c491cffa54
Author: Ignat Korchagin <ignat@cloudflare.com>
Date:   Mon Jan 4 14:59:47 2021 +0000

    dm crypt: do not wait for backlogged crypto request completion in softirq
    
    commit 8abec36d1274bbd5ae8f36f3658b9abb3db56c31 upstream.
    
    Commit 39d42fa96ba1 ("dm crypt: add flags to optionally bypass kcryptd
    workqueues") made it possible for some code paths in dm-crypt to be
    executed in softirq context, when the underlying driver processes IO
    requests in interrupt/softirq context.
    
    When Crypto API backlogs a crypto request, dm-crypt uses
    wait_for_completion to avoid sending further requests to an already
    overloaded crypto driver. However, if the code is executing in softirq
    context, we might get the following stacktrace:
    
    [  210.235213][    C0] BUG: scheduling while atomic: fio/2602/0x00000102
    [  210.236701][    C0] Modules linked in:
    [  210.237566][    C0] CPU: 0 PID: 2602 Comm: fio Tainted: G        W         5.10.0+ #50
    [  210.239292][    C0] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.0.0 02/06/2015
    [  210.241233][    C0] Call Trace:
    [  210.241946][    C0]  <IRQ>
    [  210.242561][    C0]  dump_stack+0x7d/0xa3
    [  210.243466][    C0]  __schedule_bug.cold+0xb3/0xc2
    [  210.244539][    C0]  __schedule+0x156f/0x20d0
    [  210.245518][    C0]  ? io_schedule_timeout+0x140/0x140
    [  210.246660][    C0]  schedule+0xd0/0x270
    [  210.247541][    C0]  schedule_timeout+0x1fb/0x280
    [  210.248586][    C0]  ? usleep_range+0x150/0x150
    [  210.249624][    C0]  ? unpoison_range+0x3a/0x60
    [  210.250632][    C0]  ? ____kasan_kmalloc.constprop.0+0x82/0xa0
    [  210.251949][    C0]  ? unpoison_range+0x3a/0x60
    [  210.252958][    C0]  ? __prepare_to_swait+0xa7/0x190
    [  210.254067][    C0]  do_wait_for_common+0x2ab/0x370
    [  210.255158][    C0]  ? usleep_range+0x150/0x150
    [  210.256192][    C0]  ? bit_wait_io_timeout+0x160/0x160
    [  210.257358][    C0]  ? blk_update_request+0x757/0x1150
    [  210.258582][    C0]  ? _raw_spin_lock_irq+0x82/0xd0
    [  210.259674][    C0]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [  210.260917][    C0]  wait_for_completion+0x4c/0x90
    [  210.261971][    C0]  crypt_convert+0x19a6/0x4c00
    [  210.263033][    C0]  ? _raw_spin_lock_irqsave+0x87/0xe0
    [  210.264193][    C0]  ? kasan_set_track+0x1c/0x30
    [  210.265191][    C0]  ? crypt_iv_tcw_ctr+0x4a0/0x4a0
    [  210.266283][    C0]  ? kmem_cache_free+0x104/0x470
    [  210.267363][    C0]  ? crypt_endio+0x91/0x180
    [  210.268327][    C0]  kcryptd_crypt_read_convert+0x30e/0x420
    [  210.269565][    C0]  blk_update_request+0x757/0x1150
    [  210.270563][    C0]  blk_mq_end_request+0x4b/0x480
    [  210.271680][    C0]  blk_done_softirq+0x21d/0x340
    [  210.272775][    C0]  ? _raw_spin_lock+0x81/0xd0
    [  210.273847][    C0]  ? blk_mq_stop_hw_queue+0x30/0x30
    [  210.275031][    C0]  ? _raw_read_lock_irq+0x40/0x40
    [  210.276182][    C0]  __do_softirq+0x190/0x611
    [  210.277203][    C0]  ? handle_edge_irq+0x221/0xb60
    [  210.278340][    C0]  asm_call_irq_on_stack+0x12/0x20
    [  210.279514][    C0]  </IRQ>
    [  210.280164][    C0]  do_softirq_own_stack+0x37/0x40
    [  210.281281][    C0]  irq_exit_rcu+0x110/0x1b0
    [  210.282286][    C0]  common_interrupt+0x74/0x120
    [  210.283376][    C0]  asm_common_interrupt+0x1e/0x40
    [  210.284496][    C0] RIP: 0010:_aesni_enc1+0x65/0xb0
    
    Fix this by making crypt_convert function reentrant from the point of
    a single bio and make dm-crypt defer further bio processing to a
    workqueue, if Crypto API backlogs a request in interrupt context.
    
    Fixes: 39d42fa96ba1 ("dm crypt: add flags to optionally bypass kcryptd workqueues")
    Cc: stable@vger.kernel.org # v5.9+
    Signed-off-by: Ignat Korchagin <ignat@cloudflare.com>
    Acked-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bca585d24a1719d9314d5438b0d2804a33d9bbb6
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Tue Jan 5 14:13:52 2021 -0500

    new helper: d_find_alias_rcu()
    
    similar to d_find_alias(inode), except that
            * the caller must be holding rcu_read_lock()
            * inode must not be freed until matching rcu_read_unlock()
            * result is *NOT* pinned and can only be dereferenced until
    the matching rcu_read_unlock().
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 8abec36d1274bbd5ae8f36f3658b9abb3db56c31
Author: Ignat Korchagin <ignat@cloudflare.com>
Date:   Mon Jan 4 14:59:47 2021 +0000

    dm crypt: do not wait for backlogged crypto request completion in softirq
    
    Commit 39d42fa96ba1 ("dm crypt: add flags to optionally bypass kcryptd
    workqueues") made it possible for some code paths in dm-crypt to be
    executed in softirq context, when the underlying driver processes IO
    requests in interrupt/softirq context.
    
    When Crypto API backlogs a crypto request, dm-crypt uses
    wait_for_completion to avoid sending further requests to an already
    overloaded crypto driver. However, if the code is executing in softirq
    context, we might get the following stacktrace:
    
    [  210.235213][    C0] BUG: scheduling while atomic: fio/2602/0x00000102
    [  210.236701][    C0] Modules linked in:
    [  210.237566][    C0] CPU: 0 PID: 2602 Comm: fio Tainted: G        W         5.10.0+ #50
    [  210.239292][    C0] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 0.0.0 02/06/2015
    [  210.241233][    C0] Call Trace:
    [  210.241946][    C0]  <IRQ>
    [  210.242561][    C0]  dump_stack+0x7d/0xa3
    [  210.243466][    C0]  __schedule_bug.cold+0xb3/0xc2
    [  210.244539][    C0]  __schedule+0x156f/0x20d0
    [  210.245518][    C0]  ? io_schedule_timeout+0x140/0x140
    [  210.246660][    C0]  schedule+0xd0/0x270
    [  210.247541][    C0]  schedule_timeout+0x1fb/0x280
    [  210.248586][    C0]  ? usleep_range+0x150/0x150
    [  210.249624][    C0]  ? unpoison_range+0x3a/0x60
    [  210.250632][    C0]  ? ____kasan_kmalloc.constprop.0+0x82/0xa0
    [  210.251949][    C0]  ? unpoison_range+0x3a/0x60
    [  210.252958][    C0]  ? __prepare_to_swait+0xa7/0x190
    [  210.254067][    C0]  do_wait_for_common+0x2ab/0x370
    [  210.255158][    C0]  ? usleep_range+0x150/0x150
    [  210.256192][    C0]  ? bit_wait_io_timeout+0x160/0x160
    [  210.257358][    C0]  ? blk_update_request+0x757/0x1150
    [  210.258582][    C0]  ? _raw_spin_lock_irq+0x82/0xd0
    [  210.259674][    C0]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [  210.260917][    C0]  wait_for_completion+0x4c/0x90
    [  210.261971][    C0]  crypt_convert+0x19a6/0x4c00
    [  210.263033][    C0]  ? _raw_spin_lock_irqsave+0x87/0xe0
    [  210.264193][    C0]  ? kasan_set_track+0x1c/0x30
    [  210.265191][    C0]  ? crypt_iv_tcw_ctr+0x4a0/0x4a0
    [  210.266283][    C0]  ? kmem_cache_free+0x104/0x470
    [  210.267363][    C0]  ? crypt_endio+0x91/0x180
    [  210.268327][    C0]  kcryptd_crypt_read_convert+0x30e/0x420
    [  210.269565][    C0]  blk_update_request+0x757/0x1150
    [  210.270563][    C0]  blk_mq_end_request+0x4b/0x480
    [  210.271680][    C0]  blk_done_softirq+0x21d/0x340
    [  210.272775][    C0]  ? _raw_spin_lock+0x81/0xd0
    [  210.273847][    C0]  ? blk_mq_stop_hw_queue+0x30/0x30
    [  210.275031][    C0]  ? _raw_read_lock_irq+0x40/0x40
    [  210.276182][    C0]  __do_softirq+0x190/0x611
    [  210.277203][    C0]  ? handle_edge_irq+0x221/0xb60
    [  210.278340][    C0]  asm_call_irq_on_stack+0x12/0x20
    [  210.279514][    C0]  </IRQ>
    [  210.280164][    C0]  do_softirq_own_stack+0x37/0x40
    [  210.281281][    C0]  irq_exit_rcu+0x110/0x1b0
    [  210.282286][    C0]  common_interrupt+0x74/0x120
    [  210.283376][    C0]  asm_common_interrupt+0x1e/0x40
    [  210.284496][    C0] RIP: 0010:_aesni_enc1+0x65/0xb0
    
    Fix this by making crypt_convert function reentrant from the point of
    a single bio and make dm-crypt defer further bio processing to a
    workqueue, if Crypto API backlogs a request in interrupt context.
    
    Fixes: 39d42fa96ba1 ("dm crypt: add flags to optionally bypass kcryptd workqueues")
    Cc: stable@vger.kernel.org # v5.9+
    Signed-off-by: Ignat Korchagin <ignat@cloudflare.com>
    Acked-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>

commit 417602ef3f4a81116c1a7742eeb9183f9b2729d4
Author: Bhaumik Bhatt <bbhatt@codeaurora.org>
Date:   Thu Oct 15 11:47:51 2020 -0700

    bus: mhi: core: Remove double locking from mhi_driver_remove()
    
    [ Upstream commit 9b627c25e70816a5e1dca940444b5029065b4d60 ]
    
    There is double acquisition of the pm_lock from mhi_driver_remove()
    function. Remove the read_lock_bh/read_unlock_bh calls for pm_lock
    taken during a call to mhi_device_put() as the lock is acquired
    within the function already. This will help avoid a potential
    kernel panic.
    
    Fixes: 189ff97cca53 ("bus: mhi: core: Add support for data transfer")
    Reported-by: Shuah Khan <skhan@linuxfoundation.org>
    Signed-off-by: Bhaumik Bhatt <bbhatt@codeaurora.org>
    Reviewed-by: Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org>
    Signed-off-by: Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 878f12dbb8f514799d126544d59be4d2675caac3
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Wed Dec 9 15:42:57 2020 -0600

    exec: Don't open code get_close_on_exec
    
    Al Viro pointed out that using the phrase "close_on_exec(fd,
    rcu_dereference_raw(current->files->fdt))" instead of wrapping it in
    rcu_read_lock(), rcu_read_unlock() is a very questionable
    optimization[1].
    
    Once wrapped with rcu_read_lock()/rcu_read_unlock() that phrase
    becomes equivalent the helper function get_close_on_exec so
    simplify the code and make it more robust by simply using
    get_close_on_exec.
    
    [1] https://lkml.kernel.org/r/20201207222214.GA4115853@ZenIV.linux.org.uk
    Suggested-by: Al Viro <viro@ftp.linux.org.uk>
    Link: https://lkml.kernel.org/r/87k0tqr6zi.fsf_-_@x220.int.ebiederm.org
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

commit 0d555687edf899528a202bbd7f497e9d4727a488
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Dec 1 01:05:07 2020 -0800

    geneve: pull IP header before ECN decapsulation
    
    [ Upstream commit 4179b00c04d18ea7013f68d578d80f3c9d13150a ]
    
    IP_ECN_decapsulate() and IP6_ECN_decapsulate() assume
    IP header is already pulled.
    
    geneve does not ensure this yet.
    
    Fixing this generically in IP_ECN_decapsulate() and
    IP6_ECN_decapsulate() is not possible, since callers
    pass a pointer that might be freed by pskb_may_pull()
    
    syzbot reported :
    
    BUG: KMSAN: uninit-value in __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
    BUG: KMSAN: uninit-value in INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
    CPU: 1 PID: 8941 Comm: syz-executor.0 Not tainted 5.10.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x21c/0x280 lib/dump_stack.c:118
     kmsan_report+0xf7/0x1e0 mm/kmsan/kmsan_report.c:118
     __msan_warning+0x5f/0xa0 mm/kmsan/kmsan_instr.c:197
     __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
     INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
     geneve_rx+0x2103/0x2980 include/net/inet_ecn.h:306
     geneve_udp_encap_recv+0x105c/0x1340 drivers/net/geneve.c:377
     udp_queue_rcv_one_skb+0x193a/0x1af0 net/ipv4/udp.c:2093
     udp_queue_rcv_skb+0x282/0x1050 net/ipv4/udp.c:2167
     udp_unicast_rcv_skb net/ipv4/udp.c:2325 [inline]
     __udp4_lib_rcv+0x399d/0x5880 net/ipv4/udp.c:2394
     udp_rcv+0x5c/0x70 net/ipv4/udp.c:2564
     ip_protocol_deliver_rcu+0x572/0xc50 net/ipv4/ip_input.c:204
     ip_local_deliver_finish net/ipv4/ip_input.c:231 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_local_deliver+0x583/0x8d0 net/ipv4/ip_input.c:252
     dst_input include/net/dst.h:449 [inline]
     ip_rcv_finish net/ipv4/ip_input.c:428 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_rcv+0x5c3/0x840 net/ipv4/ip_input.c:539
     __netif_receive_skb_one_core net/core/dev.c:5315 [inline]
     __netif_receive_skb+0x1ec/0x640 net/core/dev.c:5429
     process_backlog+0x523/0xc10 net/core/dev.c:6319
     napi_poll+0x420/0x1010 net/core/dev.c:6763
     net_rx_action+0x35c/0xd40 net/core/dev.c:6833
     __do_softirq+0x1a9/0x6fa kernel/softirq.c:298
     asm_call_irq_on_stack+0xf/0x20
     </IRQ>
     __run_on_irqstack arch/x86/include/asm/irq_stack.h:26 [inline]
     run_on_irqstack_cond arch/x86/include/asm/irq_stack.h:77 [inline]
     do_softirq_own_stack+0x6e/0x90 arch/x86/kernel/irq_64.c:77
     do_softirq kernel/softirq.c:343 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:195
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:730 [inline]
     __dev_queue_xmit+0x3a9b/0x4520 net/core/dev.c:4167
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:4173
     packet_snd net/packet/af_packet.c:2992 [inline]
     packet_sendmsg+0x86f9/0x99d0 net/packet/af_packet.c:3017
     sock_sendmsg_nosec net/socket.c:651 [inline]
     sock_sendmsg net/socket.c:671 [inline]
     __sys_sendto+0x9dc/0xc80 net/socket.c:1992
     __do_sys_sendto net/socket.c:2004 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:2000
     __x64_sys_sendto+0x6e/0x90 net/socket.c:2000
     do_syscall_64+0x9f/0x140 arch/x86/entry/common.c:48
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 2d07dc79fe04 ("geneve: add initial netdev driver for GENEVE tunnels")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Link: https://lore.kernel.org/r/20201201090507.4137906-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a6cd761328726da209eb95134de7185ad350633e
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Dec 1 01:05:07 2020 -0800

    geneve: pull IP header before ECN decapsulation
    
    [ Upstream commit 4179b00c04d18ea7013f68d578d80f3c9d13150a ]
    
    IP_ECN_decapsulate() and IP6_ECN_decapsulate() assume
    IP header is already pulled.
    
    geneve does not ensure this yet.
    
    Fixing this generically in IP_ECN_decapsulate() and
    IP6_ECN_decapsulate() is not possible, since callers
    pass a pointer that might be freed by pskb_may_pull()
    
    syzbot reported :
    
    BUG: KMSAN: uninit-value in __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
    BUG: KMSAN: uninit-value in INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
    CPU: 1 PID: 8941 Comm: syz-executor.0 Not tainted 5.10.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x21c/0x280 lib/dump_stack.c:118
     kmsan_report+0xf7/0x1e0 mm/kmsan/kmsan_report.c:118
     __msan_warning+0x5f/0xa0 mm/kmsan/kmsan_instr.c:197
     __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
     INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
     geneve_rx+0x2103/0x2980 include/net/inet_ecn.h:306
     geneve_udp_encap_recv+0x105c/0x1340 drivers/net/geneve.c:377
     udp_queue_rcv_one_skb+0x193a/0x1af0 net/ipv4/udp.c:2093
     udp_queue_rcv_skb+0x282/0x1050 net/ipv4/udp.c:2167
     udp_unicast_rcv_skb net/ipv4/udp.c:2325 [inline]
     __udp4_lib_rcv+0x399d/0x5880 net/ipv4/udp.c:2394
     udp_rcv+0x5c/0x70 net/ipv4/udp.c:2564
     ip_protocol_deliver_rcu+0x572/0xc50 net/ipv4/ip_input.c:204
     ip_local_deliver_finish net/ipv4/ip_input.c:231 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_local_deliver+0x583/0x8d0 net/ipv4/ip_input.c:252
     dst_input include/net/dst.h:449 [inline]
     ip_rcv_finish net/ipv4/ip_input.c:428 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_rcv+0x5c3/0x840 net/ipv4/ip_input.c:539
     __netif_receive_skb_one_core net/core/dev.c:5315 [inline]
     __netif_receive_skb+0x1ec/0x640 net/core/dev.c:5429
     process_backlog+0x523/0xc10 net/core/dev.c:6319
     napi_poll+0x420/0x1010 net/core/dev.c:6763
     net_rx_action+0x35c/0xd40 net/core/dev.c:6833
     __do_softirq+0x1a9/0x6fa kernel/softirq.c:298
     asm_call_irq_on_stack+0xf/0x20
     </IRQ>
     __run_on_irqstack arch/x86/include/asm/irq_stack.h:26 [inline]
     run_on_irqstack_cond arch/x86/include/asm/irq_stack.h:77 [inline]
     do_softirq_own_stack+0x6e/0x90 arch/x86/kernel/irq_64.c:77
     do_softirq kernel/softirq.c:343 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:195
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:730 [inline]
     __dev_queue_xmit+0x3a9b/0x4520 net/core/dev.c:4167
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:4173
     packet_snd net/packet/af_packet.c:2992 [inline]
     packet_sendmsg+0x86f9/0x99d0 net/packet/af_packet.c:3017
     sock_sendmsg_nosec net/socket.c:651 [inline]
     sock_sendmsg net/socket.c:671 [inline]
     __sys_sendto+0x9dc/0xc80 net/socket.c:1992
     __do_sys_sendto net/socket.c:2004 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:2000
     __x64_sys_sendto+0x6e/0x90 net/socket.c:2000
     do_syscall_64+0x9f/0x140 arch/x86/entry/common.c:48
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 2d07dc79fe04 ("geneve: add initial netdev driver for GENEVE tunnels")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Link: https://lore.kernel.org/r/20201201090507.4137906-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5960c13b502f6ab21a910782226d8b9d15b49c12
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Dec 1 01:05:07 2020 -0800

    geneve: pull IP header before ECN decapsulation
    
    [ Upstream commit 4179b00c04d18ea7013f68d578d80f3c9d13150a ]
    
    IP_ECN_decapsulate() and IP6_ECN_decapsulate() assume
    IP header is already pulled.
    
    geneve does not ensure this yet.
    
    Fixing this generically in IP_ECN_decapsulate() and
    IP6_ECN_decapsulate() is not possible, since callers
    pass a pointer that might be freed by pskb_may_pull()
    
    syzbot reported :
    
    BUG: KMSAN: uninit-value in __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
    BUG: KMSAN: uninit-value in INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
    CPU: 1 PID: 8941 Comm: syz-executor.0 Not tainted 5.10.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x21c/0x280 lib/dump_stack.c:118
     kmsan_report+0xf7/0x1e0 mm/kmsan/kmsan_report.c:118
     __msan_warning+0x5f/0xa0 mm/kmsan/kmsan_instr.c:197
     __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
     INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
     geneve_rx+0x2103/0x2980 include/net/inet_ecn.h:306
     geneve_udp_encap_recv+0x105c/0x1340 drivers/net/geneve.c:377
     udp_queue_rcv_one_skb+0x193a/0x1af0 net/ipv4/udp.c:2093
     udp_queue_rcv_skb+0x282/0x1050 net/ipv4/udp.c:2167
     udp_unicast_rcv_skb net/ipv4/udp.c:2325 [inline]
     __udp4_lib_rcv+0x399d/0x5880 net/ipv4/udp.c:2394
     udp_rcv+0x5c/0x70 net/ipv4/udp.c:2564
     ip_protocol_deliver_rcu+0x572/0xc50 net/ipv4/ip_input.c:204
     ip_local_deliver_finish net/ipv4/ip_input.c:231 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_local_deliver+0x583/0x8d0 net/ipv4/ip_input.c:252
     dst_input include/net/dst.h:449 [inline]
     ip_rcv_finish net/ipv4/ip_input.c:428 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_rcv+0x5c3/0x840 net/ipv4/ip_input.c:539
     __netif_receive_skb_one_core net/core/dev.c:5315 [inline]
     __netif_receive_skb+0x1ec/0x640 net/core/dev.c:5429
     process_backlog+0x523/0xc10 net/core/dev.c:6319
     napi_poll+0x420/0x1010 net/core/dev.c:6763
     net_rx_action+0x35c/0xd40 net/core/dev.c:6833
     __do_softirq+0x1a9/0x6fa kernel/softirq.c:298
     asm_call_irq_on_stack+0xf/0x20
     </IRQ>
     __run_on_irqstack arch/x86/include/asm/irq_stack.h:26 [inline]
     run_on_irqstack_cond arch/x86/include/asm/irq_stack.h:77 [inline]
     do_softirq_own_stack+0x6e/0x90 arch/x86/kernel/irq_64.c:77
     do_softirq kernel/softirq.c:343 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:195
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:730 [inline]
     __dev_queue_xmit+0x3a9b/0x4520 net/core/dev.c:4167
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:4173
     packet_snd net/packet/af_packet.c:2992 [inline]
     packet_sendmsg+0x86f9/0x99d0 net/packet/af_packet.c:3017
     sock_sendmsg_nosec net/socket.c:651 [inline]
     sock_sendmsg net/socket.c:671 [inline]
     __sys_sendto+0x9dc/0xc80 net/socket.c:1992
     __do_sys_sendto net/socket.c:2004 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:2000
     __x64_sys_sendto+0x6e/0x90 net/socket.c:2000
     do_syscall_64+0x9f/0x140 arch/x86/entry/common.c:48
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 2d07dc79fe04 ("geneve: add initial netdev driver for GENEVE tunnels")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Link: https://lore.kernel.org/r/20201201090507.4137906-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4179b00c04d18ea7013f68d578d80f3c9d13150a
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Dec 1 01:05:07 2020 -0800

    geneve: pull IP header before ECN decapsulation
    
    IP_ECN_decapsulate() and IP6_ECN_decapsulate() assume
    IP header is already pulled.
    
    geneve does not ensure this yet.
    
    Fixing this generically in IP_ECN_decapsulate() and
    IP6_ECN_decapsulate() is not possible, since callers
    pass a pointer that might be freed by pskb_may_pull()
    
    syzbot reported :
    
    BUG: KMSAN: uninit-value in __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
    BUG: KMSAN: uninit-value in INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
    CPU: 1 PID: 8941 Comm: syz-executor.0 Not tainted 5.10.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x21c/0x280 lib/dump_stack.c:118
     kmsan_report+0xf7/0x1e0 mm/kmsan/kmsan_report.c:118
     __msan_warning+0x5f/0xa0 mm/kmsan/kmsan_instr.c:197
     __INET_ECN_decapsulate include/net/inet_ecn.h:238 [inline]
     INET_ECN_decapsulate+0x345/0x1db0 include/net/inet_ecn.h:260
     geneve_rx+0x2103/0x2980 include/net/inet_ecn.h:306
     geneve_udp_encap_recv+0x105c/0x1340 drivers/net/geneve.c:377
     udp_queue_rcv_one_skb+0x193a/0x1af0 net/ipv4/udp.c:2093
     udp_queue_rcv_skb+0x282/0x1050 net/ipv4/udp.c:2167
     udp_unicast_rcv_skb net/ipv4/udp.c:2325 [inline]
     __udp4_lib_rcv+0x399d/0x5880 net/ipv4/udp.c:2394
     udp_rcv+0x5c/0x70 net/ipv4/udp.c:2564
     ip_protocol_deliver_rcu+0x572/0xc50 net/ipv4/ip_input.c:204
     ip_local_deliver_finish net/ipv4/ip_input.c:231 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_local_deliver+0x583/0x8d0 net/ipv4/ip_input.c:252
     dst_input include/net/dst.h:449 [inline]
     ip_rcv_finish net/ipv4/ip_input.c:428 [inline]
     NF_HOOK include/linux/netfilter.h:301 [inline]
     ip_rcv+0x5c3/0x840 net/ipv4/ip_input.c:539
     __netif_receive_skb_one_core net/core/dev.c:5315 [inline]
     __netif_receive_skb+0x1ec/0x640 net/core/dev.c:5429
     process_backlog+0x523/0xc10 net/core/dev.c:6319
     napi_poll+0x420/0x1010 net/core/dev.c:6763
     net_rx_action+0x35c/0xd40 net/core/dev.c:6833
     __do_softirq+0x1a9/0x6fa kernel/softirq.c:298
     asm_call_irq_on_stack+0xf/0x20
     </IRQ>
     __run_on_irqstack arch/x86/include/asm/irq_stack.h:26 [inline]
     run_on_irqstack_cond arch/x86/include/asm/irq_stack.h:77 [inline]
     do_softirq_own_stack+0x6e/0x90 arch/x86/kernel/irq_64.c:77
     do_softirq kernel/softirq.c:343 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:195
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:730 [inline]
     __dev_queue_xmit+0x3a9b/0x4520 net/core/dev.c:4167
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:4173
     packet_snd net/packet/af_packet.c:2992 [inline]
     packet_sendmsg+0x86f9/0x99d0 net/packet/af_packet.c:3017
     sock_sendmsg_nosec net/socket.c:651 [inline]
     sock_sendmsg net/socket.c:671 [inline]
     __sys_sendto+0x9dc/0xc80 net/socket.c:1992
     __do_sys_sendto net/socket.c:2004 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:2000
     __x64_sys_sendto+0x6e/0x90 net/socket.c:2000
     do_syscall_64+0x9f/0x140 arch/x86/entry/common.c:48
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 2d07dc79fe04 ("geneve: add initial netdev driver for GENEVE tunnels")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Link: https://lore.kernel.org/r/20201201090507.4137906-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit bfb3aa735f82c8d98b32a669934ee7d6b346264d
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Oct 30 13:11:24 2020 -0700

    rcu: Do not report strict GPs for outgoing CPUs
    
    An outgoing CPU is marked offline in a stop-machine handler and most
    of that CPU's services stop at that point, including IRQ work queues.
    However, that CPU must take another pass through the scheduler and through
    a number of CPU-hotplug notifiers, many of which contain RCU readers.
    In the past, these readers were not a problem because the outgoing CPU
    has interrupts disabled, so that rcu_read_unlock_special() would not
    be invoked, and thus RCU would never attempt to queue IRQ work on the
    outgoing CPU.
    
    This changed with the advent of the CONFIG_RCU_STRICT_GRACE_PERIOD
    Kconfig option, in which rcu_read_unlock_special() is invoked upon exit
    from almost all RCU read-side critical sections.  Worse yet, because
    interrupts are disabled, rcu_read_unlock_special() cannot immediately
    report a quiescent state and will therefore attempt to defer this
    reporting, for example, by queueing IRQ work.  Which fails with a splat
    because the CPU is already marked as being offline.
    
    But it turns out that there is no need to report this quiescent state
    because rcu_report_dead() will do this job shortly after the outgoing
    CPU makes its final dive into the idle loop.  This commit therefore
    makes rcu_read_unlock_special() refrain from queuing IRQ work onto
    outgoing CPUs.
    
    Fixes: 44bad5b3cca2 ("rcu: Do full report for .need_qs for strict GPs")
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Cc: Jann Horn <jannh@google.com>

commit ed73860cecc3ec12aa50a6dcfb4900e5b4ae9507
Author: Neeraj Upadhyay <neeraju@codeaurora.org>
Date:   Wed Sep 23 12:59:33 2020 +0530

    rcu: Fix single-CPU check in rcu_blocking_is_gp()
    
    Currently, for CONFIG_PREEMPTION=n kernels, rcu_blocking_is_gp() uses
    num_online_cpus() to determine whether there is only one CPU online.  When
    there is only a single CPU online, the simple fact that synchronize_rcu()
    could be legally called implies that a full grace period has elapsed.
    Therefore, in the single-CPU case, synchronize_rcu() simply returns
    immediately.  Unfortunately, num_online_cpus() is unreliable while a
    CPU-hotplug operation is transitioning to or from single-CPU operation
    because:
    
    1.      num_online_cpus() uses atomic_read(&__num_online_cpus) to
            locklessly sample the number of online CPUs.  The hotplug locks
            are not held, which means that an incoming CPU can concurrently
            update this count.  This in turn means that an RCU read-side
            critical section on the incoming CPU might observe updates
            prior to the grace period, but also that this critical section
            might extend beyond the end of the optimized synchronize_rcu().
            This breaks RCU's fundamental guarantee.
    
    2.      In addition, num_online_cpus() does no ordering, thus providing
            another way that RCU's fundamental guarantee can be broken by
            the current code.
    
    3.      The most probable failure mode happens on outgoing CPUs.
            The outgoing CPU updates the count of online CPUs in the
            CPUHP_TEARDOWN_CPU stop-machine handler, which is fine in
            and of itself due to preemption being disabled at the call
            to num_online_cpus().  Unfortunately, after that stop-machine
            handler returns, the CPU takes one last trip through the
            scheduler (which has RCU readers) and, after the resulting
            context switch, one final dive into the idle loop.  During this
            time, RCU needs to keep track of two CPUs, but num_online_cpus()
            will say that there is only one, which in turn means that the
            surviving CPU will incorrectly ignore the outgoing CPU's RCU
            read-side critical sections.
    
    This problem is illustrated by the following litmus test in which P0()
    corresponds to synchronize_rcu() and P1() corresponds to the incoming CPU.
    The herd7 tool confirms that the "exists" clause can be satisfied,
    thus demonstrating that this breakage can happen according to the Linux
    kernel memory model.
    
       {
         int x = 0;
         atomic_t numonline = ATOMIC_INIT(1);
       }
    
       P0(int *x, atomic_t *numonline)
       {
         int r0;
         WRITE_ONCE(*x, 1);
         r0 = atomic_read(numonline);
         if (r0 == 1) {
           smp_mb();
         } else {
           synchronize_rcu();
         }
         WRITE_ONCE(*x, 2);
       }
    
       P1(int *x, atomic_t *numonline)
       {
         int r0; int r1;
    
         atomic_inc(numonline);
         smp_mb();
         rcu_read_lock();
         r0 = READ_ONCE(*x);
         smp_rmb();
         r1 = READ_ONCE(*x);
         rcu_read_unlock();
       }
    
       locations [x;numonline;]
    
       exists (1:r0=0 /\ 1:r1=2)
    
    It is important to note that these problems arise only when the system
    is transitioning to or from single-CPU operation.
    
    One solution would be to hold the CPU-hotplug locks while sampling
    num_online_cpus(), which was in fact the intent of the (redundant)
    preempt_disable() and preempt_enable() surrounding this call to
    num_online_cpus().  Actually blocking CPU hotplug would not only result
    in excessive overhead, but would also unnecessarily impede CPU-hotplug
    operations.
    
    This commit therefore follows long-standing RCU tradition by maintaining
    a separate RCU-specific set of CPU-hotplug books.
    
    This separate set of books is implemented by a new ->n_online_cpus field
    in the rcu_state structure that maintains RCU's count of the online CPUs.
    This count is incremented early in the CPU-online process, so that
    the critical transition away from single-CPU operation will occur when
    there is only a single CPU.  Similarly for the critical transition to
    single-CPU operation, the counter is decremented late in the CPU-offline
    process, again while there is only a single CPU.  Because there is only
    ever a single CPU when the ->n_online_cpus field undergoes the critical
    1->2 and 2->1 transitions, full memory ordering and mutual exclusion is
    provided implicitly and, better yet, for free.
    
    In the case where the CPU is coming online, nothing will happen until
    the current CPU helps it come online.  Therefore, the new CPU will see
    all accesses prior to the optimized grace period, which means that RCU
    does not need to further delay this new CPU.  In the case where the CPU
    is going offline, the outgoing CPU is totally out of the picture before
    the optimized grace period starts, which means that this outgoing CPU
    cannot see any of the accesses following that grace period.  Again,
    RCU needs no further interaction with the outgoing CPU.
    
    This does mean that synchronize_rcu() will unnecessarily do a few grace
    periods the hard way just before the second CPU comes online and just
    after the second-to-last CPU goes offline, but it is not worth optimizing
    this uncommon case.
    
    Reviewed-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Neeraj Upadhyay <neeraju@codeaurora.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 9b627c25e70816a5e1dca940444b5029065b4d60
Author: Bhaumik Bhatt <bbhatt@codeaurora.org>
Date:   Thu Oct 15 11:47:51 2020 -0700

    bus: mhi: core: Remove double locking from mhi_driver_remove()
    
    There is double acquisition of the pm_lock from mhi_driver_remove()
    function. Remove the read_lock_bh/read_unlock_bh calls for pm_lock
    taken during a call to mhi_device_put() as the lock is acquired
    within the function already. This will help avoid a potential
    kernel panic.
    
    Fixes: 189ff97cca53 ("bus: mhi: core: Add support for data transfer")
    Reported-by: Shuah Khan <skhan@linuxfoundation.org>
    Signed-off-by: Bhaumik Bhatt <bbhatt@codeaurora.org>
    Reviewed-by: Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org>
    Signed-off-by: Manivannan Sadhasivam <manivannan.sadhasivam@linaro.org>

commit 463fbe4f2bc20be5cfb3ac2ea5cd57052e9ca45e
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Sep 15 14:27:38 2020 -0700

    rcu-tasks: Enclose task-list scan in rcu_read_lock()
    
    commit f747c7e15d7bc71a967a94ceda686cf2460b69e8 upstream.
    
    The rcu_tasks_trace_postgp() function uses for_each_process_thread()
    to scan the task list without the benefit of RCU read-side protection,
    which can result in use-after-free errors on task_struct structures.
    This error was missed because the TRACE01 rcutorture scenario enables
    lockdep, but also builds with CONFIG_PREEMPT_NONE=y.  In this situation,
    preemption is disabled everywhere, so lockdep thinks everywhere can
    be a legitimate RCU reader.  This commit therefore adds the needed
    rcu_read_lock() and rcu_read_unlock().
    
    Note that this bug can occur only after an RCU Tasks Trace CPU stall
    warning, which by default only happens after a grace period has extended
    for ten minutes (yes, not a typo, minutes).
    
    Fixes: 4593e772b502 ("rcu-tasks: Add stall warnings for RCU Tasks Trace")
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: <bpf@vger.kernel.org>
    Cc: <stable@vger.kernel.org> # 5.7.x
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 19506c4e2022e283a2889f553c075e7221066db8
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Sep 15 14:03:34 2020 -0700

    rcu-tasks: Fix low-probability task_struct leak
    
    commit 592031cc10858be4adb10f6c0f2608f6f21824aa upstream.
    
    When rcu_tasks_trace_postgp() function detects an RCU Tasks Trace
    CPU stall, it adds all tasks blocking the current grace period to
    a list, invoking get_task_struct() on each to prevent them from
    being freed while on the list.  It then traverses that list,
    printing stall-warning messages for each one that is still blocking
    the current grace period and removing it from the list.  The list
    removal invokes the matching put_task_struct().
    
    This of course means that in the admittedly unlikely event that some
    task executes its outermost rcu_read_unlock_trace() in the meantime, it
    won't be removed from the list and put_task_struct() won't be executing,
    resulting in a task_struct leak.  This commit therefore makes the list
    removal and put_task_struct() unconditional, stopping the leak.
    
    Note further that this bug can occur only after an RCU Tasks Trace CPU
    stall warning, which by default only happens after a grace period has
    extended for ten minutes (yes, not a typo, minutes).
    
    Fixes: 4593e772b502 ("rcu-tasks: Add stall warnings for RCU Tasks Trace")
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: <bpf@vger.kernel.org>
    Cc: <stable@vger.kernel.org> # 5.7.x
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 79036216e1bb74fc868976a305062953728a790a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Sep 14 15:44:37 2020 -0700

    rcu-tasks: Fix grace-period/unlock race in RCU Tasks Trace
    
    commit ba3a86e47232ad9f76160929f33ac9c64e4d0567 upstream.
    
    The more intense grace-period processing resulting from the 50x RCU
    Tasks Trace grace-period speedups exposed the following race condition:
    
    o       Task A running on CPU 0 executes rcu_read_lock_trace(),
            entering a read-side critical section.
    
    o       When Task A eventually invokes rcu_read_unlock_trace()
            to exit its read-side critical section, this function
            notes that the ->trc_reader_special.s flag is zero and
            and therefore invoke wil set ->trc_reader_nesting to zero
            using WRITE_ONCE().  But before that happens...
    
    o       The RCU Tasks Trace grace-period kthread running on some other
            CPU interrogates Task A, but this fails because this task is
            currently running.  This kthread therefore sends an IPI to CPU 0.
    
    o       CPU 0 receives the IPI, and thus invokes trc_read_check_handler().
            Because Task A has not yet cleared its ->trc_reader_nesting
            counter, this function sees that Task A is still within its
            read-side critical section.  This function therefore sets the
            ->trc_reader_nesting.b.need_qs flag, AKA the .need_qs flag.
    
            Except that Task A has already checked the .need_qs flag, which
            is part of the ->trc_reader_special.s flag.  The .need_qs flag
            therefore remains set until Task A's next rcu_read_unlock_trace().
    
    o       Task A now invokes synchronize_rcu_tasks_trace(), which cannot
            start a new grace period until the current grace period completes.
            And thus cannot return until after that time.
    
            But Task A's .need_qs flag is still set, which prevents the current
            grace period from completing.  And because Task A is blocked, it
            will never execute rcu_read_unlock_trace() until its call to
            synchronize_rcu_tasks_trace() returns.
    
            We are therefore deadlocked.
    
    This race is improbable, but 80 hours of rcutorture made it happen twice.
    The race was possible before the grace-period speedup, but roughly 50x
    less probable.  Several thousand hours of rcutorture would have been
    necessary to have a reasonable chance of making this happen before this
    50x speedup.
    
    This commit therefore eliminates this deadlock by setting
    ->trc_reader_nesting to a large negative number before checking the
    .need_qs and zeroing (or decrementing with respect to its initial
    value) ->trc_reader_nesting.  For its part, the IPI handler's
    trc_read_check_handler() function adds a check for negative values,
    deferring evaluation of the task in this case.  Taken together, these
    changes avoid this deadlock scenario.
    
    Fixes: 276c410448db ("rcu-tasks: Split ->trc_reader_need_end")
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: <bpf@vger.kernel.org>
    Cc: <stable@vger.kernel.org> # 5.7.x
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8b725915481f945dd145a7e40ba8ac042b2e300f
Author: Wright Feng <wright.feng@cypress.com>
Date:   Mon Sep 28 00:49:22 2020 -0500

    brcmfmac: Fix warning message after dongle setup failed
    
    [ Upstream commit 6aa5a83a7ed8036c1388a811eb8bdfa77b21f19c ]
    
    Brcmfmac showed warning message in fweh.c when checking the size of event
    queue which is not initialized. Therefore, we only cancel the worker and
    reset event handler only when it is initialized.
    
    [  145.505899] brcmfmac 0000:02:00.0: brcmf_pcie_setup: Dongle setup
    [  145.929970] ------------[ cut here ]------------
    [  145.929994] WARNING: CPU: 0 PID: 288 at drivers/net/wireless/broadcom/brcm80211/brcmfmac/fweh.c:312
    brcmf_fweh_detach+0xbc/0xd0 [brcmfmac]
    ...
    [  145.930029] Call Trace:
    [  145.930036]  brcmf_detach+0x77/0x100 [brcmfmac]
    [  145.930043]  brcmf_pcie_remove+0x79/0x130 [brcmfmac]
    [  145.930046]  pci_device_remove+0x39/0xc0
    [  145.930048]  device_release_driver_internal+0x141/0x200
    [  145.930049]  device_release_driver+0x12/0x20
    [  145.930054]  brcmf_pcie_setup+0x101/0x3c0 [brcmfmac]
    [  145.930060]  brcmf_fw_request_done+0x11d/0x1f0 [brcmfmac]
    [  145.930062]  ? lock_timer_base+0x7d/0xa0
    [  145.930063]  ? internal_add_timer+0x1f/0xa0
    [  145.930064]  ? add_timer+0x11a/0x1d0
    [  145.930066]  ? __kmalloc_track_caller+0x18c/0x230
    [  145.930068]  ? kstrdup_const+0x23/0x30
    [  145.930069]  ? add_dr+0x46/0x80
    [  145.930070]  ? devres_add+0x3f/0x50
    [  145.930072]  ? usermodehelper_read_unlock+0x15/0x20
    [  145.930073]  ? _request_firmware+0x288/0xa20
    [  145.930075]  request_firmware_work_func+0x36/0x60
    [  145.930077]  process_one_work+0x144/0x360
    [  145.930078]  worker_thread+0x4d/0x3c0
    [  145.930079]  kthread+0x112/0x150
    [  145.930080]  ? rescuer_thread+0x340/0x340
    [  145.930081]  ? kthread_park+0x60/0x60
    [  145.930083]  ret_from_fork+0x25/0x30
    
    Signed-off-by: Wright Feng <wright.feng@cypress.com>
    Signed-off-by: Chi-hsien Lin <chi-hsien.lin@cypress.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20200928054922.44580-3-wright.feng@cypress.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 592cbc0a6a83c06e245365e127c5452a400c8aec
Author: Wright Feng <wright.feng@cypress.com>
Date:   Mon Sep 28 00:49:22 2020 -0500

    brcmfmac: Fix warning message after dongle setup failed
    
    [ Upstream commit 6aa5a83a7ed8036c1388a811eb8bdfa77b21f19c ]
    
    Brcmfmac showed warning message in fweh.c when checking the size of event
    queue which is not initialized. Therefore, we only cancel the worker and
    reset event handler only when it is initialized.
    
    [  145.505899] brcmfmac 0000:02:00.0: brcmf_pcie_setup: Dongle setup
    [  145.929970] ------------[ cut here ]------------
    [  145.929994] WARNING: CPU: 0 PID: 288 at drivers/net/wireless/broadcom/brcm80211/brcmfmac/fweh.c:312
    brcmf_fweh_detach+0xbc/0xd0 [brcmfmac]
    ...
    [  145.930029] Call Trace:
    [  145.930036]  brcmf_detach+0x77/0x100 [brcmfmac]
    [  145.930043]  brcmf_pcie_remove+0x79/0x130 [brcmfmac]
    [  145.930046]  pci_device_remove+0x39/0xc0
    [  145.930048]  device_release_driver_internal+0x141/0x200
    [  145.930049]  device_release_driver+0x12/0x20
    [  145.930054]  brcmf_pcie_setup+0x101/0x3c0 [brcmfmac]
    [  145.930060]  brcmf_fw_request_done+0x11d/0x1f0 [brcmfmac]
    [  145.930062]  ? lock_timer_base+0x7d/0xa0
    [  145.930063]  ? internal_add_timer+0x1f/0xa0
    [  145.930064]  ? add_timer+0x11a/0x1d0
    [  145.930066]  ? __kmalloc_track_caller+0x18c/0x230
    [  145.930068]  ? kstrdup_const+0x23/0x30
    [  145.930069]  ? add_dr+0x46/0x80
    [  145.930070]  ? devres_add+0x3f/0x50
    [  145.930072]  ? usermodehelper_read_unlock+0x15/0x20
    [  145.930073]  ? _request_firmware+0x288/0xa20
    [  145.930075]  request_firmware_work_func+0x36/0x60
    [  145.930077]  process_one_work+0x144/0x360
    [  145.930078]  worker_thread+0x4d/0x3c0
    [  145.930079]  kthread+0x112/0x150
    [  145.930080]  ? rescuer_thread+0x340/0x340
    [  145.930081]  ? kthread_park+0x60/0x60
    [  145.930083]  ret_from_fork+0x25/0x30
    
    Signed-off-by: Wright Feng <wright.feng@cypress.com>
    Signed-off-by: Chi-hsien Lin <chi-hsien.lin@cypress.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20200928054922.44580-3-wright.feng@cypress.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6aa5a83a7ed8036c1388a811eb8bdfa77b21f19c
Author: Wright Feng <wright.feng@cypress.com>
Date:   Mon Sep 28 00:49:22 2020 -0500

    brcmfmac: Fix warning message after dongle setup failed
    
    Brcmfmac showed warning message in fweh.c when checking the size of event
    queue which is not initialized. Therefore, we only cancel the worker and
    reset event handler only when it is initialized.
    
    [  145.505899] brcmfmac 0000:02:00.0: brcmf_pcie_setup: Dongle setup
    [  145.929970] ------------[ cut here ]------------
    [  145.929994] WARNING: CPU: 0 PID: 288 at drivers/net/wireless/broadcom/brcm80211/brcmfmac/fweh.c:312
    brcmf_fweh_detach+0xbc/0xd0 [brcmfmac]
    ...
    [  145.930029] Call Trace:
    [  145.930036]  brcmf_detach+0x77/0x100 [brcmfmac]
    [  145.930043]  brcmf_pcie_remove+0x79/0x130 [brcmfmac]
    [  145.930046]  pci_device_remove+0x39/0xc0
    [  145.930048]  device_release_driver_internal+0x141/0x200
    [  145.930049]  device_release_driver+0x12/0x20
    [  145.930054]  brcmf_pcie_setup+0x101/0x3c0 [brcmfmac]
    [  145.930060]  brcmf_fw_request_done+0x11d/0x1f0 [brcmfmac]
    [  145.930062]  ? lock_timer_base+0x7d/0xa0
    [  145.930063]  ? internal_add_timer+0x1f/0xa0
    [  145.930064]  ? add_timer+0x11a/0x1d0
    [  145.930066]  ? __kmalloc_track_caller+0x18c/0x230
    [  145.930068]  ? kstrdup_const+0x23/0x30
    [  145.930069]  ? add_dr+0x46/0x80
    [  145.930070]  ? devres_add+0x3f/0x50
    [  145.930072]  ? usermodehelper_read_unlock+0x15/0x20
    [  145.930073]  ? _request_firmware+0x288/0xa20
    [  145.930075]  request_firmware_work_func+0x36/0x60
    [  145.930077]  process_one_work+0x144/0x360
    [  145.930078]  worker_thread+0x4d/0x3c0
    [  145.930079]  kthread+0x112/0x150
    [  145.930080]  ? rescuer_thread+0x340/0x340
    [  145.930081]  ? kthread_park+0x60/0x60
    [  145.930083]  ret_from_fork+0x25/0x30
    
    Signed-off-by: Wright Feng <wright.feng@cypress.com>
    Signed-off-by: Chi-hsien Lin <chi-hsien.lin@cypress.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20200928054922.44580-3-wright.feng@cypress.com

commit f747c7e15d7bc71a967a94ceda686cf2460b69e8
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Sep 15 14:27:38 2020 -0700

    rcu-tasks: Enclose task-list scan in rcu_read_lock()
    
    The rcu_tasks_trace_postgp() function uses for_each_process_thread()
    to scan the task list without the benefit of RCU read-side protection,
    which can result in use-after-free errors on task_struct structures.
    This error was missed because the TRACE01 rcutorture scenario enables
    lockdep, but also builds with CONFIG_PREEMPT_NONE=y.  In this situation,
    preemption is disabled everywhere, so lockdep thinks everywhere can
    be a legitimate RCU reader.  This commit therefore adds the needed
    rcu_read_lock() and rcu_read_unlock().
    
    Note that this bug can occur only after an RCU Tasks Trace CPU stall
    warning, which by default only happens after a grace period has extended
    for ten minutes (yes, not a typo, minutes).
    
    Fixes: 4593e772b502 ("rcu-tasks: Add stall warnings for RCU Tasks Trace")
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: <bpf@vger.kernel.org>
    Cc: <stable@vger.kernel.org> # 5.7.x
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 592031cc10858be4adb10f6c0f2608f6f21824aa
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Sep 15 14:03:34 2020 -0700

    rcu-tasks: Fix low-probability task_struct leak
    
    When rcu_tasks_trace_postgp() function detects an RCU Tasks Trace
    CPU stall, it adds all tasks blocking the current grace period to
    a list, invoking get_task_struct() on each to prevent them from
    being freed while on the list.  It then traverses that list,
    printing stall-warning messages for each one that is still blocking
    the current grace period and removing it from the list.  The list
    removal invokes the matching put_task_struct().
    
    This of course means that in the admittedly unlikely event that some
    task executes its outermost rcu_read_unlock_trace() in the meantime, it
    won't be removed from the list and put_task_struct() won't be executing,
    resulting in a task_struct leak.  This commit therefore makes the list
    removal and put_task_struct() unconditional, stopping the leak.
    
    Note further that this bug can occur only after an RCU Tasks Trace CPU
    stall warning, which by default only happens after a grace period has
    extended for ten minutes (yes, not a typo, minutes).
    
    Fixes: 4593e772b502 ("rcu-tasks: Add stall warnings for RCU Tasks Trace")
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: <bpf@vger.kernel.org>
    Cc: <stable@vger.kernel.org> # 5.7.x
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit ba3a86e47232ad9f76160929f33ac9c64e4d0567
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Sep 14 15:44:37 2020 -0700

    rcu-tasks: Fix grace-period/unlock race in RCU Tasks Trace
    
    The more intense grace-period processing resulting from the 50x RCU
    Tasks Trace grace-period speedups exposed the following race condition:
    
    o       Task A running on CPU 0 executes rcu_read_lock_trace(),
            entering a read-side critical section.
    
    o       When Task A eventually invokes rcu_read_unlock_trace()
            to exit its read-side critical section, this function
            notes that the ->trc_reader_special.s flag is zero and
            and therefore invoke wil set ->trc_reader_nesting to zero
            using WRITE_ONCE().  But before that happens...
    
    o       The RCU Tasks Trace grace-period kthread running on some other
            CPU interrogates Task A, but this fails because this task is
            currently running.  This kthread therefore sends an IPI to CPU 0.
    
    o       CPU 0 receives the IPI, and thus invokes trc_read_check_handler().
            Because Task A has not yet cleared its ->trc_reader_nesting
            counter, this function sees that Task A is still within its
            read-side critical section.  This function therefore sets the
            ->trc_reader_nesting.b.need_qs flag, AKA the .need_qs flag.
    
            Except that Task A has already checked the .need_qs flag, which
            is part of the ->trc_reader_special.s flag.  The .need_qs flag
            therefore remains set until Task A's next rcu_read_unlock_trace().
    
    o       Task A now invokes synchronize_rcu_tasks_trace(), which cannot
            start a new grace period until the current grace period completes.
            And thus cannot return until after that time.
    
            But Task A's .need_qs flag is still set, which prevents the current
            grace period from completing.  And because Task A is blocked, it
            will never execute rcu_read_unlock_trace() until its call to
            synchronize_rcu_tasks_trace() returns.
    
            We are therefore deadlocked.
    
    This race is improbable, but 80 hours of rcutorture made it happen twice.
    The race was possible before the grace-period speedup, but roughly 50x
    less probable.  Several thousand hours of rcutorture would have been
    necessary to have a reasonable chance of making this happen before this
    50x speedup.
    
    This commit therefore eliminates this deadlock by setting
    ->trc_reader_nesting to a large negative number before checking the
    .need_qs and zeroing (or decrementing with respect to its initial
    value) ->trc_reader_nesting.  For its part, the IPI handler's
    trc_read_check_handler() function adds a check for negative values,
    deferring evaluation of the task in this case.  Taken together, these
    changes avoid this deadlock scenario.
    
    Fixes: 276c410448db ("rcu-tasks: Split ->trc_reader_need_end")
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Daniel Borkmann <daniel@iogearbox.net>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: <bpf@vger.kernel.org>
    Cc: <stable@vger.kernel.org> # 5.7.x
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit dc0988bbe1bd41e2fa555e4a6f890b819a34b49b
Author: Yonghong Song <yhs@fb.com>
Date:   Wed Sep 2 16:53:40 2020 -0700

    bpf: Do not use bucket_lock for hashmap iterator
    
    Currently, for hashmap, the bpf iterator will grab a bucket lock, a
    spinlock, before traversing the elements in the bucket. This can ensure
    all bpf visted elements are valid. But this mechanism may cause
    deadlock if update/deletion happens to the same bucket of the
    visited map in the program. For example, if we added bpf_map_update_elem()
    call to the same visited element in selftests bpf_iter_bpf_hash_map.c,
    we will have the following deadlock:
    
      ============================================
      WARNING: possible recursive locking detected
      5.9.0-rc1+ #841 Not tainted
      --------------------------------------------
      test_progs/1750 is trying to acquire lock:
      ffff9a5bb73c5e70 (&htab->buckets[i].raw_lock){....}-{2:2}, at: htab_map_update_elem+0x1cf/0x410
    
      but task is already holding lock:
      ffff9a5bb73c5e20 (&htab->buckets[i].raw_lock){....}-{2:2}, at: bpf_hash_map_seq_find_next+0x94/0x120
    
      other info that might help us debug this:
       Possible unsafe locking scenario:
    
             CPU0
             ----
        lock(&htab->buckets[i].raw_lock);
        lock(&htab->buckets[i].raw_lock);
    
       *** DEADLOCK ***
       ...
      Call Trace:
       dump_stack+0x78/0xa0
       __lock_acquire.cold.74+0x209/0x2e3
       lock_acquire+0xba/0x380
       ? htab_map_update_elem+0x1cf/0x410
       ? __lock_acquire+0x639/0x20c0
       _raw_spin_lock_irqsave+0x3b/0x80
       ? htab_map_update_elem+0x1cf/0x410
       htab_map_update_elem+0x1cf/0x410
       ? lock_acquire+0xba/0x380
       bpf_prog_ad6dab10433b135d_dump_bpf_hash_map+0x88/0xa9c
       ? find_held_lock+0x34/0xa0
       bpf_iter_run_prog+0x81/0x16e
       __bpf_hash_map_seq_show+0x145/0x180
       bpf_seq_read+0xff/0x3d0
       vfs_read+0xad/0x1c0
       ksys_read+0x5f/0xe0
       do_syscall_64+0x33/0x40
       entry_SYSCALL_64_after_hwframe+0x44/0xa9
      ...
    
    The bucket_lock first grabbed in seq_ops->next() called by bpf_seq_read(),
    and then grabbed again in htab_map_update_elem() in the bpf program, causing
    deadlocks.
    
    Actually, we do not need bucket_lock here, we can just use rcu_read_lock()
    similar to netlink iterator where the rcu_read_{lock,unlock} likes below:
     seq_ops->start():
         rcu_read_lock();
     seq_ops->next():
         rcu_read_unlock();
         /* next element */
         rcu_read_lock();
     seq_ops->stop();
         rcu_read_unlock();
    
    Compared to old bucket_lock mechanism, if concurrent updata/delete happens,
    we may visit stale elements, miss some elements, or repeat some elements.
    I think this is a reasonable compromise. For users wanting to avoid
    stale, missing/repeated accesses, bpf_map batch access syscall interface
    can be used.
    
    Signed-off-by: Yonghong Song <yhs@fb.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/bpf/20200902235340.2001375-1-yhs@fb.com

commit 9667305c6374df8672be46bc496f52f040999531
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Mon Aug 31 08:51:55 2020 -0700

    bpf: Fix build without BPF_SYSCALL, but with BPF_JIT.
    
    When CONFIG_BPF_SYSCALL is not set, but CONFIG_BPF_JIT=y
    the kernel build fails:
    In file included from ../kernel/bpf/trampoline.c:11:
    ../kernel/bpf/trampoline.c: In function bpf_trampoline_update:
    ../kernel/bpf/trampoline.c:220:39: error: call_rcu_tasks_trace undeclared
    ../kernel/bpf/trampoline.c: In function __bpf_prog_enter_sleepable:
    ../kernel/bpf/trampoline.c:411:2: error: implicit declaration of function rcu_read_lock_trace
    ../kernel/bpf/trampoline.c: In function __bpf_prog_exit_sleepable:
    ../kernel/bpf/trampoline.c:416:2: error: implicit declaration of function rcu_read_unlock_trace
    
    This is due to:
    obj-$(CONFIG_BPF_JIT) += trampoline.o
    obj-$(CONFIG_BPF_JIT) += dispatcher.o
    There is a number of functions that arch/x86/net/bpf_jit_comp.c is
    using from these two files, but none of them will be used when
    only cBPF is on (which is the case for BPF_SYSCALL=n BPF_JIT=y).
    
    Add rcu_trace functions to rcupdate_trace.h. The JITed code won't execute them
    and BPF trampoline logic won't be used without BPF_SYSCALL.
    
    Fixes: 1e6c62a88215 ("bpf: Introduce sleepable BPF programs")
    Reported-by: kernel test robot <lkp@intel.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Paul E. McKenney <paulmck@kernel.org>
    Link: https://lore.kernel.org/bpf/20200831155155.62754-1-alexei.starovoitov@gmail.com

commit 10496f261ed30592c6a7f8315f6b5ec055db624a
Merge: d557ea39a5f8 e68a144547fc
Author: Daniel Borkmann <daniel@iogearbox.net>
Date:   Fri Aug 28 21:20:33 2020 +0200

    Merge branch 'bpf-sleepable'
    
    Alexei Starovoitov says:
    
    ====================
    v2->v3:
    - switched to minimal allowlist approach. Essentially that means that syscall
      entry, few btrfs allow_error_inject functions, should_fail_bio(), and two LSM
      hooks: file_mprotect and bprm_committed_creds are the only hooks that allow
      attaching of sleepable BPF programs. When comprehensive analysis of LSM hooks
      will be done this allowlist will be extended.
    - added patch 1 that fixes prototypes of two mm functions to reliably work with
      error injection. It's also necessary for resolve_btfids tool to recognize
      these two funcs, but that's secondary.
    
    v1->v2:
    - split fmod_ret fix into separate patch
    - added denylist
    
    v1:
    This patch set introduces the minimal viable support for sleepable bpf programs.
    In this patch only fentry/fexit/fmod_ret and lsm progs can be sleepable.
    Only array and pre-allocated hash and lru maps allowed.
    
    Here is 'perf report' difference of sleepable vs non-sleepable:
       3.86%  bench     [k] __srcu_read_unlock
       3.22%  bench     [k] __srcu_read_lock
       0.92%  bench     [k] bpf_prog_740d4210cdcd99a3_bench_trigger_fentry_sleep
       0.50%  bench     [k] bpf_trampoline_10297
       0.26%  bench     [k] __bpf_prog_exit_sleepable
       0.21%  bench     [k] __bpf_prog_enter_sleepable
    vs
       0.88%  bench     [k] bpf_prog_740d4210cdcd99a3_bench_trigger_fentry
       0.84%  bench     [k] bpf_trampoline_10297
       0.13%  bench     [k] __bpf_prog_enter
       0.12%  bench     [k] __bpf_prog_exit
    vs
       0.79%  bench     [k] bpf_prog_740d4210cdcd99a3_bench_trigger_fentry_sleep
       0.72%  bench     [k] bpf_trampoline_10381
       0.31%  bench     [k] __bpf_prog_exit_sleepable
       0.29%  bench     [k] __bpf_prog_enter_sleepable
    
    Sleepable vs non-sleepable program invocation overhead is only marginally higher
    due to rcu_trace. srcu approach is much slower.
    ====================
    
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>

commit e68a144547fc7a956952260539cb7b8bb9afbcc0
Author: Alexei Starovoitov <ast@kernel.org>
Date:   Thu Aug 27 15:01:14 2020 -0700

    selftests/bpf: Add sleepable tests
    
    Modify few tests to sanity test sleepable bpf functionality.
    
    Running 'bench trig-fentry-sleep' vs 'bench trig-fentry' and 'perf report':
    sleepable with SRCU:
       3.86%  bench     [k] __srcu_read_unlock
       3.22%  bench     [k] __srcu_read_lock
       0.92%  bench     [k] bpf_prog_740d4210cdcd99a3_bench_trigger_fentry_sleep
       0.50%  bench     [k] bpf_trampoline_10297
       0.26%  bench     [k] __bpf_prog_exit_sleepable
       0.21%  bench     [k] __bpf_prog_enter_sleepable
    
    sleepable with RCU_TRACE:
       0.79%  bench     [k] bpf_prog_740d4210cdcd99a3_bench_trigger_fentry_sleep
       0.72%  bench     [k] bpf_trampoline_10381
       0.31%  bench     [k] __bpf_prog_exit_sleepable
       0.29%  bench     [k] __bpf_prog_enter_sleepable
    
    non-sleepable with RCU:
       0.88%  bench     [k] bpf_prog_740d4210cdcd99a3_bench_trigger_fentry
       0.84%  bench     [k] bpf_trampoline_10297
       0.13%  bench     [k] __bpf_prog_enter
       0.12%  bench     [k] __bpf_prog_exit
    
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: KP Singh <kpsingh@google.com>
    Link: https://lore.kernel.org/bpf/20200827220114.69225-6-alexei.starovoitov@gmail.com

commit aa40c138cc8f36e2f5c721fd1bdb823a1ef1a237
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Aug 10 09:58:03 2020 -0700

    rcu: Report QS for outermost PREEMPT=n rcu_read_unlock() for strict GPs
    
    The CONFIG_PREEMPT=n instance of rcu_read_unlock is even more
    aggressively than that of CONFIG_PREEMPT=y in deferring reporting
    quiescent states to the RCU core.  This is just what is wanted in normal
    use because it reduces overhead, but the resulting delay is not what
    is wanted for kernels built with CONFIG_RCU_STRICT_GRACE_PERIOD=y.
    This commit therefore adds an rcu_read_unlock_strict() function that
    checks for exceptional conditions, and reports the newly started
    quiescent state if it is safe to do so, also doing a spin-delay if
    requested via rcutree.rcu_unlock_delay.  This commit also adds a call
    to rcu_read_unlock_strict() from the CONFIG_PREEMPT=n instance of
    __rcu_read_unlock().
    
    [ paulmck: Fixed bug located by kernel test robot <lkp@intel.com> ]
    Reported-by Jann Horn <jannh@google.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 1a2f5d57a33f7b9189b6b3e997eb858301482d79
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Aug 6 16:35:08 2020 -0700

    rcu: Attempt QS when CPU discovers GP for strict GPs
    
    A given CPU normally notes a new grace period during one RCU_SOFTIRQ,
    but avoids reporting the corresponding quiescent state until some later
    RCU_SOFTIRQ.  This leisurly approach improves efficiency by increasing
    the number of update requests served by each grace period, but is not
    what is needed for kernels built with CONFIG_RCU_STRICT_GRACE_PERIOD=y.
    
    This commit therefore adds a new rcu_strict_gp_check_qs() function
    which, in CONFIG_RCU_STRICT_GRACE_PERIOD=y kernels, simply enters and
    immediately exist an RCU read-side critical section.  If the CPU is
    in a quiescent state, the rcu_read_unlock() will attempt to report an
    immediate quiescent state.  This rcu_strict_gp_check_qs() function is
    invoked from note_gp_changes(), so that a CPU just noticing a new grace
    period might immediately report a quiescent state for that grace period.
    
    Reported-by Jann Horn <jannh@google.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 44bad5b3cca2d452d17ef82841b20b42a2cf11a0
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Aug 6 15:12:50 2020 -0700

    rcu: Do full report for .need_qs for strict GPs
    
    The rcu_preempt_deferred_qs_irqrestore() function is invoked at
    the end of an RCU read-side critical section (for example, directly
    from rcu_read_unlock()) and, if .need_qs is set, invokes rcu_qs() to
    report the new quiescent state.  This works, except that rcu_qs() only
    updates per-CPU state, leaving reporting of the actual quiescent state
    to a later call to rcu_report_qs_rdp(), for example from within a later
    RCU_SOFTIRQ instance.  Although this approach is exactly what you want if
    you are more concerned about efficiency than about short grace periods,
    in CONFIG_RCU_STRICT_GRACE_PERIOD=y kernels, short grace periods are
    the name of the game.
    
    This commit therefore makes rcu_preempt_deferred_qs_irqrestore() directly
    invoke rcu_report_qs_rdp() in CONFIG_RCU_STRICT_GRACE_PERIOD=y, thus
    shortening grace periods.
    
    Historical note:  To the best of my knowledge, causing rcu_read_unlock()
    to directly report a quiescent state first appeared in Jim Houston's
    and Joe Korty's JRCU.  This is the second instance of a Linux-kernel RCU
    feature being inspired by JRCU, the first being RCU callback offloading
    (as in the RCU_NOCB_CPU Kconfig option).
    
    Reported-by Jann Horn <jannh@google.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit f19920e412fdeed1e15691bcee5b40e18b8e96ff
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Aug 6 09:40:18 2020 -0700

    rcu: Always set .need_qs from __rcu_read_lock() for strict GPs
    
    The ->rcu_read_unlock_special.b.need_qs field in the task_struct
    structure indicates that the RCU core needs a quiscent state from the
    corresponding task.  The __rcu_read_unlock() function checks this (via
    an eventual call to rcu_preempt_deferred_qs_irqrestore()), and if set
    reports a quiscent state immediately upon exit from the outermost RCU
    read-side critical section.
    
    Currently, this flag is only set when the scheduling-clock interrupt
    decides that the current RCU grace period is too old, as in about
    one full second too old.  But if the kernel has been built with
    CONFIG_RCU_STRICT_GRACE_PERIOD=y, we clearly do not want to wait that
    long.  This commit therefore sets the .need_qs field immediately at the
    start of the RCU read-side critical section from within __rcu_read_lock()
    in order to unconditionally enlist help from __rcu_read_unlock().
    
    But note the additional check for rcu_state.gp_kthread, which prevents
    attempts to awaken RCU's grace-period kthread during early boot before
    there is a scheduler.  Leaving off this check results in early boot hangs.
    So early that there is no console output.  Thus, this additional check
    fails until such time as RCU's grace-period kthread has been created,
    avoiding these empty-console hangs.
    
    Reported-by Jann Horn <jannh@google.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 8cbd0e38a9f2de38e8991c5c1c6f9024b2731d17
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Aug 5 15:51:20 2020 -0700

    rcu: Add Kconfig option for strict RCU grace periods
    
    People running automated tests have asked for a way to make RCU minimize
    grace-period duration in order to increase the probability of KASAN
    detecting a pointer being improperly leaked from an RCU read-side critical
    section, for example, like this:
    
            rcu_read_lock();
            p = rcu_dereference(gp);
            do_something_with(p); // OK
            rcu_read_unlock();
            do_something_else_with(p); // BUG!!!
    
    The rcupdate.rcu_expedited boot parameter is a start in this direction,
    given that it makes calls to synchronize_rcu() instead invoke the faster
    (and more wasteful) synchronize_rcu_expedited().  However, this does
    nothing to shorten RCU grace periods that are instead initiated by
    call_rcu(), and RCU pointer-leak bugs can involve call_rcu() just as
    surely as they can synchronize_rcu().
    
    This commit therefore adds a RCU_STRICT_GRACE_PERIOD Kconfig option
    that will be used to shorten normal (non-expedited) RCU grace periods.
    This commit also dumps out a message when this option is in effect.
    Later commits will actually shorten grace periods.
    
    Reported-by Jann Horn <jannh@google.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 000601bb62330f18dc8f5d2d0b82e9aec3e207c4
Author: Tobias Klauser <tklauser@distanz.ch>
Date:   Thu Jul 9 15:05:59 2020 +0200

    rcu: Fix kerneldoc comments in rcupdate.h
    
    This commit fixes the kerneldoc comments for rcu_read_unlock_bh(),
    rcu_read_unlock_sched() and rcu_head_after_call_rcu() so they e.g. get
    properly linked in the API documentation. Also add parenthesis after
    function names to match the notation used in other kerneldoc comments in
    the same file.
    
    Signed-off-by: Tobias Klauser <tklauser@distanz.ch>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 22ca8cb2a5b9b34034ae19d0e4c1c969d5576051
Author: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Date:   Thu Jul 30 20:25:17 2020 +0900

    block: don't do revalidate zones on invalid devices
    
    [ Upstream commit 1a1206dc4cf02cee4b5cbce583ee4c22368b4c28 ]
    
    When we loose a device for whatever reason while (re)scanning zones, we
    trip over a NULL pointer in blk_revalidate_zone_cb, like in the following
    log:
    
    sd 0:0:0:0: [sda] 3418095616 4096-byte logical blocks: (14.0 TB/12.7 TiB)
    sd 0:0:0:0: [sda] 52156 zones of 65536 logical blocks
    sd 0:0:0:0: [sda] Write Protect is off
    sd 0:0:0:0: [sda] Mode Sense: 37 00 00 08
    sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
    sd 0:0:0:0: [sda] REPORT ZONES start lba 1065287680 failed
    sd 0:0:0:0: [sda] REPORT ZONES: Result: hostbyte=0x00 driverbyte=0x08
    sd 0:0:0:0: [sda] Sense Key : 0xb [current]
    sd 0:0:0:0: [sda] ASC=0x0 ASCQ=0x6
    sda: failed to revalidate zones
    sd 0:0:0:0: [sda] 0 4096-byte logical blocks: (0 B/0 B)
    sda: detected capacity change from 14000519643136 to 0
    ==================================================================
    BUG: KASAN: null-ptr-deref in blk_revalidate_zone_cb+0x1b7/0x550
    Write of size 8 at addr 0000000000000010 by task kworker/u4:1/58
    
    CPU: 1 PID: 58 Comm: kworker/u4:1 Not tainted 5.8.0-rc1 #692
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.13.0-0-gf21b5a4-rebuilt.opensuse.org 04/01/2014
    Workqueue: events_unbound async_run_entry_fn
    Call Trace:
     dump_stack+0x7d/0xb0
     ? blk_revalidate_zone_cb+0x1b7/0x550
     kasan_report.cold+0x5/0x37
     ? blk_revalidate_zone_cb+0x1b7/0x550
     check_memory_region+0x145/0x1a0
     blk_revalidate_zone_cb+0x1b7/0x550
     sd_zbc_parse_report+0x1f1/0x370
     ? blk_req_zone_write_trylock+0x200/0x200
     ? sectors_to_logical+0x60/0x60
     ? blk_req_zone_write_trylock+0x200/0x200
     ? blk_req_zone_write_trylock+0x200/0x200
     sd_zbc_report_zones+0x3c4/0x5e0
     ? sd_dif_config_host+0x500/0x500
     blk_revalidate_disk_zones+0x231/0x44d
     ? _raw_write_lock_irqsave+0xb0/0xb0
     ? blk_queue_free_zone_bitmaps+0xd0/0xd0
     sd_zbc_read_zones+0x8cf/0x11a0
     sd_revalidate_disk+0x305c/0x64e0
     ? __device_add_disk+0x776/0xf20
     ? read_capacity_16.part.0+0x1080/0x1080
     ? blk_alloc_devt+0x250/0x250
     ? create_object.isra.0+0x595/0xa20
     ? kasan_unpoison_shadow+0x33/0x40
     sd_probe+0x8dc/0xcd2
     really_probe+0x20e/0xaf0
     __driver_attach_async_helper+0x249/0x2d0
     async_run_entry_fn+0xbe/0x560
     process_one_work+0x764/0x1290
     ? _raw_read_unlock_irqrestore+0x30/0x30
     worker_thread+0x598/0x12f0
     ? __kthread_parkme+0xc6/0x1b0
     ? schedule+0xed/0x2c0
     ? process_one_work+0x1290/0x1290
     kthread+0x36b/0x440
     ? kthread_create_worker_on_cpu+0xa0/0xa0
     ret_from_fork+0x22/0x30
    ==================================================================
    
    When the device is already gone we end up with the following scenario:
    The device's capacity is 0 and thus the number of zones will be 0 as well. When
    allocating the bitmap for the conventional zones, we then trip over a NULL
    pointer.
    
    So if we encounter a zoned block device with a 0 capacity, don't dare to
    revalidate the zones sizes.
    
    Fixes: 6c6b35491422 ("block: set the zone size in blk_revalidate_disk_zones atomically")
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Damien Le Moal <damien.lemoal@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8904c89418a5a691b16be9d862e8bda5f0332803
Author: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Date:   Thu Jul 30 20:25:17 2020 +0900

    block: don't do revalidate zones on invalid devices
    
    [ Upstream commit 1a1206dc4cf02cee4b5cbce583ee4c22368b4c28 ]
    
    When we loose a device for whatever reason while (re)scanning zones, we
    trip over a NULL pointer in blk_revalidate_zone_cb, like in the following
    log:
    
    sd 0:0:0:0: [sda] 3418095616 4096-byte logical blocks: (14.0 TB/12.7 TiB)
    sd 0:0:0:0: [sda] 52156 zones of 65536 logical blocks
    sd 0:0:0:0: [sda] Write Protect is off
    sd 0:0:0:0: [sda] Mode Sense: 37 00 00 08
    sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
    sd 0:0:0:0: [sda] REPORT ZONES start lba 1065287680 failed
    sd 0:0:0:0: [sda] REPORT ZONES: Result: hostbyte=0x00 driverbyte=0x08
    sd 0:0:0:0: [sda] Sense Key : 0xb [current]
    sd 0:0:0:0: [sda] ASC=0x0 ASCQ=0x6
    sda: failed to revalidate zones
    sd 0:0:0:0: [sda] 0 4096-byte logical blocks: (0 B/0 B)
    sda: detected capacity change from 14000519643136 to 0
    ==================================================================
    BUG: KASAN: null-ptr-deref in blk_revalidate_zone_cb+0x1b7/0x550
    Write of size 8 at addr 0000000000000010 by task kworker/u4:1/58
    
    CPU: 1 PID: 58 Comm: kworker/u4:1 Not tainted 5.8.0-rc1 #692
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.13.0-0-gf21b5a4-rebuilt.opensuse.org 04/01/2014
    Workqueue: events_unbound async_run_entry_fn
    Call Trace:
     dump_stack+0x7d/0xb0
     ? blk_revalidate_zone_cb+0x1b7/0x550
     kasan_report.cold+0x5/0x37
     ? blk_revalidate_zone_cb+0x1b7/0x550
     check_memory_region+0x145/0x1a0
     blk_revalidate_zone_cb+0x1b7/0x550
     sd_zbc_parse_report+0x1f1/0x370
     ? blk_req_zone_write_trylock+0x200/0x200
     ? sectors_to_logical+0x60/0x60
     ? blk_req_zone_write_trylock+0x200/0x200
     ? blk_req_zone_write_trylock+0x200/0x200
     sd_zbc_report_zones+0x3c4/0x5e0
     ? sd_dif_config_host+0x500/0x500
     blk_revalidate_disk_zones+0x231/0x44d
     ? _raw_write_lock_irqsave+0xb0/0xb0
     ? blk_queue_free_zone_bitmaps+0xd0/0xd0
     sd_zbc_read_zones+0x8cf/0x11a0
     sd_revalidate_disk+0x305c/0x64e0
     ? __device_add_disk+0x776/0xf20
     ? read_capacity_16.part.0+0x1080/0x1080
     ? blk_alloc_devt+0x250/0x250
     ? create_object.isra.0+0x595/0xa20
     ? kasan_unpoison_shadow+0x33/0x40
     sd_probe+0x8dc/0xcd2
     really_probe+0x20e/0xaf0
     __driver_attach_async_helper+0x249/0x2d0
     async_run_entry_fn+0xbe/0x560
     process_one_work+0x764/0x1290
     ? _raw_read_unlock_irqrestore+0x30/0x30
     worker_thread+0x598/0x12f0
     ? __kthread_parkme+0xc6/0x1b0
     ? schedule+0xed/0x2c0
     ? process_one_work+0x1290/0x1290
     kthread+0x36b/0x440
     ? kthread_create_worker_on_cpu+0xa0/0xa0
     ret_from_fork+0x22/0x30
    ==================================================================
    
    When the device is already gone we end up with the following scenario:
    The device's capacity is 0 and thus the number of zones will be 0 as well. When
    allocating the bitmap for the conventional zones, we then trip over a NULL
    pointer.
    
    So if we encounter a zoned block device with a 0 capacity, don't dare to
    revalidate the zones sizes.
    
    Fixes: 6c6b35491422 ("block: set the zone size in blk_revalidate_disk_zones atomically")
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Damien Le Moal <damien.lemoal@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a85ffd59bd362d6c2e456e7f523b091830cd5454
Author: Hugh Dickins <hughd@google.com>
Date:   Wed Aug 12 20:17:00 2020 -0700

    dma-debug: fix debug_dma_assert_idle(), use rcu_read_lock()
    
    Since commit 2a9127fcf229 ("mm: rewrite wait_on_page_bit_common()
    logic") improved unlock_page(), it has become more noticeable how
    cow_user_page() in a kernel with CONFIG_DMA_API_DEBUG=y can create and
    suffer from heavy contention on DMA debug's radix_lock in
    debug_dma_assert_idle().
    
    It is only doing a lookup: use rcu_read_lock() and rcu_read_unlock()
    instead; though that does require the static ents[] to be moved
    onstack...
    
    ...but, hold on, isn't that radix_tree_gang_lookup() and loop doing
    quite the wrong thing: searching CACHELINES_PER_PAGE entries for an
    exact match with the first cacheline of the page in question?
    radix_tree_gang_lookup() is the right tool for the job, but we need
    nothing more than to check the first entry it can find, reporting if
    that falls anywhere within the page.
    
    (Is RCU safe here? As safe as using the spinlock was. The entries are
    never freed, so don't need to be freed by RCU. They may be reused, and
    there is a faint chance of a race, with an offending entry reused while
    printing its error info; but the spinlock did not prevent that either,
    and I agree that it's not worth worrying about. ]
    
    [ Side noe: this patch is a clear improvement to the status quo, but the
      next patch will be removing this debug function entirely.
    
      But just in case we decide we want to resurrect the debugging code
      some day, I'm first applying this improvement patch so that it doesn't
      get lost    - Linus ]
    
    Fixes: 3b7a6418c749 ("dma debug: account for cachelines and read-only mappings in overlap tracking")
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Acked-by: Dan Williams <dan.j.williams@intel.com>
    Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 1a1206dc4cf02cee4b5cbce583ee4c22368b4c28
Author: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Date:   Thu Jul 30 20:25:17 2020 +0900

    block: don't do revalidate zones on invalid devices
    
    When we loose a device for whatever reason while (re)scanning zones, we
    trip over a NULL pointer in blk_revalidate_zone_cb, like in the following
    log:
    
    sd 0:0:0:0: [sda] 3418095616 4096-byte logical blocks: (14.0 TB/12.7 TiB)
    sd 0:0:0:0: [sda] 52156 zones of 65536 logical blocks
    sd 0:0:0:0: [sda] Write Protect is off
    sd 0:0:0:0: [sda] Mode Sense: 37 00 00 08
    sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
    sd 0:0:0:0: [sda] REPORT ZONES start lba 1065287680 failed
    sd 0:0:0:0: [sda] REPORT ZONES: Result: hostbyte=0x00 driverbyte=0x08
    sd 0:0:0:0: [sda] Sense Key : 0xb [current]
    sd 0:0:0:0: [sda] ASC=0x0 ASCQ=0x6
    sda: failed to revalidate zones
    sd 0:0:0:0: [sda] 0 4096-byte logical blocks: (0 B/0 B)
    sda: detected capacity change from 14000519643136 to 0
    ==================================================================
    BUG: KASAN: null-ptr-deref in blk_revalidate_zone_cb+0x1b7/0x550
    Write of size 8 at addr 0000000000000010 by task kworker/u4:1/58
    
    CPU: 1 PID: 58 Comm: kworker/u4:1 Not tainted 5.8.0-rc1 #692
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.13.0-0-gf21b5a4-rebuilt.opensuse.org 04/01/2014
    Workqueue: events_unbound async_run_entry_fn
    Call Trace:
     dump_stack+0x7d/0xb0
     ? blk_revalidate_zone_cb+0x1b7/0x550
     kasan_report.cold+0x5/0x37
     ? blk_revalidate_zone_cb+0x1b7/0x550
     check_memory_region+0x145/0x1a0
     blk_revalidate_zone_cb+0x1b7/0x550
     sd_zbc_parse_report+0x1f1/0x370
     ? blk_req_zone_write_trylock+0x200/0x200
     ? sectors_to_logical+0x60/0x60
     ? blk_req_zone_write_trylock+0x200/0x200
     ? blk_req_zone_write_trylock+0x200/0x200
     sd_zbc_report_zones+0x3c4/0x5e0
     ? sd_dif_config_host+0x500/0x500
     blk_revalidate_disk_zones+0x231/0x44d
     ? _raw_write_lock_irqsave+0xb0/0xb0
     ? blk_queue_free_zone_bitmaps+0xd0/0xd0
     sd_zbc_read_zones+0x8cf/0x11a0
     sd_revalidate_disk+0x305c/0x64e0
     ? __device_add_disk+0x776/0xf20
     ? read_capacity_16.part.0+0x1080/0x1080
     ? blk_alloc_devt+0x250/0x250
     ? create_object.isra.0+0x595/0xa20
     ? kasan_unpoison_shadow+0x33/0x40
     sd_probe+0x8dc/0xcd2
     really_probe+0x20e/0xaf0
     __driver_attach_async_helper+0x249/0x2d0
     async_run_entry_fn+0xbe/0x560
     process_one_work+0x764/0x1290
     ? _raw_read_unlock_irqrestore+0x30/0x30
     worker_thread+0x598/0x12f0
     ? __kthread_parkme+0xc6/0x1b0
     ? schedule+0xed/0x2c0
     ? process_one_work+0x1290/0x1290
     kthread+0x36b/0x440
     ? kthread_create_worker_on_cpu+0xa0/0xa0
     ret_from_fork+0x22/0x30
    ==================================================================
    
    When the device is already gone we end up with the following scenario:
    The device's capacity is 0 and thus the number of zones will be 0 as well. When
    allocating the bitmap for the conventional zones, we then trip over a NULL
    pointer.
    
    So if we encounter a zoned block device with a 0 capacity, don't dare to
    revalidate the zones sizes.
    
    Fixes: 6c6b35491422 ("block: set the zone size in blk_revalidate_disk_zones atomically")
    Signed-off-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Reviewed-by: Damien Le Moal <damien.lemoal@wdc.com>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 92fa276bc6c62cff4f4e3f6eaf8bdafd57d381ef
Author: Mike Leach <mike.leach@linaro.org>
Date:   Wed Jul 1 10:08:52 2020 -0600

    coresight: etmv4: Fix CPU power management setup in probe() function
    
    commit 9b6a3f3633a5cc928b78627764793b60cb62e0f6 upstream.
    
    The current probe() function calls a pair of cpuhp_xxx API functions to
    setup CPU hotplug handling. The hotplug lock is held for the duration of
    the two calls and other CPU related code using cpus_read_lock() /
    cpus_read_unlock() calls.
    
    The problem is that on error states, goto: statements bypass the
    cpus_read_unlock() call. This code has increased in complexity as the
    driver has developed.
    
    This patch introduces a pair of helper functions etm4_pm_setup_cpuslocked()
    and etm4_pm_clear() which correct the issues above and group the PM code a
    little better.
    
    The two functions etm4_cpu_pm_register() and etm4_cpu_pm_unregister() are
    dropped as these call cpu_pm_register_notifier() / ..unregister_notifier()
    dependent on CONFIG_CPU_PM - but this define is used to nop these functions
    out in the pm headers - so the wrapper functions are superfluous.
    
    Fixes: f188b5e76aae ("coresight: etm4x: Save/restore state across CPU low power states")
    Fixes: e9f5d63f84fe ("hwtracing/coresight-etm4x: Use cpuhp_setup_state_nocalls_cpuslocked()")
    Fixes: 58eb457be028 ("hwtracing/coresight-etm4x: Convert to hotplug state machine")
    Signed-off-by: Mike Leach <mike.leach@linaro.org>
    Cc: stable <stable@vger.kernel.org>
    Reviewed-by: Mathieu Poirier <mathieu.poirier@linaro.org>
    Link: https://lore.kernel.org/r/20200701160852.2782823-3-mathieu.poirier@linaro.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2000bb546525890584a3cf0ce4787270250b582c
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Jun 25 16:12:59 2020 -0700

    bpf, sockmap: RCU splat with redirect and strparser error or TLS
    
    [ Upstream commit 93dd5f185916b05e931cffae636596f21f98546e ]
    
    There are two paths to generate the below RCU splat the first and
    most obvious is the result of the BPF verdict program issuing a
    redirect on a TLS socket (This is the splat shown below). Unlike
    the non-TLS case the caller of the *strp_read() hooks does not
    wrap the call in a rcu_read_lock/unlock. Then if the BPF program
    issues a redirect action we hit the RCU splat.
    
    However, in the non-TLS socket case the splat appears to be
    relatively rare, because the skmsg caller into the strp_data_ready()
    is wrapped in a rcu_read_lock/unlock. Shown here,
    
     static void sk_psock_strp_data_ready(struct sock *sk)
     {
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (likely(psock)) {
                    if (tls_sw_has_ctx_rx(sk)) {
                            psock->parser.saved_data_ready(sk);
                    } else {
                            write_lock_bh(&sk->sk_callback_lock);
                            strp_data_ready(&psock->parser.strp);
                            write_unlock_bh(&sk->sk_callback_lock);
                    }
            }
            rcu_read_unlock();
     }
    
    If the above was the only way to run the verdict program we
    would be safe. But, there is a case where the strparser may throw an
    ENOMEM error while parsing the skb. This is a result of a failed
    skb_clone, or alloc_skb_for_msg while building a new merged skb when
    the msg length needed spans multiple skbs. This will in turn put the
    skb on the strp_wrk workqueue in the strparser code. The skb will
    later be dequeued and verdict programs run, but now from a
    different context without the rcu_read_lock()/unlock() critical
    section in sk_psock_strp_data_ready() shown above. In practice
    I have not seen this yet, because as far as I know most users of the
    verdict programs are also only working on single skbs. In this case no
    merge happens which could trigger the above ENOMEM errors. In addition
    the system would need to be under memory pressure. For example, we
    can't hit the above case in selftests because we missed having tests
    to merge skbs. (Added in later patch)
    
    To fix the below splat extend the rcu_read_lock/unnlock block to
    include the call to sk_psock_tls_verdict_apply(). This will fix both
    TLS redirect case and non-TLS redirect+error case. Also remove
    psock from the sk_psock_tls_verdict_apply() function signature its
    not used there.
    
    [ 1095.937597] WARNING: suspicious RCU usage
    [ 1095.940964] 5.7.0-rc7-02911-g463bac5f1ca79 #1 Tainted: G        W
    [ 1095.944363] -----------------------------
    [ 1095.947384] include/linux/skmsg.h:284 suspicious rcu_dereference_check() usage!
    [ 1095.950866]
    [ 1095.950866] other info that might help us debug this:
    [ 1095.950866]
    [ 1095.957146]
    [ 1095.957146] rcu_scheduler_active = 2, debug_locks = 1
    [ 1095.961482] 1 lock held by test_sockmap/15970:
    [ 1095.964501]  #0: ffff9ea6b25de660 (sk_lock-AF_INET){+.+.}-{0:0}, at: tls_sw_recvmsg+0x13a/0x840 [tls]
    [ 1095.968568]
    [ 1095.968568] stack backtrace:
    [ 1095.975001] CPU: 1 PID: 15970 Comm: test_sockmap Tainted: G        W         5.7.0-rc7-02911-g463bac5f1ca79 #1
    [ 1095.977883] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.12.0-1 04/01/2014
    [ 1095.980519] Call Trace:
    [ 1095.982191]  dump_stack+0x8f/0xd0
    [ 1095.984040]  sk_psock_skb_redirect+0xa6/0xf0
    [ 1095.986073]  sk_psock_tls_strp_read+0x1d8/0x250
    [ 1095.988095]  tls_sw_recvmsg+0x714/0x840 [tls]
    
    v2: Improve commit message to identify non-TLS redirect plus error case
        condition as well as more common TLS case. In the process I decided
        doing the rcu_read_unlock followed by the lock/unlock inside branches
        was unnecessarily complex. We can just extend the current rcu block
        and get the same effeective without the shuffling and branching.
        Thanks Martin!
    
    Fixes: e91de6afa81c1 ("bpf: Fix running sk_skb program types with ktls")
    Reported-by: Jakub Sitnicki <jakub@cloudflare.com>
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/bpf/159312677907.18340.11064813152758406626.stgit@john-XPS-13-9370
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7f1c6b6194807a926deac5363d532c662489a09f
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Jun 25 16:12:59 2020 -0700

    bpf, sockmap: RCU splat with redirect and strparser error or TLS
    
    [ Upstream commit 93dd5f185916b05e931cffae636596f21f98546e ]
    
    There are two paths to generate the below RCU splat the first and
    most obvious is the result of the BPF verdict program issuing a
    redirect on a TLS socket (This is the splat shown below). Unlike
    the non-TLS case the caller of the *strp_read() hooks does not
    wrap the call in a rcu_read_lock/unlock. Then if the BPF program
    issues a redirect action we hit the RCU splat.
    
    However, in the non-TLS socket case the splat appears to be
    relatively rare, because the skmsg caller into the strp_data_ready()
    is wrapped in a rcu_read_lock/unlock. Shown here,
    
     static void sk_psock_strp_data_ready(struct sock *sk)
     {
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (likely(psock)) {
                    if (tls_sw_has_ctx_rx(sk)) {
                            psock->parser.saved_data_ready(sk);
                    } else {
                            write_lock_bh(&sk->sk_callback_lock);
                            strp_data_ready(&psock->parser.strp);
                            write_unlock_bh(&sk->sk_callback_lock);
                    }
            }
            rcu_read_unlock();
     }
    
    If the above was the only way to run the verdict program we
    would be safe. But, there is a case where the strparser may throw an
    ENOMEM error while parsing the skb. This is a result of a failed
    skb_clone, or alloc_skb_for_msg while building a new merged skb when
    the msg length needed spans multiple skbs. This will in turn put the
    skb on the strp_wrk workqueue in the strparser code. The skb will
    later be dequeued and verdict programs run, but now from a
    different context without the rcu_read_lock()/unlock() critical
    section in sk_psock_strp_data_ready() shown above. In practice
    I have not seen this yet, because as far as I know most users of the
    verdict programs are also only working on single skbs. In this case no
    merge happens which could trigger the above ENOMEM errors. In addition
    the system would need to be under memory pressure. For example, we
    can't hit the above case in selftests because we missed having tests
    to merge skbs. (Added in later patch)
    
    To fix the below splat extend the rcu_read_lock/unnlock block to
    include the call to sk_psock_tls_verdict_apply(). This will fix both
    TLS redirect case and non-TLS redirect+error case. Also remove
    psock from the sk_psock_tls_verdict_apply() function signature its
    not used there.
    
    [ 1095.937597] WARNING: suspicious RCU usage
    [ 1095.940964] 5.7.0-rc7-02911-g463bac5f1ca79 #1 Tainted: G        W
    [ 1095.944363] -----------------------------
    [ 1095.947384] include/linux/skmsg.h:284 suspicious rcu_dereference_check() usage!
    [ 1095.950866]
    [ 1095.950866] other info that might help us debug this:
    [ 1095.950866]
    [ 1095.957146]
    [ 1095.957146] rcu_scheduler_active = 2, debug_locks = 1
    [ 1095.961482] 1 lock held by test_sockmap/15970:
    [ 1095.964501]  #0: ffff9ea6b25de660 (sk_lock-AF_INET){+.+.}-{0:0}, at: tls_sw_recvmsg+0x13a/0x840 [tls]
    [ 1095.968568]
    [ 1095.968568] stack backtrace:
    [ 1095.975001] CPU: 1 PID: 15970 Comm: test_sockmap Tainted: G        W         5.7.0-rc7-02911-g463bac5f1ca79 #1
    [ 1095.977883] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.12.0-1 04/01/2014
    [ 1095.980519] Call Trace:
    [ 1095.982191]  dump_stack+0x8f/0xd0
    [ 1095.984040]  sk_psock_skb_redirect+0xa6/0xf0
    [ 1095.986073]  sk_psock_tls_strp_read+0x1d8/0x250
    [ 1095.988095]  tls_sw_recvmsg+0x714/0x840 [tls]
    
    v2: Improve commit message to identify non-TLS redirect plus error case
        condition as well as more common TLS case. In the process I decided
        doing the rcu_read_unlock followed by the lock/unlock inside branches
        was unnecessarily complex. We can just extend the current rcu block
        and get the same effeective without the shuffling and branching.
        Thanks Martin!
    
    Fixes: e91de6afa81c1 ("bpf: Fix running sk_skb program types with ktls")
    Reported-by: Jakub Sitnicki <jakub@cloudflare.com>
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/bpf/159312677907.18340.11064813152758406626.stgit@john-XPS-13-9370
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d47a72152097d7be7cfc453d205196c0aa976c33
Author: Davide Caratti <dcaratti@redhat.com>
Date:   Mon Jul 6 21:06:12 2020 +0200

    mptcp: fix race in subflow_data_ready()
    
    syzkaller was able to make the kernel reach subflow_data_ready() for a
    server subflow that was closed before subflow_finish_connect() completed.
    In these cases we can avoid using the path for regular/fallback MPTCP
    data, and just wake the main socket, to avoid the following warning:
    
     WARNING: CPU: 0 PID: 9370 at net/mptcp/subflow.c:885
     subflow_data_ready+0x1e6/0x290 net/mptcp/subflow.c:885
     Kernel panic - not syncing: panic_on_warn set ...
     CPU: 0 PID: 9370 Comm: syz-executor.0 Not tainted 5.7.0 #106
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
     rel-1.12.1-0-ga5cab58e9a3f-prebuilt.qemu.org 04/01/2014
     Call Trace:
      <IRQ>
      __dump_stack lib/dump_stack.c:77 [inline]
      dump_stack+0xb7/0xfe lib/dump_stack.c:118
      panic+0x29e/0x692 kernel/panic.c:221
      __warn.cold+0x2f/0x3d kernel/panic.c:582
      report_bug+0x28b/0x2f0 lib/bug.c:195
      fixup_bug arch/x86/kernel/traps.c:105 [inline]
      fixup_bug arch/x86/kernel/traps.c:100 [inline]
      do_error_trap+0x10f/0x180 arch/x86/kernel/traps.c:197
      do_invalid_op+0x32/0x40 arch/x86/kernel/traps.c:216
      invalid_op+0x1e/0x30 arch/x86/entry/entry_64.S:1027
     RIP: 0010:subflow_data_ready+0x1e6/0x290 net/mptcp/subflow.c:885
     Code: 04 02 84 c0 74 06 0f 8e 91 00 00 00 41 0f b6 5e 48 31 ff 83 e3 18
     89 de e8 37 ec 3d fe 84 db 0f 85 65 ff ff ff e8 fa ea 3d fe <0f> 0b e9
     59 ff ff ff e8 ee ea 3d fe 48 89 ee 4c 89 ef e8 f3 77 ff
     RSP: 0018:ffff88811b2099b0 EFLAGS: 00010206
     RAX: ffff888111197000 RBX: 0000000000000000 RCX: ffffffff82fbc609
     RDX: 0000000000000100 RSI: ffffffff82fbc616 RDI: 0000000000000001
     RBP: ffff8881111bc800 R08: ffff888111197000 R09: ffffed10222a82af
     R10: ffff888111541577 R11: ffffed10222a82ae R12: 1ffff11023641336
     R13: ffff888111541000 R14: ffff88810fd4ca00 R15: ffff888111541570
      tcp_child_process+0x754/0x920 net/ipv4/tcp_minisocks.c:841
      tcp_v4_do_rcv+0x749/0x8b0 net/ipv4/tcp_ipv4.c:1642
      tcp_v4_rcv+0x2666/0x2e60 net/ipv4/tcp_ipv4.c:1999
      ip_protocol_deliver_rcu+0x29/0x1f0 net/ipv4/ip_input.c:204
      ip_local_deliver_finish net/ipv4/ip_input.c:231 [inline]
      NF_HOOK include/linux/netfilter.h:421 [inline]
      ip_local_deliver+0x2da/0x390 net/ipv4/ip_input.c:252
      dst_input include/net/dst.h:441 [inline]
      ip_rcv_finish net/ipv4/ip_input.c:428 [inline]
      ip_rcv_finish net/ipv4/ip_input.c:414 [inline]
      NF_HOOK include/linux/netfilter.h:421 [inline]
      ip_rcv+0xef/0x140 net/ipv4/ip_input.c:539
      __netif_receive_skb_one_core+0x197/0x1e0 net/core/dev.c:5268
      __netif_receive_skb+0x27/0x1c0 net/core/dev.c:5382
      process_backlog+0x1e5/0x6d0 net/core/dev.c:6226
      napi_poll net/core/dev.c:6671 [inline]
      net_rx_action+0x3e3/0xd70 net/core/dev.c:6739
      __do_softirq+0x18c/0x634 kernel/softirq.c:292
      do_softirq_own_stack+0x2a/0x40 arch/x86/entry/entry_64.S:1082
      </IRQ>
      do_softirq.part.0+0x26/0x30 kernel/softirq.c:337
      do_softirq arch/x86/include/asm/preempt.h:26 [inline]
      __local_bh_enable_ip+0x46/0x50 kernel/softirq.c:189
      local_bh_enable include/linux/bottom_half.h:32 [inline]
      rcu_read_unlock_bh include/linux/rcupdate.h:723 [inline]
      ip_finish_output2+0x78a/0x19c0 net/ipv4/ip_output.c:229
      __ip_finish_output+0x471/0x720 net/ipv4/ip_output.c:306
      dst_output include/net/dst.h:435 [inline]
      ip_local_out+0x181/0x1e0 net/ipv4/ip_output.c:125
      __ip_queue_xmit+0x7a1/0x14e0 net/ipv4/ip_output.c:530
      __tcp_transmit_skb+0x19dc/0x35e0 net/ipv4/tcp_output.c:1238
      __tcp_send_ack.part.0+0x3c2/0x5b0 net/ipv4/tcp_output.c:3785
      __tcp_send_ack net/ipv4/tcp_output.c:3791 [inline]
      tcp_send_ack+0x7d/0xa0 net/ipv4/tcp_output.c:3791
      tcp_rcv_synsent_state_process net/ipv4/tcp_input.c:6040 [inline]
      tcp_rcv_state_process+0x36a4/0x49c2 net/ipv4/tcp_input.c:6209
      tcp_v4_do_rcv+0x343/0x8b0 net/ipv4/tcp_ipv4.c:1651
      sk_backlog_rcv include/net/sock.h:996 [inline]
      __release_sock+0x1ad/0x310 net/core/sock.c:2548
      release_sock+0x54/0x1a0 net/core/sock.c:3064
      inet_wait_for_connect net/ipv4/af_inet.c:594 [inline]
      __inet_stream_connect+0x57e/0xd50 net/ipv4/af_inet.c:686
      inet_stream_connect+0x53/0xa0 net/ipv4/af_inet.c:725
      mptcp_stream_connect+0x171/0x5f0 net/mptcp/protocol.c:1920
      __sys_connect_file net/socket.c:1854 [inline]
      __sys_connect+0x267/0x2f0 net/socket.c:1871
      __do_sys_connect net/socket.c:1882 [inline]
      __se_sys_connect net/socket.c:1879 [inline]
      __x64_sys_connect+0x6f/0xb0 net/socket.c:1879
      do_syscall_64+0xb7/0x3d0 arch/x86/entry/common.c:295
      entry_SYSCALL_64_after_hwframe+0x44/0xa9
     RIP: 0033:0x7fb577d06469
     Code: 00 f3 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 40 00 48 89 f8 48 89
     f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01
     f0 ff ff 73 01 c3 48 8b 0d ff 49 2b 00 f7 d8 64 89 01 48
     RSP: 002b:00007fb5783d5dd8 EFLAGS: 00000246 ORIG_RAX: 000000000000002a
     RAX: ffffffffffffffda RBX: 000000000068bfa0 RCX: 00007fb577d06469
     RDX: 000000000000004d RSI: 0000000020000040 RDI: 0000000000000003
     RBP: 00000000ffffffff R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000000
     R13: 000000000041427c R14: 00007fb5783d65c0 R15: 0000000000000003
    
    Closes: https://github.com/multipath-tcp/mptcp_net-next/issues/39
    Reported-by: Christoph Paasch <cpaasch@apple.com>
    Fixes: e1ff9e82e2ea ("net: mptcp: improve fallback to TCP")
    Suggested-by: Paolo Abeni <pabeni@redhat.com>
    Signed-off-by: Davide Caratti <dcaratti@redhat.com>
    Reviewed-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 9b6a3f3633a5cc928b78627764793b60cb62e0f6
Author: Mike Leach <mike.leach@linaro.org>
Date:   Wed Jul 1 10:08:52 2020 -0600

    coresight: etmv4: Fix CPU power management setup in probe() function
    
    The current probe() function calls a pair of cpuhp_xxx API functions to
    setup CPU hotplug handling. The hotplug lock is held for the duration of
    the two calls and other CPU related code using cpus_read_lock() /
    cpus_read_unlock() calls.
    
    The problem is that on error states, goto: statements bypass the
    cpus_read_unlock() call. This code has increased in complexity as the
    driver has developed.
    
    This patch introduces a pair of helper functions etm4_pm_setup_cpuslocked()
    and etm4_pm_clear() which correct the issues above and group the PM code a
    little better.
    
    The two functions etm4_cpu_pm_register() and etm4_cpu_pm_unregister() are
    dropped as these call cpu_pm_register_notifier() / ..unregister_notifier()
    dependent on CONFIG_CPU_PM - but this define is used to nop these functions
    out in the pm headers - so the wrapper functions are superfluous.
    
    Fixes: f188b5e76aae ("coresight: etm4x: Save/restore state across CPU low power states")
    Fixes: e9f5d63f84fe ("hwtracing/coresight-etm4x: Use cpuhp_setup_state_nocalls_cpuslocked()")
    Fixes: 58eb457be028 ("hwtracing/coresight-etm4x: Convert to hotplug state machine")
    Signed-off-by: Mike Leach <mike.leach@linaro.org>
    Cc: stable <stable@vger.kernel.org>
    Reviewed-by: Mathieu Poirier <mathieu.poirier@linaro.org>
    Link: https://lore.kernel.org/r/20200701160852.2782823-3-mathieu.poirier@linaro.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c7dcf8106f7570b133b05ff68fd4100064965d9d
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Jun 12 13:11:29 2020 -0700

    rcu-tasks: Fix synchronize_rcu_tasks_trace() header comment
    
    The synchronize_rcu_tasks_trace() header comment incorrectly claims that
    any number of things delimit RCU Tasks Trace read-side critical sections,
    when in fact only rcu_read_lock_trace() and rcu_read_unlock_trace() do so.
    This commit therefore fixes this comment, and, while in the area, fixes
    a typo in the rcu_read_lock_trace() header comment.
    
    Reported-by: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 83b88c86da0e5f97faeac5a9bb19fe32f8c0394b
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon May 25 15:31:07 2020 -0700

    refperf: Allow decimal nanoseconds
    
    The CONFIG_PREEMPT=n rcu_read_lock()/rcu_read_unlock() pair's overhead,
    even including loop overhead, is far less than one nanosecond.
    Since logscale plots are not all that happy with zero values, provide
    picoseconds as decimals.
    
    Cc: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 75dd8efef56ed5959c398974c785026f84aa0d1a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon May 25 14:59:06 2020 -0700

    refperf: Hoist function-pointer calls out of the loop
    
    Current runs show PREEMPT=n rcu_read_lock()/rcu_read_unlock() pairs
    consuming between 20 and 30 nanoseconds, when in fact the actual value is
    zero, give or take the barrier() asm's effect on compiler optimizations.
    The additional overhead is caused by function calls through pointers
    (especially in these days of Spectre mitigations) and perhaps also
    needless argument passing, a non-const loop limit, and an upcounting loop.
    
    This commit therefore combines the ->readlock() and ->readunlock()
    function pointers into a single ->readsection() function pointer that
    takes the loop count as a const parameter and keeps any data passed
    from the read-lock to the read-unlock internal to this new function.
    
    These changes reduce the measured overhead of the aforementioned
    PREEMPT=n rcu_read_lock()/rcu_read_unlock() pairs from between 20 and
    30 nanoseconds to somewhere south of 500 picoseconds.
    
    Cc: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 93dd5f185916b05e931cffae636596f21f98546e
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Jun 25 16:12:59 2020 -0700

    bpf, sockmap: RCU splat with redirect and strparser error or TLS
    
    There are two paths to generate the below RCU splat the first and
    most obvious is the result of the BPF verdict program issuing a
    redirect on a TLS socket (This is the splat shown below). Unlike
    the non-TLS case the caller of the *strp_read() hooks does not
    wrap the call in a rcu_read_lock/unlock. Then if the BPF program
    issues a redirect action we hit the RCU splat.
    
    However, in the non-TLS socket case the splat appears to be
    relatively rare, because the skmsg caller into the strp_data_ready()
    is wrapped in a rcu_read_lock/unlock. Shown here,
    
     static void sk_psock_strp_data_ready(struct sock *sk)
     {
            struct sk_psock *psock;
    
            rcu_read_lock();
            psock = sk_psock(sk);
            if (likely(psock)) {
                    if (tls_sw_has_ctx_rx(sk)) {
                            psock->parser.saved_data_ready(sk);
                    } else {
                            write_lock_bh(&sk->sk_callback_lock);
                            strp_data_ready(&psock->parser.strp);
                            write_unlock_bh(&sk->sk_callback_lock);
                    }
            }
            rcu_read_unlock();
     }
    
    If the above was the only way to run the verdict program we
    would be safe. But, there is a case where the strparser may throw an
    ENOMEM error while parsing the skb. This is a result of a failed
    skb_clone, or alloc_skb_for_msg while building a new merged skb when
    the msg length needed spans multiple skbs. This will in turn put the
    skb on the strp_wrk workqueue in the strparser code. The skb will
    later be dequeued and verdict programs run, but now from a
    different context without the rcu_read_lock()/unlock() critical
    section in sk_psock_strp_data_ready() shown above. In practice
    I have not seen this yet, because as far as I know most users of the
    verdict programs are also only working on single skbs. In this case no
    merge happens which could trigger the above ENOMEM errors. In addition
    the system would need to be under memory pressure. For example, we
    can't hit the above case in selftests because we missed having tests
    to merge skbs. (Added in later patch)
    
    To fix the below splat extend the rcu_read_lock/unnlock block to
    include the call to sk_psock_tls_verdict_apply(). This will fix both
    TLS redirect case and non-TLS redirect+error case. Also remove
    psock from the sk_psock_tls_verdict_apply() function signature its
    not used there.
    
    [ 1095.937597] WARNING: suspicious RCU usage
    [ 1095.940964] 5.7.0-rc7-02911-g463bac5f1ca79 #1 Tainted: G        W
    [ 1095.944363] -----------------------------
    [ 1095.947384] include/linux/skmsg.h:284 suspicious rcu_dereference_check() usage!
    [ 1095.950866]
    [ 1095.950866] other info that might help us debug this:
    [ 1095.950866]
    [ 1095.957146]
    [ 1095.957146] rcu_scheduler_active = 2, debug_locks = 1
    [ 1095.961482] 1 lock held by test_sockmap/15970:
    [ 1095.964501]  #0: ffff9ea6b25de660 (sk_lock-AF_INET){+.+.}-{0:0}, at: tls_sw_recvmsg+0x13a/0x840 [tls]
    [ 1095.968568]
    [ 1095.968568] stack backtrace:
    [ 1095.975001] CPU: 1 PID: 15970 Comm: test_sockmap Tainted: G        W         5.7.0-rc7-02911-g463bac5f1ca79 #1
    [ 1095.977883] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.12.0-1 04/01/2014
    [ 1095.980519] Call Trace:
    [ 1095.982191]  dump_stack+0x8f/0xd0
    [ 1095.984040]  sk_psock_skb_redirect+0xa6/0xf0
    [ 1095.986073]  sk_psock_tls_strp_read+0x1d8/0x250
    [ 1095.988095]  tls_sw_recvmsg+0x714/0x840 [tls]
    
    v2: Improve commit message to identify non-TLS redirect plus error case
        condition as well as more common TLS case. In the process I decided
        doing the rcu_read_unlock followed by the lock/unlock inside branches
        was unnecessarily complex. We can just extend the current rcu block
        and get the same effeective without the shuffling and branching.
        Thanks Martin!
    
    Fixes: e91de6afa81c1 ("bpf: Fix running sk_skb program types with ktls")
    Reported-by: Jakub Sitnicki <jakub@cloudflare.com>
    Reported-by: kernel test robot <rong.a.chen@intel.com>
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Acked-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/bpf/159312677907.18340.11064813152758406626.stgit@john-XPS-13-9370

commit 0cc55a0213a02b760ade1d4755fdccfbf7d3157e
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:37 2020 -0700

    mmap locking API: add mmap_read_trylock_non_owner()
    
    Add a couple APIs used by kernel/bpf/stackmap.c only:
    - mmap_read_trylock_non_owner()
    - mmap_read_unlock_non_owner() (may be called from a work queue).
    
    It's still not ideal that bpf/stackmap subverts the lock ownership in this
    way.  Thanks to Peter Zijlstra for suggesting this API as the least-ugly
    way of addressing this in the short term.
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Laurent Dufour <ldufour@linux.ibm.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-8-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit d8ed45c5dcd455fc5848d47f86883a1b872ac0d0
Author: Michel Lespinasse <walken@google.com>
Date:   Mon Jun 8 21:33:25 2020 -0700

    mmap locking API: use coccinelle to convert mmap_sem rwsem call sites
    
    This change converts the existing mmap_sem rwsem calls to use the new mmap
    locking API instead.
    
    The change is generated using coccinelle with the following rule:
    
    // spatch --sp-file mmap_lock_api.cocci --in-place --include-headers --dir .
    
    @@
    expression mm;
    @@
    (
    -init_rwsem
    +mmap_init_lock
    |
    -down_write
    +mmap_write_lock
    |
    -down_write_killable
    +mmap_write_lock_killable
    |
    -down_write_trylock
    +mmap_write_trylock
    |
    -up_write
    +mmap_write_unlock
    |
    -downgrade_write
    +mmap_write_downgrade
    |
    -down_read
    +mmap_read_lock
    |
    -down_read_killable
    +mmap_read_lock_killable
    |
    -down_read_trylock
    +mmap_read_trylock
    |
    -up_read
    +mmap_read_unlock
    )
    -(&mm->mmap_sem)
    +(mm)
    
    Signed-off-by: Michel Lespinasse <walken@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Daniel Jordan <daniel.m.jordan@oracle.com>
    Reviewed-by: Laurent Dufour <ldufour@linux.ibm.com>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Davidlohr Bueso <dbueso@suse.de>
    Cc: David Rientjes <rientjes@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Jason Gunthorpe <jgg@ziepe.ca>
    Cc: Jerome Glisse <jglisse@redhat.com>
    Cc: John Hubbard <jhubbard@nvidia.com>
    Cc: Liam Howlett <Liam.Howlett@oracle.com>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Ying Han <yinghan@google.com>
    Link: http://lkml.kernel.org/r/20200520052908.204642-5-walken@google.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit c6da756cfb140da1f596b347b0d3d55ec641f642
Author: Linus Lssing <ll@simonwunderlich.de>
Date:   Fri May 22 19:04:13 2020 +0200

    mac80211: mesh: fix discovery timer re-arming issue / crash
    
    commit e2d4a80f93fcfaf72e2e20daf6a28e39c3b90677 upstream.
    
    On a non-forwarding 802.11s link between two fairly busy
    neighboring nodes (iperf with -P 16 at ~850MBit/s TCP;
    1733.3 MBit/s VHT-MCS 9 80MHz short GI VHT-NSS 4), so with
    frequent PREQ retries, usually after around 30-40 seconds the
    following crash would occur:
    
    [ 1110.822428] Unable to handle kernel read from unreadable memory at virtual address 00000000
    [ 1110.830786] Mem abort info:
    [ 1110.833573]   Exception class = IABT (current EL), IL = 32 bits
    [ 1110.839494]   SET = 0, FnV = 0
    [ 1110.842546]   EA = 0, S1PTW = 0
    [ 1110.845678] user pgtable: 4k pages, 48-bit VAs, pgd = ffff800076386000
    [ 1110.852204] [0000000000000000] *pgd=00000000f6322003, *pud=00000000f62de003, *pmd=0000000000000000
    [ 1110.861167] Internal error: Oops: 86000004 [#1] PREEMPT SMP
    [ 1110.866730] Modules linked in: pppoe ppp_async batman_adv ath10k_pci ath10k_core ath pppox ppp_generic nf_conntrack_ipv6 mac80211 iptable_nat ipt_REJECT ipt_MASQUERADE cfg80211 xt_time xt_tcpudp xt_state xt_nat xt_multiport xt_mark xt_mac xt_limit xt_conntrack xt_comment xt_TCPMSS xt_REDIRECT xt_LOG xt_FLOWOFFLOAD slhc nf_reject_ipv4 nf_nat_redirect nf_nat_masquerade_ipv4 nf_conntrack_ipv4 nf_nat_ipv4 nf_nat nf_log_ipv4 nf_flow_table_hw nf_flow_table nf_defrag_ipv6 nf_defrag_ipv4 nf_conntrack_rtcache nf_conntrack iptable_mangle iptable_filter ip_tables crc_ccitt compat nf_log_ipv6 nf_log_common ip6table_mangle ip6table_filter ip6_tables ip6t_REJECT x_tables nf_reject_ipv6 usb_storage xhci_plat_hcd xhci_pci xhci_hcd dwc3 usbcore usb_common
    [ 1110.932190] Process swapper/3 (pid: 0, stack limit = 0xffff0000090c8000)
    [ 1110.938884] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 4.14.162 #0
    [ 1110.944965] Hardware name: LS1043A RGW Board (DT)
    [ 1110.949658] task: ffff8000787a81c0 task.stack: ffff0000090c8000
    [ 1110.955568] PC is at 0x0
    [ 1110.958097] LR is at call_timer_fn.isra.27+0x24/0x78
    [ 1110.963055] pc : [<0000000000000000>] lr : [<ffff0000080ff29c>] pstate: 00400145
    [ 1110.970440] sp : ffff00000801be10
    [ 1110.973744] x29: ffff00000801be10 x28: ffff000008bf7018
    [ 1110.979047] x27: ffff000008bf87c8 x26: ffff000008c160c0
    [ 1110.984352] x25: 0000000000000000 x24: 0000000000000000
    [ 1110.989657] x23: dead000000000200 x22: 0000000000000000
    [ 1110.994959] x21: 0000000000000000 x20: 0000000000000101
    [ 1111.000262] x19: ffff8000787a81c0 x18: 0000000000000000
    [ 1111.005565] x17: ffff0000089167b0 x16: 0000000000000058
    [ 1111.010868] x15: ffff0000089167b0 x14: 0000000000000000
    [ 1111.016172] x13: ffff000008916788 x12: 0000000000000040
    [ 1111.021475] x11: ffff80007fda9af0 x10: 0000000000000001
    [ 1111.026777] x9 : ffff00000801bea0 x8 : 0000000000000004
    [ 1111.032080] x7 : 0000000000000000 x6 : ffff80007fda9aa8
    [ 1111.037383] x5 : ffff00000801bea0 x4 : 0000000000000010
    [ 1111.042685] x3 : ffff00000801be98 x2 : 0000000000000614
    [ 1111.047988] x1 : 0000000000000000 x0 : 0000000000000000
    [ 1111.053290] Call trace:
    [ 1111.055728] Exception stack(0xffff00000801bcd0 to 0xffff00000801be10)
    [ 1111.062158] bcc0:                                   0000000000000000 0000000000000000
    [ 1111.069978] bce0: 0000000000000614 ffff00000801be98 0000000000000010 ffff00000801bea0
    [ 1111.077798] bd00: ffff80007fda9aa8 0000000000000000 0000000000000004 ffff00000801bea0
    [ 1111.085618] bd20: 0000000000000001 ffff80007fda9af0 0000000000000040 ffff000008916788
    [ 1111.093437] bd40: 0000000000000000 ffff0000089167b0 0000000000000058 ffff0000089167b0
    [ 1111.101256] bd60: 0000000000000000 ffff8000787a81c0 0000000000000101 0000000000000000
    [ 1111.109075] bd80: 0000000000000000 dead000000000200 0000000000000000 0000000000000000
    [ 1111.116895] bda0: ffff000008c160c0 ffff000008bf87c8 ffff000008bf7018 ffff00000801be10
    [ 1111.124715] bdc0: ffff0000080ff29c ffff00000801be10 0000000000000000 0000000000400145
    [ 1111.132534] bde0: ffff8000787a81c0 ffff00000801bde8 0000ffffffffffff 000001029eb19be8
    [ 1111.140353] be00: ffff00000801be10 0000000000000000
    [ 1111.145220] [<          (null)>]           (null)
    [ 1111.149917] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [ 1111.155741] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [ 1111.161130] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [ 1111.166002] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [ 1111.171825] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    [ 1111.177213] Exception stack(0xffff0000090cbe30 to 0xffff0000090cbf70)
    [ 1111.183642] be20:                                   0000000000000020 0000000000000000
    [ 1111.191461] be40: 0000000000000001 0000000000000000 00008000771af000 0000000000000000
    [ 1111.199281] be60: ffff000008c95180 0000000000000000 ffff000008c19360 ffff0000090cbef0
    [ 1111.207101] be80: 0000000000000810 0000000000000400 0000000000000098 ffff000000000000
    [ 1111.214920] bea0: 0000000000000001 ffff0000089167b0 0000000000000000 ffff0000089167b0
    [ 1111.222740] bec0: 0000000000000000 ffff000008c198e8 ffff000008bf7018 ffff000008c19000
    [ 1111.230559] bee0: 0000000000000000 0000000000000000 ffff8000787a81c0 ffff000008018000
    [ 1111.238380] bf00: ffff00000801c000 ffff00000913ba34 ffff8000787a81c0 ffff0000090cbf70
    [ 1111.246199] bf20: ffff0000080857cc ffff0000090cbf70 ffff0000080857d0 0000000000400145
    [ 1111.254020] bf40: ffff000008018000 ffff00000801c000 ffffffffffffffff ffff0000080fa574
    [ 1111.261838] bf60: ffff0000090cbf70 ffff0000080857d0
    [ 1111.266706] [<ffff0000080832e8>] el1_irq+0xe8/0x18c
    [ 1111.271576] [<ffff0000080857d0>] arch_cpu_idle+0x10/0x18
    [ 1111.276880] [<ffff0000080d7de4>] do_idle+0xec/0x1b8
    [ 1111.281748] [<ffff0000080d8020>] cpu_startup_entry+0x20/0x28
    [ 1111.287399] [<ffff00000808f81c>] secondary_start_kernel+0x104/0x110
    [ 1111.293662] Code: bad PC value
    [ 1111.296710] ---[ end trace 555b6ca4363c3edd ]---
    [ 1111.301318] Kernel panic - not syncing: Fatal exception in interrupt
    [ 1111.307661] SMP: stopping secondary CPUs
    [ 1111.311574] Kernel Offset: disabled
    [ 1111.315053] CPU features: 0x0002000
    [ 1111.318530] Memory Limit: none
    [ 1111.321575] Rebooting in 3 seconds..
    
    With some added debug output / delays we were able to push the crash from
    the timer callback runner into the callback function and by that shedding
    some light on which object holding the timer gets corrupted:
    
    [  401.720899] Unable to handle kernel read from unreadable memory at virtual address 00000868
    [...]
    [  402.335836] [<ffff0000088fafa4>] _raw_spin_lock_bh+0x14/0x48
    [  402.341548] [<ffff000000dbe684>] mesh_path_timer+0x10c/0x248 [mac80211]
    [  402.348154] [<ffff0000080ff29c>] call_timer_fn.isra.27+0x24/0x78
    [  402.354150] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [  402.359974] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [  402.365362] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [  402.370231] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [  402.376053] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    
    The issue happens due to the following sequence of events:
    
    1) mesh_path_start_discovery():
    -> spin_unlock_bh(&mpath->state_lock) before mesh_path_sel_frame_tx()
    
    2) mesh_path_free_rcu()
    -> del_timer_sync(&mpath->timer)
       [...]
    -> kfree_rcu(mpath)
    
    3) mesh_path_start_discovery():
    -> mod_timer(&mpath->timer, ...)
       [...]
    -> rcu_read_unlock()
    
    4) mesh_path_free_rcu()'s kfree_rcu():
    -> kfree(mpath)
    
    5) mesh_path_timer() starts after timeout, using freed mpath object
    
    So a use-after-free issue due to a timer re-arming bug caused by an
    early spin-unlocking.
    
    This patch fixes this issue by re-checking if mpath is about to be
    free'd and if so bails out of re-arming the timer.
    
    Cc: stable@vger.kernel.org
    Fixes: 050ac52cbe1f ("mac80211: code for on-demand Hybrid Wireless Mesh Protocol")
    Cc: Simon Wunderlich <sw@simonwunderlich.de>
    Signed-off-by: Linus Lssing <ll@simonwunderlich.de>
    Link: https://lore.kernel.org/r/20200522170413.14973-1-linus.luessing@c0d3.blue
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e980f9cb2f2d51014689e85ae6169bf862b5661d
Author: Linus Lssing <ll@simonwunderlich.de>
Date:   Fri May 22 19:04:13 2020 +0200

    mac80211: mesh: fix discovery timer re-arming issue / crash
    
    commit e2d4a80f93fcfaf72e2e20daf6a28e39c3b90677 upstream.
    
    On a non-forwarding 802.11s link between two fairly busy
    neighboring nodes (iperf with -P 16 at ~850MBit/s TCP;
    1733.3 MBit/s VHT-MCS 9 80MHz short GI VHT-NSS 4), so with
    frequent PREQ retries, usually after around 30-40 seconds the
    following crash would occur:
    
    [ 1110.822428] Unable to handle kernel read from unreadable memory at virtual address 00000000
    [ 1110.830786] Mem abort info:
    [ 1110.833573]   Exception class = IABT (current EL), IL = 32 bits
    [ 1110.839494]   SET = 0, FnV = 0
    [ 1110.842546]   EA = 0, S1PTW = 0
    [ 1110.845678] user pgtable: 4k pages, 48-bit VAs, pgd = ffff800076386000
    [ 1110.852204] [0000000000000000] *pgd=00000000f6322003, *pud=00000000f62de003, *pmd=0000000000000000
    [ 1110.861167] Internal error: Oops: 86000004 [#1] PREEMPT SMP
    [ 1110.866730] Modules linked in: pppoe ppp_async batman_adv ath10k_pci ath10k_core ath pppox ppp_generic nf_conntrack_ipv6 mac80211 iptable_nat ipt_REJECT ipt_MASQUERADE cfg80211 xt_time xt_tcpudp xt_state xt_nat xt_multiport xt_mark xt_mac xt_limit xt_conntrack xt_comment xt_TCPMSS xt_REDIRECT xt_LOG xt_FLOWOFFLOAD slhc nf_reject_ipv4 nf_nat_redirect nf_nat_masquerade_ipv4 nf_conntrack_ipv4 nf_nat_ipv4 nf_nat nf_log_ipv4 nf_flow_table_hw nf_flow_table nf_defrag_ipv6 nf_defrag_ipv4 nf_conntrack_rtcache nf_conntrack iptable_mangle iptable_filter ip_tables crc_ccitt compat nf_log_ipv6 nf_log_common ip6table_mangle ip6table_filter ip6_tables ip6t_REJECT x_tables nf_reject_ipv6 usb_storage xhci_plat_hcd xhci_pci xhci_hcd dwc3 usbcore usb_common
    [ 1110.932190] Process swapper/3 (pid: 0, stack limit = 0xffff0000090c8000)
    [ 1110.938884] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 4.14.162 #0
    [ 1110.944965] Hardware name: LS1043A RGW Board (DT)
    [ 1110.949658] task: ffff8000787a81c0 task.stack: ffff0000090c8000
    [ 1110.955568] PC is at 0x0
    [ 1110.958097] LR is at call_timer_fn.isra.27+0x24/0x78
    [ 1110.963055] pc : [<0000000000000000>] lr : [<ffff0000080ff29c>] pstate: 00400145
    [ 1110.970440] sp : ffff00000801be10
    [ 1110.973744] x29: ffff00000801be10 x28: ffff000008bf7018
    [ 1110.979047] x27: ffff000008bf87c8 x26: ffff000008c160c0
    [ 1110.984352] x25: 0000000000000000 x24: 0000000000000000
    [ 1110.989657] x23: dead000000000200 x22: 0000000000000000
    [ 1110.994959] x21: 0000000000000000 x20: 0000000000000101
    [ 1111.000262] x19: ffff8000787a81c0 x18: 0000000000000000
    [ 1111.005565] x17: ffff0000089167b0 x16: 0000000000000058
    [ 1111.010868] x15: ffff0000089167b0 x14: 0000000000000000
    [ 1111.016172] x13: ffff000008916788 x12: 0000000000000040
    [ 1111.021475] x11: ffff80007fda9af0 x10: 0000000000000001
    [ 1111.026777] x9 : ffff00000801bea0 x8 : 0000000000000004
    [ 1111.032080] x7 : 0000000000000000 x6 : ffff80007fda9aa8
    [ 1111.037383] x5 : ffff00000801bea0 x4 : 0000000000000010
    [ 1111.042685] x3 : ffff00000801be98 x2 : 0000000000000614
    [ 1111.047988] x1 : 0000000000000000 x0 : 0000000000000000
    [ 1111.053290] Call trace:
    [ 1111.055728] Exception stack(0xffff00000801bcd0 to 0xffff00000801be10)
    [ 1111.062158] bcc0:                                   0000000000000000 0000000000000000
    [ 1111.069978] bce0: 0000000000000614 ffff00000801be98 0000000000000010 ffff00000801bea0
    [ 1111.077798] bd00: ffff80007fda9aa8 0000000000000000 0000000000000004 ffff00000801bea0
    [ 1111.085618] bd20: 0000000000000001 ffff80007fda9af0 0000000000000040 ffff000008916788
    [ 1111.093437] bd40: 0000000000000000 ffff0000089167b0 0000000000000058 ffff0000089167b0
    [ 1111.101256] bd60: 0000000000000000 ffff8000787a81c0 0000000000000101 0000000000000000
    [ 1111.109075] bd80: 0000000000000000 dead000000000200 0000000000000000 0000000000000000
    [ 1111.116895] bda0: ffff000008c160c0 ffff000008bf87c8 ffff000008bf7018 ffff00000801be10
    [ 1111.124715] bdc0: ffff0000080ff29c ffff00000801be10 0000000000000000 0000000000400145
    [ 1111.132534] bde0: ffff8000787a81c0 ffff00000801bde8 0000ffffffffffff 000001029eb19be8
    [ 1111.140353] be00: ffff00000801be10 0000000000000000
    [ 1111.145220] [<          (null)>]           (null)
    [ 1111.149917] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [ 1111.155741] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [ 1111.161130] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [ 1111.166002] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [ 1111.171825] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    [ 1111.177213] Exception stack(0xffff0000090cbe30 to 0xffff0000090cbf70)
    [ 1111.183642] be20:                                   0000000000000020 0000000000000000
    [ 1111.191461] be40: 0000000000000001 0000000000000000 00008000771af000 0000000000000000
    [ 1111.199281] be60: ffff000008c95180 0000000000000000 ffff000008c19360 ffff0000090cbef0
    [ 1111.207101] be80: 0000000000000810 0000000000000400 0000000000000098 ffff000000000000
    [ 1111.214920] bea0: 0000000000000001 ffff0000089167b0 0000000000000000 ffff0000089167b0
    [ 1111.222740] bec0: 0000000000000000 ffff000008c198e8 ffff000008bf7018 ffff000008c19000
    [ 1111.230559] bee0: 0000000000000000 0000000000000000 ffff8000787a81c0 ffff000008018000
    [ 1111.238380] bf00: ffff00000801c000 ffff00000913ba34 ffff8000787a81c0 ffff0000090cbf70
    [ 1111.246199] bf20: ffff0000080857cc ffff0000090cbf70 ffff0000080857d0 0000000000400145
    [ 1111.254020] bf40: ffff000008018000 ffff00000801c000 ffffffffffffffff ffff0000080fa574
    [ 1111.261838] bf60: ffff0000090cbf70 ffff0000080857d0
    [ 1111.266706] [<ffff0000080832e8>] el1_irq+0xe8/0x18c
    [ 1111.271576] [<ffff0000080857d0>] arch_cpu_idle+0x10/0x18
    [ 1111.276880] [<ffff0000080d7de4>] do_idle+0xec/0x1b8
    [ 1111.281748] [<ffff0000080d8020>] cpu_startup_entry+0x20/0x28
    [ 1111.287399] [<ffff00000808f81c>] secondary_start_kernel+0x104/0x110
    [ 1111.293662] Code: bad PC value
    [ 1111.296710] ---[ end trace 555b6ca4363c3edd ]---
    [ 1111.301318] Kernel panic - not syncing: Fatal exception in interrupt
    [ 1111.307661] SMP: stopping secondary CPUs
    [ 1111.311574] Kernel Offset: disabled
    [ 1111.315053] CPU features: 0x0002000
    [ 1111.318530] Memory Limit: none
    [ 1111.321575] Rebooting in 3 seconds..
    
    With some added debug output / delays we were able to push the crash from
    the timer callback runner into the callback function and by that shedding
    some light on which object holding the timer gets corrupted:
    
    [  401.720899] Unable to handle kernel read from unreadable memory at virtual address 00000868
    [...]
    [  402.335836] [<ffff0000088fafa4>] _raw_spin_lock_bh+0x14/0x48
    [  402.341548] [<ffff000000dbe684>] mesh_path_timer+0x10c/0x248 [mac80211]
    [  402.348154] [<ffff0000080ff29c>] call_timer_fn.isra.27+0x24/0x78
    [  402.354150] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [  402.359974] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [  402.365362] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [  402.370231] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [  402.376053] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    
    The issue happens due to the following sequence of events:
    
    1) mesh_path_start_discovery():
    -> spin_unlock_bh(&mpath->state_lock) before mesh_path_sel_frame_tx()
    
    2) mesh_path_free_rcu()
    -> del_timer_sync(&mpath->timer)
       [...]
    -> kfree_rcu(mpath)
    
    3) mesh_path_start_discovery():
    -> mod_timer(&mpath->timer, ...)
       [...]
    -> rcu_read_unlock()
    
    4) mesh_path_free_rcu()'s kfree_rcu():
    -> kfree(mpath)
    
    5) mesh_path_timer() starts after timeout, using freed mpath object
    
    So a use-after-free issue due to a timer re-arming bug caused by an
    early spin-unlocking.
    
    This patch fixes this issue by re-checking if mpath is about to be
    free'd and if so bails out of re-arming the timer.
    
    Cc: stable@vger.kernel.org
    Fixes: 050ac52cbe1f ("mac80211: code for on-demand Hybrid Wireless Mesh Protocol")
    Cc: Simon Wunderlich <sw@simonwunderlich.de>
    Signed-off-by: Linus Lssing <ll@simonwunderlich.de>
    Link: https://lore.kernel.org/r/20200522170413.14973-1-linus.luessing@c0d3.blue
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e57ed07d5321dd2ceeaba2ed890c5057b7d1a34d
Author: Linus Lssing <ll@simonwunderlich.de>
Date:   Fri May 22 19:04:13 2020 +0200

    mac80211: mesh: fix discovery timer re-arming issue / crash
    
    commit e2d4a80f93fcfaf72e2e20daf6a28e39c3b90677 upstream.
    
    On a non-forwarding 802.11s link between two fairly busy
    neighboring nodes (iperf with -P 16 at ~850MBit/s TCP;
    1733.3 MBit/s VHT-MCS 9 80MHz short GI VHT-NSS 4), so with
    frequent PREQ retries, usually after around 30-40 seconds the
    following crash would occur:
    
    [ 1110.822428] Unable to handle kernel read from unreadable memory at virtual address 00000000
    [ 1110.830786] Mem abort info:
    [ 1110.833573]   Exception class = IABT (current EL), IL = 32 bits
    [ 1110.839494]   SET = 0, FnV = 0
    [ 1110.842546]   EA = 0, S1PTW = 0
    [ 1110.845678] user pgtable: 4k pages, 48-bit VAs, pgd = ffff800076386000
    [ 1110.852204] [0000000000000000] *pgd=00000000f6322003, *pud=00000000f62de003, *pmd=0000000000000000
    [ 1110.861167] Internal error: Oops: 86000004 [#1] PREEMPT SMP
    [ 1110.866730] Modules linked in: pppoe ppp_async batman_adv ath10k_pci ath10k_core ath pppox ppp_generic nf_conntrack_ipv6 mac80211 iptable_nat ipt_REJECT ipt_MASQUERADE cfg80211 xt_time xt_tcpudp xt_state xt_nat xt_multiport xt_mark xt_mac xt_limit xt_conntrack xt_comment xt_TCPMSS xt_REDIRECT xt_LOG xt_FLOWOFFLOAD slhc nf_reject_ipv4 nf_nat_redirect nf_nat_masquerade_ipv4 nf_conntrack_ipv4 nf_nat_ipv4 nf_nat nf_log_ipv4 nf_flow_table_hw nf_flow_table nf_defrag_ipv6 nf_defrag_ipv4 nf_conntrack_rtcache nf_conntrack iptable_mangle iptable_filter ip_tables crc_ccitt compat nf_log_ipv6 nf_log_common ip6table_mangle ip6table_filter ip6_tables ip6t_REJECT x_tables nf_reject_ipv6 usb_storage xhci_plat_hcd xhci_pci xhci_hcd dwc3 usbcore usb_common
    [ 1110.932190] Process swapper/3 (pid: 0, stack limit = 0xffff0000090c8000)
    [ 1110.938884] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 4.14.162 #0
    [ 1110.944965] Hardware name: LS1043A RGW Board (DT)
    [ 1110.949658] task: ffff8000787a81c0 task.stack: ffff0000090c8000
    [ 1110.955568] PC is at 0x0
    [ 1110.958097] LR is at call_timer_fn.isra.27+0x24/0x78
    [ 1110.963055] pc : [<0000000000000000>] lr : [<ffff0000080ff29c>] pstate: 00400145
    [ 1110.970440] sp : ffff00000801be10
    [ 1110.973744] x29: ffff00000801be10 x28: ffff000008bf7018
    [ 1110.979047] x27: ffff000008bf87c8 x26: ffff000008c160c0
    [ 1110.984352] x25: 0000000000000000 x24: 0000000000000000
    [ 1110.989657] x23: dead000000000200 x22: 0000000000000000
    [ 1110.994959] x21: 0000000000000000 x20: 0000000000000101
    [ 1111.000262] x19: ffff8000787a81c0 x18: 0000000000000000
    [ 1111.005565] x17: ffff0000089167b0 x16: 0000000000000058
    [ 1111.010868] x15: ffff0000089167b0 x14: 0000000000000000
    [ 1111.016172] x13: ffff000008916788 x12: 0000000000000040
    [ 1111.021475] x11: ffff80007fda9af0 x10: 0000000000000001
    [ 1111.026777] x9 : ffff00000801bea0 x8 : 0000000000000004
    [ 1111.032080] x7 : 0000000000000000 x6 : ffff80007fda9aa8
    [ 1111.037383] x5 : ffff00000801bea0 x4 : 0000000000000010
    [ 1111.042685] x3 : ffff00000801be98 x2 : 0000000000000614
    [ 1111.047988] x1 : 0000000000000000 x0 : 0000000000000000
    [ 1111.053290] Call trace:
    [ 1111.055728] Exception stack(0xffff00000801bcd0 to 0xffff00000801be10)
    [ 1111.062158] bcc0:                                   0000000000000000 0000000000000000
    [ 1111.069978] bce0: 0000000000000614 ffff00000801be98 0000000000000010 ffff00000801bea0
    [ 1111.077798] bd00: ffff80007fda9aa8 0000000000000000 0000000000000004 ffff00000801bea0
    [ 1111.085618] bd20: 0000000000000001 ffff80007fda9af0 0000000000000040 ffff000008916788
    [ 1111.093437] bd40: 0000000000000000 ffff0000089167b0 0000000000000058 ffff0000089167b0
    [ 1111.101256] bd60: 0000000000000000 ffff8000787a81c0 0000000000000101 0000000000000000
    [ 1111.109075] bd80: 0000000000000000 dead000000000200 0000000000000000 0000000000000000
    [ 1111.116895] bda0: ffff000008c160c0 ffff000008bf87c8 ffff000008bf7018 ffff00000801be10
    [ 1111.124715] bdc0: ffff0000080ff29c ffff00000801be10 0000000000000000 0000000000400145
    [ 1111.132534] bde0: ffff8000787a81c0 ffff00000801bde8 0000ffffffffffff 000001029eb19be8
    [ 1111.140353] be00: ffff00000801be10 0000000000000000
    [ 1111.145220] [<          (null)>]           (null)
    [ 1111.149917] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [ 1111.155741] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [ 1111.161130] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [ 1111.166002] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [ 1111.171825] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    [ 1111.177213] Exception stack(0xffff0000090cbe30 to 0xffff0000090cbf70)
    [ 1111.183642] be20:                                   0000000000000020 0000000000000000
    [ 1111.191461] be40: 0000000000000001 0000000000000000 00008000771af000 0000000000000000
    [ 1111.199281] be60: ffff000008c95180 0000000000000000 ffff000008c19360 ffff0000090cbef0
    [ 1111.207101] be80: 0000000000000810 0000000000000400 0000000000000098 ffff000000000000
    [ 1111.214920] bea0: 0000000000000001 ffff0000089167b0 0000000000000000 ffff0000089167b0
    [ 1111.222740] bec0: 0000000000000000 ffff000008c198e8 ffff000008bf7018 ffff000008c19000
    [ 1111.230559] bee0: 0000000000000000 0000000000000000 ffff8000787a81c0 ffff000008018000
    [ 1111.238380] bf00: ffff00000801c000 ffff00000913ba34 ffff8000787a81c0 ffff0000090cbf70
    [ 1111.246199] bf20: ffff0000080857cc ffff0000090cbf70 ffff0000080857d0 0000000000400145
    [ 1111.254020] bf40: ffff000008018000 ffff00000801c000 ffffffffffffffff ffff0000080fa574
    [ 1111.261838] bf60: ffff0000090cbf70 ffff0000080857d0
    [ 1111.266706] [<ffff0000080832e8>] el1_irq+0xe8/0x18c
    [ 1111.271576] [<ffff0000080857d0>] arch_cpu_idle+0x10/0x18
    [ 1111.276880] [<ffff0000080d7de4>] do_idle+0xec/0x1b8
    [ 1111.281748] [<ffff0000080d8020>] cpu_startup_entry+0x20/0x28
    [ 1111.287399] [<ffff00000808f81c>] secondary_start_kernel+0x104/0x110
    [ 1111.293662] Code: bad PC value
    [ 1111.296710] ---[ end trace 555b6ca4363c3edd ]---
    [ 1111.301318] Kernel panic - not syncing: Fatal exception in interrupt
    [ 1111.307661] SMP: stopping secondary CPUs
    [ 1111.311574] Kernel Offset: disabled
    [ 1111.315053] CPU features: 0x0002000
    [ 1111.318530] Memory Limit: none
    [ 1111.321575] Rebooting in 3 seconds..
    
    With some added debug output / delays we were able to push the crash from
    the timer callback runner into the callback function and by that shedding
    some light on which object holding the timer gets corrupted:
    
    [  401.720899] Unable to handle kernel read from unreadable memory at virtual address 00000868
    [...]
    [  402.335836] [<ffff0000088fafa4>] _raw_spin_lock_bh+0x14/0x48
    [  402.341548] [<ffff000000dbe684>] mesh_path_timer+0x10c/0x248 [mac80211]
    [  402.348154] [<ffff0000080ff29c>] call_timer_fn.isra.27+0x24/0x78
    [  402.354150] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [  402.359974] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [  402.365362] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [  402.370231] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [  402.376053] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    
    The issue happens due to the following sequence of events:
    
    1) mesh_path_start_discovery():
    -> spin_unlock_bh(&mpath->state_lock) before mesh_path_sel_frame_tx()
    
    2) mesh_path_free_rcu()
    -> del_timer_sync(&mpath->timer)
       [...]
    -> kfree_rcu(mpath)
    
    3) mesh_path_start_discovery():
    -> mod_timer(&mpath->timer, ...)
       [...]
    -> rcu_read_unlock()
    
    4) mesh_path_free_rcu()'s kfree_rcu():
    -> kfree(mpath)
    
    5) mesh_path_timer() starts after timeout, using freed mpath object
    
    So a use-after-free issue due to a timer re-arming bug caused by an
    early spin-unlocking.
    
    This patch fixes this issue by re-checking if mpath is about to be
    free'd and if so bails out of re-arming the timer.
    
    Cc: stable@vger.kernel.org
    Fixes: 050ac52cbe1f ("mac80211: code for on-demand Hybrid Wireless Mesh Protocol")
    Cc: Simon Wunderlich <sw@simonwunderlich.de>
    Signed-off-by: Linus Lssing <ll@simonwunderlich.de>
    Link: https://lore.kernel.org/r/20200522170413.14973-1-linus.luessing@c0d3.blue
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e2f105e84edaf7bd32945e93de83352c75779dc1
Author: Linus Lssing <ll@simonwunderlich.de>
Date:   Fri May 22 19:04:13 2020 +0200

    mac80211: mesh: fix discovery timer re-arming issue / crash
    
    commit e2d4a80f93fcfaf72e2e20daf6a28e39c3b90677 upstream.
    
    On a non-forwarding 802.11s link between two fairly busy
    neighboring nodes (iperf with -P 16 at ~850MBit/s TCP;
    1733.3 MBit/s VHT-MCS 9 80MHz short GI VHT-NSS 4), so with
    frequent PREQ retries, usually after around 30-40 seconds the
    following crash would occur:
    
    [ 1110.822428] Unable to handle kernel read from unreadable memory at virtual address 00000000
    [ 1110.830786] Mem abort info:
    [ 1110.833573]   Exception class = IABT (current EL), IL = 32 bits
    [ 1110.839494]   SET = 0, FnV = 0
    [ 1110.842546]   EA = 0, S1PTW = 0
    [ 1110.845678] user pgtable: 4k pages, 48-bit VAs, pgd = ffff800076386000
    [ 1110.852204] [0000000000000000] *pgd=00000000f6322003, *pud=00000000f62de003, *pmd=0000000000000000
    [ 1110.861167] Internal error: Oops: 86000004 [#1] PREEMPT SMP
    [ 1110.866730] Modules linked in: pppoe ppp_async batman_adv ath10k_pci ath10k_core ath pppox ppp_generic nf_conntrack_ipv6 mac80211 iptable_nat ipt_REJECT ipt_MASQUERADE cfg80211 xt_time xt_tcpudp xt_state xt_nat xt_multiport xt_mark xt_mac xt_limit xt_conntrack xt_comment xt_TCPMSS xt_REDIRECT xt_LOG xt_FLOWOFFLOAD slhc nf_reject_ipv4 nf_nat_redirect nf_nat_masquerade_ipv4 nf_conntrack_ipv4 nf_nat_ipv4 nf_nat nf_log_ipv4 nf_flow_table_hw nf_flow_table nf_defrag_ipv6 nf_defrag_ipv4 nf_conntrack_rtcache nf_conntrack iptable_mangle iptable_filter ip_tables crc_ccitt compat nf_log_ipv6 nf_log_common ip6table_mangle ip6table_filter ip6_tables ip6t_REJECT x_tables nf_reject_ipv6 usb_storage xhci_plat_hcd xhci_pci xhci_hcd dwc3 usbcore usb_common
    [ 1110.932190] Process swapper/3 (pid: 0, stack limit = 0xffff0000090c8000)
    [ 1110.938884] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 4.14.162 #0
    [ 1110.944965] Hardware name: LS1043A RGW Board (DT)
    [ 1110.949658] task: ffff8000787a81c0 task.stack: ffff0000090c8000
    [ 1110.955568] PC is at 0x0
    [ 1110.958097] LR is at call_timer_fn.isra.27+0x24/0x78
    [ 1110.963055] pc : [<0000000000000000>] lr : [<ffff0000080ff29c>] pstate: 00400145
    [ 1110.970440] sp : ffff00000801be10
    [ 1110.973744] x29: ffff00000801be10 x28: ffff000008bf7018
    [ 1110.979047] x27: ffff000008bf87c8 x26: ffff000008c160c0
    [ 1110.984352] x25: 0000000000000000 x24: 0000000000000000
    [ 1110.989657] x23: dead000000000200 x22: 0000000000000000
    [ 1110.994959] x21: 0000000000000000 x20: 0000000000000101
    [ 1111.000262] x19: ffff8000787a81c0 x18: 0000000000000000
    [ 1111.005565] x17: ffff0000089167b0 x16: 0000000000000058
    [ 1111.010868] x15: ffff0000089167b0 x14: 0000000000000000
    [ 1111.016172] x13: ffff000008916788 x12: 0000000000000040
    [ 1111.021475] x11: ffff80007fda9af0 x10: 0000000000000001
    [ 1111.026777] x9 : ffff00000801bea0 x8 : 0000000000000004
    [ 1111.032080] x7 : 0000000000000000 x6 : ffff80007fda9aa8
    [ 1111.037383] x5 : ffff00000801bea0 x4 : 0000000000000010
    [ 1111.042685] x3 : ffff00000801be98 x2 : 0000000000000614
    [ 1111.047988] x1 : 0000000000000000 x0 : 0000000000000000
    [ 1111.053290] Call trace:
    [ 1111.055728] Exception stack(0xffff00000801bcd0 to 0xffff00000801be10)
    [ 1111.062158] bcc0:                                   0000000000000000 0000000000000000
    [ 1111.069978] bce0: 0000000000000614 ffff00000801be98 0000000000000010 ffff00000801bea0
    [ 1111.077798] bd00: ffff80007fda9aa8 0000000000000000 0000000000000004 ffff00000801bea0
    [ 1111.085618] bd20: 0000000000000001 ffff80007fda9af0 0000000000000040 ffff000008916788
    [ 1111.093437] bd40: 0000000000000000 ffff0000089167b0 0000000000000058 ffff0000089167b0
    [ 1111.101256] bd60: 0000000000000000 ffff8000787a81c0 0000000000000101 0000000000000000
    [ 1111.109075] bd80: 0000000000000000 dead000000000200 0000000000000000 0000000000000000
    [ 1111.116895] bda0: ffff000008c160c0 ffff000008bf87c8 ffff000008bf7018 ffff00000801be10
    [ 1111.124715] bdc0: ffff0000080ff29c ffff00000801be10 0000000000000000 0000000000400145
    [ 1111.132534] bde0: ffff8000787a81c0 ffff00000801bde8 0000ffffffffffff 000001029eb19be8
    [ 1111.140353] be00: ffff00000801be10 0000000000000000
    [ 1111.145220] [<          (null)>]           (null)
    [ 1111.149917] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [ 1111.155741] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [ 1111.161130] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [ 1111.166002] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [ 1111.171825] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    [ 1111.177213] Exception stack(0xffff0000090cbe30 to 0xffff0000090cbf70)
    [ 1111.183642] be20:                                   0000000000000020 0000000000000000
    [ 1111.191461] be40: 0000000000000001 0000000000000000 00008000771af000 0000000000000000
    [ 1111.199281] be60: ffff000008c95180 0000000000000000 ffff000008c19360 ffff0000090cbef0
    [ 1111.207101] be80: 0000000000000810 0000000000000400 0000000000000098 ffff000000000000
    [ 1111.214920] bea0: 0000000000000001 ffff0000089167b0 0000000000000000 ffff0000089167b0
    [ 1111.222740] bec0: 0000000000000000 ffff000008c198e8 ffff000008bf7018 ffff000008c19000
    [ 1111.230559] bee0: 0000000000000000 0000000000000000 ffff8000787a81c0 ffff000008018000
    [ 1111.238380] bf00: ffff00000801c000 ffff00000913ba34 ffff8000787a81c0 ffff0000090cbf70
    [ 1111.246199] bf20: ffff0000080857cc ffff0000090cbf70 ffff0000080857d0 0000000000400145
    [ 1111.254020] bf40: ffff000008018000 ffff00000801c000 ffffffffffffffff ffff0000080fa574
    [ 1111.261838] bf60: ffff0000090cbf70 ffff0000080857d0
    [ 1111.266706] [<ffff0000080832e8>] el1_irq+0xe8/0x18c
    [ 1111.271576] [<ffff0000080857d0>] arch_cpu_idle+0x10/0x18
    [ 1111.276880] [<ffff0000080d7de4>] do_idle+0xec/0x1b8
    [ 1111.281748] [<ffff0000080d8020>] cpu_startup_entry+0x20/0x28
    [ 1111.287399] [<ffff00000808f81c>] secondary_start_kernel+0x104/0x110
    [ 1111.293662] Code: bad PC value
    [ 1111.296710] ---[ end trace 555b6ca4363c3edd ]---
    [ 1111.301318] Kernel panic - not syncing: Fatal exception in interrupt
    [ 1111.307661] SMP: stopping secondary CPUs
    [ 1111.311574] Kernel Offset: disabled
    [ 1111.315053] CPU features: 0x0002000
    [ 1111.318530] Memory Limit: none
    [ 1111.321575] Rebooting in 3 seconds..
    
    With some added debug output / delays we were able to push the crash from
    the timer callback runner into the callback function and by that shedding
    some light on which object holding the timer gets corrupted:
    
    [  401.720899] Unable to handle kernel read from unreadable memory at virtual address 00000868
    [...]
    [  402.335836] [<ffff0000088fafa4>] _raw_spin_lock_bh+0x14/0x48
    [  402.341548] [<ffff000000dbe684>] mesh_path_timer+0x10c/0x248 [mac80211]
    [  402.348154] [<ffff0000080ff29c>] call_timer_fn.isra.27+0x24/0x78
    [  402.354150] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [  402.359974] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [  402.365362] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [  402.370231] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [  402.376053] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    
    The issue happens due to the following sequence of events:
    
    1) mesh_path_start_discovery():
    -> spin_unlock_bh(&mpath->state_lock) before mesh_path_sel_frame_tx()
    
    2) mesh_path_free_rcu()
    -> del_timer_sync(&mpath->timer)
       [...]
    -> kfree_rcu(mpath)
    
    3) mesh_path_start_discovery():
    -> mod_timer(&mpath->timer, ...)
       [...]
    -> rcu_read_unlock()
    
    4) mesh_path_free_rcu()'s kfree_rcu():
    -> kfree(mpath)
    
    5) mesh_path_timer() starts after timeout, using freed mpath object
    
    So a use-after-free issue due to a timer re-arming bug caused by an
    early spin-unlocking.
    
    This patch fixes this issue by re-checking if mpath is about to be
    free'd and if so bails out of re-arming the timer.
    
    Cc: stable@vger.kernel.org
    Fixes: 050ac52cbe1f ("mac80211: code for on-demand Hybrid Wireless Mesh Protocol")
    Cc: Simon Wunderlich <sw@simonwunderlich.de>
    Signed-off-by: Linus Lssing <ll@simonwunderlich.de>
    Link: https://lore.kernel.org/r/20200522170413.14973-1-linus.luessing@c0d3.blue
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a3e733886b59a7484d3f586b5ae77fd80b810b4c
Author: Linus Lssing <ll@simonwunderlich.de>
Date:   Fri May 22 19:04:13 2020 +0200

    mac80211: mesh: fix discovery timer re-arming issue / crash
    
    commit e2d4a80f93fcfaf72e2e20daf6a28e39c3b90677 upstream.
    
    On a non-forwarding 802.11s link between two fairly busy
    neighboring nodes (iperf with -P 16 at ~850MBit/s TCP;
    1733.3 MBit/s VHT-MCS 9 80MHz short GI VHT-NSS 4), so with
    frequent PREQ retries, usually after around 30-40 seconds the
    following crash would occur:
    
    [ 1110.822428] Unable to handle kernel read from unreadable memory at virtual address 00000000
    [ 1110.830786] Mem abort info:
    [ 1110.833573]   Exception class = IABT (current EL), IL = 32 bits
    [ 1110.839494]   SET = 0, FnV = 0
    [ 1110.842546]   EA = 0, S1PTW = 0
    [ 1110.845678] user pgtable: 4k pages, 48-bit VAs, pgd = ffff800076386000
    [ 1110.852204] [0000000000000000] *pgd=00000000f6322003, *pud=00000000f62de003, *pmd=0000000000000000
    [ 1110.861167] Internal error: Oops: 86000004 [#1] PREEMPT SMP
    [ 1110.866730] Modules linked in: pppoe ppp_async batman_adv ath10k_pci ath10k_core ath pppox ppp_generic nf_conntrack_ipv6 mac80211 iptable_nat ipt_REJECT ipt_MASQUERADE cfg80211 xt_time xt_tcpudp xt_state xt_nat xt_multiport xt_mark xt_mac xt_limit xt_conntrack xt_comment xt_TCPMSS xt_REDIRECT xt_LOG xt_FLOWOFFLOAD slhc nf_reject_ipv4 nf_nat_redirect nf_nat_masquerade_ipv4 nf_conntrack_ipv4 nf_nat_ipv4 nf_nat nf_log_ipv4 nf_flow_table_hw nf_flow_table nf_defrag_ipv6 nf_defrag_ipv4 nf_conntrack_rtcache nf_conntrack iptable_mangle iptable_filter ip_tables crc_ccitt compat nf_log_ipv6 nf_log_common ip6table_mangle ip6table_filter ip6_tables ip6t_REJECT x_tables nf_reject_ipv6 usb_storage xhci_plat_hcd xhci_pci xhci_hcd dwc3 usbcore usb_common
    [ 1110.932190] Process swapper/3 (pid: 0, stack limit = 0xffff0000090c8000)
    [ 1110.938884] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 4.14.162 #0
    [ 1110.944965] Hardware name: LS1043A RGW Board (DT)
    [ 1110.949658] task: ffff8000787a81c0 task.stack: ffff0000090c8000
    [ 1110.955568] PC is at 0x0
    [ 1110.958097] LR is at call_timer_fn.isra.27+0x24/0x78
    [ 1110.963055] pc : [<0000000000000000>] lr : [<ffff0000080ff29c>] pstate: 00400145
    [ 1110.970440] sp : ffff00000801be10
    [ 1110.973744] x29: ffff00000801be10 x28: ffff000008bf7018
    [ 1110.979047] x27: ffff000008bf87c8 x26: ffff000008c160c0
    [ 1110.984352] x25: 0000000000000000 x24: 0000000000000000
    [ 1110.989657] x23: dead000000000200 x22: 0000000000000000
    [ 1110.994959] x21: 0000000000000000 x20: 0000000000000101
    [ 1111.000262] x19: ffff8000787a81c0 x18: 0000000000000000
    [ 1111.005565] x17: ffff0000089167b0 x16: 0000000000000058
    [ 1111.010868] x15: ffff0000089167b0 x14: 0000000000000000
    [ 1111.016172] x13: ffff000008916788 x12: 0000000000000040
    [ 1111.021475] x11: ffff80007fda9af0 x10: 0000000000000001
    [ 1111.026777] x9 : ffff00000801bea0 x8 : 0000000000000004
    [ 1111.032080] x7 : 0000000000000000 x6 : ffff80007fda9aa8
    [ 1111.037383] x5 : ffff00000801bea0 x4 : 0000000000000010
    [ 1111.042685] x3 : ffff00000801be98 x2 : 0000000000000614
    [ 1111.047988] x1 : 0000000000000000 x0 : 0000000000000000
    [ 1111.053290] Call trace:
    [ 1111.055728] Exception stack(0xffff00000801bcd0 to 0xffff00000801be10)
    [ 1111.062158] bcc0:                                   0000000000000000 0000000000000000
    [ 1111.069978] bce0: 0000000000000614 ffff00000801be98 0000000000000010 ffff00000801bea0
    [ 1111.077798] bd00: ffff80007fda9aa8 0000000000000000 0000000000000004 ffff00000801bea0
    [ 1111.085618] bd20: 0000000000000001 ffff80007fda9af0 0000000000000040 ffff000008916788
    [ 1111.093437] bd40: 0000000000000000 ffff0000089167b0 0000000000000058 ffff0000089167b0
    [ 1111.101256] bd60: 0000000000000000 ffff8000787a81c0 0000000000000101 0000000000000000
    [ 1111.109075] bd80: 0000000000000000 dead000000000200 0000000000000000 0000000000000000
    [ 1111.116895] bda0: ffff000008c160c0 ffff000008bf87c8 ffff000008bf7018 ffff00000801be10
    [ 1111.124715] bdc0: ffff0000080ff29c ffff00000801be10 0000000000000000 0000000000400145
    [ 1111.132534] bde0: ffff8000787a81c0 ffff00000801bde8 0000ffffffffffff 000001029eb19be8
    [ 1111.140353] be00: ffff00000801be10 0000000000000000
    [ 1111.145220] [<          (null)>]           (null)
    [ 1111.149917] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [ 1111.155741] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [ 1111.161130] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [ 1111.166002] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [ 1111.171825] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    [ 1111.177213] Exception stack(0xffff0000090cbe30 to 0xffff0000090cbf70)
    [ 1111.183642] be20:                                   0000000000000020 0000000000000000
    [ 1111.191461] be40: 0000000000000001 0000000000000000 00008000771af000 0000000000000000
    [ 1111.199281] be60: ffff000008c95180 0000000000000000 ffff000008c19360 ffff0000090cbef0
    [ 1111.207101] be80: 0000000000000810 0000000000000400 0000000000000098 ffff000000000000
    [ 1111.214920] bea0: 0000000000000001 ffff0000089167b0 0000000000000000 ffff0000089167b0
    [ 1111.222740] bec0: 0000000000000000 ffff000008c198e8 ffff000008bf7018 ffff000008c19000
    [ 1111.230559] bee0: 0000000000000000 0000000000000000 ffff8000787a81c0 ffff000008018000
    [ 1111.238380] bf00: ffff00000801c000 ffff00000913ba34 ffff8000787a81c0 ffff0000090cbf70
    [ 1111.246199] bf20: ffff0000080857cc ffff0000090cbf70 ffff0000080857d0 0000000000400145
    [ 1111.254020] bf40: ffff000008018000 ffff00000801c000 ffffffffffffffff ffff0000080fa574
    [ 1111.261838] bf60: ffff0000090cbf70 ffff0000080857d0
    [ 1111.266706] [<ffff0000080832e8>] el1_irq+0xe8/0x18c
    [ 1111.271576] [<ffff0000080857d0>] arch_cpu_idle+0x10/0x18
    [ 1111.276880] [<ffff0000080d7de4>] do_idle+0xec/0x1b8
    [ 1111.281748] [<ffff0000080d8020>] cpu_startup_entry+0x20/0x28
    [ 1111.287399] [<ffff00000808f81c>] secondary_start_kernel+0x104/0x110
    [ 1111.293662] Code: bad PC value
    [ 1111.296710] ---[ end trace 555b6ca4363c3edd ]---
    [ 1111.301318] Kernel panic - not syncing: Fatal exception in interrupt
    [ 1111.307661] SMP: stopping secondary CPUs
    [ 1111.311574] Kernel Offset: disabled
    [ 1111.315053] CPU features: 0x0002000
    [ 1111.318530] Memory Limit: none
    [ 1111.321575] Rebooting in 3 seconds..
    
    With some added debug output / delays we were able to push the crash from
    the timer callback runner into the callback function and by that shedding
    some light on which object holding the timer gets corrupted:
    
    [  401.720899] Unable to handle kernel read from unreadable memory at virtual address 00000868
    [...]
    [  402.335836] [<ffff0000088fafa4>] _raw_spin_lock_bh+0x14/0x48
    [  402.341548] [<ffff000000dbe684>] mesh_path_timer+0x10c/0x248 [mac80211]
    [  402.348154] [<ffff0000080ff29c>] call_timer_fn.isra.27+0x24/0x78
    [  402.354150] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [  402.359974] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [  402.365362] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [  402.370231] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [  402.376053] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    
    The issue happens due to the following sequence of events:
    
    1) mesh_path_start_discovery():
    -> spin_unlock_bh(&mpath->state_lock) before mesh_path_sel_frame_tx()
    
    2) mesh_path_free_rcu()
    -> del_timer_sync(&mpath->timer)
       [...]
    -> kfree_rcu(mpath)
    
    3) mesh_path_start_discovery():
    -> mod_timer(&mpath->timer, ...)
       [...]
    -> rcu_read_unlock()
    
    4) mesh_path_free_rcu()'s kfree_rcu():
    -> kfree(mpath)
    
    5) mesh_path_timer() starts after timeout, using freed mpath object
    
    So a use-after-free issue due to a timer re-arming bug caused by an
    early spin-unlocking.
    
    This patch fixes this issue by re-checking if mpath is about to be
    free'd and if so bails out of re-arming the timer.
    
    Cc: stable@vger.kernel.org
    Fixes: 050ac52cbe1f ("mac80211: code for on-demand Hybrid Wireless Mesh Protocol")
    Cc: Simon Wunderlich <sw@simonwunderlich.de>
    Signed-off-by: Linus Lssing <ll@simonwunderlich.de>
    Link: https://lore.kernel.org/r/20200522170413.14973-1-linus.luessing@c0d3.blue
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a54ca194981be3707213437a67792b88e08264fe
Author: Tan Xiaojun <tanxiaojun@huawei.com>
Date:   Sat May 30 20:24:42 2020 +0800

    perf arm-spe: Support synthetic events
    
    After the commit ffd3d18c20b8 ("perf tools: Add ARM Statistical
    Profiling Extensions (SPE) support") has been merged, it supports to
    output raw data with option "--dump-raw-trace".  However, it misses for
    support synthetic events so cannot output any statistical info.
    
    This patch is to improve the "perf report" support for ARM SPE for four
    types synthetic events:
    
      First level cache synthetic events, including L1 data cache accessing
      and missing events;
      Last level cache synthetic events, including last level cache
      accessing and missing events;
      TLB synthetic events, including TLB accessing and missing events;
      Remote access events, which is used to account load/store operations
      caused to another socket.
    
    Example usage:
    
      $ perf record -c 1024 -e arm_spe_0/branch_filter=1,ts_enable=1,pct_enable=1,pa_enable=1,load_filter=1,jitter=1,store_filter=1,min_latency=0/ dd if=/dev/zero of=/dev/null count=10000
      $ perf report --stdio
    
      # Samples: 59  of event 'l1d-miss'
      # Event count (approx.): 59
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ..................................
      #
          23.73%    23.73%  dd       [kernel.kallsyms]  [k] perf_iterate_ctx.constprop.135
          20.34%    20.34%  dd       [kernel.kallsyms]  [k] filemap_map_pages
           5.08%     5.08%  dd       [kernel.kallsyms]  [k] perf_event_mmap
           5.08%     5.08%  dd       [kernel.kallsyms]  [k] unlock_page_memcg
           5.08%     5.08%  dd       [kernel.kallsyms]  [k] unmap_page_range
           3.39%     3.39%  dd       [kernel.kallsyms]  [k] PageHuge
           3.39%     3.39%  dd       [kernel.kallsyms]  [k] release_pages
           3.39%     3.39%  dd       ld-2.28.so         [.] 0x0000000000008b5c
           1.69%     1.69%  dd       [kernel.kallsyms]  [k] __alloc_fd
           [...]
    
      # Samples: 3K of event 'l1d-access'
      # Event count (approx.): 3980
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ......................................
      #
          26.98%    26.98%  dd       [kernel.kallsyms]  [k] ret_to_user
          10.53%    10.53%  dd       [kernel.kallsyms]  [k] fsnotify
           7.51%     7.51%  dd       [kernel.kallsyms]  [k] new_sync_read
           4.57%     4.57%  dd       [kernel.kallsyms]  [k] vfs_read
           4.35%     4.35%  dd       [kernel.kallsyms]  [k] vfs_write
           3.69%     3.69%  dd       [kernel.kallsyms]  [k] __fget_light
           3.69%     3.69%  dd       [kernel.kallsyms]  [k] rw_verify_area
           3.44%     3.44%  dd       [kernel.kallsyms]  [k] security_file_permission
           2.76%     2.76%  dd       [kernel.kallsyms]  [k] __fsnotify_parent
           2.44%     2.44%  dd       [kernel.kallsyms]  [k] ksys_write
           2.24%     2.24%  dd       [kernel.kallsyms]  [k] iov_iter_zero
           2.19%     2.19%  dd       [kernel.kallsyms]  [k] read_iter_zero
           1.81%     1.81%  dd       dd                 [.] 0x0000000000002960
           1.78%     1.78%  dd       dd                 [.] 0x0000000000002980
           [...]
    
      # Samples: 35  of event 'llc-miss'
      # Event count (approx.): 35
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ...........................
      #
          34.29%    34.29%  dd       [kernel.kallsyms]  [k] filemap_map_pages
           8.57%     8.57%  dd       [kernel.kallsyms]  [k] unlock_page_memcg
           8.57%     8.57%  dd       [kernel.kallsyms]  [k] unmap_page_range
           5.71%     5.71%  dd       [kernel.kallsyms]  [k] PageHuge
           5.71%     5.71%  dd       [kernel.kallsyms]  [k] release_pages
           5.71%     5.71%  dd       ld-2.28.so         [.] 0x0000000000008b5c
           2.86%     2.86%  dd       [kernel.kallsyms]  [k] __queue_work
           2.86%     2.86%  dd       [kernel.kallsyms]  [k] __radix_tree_lookup
           2.86%     2.86%  dd       [kernel.kallsyms]  [k] copy_page
           [...]
    
      # Samples: 2  of event 'llc-access'
      # Event count (approx.): 2
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  .............
      #
          50.00%    50.00%  dd       [kernel.kallsyms]  [k] copy_page
          50.00%    50.00%  dd       libc-2.28.so       [.] _dl_addr
    
      # Samples: 48  of event 'tlb-miss'
      # Event count (approx.): 48
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ..................................
      #
          20.83%    20.83%  dd       [kernel.kallsyms]  [k] perf_iterate_ctx.constprop.135
          12.50%    12.50%  dd       [kernel.kallsyms]  [k] __arch_clear_user
          10.42%    10.42%  dd       [kernel.kallsyms]  [k] clear_page
           4.17%     4.17%  dd       [kernel.kallsyms]  [k] copy_page
           4.17%     4.17%  dd       [kernel.kallsyms]  [k] filemap_map_pages
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] __alloc_fd
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] __mod_memcg_state.part.70
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] __queue_work
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] __rcu_read_unlock
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] d_path
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] destroy_inode
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] do_dentry_open
           [...]
    
      # Samples: 9K of event 'tlb-access'
      # Event count (approx.): 9573
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ......................................
      #
          25.79%    25.79%  dd       [kernel.kallsyms]  [k] __arch_clear_user
          11.22%    11.22%  dd       [kernel.kallsyms]  [k] ret_to_user
           8.56%     8.56%  dd       [kernel.kallsyms]  [k] fsnotify
           4.06%     4.06%  dd       [kernel.kallsyms]  [k] new_sync_read
           3.67%     3.67%  dd       [kernel.kallsyms]  [k] el0_svc_common.constprop.2
           3.04%     3.04%  dd       [kernel.kallsyms]  [k] __fsnotify_parent
           2.90%     2.90%  dd       [kernel.kallsyms]  [k] vfs_write
           2.82%     2.82%  dd       [kernel.kallsyms]  [k] vfs_read
           2.52%     2.52%  dd       libc-2.28.so       [.] write
           2.26%     2.26%  dd       [kernel.kallsyms]  [k] security_file_permission
           2.08%     2.08%  dd       [kernel.kallsyms]  [k] ksys_write
           1.96%     1.96%  dd       [kernel.kallsyms]  [k] rw_verify_area
           1.95%     1.95%  dd       [kernel.kallsyms]  [k] read_iter_zero
           [...]
    
      # Samples: 9  of event 'branch-miss'
      # Event count (approx.): 9
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  .........................
      #
          22.22%    22.22%  dd       libc-2.28.so       [.] _dl_addr
          11.11%    11.11%  dd       [kernel.kallsyms]  [k] __arch_clear_user
          11.11%    11.11%  dd       [kernel.kallsyms]  [k] __arch_copy_from_user
          11.11%    11.11%  dd       [kernel.kallsyms]  [k] __dentry_kill
          11.11%    11.11%  dd       [kernel.kallsyms]  [k] __efistub_memcpy
          11.11%    11.11%  dd       ld-2.28.so         [.] 0x0000000000012b7c
          11.11%    11.11%  dd       libc-2.28.so       [.] 0x000000000002a980
          11.11%    11.11%  dd       libc-2.28.so       [.] 0x0000000000083340
    
      # Samples: 29  of event 'remote-access'
      # Event count (approx.): 29
      #
      # Children      Self  Command  Shared Object      Symbol
      # ........  ........  .......  .................  ...........................
      #
          41.38%    41.38%  dd       [kernel.kallsyms]  [k] filemap_map_pages
          10.34%    10.34%  dd       [kernel.kallsyms]  [k] unlock_page_memcg
          10.34%    10.34%  dd       [kernel.kallsyms]  [k] unmap_page_range
           6.90%     6.90%  dd       [kernel.kallsyms]  [k] release_pages
           3.45%     3.45%  dd       [kernel.kallsyms]  [k] PageHuge
           3.45%     3.45%  dd       [kernel.kallsyms]  [k] __queue_work
           3.45%     3.45%  dd       [kernel.kallsyms]  [k] page_add_file_rmap
           3.45%     3.45%  dd       [kernel.kallsyms]  [k] page_counter_try_charge
           3.45%     3.45%  dd       [kernel.kallsyms]  [k] page_remove_rmap
           3.45%     3.45%  dd       [kernel.kallsyms]  [k] xas_start
           3.45%     3.45%  dd       ld-2.28.so         [.] 0x0000000000002a1c
           3.45%     3.45%  dd       ld-2.28.so         [.] 0x0000000000008b5c
           3.45%     3.45%  dd       ld-2.28.so         [.] 0x00000000000093cc
    
    Signed-off-by: Tan Xiaojun <tanxiaojun@huawei.com>
    Tested-by: James Clark <james.clark@arm.com>
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Al Grant <al.grant@arm.com>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Ian Rogers <irogers@google.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Leo Yan <leo.yan@linaro.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Mathieu Poirier <mathieu.poirier@linaro.org>
    Cc: Mike Leach <mike.leach@linaro.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will@kernel.org>
    Cc: linux-arm-kernel@lists.infradead.org
    Link: http://lore.kernel.org/lkml/20200530122442.490-4-leo.yan@linaro.org
    Signed-off-by: James Clark <james.clark@arm.com>
    Signed-off-by: Leo Yan <leo.yan@linaro.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 26f8819ddd10141ebe7bbce700fbab36bfa5f478
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Fri Oct 27 16:51:52 2017 +0200

    l2tp: protect sock pointer of struct pppol2tp_session with RCU
    
    commit ee40fb2e1eb5bc0ddd3f2f83c6e39a454ef5a741 upstream.
    
    pppol2tp_session_create() registers sessions that can't have their
    corresponding socket initialised. This socket has to be created by
    userspace, then connected to the session by pppol2tp_connect().
    Therefore, we need to protect the pppol2tp socket pointer of L2TP
    sessions, so that it can safely be updated when userspace is connecting
    or closing the socket. This will eventually allow pppol2tp_connect()
    to avoid generating transient states while initialising its parts of the
    session.
    
    To this end, this patch protects the pppol2tp socket pointer using RCU.
    
    The pppol2tp socket pointer is still set in pppol2tp_connect(), but
    only once we know the function isn't going to fail. It's eventually
    reset by pppol2tp_release(), which now has to wait for a grace period
    to elapse before it can drop the last reference on the socket. This
    ensures that pppol2tp_session_get_sock() can safely grab a reference
    on the socket, even after ps->sk is reset to NULL but before this
    operation actually gets visible from pppol2tp_session_get_sock().
    
    The rest is standard RCU conversion: pppol2tp_recv(), which already
    runs in atomic context, is simply enclosed by rcu_read_lock() and
    rcu_read_unlock(), while other functions are converted to use
    pppol2tp_session_get_sock() followed by sock_put().
    pppol2tp_session_setsockopt() is a special case. It used to retrieve
    the pppol2tp socket from the L2TP session, which itself was retrieved
    from the pppol2tp socket. Therefore we can just avoid dereferencing
    ps->sk and directly use the original socket pointer instead.
    
    With all users of ps->sk now handling NULL and concurrent updates, the
    L2TP ->ref() and ->deref() callbacks aren't needed anymore. Therefore,
    rather than converting pppol2tp_session_sock_hold() and
    pppol2tp_session_sock_put(), we can just drop them.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Giuliano Procida <gprocida@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5803ecd7f6ac6f747582e775caa62ac9d0489261
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Fri May 22 00:39:36 2020 +0100

    l2tp: protect sock pointer of struct pppol2tp_session with RCU
    
    commit ee40fb2e1eb5bc0ddd3f2f83c6e39a454ef5a741 upstream.
    
    pppol2tp_session_create() registers sessions that can't have their
    corresponding socket initialised. This socket has to be created by
    userspace, then connected to the session by pppol2tp_connect().
    Therefore, we need to protect the pppol2tp socket pointer of L2TP
    sessions, so that it can safely be updated when userspace is connecting
    or closing the socket. This will eventually allow pppol2tp_connect()
    to avoid generating transient states while initialising its parts of the
    session.
    
    To this end, this patch protects the pppol2tp socket pointer using RCU.
    
    The pppol2tp socket pointer is still set in pppol2tp_connect(), but
    only once we know the function isn't going to fail. It's eventually
    reset by pppol2tp_release(), which now has to wait for a grace period
    to elapse before it can drop the last reference on the socket. This
    ensures that pppol2tp_session_get_sock() can safely grab a reference
    on the socket, even after ps->sk is reset to NULL but before this
    operation actually gets visible from pppol2tp_session_get_sock().
    
    The rest is standard RCU conversion: pppol2tp_recv(), which already
    runs in atomic context, is simply enclosed by rcu_read_lock() and
    rcu_read_unlock(), while other functions are converted to use
    pppol2tp_session_get_sock() followed by sock_put().
    pppol2tp_session_setsockopt() is a special case. It used to retrieve
    the pppol2tp socket from the L2TP session, which itself was retrieved
    from the pppol2tp socket. Therefore we can just avoid dereferencing
    ps->sk and directly use the original socket pointer instead.
    
    With all users of ps->sk now handling NULL and concurrent updates, the
    L2TP ->ref() and ->deref() callbacks aren't needed anymore. Therefore,
    rather than converting pppol2tp_session_sock_hold() and
    pppol2tp_session_sock_put(), we can just drop them.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Giuliano Procida <gprocida@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c2984681fe15cfb803a9132aaaf1140ab20a72c1
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Fri May 22 00:57:39 2020 +0100

    l2tp: protect sock pointer of struct pppol2tp_session with RCU
    
    commit ee40fb2e1eb5bc0ddd3f2f83c6e39a454ef5a741 upstream.
    
    pppol2tp_session_create() registers sessions that can't have their
    corresponding socket initialised. This socket has to be created by
    userspace, then connected to the session by pppol2tp_connect().
    Therefore, we need to protect the pppol2tp socket pointer of L2TP
    sessions, so that it can safely be updated when userspace is connecting
    or closing the socket. This will eventually allow pppol2tp_connect()
    to avoid generating transient states while initialising its parts of the
    session.
    
    To this end, this patch protects the pppol2tp socket pointer using RCU.
    
    The pppol2tp socket pointer is still set in pppol2tp_connect(), but
    only once we know the function isn't going to fail. It's eventually
    reset by pppol2tp_release(), which now has to wait for a grace period
    to elapse before it can drop the last reference on the socket. This
    ensures that pppol2tp_session_get_sock() can safely grab a reference
    on the socket, even after ps->sk is reset to NULL but before this
    operation actually gets visible from pppol2tp_session_get_sock().
    
    The rest is standard RCU conversion: pppol2tp_recv(), which already
    runs in atomic context, is simply enclosed by rcu_read_lock() and
    rcu_read_unlock(), while other functions are converted to use
    pppol2tp_session_get_sock() followed by sock_put().
    pppol2tp_session_setsockopt() is a special case. It used to retrieve
    the pppol2tp socket from the L2TP session, which itself was retrieved
    from the pppol2tp socket. Therefore we can just avoid dereferencing
    ps->sk and directly use the original socket pointer instead.
    
    With all users of ps->sk now handling NULL and concurrent updates, the
    L2TP ->ref() and ->deref() callbacks aren't needed anymore. Therefore,
    rather than converting pppol2tp_session_sock_hold() and
    pppol2tp_session_sock_put(), we can just drop them.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Giuliano Procida <gprocida@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e2d4a80f93fcfaf72e2e20daf6a28e39c3b90677
Author: Linus Lssing <ll@simonwunderlich.de>
Date:   Fri May 22 19:04:13 2020 +0200

    mac80211: mesh: fix discovery timer re-arming issue / crash
    
    On a non-forwarding 802.11s link between two fairly busy
    neighboring nodes (iperf with -P 16 at ~850MBit/s TCP;
    1733.3 MBit/s VHT-MCS 9 80MHz short GI VHT-NSS 4), so with
    frequent PREQ retries, usually after around 30-40 seconds the
    following crash would occur:
    
    [ 1110.822428] Unable to handle kernel read from unreadable memory at virtual address 00000000
    [ 1110.830786] Mem abort info:
    [ 1110.833573]   Exception class = IABT (current EL), IL = 32 bits
    [ 1110.839494]   SET = 0, FnV = 0
    [ 1110.842546]   EA = 0, S1PTW = 0
    [ 1110.845678] user pgtable: 4k pages, 48-bit VAs, pgd = ffff800076386000
    [ 1110.852204] [0000000000000000] *pgd=00000000f6322003, *pud=00000000f62de003, *pmd=0000000000000000
    [ 1110.861167] Internal error: Oops: 86000004 [#1] PREEMPT SMP
    [ 1110.866730] Modules linked in: pppoe ppp_async batman_adv ath10k_pci ath10k_core ath pppox ppp_generic nf_conntrack_ipv6 mac80211 iptable_nat ipt_REJECT ipt_MASQUERADE cfg80211 xt_time xt_tcpudp xt_state xt_nat xt_multiport xt_mark xt_mac xt_limit xt_conntrack xt_comment xt_TCPMSS xt_REDIRECT xt_LOG xt_FLOWOFFLOAD slhc nf_reject_ipv4 nf_nat_redirect nf_nat_masquerade_ipv4 nf_conntrack_ipv4 nf_nat_ipv4 nf_nat nf_log_ipv4 nf_flow_table_hw nf_flow_table nf_defrag_ipv6 nf_defrag_ipv4 nf_conntrack_rtcache nf_conntrack iptable_mangle iptable_filter ip_tables crc_ccitt compat nf_log_ipv6 nf_log_common ip6table_mangle ip6table_filter ip6_tables ip6t_REJECT x_tables nf_reject_ipv6 usb_storage xhci_plat_hcd xhci_pci xhci_hcd dwc3 usbcore usb_common
    [ 1110.932190] Process swapper/3 (pid: 0, stack limit = 0xffff0000090c8000)
    [ 1110.938884] CPU: 3 PID: 0 Comm: swapper/3 Not tainted 4.14.162 #0
    [ 1110.944965] Hardware name: LS1043A RGW Board (DT)
    [ 1110.949658] task: ffff8000787a81c0 task.stack: ffff0000090c8000
    [ 1110.955568] PC is at 0x0
    [ 1110.958097] LR is at call_timer_fn.isra.27+0x24/0x78
    [ 1110.963055] pc : [<0000000000000000>] lr : [<ffff0000080ff29c>] pstate: 00400145
    [ 1110.970440] sp : ffff00000801be10
    [ 1110.973744] x29: ffff00000801be10 x28: ffff000008bf7018
    [ 1110.979047] x27: ffff000008bf87c8 x26: ffff000008c160c0
    [ 1110.984352] x25: 0000000000000000 x24: 0000000000000000
    [ 1110.989657] x23: dead000000000200 x22: 0000000000000000
    [ 1110.994959] x21: 0000000000000000 x20: 0000000000000101
    [ 1111.000262] x19: ffff8000787a81c0 x18: 0000000000000000
    [ 1111.005565] x17: ffff0000089167b0 x16: 0000000000000058
    [ 1111.010868] x15: ffff0000089167b0 x14: 0000000000000000
    [ 1111.016172] x13: ffff000008916788 x12: 0000000000000040
    [ 1111.021475] x11: ffff80007fda9af0 x10: 0000000000000001
    [ 1111.026777] x9 : ffff00000801bea0 x8 : 0000000000000004
    [ 1111.032080] x7 : 0000000000000000 x6 : ffff80007fda9aa8
    [ 1111.037383] x5 : ffff00000801bea0 x4 : 0000000000000010
    [ 1111.042685] x3 : ffff00000801be98 x2 : 0000000000000614
    [ 1111.047988] x1 : 0000000000000000 x0 : 0000000000000000
    [ 1111.053290] Call trace:
    [ 1111.055728] Exception stack(0xffff00000801bcd0 to 0xffff00000801be10)
    [ 1111.062158] bcc0:                                   0000000000000000 0000000000000000
    [ 1111.069978] bce0: 0000000000000614 ffff00000801be98 0000000000000010 ffff00000801bea0
    [ 1111.077798] bd00: ffff80007fda9aa8 0000000000000000 0000000000000004 ffff00000801bea0
    [ 1111.085618] bd20: 0000000000000001 ffff80007fda9af0 0000000000000040 ffff000008916788
    [ 1111.093437] bd40: 0000000000000000 ffff0000089167b0 0000000000000058 ffff0000089167b0
    [ 1111.101256] bd60: 0000000000000000 ffff8000787a81c0 0000000000000101 0000000000000000
    [ 1111.109075] bd80: 0000000000000000 dead000000000200 0000000000000000 0000000000000000
    [ 1111.116895] bda0: ffff000008c160c0 ffff000008bf87c8 ffff000008bf7018 ffff00000801be10
    [ 1111.124715] bdc0: ffff0000080ff29c ffff00000801be10 0000000000000000 0000000000400145
    [ 1111.132534] bde0: ffff8000787a81c0 ffff00000801bde8 0000ffffffffffff 000001029eb19be8
    [ 1111.140353] be00: ffff00000801be10 0000000000000000
    [ 1111.145220] [<          (null)>]           (null)
    [ 1111.149917] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [ 1111.155741] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [ 1111.161130] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [ 1111.166002] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [ 1111.171825] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    [ 1111.177213] Exception stack(0xffff0000090cbe30 to 0xffff0000090cbf70)
    [ 1111.183642] be20:                                   0000000000000020 0000000000000000
    [ 1111.191461] be40: 0000000000000001 0000000000000000 00008000771af000 0000000000000000
    [ 1111.199281] be60: ffff000008c95180 0000000000000000 ffff000008c19360 ffff0000090cbef0
    [ 1111.207101] be80: 0000000000000810 0000000000000400 0000000000000098 ffff000000000000
    [ 1111.214920] bea0: 0000000000000001 ffff0000089167b0 0000000000000000 ffff0000089167b0
    [ 1111.222740] bec0: 0000000000000000 ffff000008c198e8 ffff000008bf7018 ffff000008c19000
    [ 1111.230559] bee0: 0000000000000000 0000000000000000 ffff8000787a81c0 ffff000008018000
    [ 1111.238380] bf00: ffff00000801c000 ffff00000913ba34 ffff8000787a81c0 ffff0000090cbf70
    [ 1111.246199] bf20: ffff0000080857cc ffff0000090cbf70 ffff0000080857d0 0000000000400145
    [ 1111.254020] bf40: ffff000008018000 ffff00000801c000 ffffffffffffffff ffff0000080fa574
    [ 1111.261838] bf60: ffff0000090cbf70 ffff0000080857d0
    [ 1111.266706] [<ffff0000080832e8>] el1_irq+0xe8/0x18c
    [ 1111.271576] [<ffff0000080857d0>] arch_cpu_idle+0x10/0x18
    [ 1111.276880] [<ffff0000080d7de4>] do_idle+0xec/0x1b8
    [ 1111.281748] [<ffff0000080d8020>] cpu_startup_entry+0x20/0x28
    [ 1111.287399] [<ffff00000808f81c>] secondary_start_kernel+0x104/0x110
    [ 1111.293662] Code: bad PC value
    [ 1111.296710] ---[ end trace 555b6ca4363c3edd ]---
    [ 1111.301318] Kernel panic - not syncing: Fatal exception in interrupt
    [ 1111.307661] SMP: stopping secondary CPUs
    [ 1111.311574] Kernel Offset: disabled
    [ 1111.315053] CPU features: 0x0002000
    [ 1111.318530] Memory Limit: none
    [ 1111.321575] Rebooting in 3 seconds..
    
    With some added debug output / delays we were able to push the crash from
    the timer callback runner into the callback function and by that shedding
    some light on which object holding the timer gets corrupted:
    
    [  401.720899] Unable to handle kernel read from unreadable memory at virtual address 00000868
    [...]
    [  402.335836] [<ffff0000088fafa4>] _raw_spin_lock_bh+0x14/0x48
    [  402.341548] [<ffff000000dbe684>] mesh_path_timer+0x10c/0x248 [mac80211]
    [  402.348154] [<ffff0000080ff29c>] call_timer_fn.isra.27+0x24/0x78
    [  402.354150] [<ffff0000080ff77c>] run_timer_softirq+0x184/0x398
    [  402.359974] [<ffff000008081938>] __do_softirq+0x100/0x1fc
    [  402.365362] [<ffff0000080a2e28>] irq_exit+0x80/0xd8
    [  402.370231] [<ffff0000080ea708>] __handle_domain_irq+0x88/0xb0
    [  402.376053] [<ffff000008081678>] gic_handle_irq+0x68/0xb0
    
    The issue happens due to the following sequence of events:
    
    1) mesh_path_start_discovery():
    -> spin_unlock_bh(&mpath->state_lock) before mesh_path_sel_frame_tx()
    
    2) mesh_path_free_rcu()
    -> del_timer_sync(&mpath->timer)
       [...]
    -> kfree_rcu(mpath)
    
    3) mesh_path_start_discovery():
    -> mod_timer(&mpath->timer, ...)
       [...]
    -> rcu_read_unlock()
    
    4) mesh_path_free_rcu()'s kfree_rcu():
    -> kfree(mpath)
    
    5) mesh_path_timer() starts after timeout, using freed mpath object
    
    So a use-after-free issue due to a timer re-arming bug caused by an
    early spin-unlocking.
    
    This patch fixes this issue by re-checking if mpath is about to be
    free'd and if so bails out of re-arming the timer.
    
    Cc: stable@vger.kernel.org
    Fixes: 050ac52cbe1f ("mac80211: code for on-demand Hybrid Wireless Mesh Protocol")
    Cc: Simon Wunderlich <sw@simonwunderlich.de>
    Signed-off-by: Linus Lssing <ll@simonwunderlich.de>
    Link: https://lore.kernel.org/r/20200522170413.14973-1-linus.luessing@c0d3.blue
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>

commit 9582d5bdef0cbebbfa451b4894518f0d790f05c8
Author: Lorenzo Bianconi <lorenzo@kernel.org>
Date:   Sat May 2 18:00:41 2020 +0200

    mt76: mt7615: fix ibss mode for mt7663
    
    Fix the following kernel warning adding an adhoc interface to a
    mt7663e device
    
    [  233.363394] WARNING: CPU: 0 PID: 2345 at drivers/net/wireless/mt76/mt7615/mcu.c:1449 mt7615_mcu_uni_add_bss+0x15f/0x24e [mt7615_common]
    [  233.363432] CPU: 0 PID: 2345 Comm: iw Tainted: G        W       4.14.171 #12
    [  233.363434] Hardware name: HP Meep/Meep, BIOS Google_Meep.11297.75.0 06/17/2019
    [  233.363436] task: ffff9a1a4020e3c0 task.stack: ffffb9124113c000
    [  233.363441] RIP: 0010:mt7615_mcu_uni_add_bss+0x15f/0x24e [mt7615_common]
    [  233.363443] RSP: 0018:ffffb9124113f730 EFLAGS: 00010246
    [  233.363446] RAX: 0000000000000024 RBX: ffff9a1a788c74e8 RCX: 41826d413aea9200
    [  233.363448] RDX: 0000000000000007 RSI: 0000000000000006 RDI: ffff9a1a7fc15418
    [  233.363450] RBP: ffffb9124113f7c0 R08: 0000000000000356 R09: 00000000ffff0a10
    [  233.363452] R10: 0000001000000000 R11: ffffffff93f2a4be R12: 0000000000000000
    [  233.363454] R13: ffff9a1a7383bd48 R14: ffffb9124113f77a R15: 0000000000000000
    [  233.363456] FS:  00007f203314ab80(0000) GS:ffff9a1a7fc00000(0000) knlGS:0000000000000000
    [  233.363458] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  233.363460] CR2: 00005a13d647c950 CR3: 0000000171238000 CR4: 00000000003406f0
    [  233.363462] Call Trace:
    [  233.363470]  mt7615_bss_info_changed+0x98/0xf4 [mt7615_common]
    [  233.363484]  ieee80211_bss_info_change_notify+0x139/0x1d4 [mt76_mac80211]
    [  233.363496]  ieee80211_ibss_disconnect+0x183/0x1bb [mt76_mac80211]
    [  233.363507]  ieee80211_ibss_leave+0x14/0xa0 [mt76_mac80211]
    [  233.363519]  __cfg80211_leave_ibss+0xa6/0x13a [cfg80211]
    [  233.363528]  cfg80211_netdev_notifier_call+0x8b/0x631 [cfg80211]
    [  233.363535]  ? packet_notifier+0x196/0x1a3
    [  233.363540]  raw_notifier_call_chain+0x39/0x58
    [  233.363544]  __dev_close_many+0x6b/0xf0
    [  233.363548]  dev_close_many+0x62/0xe8
    [  233.363552]  ? _raw_spin_unlock_irq+0xe/0x21
    [  233.363555]  rollback_registered_many+0xf6/0x35c
    [  233.363560]  ? __rcu_read_unlock+0x4a/0x4a
    [  233.363563]  unregister_netdevice_queue+0x7f/0x105
    [  233.363573]  ieee80211_del_iface+0x12/0x16 [mt76_mac80211]
    [  233.363582]  nl80211_del_interface+0xa8/0x124 [cfg80211]
    [  233.363588]  genl_rcv_msg+0x40b/0x481
    [  233.363592]  ? genl_unbind+0xb8/0xb8
    [  233.363595]  netlink_rcv_skb+0x85/0xf8
    [  233.363598]  genl_rcv+0x28/0x36
    [  233.363601]  netlink_unicast+0x165/0x1f8
    [  233.363604]  netlink_sendmsg+0x35f/0x3a6
    [  233.363608]  sock_sendmsg+0x38/0x48
    [  233.363611]  ___sys_sendmsg+0x1bf/0x267
    [  233.363615]  ? __inode_wait_for_writeback+0x72/0xd7
    [  233.363619]  ? dentry_kill+0x69/0x76
    [  233.363622]  ? dput+0xd1/0x170
    [  233.363624]  __sys_sendmsg+0x52/0x8f
    [  233.363628]  do_syscall_64+0x6b/0xf7
    [  233.363632]  entry_SYSCALL_64_after_hwframe+0x3d/0xa2
    [  233.363635] RIP: 0033:0x7f2032ca1264
    [  233.363637] RSP: 002b:00007ffec3668e38 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  233.363639] RAX: ffffffffffffffda RBX: 000058f7175e7880 RCX: 00007f2032ca1264
    [  233.363641] RDX: 0000000000000000 RSI: 00007ffec3668e98 RDI: 0000000000000003
    [  233.363643] RBP: 00007ffec3668e70 R08: 0000000000000001 R09: 00007f2032ce1fd0
    [  233.363645] R10: 000058f7175e2010 R11: 0000000000000246 R12: 000058f7175e7740
    [  233.363646] R13: 00007ffec3668ff0 R14: 000058f7175e2350 R15: 00007ffec3668e98
    
    Fixes: f40ac0f3d3c0 ("mt76: mt7615: introduce mt7663e support")
    Signed-off-by: Lorenzo Bianconi <lorenzo@kernel.org>
    Signed-off-by: Felix Fietkau <nbd@nbd.name>

commit a621372a04ac6435edbf270ff85edae8a3e04c91
Author: Lorenzo Bianconi <lorenzo@kernel.org>
Date:   Wed Apr 22 10:47:23 2020 +0200

    mt76: mt7615: rework mt7615_mac_sta_poll for usb code
    
    Since usb code can't access device registers in interrupt context, move
    rcu_read_lock/rcu_read_unlock in mt7615_poll_tx routine. Moreover loop
    over a local msta list in mt7615_mac_sta_poll since mt7663u driver will
    not be able to complete the inner while loop before sta_poll_list list
    is refilled by mt7615_mac_add_txs/mt7615_mac_fill_rx
    
    Signed-off-by: Lorenzo Bianconi <lorenzo@kernel.org>
    Signed-off-by: Felix Fietkau <nbd@nbd.name>

commit 3eb2ce0b1602c7eca71ba91148ed97d1bfc51ef7
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    commit 5604285839aaedfb23ebe297799c6e558939334d upstream.
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    [bwh: Backported to 3.16: adjust filename]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit f19d773f4a3192baf31500e77d4088c8e1be248c
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 upstream.
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    [bwh: Backported to 3.16: adjust filename]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 6d8764d3b222716eda5050ecda0bc461080ce435
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    [bwh: Backported to 3.16: adjust filename, context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit b38f57c1fe64276773b124dffb0a139cc32ab3cb
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Fri Mar 20 14:29:08 2020 -0700

    rcu-tasks: Allow rcu_read_unlock_trace() under scheduler locks
    
    The rcu_read_unlock_trace() can invoke rcu_read_unlock_trace_special(),
    which in turn can call wake_up().  Therefore, if any scheduler lock is
    held across a call to rcu_read_unlock_trace(), self-deadlock can occur.
    This commit therefore uses the irq_work facility to defer the wake_up()
    to a clean environment where no scheduler locks will be held.
    
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    [ paulmck: Update #includes for m68k per kbuild test robot. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 7d0c9c50c5a109acd7a5cf589fc5563f9ef7149a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Thu Mar 19 15:33:12 2020 -0700

    rcu-tasks: Avoid IPIing userspace/idle tasks if kernel is so built
    
    Systems running CPU-bound real-time task do not want IPIs sent to CPUs
    executing nohz_full userspace tasks.  Battery-powered systems don't
    want IPIs sent to idle CPUs in low-power mode.  Unfortunately, RCU tasks
    trace can and will send such IPIs in some cases.
    
    Both of these situations occur only when the target CPU is in RCU
    dyntick-idle mode, in other words, when RCU is not watching the
    target CPU.  This suggests that CPUs in dyntick-idle mode should use
    memory barriers in outermost invocations of rcu_read_lock_trace()
    and rcu_read_unlock_trace(), which would allow the RCU tasks trace
    grace period to directly read out the target CPU's read-side state.
    One challenge is that RCU tasks trace is not targeting a specific
    CPU, but rather a task.  And that task could switch from one CPU to
    another at any time.
    
    This commit therefore uses try_invoke_on_locked_down_task()
    and checks for task_curr() in trc_inspect_reader_notrunning().
    When this condition holds, the target task is running and cannot move.
    If CONFIG_TASKS_TRACE_RCU_READ_MB=y, the new rcu_dynticks_zero_in_eqs()
    function can be used to check if the specified integer (in this case,
    t->trc_reader_nesting) is zero while the target CPU remains in that same
    dyntick-idle sojourn.  If so, the target task is in a quiescent state.
    If not, trc_read_check_handler() must indicate failure so that the
    grace-period kthread can take appropriate action or retry after an
    appropriate delay, as the case may be.
    
    With this change, given CONFIG_TASKS_TRACE_RCU_READ_MB=y, if a given
    CPU remains idle or a given task continues executing in nohz_full mode,
    the RCU tasks trace grace-period kthread will detect this without the
    need to send an IPI.
    
    Suggested-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 9ae58d7bd11f1fc4c96389df11751f8593d8bd33
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Mar 18 17:16:37 2020 -0700

    rcu-tasks: Add Kconfig option to mediate smp_mb() vs. IPI
    
    This commit provides a new TASKS_TRACE_RCU_READ_MB Kconfig option that
    enables use of read-side memory barriers by both rcu_read_lock_trace()
    and rcu_read_unlock_trace() when the are executed with the
    current->trc_reader_special.b.need_mb flag set.  This flag is currently
    never set.  Doing that is the subject of a later commit.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 276c410448dbca357a2bc3539acfe04862e5f172
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue Mar 17 16:02:06 2020 -0700

    rcu-tasks: Split ->trc_reader_need_end
    
    This commit splits ->trc_reader_need_end by using the rcu_special union.
    This change permits readers to check to see if a memory barrier is
    required without any added overhead in the common case where no such
    barrier is required.  This commit also adds the read-side checking.
    Later commits will add the machinery to properly set the new
    ->trc_reader_special.b.need_mb field.
    
    This commit also makes rcu_read_unlock_trace_special() tolerate nested
    read-side critical sections within interrupt and NMI handlers.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit d5f177d35c24429c87db2567d20563fc16f7e8f6
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Mar 9 19:56:53 2020 -0700

    rcu-tasks: Add an RCU Tasks Trace to simplify protection of tracing hooks
    
    Because RCU does not watch exception early-entry/late-exit, idle-loop,
    or CPU-hotplug execution, protection of tracing and BPF operations is
    needlessly complicated.  This commit therefore adds a variant of
    Tasks RCU that:
    
    o       Has explicit read-side markers to allow finite grace periods in
            the face of in-kernel loops for PREEMPT=n builds.  These markers
            are rcu_read_lock_trace() and rcu_read_unlock_trace().
    
    o       Protects code in the idle loop, exception entry/exit, and
            CPU-hotplug code paths.  In this respect, RCU-tasks trace is
            similar to SRCU, but with lighter-weight readers.
    
    o       Avoids expensive read-side instruction, having overhead similar
            to that of Preemptible RCU.
    
    There are of course downsides:
    
    o       The grace-period code can send IPIs to CPUs, even when those
            CPUs are in the idle loop or in nohz_full userspace.  This is
            mitigated by later commits.
    
    o       It is necessary to scan the full tasklist, much as for Tasks RCU.
    
    o       There is a single callback queue guarded by a single lock,
            again, much as for Tasks RCU.  However, those early use cases
            that request multiple grace periods in quick succession are
            expected to do so from a single task, which makes the single
            lock almost irrelevant.  If needed, multiple callback queues
            can be provided using any number of schemes.
    
    Perhaps most important, this variant of RCU does not affect the vanilla
    flavors, rcu_preempt and rcu_sched.  The fact that RCU Tasks Trace
    readers can operate from idle, offline, and exception entry/exit in no
    way enables rcu_preempt and rcu_sched readers to do so.
    
    The memory ordering was outlined here:
    https://lore.kernel.org/lkml/20200319034030.GX3199@paulmck-ThinkPad-P72/
    
    This effort benefited greatly from off-list discussions of BPF
    requirements with Alexei Starovoitov and Andrii Nakryiko.  At least
    some of the on-list discussions are captured in the Link: tags below.
    In addition, KCSAN was quite helpful in finding some early bugs.
    
    Link: https://lore.kernel.org/lkml/20200219150744.428764577@infradead.org/
    Link: https://lore.kernel.org/lkml/87mu8p797b.fsf@nanos.tec.linutronix.de/
    Link: https://lore.kernel.org/lkml/20200225221305.605144982@linutronix.de/
    Cc: Alexei Starovoitov <alexei.starovoitov@gmail.com>
    Cc: Andrii Nakryiko <andriin@fb.com>
    [ paulmck: Apply feedback from Steve Rostedt and Joel Fernandes. ]
    [ paulmck: Decrement trc_n_readers_need_end upon IPI failure. ]
    [ paulmck: Fix locking issue reported by rcutorture. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 52b1fc3f798d02a3a9d1cf7a84e98a795223410a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Sat Mar 28 18:53:25 2020 -0700

    rcutorture: Add test of holding scheduler locks across rcu_read_unlock()
    
    Now that it should be safe to hold scheduler locks across
    rcu_read_unlock(), even in cases where the corresponding RCU read-side
    critical section might have been preempted and boosted, the commit adds
    a test of this capability to rcutorture.  This has been tested on current
    mainline (which can deadlock in this situation), and lockdep duly reported
    the expected deadlock.  On -rcu, lockdep is silent, thus far, anyway.
    
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Juri Lelli <juri.lelli@redhat.com>
    Cc: Vincent Guittot <vincent.guittot@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 5f5fa7ea89dc82d34ed458f4d7a8634e8e9eefce
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Sat Feb 15 15:23:26 2020 -0800

    rcu: Don't use negative nesting depth in __rcu_read_unlock()
    
    Now that RCU flavors have been consolidated, an RCU-preempt
    rcu_read_unlock() in an interrupt or softirq handler cannot possibly
    end the RCU read-side critical section.  Consider the old vulnerability
    involving rcu_read_unlock() being invoked within such a handler that
    interrupted an __rcu_read_unlock_special(), in which a wakeup might be
    invoked with a scheduler lock held.  Because rcu_read_unlock_special()
    no longer does wakeups in such situations, it is no longer necessary
    for __rcu_read_unlock() to set the nesting level negative.
    
    This commit therefore removes this recursion-protection code from
    __rcu_read_unlock().
    
    [ paulmck: Let rcu_exp_handler() continue to call rcu_report_exp_rdp(). ]
    [ paulmck: Adjust other checks given no more negative nesting. ]
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit f0bdf6d473cf12a488a78422e15aafdfe77cf853
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Sat Feb 15 14:52:32 2020 -0800

    rcu: Remove unused ->rcu_read_unlock_special.b.deferred_qs field
    
    The ->rcu_read_unlock_special.b.deferred_qs field is set to true in
    rcu_read_unlock_special() but never set to false.  This is not
    particularly useful, so this commit removes this field.
    
    The only possible justification for this field is to ease debugging
    of RCU deferred quiscent states, but the combination of the other
    ->rcu_read_unlock_special fields plus ->rcu_blocked_node and of course
    ->rcu_read_lock_nesting should cover debugging needs.  And if this last
    proves incorrect, this patch can always be reverted, along with the
    required setting of ->rcu_read_unlock_special.b.deferred_qs to false
    in rcu_preempt_deferred_qs_irqrestore().
    
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 07b4a930fc44a537efecf73c1fd2b4937f64caaa
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Sat Feb 15 14:37:26 2020 -0800

    rcu: Don't set nesting depth negative in rcu_preempt_deferred_qs()
    
    Now that RCU flavors have been consolidated, an RCU-preempt
    rcu_read_unlock() in an interrupt or softirq handler cannot possibly
    end the RCU read-side critical section.  Consider the old vulnerability
    involving rcu_preempt_deferred_qs() being invoked within such a handler
    that interrupted an extended RCU read-side critical section, in which
    a wakeup might be invoked with a scheduler lock held.  Because
    rcu_read_unlock_special() no longer does wakeups in such situations,
    it is no longer necessary for rcu_preempt_deferred_qs() to set the
    nesting level negative.
    
    This commit therefore removes this recursion-protection code from
    rcu_preempt_deferred_qs().
    
    [ paulmck: Fix typo in commit log per Steve Rostedt. ]
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit e4453d8a1c56050df320ef54f339ffa4a9513d0a
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Sat Feb 15 14:18:09 2020 -0800

    rcu: Make rcu_read_unlock_special() safe for rq/pi locks
    
    The scheduler is currently required to hold rq/pi locks across the entire
    RCU read-side critical section or not at all.  This is inconvenient and
    leaves traps for the unwary, including the author of this commit.
    
    But now that excessively long grace periods enable scheduling-clock
    interrupts for holdout nohz_full CPUs, the nohz_full rescue logic in
    rcu_read_unlock_special() can be dispensed with.  In other words, the
    rcu_read_unlock_special() function can refrain from doing wakeups unless
    such wakeups are guaranteed safe.
    
    This commit therefore avoids unsafe wakeups, freeing the scheduler to
    hold rq/pi locks across rcu_read_unlock() even if the corresponding RCU
    read-side critical section might have been preempted.  This commit also
    updates RCU's requirements documentation.
    
    This commit is inspired by a patch from Lai Jiangshan:
    https://lore.kernel.org/lkml/20191102124559.1135-2-laijs@linux.alibaba.com
    This commit is further intended to be a step towards his goal of permitting
    the inlining of RCU-preempt's rcu_read_lock() and rcu_read_unlock().
    
    Cc: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 8c0b2d8213f07e3c9d7f4c9b1ef6cb45b5fe277f
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jul 6 15:31:46 2017 +0100

    Btrfs: incremental send, fix invalid memory access
    
    commit 24e52b11e0ca788513b945a87b57cc0522a92933 upstream.
    
    When doing an incremental send, while processing an extent that changed
    between the parent and send snapshots and that extent was an inline extent
    in the parent snapshot, it's possible to access a memory region beyond
    the end of leaf if the inline extent is very small and it is the first
    item in a leaf.
    
    An example scenario is described below.
    
    The send snapshot has the following leaf:
    
     leaf 33865728 items 33 free space 773 generation 46 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            (...)
            item 14 key (335 EXTENT_DATA 0) itemoff 3052 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 12791808 nr 4096
                    extent data offset 0 nr 4096 ram 4096
                    extent compression 0 (none)
            item 15 key (335 EXTENT_DATA 8192) itemoff 2999 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 138170368 nr 225280
                    extent data offset 0 nr 225280 ram 225280
                    extent compression 0 (none)
            (...)
    
    And the parent snapshot has the following leaf:
    
     leaf 31272960 items 17 free space 17 generation 31 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            item 0 key (335 EXTENT_DATA 0) itemoff 3951 itemsize 44
                    generation 31 type 0 (inline)
                    inline extent data size 23 ram_bytes 613 compression 1 (zlib)
            (...)
    
    When computing the send stream, it is detected that the extent of inode
    335, at file offset 0, and at fs/btrfs/send.c:is_extent_unchanged() we
    grab the leaf from the parent snapshot and access the inline extent item.
    However, before jumping to the 'out' label, we access the 'offset' and
    'disk_bytenr' fields of the extent item, which should not be done for
    inline extents since the inlined data starts at the offset of the
    'disk_bytenr' field and can be very small. For example accessing the
    'offset' field of the file extent item results in the following trace:
    
    [  599.705368] general protection fault: 0000 [#1] PREEMPT SMP
    [  599.706296] Modules linked in: btrfs psmouse i2c_piix4 ppdev acpi_cpufreq serio_raw parport_pc i2c_core evdev tpm_tis tpm_tis_core sg pcspkr parport tpm button su$
    [  599.709340] CPU: 7 PID: 5283 Comm: btrfs Not tainted 4.10.0-rc8-btrfs-next-46+ #1
    [  599.709340] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  599.709340] task: ffff88023eedd040 task.stack: ffffc90006658000
    [  599.709340] RIP: 0010:read_extent_buffer+0xdb/0xf4 [btrfs]
    [  599.709340] RSP: 0018:ffffc9000665ba00 EFLAGS: 00010286
    [  599.709340] RAX: db73880000000000 RBX: 0000000000000000 RCX: 0000000000000001
    [  599.709340] RDX: ffffc9000665ba60 RSI: db73880000000000 RDI: ffffc9000665ba5f
    [  599.709340] RBP: ffffc9000665ba30 R08: 0000000000000001 R09: ffff88020dc5e098
    [  599.709340] R10: 0000000000001000 R11: 0000160000000000 R12: 6db6db6db6db6db7
    [  599.709340] R13: ffff880000000000 R14: 0000000000000000 R15: ffff88020dc5e088
    [  599.709340] FS:  00007f519555a8c0(0000) GS:ffff88023f3c0000(0000) knlGS:0000000000000000
    [  599.709340] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  599.709340] CR2: 00007f1411afd000 CR3: 0000000235f8e000 CR4: 00000000000006e0
    [  599.709340] Call Trace:
    [  599.709340]  btrfs_get_token_64+0x93/0xce [btrfs]
    [  599.709340]  ? printk+0x48/0x50
    [  599.709340]  btrfs_get_64+0xb/0xd [btrfs]
    [  599.709340]  process_extent+0x3a1/0x1106 [btrfs]
    [  599.709340]  ? btree_read_extent_buffer_pages+0x5/0xef [btrfs]
    [  599.709340]  changed_cb+0xb03/0xb3d [btrfs]
    [  599.709340]  ? btrfs_get_token_32+0x7a/0xcc [btrfs]
    [  599.709340]  btrfs_compare_trees+0x432/0x53d [btrfs]
    [  599.709340]  ? process_extent+0x1106/0x1106 [btrfs]
    [  599.709340]  btrfs_ioctl_send+0x960/0xe26 [btrfs]
    [  599.709340]  btrfs_ioctl+0x181b/0x1fed [btrfs]
    [  599.709340]  ? trace_hardirqs_on_caller+0x150/0x1ac
    [  599.709340]  vfs_ioctl+0x21/0x38
    [  599.709340]  ? vfs_ioctl+0x21/0x38
    [  599.709340]  do_vfs_ioctl+0x611/0x645
    [  599.709340]  ? rcu_read_unlock+0x5b/0x5d
    [  599.709340]  ? __fget+0x6d/0x79
    [  599.709340]  SyS_ioctl+0x57/0x7b
    [  599.709340]  entry_SYSCALL_64_fastpath+0x18/0xad
    [  599.709340] RIP: 0033:0x7f51945eec47
    [  599.709340] RSP: 002b:00007ffc21c13e98 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
    [  599.709340] RAX: ffffffffffffffda RBX: ffffffff81096459 RCX: 00007f51945eec47
    [  599.709340] RDX: 00007ffc21c13f20 RSI: 0000000040489426 RDI: 0000000000000004
    [  599.709340] RBP: ffffc9000665bf98 R08: 00007f519450d700 R09: 00007f519450d700
    [  599.709340] R10: 00007f519450d9d0 R11: 0000000000000202 R12: 0000000000000046
    [  599.709340] R13: ffffc9000665bf78 R14: 0000000000000000 R15: 00007f5195574040
    [  599.709340]  ? trace_hardirqs_off_caller+0x43/0xb1
    [  599.709340] Code: 29 f0 49 39 d8 4c 0f 47 c3 49 03 81 58 01 00 00 44 89 c1 4c 01 c2 4c 29 c3 48 c1 f8 03 49 0f af c4 48 c1 e0 0c 4c 01 e8 48 01 c6 <f3> a4 31 f6 4$
    [  599.709340] RIP: read_extent_buffer+0xdb/0xf4 [btrfs] RSP: ffffc9000665ba00
    [  599.762057] ---[ end trace fe00d7af61b9f49e ]---
    
    This is because the 'offset' field starts at an offset of 37 bytes
    (offsetof(struct btrfs_file_extent_item, offset)), has a length of 8
    bytes and therefore attemping to read it causes a 1 byte access beyond
    the end of the leaf, as the first item's content in a leaf is located
    at the tail of the leaf, the item size is 44 bytes and the offset of
    that field plus its length (37 + 8 = 45) goes beyond the item's size
    by 1 byte.
    
    So fix this by accessing the 'offset' and 'disk_bytenr' fields after
    jumping to the 'out' label if we are processing an inline extent. We
    move the reading operation of the 'disk_bytenr' field too because we
    have the same problem as for the 'offset' field explained above when
    the inline data is less then 8 bytes. The access to the 'generation'
    field is also moved but just for the sake of grouping access to all
    the fields.
    
    Fixes: e1cbfd7bf6da ("Btrfs: send, fix file hole not being preserved due to inline extent")
    Cc: <stable@vger.kernel.org>  # v4.12+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 774acb2a094c218cb0129979afc67eda7e1ec4b9
Merge: b484f3c3c6f1 a966dcfe153a
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat Apr 18 11:38:51 2020 -0700

    Merge tag 'for-linus-2020-04-18' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux
    
    Pull thread fixes from Christian Brauner:
     "A few fixes and minor improvements:
    
       - Correctly validate the cgroup file descriptor when clone3() is used
         with CLONE_INTO_CGROUP.
    
       - Check that a new enough version of struct clone_args is passed
         which supports the cgroup file descriptor argument when
         CLONE_INTO_CGROUP is set in the flags argument.
    
       - Catch nonsensical struct clone_args layouts at build time.
    
       - Catch extensions of struct clone_args without updating the uapi
         visible size definitions at build time.
    
       - Check whether the signal is valid early in kill_pid_usb_asyncio()
         before doing further work.
    
       - Replace open-coded rcu_read_lock()+kill_pid_info()+rcu_read_unlock()
         sequence in kill_something_info() with kill_proc_info() which is a
         dedicated helper to do just that"
    
    * tag 'for-linus-2020-04-18' of git://git.kernel.org/pub/scm/linux/kernel/git/brauner/linux:
      clone3: add build-time CLONE_ARGS_SIZE_VER* validity checks
      clone3: add a check for the user struct size if CLONE_INTO_CGROUP is set
      clone3: fix cgroup argument sanity check
      signal: use kill_proc_info instead of kill_pid_info in kill_something_info
      signal: check sig before setting info in kill_pid_usb_asyncio

commit 8a374cccee8cdfa2902bb7a07a10671ffc1a72c1
Author: Jules Irenge <jbi.octave@gmail.com>
Date:   Mon Apr 6 20:08:24 2020 -0700

    mm/zsmalloc: add missing annotation for migrate_read_unlock()
    
    Sparse reports a warning at migrate_read_unlock()()
    
     warning: context imbalance in migrate_read_unlock() - unexpected unlock
    
    The root cause is the missing annotation at migrate_read_unlock()
    Add the missing __releases(&zspage->lock) annotation
    
    Signed-off-by: Jules Irenge <jbi.octave@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Link: http://lkml.kernel.org/r/20200214204741.94112-12-jbi.octave@gmail.com
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 0ac1dd7bb8f1b40f1bf494f6a27235a7a3b36350
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    commit 4c59406ed00379c8663f8663d82b2537467ce9d7 upstream.
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5778b9b2aaa071c3bae1931b4c208304472fb129
Author: Lyude Paul <lyude@redhat.com>
Date:   Wed Nov 28 16:00:05 2018 -0500

    Revert "drm/dp_mst: Skip validating ports during destruction, just ref"
    
    commit 9765635b30756eb74e05e260ac812659c296cd28 upstream.
    
    This reverts commit:
    
    c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    
    ugh.
    
    In drm_dp_destroy_connector_work(), we have a pretty good chance of
    freeing the actual struct drm_dp_mst_port. However, after destroying
    things we send a hotplug through (*mgr->cbs->hotplug)(mgr) which is
    where the problems start.
    
    For i915, this calls all the way down to the fbcon probing helpers,
    which start trying to access the port in a modeset.
    
    [   45.062001] ==================================================================
    [   45.062112] BUG: KASAN: use-after-free in ex_handler_refcount+0x146/0x180
    [   45.062196] Write of size 4 at addr ffff8882b4b70968 by task kworker/3:1/53
    
    [   45.062325] CPU: 3 PID: 53 Comm: kworker/3:1 Kdump: loaded Tainted: G           O      4.20.0-rc4Lyude-Test+ #3
    [   45.062442] Hardware name: LENOVO 20BWS1KY00/20BWS1KY00, BIOS JBET71WW (1.35 ) 09/14/2018
    [   45.062554] Workqueue: events drm_dp_destroy_connector_work [drm_kms_helper]
    [   45.062641] Call Trace:
    [   45.062685]  dump_stack+0xbd/0x15a
    [   45.062735]  ? dump_stack_print_info.cold.0+0x1b/0x1b
    [   45.062801]  ? printk+0x9f/0xc5
    [   45.062847]  ? kmsg_dump_rewind_nolock+0xe4/0xe4
    [   45.062909]  ? ex_handler_refcount+0x146/0x180
    [   45.062970]  print_address_description+0x71/0x239
    [   45.063036]  ? ex_handler_refcount+0x146/0x180
    [   45.063095]  kasan_report.cold.5+0x242/0x30b
    [   45.063155]  __asan_report_store4_noabort+0x1c/0x20
    [   45.063313]  ex_handler_refcount+0x146/0x180
    [   45.063371]  ? ex_handler_clear_fs+0xb0/0xb0
    [   45.063428]  fixup_exception+0x98/0xd7
    [   45.063484]  ? raw_notifier_call_chain+0x20/0x20
    [   45.063548]  do_trap+0x6d/0x210
    [   45.063605]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063732]  do_error_trap+0xc0/0x170
    [   45.063802]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063929]  do_invalid_op+0x3b/0x50
    [   45.063997]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064103]  invalid_op+0x14/0x20
    [   45.064162] RIP: 0010:_GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064274] Code: 00 48 c7 c7 80 fe 53 a0 48 89 e5 e8 5b 6f 26 e1 5d c3 48 8d 0e 0f 0b 48 8d 0b 0f 0b 48 8d 0f 0f 0b 48 8d 0f 0f 0b 49 8d 4d 00 <0f> 0b 49 8d 0e 0f 0b 48 8d 08 0f 0b 49 8d 4d 00 0f 0b 48 8d 0b 0f
    [   45.064569] RSP: 0018:ffff8882b789ee10 EFLAGS: 00010282
    [   45.064637] RAX: ffff8882af47ae70 RBX: ffff8882af47aa60 RCX: ffff8882b4b70968
    [   45.064723] RDX: ffff8882af47ae70 RSI: 0000000000000008 RDI: ffff8882b788bdb8
    [   45.064808] RBP: ffff8882b789ee28 R08: ffffed1056f13db4 R09: ffffed1056f13db3
    [   45.064894] R10: ffffed1056f13db3 R11: ffff8882b789ed9f R12: ffff8882af47ad28
    [   45.064980] R13: ffff8882b4b70968 R14: ffff8882acd86728 R15: ffff8882b4b75dc8
    [   45.065084]  drm_dp_mst_reset_vcpi_slots+0x12/0x80 [drm_kms_helper]
    [   45.065225]  intel_mst_disable_dp+0xda/0x180 [i915]
    [   45.065361]  intel_encoders_disable.isra.107+0x197/0x310 [i915]
    [   45.065498]  haswell_crtc_disable+0xbe/0x400 [i915]
    [   45.065622]  ? i9xx_disable_plane+0x1c0/0x3e0 [i915]
    [   45.065750]  intel_atomic_commit_tail+0x74e/0x3e60 [i915]
    [   45.065884]  ? intel_pre_plane_update+0xbc0/0xbc0 [i915]
    [   45.065968]  ? drm_atomic_helper_swap_state+0x88b/0x1d90 [drm_kms_helper]
    [   45.066054]  ? kasan_check_write+0x14/0x20
    [   45.066165]  ? i915_gem_track_fb+0x13a/0x330 [i915]
    [   45.066277]  ? i915_sw_fence_complete+0xe9/0x140 [i915]
    [   45.066406]  ? __i915_sw_fence_complete+0xc50/0xc50 [i915]
    [   45.066540]  intel_atomic_commit+0x72e/0xef0 [i915]
    [   45.066635]  ? drm_dev_dbg+0x200/0x200 [drm]
    [   45.066764]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.066898]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.067001]  drm_atomic_commit+0xc4/0xf0 [drm]
    [   45.067074]  restore_fbdev_mode_atomic+0x562/0x780 [drm_kms_helper]
    [   45.067166]  ? drm_fb_helper_debug_leave+0x690/0x690 [drm_kms_helper]
    [   45.067249]  ? kasan_check_read+0x11/0x20
    [   45.067324]  restore_fbdev_mode+0x127/0x4b0 [drm_kms_helper]
    [   45.067364]  ? kasan_check_read+0x11/0x20
    [   45.067406]  drm_fb_helper_restore_fbdev_mode_unlocked+0x164/0x200 [drm_kms_helper]
    [   45.067462]  ? drm_fb_helper_hotplug_event+0x30/0x30 [drm_kms_helper]
    [   45.067508]  ? kasan_check_write+0x14/0x20
    [   45.070360]  ? mutex_unlock+0x22/0x40
    [   45.073748]  drm_fb_helper_set_par+0xb2/0xf0 [drm_kms_helper]
    [   45.075846]  drm_fb_helper_hotplug_event.part.33+0x1cd/0x290 [drm_kms_helper]
    [   45.078088]  drm_fb_helper_hotplug_event+0x1c/0x30 [drm_kms_helper]
    [   45.082614]  intel_fbdev_output_poll_changed+0x9f/0x140 [i915]
    [   45.087069]  drm_kms_helper_hotplug_event+0x67/0x90 [drm_kms_helper]
    [   45.089319]  intel_dp_mst_hotplug+0x37/0x50 [i915]
    [   45.091496]  drm_dp_destroy_connector_work+0x510/0x6f0 [drm_kms_helper]
    [   45.093675]  ? drm_dp_update_payload_part1+0x1220/0x1220 [drm_kms_helper]
    [   45.095851]  ? kasan_check_write+0x14/0x20
    [   45.098473]  ? kasan_check_read+0x11/0x20
    [   45.101155]  ? strscpy+0x17c/0x530
    [   45.103808]  ? __switch_to_asm+0x34/0x70
    [   45.106456]  ? syscall_return_via_sysret+0xf/0x7f
    [   45.109711]  ? read_word_at_a_time+0x20/0x20
    [   45.113138]  ? __switch_to_asm+0x40/0x70
    [   45.116529]  ? __switch_to_asm+0x34/0x70
    [   45.119891]  ? __switch_to_asm+0x40/0x70
    [   45.123224]  ? __switch_to_asm+0x34/0x70
    [   45.126540]  ? __switch_to_asm+0x34/0x70
    [   45.129824]  process_one_work+0x88d/0x15d0
    [   45.133172]  ? pool_mayday_timeout+0x850/0x850
    [   45.136459]  ? pci_mmcfg_check_reserved+0x110/0x128
    [   45.139739]  ? wake_q_add+0xb0/0xb0
    [   45.143010]  ? check_preempt_wakeup+0x652/0x1050
    [   45.146304]  ? worker_enter_idle+0x29e/0x740
    [   45.149589]  ? __schedule+0x1ec0/0x1ec0
    [   45.152937]  ? kasan_check_read+0x11/0x20
    [   45.156179]  ? _raw_spin_lock_irq+0xa3/0x130
    [   45.159382]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   45.162542]  ? kasan_check_write+0x14/0x20
    [   45.165657]  worker_thread+0x1a5/0x1470
    [   45.168725]  ? set_load_weight+0x2e0/0x2e0
    [   45.171755]  ? process_one_work+0x15d0/0x15d0
    [   45.174806]  ? __switch_to_asm+0x34/0x70
    [   45.177645]  ? __switch_to_asm+0x40/0x70
    [   45.180323]  ? __switch_to_asm+0x34/0x70
    [   45.182936]  ? __switch_to_asm+0x40/0x70
    [   45.185539]  ? __switch_to_asm+0x34/0x70
    [   45.188100]  ? __switch_to_asm+0x40/0x70
    [   45.190628]  ? __schedule+0x7d4/0x1ec0
    [   45.193143]  ? save_stack+0xa9/0xd0
    [   45.195632]  ? kasan_check_write+0x10/0x20
    [   45.198162]  ? kasan_kmalloc+0xc4/0xe0
    [   45.200609]  ? kmem_cache_alloc_trace+0xdd/0x190
    [   45.203046]  ? kthread+0x9f/0x3b0
    [   45.205470]  ? ret_from_fork+0x35/0x40
    [   45.207876]  ? unwind_next_frame+0x43/0x50
    [   45.210273]  ? __save_stack_trace+0x82/0x100
    [   45.212658]  ? deactivate_slab.isra.67+0x3d4/0x580
    [   45.215026]  ? default_wake_function+0x35/0x50
    [   45.217399]  ? kasan_check_read+0x11/0x20
    [   45.219825]  ? _raw_spin_lock_irqsave+0xae/0x140
    [   45.222174]  ? __lock_text_start+0x8/0x8
    [   45.224521]  ? replenish_dl_entity.cold.62+0x4f/0x4f
    [   45.226868]  ? __kthread_parkme+0x87/0xf0
    [   45.229200]  kthread+0x2f7/0x3b0
    [   45.231557]  ? process_one_work+0x15d0/0x15d0
    [   45.233923]  ? kthread_park+0x120/0x120
    [   45.236249]  ret_from_fork+0x35/0x40
    
    [   45.240875] Allocated by task 242:
    [   45.243136]  save_stack+0x43/0xd0
    [   45.245385]  kasan_kmalloc+0xc4/0xe0
    [   45.247597]  kmem_cache_alloc_trace+0xdd/0x190
    [   45.249793]  drm_dp_add_port+0x1e0/0x2170 [drm_kms_helper]
    [   45.252000]  drm_dp_send_link_address+0x4a7/0x740 [drm_kms_helper]
    [   45.254389]  drm_dp_check_and_send_link_address+0x1a7/0x210 [drm_kms_helper]
    [   45.256803]  drm_dp_mst_link_probe_work+0x6f/0xb0 [drm_kms_helper]
    [   45.259200]  process_one_work+0x88d/0x15d0
    [   45.261597]  worker_thread+0x1a5/0x1470
    [   45.264038]  kthread+0x2f7/0x3b0
    [   45.266371]  ret_from_fork+0x35/0x40
    
    [   45.270937] Freed by task 53:
    [   45.273170]  save_stack+0x43/0xd0
    [   45.275382]  __kasan_slab_free+0x139/0x190
    [   45.277604]  kasan_slab_free+0xe/0x10
    [   45.279826]  kfree+0x99/0x1b0
    [   45.282044]  drm_dp_free_mst_port+0x4a/0x60 [drm_kms_helper]
    [   45.284330]  drm_dp_destroy_connector_work+0x43e/0x6f0 [drm_kms_helper]
    [   45.286660]  process_one_work+0x88d/0x15d0
    [   45.288934]  worker_thread+0x1a5/0x1470
    [   45.291231]  kthread+0x2f7/0x3b0
    [   45.293547]  ret_from_fork+0x35/0x40
    
    [   45.298206] The buggy address belongs to the object at ffff8882b4b70968
                    which belongs to the cache kmalloc-2k of size 2048
    [   45.303047] The buggy address is located 0 bytes inside of
                    2048-byte region [ffff8882b4b70968, ffff8882b4b71168)
    [   45.308010] The buggy address belongs to the page:
    [   45.310477] page:ffffea000ad2dc00 count:1 mapcount:0 mapping:ffff8882c080cf40 index:0x0 compound_mapcount: 0
    [   45.313051] flags: 0x8000000000010200(slab|head)
    [   45.315635] raw: 8000000000010200 ffffea000aac2808 ffffea000abe8608 ffff8882c080cf40
    [   45.318300] raw: 0000000000000000 00000000000d000d 00000001ffffffff 0000000000000000
    [   45.320966] page dumped because: kasan: bad access detected
    
    [   45.326312] Memory state around the buggy address:
    [   45.329085]  ffff8882b4b70800: fb fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.331845]  ffff8882b4b70880: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.334584] >ffff8882b4b70900: fc fc fc fc fc fc fc fc fc fc fc fc fc fb fb fb
    [   45.337302]                                                           ^
    [   45.340061]  ffff8882b4b70980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.342910]  ffff8882b4b70a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.345748] ==================================================================
    
    So, this definitely isn't a fix that we want. This being said; there's
    no real easy fix for this problem because of some of the catch-22's of
    the MST helpers current design. For starters; we always need to validate
    a port with drm_dp_get_validated_port_ref(), but validation relies on
    the lifetime of the port in the actual topology. So once the port is
    gone, it can't be validated again.
    
    If we were to try to make the payload helpers not use port validation,
    then we'd cause another problem: if the port isn't validated, it could
    be freed and we'd just start causing more KASAN issues. There are
    already hacks that attempt to workaround this in
    drm_dp_mst_destroy_connector_work() by re-initializing the kref so that
    it can be used again and it's memory can be freed once the VCPI helpers
    finish removing the port's respective payloads. But none of these really
    do anything helpful since the port still can't be validated since it's
    gone from the topology. Also, that workaround is immensely confusing to
    read through.
    
    What really needs to be done in order to fix this is to teach DRM how to
    track the lifetime of the structs for MST ports and branch devices
    separately from their lifetime in the actual topology. Simply put; this
    means having two different krefs-one that removes the port/branch device
    from the topology, and one that finally calls kfree(). This would let us
    simplify things, since we'd now be able to keep ports around without
    having to keep them in the topology at the same time, which is exactly
    what we need in order to teach our VCPI helpers to only validate ports
    when it's actually necessary without running the risk of trying to use
    unallocated memory.
    
    Such a fix is on it's way, but for now let's play it safe and just
    revert this. If this bug has been around for well over a year, we can
    wait a little while to get an actual proper fix here.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Fixes: c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Sean Paul <sean@poorly.run>
    Cc: Jerry Zuo <Jerry.Zuo@amd.com>
    Cc: Harry Wentland <Harry.Wentland@amd.com>
    Cc: stable@vger.kernel.org # v4.6+
    Acked-by: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181128210005.24434-1-lyude@redhat.com
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 86e98ce7de083649e330d518e98a80b9e39b5d43
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    commit 4c59406ed00379c8663f8663d82b2537467ce9d7 upstream.
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 594b060252bbc6965c9dbb7c7db636c58815a3ab
Author: Lyude Paul <lyude@redhat.com>
Date:   Wed Nov 28 16:00:05 2018 -0500

    Revert "drm/dp_mst: Skip validating ports during destruction, just ref"
    
    commit 9765635b30756eb74e05e260ac812659c296cd28 upstream.
    
    This reverts commit:
    
    c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    
    ugh.
    
    In drm_dp_destroy_connector_work(), we have a pretty good chance of
    freeing the actual struct drm_dp_mst_port. However, after destroying
    things we send a hotplug through (*mgr->cbs->hotplug)(mgr) which is
    where the problems start.
    
    For i915, this calls all the way down to the fbcon probing helpers,
    which start trying to access the port in a modeset.
    
    [   45.062001] ==================================================================
    [   45.062112] BUG: KASAN: use-after-free in ex_handler_refcount+0x146/0x180
    [   45.062196] Write of size 4 at addr ffff8882b4b70968 by task kworker/3:1/53
    
    [   45.062325] CPU: 3 PID: 53 Comm: kworker/3:1 Kdump: loaded Tainted: G           O      4.20.0-rc4Lyude-Test+ #3
    [   45.062442] Hardware name: LENOVO 20BWS1KY00/20BWS1KY00, BIOS JBET71WW (1.35 ) 09/14/2018
    [   45.062554] Workqueue: events drm_dp_destroy_connector_work [drm_kms_helper]
    [   45.062641] Call Trace:
    [   45.062685]  dump_stack+0xbd/0x15a
    [   45.062735]  ? dump_stack_print_info.cold.0+0x1b/0x1b
    [   45.062801]  ? printk+0x9f/0xc5
    [   45.062847]  ? kmsg_dump_rewind_nolock+0xe4/0xe4
    [   45.062909]  ? ex_handler_refcount+0x146/0x180
    [   45.062970]  print_address_description+0x71/0x239
    [   45.063036]  ? ex_handler_refcount+0x146/0x180
    [   45.063095]  kasan_report.cold.5+0x242/0x30b
    [   45.063155]  __asan_report_store4_noabort+0x1c/0x20
    [   45.063313]  ex_handler_refcount+0x146/0x180
    [   45.063371]  ? ex_handler_clear_fs+0xb0/0xb0
    [   45.063428]  fixup_exception+0x98/0xd7
    [   45.063484]  ? raw_notifier_call_chain+0x20/0x20
    [   45.063548]  do_trap+0x6d/0x210
    [   45.063605]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063732]  do_error_trap+0xc0/0x170
    [   45.063802]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063929]  do_invalid_op+0x3b/0x50
    [   45.063997]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064103]  invalid_op+0x14/0x20
    [   45.064162] RIP: 0010:_GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064274] Code: 00 48 c7 c7 80 fe 53 a0 48 89 e5 e8 5b 6f 26 e1 5d c3 48 8d 0e 0f 0b 48 8d 0b 0f 0b 48 8d 0f 0f 0b 48 8d 0f 0f 0b 49 8d 4d 00 <0f> 0b 49 8d 0e 0f 0b 48 8d 08 0f 0b 49 8d 4d 00 0f 0b 48 8d 0b 0f
    [   45.064569] RSP: 0018:ffff8882b789ee10 EFLAGS: 00010282
    [   45.064637] RAX: ffff8882af47ae70 RBX: ffff8882af47aa60 RCX: ffff8882b4b70968
    [   45.064723] RDX: ffff8882af47ae70 RSI: 0000000000000008 RDI: ffff8882b788bdb8
    [   45.064808] RBP: ffff8882b789ee28 R08: ffffed1056f13db4 R09: ffffed1056f13db3
    [   45.064894] R10: ffffed1056f13db3 R11: ffff8882b789ed9f R12: ffff8882af47ad28
    [   45.064980] R13: ffff8882b4b70968 R14: ffff8882acd86728 R15: ffff8882b4b75dc8
    [   45.065084]  drm_dp_mst_reset_vcpi_slots+0x12/0x80 [drm_kms_helper]
    [   45.065225]  intel_mst_disable_dp+0xda/0x180 [i915]
    [   45.065361]  intel_encoders_disable.isra.107+0x197/0x310 [i915]
    [   45.065498]  haswell_crtc_disable+0xbe/0x400 [i915]
    [   45.065622]  ? i9xx_disable_plane+0x1c0/0x3e0 [i915]
    [   45.065750]  intel_atomic_commit_tail+0x74e/0x3e60 [i915]
    [   45.065884]  ? intel_pre_plane_update+0xbc0/0xbc0 [i915]
    [   45.065968]  ? drm_atomic_helper_swap_state+0x88b/0x1d90 [drm_kms_helper]
    [   45.066054]  ? kasan_check_write+0x14/0x20
    [   45.066165]  ? i915_gem_track_fb+0x13a/0x330 [i915]
    [   45.066277]  ? i915_sw_fence_complete+0xe9/0x140 [i915]
    [   45.066406]  ? __i915_sw_fence_complete+0xc50/0xc50 [i915]
    [   45.066540]  intel_atomic_commit+0x72e/0xef0 [i915]
    [   45.066635]  ? drm_dev_dbg+0x200/0x200 [drm]
    [   45.066764]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.066898]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.067001]  drm_atomic_commit+0xc4/0xf0 [drm]
    [   45.067074]  restore_fbdev_mode_atomic+0x562/0x780 [drm_kms_helper]
    [   45.067166]  ? drm_fb_helper_debug_leave+0x690/0x690 [drm_kms_helper]
    [   45.067249]  ? kasan_check_read+0x11/0x20
    [   45.067324]  restore_fbdev_mode+0x127/0x4b0 [drm_kms_helper]
    [   45.067364]  ? kasan_check_read+0x11/0x20
    [   45.067406]  drm_fb_helper_restore_fbdev_mode_unlocked+0x164/0x200 [drm_kms_helper]
    [   45.067462]  ? drm_fb_helper_hotplug_event+0x30/0x30 [drm_kms_helper]
    [   45.067508]  ? kasan_check_write+0x14/0x20
    [   45.070360]  ? mutex_unlock+0x22/0x40
    [   45.073748]  drm_fb_helper_set_par+0xb2/0xf0 [drm_kms_helper]
    [   45.075846]  drm_fb_helper_hotplug_event.part.33+0x1cd/0x290 [drm_kms_helper]
    [   45.078088]  drm_fb_helper_hotplug_event+0x1c/0x30 [drm_kms_helper]
    [   45.082614]  intel_fbdev_output_poll_changed+0x9f/0x140 [i915]
    [   45.087069]  drm_kms_helper_hotplug_event+0x67/0x90 [drm_kms_helper]
    [   45.089319]  intel_dp_mst_hotplug+0x37/0x50 [i915]
    [   45.091496]  drm_dp_destroy_connector_work+0x510/0x6f0 [drm_kms_helper]
    [   45.093675]  ? drm_dp_update_payload_part1+0x1220/0x1220 [drm_kms_helper]
    [   45.095851]  ? kasan_check_write+0x14/0x20
    [   45.098473]  ? kasan_check_read+0x11/0x20
    [   45.101155]  ? strscpy+0x17c/0x530
    [   45.103808]  ? __switch_to_asm+0x34/0x70
    [   45.106456]  ? syscall_return_via_sysret+0xf/0x7f
    [   45.109711]  ? read_word_at_a_time+0x20/0x20
    [   45.113138]  ? __switch_to_asm+0x40/0x70
    [   45.116529]  ? __switch_to_asm+0x34/0x70
    [   45.119891]  ? __switch_to_asm+0x40/0x70
    [   45.123224]  ? __switch_to_asm+0x34/0x70
    [   45.126540]  ? __switch_to_asm+0x34/0x70
    [   45.129824]  process_one_work+0x88d/0x15d0
    [   45.133172]  ? pool_mayday_timeout+0x850/0x850
    [   45.136459]  ? pci_mmcfg_check_reserved+0x110/0x128
    [   45.139739]  ? wake_q_add+0xb0/0xb0
    [   45.143010]  ? check_preempt_wakeup+0x652/0x1050
    [   45.146304]  ? worker_enter_idle+0x29e/0x740
    [   45.149589]  ? __schedule+0x1ec0/0x1ec0
    [   45.152937]  ? kasan_check_read+0x11/0x20
    [   45.156179]  ? _raw_spin_lock_irq+0xa3/0x130
    [   45.159382]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   45.162542]  ? kasan_check_write+0x14/0x20
    [   45.165657]  worker_thread+0x1a5/0x1470
    [   45.168725]  ? set_load_weight+0x2e0/0x2e0
    [   45.171755]  ? process_one_work+0x15d0/0x15d0
    [   45.174806]  ? __switch_to_asm+0x34/0x70
    [   45.177645]  ? __switch_to_asm+0x40/0x70
    [   45.180323]  ? __switch_to_asm+0x34/0x70
    [   45.182936]  ? __switch_to_asm+0x40/0x70
    [   45.185539]  ? __switch_to_asm+0x34/0x70
    [   45.188100]  ? __switch_to_asm+0x40/0x70
    [   45.190628]  ? __schedule+0x7d4/0x1ec0
    [   45.193143]  ? save_stack+0xa9/0xd0
    [   45.195632]  ? kasan_check_write+0x10/0x20
    [   45.198162]  ? kasan_kmalloc+0xc4/0xe0
    [   45.200609]  ? kmem_cache_alloc_trace+0xdd/0x190
    [   45.203046]  ? kthread+0x9f/0x3b0
    [   45.205470]  ? ret_from_fork+0x35/0x40
    [   45.207876]  ? unwind_next_frame+0x43/0x50
    [   45.210273]  ? __save_stack_trace+0x82/0x100
    [   45.212658]  ? deactivate_slab.isra.67+0x3d4/0x580
    [   45.215026]  ? default_wake_function+0x35/0x50
    [   45.217399]  ? kasan_check_read+0x11/0x20
    [   45.219825]  ? _raw_spin_lock_irqsave+0xae/0x140
    [   45.222174]  ? __lock_text_start+0x8/0x8
    [   45.224521]  ? replenish_dl_entity.cold.62+0x4f/0x4f
    [   45.226868]  ? __kthread_parkme+0x87/0xf0
    [   45.229200]  kthread+0x2f7/0x3b0
    [   45.231557]  ? process_one_work+0x15d0/0x15d0
    [   45.233923]  ? kthread_park+0x120/0x120
    [   45.236249]  ret_from_fork+0x35/0x40
    
    [   45.240875] Allocated by task 242:
    [   45.243136]  save_stack+0x43/0xd0
    [   45.245385]  kasan_kmalloc+0xc4/0xe0
    [   45.247597]  kmem_cache_alloc_trace+0xdd/0x190
    [   45.249793]  drm_dp_add_port+0x1e0/0x2170 [drm_kms_helper]
    [   45.252000]  drm_dp_send_link_address+0x4a7/0x740 [drm_kms_helper]
    [   45.254389]  drm_dp_check_and_send_link_address+0x1a7/0x210 [drm_kms_helper]
    [   45.256803]  drm_dp_mst_link_probe_work+0x6f/0xb0 [drm_kms_helper]
    [   45.259200]  process_one_work+0x88d/0x15d0
    [   45.261597]  worker_thread+0x1a5/0x1470
    [   45.264038]  kthread+0x2f7/0x3b0
    [   45.266371]  ret_from_fork+0x35/0x40
    
    [   45.270937] Freed by task 53:
    [   45.273170]  save_stack+0x43/0xd0
    [   45.275382]  __kasan_slab_free+0x139/0x190
    [   45.277604]  kasan_slab_free+0xe/0x10
    [   45.279826]  kfree+0x99/0x1b0
    [   45.282044]  drm_dp_free_mst_port+0x4a/0x60 [drm_kms_helper]
    [   45.284330]  drm_dp_destroy_connector_work+0x43e/0x6f0 [drm_kms_helper]
    [   45.286660]  process_one_work+0x88d/0x15d0
    [   45.288934]  worker_thread+0x1a5/0x1470
    [   45.291231]  kthread+0x2f7/0x3b0
    [   45.293547]  ret_from_fork+0x35/0x40
    
    [   45.298206] The buggy address belongs to the object at ffff8882b4b70968
                    which belongs to the cache kmalloc-2k of size 2048
    [   45.303047] The buggy address is located 0 bytes inside of
                    2048-byte region [ffff8882b4b70968, ffff8882b4b71168)
    [   45.308010] The buggy address belongs to the page:
    [   45.310477] page:ffffea000ad2dc00 count:1 mapcount:0 mapping:ffff8882c080cf40 index:0x0 compound_mapcount: 0
    [   45.313051] flags: 0x8000000000010200(slab|head)
    [   45.315635] raw: 8000000000010200 ffffea000aac2808 ffffea000abe8608 ffff8882c080cf40
    [   45.318300] raw: 0000000000000000 00000000000d000d 00000001ffffffff 0000000000000000
    [   45.320966] page dumped because: kasan: bad access detected
    
    [   45.326312] Memory state around the buggy address:
    [   45.329085]  ffff8882b4b70800: fb fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.331845]  ffff8882b4b70880: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.334584] >ffff8882b4b70900: fc fc fc fc fc fc fc fc fc fc fc fc fc fb fb fb
    [   45.337302]                                                           ^
    [   45.340061]  ffff8882b4b70980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.342910]  ffff8882b4b70a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.345748] ==================================================================
    
    So, this definitely isn't a fix that we want. This being said; there's
    no real easy fix for this problem because of some of the catch-22's of
    the MST helpers current design. For starters; we always need to validate
    a port with drm_dp_get_validated_port_ref(), but validation relies on
    the lifetime of the port in the actual topology. So once the port is
    gone, it can't be validated again.
    
    If we were to try to make the payload helpers not use port validation,
    then we'd cause another problem: if the port isn't validated, it could
    be freed and we'd just start causing more KASAN issues. There are
    already hacks that attempt to workaround this in
    drm_dp_mst_destroy_connector_work() by re-initializing the kref so that
    it can be used again and it's memory can be freed once the VCPI helpers
    finish removing the port's respective payloads. But none of these really
    do anything helpful since the port still can't be validated since it's
    gone from the topology. Also, that workaround is immensely confusing to
    read through.
    
    What really needs to be done in order to fix this is to teach DRM how to
    track the lifetime of the structs for MST ports and branch devices
    separately from their lifetime in the actual topology. Simply put; this
    means having two different krefs-one that removes the port/branch device
    from the topology, and one that finally calls kfree(). This would let us
    simplify things, since we'd now be able to keep ports around without
    having to keep them in the topology at the same time, which is exactly
    what we need in order to teach our VCPI helpers to only validate ports
    when it's actually necessary without running the risk of trying to use
    unallocated memory.
    
    Such a fix is on it's way, but for now let's play it safe and just
    revert this. If this bug has been around for well over a year, we can
    wait a little while to get an actual proper fix here.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Fixes: c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Sean Paul <sean@poorly.run>
    Cc: Jerry Zuo <Jerry.Zuo@amd.com>
    Cc: Harry Wentland <Harry.Wentland@amd.com>
    Cc: stable@vger.kernel.org # v4.6+
    Acked-by: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181128210005.24434-1-lyude@redhat.com
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dc0ea9b710102ef628a26663d892031a2c381549
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    commit 4c59406ed00379c8663f8663d82b2537467ce9d7 upstream.
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0207ef3379517de58c1f9d6cbb894145c94cc7fa
Author: Lyude Paul <lyude@redhat.com>
Date:   Wed Nov 28 16:00:05 2018 -0500

    Revert "drm/dp_mst: Skip validating ports during destruction, just ref"
    
    commit 9765635b30756eb74e05e260ac812659c296cd28 upstream.
    
    This reverts commit:
    
    c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    
    ugh.
    
    In drm_dp_destroy_connector_work(), we have a pretty good chance of
    freeing the actual struct drm_dp_mst_port. However, after destroying
    things we send a hotplug through (*mgr->cbs->hotplug)(mgr) which is
    where the problems start.
    
    For i915, this calls all the way down to the fbcon probing helpers,
    which start trying to access the port in a modeset.
    
    [   45.062001] ==================================================================
    [   45.062112] BUG: KASAN: use-after-free in ex_handler_refcount+0x146/0x180
    [   45.062196] Write of size 4 at addr ffff8882b4b70968 by task kworker/3:1/53
    
    [   45.062325] CPU: 3 PID: 53 Comm: kworker/3:1 Kdump: loaded Tainted: G           O      4.20.0-rc4Lyude-Test+ #3
    [   45.062442] Hardware name: LENOVO 20BWS1KY00/20BWS1KY00, BIOS JBET71WW (1.35 ) 09/14/2018
    [   45.062554] Workqueue: events drm_dp_destroy_connector_work [drm_kms_helper]
    [   45.062641] Call Trace:
    [   45.062685]  dump_stack+0xbd/0x15a
    [   45.062735]  ? dump_stack_print_info.cold.0+0x1b/0x1b
    [   45.062801]  ? printk+0x9f/0xc5
    [   45.062847]  ? kmsg_dump_rewind_nolock+0xe4/0xe4
    [   45.062909]  ? ex_handler_refcount+0x146/0x180
    [   45.062970]  print_address_description+0x71/0x239
    [   45.063036]  ? ex_handler_refcount+0x146/0x180
    [   45.063095]  kasan_report.cold.5+0x242/0x30b
    [   45.063155]  __asan_report_store4_noabort+0x1c/0x20
    [   45.063313]  ex_handler_refcount+0x146/0x180
    [   45.063371]  ? ex_handler_clear_fs+0xb0/0xb0
    [   45.063428]  fixup_exception+0x98/0xd7
    [   45.063484]  ? raw_notifier_call_chain+0x20/0x20
    [   45.063548]  do_trap+0x6d/0x210
    [   45.063605]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063732]  do_error_trap+0xc0/0x170
    [   45.063802]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063929]  do_invalid_op+0x3b/0x50
    [   45.063997]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064103]  invalid_op+0x14/0x20
    [   45.064162] RIP: 0010:_GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064274] Code: 00 48 c7 c7 80 fe 53 a0 48 89 e5 e8 5b 6f 26 e1 5d c3 48 8d 0e 0f 0b 48 8d 0b 0f 0b 48 8d 0f 0f 0b 48 8d 0f 0f 0b 49 8d 4d 00 <0f> 0b 49 8d 0e 0f 0b 48 8d 08 0f 0b 49 8d 4d 00 0f 0b 48 8d 0b 0f
    [   45.064569] RSP: 0018:ffff8882b789ee10 EFLAGS: 00010282
    [   45.064637] RAX: ffff8882af47ae70 RBX: ffff8882af47aa60 RCX: ffff8882b4b70968
    [   45.064723] RDX: ffff8882af47ae70 RSI: 0000000000000008 RDI: ffff8882b788bdb8
    [   45.064808] RBP: ffff8882b789ee28 R08: ffffed1056f13db4 R09: ffffed1056f13db3
    [   45.064894] R10: ffffed1056f13db3 R11: ffff8882b789ed9f R12: ffff8882af47ad28
    [   45.064980] R13: ffff8882b4b70968 R14: ffff8882acd86728 R15: ffff8882b4b75dc8
    [   45.065084]  drm_dp_mst_reset_vcpi_slots+0x12/0x80 [drm_kms_helper]
    [   45.065225]  intel_mst_disable_dp+0xda/0x180 [i915]
    [   45.065361]  intel_encoders_disable.isra.107+0x197/0x310 [i915]
    [   45.065498]  haswell_crtc_disable+0xbe/0x400 [i915]
    [   45.065622]  ? i9xx_disable_plane+0x1c0/0x3e0 [i915]
    [   45.065750]  intel_atomic_commit_tail+0x74e/0x3e60 [i915]
    [   45.065884]  ? intel_pre_plane_update+0xbc0/0xbc0 [i915]
    [   45.065968]  ? drm_atomic_helper_swap_state+0x88b/0x1d90 [drm_kms_helper]
    [   45.066054]  ? kasan_check_write+0x14/0x20
    [   45.066165]  ? i915_gem_track_fb+0x13a/0x330 [i915]
    [   45.066277]  ? i915_sw_fence_complete+0xe9/0x140 [i915]
    [   45.066406]  ? __i915_sw_fence_complete+0xc50/0xc50 [i915]
    [   45.066540]  intel_atomic_commit+0x72e/0xef0 [i915]
    [   45.066635]  ? drm_dev_dbg+0x200/0x200 [drm]
    [   45.066764]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.066898]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.067001]  drm_atomic_commit+0xc4/0xf0 [drm]
    [   45.067074]  restore_fbdev_mode_atomic+0x562/0x780 [drm_kms_helper]
    [   45.067166]  ? drm_fb_helper_debug_leave+0x690/0x690 [drm_kms_helper]
    [   45.067249]  ? kasan_check_read+0x11/0x20
    [   45.067324]  restore_fbdev_mode+0x127/0x4b0 [drm_kms_helper]
    [   45.067364]  ? kasan_check_read+0x11/0x20
    [   45.067406]  drm_fb_helper_restore_fbdev_mode_unlocked+0x164/0x200 [drm_kms_helper]
    [   45.067462]  ? drm_fb_helper_hotplug_event+0x30/0x30 [drm_kms_helper]
    [   45.067508]  ? kasan_check_write+0x14/0x20
    [   45.070360]  ? mutex_unlock+0x22/0x40
    [   45.073748]  drm_fb_helper_set_par+0xb2/0xf0 [drm_kms_helper]
    [   45.075846]  drm_fb_helper_hotplug_event.part.33+0x1cd/0x290 [drm_kms_helper]
    [   45.078088]  drm_fb_helper_hotplug_event+0x1c/0x30 [drm_kms_helper]
    [   45.082614]  intel_fbdev_output_poll_changed+0x9f/0x140 [i915]
    [   45.087069]  drm_kms_helper_hotplug_event+0x67/0x90 [drm_kms_helper]
    [   45.089319]  intel_dp_mst_hotplug+0x37/0x50 [i915]
    [   45.091496]  drm_dp_destroy_connector_work+0x510/0x6f0 [drm_kms_helper]
    [   45.093675]  ? drm_dp_update_payload_part1+0x1220/0x1220 [drm_kms_helper]
    [   45.095851]  ? kasan_check_write+0x14/0x20
    [   45.098473]  ? kasan_check_read+0x11/0x20
    [   45.101155]  ? strscpy+0x17c/0x530
    [   45.103808]  ? __switch_to_asm+0x34/0x70
    [   45.106456]  ? syscall_return_via_sysret+0xf/0x7f
    [   45.109711]  ? read_word_at_a_time+0x20/0x20
    [   45.113138]  ? __switch_to_asm+0x40/0x70
    [   45.116529]  ? __switch_to_asm+0x34/0x70
    [   45.119891]  ? __switch_to_asm+0x40/0x70
    [   45.123224]  ? __switch_to_asm+0x34/0x70
    [   45.126540]  ? __switch_to_asm+0x34/0x70
    [   45.129824]  process_one_work+0x88d/0x15d0
    [   45.133172]  ? pool_mayday_timeout+0x850/0x850
    [   45.136459]  ? pci_mmcfg_check_reserved+0x110/0x128
    [   45.139739]  ? wake_q_add+0xb0/0xb0
    [   45.143010]  ? check_preempt_wakeup+0x652/0x1050
    [   45.146304]  ? worker_enter_idle+0x29e/0x740
    [   45.149589]  ? __schedule+0x1ec0/0x1ec0
    [   45.152937]  ? kasan_check_read+0x11/0x20
    [   45.156179]  ? _raw_spin_lock_irq+0xa3/0x130
    [   45.159382]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   45.162542]  ? kasan_check_write+0x14/0x20
    [   45.165657]  worker_thread+0x1a5/0x1470
    [   45.168725]  ? set_load_weight+0x2e0/0x2e0
    [   45.171755]  ? process_one_work+0x15d0/0x15d0
    [   45.174806]  ? __switch_to_asm+0x34/0x70
    [   45.177645]  ? __switch_to_asm+0x40/0x70
    [   45.180323]  ? __switch_to_asm+0x34/0x70
    [   45.182936]  ? __switch_to_asm+0x40/0x70
    [   45.185539]  ? __switch_to_asm+0x34/0x70
    [   45.188100]  ? __switch_to_asm+0x40/0x70
    [   45.190628]  ? __schedule+0x7d4/0x1ec0
    [   45.193143]  ? save_stack+0xa9/0xd0
    [   45.195632]  ? kasan_check_write+0x10/0x20
    [   45.198162]  ? kasan_kmalloc+0xc4/0xe0
    [   45.200609]  ? kmem_cache_alloc_trace+0xdd/0x190
    [   45.203046]  ? kthread+0x9f/0x3b0
    [   45.205470]  ? ret_from_fork+0x35/0x40
    [   45.207876]  ? unwind_next_frame+0x43/0x50
    [   45.210273]  ? __save_stack_trace+0x82/0x100
    [   45.212658]  ? deactivate_slab.isra.67+0x3d4/0x580
    [   45.215026]  ? default_wake_function+0x35/0x50
    [   45.217399]  ? kasan_check_read+0x11/0x20
    [   45.219825]  ? _raw_spin_lock_irqsave+0xae/0x140
    [   45.222174]  ? __lock_text_start+0x8/0x8
    [   45.224521]  ? replenish_dl_entity.cold.62+0x4f/0x4f
    [   45.226868]  ? __kthread_parkme+0x87/0xf0
    [   45.229200]  kthread+0x2f7/0x3b0
    [   45.231557]  ? process_one_work+0x15d0/0x15d0
    [   45.233923]  ? kthread_park+0x120/0x120
    [   45.236249]  ret_from_fork+0x35/0x40
    
    [   45.240875] Allocated by task 242:
    [   45.243136]  save_stack+0x43/0xd0
    [   45.245385]  kasan_kmalloc+0xc4/0xe0
    [   45.247597]  kmem_cache_alloc_trace+0xdd/0x190
    [   45.249793]  drm_dp_add_port+0x1e0/0x2170 [drm_kms_helper]
    [   45.252000]  drm_dp_send_link_address+0x4a7/0x740 [drm_kms_helper]
    [   45.254389]  drm_dp_check_and_send_link_address+0x1a7/0x210 [drm_kms_helper]
    [   45.256803]  drm_dp_mst_link_probe_work+0x6f/0xb0 [drm_kms_helper]
    [   45.259200]  process_one_work+0x88d/0x15d0
    [   45.261597]  worker_thread+0x1a5/0x1470
    [   45.264038]  kthread+0x2f7/0x3b0
    [   45.266371]  ret_from_fork+0x35/0x40
    
    [   45.270937] Freed by task 53:
    [   45.273170]  save_stack+0x43/0xd0
    [   45.275382]  __kasan_slab_free+0x139/0x190
    [   45.277604]  kasan_slab_free+0xe/0x10
    [   45.279826]  kfree+0x99/0x1b0
    [   45.282044]  drm_dp_free_mst_port+0x4a/0x60 [drm_kms_helper]
    [   45.284330]  drm_dp_destroy_connector_work+0x43e/0x6f0 [drm_kms_helper]
    [   45.286660]  process_one_work+0x88d/0x15d0
    [   45.288934]  worker_thread+0x1a5/0x1470
    [   45.291231]  kthread+0x2f7/0x3b0
    [   45.293547]  ret_from_fork+0x35/0x40
    
    [   45.298206] The buggy address belongs to the object at ffff8882b4b70968
                    which belongs to the cache kmalloc-2k of size 2048
    [   45.303047] The buggy address is located 0 bytes inside of
                    2048-byte region [ffff8882b4b70968, ffff8882b4b71168)
    [   45.308010] The buggy address belongs to the page:
    [   45.310477] page:ffffea000ad2dc00 count:1 mapcount:0 mapping:ffff8882c080cf40 index:0x0 compound_mapcount: 0
    [   45.313051] flags: 0x8000000000010200(slab|head)
    [   45.315635] raw: 8000000000010200 ffffea000aac2808 ffffea000abe8608 ffff8882c080cf40
    [   45.318300] raw: 0000000000000000 00000000000d000d 00000001ffffffff 0000000000000000
    [   45.320966] page dumped because: kasan: bad access detected
    
    [   45.326312] Memory state around the buggy address:
    [   45.329085]  ffff8882b4b70800: fb fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.331845]  ffff8882b4b70880: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.334584] >ffff8882b4b70900: fc fc fc fc fc fc fc fc fc fc fc fc fc fb fb fb
    [   45.337302]                                                           ^
    [   45.340061]  ffff8882b4b70980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.342910]  ffff8882b4b70a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.345748] ==================================================================
    
    So, this definitely isn't a fix that we want. This being said; there's
    no real easy fix for this problem because of some of the catch-22's of
    the MST helpers current design. For starters; we always need to validate
    a port with drm_dp_get_validated_port_ref(), but validation relies on
    the lifetime of the port in the actual topology. So once the port is
    gone, it can't be validated again.
    
    If we were to try to make the payload helpers not use port validation,
    then we'd cause another problem: if the port isn't validated, it could
    be freed and we'd just start causing more KASAN issues. There are
    already hacks that attempt to workaround this in
    drm_dp_mst_destroy_connector_work() by re-initializing the kref so that
    it can be used again and it's memory can be freed once the VCPI helpers
    finish removing the port's respective payloads. But none of these really
    do anything helpful since the port still can't be validated since it's
    gone from the topology. Also, that workaround is immensely confusing to
    read through.
    
    What really needs to be done in order to fix this is to teach DRM how to
    track the lifetime of the structs for MST ports and branch devices
    separately from their lifetime in the actual topology. Simply put; this
    means having two different krefs-one that removes the port/branch device
    from the topology, and one that finally calls kfree(). This would let us
    simplify things, since we'd now be able to keep ports around without
    having to keep them in the topology at the same time, which is exactly
    what we need in order to teach our VCPI helpers to only validate ports
    when it's actually necessary without running the risk of trying to use
    unallocated memory.
    
    Such a fix is on it's way, but for now let's play it safe and just
    revert this. If this bug has been around for well over a year, we can
    wait a little while to get an actual proper fix here.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Fixes: c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Sean Paul <sean@poorly.run>
    Cc: Jerry Zuo <Jerry.Zuo@amd.com>
    Cc: Harry Wentland <Harry.Wentland@amd.com>
    Cc: stable@vger.kernel.org # v4.6+
    Acked-by: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181128210005.24434-1-lyude@redhat.com
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7ad217a824f7fab1e8534a6dfa82899ae1900bcb
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    commit 4c59406ed00379c8663f8663d82b2537467ce9d7 upstream.
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 013b14652972949c5e8446b1e8ca9868780f5c7a
Author: Lyude Paul <lyude@redhat.com>
Date:   Wed Nov 28 16:00:05 2018 -0500

    Revert "drm/dp_mst: Skip validating ports during destruction, just ref"
    
    commit 9765635b30756eb74e05e260ac812659c296cd28 upstream.
    
    This reverts commit:
    
    c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    
    ugh.
    
    In drm_dp_destroy_connector_work(), we have a pretty good chance of
    freeing the actual struct drm_dp_mst_port. However, after destroying
    things we send a hotplug through (*mgr->cbs->hotplug)(mgr) which is
    where the problems start.
    
    For i915, this calls all the way down to the fbcon probing helpers,
    which start trying to access the port in a modeset.
    
    [   45.062001] ==================================================================
    [   45.062112] BUG: KASAN: use-after-free in ex_handler_refcount+0x146/0x180
    [   45.062196] Write of size 4 at addr ffff8882b4b70968 by task kworker/3:1/53
    
    [   45.062325] CPU: 3 PID: 53 Comm: kworker/3:1 Kdump: loaded Tainted: G           O      4.20.0-rc4Lyude-Test+ #3
    [   45.062442] Hardware name: LENOVO 20BWS1KY00/20BWS1KY00, BIOS JBET71WW (1.35 ) 09/14/2018
    [   45.062554] Workqueue: events drm_dp_destroy_connector_work [drm_kms_helper]
    [   45.062641] Call Trace:
    [   45.062685]  dump_stack+0xbd/0x15a
    [   45.062735]  ? dump_stack_print_info.cold.0+0x1b/0x1b
    [   45.062801]  ? printk+0x9f/0xc5
    [   45.062847]  ? kmsg_dump_rewind_nolock+0xe4/0xe4
    [   45.062909]  ? ex_handler_refcount+0x146/0x180
    [   45.062970]  print_address_description+0x71/0x239
    [   45.063036]  ? ex_handler_refcount+0x146/0x180
    [   45.063095]  kasan_report.cold.5+0x242/0x30b
    [   45.063155]  __asan_report_store4_noabort+0x1c/0x20
    [   45.063313]  ex_handler_refcount+0x146/0x180
    [   45.063371]  ? ex_handler_clear_fs+0xb0/0xb0
    [   45.063428]  fixup_exception+0x98/0xd7
    [   45.063484]  ? raw_notifier_call_chain+0x20/0x20
    [   45.063548]  do_trap+0x6d/0x210
    [   45.063605]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063732]  do_error_trap+0xc0/0x170
    [   45.063802]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063929]  do_invalid_op+0x3b/0x50
    [   45.063997]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064103]  invalid_op+0x14/0x20
    [   45.064162] RIP: 0010:_GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064274] Code: 00 48 c7 c7 80 fe 53 a0 48 89 e5 e8 5b 6f 26 e1 5d c3 48 8d 0e 0f 0b 48 8d 0b 0f 0b 48 8d 0f 0f 0b 48 8d 0f 0f 0b 49 8d 4d 00 <0f> 0b 49 8d 0e 0f 0b 48 8d 08 0f 0b 49 8d 4d 00 0f 0b 48 8d 0b 0f
    [   45.064569] RSP: 0018:ffff8882b789ee10 EFLAGS: 00010282
    [   45.064637] RAX: ffff8882af47ae70 RBX: ffff8882af47aa60 RCX: ffff8882b4b70968
    [   45.064723] RDX: ffff8882af47ae70 RSI: 0000000000000008 RDI: ffff8882b788bdb8
    [   45.064808] RBP: ffff8882b789ee28 R08: ffffed1056f13db4 R09: ffffed1056f13db3
    [   45.064894] R10: ffffed1056f13db3 R11: ffff8882b789ed9f R12: ffff8882af47ad28
    [   45.064980] R13: ffff8882b4b70968 R14: ffff8882acd86728 R15: ffff8882b4b75dc8
    [   45.065084]  drm_dp_mst_reset_vcpi_slots+0x12/0x80 [drm_kms_helper]
    [   45.065225]  intel_mst_disable_dp+0xda/0x180 [i915]
    [   45.065361]  intel_encoders_disable.isra.107+0x197/0x310 [i915]
    [   45.065498]  haswell_crtc_disable+0xbe/0x400 [i915]
    [   45.065622]  ? i9xx_disable_plane+0x1c0/0x3e0 [i915]
    [   45.065750]  intel_atomic_commit_tail+0x74e/0x3e60 [i915]
    [   45.065884]  ? intel_pre_plane_update+0xbc0/0xbc0 [i915]
    [   45.065968]  ? drm_atomic_helper_swap_state+0x88b/0x1d90 [drm_kms_helper]
    [   45.066054]  ? kasan_check_write+0x14/0x20
    [   45.066165]  ? i915_gem_track_fb+0x13a/0x330 [i915]
    [   45.066277]  ? i915_sw_fence_complete+0xe9/0x140 [i915]
    [   45.066406]  ? __i915_sw_fence_complete+0xc50/0xc50 [i915]
    [   45.066540]  intel_atomic_commit+0x72e/0xef0 [i915]
    [   45.066635]  ? drm_dev_dbg+0x200/0x200 [drm]
    [   45.066764]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.066898]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.067001]  drm_atomic_commit+0xc4/0xf0 [drm]
    [   45.067074]  restore_fbdev_mode_atomic+0x562/0x780 [drm_kms_helper]
    [   45.067166]  ? drm_fb_helper_debug_leave+0x690/0x690 [drm_kms_helper]
    [   45.067249]  ? kasan_check_read+0x11/0x20
    [   45.067324]  restore_fbdev_mode+0x127/0x4b0 [drm_kms_helper]
    [   45.067364]  ? kasan_check_read+0x11/0x20
    [   45.067406]  drm_fb_helper_restore_fbdev_mode_unlocked+0x164/0x200 [drm_kms_helper]
    [   45.067462]  ? drm_fb_helper_hotplug_event+0x30/0x30 [drm_kms_helper]
    [   45.067508]  ? kasan_check_write+0x14/0x20
    [   45.070360]  ? mutex_unlock+0x22/0x40
    [   45.073748]  drm_fb_helper_set_par+0xb2/0xf0 [drm_kms_helper]
    [   45.075846]  drm_fb_helper_hotplug_event.part.33+0x1cd/0x290 [drm_kms_helper]
    [   45.078088]  drm_fb_helper_hotplug_event+0x1c/0x30 [drm_kms_helper]
    [   45.082614]  intel_fbdev_output_poll_changed+0x9f/0x140 [i915]
    [   45.087069]  drm_kms_helper_hotplug_event+0x67/0x90 [drm_kms_helper]
    [   45.089319]  intel_dp_mst_hotplug+0x37/0x50 [i915]
    [   45.091496]  drm_dp_destroy_connector_work+0x510/0x6f0 [drm_kms_helper]
    [   45.093675]  ? drm_dp_update_payload_part1+0x1220/0x1220 [drm_kms_helper]
    [   45.095851]  ? kasan_check_write+0x14/0x20
    [   45.098473]  ? kasan_check_read+0x11/0x20
    [   45.101155]  ? strscpy+0x17c/0x530
    [   45.103808]  ? __switch_to_asm+0x34/0x70
    [   45.106456]  ? syscall_return_via_sysret+0xf/0x7f
    [   45.109711]  ? read_word_at_a_time+0x20/0x20
    [   45.113138]  ? __switch_to_asm+0x40/0x70
    [   45.116529]  ? __switch_to_asm+0x34/0x70
    [   45.119891]  ? __switch_to_asm+0x40/0x70
    [   45.123224]  ? __switch_to_asm+0x34/0x70
    [   45.126540]  ? __switch_to_asm+0x34/0x70
    [   45.129824]  process_one_work+0x88d/0x15d0
    [   45.133172]  ? pool_mayday_timeout+0x850/0x850
    [   45.136459]  ? pci_mmcfg_check_reserved+0x110/0x128
    [   45.139739]  ? wake_q_add+0xb0/0xb0
    [   45.143010]  ? check_preempt_wakeup+0x652/0x1050
    [   45.146304]  ? worker_enter_idle+0x29e/0x740
    [   45.149589]  ? __schedule+0x1ec0/0x1ec0
    [   45.152937]  ? kasan_check_read+0x11/0x20
    [   45.156179]  ? _raw_spin_lock_irq+0xa3/0x130
    [   45.159382]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   45.162542]  ? kasan_check_write+0x14/0x20
    [   45.165657]  worker_thread+0x1a5/0x1470
    [   45.168725]  ? set_load_weight+0x2e0/0x2e0
    [   45.171755]  ? process_one_work+0x15d0/0x15d0
    [   45.174806]  ? __switch_to_asm+0x34/0x70
    [   45.177645]  ? __switch_to_asm+0x40/0x70
    [   45.180323]  ? __switch_to_asm+0x34/0x70
    [   45.182936]  ? __switch_to_asm+0x40/0x70
    [   45.185539]  ? __switch_to_asm+0x34/0x70
    [   45.188100]  ? __switch_to_asm+0x40/0x70
    [   45.190628]  ? __schedule+0x7d4/0x1ec0
    [   45.193143]  ? save_stack+0xa9/0xd0
    [   45.195632]  ? kasan_check_write+0x10/0x20
    [   45.198162]  ? kasan_kmalloc+0xc4/0xe0
    [   45.200609]  ? kmem_cache_alloc_trace+0xdd/0x190
    [   45.203046]  ? kthread+0x9f/0x3b0
    [   45.205470]  ? ret_from_fork+0x35/0x40
    [   45.207876]  ? unwind_next_frame+0x43/0x50
    [   45.210273]  ? __save_stack_trace+0x82/0x100
    [   45.212658]  ? deactivate_slab.isra.67+0x3d4/0x580
    [   45.215026]  ? default_wake_function+0x35/0x50
    [   45.217399]  ? kasan_check_read+0x11/0x20
    [   45.219825]  ? _raw_spin_lock_irqsave+0xae/0x140
    [   45.222174]  ? __lock_text_start+0x8/0x8
    [   45.224521]  ? replenish_dl_entity.cold.62+0x4f/0x4f
    [   45.226868]  ? __kthread_parkme+0x87/0xf0
    [   45.229200]  kthread+0x2f7/0x3b0
    [   45.231557]  ? process_one_work+0x15d0/0x15d0
    [   45.233923]  ? kthread_park+0x120/0x120
    [   45.236249]  ret_from_fork+0x35/0x40
    
    [   45.240875] Allocated by task 242:
    [   45.243136]  save_stack+0x43/0xd0
    [   45.245385]  kasan_kmalloc+0xc4/0xe0
    [   45.247597]  kmem_cache_alloc_trace+0xdd/0x190
    [   45.249793]  drm_dp_add_port+0x1e0/0x2170 [drm_kms_helper]
    [   45.252000]  drm_dp_send_link_address+0x4a7/0x740 [drm_kms_helper]
    [   45.254389]  drm_dp_check_and_send_link_address+0x1a7/0x210 [drm_kms_helper]
    [   45.256803]  drm_dp_mst_link_probe_work+0x6f/0xb0 [drm_kms_helper]
    [   45.259200]  process_one_work+0x88d/0x15d0
    [   45.261597]  worker_thread+0x1a5/0x1470
    [   45.264038]  kthread+0x2f7/0x3b0
    [   45.266371]  ret_from_fork+0x35/0x40
    
    [   45.270937] Freed by task 53:
    [   45.273170]  save_stack+0x43/0xd0
    [   45.275382]  __kasan_slab_free+0x139/0x190
    [   45.277604]  kasan_slab_free+0xe/0x10
    [   45.279826]  kfree+0x99/0x1b0
    [   45.282044]  drm_dp_free_mst_port+0x4a/0x60 [drm_kms_helper]
    [   45.284330]  drm_dp_destroy_connector_work+0x43e/0x6f0 [drm_kms_helper]
    [   45.286660]  process_one_work+0x88d/0x15d0
    [   45.288934]  worker_thread+0x1a5/0x1470
    [   45.291231]  kthread+0x2f7/0x3b0
    [   45.293547]  ret_from_fork+0x35/0x40
    
    [   45.298206] The buggy address belongs to the object at ffff8882b4b70968
                    which belongs to the cache kmalloc-2k of size 2048
    [   45.303047] The buggy address is located 0 bytes inside of
                    2048-byte region [ffff8882b4b70968, ffff8882b4b71168)
    [   45.308010] The buggy address belongs to the page:
    [   45.310477] page:ffffea000ad2dc00 count:1 mapcount:0 mapping:ffff8882c080cf40 index:0x0 compound_mapcount: 0
    [   45.313051] flags: 0x8000000000010200(slab|head)
    [   45.315635] raw: 8000000000010200 ffffea000aac2808 ffffea000abe8608 ffff8882c080cf40
    [   45.318300] raw: 0000000000000000 00000000000d000d 00000001ffffffff 0000000000000000
    [   45.320966] page dumped because: kasan: bad access detected
    
    [   45.326312] Memory state around the buggy address:
    [   45.329085]  ffff8882b4b70800: fb fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.331845]  ffff8882b4b70880: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.334584] >ffff8882b4b70900: fc fc fc fc fc fc fc fc fc fc fc fc fc fb fb fb
    [   45.337302]                                                           ^
    [   45.340061]  ffff8882b4b70980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.342910]  ffff8882b4b70a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.345748] ==================================================================
    
    So, this definitely isn't a fix that we want. This being said; there's
    no real easy fix for this problem because of some of the catch-22's of
    the MST helpers current design. For starters; we always need to validate
    a port with drm_dp_get_validated_port_ref(), but validation relies on
    the lifetime of the port in the actual topology. So once the port is
    gone, it can't be validated again.
    
    If we were to try to make the payload helpers not use port validation,
    then we'd cause another problem: if the port isn't validated, it could
    be freed and we'd just start causing more KASAN issues. There are
    already hacks that attempt to workaround this in
    drm_dp_mst_destroy_connector_work() by re-initializing the kref so that
    it can be used again and it's memory can be freed once the VCPI helpers
    finish removing the port's respective payloads. But none of these really
    do anything helpful since the port still can't be validated since it's
    gone from the topology. Also, that workaround is immensely confusing to
    read through.
    
    What really needs to be done in order to fix this is to teach DRM how to
    track the lifetime of the structs for MST ports and branch devices
    separately from their lifetime in the actual topology. Simply put; this
    means having two different krefs-one that removes the port/branch device
    from the topology, and one that finally calls kfree(). This would let us
    simplify things, since we'd now be able to keep ports around without
    having to keep them in the topology at the same time, which is exactly
    what we need in order to teach our VCPI helpers to only validate ports
    when it's actually necessary without running the risk of trying to use
    unallocated memory.
    
    Such a fix is on it's way, but for now let's play it safe and just
    revert this. If this bug has been around for well over a year, we can
    wait a little while to get an actual proper fix here.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Fixes: c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Sean Paul <sean@poorly.run>
    Cc: Jerry Zuo <Jerry.Zuo@amd.com>
    Cc: Harry Wentland <Harry.Wentland@amd.com>
    Cc: stable@vger.kernel.org # v4.6+
    Acked-by: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181128210005.24434-1-lyude@redhat.com
    Cc: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 21af83e17ffae4955bbd8154a1e975826b8188a1
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    commit 4c59406ed00379c8663f8663d82b2537467ce9d7 upstream.
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a6ca6e66a8b2f8741610d99c95c9bf5748e08372
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    commit 4c59406ed00379c8663f8663d82b2537467ce9d7 upstream.
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4c59406ed00379c8663f8663d82b2537467ce9d7
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Mon Mar 23 15:32:39 2020 +0800

    xfrm: policy: Fix doulbe free in xfrm_policy_timer
    
    After xfrm_add_policy add a policy, its ref is 2, then
    
                                 xfrm_policy_timer
                                   read_lock
                                   xp->walk.dead is 0
                                   ....
                                   mod_timer()
    xfrm_policy_kill
      policy->walk.dead = 1
      ....
      del_timer(&policy->timer)
        xfrm_pol_put //ref is 1
      xfrm_pol_put  //ref is 0
        xfrm_policy_destroy
          call_rcu
                                     xfrm_pol_hold //ref is 1
                                   read_unlock
                                   xfrm_pol_put //ref is 0
                                     xfrm_policy_destroy
                                      call_rcu
    
    xfrm_policy_destroy is called twice, which may leads to
    double free.
    
    Call Trace:
    RIP: 0010:refcount_warn_saturate+0x161/0x210
    ...
     xfrm_policy_timer+0x522/0x600
     call_timer_fn+0x1b3/0x5e0
     ? __xfrm_decode_session+0x2990/0x2990
     ? msleep+0xb0/0xb0
     ? _raw_spin_unlock_irq+0x24/0x40
     ? __xfrm_decode_session+0x2990/0x2990
     ? __xfrm_decode_session+0x2990/0x2990
     run_timer_softirq+0x5c5/0x10e0
    
    Fix this by use write_lock_bh in xfrm_policy_kill.
    
    Fixes: ea2dea9dacc2 ("xfrm: remove policy lock when accessing policy->walk.dead")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Acked-by: Timo Ters <timo.teras@iki.fi>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

commit eb095c14030fbb07fcc61c64b6b39cc297a429c6
Author: Zhouyi Zhou <zhouzhouyi@gmail.com>
Date:   Fri Mar 6 03:45:26 2020 +0000

    NFS:remove redundant call to nfs_do_access
    
    In function nfs_permission:
    1. the rcu_read_lock and rcu_read_unlock around nfs_do_access
    is unnecessary because the rcu critical data structure is already
    protected in subsidiary function nfs_access_get_cached_rcu. No other
    data structure needs rcu_read_lock in nfs_do_access.
    
    2. call nfs_do_access once is enough, because:
    2-1. when mask has MAY_NOT_BLOCK bit
    The second call to nfs_do_access will not happen.
    
    2-2. when mask has no MAY_NOT_BLOCK bit
    The second call to nfs_do_access will happen if res == -ECHILD, which
    means the first nfs_do_access goes out after statement if (!may_block).
    The second call to nfs_do_access will go through this procedure once
    again except continue the work after if (!may_block).
    But above work can be performed by only one call to nfs_do_access
    without mangling the mask flag.
    
    Tested in x86_64
    Signed-off-by: Zhouyi Zhou <zhouzhouyi@gmail.com>
    Signed-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>

commit ab7789c5174cb12c9f9fb4f85efc6d18e7f04c2b
Author: Jules Irenge <jbi.octave@gmail.com>
Date:   Fri Feb 14 20:47:30 2020 +0000

    driver core: Add missing annotation for device_links_read_lock()
    
    Sparse reports a warning at device_links_read_unlock()
    
    warning:  warning: context imbalance in device_links_read_unlock()
             - unexpected unlock
    
    The root cause is the missing annotation at device_links_read_unlock()
    Add the missing __releases(&device_links_srcu) annotation
    
    Signed-off-by: Jules Irenge <jbi.octave@gmail.com>
    Link: https://lore.kernel.org/r/20200214204741.94112-20-jbi.octave@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 847e6a7618019356de6c58760169b3991c12a9d0
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    [ Upstream commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 ]
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 61087dce64a53f13b8cc162032f25ef80f50b15c
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    [ Upstream commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 ]
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8ffeb2114dc105c7b47a18a85dd8acd611242b5d
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    [ Upstream commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 ]
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 783c96281bce4b38bb51e8c24b27b5dc4fdb3a51
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    [ Upstream commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 ]
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6a7ad15be999f8f7c78b081c2fc77f3ec1269e6e
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 88c38166434a9dbed0b567285a1128eb8b467aa7
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    [ Upstream commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 ]
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8c74cc7191b85f46d803e1ddcb26c3caaa915513
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03b4aeda9b6f455d81d1147f0900f1320bc48a44
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    [ Upstream commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4 ]
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c31a8186c195116d8f9b8628bb2650c051015613
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dc714706d48a37a2b509bc5c32a49fb4e4547019
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 09d89628a6d711d3887bdc599b556081443a4dd9
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Nov 4 08:22:45 2019 -0800

    rcu: Use READ_ONCE() for ->expmask in rcu_read_unlock_special()
    
    commit c51f83c315c392d9776c33eb16a2fe1349d65c7f upstream.
    
    The rcu_node structure's ->expmask field is updated only when holding the
    ->lock, but is also accessed locklessly.  This means that all ->expmask
    updates must use WRITE_ONCE() and all reads carried out without holding
    ->lock must use READ_ONCE().  This commit therefore changes the lockless
    ->expmask read in rcu_read_unlock_special() to use READ_ONCE().
    
    Reported-by: syzbot+99f4ddade3c22ab0cf23@syzkaller.appspotmail.com
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Marco Elver <elver@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 53e197803d428f886610ea7f2dd770484d82945d
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 9 14:21:54 2019 -0700

    rcu: Avoid data-race in rcu_gp_fqs_check_wake()
    
    commit 6935c3983b246d5fbfebd3b891c825e65c118f2d upstream.
    
    The rcu_gp_fqs_check_wake() function uses rcu_preempt_blocked_readers_cgp()
    to read ->gp_tasks while other cpus might overwrite this field.
    
    We need READ_ONCE()/WRITE_ONCE() pairs to avoid compiler
    tricks and KCSAN splats like the following :
    
    BUG: KCSAN: data-race in rcu_gp_fqs_check_wake / rcu_preempt_deferred_qs_irqrestore
    
    write to 0xffffffff85a7f190 of 8 bytes by task 7317 on cpu 0:
     rcu_preempt_deferred_qs_irqrestore+0x43d/0x580 kernel/rcu/tree_plugin.h:507
     rcu_read_unlock_special+0xec/0x370 kernel/rcu/tree_plugin.h:659
     __rcu_read_unlock+0xcf/0xe0 kernel/rcu/tree_plugin.h:394
     rcu_read_unlock include/linux/rcupdate.h:645 [inline]
     __ip_queue_xmit+0x3b0/0xa40 net/ipv4/ip_output.c:533
     ip_queue_xmit+0x45/0x60 include/net/ip.h:236
     __tcp_transmit_skb+0xdeb/0x1cd0 net/ipv4/tcp_output.c:1158
     __tcp_send_ack+0x246/0x300 net/ipv4/tcp_output.c:3685
     tcp_send_ack+0x34/0x40 net/ipv4/tcp_output.c:3691
     tcp_cleanup_rbuf+0x130/0x360 net/ipv4/tcp.c:1575
     tcp_recvmsg+0x633/0x1a30 net/ipv4/tcp.c:2179
     inet_recvmsg+0xbb/0x250 net/ipv4/af_inet.c:838
     sock_recvmsg_nosec net/socket.c:871 [inline]
     sock_recvmsg net/socket.c:889 [inline]
     sock_recvmsg+0x92/0xb0 net/socket.c:885
     sock_read_iter+0x15f/0x1e0 net/socket.c:967
     call_read_iter include/linux/fs.h:1864 [inline]
     new_sync_read+0x389/0x4f0 fs/read_write.c:414
    
    read to 0xffffffff85a7f190 of 8 bytes by task 10 on cpu 1:
     rcu_gp_fqs_check_wake kernel/rcu/tree.c:1556 [inline]
     rcu_gp_fqs_check_wake+0x93/0xd0 kernel/rcu/tree.c:1546
     rcu_gp_fqs_loop+0x36c/0x580 kernel/rcu/tree.c:1611
     rcu_gp_kthread+0x143/0x220 kernel/rcu/tree.c:1768
     kthread+0x1d4/0x200 drivers/block/aoe/aoecmd.c:1253
     ret_from_fork+0x1f/0x30 arch/x86/entry/entry_64.S:352
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 10 Comm: rcu_preempt Not tainted 5.3.0+ #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    [ paulmck:  Added another READ_ONCE() for RCU CPU stall warnings. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 301763168c5f3e8b17ec56c7f98232f362f230f4
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6a4fea54ab46c2623d74449eaaff8a7e08b19c5e
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Nov 4 08:22:45 2019 -0800

    rcu: Use READ_ONCE() for ->expmask in rcu_read_unlock_special()
    
    commit c51f83c315c392d9776c33eb16a2fe1349d65c7f upstream.
    
    The rcu_node structure's ->expmask field is updated only when holding the
    ->lock, but is also accessed locklessly.  This means that all ->expmask
    updates must use WRITE_ONCE() and all reads carried out without holding
    ->lock must use READ_ONCE().  This commit therefore changes the lockless
    ->expmask read in rcu_read_unlock_special() to use READ_ONCE().
    
    Reported-by: syzbot+99f4ddade3c22ab0cf23@syzkaller.appspotmail.com
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Marco Elver <elver@google.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dcad7270b2c72c23dda243d832aff33cb189fc76
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 9 14:21:54 2019 -0700

    rcu: Avoid data-race in rcu_gp_fqs_check_wake()
    
    commit 6935c3983b246d5fbfebd3b891c825e65c118f2d upstream.
    
    The rcu_gp_fqs_check_wake() function uses rcu_preempt_blocked_readers_cgp()
    to read ->gp_tasks while other cpus might overwrite this field.
    
    We need READ_ONCE()/WRITE_ONCE() pairs to avoid compiler
    tricks and KCSAN splats like the following :
    
    BUG: KCSAN: data-race in rcu_gp_fqs_check_wake / rcu_preempt_deferred_qs_irqrestore
    
    write to 0xffffffff85a7f190 of 8 bytes by task 7317 on cpu 0:
     rcu_preempt_deferred_qs_irqrestore+0x43d/0x580 kernel/rcu/tree_plugin.h:507
     rcu_read_unlock_special+0xec/0x370 kernel/rcu/tree_plugin.h:659
     __rcu_read_unlock+0xcf/0xe0 kernel/rcu/tree_plugin.h:394
     rcu_read_unlock include/linux/rcupdate.h:645 [inline]
     __ip_queue_xmit+0x3b0/0xa40 net/ipv4/ip_output.c:533
     ip_queue_xmit+0x45/0x60 include/net/ip.h:236
     __tcp_transmit_skb+0xdeb/0x1cd0 net/ipv4/tcp_output.c:1158
     __tcp_send_ack+0x246/0x300 net/ipv4/tcp_output.c:3685
     tcp_send_ack+0x34/0x40 net/ipv4/tcp_output.c:3691
     tcp_cleanup_rbuf+0x130/0x360 net/ipv4/tcp.c:1575
     tcp_recvmsg+0x633/0x1a30 net/ipv4/tcp.c:2179
     inet_recvmsg+0xbb/0x250 net/ipv4/af_inet.c:838
     sock_recvmsg_nosec net/socket.c:871 [inline]
     sock_recvmsg net/socket.c:889 [inline]
     sock_recvmsg+0x92/0xb0 net/socket.c:885
     sock_read_iter+0x15f/0x1e0 net/socket.c:967
     call_read_iter include/linux/fs.h:1864 [inline]
     new_sync_read+0x389/0x4f0 fs/read_write.c:414
    
    read to 0xffffffff85a7f190 of 8 bytes by task 10 on cpu 1:
     rcu_gp_fqs_check_wake kernel/rcu/tree.c:1556 [inline]
     rcu_gp_fqs_check_wake+0x93/0xd0 kernel/rcu/tree.c:1546
     rcu_gp_fqs_loop+0x36c/0x580 kernel/rcu/tree.c:1611
     rcu_gp_kthread+0x143/0x220 kernel/rcu/tree.c:1768
     kthread+0x1d4/0x200 drivers/block/aoe/aoecmd.c:1253
     ret_from_fork+0x1f/0x30 arch/x86/entry/entry_64.S:352
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 10 Comm: rcu_preempt Not tainted 5.3.0+ #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    [ paulmck:  Added another READ_ONCE() for RCU CPU stall warnings. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit eab22172e982f34a37ef168fafcaa442fc05fffe
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c upstream.
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 00b13445f92180a4ac83c5fc1b7cce3ea5ed9a6d
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 9 14:21:54 2019 -0700

    rcu: Avoid data-race in rcu_gp_fqs_check_wake()
    
    commit 6935c3983b246d5fbfebd3b891c825e65c118f2d upstream.
    
    The rcu_gp_fqs_check_wake() function uses rcu_preempt_blocked_readers_cgp()
    to read ->gp_tasks while other cpus might overwrite this field.
    
    We need READ_ONCE()/WRITE_ONCE() pairs to avoid compiler
    tricks and KCSAN splats like the following :
    
    BUG: KCSAN: data-race in rcu_gp_fqs_check_wake / rcu_preempt_deferred_qs_irqrestore
    
    write to 0xffffffff85a7f190 of 8 bytes by task 7317 on cpu 0:
     rcu_preempt_deferred_qs_irqrestore+0x43d/0x580 kernel/rcu/tree_plugin.h:507
     rcu_read_unlock_special+0xec/0x370 kernel/rcu/tree_plugin.h:659
     __rcu_read_unlock+0xcf/0xe0 kernel/rcu/tree_plugin.h:394
     rcu_read_unlock include/linux/rcupdate.h:645 [inline]
     __ip_queue_xmit+0x3b0/0xa40 net/ipv4/ip_output.c:533
     ip_queue_xmit+0x45/0x60 include/net/ip.h:236
     __tcp_transmit_skb+0xdeb/0x1cd0 net/ipv4/tcp_output.c:1158
     __tcp_send_ack+0x246/0x300 net/ipv4/tcp_output.c:3685
     tcp_send_ack+0x34/0x40 net/ipv4/tcp_output.c:3691
     tcp_cleanup_rbuf+0x130/0x360 net/ipv4/tcp.c:1575
     tcp_recvmsg+0x633/0x1a30 net/ipv4/tcp.c:2179
     inet_recvmsg+0xbb/0x250 net/ipv4/af_inet.c:838
     sock_recvmsg_nosec net/socket.c:871 [inline]
     sock_recvmsg net/socket.c:889 [inline]
     sock_recvmsg+0x92/0xb0 net/socket.c:885
     sock_read_iter+0x15f/0x1e0 net/socket.c:967
     call_read_iter include/linux/fs.h:1864 [inline]
     new_sync_read+0x389/0x4f0 fs/read_write.c:414
    
    read to 0xffffffff85a7f190 of 8 bytes by task 10 on cpu 1:
     rcu_gp_fqs_check_wake kernel/rcu/tree.c:1556 [inline]
     rcu_gp_fqs_check_wake+0x93/0xd0 kernel/rcu/tree.c:1546
     rcu_gp_fqs_loop+0x36c/0x580 kernel/rcu/tree.c:1611
     rcu_gp_kthread+0x143/0x220 kernel/rcu/tree.c:1768
     kthread+0x1d4/0x200 drivers/block/aoe/aoecmd.c:1253
     ret_from_fork+0x1f/0x30 arch/x86/entry/entry_64.S:352
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 10 Comm: rcu_preempt Not tainted 5.3.0+ #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    [ paulmck:  Added another READ_ONCE() for RCU CPU stall warnings. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d99391ec2b42d827d92003dcdcb96fadac9d862b
Merge: 8b561778f297 f8a4bb6bfa63
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jan 28 08:46:13 2020 -0800

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     "The RCU changes in this cycle were:
       - Expedited grace-period updates
       - kfree_rcu() updates
       - RCU list updates
       - Preemptible RCU updates
       - Torture-test updates
       - Miscellaneous fixes
       - Documentation updates"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (69 commits)
      rcu: Remove unused stop-machine #include
      powerpc: Remove comment about read_barrier_depends()
      .mailmap: Add entries for old paulmck@kernel.org addresses
      srcu: Apply *_ONCE() to ->srcu_last_gp_end
      rcu: Switch force_qs_rnp() to for_each_leaf_node_cpu_mask()
      rcu: Move rcu_{expedited,normal} definitions into rcupdate.h
      rcu: Move gp_state_names[] and gp_state_getname() to tree_stall.h
      rcu: Remove the declaration of call_rcu() in tree.h
      rcu: Fix tracepoint tracking RCU CPU kthread utilization
      rcu: Fix harmless omission of "CONFIG_" from #if condition
      rcu: Avoid tick_dep_set_cpu() misordering
      rcu: Provide wrappers for uses of ->rcu_read_lock_nesting
      rcu: Use READ_ONCE() for ->expmask in rcu_read_unlock_special()
      rcu: Clear ->rcu_read_unlock_special only once
      rcu: Clear .exp_hint only when deferred quiescent state has been reported
      rcu: Rename some instance of CONFIG_PREEMPTION to CONFIG_PREEMPT_RCU
      rcu: Remove kfree_call_rcu_nobatch()
      rcu: Remove kfree_rcu() special casing and lazy-callback handling
      rcu: Add support for debug_objects debugging for kfree_rcu()
      rcu: Add multiple in-flight batches of kfree_rcu() work
      ...

commit c7bf1fb7ddca331780b9a733ae308737b39f1ad4
Author: Nicolai Stange <nstange@suse.de>
Date:   Tue Jan 14 11:39:02 2020 +0100

    libertas: don't exit from lbs_ibss_join_existing() with RCU read lock held
    
    Commit e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss
    descriptor") introduced a bounds check on the number of supplied rates to
    lbs_ibss_join_existing().
    
    Unfortunately, it introduced a return path from within a RCU read side
    critical section without a corresponding rcu_read_unlock(). Fix this.
    
    Fixes: e5e884b42639 ("libertas: Fix two buffer overflows at parsing bss descriptor")
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>

commit 65b1aae0d9d5962faccc06bdb8e91a2a0b09451c
Author: Brian Norris <briannorris@chromium.org>
Date:   Mon Jan 6 14:42:12 2020 -0800

    mwifiex: fix unbalanced locking in mwifiex_process_country_ie()
    
    We called rcu_read_lock(), so we need to call rcu_read_unlock() before
    we return.
    
    Fixes: 3d94a4a8373b ("mwifiex: fix possible heap overflow in mwifiex_process_country_ie()")
    Cc: stable@vger.kernel.org
    Cc: huangwen <huangwenabc@gmail.com>
    Cc: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Brian Norris <briannorris@chromium.org>
    Acked-by: Ganapathi Bhat <ganapathi.bhat@nxp.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>

commit b23bfa5633b19bf1db87b36a76b2225c734f794c
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Sun Jan 26 16:14:02 2020 -0800

    bpf, xdp: Remove no longer required rcu_read_{un}lock()
    
    Now that we depend on rcu_call() and synchronize_rcu() to also wait
    for preempt_disabled region to complete the rcu read critical section
    in __dev_map_flush() is no longer required. Except in a few special
    cases in drivers that need it for other reasons.
    
    These originally ensured the map reference was safe while a map was
    also being free'd. And additionally that bpf program updates via
    ndo_bpf did not happen while flush updates were in flight. But flush
    by new rules can only be called from preempt-disabled NAPI context.
    The synchronize_rcu from the map free path and the rcu_call from the
    delete path will ensure the reference there is safe. So lets remove
    the rcu_read_lock and rcu_read_unlock pair to avoid any confusion
    around how this is being protected.
    
    If the rcu_read_lock was required it would mean errors in the above
    logic and the original patch would also be wrong.
    
    Now that we have done above we put the rcu_read_lock in the driver
    code where it is needed in a driver dependent way. I think this
    helps readability of the code so we know where and why we are
    taking read locks. Most drivers will not need rcu_read_locks here
    and further XDP drivers already have rcu_read_locks in their code
    paths for reading xdp programs on RX side so this makes it symmetric
    where we don't have half of rcu critical sections define in driver
    and the other half in devmap.
    
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Link: https://lore.kernel.org/bpf/1580084042-11598-4-git-send-email-john.fastabend@gmail.com

commit 77339e61aa309310a535bd01eb3388f7a27b36f9
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Fri Nov 15 14:08:53 2019 -0800

    rcu: Provide wrappers for uses of ->rcu_read_lock_nesting
    
    This commit provides wrapper functions for uses of ->rcu_read_lock_nesting
    to improve readability and to ease future changes to support inlining
    of __rcu_read_lock() and __rcu_read_unlock().
    
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit c51f83c315c392d9776c33eb16a2fe1349d65c7f
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Nov 4 08:22:45 2019 -0800

    rcu: Use READ_ONCE() for ->expmask in rcu_read_unlock_special()
    
    The rcu_node structure's ->expmask field is updated only when holding the
    ->lock, but is also accessed locklessly.  This means that all ->expmask
    updates must use WRITE_ONCE() and all reads carried out without holding
    ->lock must use READ_ONCE().  This commit therefore changes the lockless
    ->expmask read in rcu_read_unlock_special() to use READ_ONCE().
    
    Reported-by: syzbot+99f4ddade3c22ab0cf23@syzkaller.appspotmail.com
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
    Acked-by: Marco Elver <elver@google.com>

commit 3717e1e9f25ec7059e421ab6fc602cab7063c11c
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Fri Nov 1 05:06:21 2019 -0700

    rcu: Clear ->rcu_read_unlock_special only once
    
    In rcu_preempt_deferred_qs_irqrestore(), ->rcu_read_unlock_special is
    cleared one piece at a time.  Given that the "if" statements in this
    function use the copy in "special", this commit removes the clearing
    of the individual pieces in favor of clearing ->rcu_read_unlock_special
    in one go just after it has been determined to be non-zero.
    
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 2eeba5838fd8c5e19bb91e25624116936348e7af
Author: Lai Jiangshan <laijs@linux.alibaba.com>
Date:   Fri Nov 1 04:06:22 2019 -0700

    rcu: Clear .exp_hint only when deferred quiescent state has been reported
    
    Currently, the .exp_hint flag is cleared in rcu_read_unlock_special(),
    which works, but which can also prevent subsequent rcu_read_unlock() calls
    from helping expedite the quiescent state needed by an ongoing expedited
    RCU grace period.  This commit therefore defers clearing of .exp_hint
    from rcu_read_unlock_special() to rcu_preempt_deferred_qs_irqrestore(),
    thus ensuring that intervening calls to rcu_read_unlock() have a chance
    to help end the expedited grace period.
    
    Signed-off-by: Lai Jiangshan <laijs@linux.alibaba.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 6d7c51075ffeb506df6f7a256a3a5f7a2290538a
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Nov 21 08:25:09 2019 -0800

    bpf: skmsg, fix potential psock NULL pointer dereference
    
    commit 8163999db445021f2651a8a47b5632483e8722ea upstream.
    
    Report from Dan Carpenter,
    
     net/core/skmsg.c:792 sk_psock_write_space()
     error: we previously assumed 'psock' could be null (see line 790)
    
     net/core/skmsg.c
       789 psock = sk_psock(sk);
       790 if (likely(psock && sk_psock_test_state(psock, SK_PSOCK_TX_ENABLED)))
     Check for NULL
       791 schedule_work(&psock->work);
       792 write_space = psock->saved_write_space;
                         ^^^^^^^^^^^^^^^^^^^^^^^^
       793          rcu_read_unlock();
       794          write_space(sk);
    
    Ensure psock dereference on line 792 only occurs if psock is not null.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Fixes: 604326b41a6f ("bpf, sockmap: convert to generic sk_msg interface")
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3b91237c52549da9890b69b751d96042c7c2dcdf
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Nov 8 08:45:23 2019 -0800

    net/sched: annotate lockless accesses to qdisc->empty
    
    commit 90b2be27bb0e56483f335cc10fb59ec66882b949 upstream.
    
    KCSAN reported the following race [1]
    
    BUG: KCSAN: data-race in __dev_queue_xmit / net_tx_action
    
    read to 0xffff8880ba403508 of 1 bytes by task 21814 on cpu 1:
     __dev_xmit_skb net/core/dev.c:3389 [inline]
     __dev_queue_xmit+0x9db/0x1b40 net/core/dev.c:3761
     dev_queue_xmit+0x21/0x30 net/core/dev.c:3825
     neigh_hh_output include/net/neighbour.h:500 [inline]
     neigh_output include/net/neighbour.h:509 [inline]
     ip6_finish_output2+0x873/0xec0 net/ipv6/ip6_output.c:116
     __ip6_finish_output net/ipv6/ip6_output.c:142 [inline]
     __ip6_finish_output+0x2d7/0x330 net/ipv6/ip6_output.c:127
     ip6_finish_output+0x41/0x160 net/ipv6/ip6_output.c:152
     NF_HOOK_COND include/linux/netfilter.h:294 [inline]
     ip6_output+0xf2/0x280 net/ipv6/ip6_output.c:175
     dst_output include/net/dst.h:436 [inline]
     ip6_local_out+0x74/0x90 net/ipv6/output_core.c:179
     ip6_send_skb+0x53/0x110 net/ipv6/ip6_output.c:1795
     udp_v6_send_skb.isra.0+0x3ec/0xa70 net/ipv6/udp.c:1173
     udpv6_sendmsg+0x1906/0x1c20 net/ipv6/udp.c:1471
     inet6_sendmsg+0x6d/0x90 net/ipv6/af_inet6.c:576
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg+0x9f/0xc0 net/socket.c:657
     ___sys_sendmsg+0x2b7/0x5d0 net/socket.c:2311
     __sys_sendmmsg+0x123/0x350 net/socket.c:2413
     __do_sys_sendmmsg net/socket.c:2442 [inline]
     __se_sys_sendmmsg net/socket.c:2439 [inline]
     __x64_sys_sendmmsg+0x64/0x80 net/socket.c:2439
     do_syscall_64+0xcc/0x370 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    write to 0xffff8880ba403508 of 1 bytes by interrupt on cpu 0:
     qdisc_run_begin include/net/sch_generic.h:160 [inline]
     qdisc_run include/net/pkt_sched.h:120 [inline]
     net_tx_action+0x2b1/0x6c0 net/core/dev.c:4551
     __do_softirq+0x115/0x33f kernel/softirq.c:292
     do_softirq_own_stack+0x2a/0x40 arch/x86/entry/entry_64.S:1082
     do_softirq.part.0+0x6b/0x80 kernel/softirq.c:337
     do_softirq kernel/softirq.c:329 [inline]
     __local_bh_enable_ip+0x76/0x80 kernel/softirq.c:189
     local_bh_enable include/linux/bottom_half.h:32 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     ip6_finish_output2+0x7bb/0xec0 net/ipv6/ip6_output.c:117
     __ip6_finish_output net/ipv6/ip6_output.c:142 [inline]
     __ip6_finish_output+0x2d7/0x330 net/ipv6/ip6_output.c:127
     ip6_finish_output+0x41/0x160 net/ipv6/ip6_output.c:152
     NF_HOOK_COND include/linux/netfilter.h:294 [inline]
     ip6_output+0xf2/0x280 net/ipv6/ip6_output.c:175
     dst_output include/net/dst.h:436 [inline]
     ip6_local_out+0x74/0x90 net/ipv6/output_core.c:179
     ip6_send_skb+0x53/0x110 net/ipv6/ip6_output.c:1795
     udp_v6_send_skb.isra.0+0x3ec/0xa70 net/ipv6/udp.c:1173
     udpv6_sendmsg+0x1906/0x1c20 net/ipv6/udp.c:1471
     inet6_sendmsg+0x6d/0x90 net/ipv6/af_inet6.c:576
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg+0x9f/0xc0 net/socket.c:657
     ___sys_sendmsg+0x2b7/0x5d0 net/socket.c:2311
     __sys_sendmmsg+0x123/0x350 net/socket.c:2413
     __do_sys_sendmmsg net/socket.c:2442 [inline]
     __se_sys_sendmmsg net/socket.c:2439 [inline]
     __x64_sys_sendmmsg+0x64/0x80 net/socket.c:2439
     do_syscall_64+0xcc/0x370 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 0 PID: 21817 Comm: syz-executor.2 Not tainted 5.4.0-rc6+ #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Fixes: d518d2ed8640 ("net/sched: fix race between deactivation and dequeue for NOLOCK qdisc")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Paolo Abeni <pabeni@redhat.com>
    Cc: Davide Caratti <dcaratti@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b0fc9cf57ff3fdcdc96748673aa88d7b93938e2d
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    commit 5604285839aaedfb23ebe297799c6e558939334d upstream.
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2ad86afcd92a9cfdd986369d0c2209260869c0f3
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    commit 5604285839aaedfb23ebe297799c6e558939334d upstream.
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ff194a90990e8186e087387c0638ffc4d621cd57
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    commit 5604285839aaedfb23ebe297799c6e558939334d upstream.
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d47d4d0168558dc53b147b675601c0dd5e0d755a
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    commit 5604285839aaedfb23ebe297799c6e558939334d upstream.
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e49b8dbaeaad015e24d73cd521b9cc968276da5c
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    commit 5604285839aaedfb23ebe297799c6e558939334d upstream.
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6935c3983b246d5fbfebd3b891c825e65c118f2d
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Oct 9 14:21:54 2019 -0700

    rcu: Avoid data-race in rcu_gp_fqs_check_wake()
    
    The rcu_gp_fqs_check_wake() function uses rcu_preempt_blocked_readers_cgp()
    to read ->gp_tasks while other cpus might overwrite this field.
    
    We need READ_ONCE()/WRITE_ONCE() pairs to avoid compiler
    tricks and KCSAN splats like the following :
    
    BUG: KCSAN: data-race in rcu_gp_fqs_check_wake / rcu_preempt_deferred_qs_irqrestore
    
    write to 0xffffffff85a7f190 of 8 bytes by task 7317 on cpu 0:
     rcu_preempt_deferred_qs_irqrestore+0x43d/0x580 kernel/rcu/tree_plugin.h:507
     rcu_read_unlock_special+0xec/0x370 kernel/rcu/tree_plugin.h:659
     __rcu_read_unlock+0xcf/0xe0 kernel/rcu/tree_plugin.h:394
     rcu_read_unlock include/linux/rcupdate.h:645 [inline]
     __ip_queue_xmit+0x3b0/0xa40 net/ipv4/ip_output.c:533
     ip_queue_xmit+0x45/0x60 include/net/ip.h:236
     __tcp_transmit_skb+0xdeb/0x1cd0 net/ipv4/tcp_output.c:1158
     __tcp_send_ack+0x246/0x300 net/ipv4/tcp_output.c:3685
     tcp_send_ack+0x34/0x40 net/ipv4/tcp_output.c:3691
     tcp_cleanup_rbuf+0x130/0x360 net/ipv4/tcp.c:1575
     tcp_recvmsg+0x633/0x1a30 net/ipv4/tcp.c:2179
     inet_recvmsg+0xbb/0x250 net/ipv4/af_inet.c:838
     sock_recvmsg_nosec net/socket.c:871 [inline]
     sock_recvmsg net/socket.c:889 [inline]
     sock_recvmsg+0x92/0xb0 net/socket.c:885
     sock_read_iter+0x15f/0x1e0 net/socket.c:967
     call_read_iter include/linux/fs.h:1864 [inline]
     new_sync_read+0x389/0x4f0 fs/read_write.c:414
    
    read to 0xffffffff85a7f190 of 8 bytes by task 10 on cpu 1:
     rcu_gp_fqs_check_wake kernel/rcu/tree.c:1556 [inline]
     rcu_gp_fqs_check_wake+0x93/0xd0 kernel/rcu/tree.c:1546
     rcu_gp_fqs_loop+0x36c/0x580 kernel/rcu/tree.c:1611
     rcu_gp_kthread+0x143/0x220 kernel/rcu/tree.c:1768
     kthread+0x1d4/0x200 drivers/block/aoe/aoecmd.c:1253
     ret_from_fork+0x1f/0x30 arch/x86/entry/entry_64.S:352
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 10 Comm: rcu_preempt Not tainted 5.3.0+ #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    [ paulmck:  Added another READ_ONCE() for RCU CPU stall warnings. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit df1e849ae4559544ff00ff5052eefe2479750539
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Wed Nov 27 16:36:45 2019 -0800

    rcu: Enable tick for nohz_full CPUs slow to provide expedited QS
    
    An expedited grace period can be stalled by a nohz_full CPU looping
    in kernel context.  This possibility is currently handled by some
    carefully crafted checks in rcu_read_unlock_special() that enlist help
    from ksoftirqd when permitted by the scheduler.  However, it is exactly
    these checks that require the scheduler avoid holding any of its rq or
    pi locks across rcu_read_unlock() without also having held them across
    the entire RCU read-side critical section.
    
    It would therefore be very nice if expedited grace periods could
    handle nohz_full CPUs looping in kernel context without such checks.
    This commit therefore adds code to the expedited grace period's wait
    and cleanup code that forces the scheduler-clock interrupt on for CPUs
    that fail to quickly supply a quiescent state.  "Quickly" is currently
    a hard-coded single-jiffy delay.
    
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 5604285839aaedfb23ebe297799c6e558939334d
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Dec 7 14:43:39 2019 -0800

    netfilter: bridge: make sure to pull arp header in br_nf_forward_arp()
    
    syzbot is kind enough to remind us we need to call skb_may_pull()
    
    BUG: KMSAN: uninit-value in br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
    CPU: 1 PID: 11631 Comm: syz-executor.1 Not tainted 5.4.0-rc8-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x1c9/0x220 lib/dump_stack.c:118
     kmsan_report+0x128/0x220 mm/kmsan/kmsan_report.c:108
     __msan_warning+0x64/0xc0 mm/kmsan/kmsan_instr.c:245
     br_nf_forward_arp+0xe61/0x1230 net/bridge/br_netfilter_hooks.c:665
     nf_hook_entry_hookfn include/linux/netfilter.h:135 [inline]
     nf_hook_slow+0x18b/0x3f0 net/netfilter/core.c:512
     nf_hook include/linux/netfilter.h:260 [inline]
     NF_HOOK include/linux/netfilter.h:303 [inline]
     __br_forward+0x78f/0xe30 net/bridge/br_forward.c:109
     br_flood+0xef0/0xfe0 net/bridge/br_forward.c:234
     br_handle_frame_finish+0x1a77/0x1c20 net/bridge/br_input.c:162
     nf_hook_bridge_pre net/bridge/br_input.c:245 [inline]
     br_handle_frame+0xfb6/0x1eb0 net/bridge/br_input.c:348
     __netif_receive_skb_core+0x20b9/0x51a0 net/core/dev.c:4830
     __netif_receive_skb_one_core net/core/dev.c:4927 [inline]
     __netif_receive_skb net/core/dev.c:5043 [inline]
     process_backlog+0x610/0x13c0 net/core/dev.c:5874
     napi_poll net/core/dev.c:6311 [inline]
     net_rx_action+0x7a6/0x1aa0 net/core/dev.c:6379
     __do_softirq+0x4a1/0x83a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1091
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x184/0x1d0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     __dev_queue_xmit+0x38e8/0x4200 net/core/dev.c:3819
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3825
     packet_snd net/packet/af_packet.c:2959 [inline]
     packet_sendmsg+0x8234/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    RIP: 0033:0x45a679
    Code: ad b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 7b b6 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f0a3c9e5c78 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000006 RCX: 000000000045a679
    RDX: 000000000000000e RSI: 0000000020000200 RDI: 0000000000000003
    RBP: 000000000075bf20 R08: 00000000200000c0 R09: 0000000000000014
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f0a3c9e66d4
    R13: 00000000004c8ec1 R14: 00000000004dfe28 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:149 [inline]
     kmsan_internal_poison_shadow+0x5c/0x110 mm/kmsan/kmsan.c:132
     kmsan_slab_alloc+0x97/0x100 mm/kmsan/kmsan_hooks.c:86
     slab_alloc_node mm/slub.c:2773 [inline]
     __kmalloc_node_track_caller+0xe27/0x11a0 mm/slub.c:4381
     __kmalloc_reserve net/core/skbuff.c:141 [inline]
     __alloc_skb+0x306/0xa10 net/core/skbuff.c:209
     alloc_skb include/linux/skbuff.h:1049 [inline]
     alloc_skb_with_frags+0x18c/0xa80 net/core/skbuff.c:5662
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2244
     packet_alloc_skb net/packet/af_packet.c:2807 [inline]
     packet_snd net/packet/af_packet.c:2902 [inline]
     packet_sendmsg+0x63a6/0x9100 net/packet/af_packet.c:2984
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg net/socket.c:657 [inline]
     __sys_sendto+0xc44/0xc70 net/socket.c:1952
     __do_sys_sendto net/socket.c:1964 [inline]
     __se_sys_sendto+0x107/0x130 net/socket.c:1960
     __x64_sys_sendto+0x6e/0x90 net/socket.c:1960
     do_syscall_64+0xb6/0x160 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: c4e70a87d975 ("netfilter: bridge: rename br_netfilter.c to br_netfilter_hooks.c")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Reviewed-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 8163999db445021f2651a8a47b5632483e8722ea
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Nov 21 08:25:09 2019 -0800

    bpf: skmsg, fix potential psock NULL pointer dereference
    
    Report from Dan Carpenter,
    
     net/core/skmsg.c:792 sk_psock_write_space()
     error: we previously assumed 'psock' could be null (see line 790)
    
     net/core/skmsg.c
       789 psock = sk_psock(sk);
       790 if (likely(psock && sk_psock_test_state(psock, SK_PSOCK_TX_ENABLED)))
     Check for NULL
       791 schedule_work(&psock->work);
       792 write_space = psock->saved_write_space;
                         ^^^^^^^^^^^^^^^^^^^^^^^^
       793          rcu_read_unlock();
       794          write_space(sk);
    
    Ensure psock dereference on line 792 only occurs if psock is not null.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Fixes: 604326b41a6f ("bpf, sockmap: convert to generic sk_msg interface")
    Signed-off-by: John Fastabend <john.fastabend@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit deb0c3c29d552ab81ecd5481bb83bf2f4e41927d
Author: Qian Cai <cai@lca.pw>
Date:   Wed Nov 6 00:29:35 2019 -0500

    perf/core: Fix unlock balance in perf_init_event()
    
    Commit:
    
      66d258c5b048 ("perf/core: Optimize perf_init_event()")
    
    introduced an unlock imbalance in perf_init_event() where it calls
    "goto again" and then only repeat rcu_read_unlock().
    
    Signed-off-by: Qian Cai <cai@lca.pw>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mark Rutland <mark.rutland@arm.com>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Stephane Eranian <eranian@google.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vince Weaver <vincent.weaver@maine.edu>
    Fixes: 66d258c5b048 ("perf/core: Optimize perf_init_event()")
    Link: https://lkml.kernel.org/r/20191106052935.8352-1-cai@lca.pw
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 90b2be27bb0e56483f335cc10fb59ec66882b949
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Nov 8 08:45:23 2019 -0800

    net/sched: annotate lockless accesses to qdisc->empty
    
    KCSAN reported the following race [1]
    
    BUG: KCSAN: data-race in __dev_queue_xmit / net_tx_action
    
    read to 0xffff8880ba403508 of 1 bytes by task 21814 on cpu 1:
     __dev_xmit_skb net/core/dev.c:3389 [inline]
     __dev_queue_xmit+0x9db/0x1b40 net/core/dev.c:3761
     dev_queue_xmit+0x21/0x30 net/core/dev.c:3825
     neigh_hh_output include/net/neighbour.h:500 [inline]
     neigh_output include/net/neighbour.h:509 [inline]
     ip6_finish_output2+0x873/0xec0 net/ipv6/ip6_output.c:116
     __ip6_finish_output net/ipv6/ip6_output.c:142 [inline]
     __ip6_finish_output+0x2d7/0x330 net/ipv6/ip6_output.c:127
     ip6_finish_output+0x41/0x160 net/ipv6/ip6_output.c:152
     NF_HOOK_COND include/linux/netfilter.h:294 [inline]
     ip6_output+0xf2/0x280 net/ipv6/ip6_output.c:175
     dst_output include/net/dst.h:436 [inline]
     ip6_local_out+0x74/0x90 net/ipv6/output_core.c:179
     ip6_send_skb+0x53/0x110 net/ipv6/ip6_output.c:1795
     udp_v6_send_skb.isra.0+0x3ec/0xa70 net/ipv6/udp.c:1173
     udpv6_sendmsg+0x1906/0x1c20 net/ipv6/udp.c:1471
     inet6_sendmsg+0x6d/0x90 net/ipv6/af_inet6.c:576
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg+0x9f/0xc0 net/socket.c:657
     ___sys_sendmsg+0x2b7/0x5d0 net/socket.c:2311
     __sys_sendmmsg+0x123/0x350 net/socket.c:2413
     __do_sys_sendmmsg net/socket.c:2442 [inline]
     __se_sys_sendmmsg net/socket.c:2439 [inline]
     __x64_sys_sendmmsg+0x64/0x80 net/socket.c:2439
     do_syscall_64+0xcc/0x370 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    write to 0xffff8880ba403508 of 1 bytes by interrupt on cpu 0:
     qdisc_run_begin include/net/sch_generic.h:160 [inline]
     qdisc_run include/net/pkt_sched.h:120 [inline]
     net_tx_action+0x2b1/0x6c0 net/core/dev.c:4551
     __do_softirq+0x115/0x33f kernel/softirq.c:292
     do_softirq_own_stack+0x2a/0x40 arch/x86/entry/entry_64.S:1082
     do_softirq.part.0+0x6b/0x80 kernel/softirq.c:337
     do_softirq kernel/softirq.c:329 [inline]
     __local_bh_enable_ip+0x76/0x80 kernel/softirq.c:189
     local_bh_enable include/linux/bottom_half.h:32 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:688 [inline]
     ip6_finish_output2+0x7bb/0xec0 net/ipv6/ip6_output.c:117
     __ip6_finish_output net/ipv6/ip6_output.c:142 [inline]
     __ip6_finish_output+0x2d7/0x330 net/ipv6/ip6_output.c:127
     ip6_finish_output+0x41/0x160 net/ipv6/ip6_output.c:152
     NF_HOOK_COND include/linux/netfilter.h:294 [inline]
     ip6_output+0xf2/0x280 net/ipv6/ip6_output.c:175
     dst_output include/net/dst.h:436 [inline]
     ip6_local_out+0x74/0x90 net/ipv6/output_core.c:179
     ip6_send_skb+0x53/0x110 net/ipv6/ip6_output.c:1795
     udp_v6_send_skb.isra.0+0x3ec/0xa70 net/ipv6/udp.c:1173
     udpv6_sendmsg+0x1906/0x1c20 net/ipv6/udp.c:1471
     inet6_sendmsg+0x6d/0x90 net/ipv6/af_inet6.c:576
     sock_sendmsg_nosec net/socket.c:637 [inline]
     sock_sendmsg+0x9f/0xc0 net/socket.c:657
     ___sys_sendmsg+0x2b7/0x5d0 net/socket.c:2311
     __sys_sendmmsg+0x123/0x350 net/socket.c:2413
     __do_sys_sendmmsg net/socket.c:2442 [inline]
     __se_sys_sendmmsg net/socket.c:2439 [inline]
     __x64_sys_sendmmsg+0x64/0x80 net/socket.c:2439
     do_syscall_64+0xcc/0x370 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 0 PID: 21817 Comm: syz-executor.2 Not tainted 5.4.0-rc6+ #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    
    Fixes: d518d2ed8640 ("net/sched: fix race between deactivation and dequeue for NOLOCK qdisc")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Paolo Abeni <pabeni@redhat.com>
    Cc: Davide Caratti <dcaratti@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 45df94c2ad281721db6021ba1466e642828505da
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Tue Oct 1 12:38:19 2019 -0300

    RDMA/mlx5: Order num_pending_prefetch properly with synchronize_srcu
    
    [ Upstream commit aa116b810ac9077a263ed8679fb4d595f180e0eb ]
    
    During destroy setting live = 0 and then synchronize_srcu() prevents
    num_pending_prefetch from incrementing, and also, ensures that all work
    holding that count is queued on the WQ. Testing before causes races of the
    form:
    
        CPU0                                         CPU1
      dereg_mr()
                                              mlx5_ib_advise_mr_prefetch()
                                               srcu_read_lock()
                                                num_pending_prefetch_inc()
                                                  if (!live)
       live = 0
       atomic_read() == 0
         // skip flush_workqueue()
                                                  atomic_inc()
                                                  queue_work();
                                               srcu_read_unlock()
       WARN_ON(atomic_read())  // Fails
    
    Swap the order so that the synchronize_srcu() prevents this.
    
    Fixes: a6bc3875f176 ("IB/mlx5: Protect against prefetch of invalid MR")
    Link: https://lore.kernel.org/r/20191001153821.23621-5-jgg@ziepe.ca
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7dee607ed0e04500459db53001d8e02f8831f084
Author: Parav Pandit <parav@mellanox.com>
Date:   Wed Sep 18 18:50:32 2019 -0500

    net/mlx5: Support lockless FTE read lookups
    
    During connection tracking offloads with high number of connections,
    (40K connections per second), flow table group lock contention is
    observed.
    To improve the performance by reducing lock contention, lockless
    FTE read lookup is performed as described below.
    
    Each flow table entry is refcounted.
    Flow table entry is removed when refcount drops to zero.
    rhash table allows rcu protected lookup.
    Each hash table entry insertion and removal is write lock protected.
    
    Hence, it is possible to perform lockless lookup in rhash table using
    following scheme.
    
    (a) Guard FTE entry lookup per group using rcu read lock.
    (b) Before freeing the FTE entry, wait for all readers to finish
    accessing the FTE.
    
    Below example of one reader and write in parallel racing, shows
    protection in effect with rcu lock.
    
    lookup_fte_locked()
      rcu_read_lock();
      search_hash_table()
                                      existing_flow_group_write_lock();
                                      tree_put_node(fte)
                                        drop_ref_cnt(fte)
                                        del_sw_fte(fte)
                                        del_hash_table_entry();
                                        call_rcu();
                                      existing_flow_group_write_unlock();
      get_ref_cnt(fte) fails
      rcu_read_unlock();
                                      rcu grace period();
                                        [..]
                                        kmem_cache_free(fte);
    
    Signed-off-by: Parav Pandit <parav@mellanox.com>
    Reviewed-by: Mark Bloch <markb@mellanox.com>
    Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>

commit 71cb46ae46bda16e766a8957bc68396002767352
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Thu Aug 1 17:39:22 2019 -0400

    Restore docs "rcu: Restore barrier() to rcu_read_lock() and rcu_read_unlock()"
    
    This restores docs back in ReST format.
    
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    [ paulmck: Added Joel's SoB per Stephen Rothwell feedback. ]
    [ paulmck: Joel approved via private email. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 97df75cde57f0a24075200e22d9e2cfb1f2e195b
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Thu Aug 1 17:39:16 2019 -0400

    Revert docs from "rcu: Restore barrier() to rcu_read_lock() and rcu_read_unlock()"
    
    This reverts docs from commit d6b9cd7dc8e041ee83cb1362fce59a3cdb1f2709.
    
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    [ paulmck: Added Joel's SoB per Stephen Rothwell feedback. ]
    [ paulmck: Joel approved via private email. ]
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 328891dc96feb6139438bd5b02fcad2dd4168844
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri May 20 01:57:20 2016 +0100

    Btrfs: fix race between readahead and device replace/removal
    
    commit ce7791ffee1e1ee9f97193b817c7dd1fa6746aad upstream.
    
    The list of devices is protected by the device_list_mutex and the device
    replace code, in its finishing phase correctly takes that mutex before
    removing the source device from that list. However the readahead code was
    iterating that list without acquiring the respective mutex leading to
    crashes later on due to invalid memory accesses:
    
    [125671.831036] general protection fault: 0000 [#1] PREEMPT SMP
    [125671.832129] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis tpm ppdev evdev parport_pc psmouse sg parport
    processor ser
    [125671.834973] CPU: 10 PID: 19603 Comm: kworker/u32:19 Tainted: G        W       4.6.0-rc7-btrfs-next-29+ #1
    [125671.834973] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [125671.834973] Workqueue: btrfs-readahead btrfs_readahead_helper [btrfs]
    [125671.834973] task: ffff8801ac520540 ti: ffff8801ac918000 task.ti: ffff8801ac918000
    [125671.834973] RIP: 0010:[<ffffffff81270479>]  [<ffffffff81270479>] __radix_tree_lookup+0x6a/0x105
    [125671.834973] RSP: 0018:ffff8801ac91bc28  EFLAGS: 00010206
    [125671.834973] RAX: 0000000000000000 RBX: 6b6b6b6b6b6b6b6a RCX: 0000000000000000
    [125671.834973] RDX: 0000000000000000 RSI: 00000000000c1bff RDI: ffff88002ebd62a8
    [125671.834973] RBP: ffff8801ac91bc70 R08: 0000000000000001 R09: 0000000000000000
    [125671.834973] R10: ffff8801ac91bc70 R11: 0000000000000000 R12: ffff88002ebd62a8
    [125671.834973] R13: 0000000000000000 R14: 0000000000000000 R15: 00000000000c1bff
    [125671.834973] FS:  0000000000000000(0000) GS:ffff88023fd40000(0000) knlGS:0000000000000000
    [125671.834973] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [125671.834973] CR2: 000000000073cae4 CR3: 00000000b7723000 CR4: 00000000000006e0
    [125671.834973] Stack:
    [125671.834973]  0000000000000000 ffff8801422d5600 ffff8802286bbc00 0000000000000000
    [125671.834973]  0000000000000001 ffff8802286bbc00 00000000000c1bff 0000000000000000
    [125671.834973]  ffff88002e639eb8 ffff8801ac91bc80 ffffffff81270541 ffff8801ac91bcb0
    [125671.834973] Call Trace:
    [125671.834973]  [<ffffffff81270541>] radix_tree_lookup+0xd/0xf
    [125671.834973]  [<ffffffffa04ae6a6>] reada_peer_zones_set_lock+0x3e/0x60 [btrfs]
    [125671.834973]  [<ffffffffa04ae8b9>] reada_pick_zone+0x29/0x103 [btrfs]
    [125671.834973]  [<ffffffffa04af42f>] reada_start_machine_worker+0x129/0x2d3 [btrfs]
    [125671.834973]  [<ffffffffa04880be>] btrfs_scrubparity_helper+0x185/0x3aa [btrfs]
    [125671.834973]  [<ffffffffa0488341>] btrfs_readahead_helper+0xe/0x10 [btrfs]
    [125671.834973]  [<ffffffff81069691>] process_one_work+0x271/0x4e9
    [125671.834973]  [<ffffffff81069dda>] worker_thread+0x1eb/0x2c9
    [125671.834973]  [<ffffffff81069bef>] ? rescuer_thread+0x2b3/0x2b3
    [125671.834973]  [<ffffffff8106f403>] kthread+0xd4/0xdc
    [125671.834973]  [<ffffffff8149e242>] ret_from_fork+0x22/0x40
    [125671.834973]  [<ffffffff8106f32f>] ? kthread_stop+0x286/0x286
    
    So fix this by taking the device_list_mutex in the readahead code. We
    can't use here the lighter approach of using a rcu_read_lock() and
    rcu_read_unlock() pair together with a list_for_each_entry_rcu() call
    because we end up doing calls to sleeping functions (kzalloc()) in the
    respective code path.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 2bcdfbf87d239226730cc4936e727fd364123bc7
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 2dc3162e5dee47c807493a3084313758aaa48a9b
Author: James Morse <james.morse@arm.com>
Date:   Tue Aug 20 18:45:57 2019 +0100

    arm64: entry: Move ct_user_exit before any other exception
    
    [ Upstream commit 2671828c3ff4ffadf777f793a1f3232d6e51394a ]
    
    When taking an SError or Debug exception from EL0, we run the C
    handler for these exceptions before updating the context tracking
    code and unmasking lower priority interrupts.
    
    When booting with nohz_full lockdep tells us we got this wrong:
    | =============================
    | WARNING: suspicious RCU usage
    | 5.3.0-rc2-00010-gb4b5e9dcb11b-dirty #11271 Not tainted
    | -----------------------------
    | include/linux/rcupdate.h:643 rcu_read_unlock() used illegally wh!
    |
    | other info that might help us debug this:
    |
    |
    | RCU used illegally from idle CPU!
    | rcu_scheduler_active = 2, debug_locks = 1
    | RCU used illegally from extended quiescent state!
    | 1 lock held by a.out/432:
    |  #0: 00000000c7a79515 (rcu_read_lock){....}, at: brk_handler+0x00
    |
    | stack backtrace:
    | CPU: 1 PID: 432 Comm: a.out Not tainted 5.3.0-rc2-00010-gb4b5e9d1
    | Hardware name: ARM LTD ARM Juno Development Platform/ARM Juno De8
    | Call trace:
    |  dump_backtrace+0x0/0x140
    |  show_stack+0x14/0x20
    |  dump_stack+0xbc/0x104
    |  lockdep_rcu_suspicious+0xf8/0x108
    |  brk_handler+0x164/0x1b0
    |  do_debug_exception+0x11c/0x278
    |  el0_dbg+0x14/0x20
    
    Moving the ct_user_exit calls to be before do_debug_exception() means
    they are also before trace_hardirqs_off() has been updated. Add a new
    ct_user_exit_irqoff macro to avoid the context-tracking code using
    irqsave/restore before we've updated trace_hardirqs_off(). To be
    consistent, do this everywhere.
    
    The C helper is called enter_from_user_mode() to match x86 in the hope
    we can merge them into kernel/context_tracking.c later.
    
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Fixes: 6c81fe7925cc4c42 ("arm64: enable context tracking")
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ad856c85132c4a5f699ec39e9a6c938617103827
Author: James Morse <james.morse@arm.com>
Date:   Tue Aug 20 18:45:57 2019 +0100

    arm64: entry: Move ct_user_exit before any other exception
    
    [ Upstream commit 2671828c3ff4ffadf777f793a1f3232d6e51394a ]
    
    When taking an SError or Debug exception from EL0, we run the C
    handler for these exceptions before updating the context tracking
    code and unmasking lower priority interrupts.
    
    When booting with nohz_full lockdep tells us we got this wrong:
    | =============================
    | WARNING: suspicious RCU usage
    | 5.3.0-rc2-00010-gb4b5e9dcb11b-dirty #11271 Not tainted
    | -----------------------------
    | include/linux/rcupdate.h:643 rcu_read_unlock() used illegally wh!
    |
    | other info that might help us debug this:
    |
    |
    | RCU used illegally from idle CPU!
    | rcu_scheduler_active = 2, debug_locks = 1
    | RCU used illegally from extended quiescent state!
    | 1 lock held by a.out/432:
    |  #0: 00000000c7a79515 (rcu_read_lock){....}, at: brk_handler+0x00
    |
    | stack backtrace:
    | CPU: 1 PID: 432 Comm: a.out Not tainted 5.3.0-rc2-00010-gb4b5e9d1
    | Hardware name: ARM LTD ARM Juno Development Platform/ARM Juno De8
    | Call trace:
    |  dump_backtrace+0x0/0x140
    |  show_stack+0x14/0x20
    |  dump_stack+0xbc/0x104
    |  lockdep_rcu_suspicious+0xf8/0x108
    |  brk_handler+0x164/0x1b0
    |  do_debug_exception+0x11c/0x278
    |  el0_dbg+0x14/0x20
    
    Moving the ct_user_exit calls to be before do_debug_exception() means
    they are also before trace_hardirqs_off() has been updated. Add a new
    ct_user_exit_irqoff macro to avoid the context-tracking code using
    irqsave/restore before we've updated trace_hardirqs_off(). To be
    consistent, do this everywhere.
    
    The C helper is called enter_from_user_mode() to match x86 in the hope
    we can merge them into kernel/context_tracking.c later.
    
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Fixes: 6c81fe7925cc4c42 ("arm64: enable context tracking")
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit aa116b810ac9077a263ed8679fb4d595f180e0eb
Author: Jason Gunthorpe <jgg@mellanox.com>
Date:   Tue Oct 1 12:38:19 2019 -0300

    RDMA/mlx5: Order num_pending_prefetch properly with synchronize_srcu
    
    During destroy setting live = 0 and then synchronize_srcu() prevents
    num_pending_prefetch from incrementing, and also, ensures that all work
    holding that count is queued on the WQ. Testing before causes races of the
    form:
    
        CPU0                                         CPU1
      dereg_mr()
                                              mlx5_ib_advise_mr_prefetch()
                                               srcu_read_lock()
                                                num_pending_prefetch_inc()
                                                  if (!live)
       live = 0
       atomic_read() == 0
         // skip flush_workqueue()
                                                  atomic_inc()
                                                  queue_work();
                                               srcu_read_unlock()
       WARN_ON(atomic_read())  // Fails
    
    Swap the order so that the synchronize_srcu() prevents this.
    
    Fixes: a6bc3875f176 ("IB/mlx5: Protect against prefetch of invalid MR")
    Link: https://lore.kernel.org/r/20191001153821.23621-5-jgg@ziepe.ca
    Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 94cfb33438e03f4c9abcc41f10dcd13b32c9d349
Author: John Garry <john.garry@huawei.com>
Date:   Tue Jul 30 21:29:52 2019 +0800

    lib: logic_pio: Fix RCU usage
    
    commit 06709e81c668f5f56c65b806895b278517bd44e0 upstream.
    
    The traversing of io_range_list with list_for_each_entry_rcu()
    is not properly protected by rcu_read_lock() and rcu_read_unlock(),
    so add them.
    
    These functions mark the critical section scope where the list is
    protected for the reader, it cannot be  "reclaimed". Any updater - in
    this case, the logical PIO registration functions - cannot update the
    list until the reader exits this critical section.
    
    In addition, the list traversing used in logic_pio_register_range()
    does not need to use the rcu variant.
    
    This is because we are already using io_range_mutex to guarantee mutual
    exclusion from mutating the list.
    
    Cc: stable@vger.kernel.org
    Fixes: 031e3601869c ("lib: Add generic PIO mapping method")
    Signed-off-by: John Garry <john.garry@huawei.com>
    Signed-off-by: Wei Xu <xuwei5@hisilicon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b865c2c6e3f2ab13196c736318f2112d22b7c9de
Author: John Garry <john.garry@huawei.com>
Date:   Tue Jul 30 21:29:52 2019 +0800

    lib: logic_pio: Fix RCU usage
    
    commit 06709e81c668f5f56c65b806895b278517bd44e0 upstream.
    
    The traversing of io_range_list with list_for_each_entry_rcu()
    is not properly protected by rcu_read_lock() and rcu_read_unlock(),
    so add them.
    
    These functions mark the critical section scope where the list is
    protected for the reader, it cannot be  "reclaimed". Any updater - in
    this case, the logical PIO registration functions - cannot update the
    list until the reader exits this critical section.
    
    In addition, the list traversing used in logic_pio_register_range()
    does not need to use the rcu variant.
    
    This is because we are already using io_range_mutex to guarantee mutual
    exclusion from mutating the list.
    
    Cc: stable@vger.kernel.org
    Fixes: 031e3601869c ("lib: Add generic PIO mapping method")
    Signed-off-by: John Garry <john.garry@huawei.com>
    Signed-off-by: Wei Xu <xuwei5@hisilicon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2671828c3ff4ffadf777f793a1f3232d6e51394a
Author: James Morse <james.morse@arm.com>
Date:   Tue Aug 20 18:45:57 2019 +0100

    arm64: entry: Move ct_user_exit before any other exception
    
    When taking an SError or Debug exception from EL0, we run the C
    handler for these exceptions before updating the context tracking
    code and unmasking lower priority interrupts.
    
    When booting with nohz_full lockdep tells us we got this wrong:
    | =============================
    | WARNING: suspicious RCU usage
    | 5.3.0-rc2-00010-gb4b5e9dcb11b-dirty #11271 Not tainted
    | -----------------------------
    | include/linux/rcupdate.h:643 rcu_read_unlock() used illegally wh!
    |
    | other info that might help us debug this:
    |
    |
    | RCU used illegally from idle CPU!
    | rcu_scheduler_active = 2, debug_locks = 1
    | RCU used illegally from extended quiescent state!
    | 1 lock held by a.out/432:
    |  #0: 00000000c7a79515 (rcu_read_lock){....}, at: brk_handler+0x00
    |
    | stack backtrace:
    | CPU: 1 PID: 432 Comm: a.out Not tainted 5.3.0-rc2-00010-gb4b5e9d1
    | Hardware name: ARM LTD ARM Juno Development Platform/ARM Juno De8
    | Call trace:
    |  dump_backtrace+0x0/0x140
    |  show_stack+0x14/0x20
    |  dump_stack+0xbc/0x104
    |  lockdep_rcu_suspicious+0xf8/0x108
    |  brk_handler+0x164/0x1b0
    |  do_debug_exception+0x11c/0x278
    |  el0_dbg+0x14/0x20
    
    Moving the ct_user_exit calls to be before do_debug_exception() means
    they are also before trace_hardirqs_off() has been updated. Add a new
    ct_user_exit_irqoff macro to avoid the context-tracking code using
    irqsave/restore before we've updated trace_hardirqs_off(). To be
    consistent, do this everywhere.
    
    The C helper is called enter_from_user_mode() to match x86 in the hope
    we can merge them into kernel/context_tracking.c later.
    
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Fixes: 6c81fe7925cc4c42 ("arm64: enable context tracking")
    Signed-off-by: James Morse <james.morse@arm.com>
    Signed-off-by: Will Deacon <will@kernel.org>

commit 06709e81c668f5f56c65b806895b278517bd44e0
Author: John Garry <john.garry@huawei.com>
Date:   Tue Jul 30 21:29:52 2019 +0800

    lib: logic_pio: Fix RCU usage
    
    The traversing of io_range_list with list_for_each_entry_rcu()
    is not properly protected by rcu_read_lock() and rcu_read_unlock(),
    so add them.
    
    These functions mark the critical section scope where the list is
    protected for the reader, it cannot be  "reclaimed". Any updater - in
    this case, the logical PIO registration functions - cannot update the
    list until the reader exits this critical section.
    
    In addition, the list traversing used in logic_pio_register_range()
    does not need to use the rcu variant.
    
    This is because we are already using io_range_mutex to guarantee mutual
    exclusion from mutating the list.
    
    Cc: stable@vger.kernel.org
    Fixes: 031e3601869c ("lib: Add generic PIO mapping method")
    Signed-off-by: John Garry <john.garry@huawei.com>
    Signed-off-by: Wei Xu <xuwei5@hisilicon.com>

commit 43a4b60d04362185cd5475fd77a02bf6c56c07e4
Author: David Ahern <dsahern@gmail.com>
Date:   Thu Aug 1 15:18:08 2019 -0700

    ipv6: have a single rcu unlock point in __ip6_rt_update_pmtu
    
    Simplify the unlock path in __ip6_rt_update_pmtu by using a
    single point where rcu_read_unlock is called.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit cff6a327d78b05c98e0d1c4be77225ea2c0bfe8e
Author: David Ahern <dsahern@gmail.com>
Date:   Thu Aug 1 14:36:35 2019 -0700

    ipv6: Fix unbalanced rcu locking in rt6_update_exception_stamp_rt
    
    The nexthop path in rt6_update_exception_stamp_rt needs to call
    rcu_read_unlock if it fails to find a fib6_nh match rather than
    just returning.
    
    Fixes: e659ba31d806 ("ipv6: Handle all fib6_nh in a nexthop in exception handling")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1f3ebc8253ee56bfaa883c5114fb5569c56f6197
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Tue Jun 4 14:05:52 2019 -0700

    rcu: Restore barrier() to rcu_read_lock() and rcu_read_unlock()
    
    Commit bb73c52bad36 ("rcu: Don't disable preemption for Tiny and Tree
    RCU readers") removed the barrier() calls from rcu_read_lock() and
    rcu_write_lock() in CONFIG_PREEMPT=n&&CONFIG_PREEMPT_COUNT=n kernels.
    Within RCU, this commit was OK, but it failed to account for things like
    get_user() that can pagefault and that can be reordered by the compiler.
    Lack of the barrier() calls in rcu_read_lock() and rcu_read_unlock()
    can cause these page faults to migrate into RCU read-side critical
    sections, which in CONFIG_PREEMPT=n kernels could result in too-short
    grace periods and arbitrary misbehavior.  Please see commit 386afc91144b
    ("spinlocks and preemption points need to be at least compiler barriers")
    and Linus's commit 66be4e66a7f4 ("rcu: locking and unlocking need to
    always be at least barriers"), this last of which restores the barrier()
    call to both rcu_read_lock() and rcu_read_unlock().
    
    This commit removes barrier() calls that are no longer needed given that
    the addition of them in Linus's commit noted above.  The combination of
    this commit and Linus's commit effectively reverts commit bb73c52bad36
    ("rcu: Don't disable preemption for Tiny and Tree RCU readers").
    
    Reported-by: Herbert Xu <herbert@gondor.apana.org.au>
    Reported-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    [ paulmck: Fix embarrassing typo located by Alan Stern. ]

commit cb4dbbfaa1f5a190f041b174177699a009ab2ecd
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Mon Jul 1 00:04:14 2019 -0400

    rcu: Simplify rcu_note_context_switch exit from critical section
    
    Because __rcu_read_unlock() can be preempted just before the call to
    rcu_read_unlock_special(), it is possible for a task to be preempted just
    before it would have fully exited its RCU read-side critical section.
    This would result in a needless extension of that critical section until
    that task was resumed, which might in turn result in a needlessly
    long grace period, needless RCU priority boosting, and needless
    force-quiescent-state actions.  Therefore, rcu_note_context_switch()
    invokes __rcu_read_unlock() followed by rcu_preempt_deferred_qs() when
    it detects this situation.  This action by rcu_note_context_switch()
    ends the RCU read-side critical section immediately.
    
    Of course, once the task resumes, it will invoke rcu_read_unlock_special()
    redundantly.  This is harmless because the fact that a preemption
    happened means that interrupts, preemption, and softirqs cannot
    have been disabled, so there would be no deferred quiescent state.
    While ->rcu_read_lock_nesting remains less than zero, none of the
    ->rcu_read_unlock_special.b bits can be set, and they were all zeroed by
    the call to rcu_note_context_switch() at task-preemption time.  Therefore,
    setting ->rcu_read_unlock_special.b.exp_hint to false has no effect.
    
    Therefore, the extra call to rcu_preempt_deferred_qs_irqrestore()
    would return immediately.  With one possible exception, which is
    if an expedited grace period started just as the task was being
    resumed, which could leave ->exp_deferred_qs set.  This will cause
    rcu_preempt_deferred_qs_irqrestore() to invoke rcu_report_exp_rdp(),
    reporting the quiescent state, just as it should.  (Such an expedited
    grace period won't affect the preemption code path due to interrupts
    having already been disabled.)
    
    But when rcu_note_context_switch() invokes __rcu_read_unlock(), it
    is doing so with preemption disabled, hence __rcu_read_unlock() will
    unconditionally defer the quiescent state, only to immediately invoke
    rcu_preempt_deferred_qs(), thus immediately reporting the deferred
    quiescent state.  It turns out to be safe (and faster) to instead
    just invoke rcu_preempt_deferred_qs() without the __rcu_read_unlock()
    middleman.
    
    Because this is the invocation during the preemption (as opposed to
    the invocation just after the resume), at least one of the bits in
    ->rcu_read_unlock_special.b must be set and ->rcu_read_lock_nesting
    must be negative.  This means that rcu_preempt_need_deferred_qs() must
    return true, avoiding the early exit from rcu_preempt_deferred_qs().
    Thus, rcu_preempt_deferred_qs_irqrestore() will be invoked immediately,
    as required.
    
    This commit therefore simplifies the CONFIG_PREEMPT=y version of
    rcu_note_context_switch() by removing the "else if" branch of its
    "if" statement.  This change means that all callers that would have
    invoked rcu_read_unlock_special() followed by rcu_preempt_deferred_qs()
    will now simply invoke rcu_preempt_deferred_qs(), thus avoiding the
    rcu_read_unlock_special() middleman when __rcu_read_unlock() is preempted.
    
    Cc: rcu@vger.kernel.org
    Cc: kernel-team@android.com
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 87446b48748b49dd34900904649a5ec95a591699
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Jun 28 11:25:26 2019 -0700

    rcu: Make rcu_read_unlock_special() checks match raise_softirq_irqoff()
    
    Threaded interrupts provide additional interesting interactions between
    RCU and raise_softirq() that can result in self-deadlocks in v5.0-2 of
    the Linux kernel.  These self-deadlocks can be provoked in susceptible
    kernels within a few minutes using the following rcutorture command on
    an 8-CPU system:
    
    tools/testing/selftests/rcutorture/bin/kvm.sh --duration 5 --configs "TREE03" --bootargs "threadirqs"
    
    Although post-v5.2 RCU commits have at least greatly reduced the
    probability of these self-deadlocks, this was entirely by accident.
    Although this sort of accident should be rowdily celebrated on those
    rare occasions when it does occur, such celebrations should be quickly
    followed by a principled patch, which is what this patch purports to be.
    
    The key point behind this patch is that when in_interrupt() returns
    true, __raise_softirq_irqoff() will never attempt a wakeup.  Therefore,
    if in_interrupt(), calls to raise_softirq*() are both safe and
    extremely cheap.
    
    This commit therefore replaces the in_irq() calls in the "if" statement
    in rcu_read_unlock_special() with in_interrupt() and simplifies the
    "if" condition to the following:
    
            if (irqs_were_disabled && use_softirq &&
                (in_interrupt() ||
                 (exp && !t->rcu_read_unlock_special.b.deferred_qs))) {
                    raise_softirq_irqoff(RCU_SOFTIRQ);
            } else {
                    /* Appeal to the scheduler. */
            }
    
    The rationale behind the "if" condition is as follows:
    
    1.      irqs_were_disabled:  If interrupts are enabled, we should
            instead appeal to the scheduler so as to let the upcoming
            irq_enable()/local_bh_enable() do the rescheduling for us.
    2.      use_softirq: If this kernel isn't using softirq, then
            raise_softirq_irqoff() will be unhelpful.
    3.      a.      in_interrupt(): If this returns true, the subsequent
                    call to raise_softirq_irqoff() is guaranteed not to
                    do a wakeup, so that call will be both very cheap and
                    quite safe.
            b.      Otherwise, if !in_interrupt() the raise_softirq_irqoff()
                    might do a wakeup, which is expensive and, in some
                    contexts, unsafe.
                    i.      The "exp" (an expedited RCU grace period is being
                            blocked) says that the wakeup is worthwhile, and:
                    ii.     The !.deferred_qs says that scheduler locks
                            cannot be held, so the wakeup will be safe.
    
    Backporting this requires considerable care, so no auto-backport, please!
    
    Fixes: 05f415715ce45 ("rcu: Speed up expedited GPs when interrupting RCU reader")
    Reported-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit d143b3d1cd89f6bcab67dc88160914aa3536c663
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Sat Jun 22 12:05:54 2019 -0700

    rcu: Simplify rcu_read_unlock_special() deferred wakeups
    
    In !use_softirq runs, we clearly cannot rely on raise_softirq() and
    its lightweight bit setting, so we must instead do some form of wakeup.
    In the absence of a self-IPI when interrupts are disabled, these wakeups
    can be delayed until the next interrupt occurs.  This means that calling
    invoke_rcu_core() doesn't actually do any expediting.
    
    In this case, it is better to take the "else" clause, which sets the
    current CPU's resched bits and, if there is an expedited grace period
    in flight, uses IRQ-work to force the needed self-IPI.  This commit
    therefore removes the "else if" clause that calls invoke_rcu_core().
    
    Reported-by: Scott Wood <swood@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 760d8ed069c4e32a92e2ba251a3b0d9a87a3e771
Author: Masami Hiramatsu <mhiramat@kernel.org>
Date:   Thu Jul 25 17:16:25 2019 +0900

    arm64: Remove unneeded rcu_read_lock from debug handlers
    
    Remove rcu_read_lock()/rcu_read_unlock() from debug exception
    handlers since we are sure those are not preemptible and
    interrupts are off.
    
    Acked-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
    Signed-off-by: Will Deacon <will@kernel.org>

commit 9770fe1b202f423e69e415a695c46c6a1a2a9a02
Author: Haiyang Zhang <haiyangz@microsoft.com>
Date:   Fri Jul 19 17:33:51 2019 +0000

    hv_netvsc: Fix extra rcu_read_unlock in netvsc_recv_callback()
    
    [ Upstream commit be4363bdf0ce9530f15aa0a03d1060304d116b15 ]
    
    There is an extra rcu_read_unlock left in netvsc_recv_callback(),
    after a previous patch that removes RCU from this function.
    This patch removes the extra RCU unlock.
    
    Fixes: 345ac08990b8 ("hv_netvsc: pass netvsc_device to receive callback")
    Signed-off-by: Haiyang Zhang <haiyangz@microsoft.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5b8385de62269b5344f4c15ed92619c06ec92526
Author: Haiyang Zhang <haiyangz@microsoft.com>
Date:   Fri Jul 19 17:33:51 2019 +0000

    hv_netvsc: Fix extra rcu_read_unlock in netvsc_recv_callback()
    
    [ Upstream commit be4363bdf0ce9530f15aa0a03d1060304d116b15 ]
    
    There is an extra rcu_read_unlock left in netvsc_recv_callback(),
    after a previous patch that removes RCU from this function.
    This patch removes the extra RCU unlock.
    
    Fixes: 345ac08990b8 ("hv_netvsc: pass netvsc_device to receive callback")
    Signed-off-by: Haiyang Zhang <haiyangz@microsoft.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c62f5f32356ff5b7be4e7a937425889c3ef86903
Author: Haiyang Zhang <haiyangz@microsoft.com>
Date:   Fri Jul 19 17:33:51 2019 +0000

    hv_netvsc: Fix extra rcu_read_unlock in netvsc_recv_callback()
    
    [ Upstream commit be4363bdf0ce9530f15aa0a03d1060304d116b15 ]
    
    There is an extra rcu_read_unlock left in netvsc_recv_callback(),
    after a previous patch that removes RCU from this function.
    This patch removes the extra RCU unlock.
    
    Fixes: 345ac08990b8 ("hv_netvsc: pass netvsc_device to receive callback")
    Signed-off-by: Haiyang Zhang <haiyangz@microsoft.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5a439255b9e1bfe60264f26bc584ae7f0a0566a6
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Fri Jun 28 14:07:25 2019 +0900

    vxlan: do not destroy fdb if register_netdevice() is failed
    
    [ Upstream commit 7c31e54aeee517d1318dfc0bde9fa7de75893dc6 ]
    
    __vxlan_dev_create() destroys FDB using specific pointer which indicates
    a fdb when error occurs.
    But that pointer should not be used when register_netdevice() fails because
    register_netdevice() internally destroys fdb when error occurs.
    
    This patch makes vxlan_fdb_create() to do not link fdb entry to vxlan dev
    internally.
    Instead, a new function vxlan_fdb_insert() is added to link fdb to vxlan
    dev.
    
    vxlan_fdb_insert() is called after calling register_netdevice().
    This routine can avoid situation that ->ndo_uninit() destroys fdb entry
    in error path of register_netdevice().
    Hence, error path of __vxlan_dev_create() routine can have an opportunity
    to destroy default fdb entry by hand.
    
    Test command
        ip link add bonding_masters type vxlan id 0 group 239.1.1.1 \
                dev enp0s9 dstport 4789
    
    Splat looks like:
    [  213.392816] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [  213.401257] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [  213.402178] CPU: 0 PID: 1414 Comm: ip Not tainted 5.2.0-rc5+ #256
    [  213.402178] RIP: 0010:vxlan_fdb_destroy+0x120/0x220 [vxlan]
    [  213.402178] Code: df 48 8b 2b 48 89 fa 48 c1 ea 03 80 3c 02 00 0f 85 06 01 00 00 4c 8b 63 08 48 b8 00 00 00 00 00 fc d
    [  213.402178] RSP: 0018:ffff88810cb9f0a0 EFLAGS: 00010202
    [  213.402178] RAX: dffffc0000000000 RBX: ffff888101d4a8c8 RCX: 0000000000000000
    [  213.402178] RDX: 1bd5a00000000040 RSI: ffff888101d4a8c8 RDI: ffff888101d4a8d0
    [  213.402178] RBP: 0000000000000000 R08: fffffbfff22b72d9 R09: 0000000000000000
    [  213.402178] R10: 00000000ffffffef R11: 0000000000000000 R12: dead000000000200
    [  213.402178] R13: ffff88810cb9f1f8 R14: ffff88810efccda0 R15: ffff88810efccda0
    [  213.402178] FS:  00007f7f6621a0c0(0000) GS:ffff88811b000000(0000) knlGS:0000000000000000
    [  213.402178] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  213.402178] CR2: 000055746f0807d0 CR3: 00000001123e0000 CR4: 00000000001006f0
    [  213.402178] Call Trace:
    [  213.402178]  __vxlan_dev_create+0x3a9/0x7d0 [vxlan]
    [  213.402178]  ? vxlan_changelink+0x740/0x740 [vxlan]
    [  213.402178]  ? rcu_read_unlock+0x60/0x60 [vxlan]
    [  213.402178]  ? __kasan_kmalloc.constprop.3+0xa0/0xd0
    [  213.402178]  vxlan_newlink+0x8d/0xc0 [vxlan]
    [  213.402178]  ? __vxlan_dev_create+0x7d0/0x7d0 [vxlan]
    [  213.554119]  ? __netlink_ns_capable+0xc3/0xf0
    [  213.554119]  __rtnl_newlink+0xb75/0x1180
    [  213.554119]  ? rtnl_link_unregister+0x230/0x230
    [ ... ]
    
    Fixes: 0241b836732f ("vxlan: fix default fdb entry netlink notify ordering during netdev create")
    Suggested-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Acked-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7429e6e2fb002bfd1117975abd0d659e17ada2ed
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Fri Jun 28 14:07:25 2019 +0900

    vxlan: do not destroy fdb if register_netdevice() is failed
    
    [ Upstream commit 7c31e54aeee517d1318dfc0bde9fa7de75893dc6 ]
    
    __vxlan_dev_create() destroys FDB using specific pointer which indicates
    a fdb when error occurs.
    But that pointer should not be used when register_netdevice() fails because
    register_netdevice() internally destroys fdb when error occurs.
    
    This patch makes vxlan_fdb_create() to do not link fdb entry to vxlan dev
    internally.
    Instead, a new function vxlan_fdb_insert() is added to link fdb to vxlan
    dev.
    
    vxlan_fdb_insert() is called after calling register_netdevice().
    This routine can avoid situation that ->ndo_uninit() destroys fdb entry
    in error path of register_netdevice().
    Hence, error path of __vxlan_dev_create() routine can have an opportunity
    to destroy default fdb entry by hand.
    
    Test command
        ip link add bonding_masters type vxlan id 0 group 239.1.1.1 \
                dev enp0s9 dstport 4789
    
    Splat looks like:
    [  213.392816] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [  213.401257] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [  213.402178] CPU: 0 PID: 1414 Comm: ip Not tainted 5.2.0-rc5+ #256
    [  213.402178] RIP: 0010:vxlan_fdb_destroy+0x120/0x220 [vxlan]
    [  213.402178] Code: df 48 8b 2b 48 89 fa 48 c1 ea 03 80 3c 02 00 0f 85 06 01 00 00 4c 8b 63 08 48 b8 00 00 00 00 00 fc d
    [  213.402178] RSP: 0018:ffff88810cb9f0a0 EFLAGS: 00010202
    [  213.402178] RAX: dffffc0000000000 RBX: ffff888101d4a8c8 RCX: 0000000000000000
    [  213.402178] RDX: 1bd5a00000000040 RSI: ffff888101d4a8c8 RDI: ffff888101d4a8d0
    [  213.402178] RBP: 0000000000000000 R08: fffffbfff22b72d9 R09: 0000000000000000
    [  213.402178] R10: 00000000ffffffef R11: 0000000000000000 R12: dead000000000200
    [  213.402178] R13: ffff88810cb9f1f8 R14: ffff88810efccda0 R15: ffff88810efccda0
    [  213.402178] FS:  00007f7f6621a0c0(0000) GS:ffff88811b000000(0000) knlGS:0000000000000000
    [  213.402178] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  213.402178] CR2: 000055746f0807d0 CR3: 00000001123e0000 CR4: 00000000001006f0
    [  213.402178] Call Trace:
    [  213.402178]  __vxlan_dev_create+0x3a9/0x7d0 [vxlan]
    [  213.402178]  ? vxlan_changelink+0x740/0x740 [vxlan]
    [  213.402178]  ? rcu_read_unlock+0x60/0x60 [vxlan]
    [  213.402178]  ? __kasan_kmalloc.constprop.3+0xa0/0xd0
    [  213.402178]  vxlan_newlink+0x8d/0xc0 [vxlan]
    [  213.402178]  ? __vxlan_dev_create+0x7d0/0x7d0 [vxlan]
    [  213.554119]  ? __netlink_ns_capable+0xc3/0xf0
    [  213.554119]  __rtnl_newlink+0xb75/0x1180
    [  213.554119]  ? rtnl_link_unregister+0x230/0x230
    [ ... ]
    
    Fixes: 0241b836732f ("vxlan: fix default fdb entry netlink notify ordering during netdev create")
    Suggested-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Acked-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 83768245a3b158b96d33012b22ab01d193afb2da
Merge: 5f9e832c1370 b617158dc096
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jul 22 08:49:22 2019 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Pull networking fixes from David Miller:
    
     1) Several netfilter fixes including a nfnetlink deadlock fix from
        Florian Westphal and fix for dropping VRF packets from Miaohe Lin.
    
     2) Flow offload fixes from Pablo Neira Ayuso including a fix to restore
        proper block sharing.
    
     3) Fix r8169 PHY init from Thomas Voegtle.
    
     4) Fix memory leak in mac80211, from Lorenzo Bianconi.
    
     5) Missing NULL check on object allocation in cxgb4, from Navid
        Emamdoost.
    
     6) Fix scaling of RX power in sfp phy driver, from Andrew Lunn.
    
     7) Check that there is actually an ip header to access in skb->data in
        VRF, from Peter Kosyh.
    
     8) Remove spurious rcu unlock in hv_netvsc, from Haiyang Zhang.
    
     9) One more tweak the the TCP fragmentation memory limit changes, to be
        less harmful to applications setting small SO_SNDBUF values. From
        Eric Dumazet.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net: (40 commits)
      tcp: be more careful in tcp_fragment()
      hv_netvsc: Fix extra rcu_read_unlock in netvsc_recv_callback()
      vrf: make sure skb->data contains ip header to make routing
      connector: remove redundant input callback from cn_dev
      qed: Prefer pcie_capability_read_word()
      igc: Prefer pcie_capability_read_word()
      cxgb4: Prefer pcie_capability_read_word()
      be2net: Synchronize be_update_queues with dev_watchdog
      bnx2x: Prevent load reordering in tx completion processing
      net: phy: sfp: hwmon: Fix scaling of RX power
      net: sched: verify that q!=NULL before setting q->flags
      chelsio: Fix a typo in a function name
      allocate_flower_entry: should check for null deref
      net: hns3: typo in the name of a constant
      kbuild: add net/netfilter/nf_tables_offload.h to header-test blacklist.
      tipc: Fix a typo
      mac80211: don't warn about CW params when not using them
      mac80211: fix possible memory leak in ieee80211_assign_beacon
      nl80211: fix NL80211_HE_MAX_CAPABILITY_LEN
      nl80211: fix VENDOR_CMD_RAW_DATA
      ...

commit be4363bdf0ce9530f15aa0a03d1060304d116b15
Author: Haiyang Zhang <haiyangz@microsoft.com>
Date:   Fri Jul 19 17:33:51 2019 +0000

    hv_netvsc: Fix extra rcu_read_unlock in netvsc_recv_callback()
    
    There is an extra rcu_read_unlock left in netvsc_recv_callback(),
    after a previous patch that removes RCU from this function.
    This patch removes the extra RCU unlock.
    
    Fixes: 345ac08990b8 ("hv_netvsc: pass netvsc_device to receive callback")
    Signed-off-by: Haiyang Zhang <haiyangz@microsoft.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c1a970d06f8cf390354a4a426976ed7f960b71f1
Author: Vlad Buslov <vladbu@mellanox.com>
Date:   Wed Jul 10 20:12:29 2019 +0300

    net: sched: Fix NULL-pointer dereference in tc_indr_block_ing_cmd()
    
    After recent refactoring of block offlads infrastructure, indr_dev->block
    pointer is dereferenced before it is verified to be non-NULL. Example stack
    trace where this behavior leads to NULL-pointer dereference error when
    creating vxlan dev on system with mlx5 NIC with offloads enabled:
    
    [ 1157.852938] ==================================================================
    [ 1157.866877] BUG: KASAN: null-ptr-deref in tc_indr_block_ing_cmd.isra.41+0x9c/0x160
    [ 1157.880877] Read of size 4 at addr 0000000000000090 by task ip/3829
    [ 1157.901637] CPU: 22 PID: 3829 Comm: ip Not tainted 5.2.0-rc6+ #488
    [ 1157.914438] Hardware name: Supermicro SYS-2028TP-DECR/X10DRT-P, BIOS 2.0b 03/30/2017
    [ 1157.929031] Call Trace:
    [ 1157.938318]  dump_stack+0x9a/0xeb
    [ 1157.948362]  ? tc_indr_block_ing_cmd.isra.41+0x9c/0x160
    [ 1157.960262]  ? tc_indr_block_ing_cmd.isra.41+0x9c/0x160
    [ 1157.972082]  __kasan_report+0x176/0x192
    [ 1157.982513]  ? tc_indr_block_ing_cmd.isra.41+0x9c/0x160
    [ 1157.994348]  kasan_report+0xe/0x20
    [ 1158.004324]  tc_indr_block_ing_cmd.isra.41+0x9c/0x160
    [ 1158.015950]  ? tcf_block_setup+0x430/0x430
    [ 1158.026558]  ? kasan_unpoison_shadow+0x30/0x40
    [ 1158.037464]  __tc_indr_block_cb_register+0x5f5/0xf20
    [ 1158.049288]  ? mlx5e_rep_indr_tc_block_unbind+0xa0/0xa0 [mlx5_core]
    [ 1158.062344]  ? tc_indr_block_dev_put.part.47+0x5c0/0x5c0
    [ 1158.074498]  ? rdma_roce_rescan_device+0x20/0x20 [ib_core]
    [ 1158.086580]  ? br_device_event+0x98/0x480 [bridge]
    [ 1158.097870]  ? strcmp+0x30/0x50
    [ 1158.107578]  mlx5e_nic_rep_netdevice_event+0xdd/0x180 [mlx5_core]
    [ 1158.120212]  notifier_call_chain+0x6d/0xa0
    [ 1158.130753]  register_netdevice+0x6fc/0x7e0
    [ 1158.141322]  ? netdev_change_features+0xa0/0xa0
    [ 1158.152218]  ? vxlan_config_apply+0x210/0x310 [vxlan]
    [ 1158.163593]  __vxlan_dev_create+0x2ad/0x520 [vxlan]
    [ 1158.174770]  ? vxlan_changelink+0x490/0x490 [vxlan]
    [ 1158.185870]  ? rcu_read_unlock+0x60/0x60 [vxlan]
    [ 1158.196798]  vxlan_newlink+0x99/0xf0 [vxlan]
    [ 1158.207303]  ? __vxlan_dev_create+0x520/0x520 [vxlan]
    [ 1158.218601]  ? rtnl_create_link+0x3d0/0x450
    [ 1158.228900]  __rtnl_newlink+0x8a7/0xb00
    [ 1158.238701]  ? stack_access_ok+0x35/0x80
    [ 1158.248450]  ? rtnl_link_unregister+0x1a0/0x1a0
    [ 1158.258735]  ? find_held_lock+0x6d/0xd0
    [ 1158.268379]  ? is_bpf_text_address+0x67/0xf0
    [ 1158.278330]  ? lock_acquire+0xc1/0x1f0
    [ 1158.287686]  ? is_bpf_text_address+0x5/0xf0
    [ 1158.297449]  ? is_bpf_text_address+0x86/0xf0
    [ 1158.307310]  ? kernel_text_address+0xec/0x100
    [ 1158.317155]  ? arch_stack_walk+0x92/0xe0
    [ 1158.326497]  ? __kernel_text_address+0xe/0x30
    [ 1158.336213]  ? unwind_get_return_address+0x2f/0x50
    [ 1158.346267]  ? create_prof_cpu_mask+0x20/0x20
    [ 1158.355936]  ? arch_stack_walk+0x92/0xe0
    [ 1158.365117]  ? stack_trace_save+0x8a/0xb0
    [ 1158.374272]  ? stack_trace_consume_entry+0x80/0x80
    [ 1158.384226]  ? match_held_lock+0x33/0x210
    [ 1158.393216]  ? kasan_unpoison_shadow+0x30/0x40
    [ 1158.402593]  rtnl_newlink+0x53/0x80
    [ 1158.410925]  rtnetlink_rcv_msg+0x3a5/0x600
    [ 1158.419777]  ? validate_linkmsg+0x400/0x400
    [ 1158.428620]  ? find_held_lock+0x6d/0xd0
    [ 1158.437117]  ? match_held_lock+0x1b/0x210
    [ 1158.445760]  ? validate_linkmsg+0x400/0x400
    [ 1158.454642]  netlink_rcv_skb+0xc7/0x1f0
    [ 1158.463150]  ? netlink_ack+0x470/0x470
    [ 1158.471538]  ? netlink_deliver_tap+0x1f3/0x5a0
    [ 1158.480607]  netlink_unicast+0x2ae/0x350
    [ 1158.489099]  ? netlink_attachskb+0x340/0x340
    [ 1158.497935]  ? _copy_from_iter_full+0xde/0x3b0
    [ 1158.506945]  ? __virt_addr_valid+0xb6/0xf0
    [ 1158.515578]  ? __check_object_size+0x159/0x240
    [ 1158.524515]  netlink_sendmsg+0x4d3/0x630
    [ 1158.532879]  ? netlink_unicast+0x350/0x350
    [ 1158.541400]  ? netlink_unicast+0x350/0x350
    [ 1158.549805]  sock_sendmsg+0x94/0xa0
    [ 1158.557561]  ___sys_sendmsg+0x49d/0x570
    [ 1158.565625]  ? copy_msghdr_from_user+0x210/0x210
    [ 1158.574457]  ? __fput+0x1e2/0x330
    [ 1158.581948]  ? __kasan_slab_free+0x130/0x180
    [ 1158.590407]  ? kmem_cache_free+0xb6/0x2d0
    [ 1158.598574]  ? mark_lock+0xc7/0x790
    [ 1158.606177]  ? task_work_run+0xcf/0x100
    [ 1158.614165]  ? exit_to_usermode_loop+0x102/0x110
    [ 1158.622954]  ? __lock_acquire+0x963/0x1ee0
    [ 1158.631199]  ? lockdep_hardirqs_on+0x260/0x260
    [ 1158.639777]  ? match_held_lock+0x1b/0x210
    [ 1158.647918]  ? lockdep_hardirqs_on+0x260/0x260
    [ 1158.656501]  ? match_held_lock+0x1b/0x210
    [ 1158.664643]  ? __fget_light+0xa6/0xe0
    [ 1158.672423]  ? __sys_sendmsg+0xd2/0x150
    [ 1158.680334]  __sys_sendmsg+0xd2/0x150
    [ 1158.688063]  ? __ia32_sys_shutdown+0x30/0x30
    [ 1158.696435]  ? lock_downgrade+0x2e0/0x2e0
    [ 1158.704541]  ? mark_held_locks+0x1a/0x90
    [ 1158.712611]  ? mark_held_locks+0x1a/0x90
    [ 1158.720619]  ? do_syscall_64+0x1e/0x2c0
    [ 1158.728530]  do_syscall_64+0x78/0x2c0
    [ 1158.736254]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [ 1158.745414] RIP: 0033:0x7f62d505cb87
    [ 1158.753070] Code: 64 89 02 48 c7 c0 ff ff ff ff eb b9 0f 1f 80 00 00 00 00 8b 05 6a 2b 2c 00 48 63 d2 48 63 ff 85 c0 75 18 b8 2e 00 00 00 0f 05 <48> 3d 00 f0 ff ff 77 59 f3 c3 0f 1f 80 00 00[87/1817]
     48 89 f3 48
    [ 1158.780924] RSP: 002b:00007fffd9832268 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 1158.793204] RAX: ffffffffffffffda RBX: 000000005d26048f RCX: 00007f62d505cb87
    [ 1158.805111] RDX: 0000000000000000 RSI: 00007fffd98322d0 RDI: 0000000000000003
    [ 1158.817055] RBP: 0000000000000000 R08: 0000000000000001 R09: 0000000000000006
    [ 1158.828987] R10: 00007f62d50ce260 R11: 0000000000000246 R12: 0000000000000001
    [ 1158.840909] R13: 000000000067e540 R14: 0000000000000000 R15: 000000000067ed20
    [ 1158.852873] ==================================================================
    
    Introduce new function tcf_block_non_null_shared() that verifies block
    pointer before dereferencing it to obtain index. Use the function in
    tc_indr_block_ing_cmd() to prevent NULL pointer dereference.
    
    Fixes: 955bcb6ea0df ("drivers: net: use flow block API")
    Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 95c82386950c7a5e018ac02d795aa8782f52754b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri May 20 01:57:20 2016 +0100

    Btrfs: fix race between readahead and device replace/removal
    
    commit ce7791ffee1e1ee9f97193b817c7dd1fa6746aad upstream.
    
    The list of devices is protected by the device_list_mutex and the device
    replace code, in its finishing phase correctly takes that mutex before
    removing the source device from that list. However the readahead code was
    iterating that list without acquiring the respective mutex leading to
    crashes later on due to invalid memory accesses:
    
    [125671.831036] general protection fault: 0000 [#1] PREEMPT SMP
    [125671.832129] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis tpm ppdev evdev parport_pc psmouse sg parport
    processor ser
    [125671.834973] CPU: 10 PID: 19603 Comm: kworker/u32:19 Tainted: G        W       4.6.0-rc7-btrfs-next-29+ #1
    [125671.834973] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [125671.834973] Workqueue: btrfs-readahead btrfs_readahead_helper [btrfs]
    [125671.834973] task: ffff8801ac520540 ti: ffff8801ac918000 task.ti: ffff8801ac918000
    [125671.834973] RIP: 0010:[<ffffffff81270479>]  [<ffffffff81270479>] __radix_tree_lookup+0x6a/0x105
    [125671.834973] RSP: 0018:ffff8801ac91bc28  EFLAGS: 00010206
    [125671.834973] RAX: 0000000000000000 RBX: 6b6b6b6b6b6b6b6a RCX: 0000000000000000
    [125671.834973] RDX: 0000000000000000 RSI: 00000000000c1bff RDI: ffff88002ebd62a8
    [125671.834973] RBP: ffff8801ac91bc70 R08: 0000000000000001 R09: 0000000000000000
    [125671.834973] R10: ffff8801ac91bc70 R11: 0000000000000000 R12: ffff88002ebd62a8
    [125671.834973] R13: 0000000000000000 R14: 0000000000000000 R15: 00000000000c1bff
    [125671.834973] FS:  0000000000000000(0000) GS:ffff88023fd40000(0000) knlGS:0000000000000000
    [125671.834973] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [125671.834973] CR2: 000000000073cae4 CR3: 00000000b7723000 CR4: 00000000000006e0
    [125671.834973] Stack:
    [125671.834973]  0000000000000000 ffff8801422d5600 ffff8802286bbc00 0000000000000000
    [125671.834973]  0000000000000001 ffff8802286bbc00 00000000000c1bff 0000000000000000
    [125671.834973]  ffff88002e639eb8 ffff8801ac91bc80 ffffffff81270541 ffff8801ac91bcb0
    [125671.834973] Call Trace:
    [125671.834973]  [<ffffffff81270541>] radix_tree_lookup+0xd/0xf
    [125671.834973]  [<ffffffffa04ae6a6>] reada_peer_zones_set_lock+0x3e/0x60 [btrfs]
    [125671.834973]  [<ffffffffa04ae8b9>] reada_pick_zone+0x29/0x103 [btrfs]
    [125671.834973]  [<ffffffffa04af42f>] reada_start_machine_worker+0x129/0x2d3 [btrfs]
    [125671.834973]  [<ffffffffa04880be>] btrfs_scrubparity_helper+0x185/0x3aa [btrfs]
    [125671.834973]  [<ffffffffa0488341>] btrfs_readahead_helper+0xe/0x10 [btrfs]
    [125671.834973]  [<ffffffff81069691>] process_one_work+0x271/0x4e9
    [125671.834973]  [<ffffffff81069dda>] worker_thread+0x1eb/0x2c9
    [125671.834973]  [<ffffffff81069bef>] ? rescuer_thread+0x2b3/0x2b3
    [125671.834973]  [<ffffffff8106f403>] kthread+0xd4/0xdc
    [125671.834973]  [<ffffffff8149e242>] ret_from_fork+0x22/0x40
    [125671.834973]  [<ffffffff8106f32f>] ? kthread_stop+0x286/0x286
    
    So fix this by taking the device_list_mutex in the readahead code. We
    can't use here the lighter approach of using a rcu_read_lock() and
    rcu_read_unlock() pair together with a list_for_each_entry_rcu() call
    because we end up doing calls to sleeping functions (kzalloc()) in the
    respective code path.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 04096b3beacee419bc36650c9f3620a20e9dfdfe
Author: Wei Yongjun <weiyongjun1@huawei.com>
Date:   Mon Feb 18 11:29:29 2019 +0100

    mac80211: mesh: fix missing unlock on error in table_path_del()
    
    [ Upstream commit f2ffff085d287eec499f1fccd682796ad8010303 ]
    
    spin_lock_bh() is used in table_path_del() but rcu_read_unlock()
    is used for unlocking. Fix it by using spin_unlock_bh() instead
    of rcu_read_unlock() in the error handling case.
    
    Fixes: b4c3fbe63601 ("mac80211: Use linked list instead of rhashtable walk for mesh tables")
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Wei Yongjun <weiyongjun1@huawei.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7c31e54aeee517d1318dfc0bde9fa7de75893dc6
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Fri Jun 28 14:07:25 2019 +0900

    vxlan: do not destroy fdb if register_netdevice() is failed
    
    __vxlan_dev_create() destroys FDB using specific pointer which indicates
    a fdb when error occurs.
    But that pointer should not be used when register_netdevice() fails because
    register_netdevice() internally destroys fdb when error occurs.
    
    This patch makes vxlan_fdb_create() to do not link fdb entry to vxlan dev
    internally.
    Instead, a new function vxlan_fdb_insert() is added to link fdb to vxlan
    dev.
    
    vxlan_fdb_insert() is called after calling register_netdevice().
    This routine can avoid situation that ->ndo_uninit() destroys fdb entry
    in error path of register_netdevice().
    Hence, error path of __vxlan_dev_create() routine can have an opportunity
    to destroy default fdb entry by hand.
    
    Test command
        ip link add bonding_masters type vxlan id 0 group 239.1.1.1 \
                dev enp0s9 dstport 4789
    
    Splat looks like:
    [  213.392816] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [  213.401257] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [  213.402178] CPU: 0 PID: 1414 Comm: ip Not tainted 5.2.0-rc5+ #256
    [  213.402178] RIP: 0010:vxlan_fdb_destroy+0x120/0x220 [vxlan]
    [  213.402178] Code: df 48 8b 2b 48 89 fa 48 c1 ea 03 80 3c 02 00 0f 85 06 01 00 00 4c 8b 63 08 48 b8 00 00 00 00 00 fc d
    [  213.402178] RSP: 0018:ffff88810cb9f0a0 EFLAGS: 00010202
    [  213.402178] RAX: dffffc0000000000 RBX: ffff888101d4a8c8 RCX: 0000000000000000
    [  213.402178] RDX: 1bd5a00000000040 RSI: ffff888101d4a8c8 RDI: ffff888101d4a8d0
    [  213.402178] RBP: 0000000000000000 R08: fffffbfff22b72d9 R09: 0000000000000000
    [  213.402178] R10: 00000000ffffffef R11: 0000000000000000 R12: dead000000000200
    [  213.402178] R13: ffff88810cb9f1f8 R14: ffff88810efccda0 R15: ffff88810efccda0
    [  213.402178] FS:  00007f7f6621a0c0(0000) GS:ffff88811b000000(0000) knlGS:0000000000000000
    [  213.402178] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  213.402178] CR2: 000055746f0807d0 CR3: 00000001123e0000 CR4: 00000000001006f0
    [  213.402178] Call Trace:
    [  213.402178]  __vxlan_dev_create+0x3a9/0x7d0 [vxlan]
    [  213.402178]  ? vxlan_changelink+0x740/0x740 [vxlan]
    [  213.402178]  ? rcu_read_unlock+0x60/0x60 [vxlan]
    [  213.402178]  ? __kasan_kmalloc.constprop.3+0xa0/0xd0
    [  213.402178]  vxlan_newlink+0x8d/0xc0 [vxlan]
    [  213.402178]  ? __vxlan_dev_create+0x7d0/0x7d0 [vxlan]
    [  213.554119]  ? __netlink_ns_capable+0xc3/0xf0
    [  213.554119]  __rtnl_newlink+0xb75/0x1180
    [  213.554119]  ? rtnl_link_unregister+0x230/0x230
    [ ... ]
    
    Fixes: 0241b836732f ("vxlan: fix default fdb entry netlink notify ordering during netdev create")
    Suggested-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Acked-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f9de417121001879d92a86960647adb06b5b81bf
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Jun 20 11:55:36 2019 -0400

    tools/memory-model: Expand definition of barrier
    
    Commit 66be4e66a7f4 ("rcu: locking and unlocking need to always be at
    least barriers") added compiler barriers back into rcu_read_lock() and
    rcu_read_unlock().  Furthermore, srcu_read_lock() and
    srcu_read_unlock() have always contained compiler barriers.
    
    The Linux Kernel Memory Model ought to know about these barriers.
    This patch adds them into the memory model.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Acked-by: Andrea Parri <andrea.parri@amarulasolutions.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 85f9aa7565bd79b039325f2c01af7ffa717924df
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 19 09:38:38 2019 -0700

    inet: clear num_timeout reqsk_alloc()
    
    KMSAN caught uninit-value in tcp_create_openreq_child() [1]
    This is caused by a recent change, combined by the fact
    that TCP cleared num_timeout, num_retrans and sk fields only
    when a request socket was about to be queued.
    
    Under syncookie mode, a temporary request socket is used,
    and req->num_timeout could contain garbage.
    
    Lets clear these three fields sooner, there is really no
    point trying to defer this and risk other bugs.
    
    [1]
    
    BUG: KMSAN: uninit-value in tcp_create_openreq_child+0x157f/0x1cc0 net/ipv4/tcp_minisocks.c:526
    CPU: 1 PID: 13357 Comm: syz-executor591 Not tainted 5.2.0-rc4+ #3
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x191/0x1f0 lib/dump_stack.c:113
     kmsan_report+0x162/0x2d0 mm/kmsan/kmsan.c:611
     __msan_warning+0x75/0xe0 mm/kmsan/kmsan_instr.c:304
     tcp_create_openreq_child+0x157f/0x1cc0 net/ipv4/tcp_minisocks.c:526
     tcp_v6_syn_recv_sock+0x761/0x2d80 net/ipv6/tcp_ipv6.c:1152
     tcp_get_cookie_sock+0x16e/0x6b0 net/ipv4/syncookies.c:209
     cookie_v6_check+0x27e0/0x29a0 net/ipv6/syncookies.c:252
     tcp_v6_cookie_check net/ipv6/tcp_ipv6.c:1039 [inline]
     tcp_v6_do_rcv+0xf1c/0x1ce0 net/ipv6/tcp_ipv6.c:1344
     tcp_v6_rcv+0x60b7/0x6a30 net/ipv6/tcp_ipv6.c:1554
     ip6_protocol_deliver_rcu+0x1433/0x22f0 net/ipv6/ip6_input.c:397
     ip6_input_finish net/ipv6/ip6_input.c:438 [inline]
     NF_HOOK include/linux/netfilter.h:305 [inline]
     ip6_input+0x2af/0x340 net/ipv6/ip6_input.c:447
     dst_input include/net/dst.h:439 [inline]
     ip6_rcv_finish net/ipv6/ip6_input.c:76 [inline]
     NF_HOOK include/linux/netfilter.h:305 [inline]
     ipv6_rcv+0x683/0x710 net/ipv6/ip6_input.c:272
     __netif_receive_skb_one_core net/core/dev.c:4981 [inline]
     __netif_receive_skb net/core/dev.c:5095 [inline]
     process_backlog+0x721/0x1410 net/core/dev.c:5906
     napi_poll net/core/dev.c:6329 [inline]
     net_rx_action+0x738/0x1940 net/core/dev.c:6395
     __do_softirq+0x4ad/0x858 kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1052
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x199/0x1e0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:682 [inline]
     ip6_finish_output2+0x213f/0x2670 net/ipv6/ip6_output.c:117
     ip6_finish_output+0xae4/0xbc0 net/ipv6/ip6_output.c:150
     NF_HOOK_COND include/linux/netfilter.h:294 [inline]
     ip6_output+0x5d3/0x720 net/ipv6/ip6_output.c:167
     dst_output include/net/dst.h:433 [inline]
     NF_HOOK include/linux/netfilter.h:305 [inline]
     ip6_xmit+0x1f53/0x2650 net/ipv6/ip6_output.c:271
     inet6_csk_xmit+0x3df/0x4f0 net/ipv6/inet6_connection_sock.c:135
     __tcp_transmit_skb+0x4076/0x5b40 net/ipv4/tcp_output.c:1156
     tcp_transmit_skb net/ipv4/tcp_output.c:1172 [inline]
     tcp_write_xmit+0x39a9/0xa730 net/ipv4/tcp_output.c:2397
     __tcp_push_pending_frames+0x124/0x4e0 net/ipv4/tcp_output.c:2573
     tcp_send_fin+0xd43/0x1540 net/ipv4/tcp_output.c:3118
     tcp_close+0x16ba/0x1860 net/ipv4/tcp.c:2403
     inet_release+0x1f7/0x270 net/ipv4/af_inet.c:427
     inet6_release+0xaf/0x100 net/ipv6/af_inet6.c:470
     __sock_release net/socket.c:601 [inline]
     sock_close+0x156/0x490 net/socket.c:1273
     __fput+0x4c9/0xba0 fs/file_table.c:280
     ____fput+0x37/0x40 fs/file_table.c:313
     task_work_run+0x22e/0x2a0 kernel/task_work.c:113
     tracehook_notify_resume include/linux/tracehook.h:185 [inline]
     exit_to_usermode_loop arch/x86/entry/common.c:168 [inline]
     prepare_exit_to_usermode+0x39d/0x4d0 arch/x86/entry/common.c:199
     syscall_return_slowpath+0x90/0x5c0 arch/x86/entry/common.c:279
     do_syscall_64+0xe2/0xf0 arch/x86/entry/common.c:305
     entry_SYSCALL_64_after_hwframe+0x63/0xe7
    RIP: 0033:0x401d50
    Code: 01 f0 ff ff 0f 83 40 0d 00 00 c3 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00 83 3d dd 8d 2d 00 00 75 14 b8 03 00 00 00 0f 05 <48> 3d 01 f0 ff ff 0f 83 14 0d 00 00 c3 48 83 ec 08 e8 7a 02 00 00
    RSP: 002b:00007fff1cf58cf8 EFLAGS: 00000246 ORIG_RAX: 0000000000000003
    RAX: 0000000000000000 RBX: 0000000000000004 RCX: 0000000000401d50
    RDX: 000000000000001c RSI: 0000000000000000 RDI: 0000000000000003
    RBP: 00000000004a9050 R08: 0000000020000040 R09: 000000000000001c
    R10: 0000000020004004 R11: 0000000000000246 R12: 0000000000402ef0
    R13: 0000000000402f80 R14: 0000000000000000 R15: 0000000000000000
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:201 [inline]
     kmsan_internal_poison_shadow+0x53/0xa0 mm/kmsan/kmsan.c:160
     kmsan_kmalloc+0xa4/0x130 mm/kmsan/kmsan_hooks.c:177
     kmem_cache_alloc+0x534/0xb00 mm/slub.c:2781
     reqsk_alloc include/net/request_sock.h:84 [inline]
     inet_reqsk_alloc+0xa8/0x600 net/ipv4/tcp_input.c:6384
     cookie_v6_check+0xadb/0x29a0 net/ipv6/syncookies.c:173
     tcp_v6_cookie_check net/ipv6/tcp_ipv6.c:1039 [inline]
     tcp_v6_do_rcv+0xf1c/0x1ce0 net/ipv6/tcp_ipv6.c:1344
     tcp_v6_rcv+0x60b7/0x6a30 net/ipv6/tcp_ipv6.c:1554
     ip6_protocol_deliver_rcu+0x1433/0x22f0 net/ipv6/ip6_input.c:397
     ip6_input_finish net/ipv6/ip6_input.c:438 [inline]
     NF_HOOK include/linux/netfilter.h:305 [inline]
     ip6_input+0x2af/0x340 net/ipv6/ip6_input.c:447
     dst_input include/net/dst.h:439 [inline]
     ip6_rcv_finish net/ipv6/ip6_input.c:76 [inline]
     NF_HOOK include/linux/netfilter.h:305 [inline]
     ipv6_rcv+0x683/0x710 net/ipv6/ip6_input.c:272
     __netif_receive_skb_one_core net/core/dev.c:4981 [inline]
     __netif_receive_skb net/core/dev.c:5095 [inline]
     process_backlog+0x721/0x1410 net/core/dev.c:5906
     napi_poll net/core/dev.c:6329 [inline]
     net_rx_action+0x738/0x1940 net/core/dev.c:6395
     __do_softirq+0x4ad/0x858 kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1052
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x199/0x1e0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:682 [inline]
     ip6_finish_output2+0x213f/0x2670 net/ipv6/ip6_output.c:117
     ip6_finish_output+0xae4/0xbc0 net/ipv6/ip6_output.c:150
     NF_HOOK_COND include/linux/netfilter.h:294 [inline]
     ip6_output+0x5d3/0x720 net/ipv6/ip6_output.c:167
     dst_output include/net/dst.h:433 [inline]
     NF_HOOK include/linux/netfilter.h:305 [inline]
     ip6_xmit+0x1f53/0x2650 net/ipv6/ip6_output.c:271
     inet6_csk_xmit+0x3df/0x4f0 net/ipv6/inet6_connection_sock.c:135
     __tcp_transmit_skb+0x4076/0x5b40 net/ipv4/tcp_output.c:1156
     tcp_transmit_skb net/ipv4/tcp_output.c:1172 [inline]
     tcp_write_xmit+0x39a9/0xa730 net/ipv4/tcp_output.c:2397
     __tcp_push_pending_frames+0x124/0x4e0 net/ipv4/tcp_output.c:2573
     tcp_send_fin+0xd43/0x1540 net/ipv4/tcp_output.c:3118
     tcp_close+0x16ba/0x1860 net/ipv4/tcp.c:2403
     inet_release+0x1f7/0x270 net/ipv4/af_inet.c:427
     inet6_release+0xaf/0x100 net/ipv6/af_inet6.c:470
     __sock_release net/socket.c:601 [inline]
     sock_close+0x156/0x490 net/socket.c:1273
     __fput+0x4c9/0xba0 fs/file_table.c:280
     ____fput+0x37/0x40 fs/file_table.c:313
     task_work_run+0x22e/0x2a0 kernel/task_work.c:113
     tracehook_notify_resume include/linux/tracehook.h:185 [inline]
     exit_to_usermode_loop arch/x86/entry/common.c:168 [inline]
     prepare_exit_to_usermode+0x39d/0x4d0 arch/x86/entry/common.c:199
     syscall_return_slowpath+0x90/0x5c0 arch/x86/entry/common.c:279
     do_syscall_64+0xe2/0xf0 arch/x86/entry/common.c:305
     entry_SYSCALL_64_after_hwframe+0x63/0xe7
    
    Fixes: 336c39a03151 ("tcp: undo init congestion window on false SYNACK timeout")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Yuchung Cheng <ycheng@google.com>
    Cc: Neal Cardwell <ncardwell@google.com>
    Cc: Soheil Hassas Yeganeh <soheil@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
    Acked-by: Yuchung Cheng <ycheng@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6a6ef5ee257eb178a5ada3b4327a9a208d3a4683
Author: Oak Zeng <Oak.Zeng@amd.com>
Date:   Fri Jun 14 20:10:45 2019 -0500

    drm/amdkfd: Fix a circular lock dependency
    
    The idea to break the circular lock dependency is to temporarily drop
    dqm lock before calling allocate_mqd. See callstack #1 below.
    
    [   59.510149] [drm] Initialized amdgpu 3.30.0 20150101 for 0000:04:00.0 on minor 0
    
    [  513.604034] ======================================================
    [  513.604205] WARNING: possible circular locking dependency detected
    [  513.604375] 4.18.0-kfd-root #2 Tainted: G        W
    [  513.604530] ------------------------------------------------------
    [  513.604699] kswapd0/611 is trying to acquire lock:
    [  513.604840] 00000000d254022e (&dqm->lock_hidden){+.+.}, at: evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.605150]
                   but task is already holding lock:
    [  513.605307] 00000000961547fc (&anon_vma->rwsem){++++}, at: page_lock_anon_vma_read+0xe4/0x250
    [  513.605540]
                   which lock already depends on the new lock.
    
    [  513.605747]
                   the existing dependency chain (in reverse order) is:
    [  513.605944]
                   -> #4 (&anon_vma->rwsem){++++}:
    [  513.606106]        __vma_adjust+0x147/0x7f0
    [  513.606231]        __split_vma+0x179/0x190
    [  513.606353]        mprotect_fixup+0x217/0x260
    [  513.606553]        do_mprotect_pkey+0x211/0x380
    [  513.606752]        __x64_sys_mprotect+0x1b/0x20
    [  513.606954]        do_syscall_64+0x50/0x1a0
    [  513.607149]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  513.607380]
                   -> #3 (&mapping->i_mmap_rwsem){++++}:
    [  513.607678]        rmap_walk_file+0x1f0/0x280
    [  513.607887]        page_referenced+0xdd/0x180
    [  513.608081]        shrink_page_list+0x853/0xcb0
    [  513.608279]        shrink_inactive_list+0x33b/0x700
    [  513.608483]        shrink_node_memcg+0x37a/0x7f0
    [  513.608682]        shrink_node+0xd8/0x490
    [  513.608869]        balance_pgdat+0x18b/0x3b0
    [  513.609062]        kswapd+0x203/0x5c0
    [  513.609241]        kthread+0x100/0x140
    [  513.609420]        ret_from_fork+0x24/0x30
    [  513.609607]
                   -> #2 (fs_reclaim){+.+.}:
    [  513.609883]        kmem_cache_alloc_trace+0x34/0x2e0
    [  513.610093]        reservation_object_reserve_shared+0x139/0x300
    [  513.610326]        ttm_bo_init_reserved+0x291/0x480 [ttm]
    [  513.610567]        amdgpu_bo_do_create+0x1d2/0x650 [amdgpu]
    [  513.610811]        amdgpu_bo_create+0x40/0x1f0 [amdgpu]
    [  513.611041]        amdgpu_bo_create_reserved+0x249/0x2d0 [amdgpu]
    [  513.611290]        amdgpu_bo_create_kernel+0x12/0x70 [amdgpu]
    [  513.611584]        amdgpu_ttm_init+0x2cb/0x560 [amdgpu]
    [  513.611823]        gmc_v9_0_sw_init+0x400/0x750 [amdgpu]
    [  513.612491]        amdgpu_device_init+0x14eb/0x1990 [amdgpu]
    [  513.612730]        amdgpu_driver_load_kms+0x78/0x290 [amdgpu]
    [  513.612958]        drm_dev_register+0x111/0x1a0
    [  513.613171]        amdgpu_pci_probe+0x11c/0x1e0 [amdgpu]
    [  513.613389]        local_pci_probe+0x3f/0x90
    [  513.613581]        pci_device_probe+0x102/0x1c0
    [  513.613779]        driver_probe_device+0x2a7/0x480
    [  513.613984]        __driver_attach+0x10a/0x110
    [  513.614179]        bus_for_each_dev+0x67/0xc0
    [  513.614372]        bus_add_driver+0x1eb/0x260
    [  513.614565]        driver_register+0x5b/0xe0
    [  513.614756]        do_one_initcall+0xac/0x357
    [  513.614952]        do_init_module+0x5b/0x213
    [  513.615145]        load_module+0x2542/0x2d30
    [  513.615337]        __do_sys_finit_module+0xd2/0x100
    [  513.615541]        do_syscall_64+0x50/0x1a0
    [  513.615731]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  513.615963]
                   -> #1 (reservation_ww_class_mutex){+.+.}:
    [  513.616293]        amdgpu_amdkfd_alloc_gtt_mem+0xcf/0x2c0 [amdgpu]
    [  513.616554]        init_mqd+0x223/0x260 [amdgpu]
    [  513.616779]        create_queue_nocpsch+0x4d9/0x600 [amdgpu]
    [  513.617031]        pqm_create_queue+0x37c/0x520 [amdgpu]
    [  513.617270]        kfd_ioctl_create_queue+0x2f9/0x650 [amdgpu]
    [  513.617522]        kfd_ioctl+0x202/0x350 [amdgpu]
    [  513.617724]        do_vfs_ioctl+0x9f/0x6c0
    [  513.617914]        ksys_ioctl+0x66/0x70
    [  513.618095]        __x64_sys_ioctl+0x16/0x20
    [  513.618286]        do_syscall_64+0x50/0x1a0
    [  513.618476]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  513.618695]
                   -> #0 (&dqm->lock_hidden){+.+.}:
    [  513.618984]        __mutex_lock+0x98/0x970
    [  513.619197]        evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.619459]        kfd_process_evict_queues+0x3b/0xb0 [amdgpu]
    [  513.619710]        kgd2kfd_quiesce_mm+0x1c/0x40 [amdgpu]
    [  513.620103]        amdgpu_amdkfd_evict_userptr+0x38/0x70 [amdgpu]
    [  513.620363]        amdgpu_mn_invalidate_range_start_hsa+0xa6/0xc0 [amdgpu]
    [  513.620614]        __mmu_notifier_invalidate_range_start+0x70/0xb0
    [  513.620851]        try_to_unmap_one+0x7fc/0x8f0
    [  513.621049]        rmap_walk_anon+0x121/0x290
    [  513.621242]        try_to_unmap+0x93/0xf0
    [  513.621428]        shrink_page_list+0x606/0xcb0
    [  513.621625]        shrink_inactive_list+0x33b/0x700
    [  513.621835]        shrink_node_memcg+0x37a/0x7f0
    [  513.622034]        shrink_node+0xd8/0x490
    [  513.622219]        balance_pgdat+0x18b/0x3b0
    [  513.622410]        kswapd+0x203/0x5c0
    [  513.622589]        kthread+0x100/0x140
    [  513.622769]        ret_from_fork+0x24/0x30
    [  513.622957]
                   other info that might help us debug this:
    
    [  513.623354] Chain exists of:
                     &dqm->lock_hidden --> &mapping->i_mmap_rwsem --> &anon_vma->rwsem
    
    [  513.623900]  Possible unsafe locking scenario:
    
    [  513.624189]        CPU0                    CPU1
    [  513.624397]        ----                    ----
    [  513.624594]   lock(&anon_vma->rwsem);
    [  513.624771]                                lock(&mapping->i_mmap_rwsem);
    [  513.625020]                                lock(&anon_vma->rwsem);
    [  513.625253]   lock(&dqm->lock_hidden);
    [  513.625433]
                    *** DEADLOCK ***
    
    [  513.625783] 3 locks held by kswapd0/611:
    [  513.625967]  #0: 00000000f14edf84 (fs_reclaim){+.+.}, at: __fs_reclaim_acquire+0x5/0x30
    [  513.626309]  #1: 00000000961547fc (&anon_vma->rwsem){++++}, at: page_lock_anon_vma_read+0xe4/0x250
    [  513.626671]  #2: 0000000067b5cd12 (srcu){....}, at: __mmu_notifier_invalidate_range_start+0x5/0xb0
    [  513.627037]
                   stack backtrace:
    [  513.627292] CPU: 0 PID: 611 Comm: kswapd0 Tainted: G        W         4.18.0-kfd-root #2
    [  513.627632] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
    [  513.627990] Call Trace:
    [  513.628143]  dump_stack+0x7c/0xbb
    [  513.628315]  print_circular_bug.isra.37+0x21b/0x228
    [  513.628581]  __lock_acquire+0xf7d/0x1470
    [  513.628782]  ? unwind_next_frame+0x6c/0x4f0
    [  513.628974]  ? lock_acquire+0xec/0x1e0
    [  513.629154]  lock_acquire+0xec/0x1e0
    [  513.629357]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.629587]  __mutex_lock+0x98/0x970
    [  513.629790]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630047]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630309]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630562]  evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630816]  kfd_process_evict_queues+0x3b/0xb0 [amdgpu]
    [  513.631057]  kgd2kfd_quiesce_mm+0x1c/0x40 [amdgpu]
    [  513.631288]  amdgpu_amdkfd_evict_userptr+0x38/0x70 [amdgpu]
    [  513.631536]  amdgpu_mn_invalidate_range_start_hsa+0xa6/0xc0 [amdgpu]
    [  513.632076]  __mmu_notifier_invalidate_range_start+0x70/0xb0
    [  513.632299]  try_to_unmap_one+0x7fc/0x8f0
    [  513.632487]  ? page_lock_anon_vma_read+0x68/0x250
    [  513.632690]  rmap_walk_anon+0x121/0x290
    [  513.632875]  try_to_unmap+0x93/0xf0
    [  513.633050]  ? page_remove_rmap+0x330/0x330
    [  513.633239]  ? rcu_read_unlock+0x60/0x60
    [  513.633422]  ? page_get_anon_vma+0x160/0x160
    [  513.633613]  shrink_page_list+0x606/0xcb0
    [  513.633800]  shrink_inactive_list+0x33b/0x700
    [  513.633997]  shrink_node_memcg+0x37a/0x7f0
    [  513.634186]  ? shrink_node+0xd8/0x490
    [  513.634363]  shrink_node+0xd8/0x490
    [  513.634537]  balance_pgdat+0x18b/0x3b0
    [  513.634718]  kswapd+0x203/0x5c0
    [  513.634887]  ? wait_woken+0xb0/0xb0
    [  513.635062]  kthread+0x100/0x140
    [  513.635231]  ? balance_pgdat+0x3b0/0x3b0
    [  513.635414]  ? kthread_delayed_work_timer_fn+0x80/0x80
    [  513.635626]  ret_from_fork+0x24/0x30
    [  513.636042] Evicting PASID 32768 queues
    [  513.936236] Restoring PASID 32768 queues
    [  524.708912] Evicting PASID 32768 queues
    [  524.999875] Restoring PASID 32768 queues
    
    Signed-off-by: Oak Zeng <Oak.Zeng@amd.com>
    Reviewed-by: Philip Yang <philip.yang@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

commit 06b89b38f3cc518a761164f9f958a9607bbb3587
Author: Oak Zeng <Oak.Zeng@amd.com>
Date:   Mon Jun 3 21:44:55 2019 -0500

    drm/amdkfd: Fix a circular lock dependency
    
    The idea to break the circular lock dependency is to move allocate_mqd
    out of dqm lock protection. See callstack #1 below.
    
    [   59.510149] [drm] Initialized amdgpu 3.30.0 20150101 for 0000:04:00.0 on minor 0
    
    [  513.604034] ======================================================
    [  513.604205] WARNING: possible circular locking dependency detected
    [  513.604375] 4.18.0-kfd-root #2 Tainted: G        W
    [  513.604530] ------------------------------------------------------
    [  513.604699] kswapd0/611 is trying to acquire lock:
    [  513.604840] 00000000d254022e (&dqm->lock_hidden){+.+.}, at: evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.605150]
                   but task is already holding lock:
    [  513.605307] 00000000961547fc (&anon_vma->rwsem){++++}, at: page_lock_anon_vma_read+0xe4/0x250
    [  513.605540]
                   which lock already depends on the new lock.
    
    [  513.605747]
                   the existing dependency chain (in reverse order) is:
    [  513.605944]
                   -> #4 (&anon_vma->rwsem){++++}:
    [  513.606106]        __vma_adjust+0x147/0x7f0
    [  513.606231]        __split_vma+0x179/0x190
    [  513.606353]        mprotect_fixup+0x217/0x260
    [  513.606553]        do_mprotect_pkey+0x211/0x380
    [  513.606752]        __x64_sys_mprotect+0x1b/0x20
    [  513.606954]        do_syscall_64+0x50/0x1a0
    [  513.607149]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  513.607380]
                   -> #3 (&mapping->i_mmap_rwsem){++++}:
    [  513.607678]        rmap_walk_file+0x1f0/0x280
    [  513.607887]        page_referenced+0xdd/0x180
    [  513.608081]        shrink_page_list+0x853/0xcb0
    [  513.608279]        shrink_inactive_list+0x33b/0x700
    [  513.608483]        shrink_node_memcg+0x37a/0x7f0
    [  513.608682]        shrink_node+0xd8/0x490
    [  513.608869]        balance_pgdat+0x18b/0x3b0
    [  513.609062]        kswapd+0x203/0x5c0
    [  513.609241]        kthread+0x100/0x140
    [  513.609420]        ret_from_fork+0x24/0x30
    [  513.609607]
                   -> #2 (fs_reclaim){+.+.}:
    [  513.609883]        kmem_cache_alloc_trace+0x34/0x2e0
    [  513.610093]        reservation_object_reserve_shared+0x139/0x300
    [  513.610326]        ttm_bo_init_reserved+0x291/0x480 [ttm]
    [  513.610567]        amdgpu_bo_do_create+0x1d2/0x650 [amdgpu]
    [  513.610811]        amdgpu_bo_create+0x40/0x1f0 [amdgpu]
    [  513.611041]        amdgpu_bo_create_reserved+0x249/0x2d0 [amdgpu]
    [  513.611290]        amdgpu_bo_create_kernel+0x12/0x70 [amdgpu]
    [  513.611584]        amdgpu_ttm_init+0x2cb/0x560 [amdgpu]
    [  513.611823]        gmc_v9_0_sw_init+0x400/0x750 [amdgpu]
    [  513.612491]        amdgpu_device_init+0x14eb/0x1990 [amdgpu]
    [  513.612730]        amdgpu_driver_load_kms+0x78/0x290 [amdgpu]
    [  513.612958]        drm_dev_register+0x111/0x1a0
    [  513.613171]        amdgpu_pci_probe+0x11c/0x1e0 [amdgpu]
    [  513.613389]        local_pci_probe+0x3f/0x90
    [  513.613581]        pci_device_probe+0x102/0x1c0
    [  513.613779]        driver_probe_device+0x2a7/0x480
    [  513.613984]        __driver_attach+0x10a/0x110
    [  513.614179]        bus_for_each_dev+0x67/0xc0
    [  513.614372]        bus_add_driver+0x1eb/0x260
    [  513.614565]        driver_register+0x5b/0xe0
    [  513.614756]        do_one_initcall+0xac/0x357
    [  513.614952]        do_init_module+0x5b/0x213
    [  513.615145]        load_module+0x2542/0x2d30
    [  513.615337]        __do_sys_finit_module+0xd2/0x100
    [  513.615541]        do_syscall_64+0x50/0x1a0
    [  513.615731]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  513.615963]
                   -> #1 (reservation_ww_class_mutex){+.+.}:
    [  513.616293]        amdgpu_amdkfd_alloc_gtt_mem+0xcf/0x2c0 [amdgpu]
    [  513.616554]        init_mqd+0x223/0x260 [amdgpu]
    [  513.616779]        create_queue_nocpsch+0x4d9/0x600 [amdgpu]
    [  513.617031]        pqm_create_queue+0x37c/0x520 [amdgpu]
    [  513.617270]        kfd_ioctl_create_queue+0x2f9/0x650 [amdgpu]
    [  513.617522]        kfd_ioctl+0x202/0x350 [amdgpu]
    [  513.617724]        do_vfs_ioctl+0x9f/0x6c0
    [  513.617914]        ksys_ioctl+0x66/0x70
    [  513.618095]        __x64_sys_ioctl+0x16/0x20
    [  513.618286]        do_syscall_64+0x50/0x1a0
    [  513.618476]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  513.618695]
                   -> #0 (&dqm->lock_hidden){+.+.}:
    [  513.618984]        __mutex_lock+0x98/0x970
    [  513.619197]        evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.619459]        kfd_process_evict_queues+0x3b/0xb0 [amdgpu]
    [  513.619710]        kgd2kfd_quiesce_mm+0x1c/0x40 [amdgpu]
    [  513.620103]        amdgpu_amdkfd_evict_userptr+0x38/0x70 [amdgpu]
    [  513.620363]        amdgpu_mn_invalidate_range_start_hsa+0xa6/0xc0 [amdgpu]
    [  513.620614]        __mmu_notifier_invalidate_range_start+0x70/0xb0
    [  513.620851]        try_to_unmap_one+0x7fc/0x8f0
    [  513.621049]        rmap_walk_anon+0x121/0x290
    [  513.621242]        try_to_unmap+0x93/0xf0
    [  513.621428]        shrink_page_list+0x606/0xcb0
    [  513.621625]        shrink_inactive_list+0x33b/0x700
    [  513.621835]        shrink_node_memcg+0x37a/0x7f0
    [  513.622034]        shrink_node+0xd8/0x490
    [  513.622219]        balance_pgdat+0x18b/0x3b0
    [  513.622410]        kswapd+0x203/0x5c0
    [  513.622589]        kthread+0x100/0x140
    [  513.622769]        ret_from_fork+0x24/0x30
    [  513.622957]
                   other info that might help us debug this:
    
    [  513.623354] Chain exists of:
                     &dqm->lock_hidden --> &mapping->i_mmap_rwsem --> &anon_vma->rwsem
    
    [  513.623900]  Possible unsafe locking scenario:
    
    [  513.624189]        CPU0                    CPU1
    [  513.624397]        ----                    ----
    [  513.624594]   lock(&anon_vma->rwsem);
    [  513.624771]                                lock(&mapping->i_mmap_rwsem);
    [  513.625020]                                lock(&anon_vma->rwsem);
    [  513.625253]   lock(&dqm->lock_hidden);
    [  513.625433]
                    *** DEADLOCK ***
    
    [  513.625783] 3 locks held by kswapd0/611:
    [  513.625967]  #0: 00000000f14edf84 (fs_reclaim){+.+.}, at: __fs_reclaim_acquire+0x5/0x30
    [  513.626309]  #1: 00000000961547fc (&anon_vma->rwsem){++++}, at: page_lock_anon_vma_read+0xe4/0x250
    [  513.626671]  #2: 0000000067b5cd12 (srcu){....}, at: __mmu_notifier_invalidate_range_start+0x5/0xb0
    [  513.627037]
                   stack backtrace:
    [  513.627292] CPU: 0 PID: 611 Comm: kswapd0 Tainted: G        W         4.18.0-kfd-root #2
    [  513.627632] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
    [  513.627990] Call Trace:
    [  513.628143]  dump_stack+0x7c/0xbb
    [  513.628315]  print_circular_bug.isra.37+0x21b/0x228
    [  513.628581]  __lock_acquire+0xf7d/0x1470
    [  513.628782]  ? unwind_next_frame+0x6c/0x4f0
    [  513.628974]  ? lock_acquire+0xec/0x1e0
    [  513.629154]  lock_acquire+0xec/0x1e0
    [  513.629357]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.629587]  __mutex_lock+0x98/0x970
    [  513.629790]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630047]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630309]  ? evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630562]  evict_process_queues_nocpsch+0x26/0x140 [amdgpu]
    [  513.630816]  kfd_process_evict_queues+0x3b/0xb0 [amdgpu]
    [  513.631057]  kgd2kfd_quiesce_mm+0x1c/0x40 [amdgpu]
    [  513.631288]  amdgpu_amdkfd_evict_userptr+0x38/0x70 [amdgpu]
    [  513.631536]  amdgpu_mn_invalidate_range_start_hsa+0xa6/0xc0 [amdgpu]
    [  513.632076]  __mmu_notifier_invalidate_range_start+0x70/0xb0
    [  513.632299]  try_to_unmap_one+0x7fc/0x8f0
    [  513.632487]  ? page_lock_anon_vma_read+0x68/0x250
    [  513.632690]  rmap_walk_anon+0x121/0x290
    [  513.632875]  try_to_unmap+0x93/0xf0
    [  513.633050]  ? page_remove_rmap+0x330/0x330
    [  513.633239]  ? rcu_read_unlock+0x60/0x60
    [  513.633422]  ? page_get_anon_vma+0x160/0x160
    [  513.633613]  shrink_page_list+0x606/0xcb0
    [  513.633800]  shrink_inactive_list+0x33b/0x700
    [  513.633997]  shrink_node_memcg+0x37a/0x7f0
    [  513.634186]  ? shrink_node+0xd8/0x490
    [  513.634363]  shrink_node+0xd8/0x490
    [  513.634537]  balance_pgdat+0x18b/0x3b0
    [  513.634718]  kswapd+0x203/0x5c0
    [  513.634887]  ? wait_woken+0xb0/0xb0
    [  513.635062]  kthread+0x100/0x140
    [  513.635231]  ? balance_pgdat+0x3b0/0x3b0
    [  513.635414]  ? kthread_delayed_work_timer_fn+0x80/0x80
    [  513.635626]  ret_from_fork+0x24/0x30
    [  513.636042] Evicting PASID 32768 queues
    [  513.936236] Restoring PASID 32768 queues
    [  524.708912] Evicting PASID 32768 queues
    [  524.999875] Restoring PASID 32768 queues
    
    Signed-off-by: Oak Zeng <Oak.Zeng@amd.com>
    Reviewed-by: Felix Kuehling <Felix.Kuehling@amd.com>
    Signed-off-by: Alex Deucher <alexander.deucher@amd.com>

commit 0fa88718cdc50d42a6f9191792d8eaede77bd293
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b50e058746ba29f517e27299447831ab3d93f896
Author: Zhu Yanjun <yanjun.zhu@oracle.com>
Date:   Mon Jun 3 08:48:19 2019 -0400

    net: rds: fix memory leak when unload rds_rdma
    
    When KASAN is enabled, after several rds connections are
    created, then "rmmod rds_rdma" is run. The following will
    appear.
    
    "
    BUG rds_ib_incoming (Not tainted): Objects remaining
    in rds_ib_incoming on __kmem_cache_shutdown()
    
    Call Trace:
     dump_stack+0x71/0xab
     slab_err+0xad/0xd0
     __kmem_cache_shutdown+0x17d/0x370
     shutdown_cache+0x17/0x130
     kmem_cache_destroy+0x1df/0x210
     rds_ib_recv_exit+0x11/0x20 [rds_rdma]
     rds_ib_exit+0x7a/0x90 [rds_rdma]
     __x64_sys_delete_module+0x224/0x2c0
     ? __ia32_sys_delete_module+0x2c0/0x2c0
     do_syscall_64+0x73/0x190
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    "
    This is rds connection memory leak. The root cause is:
    When "rmmod rds_rdma" is run, rds_ib_remove_one will call
    rds_ib_dev_shutdown to drop the rds connections.
    rds_ib_dev_shutdown will call rds_conn_drop to drop rds
    connections as below.
    "
    rds_conn_path_drop(&conn->c_path[0], false);
    "
    In the above, destroy is set to false.
    void rds_conn_path_drop(struct rds_conn_path *cp, bool destroy)
    {
            atomic_set(&cp->cp_state, RDS_CONN_ERROR);
    
            rcu_read_lock();
            if (!destroy && rds_destroy_pending(cp->cp_conn)) {
                    rcu_read_unlock();
                    return;
            }
            queue_work(rds_wq, &cp->cp_down_w);
            rcu_read_unlock();
    }
    In the above function, destroy is set to false. rds_destroy_pending
    is called. This does not move rds connections to ib_nodev_conns.
    So destroy is set to true to move rds connections to ib_nodev_conns.
    In rds_ib_unregister_client, flush_workqueue is called to make rds_wq
    finsh shutdown rds connections. The function rds_ib_destroy_nodev_conns
    is called to shutdown rds connections finally.
    Then rds_ib_recv_exit is called to destroy slab.
    
    void rds_ib_recv_exit(void)
    {
            kmem_cache_destroy(rds_ib_incoming_slab);
            kmem_cache_destroy(rds_ib_frag_slab);
    }
    The above slab memory leak will not occur again.
    
    >From tests,
    256 rds connections
    [root@ca-dev14 ~]# time rmmod rds_rdma
    
    real    0m16.522s
    user    0m0.000s
    sys     0m8.152s
    512 rds connections
    [root@ca-dev14 ~]# time rmmod rds_rdma
    
    real    0m32.054s
    user    0m0.000s
    sys     0m15.568s
    
    To rmmod rds_rdma with 256 rds connections, about 16 seconds are needed.
    And with 512 rds connections, about 32 seconds are needed.
    >From ftrace, when one rds connection is destroyed,
    
    "
     19)               |  rds_conn_destroy [rds]() {
     19)   7.782 us    |    rds_conn_path_drop [rds]();
     15)               |  rds_shutdown_worker [rds]() {
     15)               |    rds_conn_shutdown [rds]() {
     15)   1.651 us    |      rds_send_path_reset [rds]();
     15)   7.195 us    |    }
     15) + 11.434 us   |  }
     19)   2.285 us    |    rds_cong_remove_conn [rds]();
     19) * 24062.76 us |  }
    "
    So if many rds connections will be destroyed, this function
    rds_ib_destroy_nodev_conns uses most of time.
    
    Suggested-by: Hkon Bugge <haakon.bugge@oracle.com>
    Signed-off-by: Zhu Yanjun <yanjun.zhu@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 8852217434663c9e0cc39a409716e1d92b4080c2
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 763d209ec6fffbf508efdac6d53a8d3d84808adb
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 92f907d7d63b178da6d01a6870dea7831e6abf3e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 17faae8e22c66116c7d72cf4123b53ed3e3c574c
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ffd658adf684aa47b73229ab12b9adc8f4dc18f6
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    commit 0c713cbab6200b0ab6473b50435e450a6e1de85d upstream.
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c682db558e6eec10a711b0a6bcb8c35fd15f6a39
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Apr 19 07:38:27 2019 -0700

    rcutorture: Add trivial RCU implementation
    
    I have been showing off a trivial RCU implementation for non-preemptive
    environments for some time now:
    
            #define rcu_read_lock()
            #define rcu_read_unlock()
            #define rcu_dereference(p) READ_ONCE(p)
            #define rcu_assign_pointer(p, v) smp_store_release(&(p), (v))
            void synchronize_rcu(void)
            {
            int cpu;
                    for_each_online_cpu(cpu)
                            sched_setaffinity(current->pid, cpumask_of(cpu));
            }
    
    Trivial or not, as the old saying goes, "if it ain't tested, it don't
    work!".  This commit therefore adds a "trivial" flavor to rcutorture
    and a corresponding TRIVIAL test scenario.  This variant does not handle
    CPU hotplug, which is unconditionally enabled on x86 for post-v5.1-rc3
    kernels, which is why the TRIVIAL.boot says "rcutorture.onoff_interval=0".
    This commit actually does handle CONFIG_PREEMPT=y kernels, but only
    because it turns back the Linux-kernel clock in order to provide these
    alternative definitions (or the moral equivalent thereof):
    
            #define rcu_read_lock() preempt_disable()
            #define rcu_read_unlock() preempt_enable()
    
    In CONFIG_PREEMPT=n kernels without debugging, these are equivalent to
    empty macros give or take a compiler barrier.  However, the have been
    successfully tested with actual empty macros as well.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    [ paulmck: Fix symbol issue reported by kbuild test robot <lkp@intel.com>. ]
    [ paulmck: Work around sched_setaffinity() issue noted by Andrea Parri. ]
    [ paulmck: Add rcutorture.shuffle_interval=0 to TRIVIAL.boot to fix
      interaction with shuffler task noted by Peter Zijlstra. ]
    Tested-by: Andrea Parri <andrea.parri@amarulasolutions.com>

commit 0864f057b050bc6dd68106b3185e02db5140012d
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Thu Apr 4 12:19:25 2019 -0700

    rcu: Use irq_work to get scheduler's attention in clean context
    
    When rcu_read_unlock_special() is invoked with interrupts disabled, is
    either not in an interrupt handler or is not using RCU_SOFTIRQ, is not
    the first RCU read-side critical section in the chain, and either there
    is an expedited grace period in flight or this is a NO_HZ_FULL kernel,
    the end of the grace period can be unduly delayed.  The reason for this
    is that it is not safe to do wakeups in this situation.
    
    This commit fixes this problem by using the irq_work subsystem to
    force a later interrupt handler in a clean environment.  Because
    set_tsk_need_resched(current) and set_preempt_need_resched() are
    invoked prior to this, the scheduler will force a context switch
    upon return from this interrupt (though perhaps at the end of any
    interrupted preempt-disable or BH-disable region of code), which will
    invoke rcu_note_context_switch() (again in a clean environment), which
    will in turn give RCU the chance to report the deferred quiescent state.
    
    Of course, by then this task might be within another RCU read-side
    critical section.  But that will be detected at that time and reporting
    will be further deferred to the outermost rcu_read_unlock().  See
    rcu_preempt_need_deferred_qs() and rcu_preempt_deferred_qs() for more
    details on the checking.
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 385b599e8c04fa843c4d7f785478827cc512d720
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Mon Apr 1 15:12:47 2019 -0700

    rcu: Allow rcu_read_unlock_special() to raise_softirq() if in_irq()
    
    When running in an interrupt handler, raise_softirq() and
    raise_softirq_irqoff() have extremely low overhead: They simply set a
    bit in a per-CPU mask, which is checked upon exit from that interrupt
    handler.  Therefore, if rcu_read_unlock_special() is invoked within an
    interrupt handler and RCU_SOFTIRQ is in use, this commit make use of
    raise_softirq_irqoff() even if there is no expedited grace period in
    flight and even if this is not a nohz_full CPU.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 25102de65fdd246eb6801114ce6dfa3a076bb678
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Mon Apr 1 14:12:50 2019 -0700

    rcu: Only do rcu_read_unlock_special() wakeups if expedited
    
    Currently, rcu_read_unlock_special() will do wakeups whenever it is safe
    to do so.  However, wakeups are expensive, and they are only really
    needed when the just-ended RCU read-side critical section is blocking
    an expedited grace period (in which case speed is of the essence)
    or on a nohz_full CPU (where it might be a good long time before an
    interrupt arrives).  This commit therefore checks for these conditions,
    and does the expensive wakeups only if doing so would be useful.
    
    Note it can be rather expensive to determine whether or not the current
    task (as opposed to the current CPU) is blocking the current expedited
    grace period.  Doing so requires traversing the ->blkd_tasks list, which
    can be quite long.  This commit therefore cheats:  If the current task
    is on a given ->blkd_tasks list, and some task on that list is blocking
    the current expedited grace period, the code assumes that the current
    task is blocking that expedited grace period.
    
    Reported-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 23634ebc1d946f19eb112d4455c1d84948875e31
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Sun Mar 24 15:25:51 2019 -0700

    rcu: Check for wakeup-safe conditions in rcu_read_unlock_special()
    
    When RCU core processing is offloaded from RCU_SOFTIRQ to the rcuc
    kthreads, a full and unconditional wakeup is required to initiate RCU
    core processing.  In contrast, when RCU core processing is carried
    out by RCU_SOFTIRQ, a raise_softirq() suffices.  Of course, there are
    situations where raise_softirq() does a full wakeup, but these do not
    occur with normal usage of rcu_read_unlock().
    
    The reason that full wakeups can be problematic is that the scheduler
    sometimes invokes rcu_read_unlock() with its pi or rq locks held,
    which can of course result in deadlock in CONFIG_PREEMPT=y kernels when
    rcu_read_unlock() invokes the scheduler.  Scheduler invocations can happen
    in the following situations: (1) The just-ended reader has been subjected
    to RCU priority boosting, in which case rcu_read_unlock() must deboost,
    (2) Interrupts were disabled across the call to rcu_read_unlock(), so
    the quiescent state must be deferred, requiring a wakeup of the rcuc
    kthread corresponding to the current CPU.
    
    Now, the scheduler may hold one of its locks across rcu_read_unlock()
    only if preemption has been disabled across the entire RCU read-side
    critical section, which in the days prior to RCU flavor consolidation
    meant that rcu_read_unlock() never needed to do wakeups.  However, this
    is no longer the case for any but the first rcu_read_unlock() following a
    condition (e.g., preempted RCU reader) requiring special rcu_read_unlock()
    attention.  For example, an RCU read-side critical section might be
    preempted, but preemption might be disabled across the rcu_read_unlock().
    The rcu_read_unlock() must defer the quiescent state, and therefore
    leaves the task queued on its leaf rcu_node structure.  If a scheduler
    interrupt occurs, the scheduler might well invoke rcu_read_unlock() with
    one of its locks held.  However, the preempted task is still queued, so
    rcu_read_unlock() will attempt to defer the quiescent state once more.
    When RCU core processing is carried out by RCU_SOFTIRQ, this works just
    fine: The raise_softirq() function simply sets a bit in a per-CPU mask
    and the RCU core processing will be undertaken upon return from interrupt.
    
    Not so when RCU core processing is carried out by the rcuc kthread: In this
    case, the required wakeup can result in deadlock.
    
    The initial solution to this problem was to use set_tsk_need_resched() and
    set_preempt_need_resched() to force a future context switch, which allows
    rcu_preempt_note_context_switch() to report the deferred quiescent state
    to RCU's core processing.  Unfortunately for expedited grace periods,
    there can be a significant delay between the call for a context switch
    and the actual context switch.
    
    This commit therefore introduces a ->deferred_qs flag to the task_struct
    structure's rcu_special structure.  This flag is initially false, and
    is set to true by the first call to rcu_read_unlock() requiring special
    attention, then finally reset back to false when the quiescent state is
    finally reported.  Then rcu_read_unlock() attempts full wakeups only when
    ->deferred_qs is false, that is, on the first rcu_read_unlock() requiring
    special attention.  Note that a chain of RCU readers linked by some other
    sort of reader may find that a later rcu_read_unlock() is once again able
    to do a full wakeup, courtesy of an intervening preemption:
    
            rcu_read_lock();
            /* preempted */
            local_irq_disable();
            rcu_read_unlock(); /* Can do full wakeup, sets ->deferred_qs. */
            rcu_read_lock();
            local_irq_enable();
            preempt_disable()
            rcu_read_unlock(); /* Cannot do full wakeup, ->deferred_qs set. */
            rcu_read_lock();
            preempt_enable();
            /* preempted, >deferred_qs reset. */
            local_irq_disable();
            rcu_read_unlock(); /* Can again do full wakeup, sets ->deferred_qs. */
    
    Such linked RCU readers do not yet seem to appear in the Linux kernel, and
    it is probably best if they don't.  However, RCU needs to handle them, and
    some variations on this theme could make even raise_softirq() unsafe due to
    the possibility of its doing a full wakeup.  This commit therefore also
    avoids invoking raise_softirq() when the ->deferred_qs set flag is set.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>

commit 48d07c04b4cc1dc1221965312f58fd84926212fe
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Mar 20 22:13:33 2019 +0100

    rcu: Enable elimination of Tree-RCU softirq processing
    
    Some workloads need to change kthread priority for RCU core processing
    without affecting other softirq work.  This commit therefore introduces
    the rcutree.use_softirq kernel boot parameter, which moves the RCU core
    work from softirq to a per-CPU SCHED_OTHER kthread named rcuc.  Use of
    SCHED_OTHER approach avoids the scalability problems that appeared
    with the earlier attempt to move RCU core processing to from softirq
    to kthreads.  That said, kernels built with RCU_BOOST=y will run the
    rcuc kthreads at the RCU-boosting priority.
    
    Note that rcutree.use_softirq=0 must be specified to move RCU core
    processing to the rcuc kthreads: rcutree.use_softirq=1 is the default.
    
    Reported-by: Thomas Gleixner <tglx@linutronix.de>
    Tested-by: Mike Galbraith <efault@gmx.de>
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    [ paulmck: Adjust for invoke_rcu_callbacks() only ever being invoked
      from RCU core processing, in contrast to softirq->rcuc transition
      in old mainline RCU priority boosting. ]
    [ paulmck: Avoid wakeups when scheduler might have invoked rcu_read_unlock()
      while holding rq or pi locks, also possibly fixing a pre-existing latent
      bug involving raise_softirq()-induced wakeups. ]
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 0c713cbab6200b0ab6473b50435e450a6e1de85d
Author: Filipe Manana <fdmanana@suse.com>
Date:   Mon May 6 16:44:02 2019 +0100

    Btrfs: fix race between ranged fsync and writeback of adjacent ranges
    
    When we do a full fsync (the bit BTRFS_INODE_NEEDS_FULL_SYNC is set in the
    inode) that happens to be ranged, which happens during a msync() or writes
    for files opened with O_SYNC for example, we can end up with a corrupt log,
    due to different file extent items representing ranges that overlap with
    each other, or hit some assertion failures.
    
    When doing a ranged fsync we only flush delalloc and wait for ordered
    exents within that range. If while we are logging items from our inode
    ordered extents for adjacent ranges complete, we end up in a race that can
    make us insert the file extent items that overlap with others we logged
    previously and the assertion failures.
    
    For example, if tree-log.c:copy_items() receives a leaf that has the
    following file extents items, all with a length of 4K and therefore there
    is an implicit hole in the range 68K to 72K - 1:
    
      (257 EXTENT_ITEM 64K), (257 EXTENT_ITEM 72K), (257 EXTENT_ITEM 76K), ...
    
    It copies them to the log tree. However due to the need to detect implicit
    holes, it may release the path, in order to look at the previous leaf to
    detect an implicit hole, and then later it will search again in the tree
    for the first file extent item key, with the goal of locking again the
    leaf (which might have changed due to concurrent changes to other inodes).
    
    However when it locks again the leaf containing the first key, the key
    corresponding to the extent at offset 72K may not be there anymore since
    there is an ordered extent for that range that is finishing (that is,
    somewhere in the middle of btrfs_finish_ordered_io()), and it just
    removed the file extent item but has not yet replaced it with a new file
    extent item, so the part of copy_items() that does hole detection will
    decide that there is a hole in the range starting from 68K to 76K - 1,
    and therefore insert a file extent item to represent that hole, having
    a key offset of 68K. After that we now have a log tree with 2 different
    extent items that have overlapping ranges:
    
     1) The file extent item copied before copy_items() released the path,
        which has a key offset of 72K and a length of 4K, representing the
        file range 72K to 76K - 1.
    
     2) And a file extent item representing a hole that has a key offset of
        68K and a length of 8K, representing the range 68K to 76K - 1. This
        item was inserted after releasing the path, and overlaps with the
        extent item inserted before.
    
    The overlapping extent items can cause all sorts of unpredictable and
    incorrect behaviour, either when replayed or if a fast (non full) fsync
    happens later, which can trigger a BUG_ON() when calling
    btrfs_set_item_key_safe() through __btrfs_drop_extents(), producing a
    trace like the following:
    
      [61666.783269] ------------[ cut here ]------------
      [61666.783943] kernel BUG at fs/btrfs/ctree.c:3182!
      [61666.784644] invalid opcode: 0000 [#1] PREEMPT SMP
      (...)
      [61666.786253] task: ffff880117b88c40 task.stack: ffffc90008168000
      [61666.786253] RIP: 0010:btrfs_set_item_key_safe+0x7c/0xd2 [btrfs]
      [61666.786253] RSP: 0018:ffffc9000816b958 EFLAGS: 00010246
      [61666.786253] RAX: 0000000000000000 RBX: 000000000000000f RCX: 0000000000030000
      [61666.786253] RDX: 0000000000000000 RSI: ffffc9000816ba4f RDI: ffffc9000816b937
      [61666.786253] RBP: ffffc9000816b998 R08: ffff88011dae2428 R09: 0000000000001000
      [61666.786253] R10: 0000160000000000 R11: 6db6db6db6db6db7 R12: ffff88011dae2418
      [61666.786253] R13: ffffc9000816ba4f R14: ffff8801e10c4118 R15: ffff8801e715c000
      [61666.786253] FS:  00007f6060a18700(0000) GS:ffff88023f5c0000(0000) knlGS:0000000000000000
      [61666.786253] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [61666.786253] CR2: 00007f6060a28000 CR3: 0000000213e69000 CR4: 00000000000006e0
      [61666.786253] Call Trace:
      [61666.786253]  __btrfs_drop_extents+0x5e3/0xaad [btrfs]
      [61666.786253]  ? time_hardirqs_on+0x9/0x14
      [61666.786253]  btrfs_log_changed_extents+0x294/0x4e0 [btrfs]
      [61666.786253]  ? release_extent_buffer+0x38/0xb4 [btrfs]
      [61666.786253]  btrfs_log_inode+0xb6e/0xcdc [btrfs]
      [61666.786253]  ? lock_acquire+0x131/0x1c5
      [61666.786253]  ? btrfs_log_inode_parent+0xee/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? btrfs_log_inode_parent+0x1f5/0x659 [btrfs]
      [61666.786253]  btrfs_log_inode_parent+0x223/0x659 [btrfs]
      [61666.786253]  ? arch_local_irq_save+0x9/0xc
      [61666.786253]  ? lockref_get_not_zero+0x2c/0x34
      [61666.786253]  ? rcu_read_unlock+0x3e/0x5d
      [61666.786253]  btrfs_log_dentry_safe+0x60/0x7b [btrfs]
      [61666.786253]  btrfs_sync_file+0x317/0x42c [btrfs]
      [61666.786253]  vfs_fsync_range+0x8c/0x9e
      [61666.786253]  SyS_msync+0x13c/0x1c9
      [61666.786253]  entry_SYSCALL_64_fastpath+0x18/0xad
    
    A sample of a corrupt log tree leaf with overlapping extents I got from
    running btrfs/072:
    
          item 14 key (295 108 200704) itemoff 2599 itemsize 53
                  extent data disk bytenr 0 nr 0
                  extent data offset 0 nr 458752 ram 458752
          item 15 key (295 108 659456) itemoff 2546 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 606208 nr 163840 ram 770048
          item 16 key (295 108 663552) itemoff 2493 itemsize 53
                  extent data disk bytenr 4343541760 nr 770048
                  extent data offset 610304 nr 155648 ram 770048
          item 17 key (295 108 819200) itemoff 2440 itemsize 53
                  extent data disk bytenr 4334788608 nr 4096
                  extent data offset 0 nr 4096 ram 4096
    
    The file extent item at offset 659456 (item 15) ends at offset 823296
    (659456 + 163840) while the next file extent item (item 16) starts at
    offset 663552.
    
    Another different problem that the race can trigger is a failure in the
    assertions at tree-log.c:copy_items(), which expect that the first file
    extent item key we found before releasing the path exists after we have
    released path and that the last key we found before releasing the path
    also exists after releasing the path:
    
      $ cat -n fs/btrfs/tree-log.c
      4080          if (need_find_last_extent) {
      4081                  /* btrfs_prev_leaf could return 1 without releasing the path */
      4082                  btrfs_release_path(src_path);
      4083                  ret = btrfs_search_slot(NULL, inode->root, &first_key,
      4084                                  src_path, 0, 0);
      4085                  if (ret < 0)
      4086                          return ret;
      4087                  ASSERT(ret == 0);
      (...)
      4103                  if (i >= btrfs_header_nritems(src_path->nodes[0])) {
      4104                          ret = btrfs_next_leaf(inode->root, src_path);
      4105                          if (ret < 0)
      4106                                  return ret;
      4107                          ASSERT(ret == 0);
      4108                          src = src_path->nodes[0];
      4109                          i = 0;
      4110                          need_find_last_extent = true;
      4111                  }
      (...)
    
    The second assertion implicitly expects that the last key before the path
    release still exists, because the surrounding while loop only stops after
    we have found that key. When this assertion fails it produces a stack like
    this:
    
      [139590.037075] assertion failed: ret == 0, file: fs/btrfs/tree-log.c, line: 4107
      [139590.037406] ------------[ cut here ]------------
      [139590.037707] kernel BUG at fs/btrfs/ctree.h:3546!
      [139590.038034] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC PTI
      [139590.038340] CPU: 1 PID: 31841 Comm: fsstress Tainted: G        W         5.0.0-btrfs-next-46 #1
      (...)
      [139590.039354] RIP: 0010:assfail.constprop.24+0x18/0x1a [btrfs]
      (...)
      [139590.040397] RSP: 0018:ffffa27f48f2b9b0 EFLAGS: 00010282
      [139590.040730] RAX: 0000000000000041 RBX: ffff897c635d92c8 RCX: 0000000000000000
      [139590.041105] RDX: 0000000000000000 RSI: ffff897d36a96868 RDI: ffff897d36a96868
      [139590.041470] RBP: ffff897d1b9a0708 R08: 0000000000000000 R09: 0000000000000000
      [139590.041815] R10: 0000000000000008 R11: 0000000000000000 R12: 0000000000000013
      [139590.042159] R13: 0000000000000227 R14: ffff897cffcbba88 R15: 0000000000000001
      [139590.042501] FS:  00007f2efc8dee80(0000) GS:ffff897d36a80000(0000) knlGS:0000000000000000
      [139590.042847] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [139590.043199] CR2: 00007f8c064935e0 CR3: 0000000232252002 CR4: 00000000003606e0
      [139590.043547] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
      [139590.043899] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
      [139590.044250] Call Trace:
      [139590.044631]  copy_items+0xa3f/0x1000 [btrfs]
      [139590.045009]  ? generic_bin_search.constprop.32+0x61/0x200 [btrfs]
      [139590.045396]  btrfs_log_inode+0x7b3/0xd70 [btrfs]
      [139590.045773]  btrfs_log_inode_parent+0x2b3/0xce0 [btrfs]
      [139590.046143]  ? do_raw_spin_unlock+0x49/0xc0
      [139590.046510]  btrfs_log_dentry_safe+0x4a/0x70 [btrfs]
      [139590.046872]  btrfs_sync_file+0x3b6/0x440 [btrfs]
      [139590.047243]  btrfs_file_write_iter+0x45b/0x5c0 [btrfs]
      [139590.047592]  __vfs_write+0x129/0x1c0
      [139590.047932]  vfs_write+0xc2/0x1b0
      [139590.048270]  ksys_write+0x55/0xc0
      [139590.048608]  do_syscall_64+0x60/0x1b0
      [139590.048946]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
      [139590.049287] RIP: 0033:0x7f2efc4be190
      (...)
      [139590.050342] RSP: 002b:00007ffe743243a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000001
      [139590.050701] RAX: ffffffffffffffda RBX: 0000000000008d58 RCX: 00007f2efc4be190
      [139590.051067] RDX: 0000000000008d58 RSI: 00005567eca0f370 RDI: 0000000000000003
      [139590.051459] RBP: 0000000000000024 R08: 0000000000000003 R09: 0000000000008d60
      [139590.051863] R10: 0000000000000078 R11: 0000000000000246 R12: 0000000000000003
      [139590.052252] R13: 00000000003d3507 R14: 00005567eca0f370 R15: 0000000000000000
      (...)
      [139590.055128] ---[ end trace 193f35d0215cdeeb ]---
    
    So fix this race between a full ranged fsync and writeback of adjacent
    ranges by flushing all delalloc and waiting for all ordered extents to
    complete before logging the inode. This is the simplest way to solve the
    problem because currently the full fsync path does not deal with ranges
    at all (it assumes a full range from 0 to LLONG_MAX) and it always needs
    to look at adjacent ranges for hole detection. For use cases of ranged
    fsyncs this can make a few fsyncs slower but on the other hand it can
    make some following fsyncs to other ranges do less work or no need to do
    anything at all. A full fsync is rare anyway and happens only once after
    loading/creating an inode and once after less common operations such as a
    shrinking truncate.
    
    This is an issue that exists for a long time, and was often triggered by
    generic/127, because it does mmap'ed writes and msync (which triggers a
    ranged fsync). Adding support for the tree checker to detect overlapping
    extents (next patch in the series) and trigger a WARN() when such cases
    are found, and then calling btrfs_check_leaf_full() at the end of
    btrfs_insert_file_extent() made the issue much easier to detect. Running
    btrfs/072 with that change to the tree checker and making fsstress open
    files always with O_SYNC made it much easier to trigger the issue (as
    triggering it with generic/127 is very rare).
    
    CC: stable@vger.kernel.org # 3.16+
    Reviewed-by: Josef Bacik <josef@toxicpanda.com>
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit 3d11671070042b3525c2495eb4c5956e16afd0ec
Author: Julia Cartwright <julia@ni.com>
Date:   Wed Feb 20 16:46:31 2019 +0000

    iommu/dmar: Fix buffer overflow during PCI bus notification
    
    [ Upstream commit cffaaf0c816238c45cd2d06913476c83eb50f682 ]
    
    Commit 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI
    device path") changed the type of the path data, however, the change in
    path type was not reflected in size calculations.  Update to use the
    correct type and prevent a buffer overflow.
    
    This bug manifests in systems with deep PCI hierarchies, and can lead to
    an overflow of the static allocated buffer (dmar_pci_notify_info_buf),
    or can lead to overflow of slab-allocated data.
    
       BUG: KASAN: global-out-of-bounds in dmar_alloc_pci_notify_info+0x1d5/0x2e0
       Write of size 1 at addr ffffffff90445d80 by task swapper/0/1
       CPU: 0 PID: 1 Comm: swapper/0 Tainted: G        W       4.14.87-rt49-02406-gd0a0e96 #1
       Call Trace:
        ? dump_stack+0x46/0x59
        ? print_address_description+0x1df/0x290
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? kasan_report+0x256/0x340
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? e820__memblock_setup+0xb0/0xb0
        ? dmar_dev_scope_init+0x424/0x48f
        ? __down_write_common+0x1ec/0x230
        ? dmar_dev_scope_init+0x48f/0x48f
        ? dmar_free_unused_resources+0x109/0x109
        ? cpumask_next+0x16/0x20
        ? __kmem_cache_create+0x392/0x430
        ? kmem_cache_create+0x135/0x2f0
        ? e820__memblock_setup+0xb0/0xb0
        ? intel_iommu_init+0x170/0x1848
        ? _raw_spin_unlock_irqrestore+0x32/0x60
        ? migrate_enable+0x27a/0x5b0
        ? sched_setattr+0x20/0x20
        ? migrate_disable+0x1fc/0x380
        ? task_rq_lock+0x170/0x170
        ? try_to_run_init_process+0x40/0x40
        ? locks_remove_file+0x85/0x2f0
        ? dev_prepare_static_identity_mapping+0x78/0x78
        ? rt_spin_unlock+0x39/0x50
        ? lockref_put_or_lock+0x2a/0x40
        ? dput+0x128/0x2f0
        ? __rcu_read_unlock+0x66/0x80
        ? __fput+0x250/0x300
        ? __rcu_read_lock+0x1b/0x30
        ? mntput_no_expire+0x38/0x290
        ? e820__memblock_setup+0xb0/0xb0
        ? pci_iommu_init+0x25/0x63
        ? pci_iommu_init+0x25/0x63
        ? do_one_initcall+0x7e/0x1c0
        ? initcall_blacklisted+0x120/0x120
        ? kernel_init_freeable+0x27b/0x307
        ? rest_init+0xd0/0xd0
        ? kernel_init+0xf/0x120
        ? rest_init+0xd0/0xd0
        ? ret_from_fork+0x1f/0x40
       The buggy address belongs to the variable:
        dmar_pci_notify_info_buf+0x40/0x60
    
    Fixes: 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI device path")
    Signed-off-by: Julia Cartwright <julia@ni.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 88f8bbd24dfeb87442fb5be6aa9dad575021a5f4
Author: Julia Cartwright <julia@ni.com>
Date:   Wed Feb 20 16:46:31 2019 +0000

    iommu/dmar: Fix buffer overflow during PCI bus notification
    
    [ Upstream commit cffaaf0c816238c45cd2d06913476c83eb50f682 ]
    
    Commit 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI
    device path") changed the type of the path data, however, the change in
    path type was not reflected in size calculations.  Update to use the
    correct type and prevent a buffer overflow.
    
    This bug manifests in systems with deep PCI hierarchies, and can lead to
    an overflow of the static allocated buffer (dmar_pci_notify_info_buf),
    or can lead to overflow of slab-allocated data.
    
       BUG: KASAN: global-out-of-bounds in dmar_alloc_pci_notify_info+0x1d5/0x2e0
       Write of size 1 at addr ffffffff90445d80 by task swapper/0/1
       CPU: 0 PID: 1 Comm: swapper/0 Tainted: G        W       4.14.87-rt49-02406-gd0a0e96 #1
       Call Trace:
        ? dump_stack+0x46/0x59
        ? print_address_description+0x1df/0x290
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? kasan_report+0x256/0x340
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? e820__memblock_setup+0xb0/0xb0
        ? dmar_dev_scope_init+0x424/0x48f
        ? __down_write_common+0x1ec/0x230
        ? dmar_dev_scope_init+0x48f/0x48f
        ? dmar_free_unused_resources+0x109/0x109
        ? cpumask_next+0x16/0x20
        ? __kmem_cache_create+0x392/0x430
        ? kmem_cache_create+0x135/0x2f0
        ? e820__memblock_setup+0xb0/0xb0
        ? intel_iommu_init+0x170/0x1848
        ? _raw_spin_unlock_irqrestore+0x32/0x60
        ? migrate_enable+0x27a/0x5b0
        ? sched_setattr+0x20/0x20
        ? migrate_disable+0x1fc/0x380
        ? task_rq_lock+0x170/0x170
        ? try_to_run_init_process+0x40/0x40
        ? locks_remove_file+0x85/0x2f0
        ? dev_prepare_static_identity_mapping+0x78/0x78
        ? rt_spin_unlock+0x39/0x50
        ? lockref_put_or_lock+0x2a/0x40
        ? dput+0x128/0x2f0
        ? __rcu_read_unlock+0x66/0x80
        ? __fput+0x250/0x300
        ? __rcu_read_lock+0x1b/0x30
        ? mntput_no_expire+0x38/0x290
        ? e820__memblock_setup+0xb0/0xb0
        ? pci_iommu_init+0x25/0x63
        ? pci_iommu_init+0x25/0x63
        ? do_one_initcall+0x7e/0x1c0
        ? initcall_blacklisted+0x120/0x120
        ? kernel_init_freeable+0x27b/0x307
        ? rest_init+0xd0/0xd0
        ? kernel_init+0xf/0x120
        ? rest_init+0xd0/0xd0
        ? ret_from_fork+0x1f/0x40
       The buggy address belongs to the variable:
        dmar_pci_notify_info_buf+0x40/0x60
    
    Fixes: 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI device path")
    Signed-off-by: Julia Cartwright <julia@ni.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0e58156d700ac45fd5f0f90698a13233b1fe4c44
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Apr 24 17:21:40 2019 -0700

    tipc: remove rcu_read_unlock() left in tipc_udp_recv()
    
    I forgot to remove one rcu_read_unlock() before a return statement.
    
    Joy of mixing goto and return styles in a function :)
    
    Fixes: 4109a2c3b91e ("tipc: tipc_udp_recv() cleanup vs rcu verbs")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: kbuild test robot <lkp@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4109a2c3b91e5f38e401fc4ea56848e65e429785
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Apr 23 09:24:46 2019 -0700

    tipc: tipc_udp_recv() cleanup vs rcu verbs
    
    First thing tipc_udp_recv() does is to use rcu_dereference_sk_user_data(),
    and this is really hinting we already own rcu_read_lock() from the caller
    (UDP stack).
    
    No need to add another rcu_read_lock()/rcu_read_unlock() pair.
    
    Also use rcu_dereference() instead of rcu_dereference_rtnl()
    in the data path.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Jon Maloy <jon.maloy@ericsson.com>
    Cc: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 38855a84d891d835eb91f96e6594f886b593bdc3
Author: Julia Cartwright <julia@ni.com>
Date:   Wed Feb 20 16:46:31 2019 +0000

    iommu/dmar: Fix buffer overflow during PCI bus notification
    
    [ Upstream commit cffaaf0c816238c45cd2d06913476c83eb50f682 ]
    
    Commit 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI
    device path") changed the type of the path data, however, the change in
    path type was not reflected in size calculations.  Update to use the
    correct type and prevent a buffer overflow.
    
    This bug manifests in systems with deep PCI hierarchies, and can lead to
    an overflow of the static allocated buffer (dmar_pci_notify_info_buf),
    or can lead to overflow of slab-allocated data.
    
       BUG: KASAN: global-out-of-bounds in dmar_alloc_pci_notify_info+0x1d5/0x2e0
       Write of size 1 at addr ffffffff90445d80 by task swapper/0/1
       CPU: 0 PID: 1 Comm: swapper/0 Tainted: G        W       4.14.87-rt49-02406-gd0a0e96 #1
       Call Trace:
        ? dump_stack+0x46/0x59
        ? print_address_description+0x1df/0x290
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? kasan_report+0x256/0x340
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? e820__memblock_setup+0xb0/0xb0
        ? dmar_dev_scope_init+0x424/0x48f
        ? __down_write_common+0x1ec/0x230
        ? dmar_dev_scope_init+0x48f/0x48f
        ? dmar_free_unused_resources+0x109/0x109
        ? cpumask_next+0x16/0x20
        ? __kmem_cache_create+0x392/0x430
        ? kmem_cache_create+0x135/0x2f0
        ? e820__memblock_setup+0xb0/0xb0
        ? intel_iommu_init+0x170/0x1848
        ? _raw_spin_unlock_irqrestore+0x32/0x60
        ? migrate_enable+0x27a/0x5b0
        ? sched_setattr+0x20/0x20
        ? migrate_disable+0x1fc/0x380
        ? task_rq_lock+0x170/0x170
        ? try_to_run_init_process+0x40/0x40
        ? locks_remove_file+0x85/0x2f0
        ? dev_prepare_static_identity_mapping+0x78/0x78
        ? rt_spin_unlock+0x39/0x50
        ? lockref_put_or_lock+0x2a/0x40
        ? dput+0x128/0x2f0
        ? __rcu_read_unlock+0x66/0x80
        ? __fput+0x250/0x300
        ? __rcu_read_lock+0x1b/0x30
        ? mntput_no_expire+0x38/0x290
        ? e820__memblock_setup+0xb0/0xb0
        ? pci_iommu_init+0x25/0x63
        ? pci_iommu_init+0x25/0x63
        ? do_one_initcall+0x7e/0x1c0
        ? initcall_blacklisted+0x120/0x120
        ? kernel_init_freeable+0x27b/0x307
        ? rest_init+0xd0/0xd0
        ? kernel_init+0xf/0x120
        ? rest_init+0xd0/0xd0
        ? ret_from_fork+0x1f/0x40
       The buggy address belongs to the variable:
        dmar_pci_notify_info_buf+0x40/0x60
    
    Fixes: 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI device path")
    Signed-off-by: Julia Cartwright <julia@ni.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e2f0e69fd9969b9940c3d8c48316dbc5ec16dd99
Author: Julia Cartwright <julia@ni.com>
Date:   Wed Feb 20 16:46:31 2019 +0000

    iommu/dmar: Fix buffer overflow during PCI bus notification
    
    [ Upstream commit cffaaf0c816238c45cd2d06913476c83eb50f682 ]
    
    Commit 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI
    device path") changed the type of the path data, however, the change in
    path type was not reflected in size calculations.  Update to use the
    correct type and prevent a buffer overflow.
    
    This bug manifests in systems with deep PCI hierarchies, and can lead to
    an overflow of the static allocated buffer (dmar_pci_notify_info_buf),
    or can lead to overflow of slab-allocated data.
    
       BUG: KASAN: global-out-of-bounds in dmar_alloc_pci_notify_info+0x1d5/0x2e0
       Write of size 1 at addr ffffffff90445d80 by task swapper/0/1
       CPU: 0 PID: 1 Comm: swapper/0 Tainted: G        W       4.14.87-rt49-02406-gd0a0e96 #1
       Call Trace:
        ? dump_stack+0x46/0x59
        ? print_address_description+0x1df/0x290
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? kasan_report+0x256/0x340
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? e820__memblock_setup+0xb0/0xb0
        ? dmar_dev_scope_init+0x424/0x48f
        ? __down_write_common+0x1ec/0x230
        ? dmar_dev_scope_init+0x48f/0x48f
        ? dmar_free_unused_resources+0x109/0x109
        ? cpumask_next+0x16/0x20
        ? __kmem_cache_create+0x392/0x430
        ? kmem_cache_create+0x135/0x2f0
        ? e820__memblock_setup+0xb0/0xb0
        ? intel_iommu_init+0x170/0x1848
        ? _raw_spin_unlock_irqrestore+0x32/0x60
        ? migrate_enable+0x27a/0x5b0
        ? sched_setattr+0x20/0x20
        ? migrate_disable+0x1fc/0x380
        ? task_rq_lock+0x170/0x170
        ? try_to_run_init_process+0x40/0x40
        ? locks_remove_file+0x85/0x2f0
        ? dev_prepare_static_identity_mapping+0x78/0x78
        ? rt_spin_unlock+0x39/0x50
        ? lockref_put_or_lock+0x2a/0x40
        ? dput+0x128/0x2f0
        ? __rcu_read_unlock+0x66/0x80
        ? __fput+0x250/0x300
        ? __rcu_read_lock+0x1b/0x30
        ? mntput_no_expire+0x38/0x290
        ? e820__memblock_setup+0xb0/0xb0
        ? pci_iommu_init+0x25/0x63
        ? pci_iommu_init+0x25/0x63
        ? do_one_initcall+0x7e/0x1c0
        ? initcall_blacklisted+0x120/0x120
        ? kernel_init_freeable+0x27b/0x307
        ? rest_init+0xd0/0xd0
        ? kernel_init+0xf/0x120
        ? rest_init+0xd0/0xd0
        ? ret_from_fork+0x1f/0x40
       The buggy address belongs to the variable:
        dmar_pci_notify_info_buf+0x40/0x60
    
    Fixes: 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI device path")
    Signed-off-by: Julia Cartwright <julia@ni.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0afa6d86e036e9de1db8d9a5236529e149b4fccf
Author: Julia Cartwright <julia@ni.com>
Date:   Wed Feb 20 16:46:31 2019 +0000

    iommu/dmar: Fix buffer overflow during PCI bus notification
    
    [ Upstream commit cffaaf0c816238c45cd2d06913476c83eb50f682 ]
    
    Commit 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI
    device path") changed the type of the path data, however, the change in
    path type was not reflected in size calculations.  Update to use the
    correct type and prevent a buffer overflow.
    
    This bug manifests in systems with deep PCI hierarchies, and can lead to
    an overflow of the static allocated buffer (dmar_pci_notify_info_buf),
    or can lead to overflow of slab-allocated data.
    
       BUG: KASAN: global-out-of-bounds in dmar_alloc_pci_notify_info+0x1d5/0x2e0
       Write of size 1 at addr ffffffff90445d80 by task swapper/0/1
       CPU: 0 PID: 1 Comm: swapper/0 Tainted: G        W       4.14.87-rt49-02406-gd0a0e96 #1
       Call Trace:
        ? dump_stack+0x46/0x59
        ? print_address_description+0x1df/0x290
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? kasan_report+0x256/0x340
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? e820__memblock_setup+0xb0/0xb0
        ? dmar_dev_scope_init+0x424/0x48f
        ? __down_write_common+0x1ec/0x230
        ? dmar_dev_scope_init+0x48f/0x48f
        ? dmar_free_unused_resources+0x109/0x109
        ? cpumask_next+0x16/0x20
        ? __kmem_cache_create+0x392/0x430
        ? kmem_cache_create+0x135/0x2f0
        ? e820__memblock_setup+0xb0/0xb0
        ? intel_iommu_init+0x170/0x1848
        ? _raw_spin_unlock_irqrestore+0x32/0x60
        ? migrate_enable+0x27a/0x5b0
        ? sched_setattr+0x20/0x20
        ? migrate_disable+0x1fc/0x380
        ? task_rq_lock+0x170/0x170
        ? try_to_run_init_process+0x40/0x40
        ? locks_remove_file+0x85/0x2f0
        ? dev_prepare_static_identity_mapping+0x78/0x78
        ? rt_spin_unlock+0x39/0x50
        ? lockref_put_or_lock+0x2a/0x40
        ? dput+0x128/0x2f0
        ? __rcu_read_unlock+0x66/0x80
        ? __fput+0x250/0x300
        ? __rcu_read_lock+0x1b/0x30
        ? mntput_no_expire+0x38/0x290
        ? e820__memblock_setup+0xb0/0xb0
        ? pci_iommu_init+0x25/0x63
        ? pci_iommu_init+0x25/0x63
        ? do_one_initcall+0x7e/0x1c0
        ? initcall_blacklisted+0x120/0x120
        ? kernel_init_freeable+0x27b/0x307
        ? rest_init+0xd0/0xd0
        ? kernel_init+0xf/0x120
        ? rest_init+0xd0/0xd0
        ? ret_from_fork+0x1f/0x40
       The buggy address belongs to the variable:
        dmar_pci_notify_info_buf+0x40/0x60
    
    Fixes: 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI device path")
    Signed-off-by: Julia Cartwright <julia@ni.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 540f120998dff8c22e4a5ff734732f4550f2765b
Author: Vadim Pasternak <vadimp@mellanox.com>
Date:   Sun Feb 17 18:15:30 2019 +0000

    platform/mellanox: mlxreg-hotplug: Fix KASAN warning
    
    [ Upstream commit e4c275f77624961b56cce397814d9d770a45ac59 ]
    
    Fix the following KASAN warning produced when booting a 64-bit kernel:
    [   13.334750] BUG: KASAN: stack-out-of-bounds in find_first_bit+0x19/0x70
    [   13.342166] Read of size 8 at addr ffff880235067178 by task kworker/2:1/42
    [   13.342176] CPU: 2 PID: 42 Comm: kworker/2:1 Not tainted 4.20.0-rc1+ #106
    [   13.342179] Hardware name: Mellanox Technologies Ltd. MSN2740/Mellanox x86 SFF board, BIOS 5.6.5 06/07/2016
    [   13.342190] Workqueue: events deferred_probe_work_func
    [   13.342194] Call Trace:
    [   13.342206]  dump_stack+0xc7/0x15b
    [   13.342214]  ? show_regs_print_info+0x5/0x5
    [   13.342220]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [   13.342234]  ? _raw_write_lock_irqsave+0x100/0x100
    [   13.351593]  print_address_description+0x73/0x260
    [   13.351603]  kasan_report+0x260/0x380
    [   13.351611]  ? find_first_bit+0x19/0x70
    [   13.351619]  find_first_bit+0x19/0x70
    [   13.351630]  mlxreg_hotplug_work_handler+0x73c/0x920 [mlxreg_hotplug]
    [   13.351639]  ? __lock_text_start+0x8/0x8
    [   13.351646]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351656]  ? mlxreg_hotplug_remove+0x1e0/0x1e0 [mlxreg_hotplug]
    [   13.351663]  ? regmap_volatile+0x40/0xb0
    [   13.351668]  ? regcache_write+0x4c/0x90
    [   13.351676]  ? mlxplat_mlxcpld_reg_write+0x24/0x30 [mlx_platform]
    [   13.351681]  ? _regmap_write+0xea/0x220
    [   13.351688]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351696]  ? devm_add_action+0x70/0x70
    [   13.351701]  ? mutex_unlock+0x1d/0x40
    [   13.351710]  mlxreg_hotplug_probe+0x82e/0x989 [mlxreg_hotplug]
    [   13.351723]  ? mlxreg_hotplug_work_handler+0x920/0x920 [mlxreg_hotplug]
    [   13.351731]  ? sysfs_do_create_link_sd.isra.2+0xf4/0x190
    [   13.351737]  ? sysfs_rename_link_ns+0xf0/0xf0
    [   13.351743]  ? devres_close_group+0x2b0/0x2b0
    [   13.351749]  ? pinctrl_put+0x20/0x20
    [   13.351755]  ? acpi_dev_pm_attach+0x2c/0xd0
    [   13.351763]  platform_drv_probe+0x70/0xd0
    [   13.351771]  really_probe+0x480/0x6e0
    [   13.351778]  ? device_attach+0x10/0x10
    [   13.351784]  ? __lock_text_start+0x8/0x8
    [   13.351790]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351797]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351806]  ? __driver_attach+0x190/0x190
    [   13.351812]  driver_probe_device+0x17d/0x1a0
    [   13.351819]  ? __driver_attach+0x190/0x190
    [   13.351825]  bus_for_each_drv+0xd6/0x130
    [   13.351831]  ? bus_rescan_devices+0x20/0x20
    [   13.351837]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351845]  __device_attach+0x18c/0x230
    [   13.351852]  ? device_bind_driver+0x70/0x70
    [   13.351859]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351866]  bus_probe_device+0xea/0x110
    [   13.351874]  deferred_probe_work_func+0x1c9/0x290
    [   13.351882]  ? driver_deferred_probe_add+0x1d0/0x1d0
    [   13.351889]  ? preempt_notifier_dec+0x20/0x20
    [   13.351897]  ? read_word_at_a_time+0xe/0x20
    [   13.351904]  ? strscpy+0x151/0x290
    [   13.351912]  ? set_work_pool_and_clear_pending+0x9c/0xf0
    [   13.351918]  ? __switch_to_asm+0x34/0x70
    [   13.351924]  ? __switch_to_asm+0x40/0x70
    [   13.351929]  ? __switch_to_asm+0x34/0x70
    [   13.351935]  ? __switch_to_asm+0x40/0x70
    [   13.351942]  process_one_work+0x5cc/0xa00
    [   13.351952]  ? pwq_dec_nr_in_flight+0x1e0/0x1e0
    [   13.351960]  ? pci_mmcfg_check_reserved+0x80/0xb8
    [   13.351967]  ? run_rebalance_domains+0x250/0x250
    [   13.351980]  ? stack_access_ok+0x35/0x80
    [   13.351986]  ? deref_stack_reg+0xa1/0xe0
    [   13.351994]  ? schedule+0xcd/0x250
    [   13.352000]  ? worker_enter_idle+0x2d6/0x330
    [   13.352006]  ? __schedule+0xeb0/0xeb0
    [   13.352014]  ? fork_usermode_blob+0x130/0x130
    [   13.352019]  ? mutex_lock+0xa7/0x100
    [   13.352026]  ? _raw_spin_lock_irq+0x98/0xf0
    [   13.352032]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   13.352037] i2c i2c-2: Added multiplexed i2c bus 11
    [   13.352043]  worker_thread+0x181/0xa80
    [   13.352052]  ? __switch_to_asm+0x34/0x70
    [   13.352058]  ? __switch_to_asm+0x40/0x70
    [   13.352064]  ? process_one_work+0xa00/0xa00
    [   13.352070]  ? __switch_to_asm+0x34/0x70
    [   13.352076]  ? __switch_to_asm+0x40/0x70
    [   13.352081]  ? __switch_to_asm+0x34/0x70
    [   13.352086]  ? __switch_to_asm+0x40/0x70
    [   13.352092]  ? __switch_to_asm+0x34/0x70
    [   13.352097]  ? __switch_to_asm+0x40/0x70
    [   13.352105]  ? __schedule+0x3d6/0xeb0
    [   13.352112]  ? migrate_swap_stop+0x470/0x470
    [   13.352119]  ? save_stack+0x89/0xb0
    [   13.352127]  ? kmem_cache_alloc_trace+0xe5/0x570
    [   13.352132]  ? kthread+0x59/0x1d0
    [   13.352138]  ? ret_from_fork+0x35/0x40
    [   13.352154]  ? __schedule+0xeb0/0xeb0
    [   13.352161]  ? remove_wait_queue+0x150/0x150
    [   13.352169]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.352175]  ? __lock_text_start+0x8/0x8
    [   13.352183]  ? process_one_work+0xa00/0xa00
    [   13.352188]  kthread+0x1a4/0x1d0
    [   13.352195]  ? kthread_create_worker_on_cpu+0xc0/0xc0
    [   13.352202]  ret_from_fork+0x35/0x40
    
    [   13.353879] The buggy address belongs to the page:
    [   13.353885] page:ffffea0008d419c0 count:0 mapcount:0 mapping:0000000000000000 index:0x0
    [   13.353890] flags: 0x2ffff8000000000()
    [   13.353897] raw: 02ffff8000000000 ffffea0008d419c8 ffffea0008d419c8 0000000000000000
    [   13.353903] raw: 0000000000000000 0000000000000000 00000000ffffffff 0000000000000000
    [   13.353905] page dumped because: kasan: bad access detected
    
    [   13.353908] Memory state around the buggy address:
    [   13.353912]  ffff880235067000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   13.353917]  ffff880235067080: 00 00 00 00 00 00 00 00 00 00 00 f1 f1 f1 f1 04
    [   13.353921] >ffff880235067100: f2 f2 f2 f2 f2 f2 f2 04 f2 f2 f2 f2 f2 f2 f2 04
    [   13.353923]                                                                 ^
    [   13.353927]  ffff880235067180: f2 f2 f2 f2 f2 f2 f2 04 f2 f2 f2 00 00 00 00 00
    [   13.353931]  ffff880235067200: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   13.353933] ==================================================================
    
    The warning is caused by the below loop:
            for_each_set_bit(bit, (unsigned long *)&asserted, 8) {
    while "asserted" is declared as 'unsigned'.
    
    The casting of 32-bit unsigned integer pointer to a 64-bit unsigned long
    pointer. There are two problems here.
    It causes the access of four extra byte, which can corrupt memory
    The 32-bit pointer address may not be 64-bit aligned.
    
    The fix changes variable "asserted" to "unsigned long".
    
    Fixes: 1f976f6978bf ("platform/x86: Move Mellanox platform hotplug driver to platform/mellanox")
    Signed-off-by: Vadim Pasternak <vadimp@mellanox.com>
    Signed-off-by: Darren Hart (VMware) <dvhart@infradead.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 07a31820b241fff43a9ad5619db8c663f13dd6c0
Author: Vadim Pasternak <vadimp@mellanox.com>
Date:   Sun Feb 17 18:15:30 2019 +0000

    platform/mellanox: mlxreg-hotplug: Fix KASAN warning
    
    [ Upstream commit e4c275f77624961b56cce397814d9d770a45ac59 ]
    
    Fix the following KASAN warning produced when booting a 64-bit kernel:
    [   13.334750] BUG: KASAN: stack-out-of-bounds in find_first_bit+0x19/0x70
    [   13.342166] Read of size 8 at addr ffff880235067178 by task kworker/2:1/42
    [   13.342176] CPU: 2 PID: 42 Comm: kworker/2:1 Not tainted 4.20.0-rc1+ #106
    [   13.342179] Hardware name: Mellanox Technologies Ltd. MSN2740/Mellanox x86 SFF board, BIOS 5.6.5 06/07/2016
    [   13.342190] Workqueue: events deferred_probe_work_func
    [   13.342194] Call Trace:
    [   13.342206]  dump_stack+0xc7/0x15b
    [   13.342214]  ? show_regs_print_info+0x5/0x5
    [   13.342220]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [   13.342234]  ? _raw_write_lock_irqsave+0x100/0x100
    [   13.351593]  print_address_description+0x73/0x260
    [   13.351603]  kasan_report+0x260/0x380
    [   13.351611]  ? find_first_bit+0x19/0x70
    [   13.351619]  find_first_bit+0x19/0x70
    [   13.351630]  mlxreg_hotplug_work_handler+0x73c/0x920 [mlxreg_hotplug]
    [   13.351639]  ? __lock_text_start+0x8/0x8
    [   13.351646]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351656]  ? mlxreg_hotplug_remove+0x1e0/0x1e0 [mlxreg_hotplug]
    [   13.351663]  ? regmap_volatile+0x40/0xb0
    [   13.351668]  ? regcache_write+0x4c/0x90
    [   13.351676]  ? mlxplat_mlxcpld_reg_write+0x24/0x30 [mlx_platform]
    [   13.351681]  ? _regmap_write+0xea/0x220
    [   13.351688]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351696]  ? devm_add_action+0x70/0x70
    [   13.351701]  ? mutex_unlock+0x1d/0x40
    [   13.351710]  mlxreg_hotplug_probe+0x82e/0x989 [mlxreg_hotplug]
    [   13.351723]  ? mlxreg_hotplug_work_handler+0x920/0x920 [mlxreg_hotplug]
    [   13.351731]  ? sysfs_do_create_link_sd.isra.2+0xf4/0x190
    [   13.351737]  ? sysfs_rename_link_ns+0xf0/0xf0
    [   13.351743]  ? devres_close_group+0x2b0/0x2b0
    [   13.351749]  ? pinctrl_put+0x20/0x20
    [   13.351755]  ? acpi_dev_pm_attach+0x2c/0xd0
    [   13.351763]  platform_drv_probe+0x70/0xd0
    [   13.351771]  really_probe+0x480/0x6e0
    [   13.351778]  ? device_attach+0x10/0x10
    [   13.351784]  ? __lock_text_start+0x8/0x8
    [   13.351790]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351797]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351806]  ? __driver_attach+0x190/0x190
    [   13.351812]  driver_probe_device+0x17d/0x1a0
    [   13.351819]  ? __driver_attach+0x190/0x190
    [   13.351825]  bus_for_each_drv+0xd6/0x130
    [   13.351831]  ? bus_rescan_devices+0x20/0x20
    [   13.351837]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351845]  __device_attach+0x18c/0x230
    [   13.351852]  ? device_bind_driver+0x70/0x70
    [   13.351859]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351866]  bus_probe_device+0xea/0x110
    [   13.351874]  deferred_probe_work_func+0x1c9/0x290
    [   13.351882]  ? driver_deferred_probe_add+0x1d0/0x1d0
    [   13.351889]  ? preempt_notifier_dec+0x20/0x20
    [   13.351897]  ? read_word_at_a_time+0xe/0x20
    [   13.351904]  ? strscpy+0x151/0x290
    [   13.351912]  ? set_work_pool_and_clear_pending+0x9c/0xf0
    [   13.351918]  ? __switch_to_asm+0x34/0x70
    [   13.351924]  ? __switch_to_asm+0x40/0x70
    [   13.351929]  ? __switch_to_asm+0x34/0x70
    [   13.351935]  ? __switch_to_asm+0x40/0x70
    [   13.351942]  process_one_work+0x5cc/0xa00
    [   13.351952]  ? pwq_dec_nr_in_flight+0x1e0/0x1e0
    [   13.351960]  ? pci_mmcfg_check_reserved+0x80/0xb8
    [   13.351967]  ? run_rebalance_domains+0x250/0x250
    [   13.351980]  ? stack_access_ok+0x35/0x80
    [   13.351986]  ? deref_stack_reg+0xa1/0xe0
    [   13.351994]  ? schedule+0xcd/0x250
    [   13.352000]  ? worker_enter_idle+0x2d6/0x330
    [   13.352006]  ? __schedule+0xeb0/0xeb0
    [   13.352014]  ? fork_usermode_blob+0x130/0x130
    [   13.352019]  ? mutex_lock+0xa7/0x100
    [   13.352026]  ? _raw_spin_lock_irq+0x98/0xf0
    [   13.352032]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   13.352037] i2c i2c-2: Added multiplexed i2c bus 11
    [   13.352043]  worker_thread+0x181/0xa80
    [   13.352052]  ? __switch_to_asm+0x34/0x70
    [   13.352058]  ? __switch_to_asm+0x40/0x70
    [   13.352064]  ? process_one_work+0xa00/0xa00
    [   13.352070]  ? __switch_to_asm+0x34/0x70
    [   13.352076]  ? __switch_to_asm+0x40/0x70
    [   13.352081]  ? __switch_to_asm+0x34/0x70
    [   13.352086]  ? __switch_to_asm+0x40/0x70
    [   13.352092]  ? __switch_to_asm+0x34/0x70
    [   13.352097]  ? __switch_to_asm+0x40/0x70
    [   13.352105]  ? __schedule+0x3d6/0xeb0
    [   13.352112]  ? migrate_swap_stop+0x470/0x470
    [   13.352119]  ? save_stack+0x89/0xb0
    [   13.352127]  ? kmem_cache_alloc_trace+0xe5/0x570
    [   13.352132]  ? kthread+0x59/0x1d0
    [   13.352138]  ? ret_from_fork+0x35/0x40
    [   13.352154]  ? __schedule+0xeb0/0xeb0
    [   13.352161]  ? remove_wait_queue+0x150/0x150
    [   13.352169]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.352175]  ? __lock_text_start+0x8/0x8
    [   13.352183]  ? process_one_work+0xa00/0xa00
    [   13.352188]  kthread+0x1a4/0x1d0
    [   13.352195]  ? kthread_create_worker_on_cpu+0xc0/0xc0
    [   13.352202]  ret_from_fork+0x35/0x40
    
    [   13.353879] The buggy address belongs to the page:
    [   13.353885] page:ffffea0008d419c0 count:0 mapcount:0 mapping:0000000000000000 index:0x0
    [   13.353890] flags: 0x2ffff8000000000()
    [   13.353897] raw: 02ffff8000000000 ffffea0008d419c8 ffffea0008d419c8 0000000000000000
    [   13.353903] raw: 0000000000000000 0000000000000000 00000000ffffffff 0000000000000000
    [   13.353905] page dumped because: kasan: bad access detected
    
    [   13.353908] Memory state around the buggy address:
    [   13.353912]  ffff880235067000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   13.353917]  ffff880235067080: 00 00 00 00 00 00 00 00 00 00 00 f1 f1 f1 f1 04
    [   13.353921] >ffff880235067100: f2 f2 f2 f2 f2 f2 f2 04 f2 f2 f2 f2 f2 f2 f2 04
    [   13.353923]                                                                 ^
    [   13.353927]  ffff880235067180: f2 f2 f2 f2 f2 f2 f2 04 f2 f2 f2 00 00 00 00 00
    [   13.353931]  ffff880235067200: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   13.353933] ==================================================================
    
    The warning is caused by the below loop:
            for_each_set_bit(bit, (unsigned long *)&asserted, 8) {
    while "asserted" is declared as 'unsigned'.
    
    The casting of 32-bit unsigned integer pointer to a 64-bit unsigned long
    pointer. There are two problems here.
    It causes the access of four extra byte, which can corrupt memory
    The 32-bit pointer address may not be 64-bit aligned.
    
    The fix changes variable "asserted" to "unsigned long".
    
    Fixes: 1f976f6978bf ("platform/x86: Move Mellanox platform hotplug driver to platform/mellanox")
    Signed-off-by: Vadim Pasternak <vadimp@mellanox.com>
    Signed-off-by: Darren Hart (VMware) <dvhart@infradead.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 9765097ba2ab822c42bbac9f955ab9e2d99f7e46
Author: Christoffer Dall <christoffer.dall@arm.com>
Date:   Tue Dec 11 13:23:57 2018 +0100

    KVM: arm/arm64: Fix VMID alloc race by reverting to lock-less
    
    commit fb544d1ca65a89f7a3895f7531221ceeed74ada7 upstream.
    
    We recently addressed a VMID generation race by introducing a read/write
    lock around accesses and updates to the vmid generation values.
    
    However, kvm_arch_vcpu_ioctl_run() also calls need_new_vmid_gen() but
    does so without taking the read lock.
    
    As far as I can tell, this can lead to the same kind of race:
    
      VM 0, VCPU 0                  VM 0, VCPU 1
      ------------                  ------------
      update_vttbr (vmid 254)
                                    update_vttbr (vmid 1) // roll over
                                    read_lock(kvm_vmid_lock);
                                    force_vm_exit()
      local_irq_disable
      need_new_vmid_gen == false //because vmid gen matches
    
      enter_guest (vmid 254)
                                    kvm_arch.vttbr = <PGD>:<VMID 1>
                                    read_unlock(kvm_vmid_lock);
    
                                    enter_guest (vmid 1)
    
    Which results in running two VCPUs in the same VM with different VMIDs
    and (even worse) other VCPUs from other VMs could now allocate clashing
    VMID 254 from the new generation as long as VCPU 0 is not exiting.
    
    Attempt to solve this by making sure vttbr is updated before another CPU
    can observe the updated VMID generation.
    
    Fixes: f0cf47d939d0 "KVM: arm/arm64: Close VMID generation race"
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    [bwh: Backported to 3.16:
     - Use ACCESS_ONCE() instead of {READ,WRITE}_ONCE()
     - Adjust filename]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit bb06073a9cad930f5c8bb5f433dcd478c26608dd
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 16 13:09:53 2019 -0700

    tun: add a missing rcu_read_unlock() in error path
    
    commit 9180bb4f046064dfa4541488102703b402bb04e1 upstream.
    
    In my latest patch I missed one rcu_read_unlock(), in case
    device is down.
    
    Fixes: 4477138fa0ae ("tun: properly test for IFF_UP")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e044d21c2999d35c26cc15011e6478e2a9eaee63
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 16 13:09:53 2019 -0700

    tun: add a missing rcu_read_unlock() in error path
    
    commit 9180bb4f046064dfa4541488102703b402bb04e1 upstream.
    
    In my latest patch I missed one rcu_read_unlock(), in case
    device is down.
    
    Fixes: 4477138fa0ae ("tun: properly test for IFF_UP")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6caa2c1036293ef8571f5263b0fb247d81fb19f4
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 16 13:09:53 2019 -0700

    tun: add a missing rcu_read_unlock() in error path
    
    commit 9180bb4f046064dfa4541488102703b402bb04e1 upstream.
    
    In my latest patch I missed one rcu_read_unlock(), in case
    device is down.
    
    Fixes: 4477138fa0ae ("tun: properly test for IFF_UP")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7b5f260ff73f28143fff4b22aa7067d9a6b22aa4
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 16 13:09:53 2019 -0700

    tun: add a missing rcu_read_unlock() in error path
    
    commit 9180bb4f046064dfa4541488102703b402bb04e1 upstream.
    
    In my latest patch I missed one rcu_read_unlock(), in case
    device is down.
    
    Fixes: 4477138fa0ae ("tun: properly test for IFF_UP")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit add0d37b4f1e77de7d170ece43c8d765572a1eab
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Tue Mar 26 10:22:22 2019 -0700

    rcu: Correct READ_ONCE()/WRITE_ONCE() for ->rcu_read_unlock_special
    
    The task_struct structure's ->rcu_read_unlock_special field is only ever
    read or written by the owning task, but it is accessed both at process
    and interrupt levels.  It may therefore be accessed using plain reads
    and writes while interrupts are disabled, but must be accessed using
    READ_ONCE() and WRITE_ONCE() or better otherwise.  This commit makes a
    few adjustments to align with this discipline.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 884157cef0acf05648fe921d80c680afababb428
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Mon Feb 11 07:21:29 2019 -0800

    rcu: Make exit_rcu() handle non-preempted RCU readers
    
    The purpose of exit_rcu() is to handle cases where buggy code causes a
    task to exit within an RCU read-side critical section.  It currently
    does that in the case where said RCU read-side critical section was
    preempted at least once, but fails to handle cases where preemption did
    not occur.  This case needs to be handled because otherwise the final
    context switch away from the exiting task will incorrectly behave as if
    task exit were instead a preemption of an RCU read-side critical section,
    and will therefore queue the exiting task.  The exiting task will have
    exited, and thus won't ever execute rcu_read_unlock(), which means that
    it will remain queued forever, blocking all subsequent grace periods,
    and eventually resulting in OOM.
    
    Although this is arguably better than letting grace periods proceed
    and having a later rcu_read_unlock() access the now-freed task
    structure that once belonged to the exiting tasks, it would obviously
    be better to correctly handle this case.  This commit therefore sets
    ->rcu_read_lock_nesting to 1 in that case, so that the subsequence call
    to __rcu_read_unlock() causes the exiting task to exit its dangling RCU
    read-side critical section.
    
    Note that deferred quiescent states need not be considered.  The reason
    is that removing the task from the ->blkd_tasks[] list in the call to
    rcu_preempt_deferred_qs() handles the per-task component of any deferred
    quiescent state, and all other components of any deferred quiescent state
    are associated with the CPU, which isn't going anywhere until some later
    CPU-hotplug operation, which will report any remaining deferred quiescent
    states from within the rcu_report_dead() function.
    
    Note also that negative values of ->rcu_read_lock_nesting need not be
    considered.  First, these won't show up in exit_rcu() unless there is
    a serious bug in RCU, and second, setting ->rcu_read_lock_nesting sets
    the state so that the RCU read-side critical section will be exited
    normally.
    
    Again, this code has no effect unless there has been some prior bug
    that prevents a task from leaving an RCU read-side critical section
    before exiting.  Furthermore, there have been no reports of the bug
    fixed by this commit appearing in production.  This commit is therefore
    absolutely -not- recommended for backporting to -stable.
    
    Reported-by: ABHISHEK DUBEY <dabhishek@iisc.ac.in>
    Reported-by: BHARATH Y MOURYA <bharathm@iisc.ac.in>
    Reported-by: Aravinda Prasad <aravinda@iisc.ac.in>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Tested-by: ABHISHEK DUBEY <dabhishek@iisc.ac.in>

commit 8f07d76481d575ec684ac583c2dc9be5c878149b
Author: Sylwester Nawrocki <s.nawrocki@samsung.com>
Date:   Thu Feb 7 15:20:41 2019 +0100

    ASoC: samsung: Prevent clk_get_rate() calls in atomic context
    
    [ Upstream commit 860b454c2c0cbda6892954f5cdbbb48931b3c8db ]
    
    This patch moves clk_get_rate() call from trigger() to hw_params()
    callback to avoid calling sleeping clk API from atomic context
    and prevent deadlock as indicated below.
    
    Before this change clk_get_rate() was being called with same
    spinlock held as the one passed to the clk API when registering
    clocks exposed by the I2S driver.
    
    [   82.109780] BUG: sleeping function called from invalid context at kernel/locking/mutex.c:908
    [   82.117009] in_atomic(): 1, irqs_disabled(): 128, pid: 1554, name: speaker-test
    [   82.124235] 3 locks held by speaker-test/1554:
    [   82.128653]  #0: cc8c5328 (snd_pcm_link_rwlock){...-}, at: snd_pcm_stream_lock_irq+0x20/0x38
    [   82.137058]  #1: ec9eda17 (&(&substream->self_group.lock)->rlock){..-.}, at: snd_pcm_ioctl+0x900/0x1268
    [   82.146417]  #2: 6ac279bf (&(&pri_dai->spinlock)->rlock){..-.}, at: i2s_trigger+0x64/0x6d4
    [   82.154650] irq event stamp: 8144
    [   82.157949] hardirqs last  enabled at (8143): [<c0a0f574>] _raw_read_unlock_irq+0x24/0x5c
    [   82.166089] hardirqs last disabled at (8144): [<c0a0f6a8>] _raw_read_lock_irq+0x18/0x58
    [   82.174063] softirqs last  enabled at (8004): [<c01024e4>] __do_softirq+0x3a4/0x66c
    [   82.181688] softirqs last disabled at (7997): [<c012d730>] irq_exit+0x140/0x168
    [   82.188964] Preemption disabled at:
    [   82.188967] [<00000000>]   (null)
    [   82.195728] CPU: 6 PID: 1554 Comm: speaker-test Not tainted 5.0.0-rc5-00192-ga6e6caca8f03 #191
    [   82.204302] Hardware name: SAMSUNG EXYNOS (Flattened Device Tree)
    [   82.210376] [<c0111a54>] (unwind_backtrace) from [<c010d8f4>] (show_stack+0x10/0x14)
    [   82.218084] [<c010d8f4>] (show_stack) from [<c09ef004>] (dump_stack+0x90/0xc8)
    [   82.225278] [<c09ef004>] (dump_stack) from [<c0152980>] (___might_sleep+0x22c/0x2c8)
    [   82.232990] [<c0152980>] (___might_sleep) from [<c0a0a2e4>] (__mutex_lock+0x28/0xa3c)
    [   82.240788] [<c0a0a2e4>] (__mutex_lock) from [<c0a0ad80>] (mutex_lock_nested+0x1c/0x24)
    [   82.248763] [<c0a0ad80>] (mutex_lock_nested) from [<c04923dc>] (clk_prepare_lock+0x78/0xec)
    [   82.257079] [<c04923dc>] (clk_prepare_lock) from [<c049538c>] (clk_core_get_rate+0xc/0x5c)
    [   82.265309] [<c049538c>] (clk_core_get_rate) from [<c0766b18>] (i2s_trigger+0x490/0x6d4)
    [   82.273369] [<c0766b18>] (i2s_trigger) from [<c074fec4>] (soc_pcm_trigger+0x100/0x140)
    [   82.281254] [<c074fec4>] (soc_pcm_trigger) from [<c07378a0>] (snd_pcm_do_start+0x2c/0x30)
    [   82.289400] [<c07378a0>] (snd_pcm_do_start) from [<c07376cc>] (snd_pcm_action_single+0x38/0x78)
    [   82.298065] [<c07376cc>] (snd_pcm_action_single) from [<c073a450>] (snd_pcm_ioctl+0x910/0x1268)
    [   82.306734] [<c073a450>] (snd_pcm_ioctl) from [<c0292344>] (do_vfs_ioctl+0x90/0x9ec)
    [   82.314443] [<c0292344>] (do_vfs_ioctl) from [<c0292cd4>] (ksys_ioctl+0x34/0x60)
    [   82.321808] [<c0292cd4>] (ksys_ioctl) from [<c0101000>] (ret_fast_syscall+0x0/0x28)
    [   82.329431] Exception stack(0xeb875fa8 to 0xeb875ff0)
    [   82.334459] 5fa0:                   00033c18 b6e31000 00000004 00004142 00033d80 00033d80
    [   82.342605] 5fc0: 00033c18 b6e31000 00008000 00000036 00008000 00000000 beea38a8 00008000
    [   82.350748] 5fe0: b6e3142c beea384c b6da9a30 b6c9212c
    [   82.355789]
    [   82.357245] ======================================================
    [   82.363397] WARNING: possible circular locking dependency detected
    [   82.369551] 5.0.0-rc5-00192-ga6e6caca8f03 #191 Tainted: G        W
    [   82.376395] ------------------------------------------------------
    [   82.382548] speaker-test/1554 is trying to acquire lock:
    [   82.387834] 6d2007f4 (prepare_lock){+.+.}, at: clk_prepare_lock+0x78/0xec
    [   82.394593]
    [   82.394593] but task is already holding lock:
    [   82.400398] 6ac279bf (&(&pri_dai->spinlock)->rlock){..-.}, at: i2s_trigger+0x64/0x6d4
    [   82.408197]
    [   82.408197] which lock already depends on the new lock.
    [   82.416343]
    [   82.416343] the existing dependency chain (in reverse order) is:
    [   82.423795]
    [   82.423795] -> #1 (&(&pri_dai->spinlock)->rlock){..-.}:
    [   82.430472]        clk_mux_set_parent+0x34/0xb8
    [   82.434975]        clk_core_set_parent_nolock+0x1c4/0x52c
    [   82.440347]        clk_set_parent+0x38/0x6c
    [   82.444509]        of_clk_set_defaults+0xc8/0x308
    [   82.449186]        of_clk_add_provider+0x84/0xd0
    [   82.453779]        samsung_i2s_probe+0x408/0x5f8
    [   82.458376]        platform_drv_probe+0x48/0x98
    [   82.462879]        really_probe+0x224/0x3f4
    [   82.467037]        driver_probe_device+0x70/0x1c4
    [   82.471716]        bus_for_each_drv+0x44/0x8c
    [   82.476049]        __device_attach+0xa0/0x138
    [   82.480382]        bus_probe_device+0x88/0x90
    [   82.484715]        deferred_probe_work_func+0x6c/0xbc
    [   82.489741]        process_one_work+0x200/0x740
    [   82.494246]        worker_thread+0x2c/0x4c8
    [   82.498408]        kthread+0x128/0x164
    [   82.502131]        ret_from_fork+0x14/0x20
    [   82.506204]          (null)
    [   82.508976]
    [   82.508976] -> #0 (prepare_lock){+.+.}:
    [   82.514264]        __mutex_lock+0x60/0xa3c
    [   82.518336]        mutex_lock_nested+0x1c/0x24
    [   82.522756]        clk_prepare_lock+0x78/0xec
    [   82.527088]        clk_core_get_rate+0xc/0x5c
    [   82.531421]        i2s_trigger+0x490/0x6d4
    [   82.535494]        soc_pcm_trigger+0x100/0x140
    [   82.539913]        snd_pcm_do_start+0x2c/0x30
    [   82.544246]        snd_pcm_action_single+0x38/0x78
    [   82.549012]        snd_pcm_ioctl+0x910/0x1268
    [   82.553345]        do_vfs_ioctl+0x90/0x9ec
    [   82.557417]        ksys_ioctl+0x34/0x60
    [   82.561229]        ret_fast_syscall+0x0/0x28
    [   82.565477]        0xbeea384c
    [   82.568421]
    [   82.568421] other info that might help us debug this:
    [   82.568421]
    [   82.576394]  Possible unsafe locking scenario:
    [   82.576394]
    [   82.582285]        CPU0                    CPU1
    [   82.586792]        ----                    ----
    [   82.591297]   lock(&(&pri_dai->spinlock)->rlock);
    [   82.595977]                                lock(prepare_lock);
    [   82.601782]                                lock(&(&pri_dai->spinlock)->rlock);
    [   82.608975]   lock(prepare_lock);
    [   82.612268]
    [   82.612268]  *** DEADLOCK ***
    
    Fixes: 647d04f8e07a ("ASoC: samsung: i2s: Ensure the RCLK rate is properly determined")
    Reported-by: Krzysztof Kozowski <krzk@kernel.org>
    Signed-off-by: Sylwester Nawrocki <s.nawrocki@samsung.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e13ab6c195476ba5f2a8c61eb75f7b69483b772a
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Sep 11 15:58:38 2017 -0700

    tcp/dccp: remove reqsk_put() from inet_child_forget()
    
    commit da8ab57863ed7e912d10b179b6bdc652f635bd19 upstream.
    
    Back in linux-4.4, I inadvertently put a call to reqsk_put() in
    inet_child_forget(), forgetting it could be called from two different
    points.
    
    In the case it is called from inet_csk_reqsk_queue_add(), we want to
    keep the reference on the request socket, since it is released later by
    the caller (tcp_v{4|6}_rcv())
    
    This bug never showed up because atomic_dec_and_test() was not signaling
    the underflow, and SLAB_DESTROY_BY RCU semantic for request sockets
    prevented the request to be put in quarantine.
    
    Recent conversion of socket refcount from atomic_t to refcount_t finally
    exposed the bug.
    
    So move the reqsk_put() to inet_csk_listen_stop() to fix this.
    
    Thanks to Shankara Pailoor for using syzkaller and providing
    a nice set of .config and C repro.
    
    WARNING: CPU: 2 PID: 4277 at lib/refcount.c:186
    refcount_sub_and_test+0x167/0x1b0 lib/refcount.c:186
    Kernel panic - not syncing: panic_on_warn set ...
    
    CPU: 2 PID: 4277 Comm: syz-executor0 Not tainted 4.13.0-rc7 #3
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    Ubuntu-1.8.2-1ubuntu1 04/01/2014
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0xf7/0x1aa lib/dump_stack.c:52
     panic+0x1ae/0x3a7 kernel/panic.c:180
     __warn+0x1c4/0x1d9 kernel/panic.c:541
     report_bug+0x211/0x2d0 lib/bug.c:183
     fixup_bug+0x40/0x90 arch/x86/kernel/traps.c:190
     do_trap_no_signal arch/x86/kernel/traps.c:224 [inline]
     do_trap+0x260/0x390 arch/x86/kernel/traps.c:273
     do_error_trap+0x118/0x340 arch/x86/kernel/traps.c:310
     do_invalid_op+0x1b/0x20 arch/x86/kernel/traps.c:323
     invalid_op+0x18/0x20 arch/x86/entry/entry_64.S:846
    RIP: 0010:refcount_sub_and_test+0x167/0x1b0 lib/refcount.c:186
    RSP: 0018:ffff88006e006b60 EFLAGS: 00010286
    RAX: 0000000000000026 RBX: 0000000000000000 RCX: 0000000000000000
    RDX: 0000000000000026 RSI: 1ffff1000dc00d2c RDI: ffffed000dc00d60
    RBP: ffff88006e006bf0 R08: 0000000000000001 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000000 R12: 1ffff1000dc00d6d
    R13: 00000000ffffffff R14: 0000000000000001 R15: ffff88006ce9d340
     refcount_dec_and_test+0x1a/0x20 lib/refcount.c:211
     reqsk_put+0x71/0x2b0 include/net/request_sock.h:123
     tcp_v4_rcv+0x259e/0x2e20 net/ipv4/tcp_ipv4.c:1729
     ip_local_deliver_finish+0x2e2/0xba0 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:248 [inline]
     ip_local_deliver+0x1ce/0x6d0 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:477 [inline]
     ip_rcv_finish+0x8db/0x19c0 net/ipv4/ip_input.c:397
     NF_HOOK include/linux/netfilter.h:248 [inline]
     ip_rcv+0xc3f/0x17d0 net/ipv4/ip_input.c:488
     __netif_receive_skb_core+0x1fb7/0x31f0 net/core/dev.c:4298
     __netif_receive_skb+0x2c/0x1b0 net/core/dev.c:4336
     process_backlog+0x1c5/0x6d0 net/core/dev.c:5102
     napi_poll net/core/dev.c:5499 [inline]
     net_rx_action+0x6d3/0x14a0 net/core/dev.c:5565
     __do_softirq+0x2cb/0xb2d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:898
     </IRQ>
     do_softirq.part.16+0x63/0x80 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x84/0x90 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:705 [inline]
     ip_finish_output2+0x8ad/0x1360 net/ipv4/ip_output.c:231
     ip_finish_output+0x74e/0xb80 net/ipv4/ip_output.c:317
     NF_HOOK_COND include/linux/netfilter.h:237 [inline]
     ip_output+0x1cc/0x850 net/ipv4/ip_output.c:405
     dst_output include/net/dst.h:471 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x8c6/0x1810 net/ipv4/ip_output.c:504
     tcp_transmit_skb+0x1963/0x3320 net/ipv4/tcp_output.c:1123
     tcp_send_ack.part.35+0x38c/0x620 net/ipv4/tcp_output.c:3575
     tcp_send_ack+0x49/0x60 net/ipv4/tcp_output.c:3545
     tcp_rcv_synsent_state_process net/ipv4/tcp_input.c:5795 [inline]
     tcp_rcv_state_process+0x4876/0x4b60 net/ipv4/tcp_input.c:5930
     tcp_v4_do_rcv+0x58a/0x820 net/ipv4/tcp_ipv4.c:1483
     sk_backlog_rcv include/net/sock.h:907 [inline]
     __release_sock+0x124/0x360 net/core/sock.c:2223
     release_sock+0xa4/0x2a0 net/core/sock.c:2715
     inet_wait_for_connect net/ipv4/af_inet.c:557 [inline]
     __inet_stream_connect+0x671/0xf00 net/ipv4/af_inet.c:643
     inet_stream_connect+0x58/0xa0 net/ipv4/af_inet.c:682
     SYSC_connect+0x204/0x470 net/socket.c:1628
     SyS_connect+0x24/0x30 net/socket.c:1609
     entry_SYSCALL_64_fastpath+0x18/0xad
    RIP: 0033:0x451e59
    RSP: 002b:00007f474843fc08 EFLAGS: 00000216 ORIG_RAX: 000000000000002a
    RAX: ffffffffffffffda RBX: 0000000000718000 RCX: 0000000000451e59
    RDX: 0000000000000010 RSI: 0000000020002000 RDI: 0000000000000007
    RBP: 0000000000000046 R08: 0000000000000000 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000216 R12: 0000000000000000
    R13: 00007ffc040a0f8f R14: 00007f47484409c0 R15: 0000000000000000
    
    Fixes: ebb516af60e1 ("tcp/dccp: fix race at listener dismantle phase")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Shankara Pailoor <sp3485@columbia.edu>
    Tested-by: Shankara Pailoor <sp3485@columbia.edu>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Guillaume Nault <gnault@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 83fe8732906d4a8815069e50aab0bc2ec35babbd
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Sep 11 15:58:38 2017 -0700

    tcp/dccp: remove reqsk_put() from inet_child_forget()
    
    commit da8ab57863ed7e912d10b179b6bdc652f635bd19 upstream.
    
    Back in linux-4.4, I inadvertently put a call to reqsk_put() in
    inet_child_forget(), forgetting it could be called from two different
    points.
    
    In the case it is called from inet_csk_reqsk_queue_add(), we want to
    keep the reference on the request socket, since it is released later by
    the caller (tcp_v{4|6}_rcv())
    
    This bug never showed up because atomic_dec_and_test() was not signaling
    the underflow, and SLAB_DESTROY_BY RCU semantic for request sockets
    prevented the request to be put in quarantine.
    
    Recent conversion of socket refcount from atomic_t to refcount_t finally
    exposed the bug.
    
    So move the reqsk_put() to inet_csk_listen_stop() to fix this.
    
    Thanks to Shankara Pailoor for using syzkaller and providing
    a nice set of .config and C repro.
    
    WARNING: CPU: 2 PID: 4277 at lib/refcount.c:186
    refcount_sub_and_test+0x167/0x1b0 lib/refcount.c:186
    Kernel panic - not syncing: panic_on_warn set ...
    
    CPU: 2 PID: 4277 Comm: syz-executor0 Not tainted 4.13.0-rc7 #3
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    Ubuntu-1.8.2-1ubuntu1 04/01/2014
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0xf7/0x1aa lib/dump_stack.c:52
     panic+0x1ae/0x3a7 kernel/panic.c:180
     __warn+0x1c4/0x1d9 kernel/panic.c:541
     report_bug+0x211/0x2d0 lib/bug.c:183
     fixup_bug+0x40/0x90 arch/x86/kernel/traps.c:190
     do_trap_no_signal arch/x86/kernel/traps.c:224 [inline]
     do_trap+0x260/0x390 arch/x86/kernel/traps.c:273
     do_error_trap+0x118/0x340 arch/x86/kernel/traps.c:310
     do_invalid_op+0x1b/0x20 arch/x86/kernel/traps.c:323
     invalid_op+0x18/0x20 arch/x86/entry/entry_64.S:846
    RIP: 0010:refcount_sub_and_test+0x167/0x1b0 lib/refcount.c:186
    RSP: 0018:ffff88006e006b60 EFLAGS: 00010286
    RAX: 0000000000000026 RBX: 0000000000000000 RCX: 0000000000000000
    RDX: 0000000000000026 RSI: 1ffff1000dc00d2c RDI: ffffed000dc00d60
    RBP: ffff88006e006bf0 R08: 0000000000000001 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000000 R12: 1ffff1000dc00d6d
    R13: 00000000ffffffff R14: 0000000000000001 R15: ffff88006ce9d340
     refcount_dec_and_test+0x1a/0x20 lib/refcount.c:211
     reqsk_put+0x71/0x2b0 include/net/request_sock.h:123
     tcp_v4_rcv+0x259e/0x2e20 net/ipv4/tcp_ipv4.c:1729
     ip_local_deliver_finish+0x2e2/0xba0 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:248 [inline]
     ip_local_deliver+0x1ce/0x6d0 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:477 [inline]
     ip_rcv_finish+0x8db/0x19c0 net/ipv4/ip_input.c:397
     NF_HOOK include/linux/netfilter.h:248 [inline]
     ip_rcv+0xc3f/0x17d0 net/ipv4/ip_input.c:488
     __netif_receive_skb_core+0x1fb7/0x31f0 net/core/dev.c:4298
     __netif_receive_skb+0x2c/0x1b0 net/core/dev.c:4336
     process_backlog+0x1c5/0x6d0 net/core/dev.c:5102
     napi_poll net/core/dev.c:5499 [inline]
     net_rx_action+0x6d3/0x14a0 net/core/dev.c:5565
     __do_softirq+0x2cb/0xb2d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:898
     </IRQ>
     do_softirq.part.16+0x63/0x80 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x84/0x90 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:705 [inline]
     ip_finish_output2+0x8ad/0x1360 net/ipv4/ip_output.c:231
     ip_finish_output+0x74e/0xb80 net/ipv4/ip_output.c:317
     NF_HOOK_COND include/linux/netfilter.h:237 [inline]
     ip_output+0x1cc/0x850 net/ipv4/ip_output.c:405
     dst_output include/net/dst.h:471 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x8c6/0x1810 net/ipv4/ip_output.c:504
     tcp_transmit_skb+0x1963/0x3320 net/ipv4/tcp_output.c:1123
     tcp_send_ack.part.35+0x38c/0x620 net/ipv4/tcp_output.c:3575
     tcp_send_ack+0x49/0x60 net/ipv4/tcp_output.c:3545
     tcp_rcv_synsent_state_process net/ipv4/tcp_input.c:5795 [inline]
     tcp_rcv_state_process+0x4876/0x4b60 net/ipv4/tcp_input.c:5930
     tcp_v4_do_rcv+0x58a/0x820 net/ipv4/tcp_ipv4.c:1483
     sk_backlog_rcv include/net/sock.h:907 [inline]
     __release_sock+0x124/0x360 net/core/sock.c:2223
     release_sock+0xa4/0x2a0 net/core/sock.c:2715
     inet_wait_for_connect net/ipv4/af_inet.c:557 [inline]
     __inet_stream_connect+0x671/0xf00 net/ipv4/af_inet.c:643
     inet_stream_connect+0x58/0xa0 net/ipv4/af_inet.c:682
     SYSC_connect+0x204/0x470 net/socket.c:1628
     SyS_connect+0x24/0x30 net/socket.c:1609
     entry_SYSCALL_64_fastpath+0x18/0xad
    RIP: 0033:0x451e59
    RSP: 002b:00007f474843fc08 EFLAGS: 00000216 ORIG_RAX: 000000000000002a
    RAX: ffffffffffffffda RBX: 0000000000718000 RCX: 0000000000451e59
    RDX: 0000000000000010 RSI: 0000000020002000 RDI: 0000000000000007
    RBP: 0000000000000046 R08: 0000000000000000 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000216 R12: 0000000000000000
    R13: 00007ffc040a0f8f R14: 00007f47484409c0 R15: 0000000000000000
    
    Fixes: ebb516af60e1 ("tcp/dccp: fix race at listener dismantle phase")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Shankara Pailoor <sp3485@columbia.edu>
    Tested-by: Shankara Pailoor <sp3485@columbia.edu>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Guillaume Nault <gnault@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9393998e9ee094f99d18783cc85c489e20f0e0e7
Author: Luc Maranget <Luc.Maranget@inria.fr>
Date:   Thu Dec 27 16:27:12 2018 +0100

    tools/memory-model: Dynamically check SRCU lock-to-unlock matching
    
    This commit checks that the return value of srcu_read_lock() is passed
    to the matching srcu_read_unlock(), where "matching" is determined by
    nesting.  This check operates as follows:
    
       1. srcu_read_lock() creates an integer token, which is stored into
          the generated events.
       2. srcu_read_unlock() records its second (token) argument into the
          generated event.
       3. A new herd primitive 'different-values' filters out pairs of events
          with identical values from the relation passed as its argument.
       4. The bell file applies the above primitive to the (srcu)
          read-side-critical-section relation 'srcu-rscs' and flags non-empty
          results.
    
    BEWARE: Works only with herd version 7.51+6 and onwards.
    
    Signed-off-by: Luc Maranget <Luc.Maranget@inria.fr>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    [ paulmck: Apply Andrea Parri's off-list feedback. ]
    Acked-by: Alan Stern <stern@rowland.harvard.edu>

commit a3f600d92da564ad35f237c8aeab268ca49377cc
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Nov 15 11:20:37 2018 -0500

    tools/memory-model: Add SRCU support
    
    Add support for SRCU.  Herd creates srcu events and linux-kernel.def
    associates them with three possible annotations (srcu-lock,
    srcu-unlock, and sync-srcu) corresponding to the API routines
    srcu_read_lock(), srcu_read_unlock(), and synchronize_srcu().
    
    The linux-kernel.bell file now declares the annotations
    and determines matching lock/unlock pairs delimiting SRCU read-side
    critical sections, and it also checks for synchronize_srcu() calls
    inside an RCU critical section (which would generate a "sleeping in
    atomic context" error in real kernel code).  The linux-kernel.cat file
    now adds SRCU-induced ordering, analogous to the existing RCU-induced
    ordering, to the gp and rcu-fence relations.
    
    Curiously enough, these small changes to the model's .cat code are all
    that is needed to describe SRCU.
    
    Portions of this patch (linux-kernel.def and the first hunk in
    linux-kernel.bell) were written by Luc Maranget.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    CC: Luc Maranget <luc.maranget@inria.fr>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Tested-by: Andrea Parri <andrea.parri@amarulasolutions.com>

commit 0172d9e322035bf7bb66a7dfdd795c38d71dbba9
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Thu Nov 15 11:19:44 2018 -0500

    tools/memory-model: Rename some RCU relations
    
    In preparation for adding support for SRCU, rename "crit" to
    "rcu-rscs", rename "rscs" to "rcu-rscsi", and remove the restriction
    to only the outermost level of nesting.
    
    The name change is needed for disambiguating RCU read-side critical
    sections from SRCU read-side critical sections.  Adding the "i" at the
    end of "rcu-rscsi" emphasizes that the relation is inverted; it links
    rcu_read_unlock() events to their corresponding preceding
    rcu_read_lock() events.
    
    The restriction to outermost nesting levels was never essential; it
    was included mostly to show that it could be done.  Rather than add
    equivalent unnecessary code for SRCU lock nesting, it seemed better to
    remove the existing code.
    
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Tested-by: Andrea Parri <andrea.parri@amarulasolutions.com>

commit 9180bb4f046064dfa4541488102703b402bb04e1
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Mar 16 13:09:53 2019 -0700

    tun: add a missing rcu_read_unlock() in error path
    
    In my latest patch I missed one rcu_read_unlock(), in case
    device is down.
    
    Fixes: 4477138fa0ae ("tun: properly test for IFF_UP")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit cffaaf0c816238c45cd2d06913476c83eb50f682
Author: Julia Cartwright <julia@ni.com>
Date:   Wed Feb 20 16:46:31 2019 +0000

    iommu/dmar: Fix buffer overflow during PCI bus notification
    
    Commit 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI
    device path") changed the type of the path data, however, the change in
    path type was not reflected in size calculations.  Update to use the
    correct type and prevent a buffer overflow.
    
    This bug manifests in systems with deep PCI hierarchies, and can lead to
    an overflow of the static allocated buffer (dmar_pci_notify_info_buf),
    or can lead to overflow of slab-allocated data.
    
       BUG: KASAN: global-out-of-bounds in dmar_alloc_pci_notify_info+0x1d5/0x2e0
       Write of size 1 at addr ffffffff90445d80 by task swapper/0/1
       CPU: 0 PID: 1 Comm: swapper/0 Tainted: G        W       4.14.87-rt49-02406-gd0a0e96 #1
       Call Trace:
        ? dump_stack+0x46/0x59
        ? print_address_description+0x1df/0x290
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? kasan_report+0x256/0x340
        ? dmar_alloc_pci_notify_info+0x1d5/0x2e0
        ? e820__memblock_setup+0xb0/0xb0
        ? dmar_dev_scope_init+0x424/0x48f
        ? __down_write_common+0x1ec/0x230
        ? dmar_dev_scope_init+0x48f/0x48f
        ? dmar_free_unused_resources+0x109/0x109
        ? cpumask_next+0x16/0x20
        ? __kmem_cache_create+0x392/0x430
        ? kmem_cache_create+0x135/0x2f0
        ? e820__memblock_setup+0xb0/0xb0
        ? intel_iommu_init+0x170/0x1848
        ? _raw_spin_unlock_irqrestore+0x32/0x60
        ? migrate_enable+0x27a/0x5b0
        ? sched_setattr+0x20/0x20
        ? migrate_disable+0x1fc/0x380
        ? task_rq_lock+0x170/0x170
        ? try_to_run_init_process+0x40/0x40
        ? locks_remove_file+0x85/0x2f0
        ? dev_prepare_static_identity_mapping+0x78/0x78
        ? rt_spin_unlock+0x39/0x50
        ? lockref_put_or_lock+0x2a/0x40
        ? dput+0x128/0x2f0
        ? __rcu_read_unlock+0x66/0x80
        ? __fput+0x250/0x300
        ? __rcu_read_lock+0x1b/0x30
        ? mntput_no_expire+0x38/0x290
        ? e820__memblock_setup+0xb0/0xb0
        ? pci_iommu_init+0x25/0x63
        ? pci_iommu_init+0x25/0x63
        ? do_one_initcall+0x7e/0x1c0
        ? initcall_blacklisted+0x120/0x120
        ? kernel_init_freeable+0x27b/0x307
        ? rest_init+0xd0/0xd0
        ? kernel_init+0xf/0x120
        ? rest_init+0xd0/0xd0
        ? ret_from_fork+0x1f/0x40
       The buggy address belongs to the variable:
        dmar_pci_notify_info_buf+0x40/0x60
    
    Fixes: 57384592c433 ("iommu/vt-d: Store bus information in RMRR PCI device path")
    Signed-off-by: Julia Cartwright <julia@ni.com>
    Signed-off-by: Joerg Roedel <jroedel@suse.de>

commit e4c275f77624961b56cce397814d9d770a45ac59
Author: Vadim Pasternak <vadimp@mellanox.com>
Date:   Sun Feb 17 18:15:30 2019 +0000

    platform/mellanox: mlxreg-hotplug: Fix KASAN warning
    
    Fix the following KASAN warning produced when booting a 64-bit kernel:
    [   13.334750] BUG: KASAN: stack-out-of-bounds in find_first_bit+0x19/0x70
    [   13.342166] Read of size 8 at addr ffff880235067178 by task kworker/2:1/42
    [   13.342176] CPU: 2 PID: 42 Comm: kworker/2:1 Not tainted 4.20.0-rc1+ #106
    [   13.342179] Hardware name: Mellanox Technologies Ltd. MSN2740/Mellanox x86 SFF board, BIOS 5.6.5 06/07/2016
    [   13.342190] Workqueue: events deferred_probe_work_func
    [   13.342194] Call Trace:
    [   13.342206]  dump_stack+0xc7/0x15b
    [   13.342214]  ? show_regs_print_info+0x5/0x5
    [   13.342220]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [   13.342234]  ? _raw_write_lock_irqsave+0x100/0x100
    [   13.351593]  print_address_description+0x73/0x260
    [   13.351603]  kasan_report+0x260/0x380
    [   13.351611]  ? find_first_bit+0x19/0x70
    [   13.351619]  find_first_bit+0x19/0x70
    [   13.351630]  mlxreg_hotplug_work_handler+0x73c/0x920 [mlxreg_hotplug]
    [   13.351639]  ? __lock_text_start+0x8/0x8
    [   13.351646]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351656]  ? mlxreg_hotplug_remove+0x1e0/0x1e0 [mlxreg_hotplug]
    [   13.351663]  ? regmap_volatile+0x40/0xb0
    [   13.351668]  ? regcache_write+0x4c/0x90
    [   13.351676]  ? mlxplat_mlxcpld_reg_write+0x24/0x30 [mlx_platform]
    [   13.351681]  ? _regmap_write+0xea/0x220
    [   13.351688]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351696]  ? devm_add_action+0x70/0x70
    [   13.351701]  ? mutex_unlock+0x1d/0x40
    [   13.351710]  mlxreg_hotplug_probe+0x82e/0x989 [mlxreg_hotplug]
    [   13.351723]  ? mlxreg_hotplug_work_handler+0x920/0x920 [mlxreg_hotplug]
    [   13.351731]  ? sysfs_do_create_link_sd.isra.2+0xf4/0x190
    [   13.351737]  ? sysfs_rename_link_ns+0xf0/0xf0
    [   13.351743]  ? devres_close_group+0x2b0/0x2b0
    [   13.351749]  ? pinctrl_put+0x20/0x20
    [   13.351755]  ? acpi_dev_pm_attach+0x2c/0xd0
    [   13.351763]  platform_drv_probe+0x70/0xd0
    [   13.351771]  really_probe+0x480/0x6e0
    [   13.351778]  ? device_attach+0x10/0x10
    [   13.351784]  ? __lock_text_start+0x8/0x8
    [   13.351790]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351797]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.351806]  ? __driver_attach+0x190/0x190
    [   13.351812]  driver_probe_device+0x17d/0x1a0
    [   13.351819]  ? __driver_attach+0x190/0x190
    [   13.351825]  bus_for_each_drv+0xd6/0x130
    [   13.351831]  ? bus_rescan_devices+0x20/0x20
    [   13.351837]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351845]  __device_attach+0x18c/0x230
    [   13.351852]  ? device_bind_driver+0x70/0x70
    [   13.351859]  ? __mutex_lock_slowpath+0x10/0x10
    [   13.351866]  bus_probe_device+0xea/0x110
    [   13.351874]  deferred_probe_work_func+0x1c9/0x290
    [   13.351882]  ? driver_deferred_probe_add+0x1d0/0x1d0
    [   13.351889]  ? preempt_notifier_dec+0x20/0x20
    [   13.351897]  ? read_word_at_a_time+0xe/0x20
    [   13.351904]  ? strscpy+0x151/0x290
    [   13.351912]  ? set_work_pool_and_clear_pending+0x9c/0xf0
    [   13.351918]  ? __switch_to_asm+0x34/0x70
    [   13.351924]  ? __switch_to_asm+0x40/0x70
    [   13.351929]  ? __switch_to_asm+0x34/0x70
    [   13.351935]  ? __switch_to_asm+0x40/0x70
    [   13.351942]  process_one_work+0x5cc/0xa00
    [   13.351952]  ? pwq_dec_nr_in_flight+0x1e0/0x1e0
    [   13.351960]  ? pci_mmcfg_check_reserved+0x80/0xb8
    [   13.351967]  ? run_rebalance_domains+0x250/0x250
    [   13.351980]  ? stack_access_ok+0x35/0x80
    [   13.351986]  ? deref_stack_reg+0xa1/0xe0
    [   13.351994]  ? schedule+0xcd/0x250
    [   13.352000]  ? worker_enter_idle+0x2d6/0x330
    [   13.352006]  ? __schedule+0xeb0/0xeb0
    [   13.352014]  ? fork_usermode_blob+0x130/0x130
    [   13.352019]  ? mutex_lock+0xa7/0x100
    [   13.352026]  ? _raw_spin_lock_irq+0x98/0xf0
    [   13.352032]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   13.352037] i2c i2c-2: Added multiplexed i2c bus 11
    [   13.352043]  worker_thread+0x181/0xa80
    [   13.352052]  ? __switch_to_asm+0x34/0x70
    [   13.352058]  ? __switch_to_asm+0x40/0x70
    [   13.352064]  ? process_one_work+0xa00/0xa00
    [   13.352070]  ? __switch_to_asm+0x34/0x70
    [   13.352076]  ? __switch_to_asm+0x40/0x70
    [   13.352081]  ? __switch_to_asm+0x34/0x70
    [   13.352086]  ? __switch_to_asm+0x40/0x70
    [   13.352092]  ? __switch_to_asm+0x34/0x70
    [   13.352097]  ? __switch_to_asm+0x40/0x70
    [   13.352105]  ? __schedule+0x3d6/0xeb0
    [   13.352112]  ? migrate_swap_stop+0x470/0x470
    [   13.352119]  ? save_stack+0x89/0xb0
    [   13.352127]  ? kmem_cache_alloc_trace+0xe5/0x570
    [   13.352132]  ? kthread+0x59/0x1d0
    [   13.352138]  ? ret_from_fork+0x35/0x40
    [   13.352154]  ? __schedule+0xeb0/0xeb0
    [   13.352161]  ? remove_wait_queue+0x150/0x150
    [   13.352169]  ? _raw_write_lock_irqsave+0x80/0x100
    [   13.352175]  ? __lock_text_start+0x8/0x8
    [   13.352183]  ? process_one_work+0xa00/0xa00
    [   13.352188]  kthread+0x1a4/0x1d0
    [   13.352195]  ? kthread_create_worker_on_cpu+0xc0/0xc0
    [   13.352202]  ret_from_fork+0x35/0x40
    
    [   13.353879] The buggy address belongs to the page:
    [   13.353885] page:ffffea0008d419c0 count:0 mapcount:0 mapping:0000000000000000 index:0x0
    [   13.353890] flags: 0x2ffff8000000000()
    [   13.353897] raw: 02ffff8000000000 ffffea0008d419c8 ffffea0008d419c8 0000000000000000
    [   13.353903] raw: 0000000000000000 0000000000000000 00000000ffffffff 0000000000000000
    [   13.353905] page dumped because: kasan: bad access detected
    
    [   13.353908] Memory state around the buggy address:
    [   13.353912]  ffff880235067000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   13.353917]  ffff880235067080: 00 00 00 00 00 00 00 00 00 00 00 f1 f1 f1 f1 04
    [   13.353921] >ffff880235067100: f2 f2 f2 f2 f2 f2 f2 04 f2 f2 f2 f2 f2 f2 f2 04
    [   13.353923]                                                                 ^
    [   13.353927]  ffff880235067180: f2 f2 f2 f2 f2 f2 f2 04 f2 f2 f2 00 00 00 00 00
    [   13.353931]  ffff880235067200: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
    [   13.353933] ==================================================================
    
    The warning is caused by the below loop:
            for_each_set_bit(bit, (unsigned long *)&asserted, 8) {
    while "asserted" is declared as 'unsigned'.
    
    The casting of 32-bit unsigned integer pointer to a 64-bit unsigned long
    pointer. There are two problems here.
    It causes the access of four extra byte, which can corrupt memory
    The 32-bit pointer address may not be 64-bit aligned.
    
    The fix changes variable "asserted" to "unsigned long".
    
    Fixes: 1f976f6978bf ("platform/x86: Move Mellanox platform hotplug driver to platform/mellanox")
    Signed-off-by: Vadim Pasternak <vadimp@mellanox.com>
    Signed-off-by: Darren Hart (VMware) <dvhart@infradead.org>

commit f2ffff085d287eec499f1fccd682796ad8010303
Author: Wei Yongjun <weiyongjun1@huawei.com>
Date:   Mon Feb 18 11:29:29 2019 +0100

    mac80211: mesh: fix missing unlock on error in table_path_del()
    
    spin_lock_bh() is used in table_path_del() but rcu_read_unlock()
    is used for unlocking. Fix it by using spin_unlock_bh() instead
    of rcu_read_unlock() in the error handling case.
    
    Fixes: b4c3fbe63601 ("mac80211: Use linked list instead of rhashtable walk for mesh tables")
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Wei Yongjun <weiyongjun1@huawei.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 2caffbf1176256cc4f8d4e5c3c524fc689cb9876
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Feb 8 15:37:03 2019 +0000

    drm/i915: Revoke mmaps and prevent access to fence registers across reset
    
    Previously, we were able to rely on the recursive properties of
    struct_mutex to allow us to serialise revoking mmaps and reacquiring the
    FENCE registers with them being clobbered over a global device reset.
    I then proceeded to throw out the baby with the bath water in order to
    pursue a struct_mutex-less reset.
    
    Perusing LWN for alternative strategies, the dilemma on how to serialise
    access to a global resource on one side was answered by
    https://lwn.net/Articles/202847/ -- Sleepable RCU:
    
        1  int readside(void) {
        2      int idx;
        3      rcu_read_lock();
        4      if (nomoresrcu) {
        5          rcu_read_unlock();
        6          return -EINVAL;
        7      }
        8      idx = srcu_read_lock(&ss);
        9      rcu_read_unlock();
        10     /* SRCU read-side critical section. */
        11     srcu_read_unlock(&ss, idx);
        12     return 0;
        13 }
        14
        15 void cleanup(void)
        16 {
        17     nomoresrcu = 1;
        18     synchronize_rcu();
        19     synchronize_srcu(&ss);
        20     cleanup_srcu_struct(&ss);
        21 }
    
    No more worrying about stop_machine, just an uber-complex mutex,
    optimised for reads, with the overhead pushed to the rare reset path.
    
    However, we do run the risk of a deadlock as we allocate underneath the
    SRCU read lock, and the allocation may require a GPU reset, causing a
    dependency cycle via the in-flight requests. We resolve that by declaring
    the driver wedged and cancelling all in-flight rendering.
    
    v2: Use expedited rcu barriers to match our earlier timing
    characteristics.
    v3: Try to annotate locking contexts for sparse
    v4: Reduce selftest lock duration to avoid a reset deadlock with fences
    v5: s/srcu/reset_backoff_srcu/
    v6: Remove more stale comments
    
    Testcase: igt/gem_mmap_gtt/hang
    Fixes: eb8d0f5af4ec ("drm/i915: Remove GPU reset dependence on struct_mutex")
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Mika Kuoppala <mika.kuoppala@intel.com>
    Reviewed-by: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190208153708.20023-2-chris@chris-wilson.co.uk

commit ee2eb3d4ee175c2fb5c7f67e84f5fe40a8147d92
Author: James Morse <james.morse@arm.com>
Date:   Tue Jan 29 18:48:45 2019 +0000

    ACPI / APEI: Generalise the estatus queue's notify code
    
    Refactor the estatus queue's pool notification routine from
    NOTIFY_NMI's handlers. This will allow another notification
    method to use the estatus queue without duplicating this code.
    
    Add rcu_read_lock()/rcu_read_unlock() around the list
    list_for_each_entry_rcu() walker. These aren't strictly necessary as
    the whole nmi_enter/nmi_exit() window is a spooky RCU read-side
    critical section.
    
    in_nmi_queue_one_entry() is separate from the rcu-list walker for a
    later caller that doesn't need to walk a list.
    
    Signed-off-by: James Morse <james.morse@arm.com>
    Reviewed-by: Punit Agrawal <punit.agrawal@arm.com>
    Tested-by: Tyler Baicar <tbaicar@codeaurora.org>
    [ rjw: Drop unnecessary err variable in two places ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit 860b454c2c0cbda6892954f5cdbbb48931b3c8db
Author: Sylwester Nawrocki <s.nawrocki@samsung.com>
Date:   Thu Feb 7 15:20:41 2019 +0100

    ASoC: samsung: Prevent clk_get_rate() calls in atomic context
    
    This patch moves clk_get_rate() call from trigger() to hw_params()
    callback to avoid calling sleeping clk API from atomic context
    and prevent deadlock as indicated below.
    
    Before this change clk_get_rate() was being called with same
    spinlock held as the one passed to the clk API when registering
    clocks exposed by the I2S driver.
    
    [   82.109780] BUG: sleeping function called from invalid context at kernel/locking/mutex.c:908
    [   82.117009] in_atomic(): 1, irqs_disabled(): 128, pid: 1554, name: speaker-test
    [   82.124235] 3 locks held by speaker-test/1554:
    [   82.128653]  #0: cc8c5328 (snd_pcm_link_rwlock){...-}, at: snd_pcm_stream_lock_irq+0x20/0x38
    [   82.137058]  #1: ec9eda17 (&(&substream->self_group.lock)->rlock){..-.}, at: snd_pcm_ioctl+0x900/0x1268
    [   82.146417]  #2: 6ac279bf (&(&pri_dai->spinlock)->rlock){..-.}, at: i2s_trigger+0x64/0x6d4
    [   82.154650] irq event stamp: 8144
    [   82.157949] hardirqs last  enabled at (8143): [<c0a0f574>] _raw_read_unlock_irq+0x24/0x5c
    [   82.166089] hardirqs last disabled at (8144): [<c0a0f6a8>] _raw_read_lock_irq+0x18/0x58
    [   82.174063] softirqs last  enabled at (8004): [<c01024e4>] __do_softirq+0x3a4/0x66c
    [   82.181688] softirqs last disabled at (7997): [<c012d730>] irq_exit+0x140/0x168
    [   82.188964] Preemption disabled at:
    [   82.188967] [<00000000>]   (null)
    [   82.195728] CPU: 6 PID: 1554 Comm: speaker-test Not tainted 5.0.0-rc5-00192-ga6e6caca8f03 #191
    [   82.204302] Hardware name: SAMSUNG EXYNOS (Flattened Device Tree)
    [   82.210376] [<c0111a54>] (unwind_backtrace) from [<c010d8f4>] (show_stack+0x10/0x14)
    [   82.218084] [<c010d8f4>] (show_stack) from [<c09ef004>] (dump_stack+0x90/0xc8)
    [   82.225278] [<c09ef004>] (dump_stack) from [<c0152980>] (___might_sleep+0x22c/0x2c8)
    [   82.232990] [<c0152980>] (___might_sleep) from [<c0a0a2e4>] (__mutex_lock+0x28/0xa3c)
    [   82.240788] [<c0a0a2e4>] (__mutex_lock) from [<c0a0ad80>] (mutex_lock_nested+0x1c/0x24)
    [   82.248763] [<c0a0ad80>] (mutex_lock_nested) from [<c04923dc>] (clk_prepare_lock+0x78/0xec)
    [   82.257079] [<c04923dc>] (clk_prepare_lock) from [<c049538c>] (clk_core_get_rate+0xc/0x5c)
    [   82.265309] [<c049538c>] (clk_core_get_rate) from [<c0766b18>] (i2s_trigger+0x490/0x6d4)
    [   82.273369] [<c0766b18>] (i2s_trigger) from [<c074fec4>] (soc_pcm_trigger+0x100/0x140)
    [   82.281254] [<c074fec4>] (soc_pcm_trigger) from [<c07378a0>] (snd_pcm_do_start+0x2c/0x30)
    [   82.289400] [<c07378a0>] (snd_pcm_do_start) from [<c07376cc>] (snd_pcm_action_single+0x38/0x78)
    [   82.298065] [<c07376cc>] (snd_pcm_action_single) from [<c073a450>] (snd_pcm_ioctl+0x910/0x1268)
    [   82.306734] [<c073a450>] (snd_pcm_ioctl) from [<c0292344>] (do_vfs_ioctl+0x90/0x9ec)
    [   82.314443] [<c0292344>] (do_vfs_ioctl) from [<c0292cd4>] (ksys_ioctl+0x34/0x60)
    [   82.321808] [<c0292cd4>] (ksys_ioctl) from [<c0101000>] (ret_fast_syscall+0x0/0x28)
    [   82.329431] Exception stack(0xeb875fa8 to 0xeb875ff0)
    [   82.334459] 5fa0:                   00033c18 b6e31000 00000004 00004142 00033d80 00033d80
    [   82.342605] 5fc0: 00033c18 b6e31000 00008000 00000036 00008000 00000000 beea38a8 00008000
    [   82.350748] 5fe0: b6e3142c beea384c b6da9a30 b6c9212c
    [   82.355789]
    [   82.357245] ======================================================
    [   82.363397] WARNING: possible circular locking dependency detected
    [   82.369551] 5.0.0-rc5-00192-ga6e6caca8f03 #191 Tainted: G        W
    [   82.376395] ------------------------------------------------------
    [   82.382548] speaker-test/1554 is trying to acquire lock:
    [   82.387834] 6d2007f4 (prepare_lock){+.+.}, at: clk_prepare_lock+0x78/0xec
    [   82.394593]
    [   82.394593] but task is already holding lock:
    [   82.400398] 6ac279bf (&(&pri_dai->spinlock)->rlock){..-.}, at: i2s_trigger+0x64/0x6d4
    [   82.408197]
    [   82.408197] which lock already depends on the new lock.
    [   82.416343]
    [   82.416343] the existing dependency chain (in reverse order) is:
    [   82.423795]
    [   82.423795] -> #1 (&(&pri_dai->spinlock)->rlock){..-.}:
    [   82.430472]        clk_mux_set_parent+0x34/0xb8
    [   82.434975]        clk_core_set_parent_nolock+0x1c4/0x52c
    [   82.440347]        clk_set_parent+0x38/0x6c
    [   82.444509]        of_clk_set_defaults+0xc8/0x308
    [   82.449186]        of_clk_add_provider+0x84/0xd0
    [   82.453779]        samsung_i2s_probe+0x408/0x5f8
    [   82.458376]        platform_drv_probe+0x48/0x98
    [   82.462879]        really_probe+0x224/0x3f4
    [   82.467037]        driver_probe_device+0x70/0x1c4
    [   82.471716]        bus_for_each_drv+0x44/0x8c
    [   82.476049]        __device_attach+0xa0/0x138
    [   82.480382]        bus_probe_device+0x88/0x90
    [   82.484715]        deferred_probe_work_func+0x6c/0xbc
    [   82.489741]        process_one_work+0x200/0x740
    [   82.494246]        worker_thread+0x2c/0x4c8
    [   82.498408]        kthread+0x128/0x164
    [   82.502131]        ret_from_fork+0x14/0x20
    [   82.506204]          (null)
    [   82.508976]
    [   82.508976] -> #0 (prepare_lock){+.+.}:
    [   82.514264]        __mutex_lock+0x60/0xa3c
    [   82.518336]        mutex_lock_nested+0x1c/0x24
    [   82.522756]        clk_prepare_lock+0x78/0xec
    [   82.527088]        clk_core_get_rate+0xc/0x5c
    [   82.531421]        i2s_trigger+0x490/0x6d4
    [   82.535494]        soc_pcm_trigger+0x100/0x140
    [   82.539913]        snd_pcm_do_start+0x2c/0x30
    [   82.544246]        snd_pcm_action_single+0x38/0x78
    [   82.549012]        snd_pcm_ioctl+0x910/0x1268
    [   82.553345]        do_vfs_ioctl+0x90/0x9ec
    [   82.557417]        ksys_ioctl+0x34/0x60
    [   82.561229]        ret_fast_syscall+0x0/0x28
    [   82.565477]        0xbeea384c
    [   82.568421]
    [   82.568421] other info that might help us debug this:
    [   82.568421]
    [   82.576394]  Possible unsafe locking scenario:
    [   82.576394]
    [   82.582285]        CPU0                    CPU1
    [   82.586792]        ----                    ----
    [   82.591297]   lock(&(&pri_dai->spinlock)->rlock);
    [   82.595977]                                lock(prepare_lock);
    [   82.601782]                                lock(&(&pri_dai->spinlock)->rlock);
    [   82.608975]   lock(prepare_lock);
    [   82.612268]
    [   82.612268]  *** DEADLOCK ***
    
    Fixes: 647d04f8e07a ("ASoC: samsung: i2s: Ensure the RCLK rate is properly determined")
    Reported-by: Krzysztof Kozowski <krzk@kernel.org>
    Signed-off-by: Sylwester Nawrocki <s.nawrocki@samsung.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

commit cc975000ebb58d2e04bce8bf5a6a354dc72588eb
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jan 5 07:35:04 2019 -0800

    ipv6: Take rcu_read_lock in __inet6_bind for mapped addresses
    
    [ Upstream commit d4a7e9bb74b5aaf07b89f6531c080b1130bdf019 ]
    
    I realized the last patch calls dev_get_by_index_rcu in a branch not
    holding the rcu lock. Add the calls to rcu_read_lock and rcu_read_unlock.
    
    Fixes: ec90ad334986 ("ipv6: Consider sk_bound_dev_if when binding a socket to a v4 mapped address")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2af7450e84355619396a9c7c5c3caac2231d3565
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jan 5 07:35:04 2019 -0800

    ipv6: Take rcu_read_lock in __inet6_bind for mapped addresses
    
    [ Upstream commit d4a7e9bb74b5aaf07b89f6531c080b1130bdf019 ]
    
    I realized the last patch calls dev_get_by_index_rcu in a branch not
    holding the rcu lock. Add the calls to rcu_read_lock and rcu_read_unlock.
    
    Fixes: ec90ad334986 ("ipv6: Consider sk_bound_dev_if when binding a socket to a v4 mapped address")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f1ce6ee14adf3790d023932d1daa377c68bbd13e
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jan 5 07:35:04 2019 -0800

    ipv6: Take rcu_read_lock in __inet6_bind for mapped addresses
    
    [ Upstream commit d4a7e9bb74b5aaf07b89f6531c080b1130bdf019 ]
    
    I realized the last patch calls dev_get_by_index_rcu in a branch not
    holding the rcu lock. Add the calls to rcu_read_lock and rcu_read_unlock.
    
    Fixes: ec90ad334986 ("ipv6: Consider sk_bound_dev_if when binding a socket to a v4 mapped address")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c1fa98a5748fa8dc5291ada95360ddbe24977246
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jan 5 07:35:04 2019 -0800

    ipv6: Take rcu_read_lock in __inet6_bind for mapped addresses
    
    [ Upstream commit d4a7e9bb74b5aaf07b89f6531c080b1130bdf019 ]
    
    I realized the last patch calls dev_get_by_index_rcu in a branch not
    holding the rcu lock. Add the calls to rcu_read_lock and rcu_read_unlock.
    
    Fixes: ec90ad334986 ("ipv6: Consider sk_bound_dev_if when binding a socket to a v4 mapped address")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cdd8fac7ad111e07d76872fffce0bc1cee7838c7
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jan 5 07:35:04 2019 -0800

    ipv6: Take rcu_read_lock in __inet6_bind for mapped addresses
    
    [ Upstream commit d4a7e9bb74b5aaf07b89f6531c080b1130bdf019 ]
    
    I realized the last patch calls dev_get_by_index_rcu in a branch not
    holding the rcu lock. Add the calls to rcu_read_lock and rcu_read_unlock.
    
    Fixes: ec90ad334986 ("ipv6: Consider sk_bound_dev_if when binding a socket to a v4 mapped address")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c8ca1aa774b20f182733d1661f3b6aa3105338e7
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Fri Nov 30 10:06:46 2018 -0800

    srcu: Check for invalid idx argument in srcu_read_unlock()
    
    The current SRCU implementation has an idx argument of zero or one,
    and never anything else.  This commit therefore adds a WARN_ON_ONCE()
    to complain if this restriction is violated.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit cb754d67c084d4e673c3dd420636d7e8eb81b024
Author: Christoffer Dall <christoffer.dall@arm.com>
Date:   Tue Dec 11 13:23:57 2018 +0100

    KVM: arm/arm64: Fix VMID alloc race by reverting to lock-less
    
    commit fb544d1ca65a89f7a3895f7531221ceeed74ada7 upstream.
    
    We recently addressed a VMID generation race by introducing a read/write
    lock around accesses and updates to the vmid generation values.
    
    However, kvm_arch_vcpu_ioctl_run() also calls need_new_vmid_gen() but
    does so without taking the read lock.
    
    As far as I can tell, this can lead to the same kind of race:
    
      VM 0, VCPU 0                  VM 0, VCPU 1
      ------------                  ------------
      update_vttbr (vmid 254)
                                    update_vttbr (vmid 1) // roll over
                                    read_lock(kvm_vmid_lock);
                                    force_vm_exit()
      local_irq_disable
      need_new_vmid_gen == false //because vmid gen matches
    
      enter_guest (vmid 254)
                                    kvm_arch.vttbr = <PGD>:<VMID 1>
                                    read_unlock(kvm_vmid_lock);
    
                                    enter_guest (vmid 1)
    
    Which results in running two VCPUs in the same VM with different VMIDs
    and (even worse) other VCPUs from other VMs could now allocate clashing
    VMID 254 from the new generation as long as VCPU 0 is not exiting.
    
    Attempt to solve this by making sure vttbr is updated before another CPU
    can observe the updated VMID generation.
    
    Cc: stable@vger.kernel.org
    Fixes: f0cf47d939d0 "KVM: arm/arm64: Close VMID generation race"
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4f14f446d115f022492f574bb02cff287b91915d
Author: Christoffer Dall <christoffer.dall@arm.com>
Date:   Tue Dec 11 13:23:57 2018 +0100

    KVM: arm/arm64: Fix VMID alloc race by reverting to lock-less
    
    commit fb544d1ca65a89f7a3895f7531221ceeed74ada7 upstream.
    
    We recently addressed a VMID generation race by introducing a read/write
    lock around accesses and updates to the vmid generation values.
    
    However, kvm_arch_vcpu_ioctl_run() also calls need_new_vmid_gen() but
    does so without taking the read lock.
    
    As far as I can tell, this can lead to the same kind of race:
    
      VM 0, VCPU 0                  VM 0, VCPU 1
      ------------                  ------------
      update_vttbr (vmid 254)
                                    update_vttbr (vmid 1) // roll over
                                    read_lock(kvm_vmid_lock);
                                    force_vm_exit()
      local_irq_disable
      need_new_vmid_gen == false //because vmid gen matches
    
      enter_guest (vmid 254)
                                    kvm_arch.vttbr = <PGD>:<VMID 1>
                                    read_unlock(kvm_vmid_lock);
    
                                    enter_guest (vmid 1)
    
    Which results in running two VCPUs in the same VM with different VMIDs
    and (even worse) other VCPUs from other VMs could now allocate clashing
    VMID 254 from the new generation as long as VCPU 0 is not exiting.
    
    Attempt to solve this by making sure vttbr is updated before another CPU
    can observe the updated VMID generation.
    
    Cc: stable@vger.kernel.org
    Fixes: f0cf47d939d0 "KVM: arm/arm64: Close VMID generation race"
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 26fc181e6cacacd4837da7ffe0c871134a421600
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Jan 11 06:27:35 2019 -0800

    fou, fou6: do not assume linear skbs
    
    Both gue_err() and gue6_err() incorrectly assume
    linear skbs. Fix them to use pskb_may_pull().
    
    BUG: KMSAN: uninit-value in gue6_err+0x475/0xc40 net/ipv6/fou6.c:101
    CPU: 0 PID: 18083 Comm: syz-executor1 Not tainted 5.0.0-rc1+ #7
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x173/0x1d0 lib/dump_stack.c:113
     kmsan_report+0x12e/0x2a0 mm/kmsan/kmsan.c:600
     __msan_warning+0x82/0xf0 mm/kmsan/kmsan_instr.c:313
     gue6_err+0x475/0xc40 net/ipv6/fou6.c:101
     __udp6_lib_err_encap_no_sk net/ipv6/udp.c:434 [inline]
     __udp6_lib_err_encap net/ipv6/udp.c:491 [inline]
     __udp6_lib_err+0x18d0/0x2590 net/ipv6/udp.c:522
     udplitev6_err+0x118/0x130 net/ipv6/udplite.c:27
     icmpv6_notify+0x462/0x9f0 net/ipv6/icmp.c:784
     icmpv6_rcv+0x18ac/0x3fa0 net/ipv6/icmp.c:872
     ip6_protocol_deliver_rcu+0xb5a/0x23a0 net/ipv6/ip6_input.c:394
     ip6_input_finish net/ipv6/ip6_input.c:434 [inline]
     NF_HOOK include/linux/netfilter.h:289 [inline]
     ip6_input+0x2b6/0x350 net/ipv6/ip6_input.c:443
     dst_input include/net/dst.h:450 [inline]
     ip6_rcv_finish+0x4e7/0x6d0 net/ipv6/ip6_input.c:76
     NF_HOOK include/linux/netfilter.h:289 [inline]
     ipv6_rcv+0x34b/0x3f0 net/ipv6/ip6_input.c:272
     __netif_receive_skb_one_core net/core/dev.c:4973 [inline]
     __netif_receive_skb net/core/dev.c:5083 [inline]
     process_backlog+0x756/0x10e0 net/core/dev.c:5923
     napi_poll net/core/dev.c:6346 [inline]
     net_rx_action+0x78b/0x1a60 net/core/dev.c:6412
     __do_softirq+0x53f/0x93a kernel/softirq.c:293
     do_softirq_own_stack+0x49/0x80 arch/x86/entry/entry_64.S:1039
     </IRQ>
     do_softirq kernel/softirq.c:338 [inline]
     __local_bh_enable_ip+0x16f/0x1a0 kernel/softirq.c:190
     local_bh_enable+0x36/0x40 include/linux/bottom_half.h:32
     rcu_read_unlock_bh include/linux/rcupdate.h:696 [inline]
     ip6_finish_output2+0x1d64/0x25f0 net/ipv6/ip6_output.c:121
     ip6_finish_output+0xae4/0xbc0 net/ipv6/ip6_output.c:154
     NF_HOOK_COND include/linux/netfilter.h:278 [inline]
     ip6_output+0x5ca/0x710 net/ipv6/ip6_output.c:171
     dst_output include/net/dst.h:444 [inline]
     ip6_local_out+0x164/0x1d0 net/ipv6/output_core.c:176
     ip6_send_skb+0xfa/0x390 net/ipv6/ip6_output.c:1727
     udp_v6_send_skb+0x1733/0x1d20 net/ipv6/udp.c:1169
     udpv6_sendmsg+0x424e/0x45d0 net/ipv6/udp.c:1466
     inet_sendmsg+0x54a/0x720 net/ipv4/af_inet.c:798
     sock_sendmsg_nosec net/socket.c:621 [inline]
     sock_sendmsg net/socket.c:631 [inline]
     ___sys_sendmsg+0xdb9/0x11b0 net/socket.c:2116
     __sys_sendmmsg+0x580/0xad0 net/socket.c:2211
     __do_sys_sendmmsg net/socket.c:2240 [inline]
     __se_sys_sendmmsg+0xbd/0xe0 net/socket.c:2237
     __x64_sys_sendmmsg+0x56/0x70 net/socket.c:2237
     do_syscall_64+0xbc/0xf0 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x63/0xe7
    RIP: 0033:0x457ec9
    Code: 6d b7 fb ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 48 89 f8 48 89 f7 48 89 d6 48 89 ca 4d 89 c2 4d 89 c8 4c 8b 4c 24 08 0f 05 <48> 3d 01 f0 ff ff 0f 83 3b b7 fb ff c3 66 2e 0f 1f 84 00 00 00 00
    RSP: 002b:00007f4a5204fc78 EFLAGS: 00000246 ORIG_RAX: 0000000000000133
    RAX: ffffffffffffffda RBX: 0000000000000004 RCX: 0000000000457ec9
    RDX: 00000000040001ab RSI: 0000000020000240 RDI: 0000000000000003
    RBP: 000000000073bf00 R08: 0000000000000000 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000246 R12: 00007f4a520506d4
    R13: 00000000004c4ce5 R14: 00000000004d85d8 R15: 00000000ffffffff
    
    Uninit was created at:
     kmsan_save_stack_with_flags mm/kmsan/kmsan.c:205 [inline]
     kmsan_internal_poison_shadow+0x92/0x150 mm/kmsan/kmsan.c:159
     kmsan_kmalloc+0xa6/0x130 mm/kmsan/kmsan_hooks.c:176
     kmsan_slab_alloc+0xe/0x10 mm/kmsan/kmsan_hooks.c:185
     slab_post_alloc_hook mm/slab.h:446 [inline]
     slab_alloc_node mm/slub.c:2754 [inline]
     __kmalloc_node_track_caller+0xe9e/0xff0 mm/slub.c:4377
     __kmalloc_reserve net/core/skbuff.c:140 [inline]
     __alloc_skb+0x309/0xa20 net/core/skbuff.c:208
     alloc_skb include/linux/skbuff.h:1012 [inline]
     alloc_skb_with_frags+0x1c7/0xac0 net/core/skbuff.c:5288
     sock_alloc_send_pskb+0xafd/0x10a0 net/core/sock.c:2091
     sock_alloc_send_skb+0xca/0xe0 net/core/sock.c:2108
     __ip6_append_data+0x42ed/0x5dc0 net/ipv6/ip6_output.c:1443
     ip6_append_data+0x3c2/0x650 net/ipv6/ip6_output.c:1619
     icmp6_send+0x2f5c/0x3c40 net/ipv6/icmp.c:574
     icmpv6_send+0xe5/0x110 net/ipv6/ip6_icmp.c:43
     ip6_link_failure+0x5c/0x2c0 net/ipv6/route.c:2231
     dst_link_failure include/net/dst.h:427 [inline]
     vti_xmit net/ipv4/ip_vti.c:229 [inline]
     vti_tunnel_xmit+0xf3b/0x1ea0 net/ipv4/ip_vti.c:265
     __netdev_start_xmit include/linux/netdevice.h:4382 [inline]
     netdev_start_xmit include/linux/netdevice.h:4391 [inline]
     xmit_one net/core/dev.c:3278 [inline]
     dev_hard_start_xmit+0x604/0xc40 net/core/dev.c:3294
     __dev_queue_xmit+0x2e48/0x3b80 net/core/dev.c:3864
     dev_queue_xmit+0x4b/0x60 net/core/dev.c:3897
     neigh_direct_output+0x42/0x50 net/core/neighbour.c:1511
     neigh_output include/net/neighbour.h:508 [inline]
     ip6_finish_output2+0x1d4e/0x25f0 net/ipv6/ip6_output.c:120
     ip6_finish_output+0xae4/0xbc0 net/ipv6/ip6_output.c:154
     NF_HOOK_COND include/linux/netfilter.h:278 [inline]
     ip6_output+0x5ca/0x710 net/ipv6/ip6_output.c:171
     dst_output include/net/dst.h:444 [inline]
     ip6_local_out+0x164/0x1d0 net/ipv6/output_core.c:176
     ip6_send_skb+0xfa/0x390 net/ipv6/ip6_output.c:1727
     udp_v6_send_skb+0x1733/0x1d20 net/ipv6/udp.c:1169
     udpv6_sendmsg+0x424e/0x45d0 net/ipv6/udp.c:1466
     inet_sendmsg+0x54a/0x720 net/ipv4/af_inet.c:798
     sock_sendmsg_nosec net/socket.c:621 [inline]
     sock_sendmsg net/socket.c:631 [inline]
     ___sys_sendmsg+0xdb9/0x11b0 net/socket.c:2116
     __sys_sendmmsg+0x580/0xad0 net/socket.c:2211
     __do_sys_sendmmsg net/socket.c:2240 [inline]
     __se_sys_sendmmsg+0xbd/0xe0 net/socket.c:2237
     __x64_sys_sendmmsg+0x56/0x70 net/socket.c:2237
     do_syscall_64+0xbc/0xf0 arch/x86/entry/common.c:291
     entry_SYSCALL_64_after_hwframe+0x63/0xe7
    
    Fixes: b8a51b38e4d4 ("fou, fou6: ICMP error handlers for FoU and GUE")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Stefano Brivio <sbrivio@redhat.com>
    Cc: Sabrina Dubroca <sd@queasysnail.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1a134af8ec671c57aaa61f23b40fe7f19a3c6234
Author: Christoffer Dall <christoffer.dall@arm.com>
Date:   Tue Dec 11 13:23:57 2018 +0100

    KVM: arm/arm64: Fix VMID alloc race by reverting to lock-less
    
    commit fb544d1ca65a89f7a3895f7531221ceeed74ada7 upstream.
    
    We recently addressed a VMID generation race by introducing a read/write
    lock around accesses and updates to the vmid generation values.
    
    However, kvm_arch_vcpu_ioctl_run() also calls need_new_vmid_gen() but
    does so without taking the read lock.
    
    As far as I can tell, this can lead to the same kind of race:
    
      VM 0, VCPU 0                  VM 0, VCPU 1
      ------------                  ------------
      update_vttbr (vmid 254)
                                    update_vttbr (vmid 1) // roll over
                                    read_lock(kvm_vmid_lock);
                                    force_vm_exit()
      local_irq_disable
      need_new_vmid_gen == false //because vmid gen matches
    
      enter_guest (vmid 254)
                                    kvm_arch.vttbr = <PGD>:<VMID 1>
                                    read_unlock(kvm_vmid_lock);
    
                                    enter_guest (vmid 1)
    
    Which results in running two VCPUs in the same VM with different VMIDs
    and (even worse) other VCPUs from other VMs could now allocate clashing
    VMID 254 from the new generation as long as VCPU 0 is not exiting.
    
    Attempt to solve this by making sure vttbr is updated before another CPU
    can observe the updated VMID generation.
    
    Cc: stable@vger.kernel.org
    Fixes: f0cf47d939d0 "KVM: arm/arm64: Close VMID generation race"
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d4a7e9bb74b5aaf07b89f6531c080b1130bdf019
Author: David Ahern <dsahern@gmail.com>
Date:   Sat Jan 5 07:35:04 2019 -0800

    ipv6: Take rcu_read_lock in __inet6_bind for mapped addresses
    
    I realized the last patch calls dev_get_by_index_rcu in a branch not
    holding the rcu lock. Add the calls to rcu_read_lock and rcu_read_unlock.
    
    Fixes: ec90ad334986 ("ipv6: Consider sk_bound_dev_if when binding a socket to a v4 mapped address")
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit fb544d1ca65a89f7a3895f7531221ceeed74ada7
Author: Christoffer Dall <christoffer.dall@arm.com>
Date:   Tue Dec 11 13:23:57 2018 +0100

    KVM: arm/arm64: Fix VMID alloc race by reverting to lock-less
    
    We recently addressed a VMID generation race by introducing a read/write
    lock around accesses and updates to the vmid generation values.
    
    However, kvm_arch_vcpu_ioctl_run() also calls need_new_vmid_gen() but
    does so without taking the read lock.
    
    As far as I can tell, this can lead to the same kind of race:
    
      VM 0, VCPU 0                  VM 0, VCPU 1
      ------------                  ------------
      update_vttbr (vmid 254)
                                    update_vttbr (vmid 1) // roll over
                                    read_lock(kvm_vmid_lock);
                                    force_vm_exit()
      local_irq_disable
      need_new_vmid_gen == false //because vmid gen matches
    
      enter_guest (vmid 254)
                                    kvm_arch.vttbr = <PGD>:<VMID 1>
                                    read_unlock(kvm_vmid_lock);
    
                                    enter_guest (vmid 1)
    
    Which results in running two VCPUs in the same VM with different VMIDs
    and (even worse) other VCPUs from other VMs could now allocate clashing
    VMID 254 from the new generation as long as VCPU 0 is not exiting.
    
    Attempt to solve this by making sure vttbr is updated before another CPU
    can observe the updated VMID generation.
    
    Cc: stable@vger.kernel.org
    Fixes: f0cf47d939d0 "KVM: arm/arm64: Close VMID generation race"
    Reviewed-by: Julien Thierry <julien.thierry@arm.com>
    Signed-off-by: Christoffer Dall <christoffer.dall@arm.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

commit 9765635b30756eb74e05e260ac812659c296cd28
Author: Lyude Paul <lyude@redhat.com>
Date:   Wed Nov 28 16:00:05 2018 -0500

    Revert "drm/dp_mst: Skip validating ports during destruction, just ref"
    
    This reverts commit:
    
    c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    
    ugh.
    
    In drm_dp_destroy_connector_work(), we have a pretty good chance of
    freeing the actual struct drm_dp_mst_port. However, after destroying
    things we send a hotplug through (*mgr->cbs->hotplug)(mgr) which is
    where the problems start.
    
    For i915, this calls all the way down to the fbcon probing helpers,
    which start trying to access the port in a modeset.
    
    [   45.062001] ==================================================================
    [   45.062112] BUG: KASAN: use-after-free in ex_handler_refcount+0x146/0x180
    [   45.062196] Write of size 4 at addr ffff8882b4b70968 by task kworker/3:1/53
    
    [   45.062325] CPU: 3 PID: 53 Comm: kworker/3:1 Kdump: loaded Tainted: G           O      4.20.0-rc4Lyude-Test+ #3
    [   45.062442] Hardware name: LENOVO 20BWS1KY00/20BWS1KY00, BIOS JBET71WW (1.35 ) 09/14/2018
    [   45.062554] Workqueue: events drm_dp_destroy_connector_work [drm_kms_helper]
    [   45.062641] Call Trace:
    [   45.062685]  dump_stack+0xbd/0x15a
    [   45.062735]  ? dump_stack_print_info.cold.0+0x1b/0x1b
    [   45.062801]  ? printk+0x9f/0xc5
    [   45.062847]  ? kmsg_dump_rewind_nolock+0xe4/0xe4
    [   45.062909]  ? ex_handler_refcount+0x146/0x180
    [   45.062970]  print_address_description+0x71/0x239
    [   45.063036]  ? ex_handler_refcount+0x146/0x180
    [   45.063095]  kasan_report.cold.5+0x242/0x30b
    [   45.063155]  __asan_report_store4_noabort+0x1c/0x20
    [   45.063313]  ex_handler_refcount+0x146/0x180
    [   45.063371]  ? ex_handler_clear_fs+0xb0/0xb0
    [   45.063428]  fixup_exception+0x98/0xd7
    [   45.063484]  ? raw_notifier_call_chain+0x20/0x20
    [   45.063548]  do_trap+0x6d/0x210
    [   45.063605]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063732]  do_error_trap+0xc0/0x170
    [   45.063802]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.063929]  do_invalid_op+0x3b/0x50
    [   45.063997]  ? _GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064103]  invalid_op+0x14/0x20
    [   45.064162] RIP: 0010:_GLOBAL__sub_I_65535_1_drm_dp_aux_unregister_devnode+0x2f/0x1c6 [drm_kms_helper]
    [   45.064274] Code: 00 48 c7 c7 80 fe 53 a0 48 89 e5 e8 5b 6f 26 e1 5d c3 48 8d 0e 0f 0b 48 8d 0b 0f 0b 48 8d 0f 0f 0b 48 8d 0f 0f 0b 49 8d 4d 00 <0f> 0b 49 8d 0e 0f 0b 48 8d 08 0f 0b 49 8d 4d 00 0f 0b 48 8d 0b 0f
    [   45.064569] RSP: 0018:ffff8882b789ee10 EFLAGS: 00010282
    [   45.064637] RAX: ffff8882af47ae70 RBX: ffff8882af47aa60 RCX: ffff8882b4b70968
    [   45.064723] RDX: ffff8882af47ae70 RSI: 0000000000000008 RDI: ffff8882b788bdb8
    [   45.064808] RBP: ffff8882b789ee28 R08: ffffed1056f13db4 R09: ffffed1056f13db3
    [   45.064894] R10: ffffed1056f13db3 R11: ffff8882b789ed9f R12: ffff8882af47ad28
    [   45.064980] R13: ffff8882b4b70968 R14: ffff8882acd86728 R15: ffff8882b4b75dc8
    [   45.065084]  drm_dp_mst_reset_vcpi_slots+0x12/0x80 [drm_kms_helper]
    [   45.065225]  intel_mst_disable_dp+0xda/0x180 [i915]
    [   45.065361]  intel_encoders_disable.isra.107+0x197/0x310 [i915]
    [   45.065498]  haswell_crtc_disable+0xbe/0x400 [i915]
    [   45.065622]  ? i9xx_disable_plane+0x1c0/0x3e0 [i915]
    [   45.065750]  intel_atomic_commit_tail+0x74e/0x3e60 [i915]
    [   45.065884]  ? intel_pre_plane_update+0xbc0/0xbc0 [i915]
    [   45.065968]  ? drm_atomic_helper_swap_state+0x88b/0x1d90 [drm_kms_helper]
    [   45.066054]  ? kasan_check_write+0x14/0x20
    [   45.066165]  ? i915_gem_track_fb+0x13a/0x330 [i915]
    [   45.066277]  ? i915_sw_fence_complete+0xe9/0x140 [i915]
    [   45.066406]  ? __i915_sw_fence_complete+0xc50/0xc50 [i915]
    [   45.066540]  intel_atomic_commit+0x72e/0xef0 [i915]
    [   45.066635]  ? drm_dev_dbg+0x200/0x200 [drm]
    [   45.066764]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.066898]  ? intel_atomic_commit_tail+0x3e60/0x3e60 [i915]
    [   45.067001]  drm_atomic_commit+0xc4/0xf0 [drm]
    [   45.067074]  restore_fbdev_mode_atomic+0x562/0x780 [drm_kms_helper]
    [   45.067166]  ? drm_fb_helper_debug_leave+0x690/0x690 [drm_kms_helper]
    [   45.067249]  ? kasan_check_read+0x11/0x20
    [   45.067324]  restore_fbdev_mode+0x127/0x4b0 [drm_kms_helper]
    [   45.067364]  ? kasan_check_read+0x11/0x20
    [   45.067406]  drm_fb_helper_restore_fbdev_mode_unlocked+0x164/0x200 [drm_kms_helper]
    [   45.067462]  ? drm_fb_helper_hotplug_event+0x30/0x30 [drm_kms_helper]
    [   45.067508]  ? kasan_check_write+0x14/0x20
    [   45.070360]  ? mutex_unlock+0x22/0x40
    [   45.073748]  drm_fb_helper_set_par+0xb2/0xf0 [drm_kms_helper]
    [   45.075846]  drm_fb_helper_hotplug_event.part.33+0x1cd/0x290 [drm_kms_helper]
    [   45.078088]  drm_fb_helper_hotplug_event+0x1c/0x30 [drm_kms_helper]
    [   45.082614]  intel_fbdev_output_poll_changed+0x9f/0x140 [i915]
    [   45.087069]  drm_kms_helper_hotplug_event+0x67/0x90 [drm_kms_helper]
    [   45.089319]  intel_dp_mst_hotplug+0x37/0x50 [i915]
    [   45.091496]  drm_dp_destroy_connector_work+0x510/0x6f0 [drm_kms_helper]
    [   45.093675]  ? drm_dp_update_payload_part1+0x1220/0x1220 [drm_kms_helper]
    [   45.095851]  ? kasan_check_write+0x14/0x20
    [   45.098473]  ? kasan_check_read+0x11/0x20
    [   45.101155]  ? strscpy+0x17c/0x530
    [   45.103808]  ? __switch_to_asm+0x34/0x70
    [   45.106456]  ? syscall_return_via_sysret+0xf/0x7f
    [   45.109711]  ? read_word_at_a_time+0x20/0x20
    [   45.113138]  ? __switch_to_asm+0x40/0x70
    [   45.116529]  ? __switch_to_asm+0x34/0x70
    [   45.119891]  ? __switch_to_asm+0x40/0x70
    [   45.123224]  ? __switch_to_asm+0x34/0x70
    [   45.126540]  ? __switch_to_asm+0x34/0x70
    [   45.129824]  process_one_work+0x88d/0x15d0
    [   45.133172]  ? pool_mayday_timeout+0x850/0x850
    [   45.136459]  ? pci_mmcfg_check_reserved+0x110/0x128
    [   45.139739]  ? wake_q_add+0xb0/0xb0
    [   45.143010]  ? check_preempt_wakeup+0x652/0x1050
    [   45.146304]  ? worker_enter_idle+0x29e/0x740
    [   45.149589]  ? __schedule+0x1ec0/0x1ec0
    [   45.152937]  ? kasan_check_read+0x11/0x20
    [   45.156179]  ? _raw_spin_lock_irq+0xa3/0x130
    [   45.159382]  ? _raw_read_unlock_irqrestore+0x30/0x30
    [   45.162542]  ? kasan_check_write+0x14/0x20
    [   45.165657]  worker_thread+0x1a5/0x1470
    [   45.168725]  ? set_load_weight+0x2e0/0x2e0
    [   45.171755]  ? process_one_work+0x15d0/0x15d0
    [   45.174806]  ? __switch_to_asm+0x34/0x70
    [   45.177645]  ? __switch_to_asm+0x40/0x70
    [   45.180323]  ? __switch_to_asm+0x34/0x70
    [   45.182936]  ? __switch_to_asm+0x40/0x70
    [   45.185539]  ? __switch_to_asm+0x34/0x70
    [   45.188100]  ? __switch_to_asm+0x40/0x70
    [   45.190628]  ? __schedule+0x7d4/0x1ec0
    [   45.193143]  ? save_stack+0xa9/0xd0
    [   45.195632]  ? kasan_check_write+0x10/0x20
    [   45.198162]  ? kasan_kmalloc+0xc4/0xe0
    [   45.200609]  ? kmem_cache_alloc_trace+0xdd/0x190
    [   45.203046]  ? kthread+0x9f/0x3b0
    [   45.205470]  ? ret_from_fork+0x35/0x40
    [   45.207876]  ? unwind_next_frame+0x43/0x50
    [   45.210273]  ? __save_stack_trace+0x82/0x100
    [   45.212658]  ? deactivate_slab.isra.67+0x3d4/0x580
    [   45.215026]  ? default_wake_function+0x35/0x50
    [   45.217399]  ? kasan_check_read+0x11/0x20
    [   45.219825]  ? _raw_spin_lock_irqsave+0xae/0x140
    [   45.222174]  ? __lock_text_start+0x8/0x8
    [   45.224521]  ? replenish_dl_entity.cold.62+0x4f/0x4f
    [   45.226868]  ? __kthread_parkme+0x87/0xf0
    [   45.229200]  kthread+0x2f7/0x3b0
    [   45.231557]  ? process_one_work+0x15d0/0x15d0
    [   45.233923]  ? kthread_park+0x120/0x120
    [   45.236249]  ret_from_fork+0x35/0x40
    
    [   45.240875] Allocated by task 242:
    [   45.243136]  save_stack+0x43/0xd0
    [   45.245385]  kasan_kmalloc+0xc4/0xe0
    [   45.247597]  kmem_cache_alloc_trace+0xdd/0x190
    [   45.249793]  drm_dp_add_port+0x1e0/0x2170 [drm_kms_helper]
    [   45.252000]  drm_dp_send_link_address+0x4a7/0x740 [drm_kms_helper]
    [   45.254389]  drm_dp_check_and_send_link_address+0x1a7/0x210 [drm_kms_helper]
    [   45.256803]  drm_dp_mst_link_probe_work+0x6f/0xb0 [drm_kms_helper]
    [   45.259200]  process_one_work+0x88d/0x15d0
    [   45.261597]  worker_thread+0x1a5/0x1470
    [   45.264038]  kthread+0x2f7/0x3b0
    [   45.266371]  ret_from_fork+0x35/0x40
    
    [   45.270937] Freed by task 53:
    [   45.273170]  save_stack+0x43/0xd0
    [   45.275382]  __kasan_slab_free+0x139/0x190
    [   45.277604]  kasan_slab_free+0xe/0x10
    [   45.279826]  kfree+0x99/0x1b0
    [   45.282044]  drm_dp_free_mst_port+0x4a/0x60 [drm_kms_helper]
    [   45.284330]  drm_dp_destroy_connector_work+0x43e/0x6f0 [drm_kms_helper]
    [   45.286660]  process_one_work+0x88d/0x15d0
    [   45.288934]  worker_thread+0x1a5/0x1470
    [   45.291231]  kthread+0x2f7/0x3b0
    [   45.293547]  ret_from_fork+0x35/0x40
    
    [   45.298206] The buggy address belongs to the object at ffff8882b4b70968
                    which belongs to the cache kmalloc-2k of size 2048
    [   45.303047] The buggy address is located 0 bytes inside of
                    2048-byte region [ffff8882b4b70968, ffff8882b4b71168)
    [   45.308010] The buggy address belongs to the page:
    [   45.310477] page:ffffea000ad2dc00 count:1 mapcount:0 mapping:ffff8882c080cf40 index:0x0 compound_mapcount: 0
    [   45.313051] flags: 0x8000000000010200(slab|head)
    [   45.315635] raw: 8000000000010200 ffffea000aac2808 ffffea000abe8608 ffff8882c080cf40
    [   45.318300] raw: 0000000000000000 00000000000d000d 00000001ffffffff 0000000000000000
    [   45.320966] page dumped because: kasan: bad access detected
    
    [   45.326312] Memory state around the buggy address:
    [   45.329085]  ffff8882b4b70800: fb fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.331845]  ffff8882b4b70880: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [   45.334584] >ffff8882b4b70900: fc fc fc fc fc fc fc fc fc fc fc fc fc fb fb fb
    [   45.337302]                                                           ^
    [   45.340061]  ffff8882b4b70980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.342910]  ffff8882b4b70a00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [   45.345748] ==================================================================
    
    So, this definitely isn't a fix that we want. This being said; there's
    no real easy fix for this problem because of some of the catch-22's of
    the MST helpers current design. For starters; we always need to validate
    a port with drm_dp_get_validated_port_ref(), but validation relies on
    the lifetime of the port in the actual topology. So once the port is
    gone, it can't be validated again.
    
    If we were to try to make the payload helpers not use port validation,
    then we'd cause another problem: if the port isn't validated, it could
    be freed and we'd just start causing more KASAN issues. There are
    already hacks that attempt to workaround this in
    drm_dp_mst_destroy_connector_work() by re-initializing the kref so that
    it can be used again and it's memory can be freed once the VCPI helpers
    finish removing the port's respective payloads. But none of these really
    do anything helpful since the port still can't be validated since it's
    gone from the topology. Also, that workaround is immensely confusing to
    read through.
    
    What really needs to be done in order to fix this is to teach DRM how to
    track the lifetime of the structs for MST ports and branch devices
    separately from their lifetime in the actual topology. Simply put; this
    means having two different krefs-one that removes the port/branch device
    from the topology, and one that finally calls kfree(). This would let us
    simplify things, since we'd now be able to keep ports around without
    having to keep them in the topology at the same time, which is exactly
    what we need in order to teach our VCPI helpers to only validate ports
    when it's actually necessary without running the risk of trying to use
    unallocated memory.
    
    Such a fix is on it's way, but for now let's play it safe and just
    revert this. If this bug has been around for well over a year, we can
    wait a little while to get an actual proper fix here.
    
    Signed-off-by: Lyude Paul <lyude@redhat.com>
    Fixes: c54c7374ff44 ("drm/dp_mst: Skip validating ports during destruction, just ref")
    Cc: Daniel Vetter <daniel@ffwll.ch>
    Cc: Sean Paul <sean@poorly.run>
    Cc: Jerry Zuo <Jerry.Zuo@amd.com>
    Cc: Harry Wentland <Harry.Wentland@amd.com>
    Cc: stable@vger.kernel.org # v4.6+
    Acked-by: Sean Paul <sean@poorly.run>
    Link: https://patchwork.freedesktop.org/patch/msgid/20181128210005.24434-1-lyude@redhat.com

commit 97b8ca659ab410c6955da052592959244d041fa8
Author: Daniel Wagner <daniel.wagner@siemens.com>
Date:   Wed Oct 31 09:14:58 2018 +0100

    x86/kconfig: Fall back to ticket spinlocks
    
    Sebastian writes:
    
    """
    We reproducibly observe cache line starvation on a Core2Duo E6850 (2
    cores), a i5-6400 SKL (4 cores) and on a NXP LS2044A ARM Cortex-A72 (4
    cores).
    
    The problem can be triggered with a v4.9-RT kernel by starting
    
        cyclictest -S -p98 -m  -i2000 -b 200
    
    and as "load"
    
        stress-ng --ptrace 4
    
    The reported maximal latency is usually less than 60us. If the problem
    triggers then values around 400us, 800us or even more are reported. The
    upperlimit is the -i parameter.
    
    Reproduction with 4.9-RT is almost immediate on Core2Duo, ARM64 and SKL,
    but it took 7.5 hours to trigger on v4.14-RT on the Core2Duo.
    
    Instrumentation show always the picture:
    
    CPU0                                         CPU1
    => do_syscall_64                              => do_syscall_64
    => SyS_ptrace                                   => syscall_slow_exit_work
    => ptrace_check_attach                          => ptrace_do_notify / rt_read_unlock
    => wait_task_inactive                              rt_spin_lock_slowunlock()
       -> while task_running()                         __rt_mutex_unlock_common()
      /   check_task_state()                           mark_wakeup_next_waiter()
     |     raw_spin_lock_irq(&p->pi_lock);             raw_spin_lock(&current->pi_lock);
     |     .                                               .
     |     raw_spin_unlock_irq(&p->pi_lock);               .
      \  cpu_relax()                                       .
       -                                                   .
        *IRQ*                                          <lock acquired>
    
    In the error case we observe that the while() loop is repeated more than
    5000 times which indicates that the pi_lock can be acquired. CPU1 on the
    other side does not make progress waiting for the same lock with interrupts
    disabled.
    
    This continues until an IRQ hits CPU0. Once CPU0 starts processing the IRQ
    the other CPU is able to acquire pi_lock and the situation relaxes.
    """
    
    This matches with the observeration for v4.4-rt on a Core2Duo E6850:
    
    CPU 0:
    
    - no progress for a very long time in rt_mutex_dequeue_pi):
    
    stress-n-1931    0d..11  5060.891219: function:             __try_to_take_rt_mutex
    stress-n-1931    0d..11  5060.891219: function:                rt_mutex_dequeue
    stress-n-1931    0d..21  5060.891220: function:                rt_mutex_enqueue_pi
    stress-n-1931    0....2  5060.891220: signal_generate:      sig=17 errno=0 code=262148 comm=stress-ng-ptrac pid=1928 grp=1 res=1
    stress-n-1931    0d..21  5060.894114: function:             rt_mutex_dequeue_pi
    stress-n-1931    0d.h11  5060.894115: local_timer_entry:    vector=239
    
    CPU 1:
    
    - IRQ at 5060.894114 on CPU 1 followed by the IRQ on CPU 0
    
    stress-n-1928    1....0  5060.891215: sys_enter:            NR 101 (18, 78b, 0, 0, 17, 788)
    stress-n-1928    1d..11  5060.891216: function:             __try_to_take_rt_mutex
    stress-n-1928    1d..21  5060.891216: function:                rt_mutex_enqueue_pi
    stress-n-1928    1d..21  5060.891217: function:             rt_mutex_dequeue_pi
    stress-n-1928    1....1  5060.891217: function:             rt_mutex_adjust_prio
    stress-n-1928    1d..11  5060.891218: function:                __rt_mutex_adjust_prio
    stress-n-1928    1d.h10  5060.894114: local_timer_entry:    vector=239
    
    Thomas writes:
    
    """
    This has nothing to do with RT. RT is merily exposing the
    problem in an observable way. The same issue happens with upstream, it's
    harder to trigger and it's harder to observe for obvious reasons.
    
    If you read through the discussions [see the links below] then you
    really see that there is an upstream issue with the x86 qrlock
    implementation and Peter has posted fixes which resolve it, both at
    the practical and the theoretical level.
    """
    
    Backporting all qspinlock related patches is very likely to introduce
    regressions on v4.4. Therefore, the recommended solution by Peter and
    Thomas is to drop back to ticket spinlocks for v4.4.
    
    Link :https://lkml.kernel.org/r/20180921120226.6xjgr4oiho22ex75@linutronix.de
    Link: https://lkml.kernel.org/r/20180926110117.405325143@infradead.org
    Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Daniel Wagner <daniel.wagner@siemens.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7113a9af08c596c62e819857c9f9a39f7de0403e
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jul 19 10:27:13 2018 +0800

    net: caif: Add a missing rcu_read_unlock() in caif_flow_cb
    
    commit 64119e05f7b31e83e2555f6782e6cdc8f81c63f4 upstream.
    
    Add a missing rcu_read_unlock in the error path
    
    Fixes: c95567c80352 ("caif: added check for potential null return")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 05f415715ce45da07a0b1a5eac842765b733157f
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Tue Oct 16 04:12:58 2018 -0700

    rcu: Speed up expedited GPs when interrupting RCU reader
    
    In PREEMPT kernels, an expedited grace period might send an IPI to a
    CPU that is executing an RCU read-side critical section.  In that case,
    it would be nice if the rcu_read_unlock() directly interacted with the
    RCU core code to immediately report the quiescent state.  And this does
    happen in the case where the reader has been preempted.  But it would
    also be a nice performance optimization if immediate reporting also
    happened in the preemption-free case.
    
    This commit therefore adds an ->exp_hint field to the task_struct structure's
    ->rcu_read_unlock_special field.  The IPI handler sets this hint when
    it has interrupted an RCU read-side critical section, and this causes
    the outermost rcu_read_unlock() call to invoke rcu_read_unlock_special(),
    which, if preemption is enabled, reports the quiescent state immediately.
    If preemption is disabled, then the report is required to be deferred
    until preemption (or bottom halves or interrupts or whatever) is re-enabled.
    
    Because this is a hint, it does nothing for more complicated cases.  For
    example, if the IPI interrupts an RCU reader, but interrupts are disabled
    across the rcu_read_unlock(), but another rcu_read_lock() is executed
    before interrupts are re-enabled, the hint will already have been cleared.
    If you do crazy things like this, reporting will be deferred until some
    later RCU_SOFTIRQ handler, context switch, cond_resched(), or similar.
    
    Reported-by: Joel Fernandes <joel@joelfernandes.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>
    Acked-by: Joel Fernandes (Google) <joel@joelfernandes.org>

commit 97562c018135a9d01c59bd3bf95a9458548b79e2
Author: Paul E. McKenney <paulmck@linux.ibm.com>
Date:   Mon Oct 15 10:54:13 2018 -0700

    doc: RCU scheduler spinlock rcu_read_unlock() restriction remains
    
    Given RCU flavor consolidation, when rcu_read_unlock() is invoked with
    interrupts disabled, the reporting of the corresponding quiescent state is
    deferred until interrupts are re-enabled.  There was therefore some hope
    that this would allow dropping the restriction against holding scheduler
    spinlocks across an rcu_read_unlock() without disabling interrupts across
    the entire corresponding RCU read-side critical section.  Unfortunately,
    the need to quickly provide a quiescent state to expedited grace periods
    sometimes requires a call to raise_softirq() during rcu_read_unlock()
    execution.  Because raise_softirq() can sometimes acquire the scheduler
    spinlocks, the restriction must remain in effect.  This commit therefore
    updates the RCU requirements documentation accordingly.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 93eb14201fc690687c2d94865bc38c1aa23356b8
Author: Joel Fernandes (Google) <joel@joelfernandes.org>
Date:   Mon Oct 8 18:33:41 2018 -0700

    doc: Make reader aware of rcu_dereference_protected
    
    The whatisRCU.txt document says rcu_dereference() cannot be used
    outside of rcu_read_lock() protected sections.  The commit adds a
    mention of rcu_dereference_protected(), so that the new reader knows
    that this API can be used to avoid update-side use of rcu_read_lock()
    and rcu_read_unlock().
    
    Cc: tytso@mit.edu
    Suggested-by: tytso@mit.edu
    Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
    [ paulmck: Update wording, including further feedback from Joel. ]
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 97d65c1b6e73e1e8ade19713a981bc55003bd798
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jul 6 15:31:46 2017 +0100

    Btrfs: incremental send, fix invalid memory access
    
    [ Upstream commit 24e52b11e0ca788513b945a87b57cc0522a92933 ]
    
    When doing an incremental send, while processing an extent that changed
    between the parent and send snapshots and that extent was an inline extent
    in the parent snapshot, it's possible to access a memory region beyond
    the end of leaf if the inline extent is very small and it is the first
    item in a leaf.
    
    An example scenario is described below.
    
    The send snapshot has the following leaf:
    
     leaf 33865728 items 33 free space 773 generation 46 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            (...)
            item 14 key (335 EXTENT_DATA 0) itemoff 3052 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 12791808 nr 4096
                    extent data offset 0 nr 4096 ram 4096
                    extent compression 0 (none)
            item 15 key (335 EXTENT_DATA 8192) itemoff 2999 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 138170368 nr 225280
                    extent data offset 0 nr 225280 ram 225280
                    extent compression 0 (none)
            (...)
    
    And the parent snapshot has the following leaf:
    
     leaf 31272960 items 17 free space 17 generation 31 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            item 0 key (335 EXTENT_DATA 0) itemoff 3951 itemsize 44
                    generation 31 type 0 (inline)
                    inline extent data size 23 ram_bytes 613 compression 1 (zlib)
            (...)
    
    When computing the send stream, it is detected that the extent of inode
    335, at file offset 0, and at fs/btrfs/send.c:is_extent_unchanged() we
    grab the leaf from the parent snapshot and access the inline extent item.
    However, before jumping to the 'out' label, we access the 'offset' and
    'disk_bytenr' fields of the extent item, which should not be done for
    inline extents since the inlined data starts at the offset of the
    'disk_bytenr' field and can be very small. For example accessing the
    'offset' field of the file extent item results in the following trace:
    
    [  599.705368] general protection fault: 0000 [#1] PREEMPT SMP
    [  599.706296] Modules linked in: btrfs psmouse i2c_piix4 ppdev acpi_cpufreq serio_raw parport_pc i2c_core evdev tpm_tis tpm_tis_core sg pcspkr parport tpm button su$
    [  599.709340] CPU: 7 PID: 5283 Comm: btrfs Not tainted 4.10.0-rc8-btrfs-next-46+ #1
    [  599.709340] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  599.709340] task: ffff88023eedd040 task.stack: ffffc90006658000
    [  599.709340] RIP: 0010:read_extent_buffer+0xdb/0xf4 [btrfs]
    [  599.709340] RSP: 0018:ffffc9000665ba00 EFLAGS: 00010286
    [  599.709340] RAX: db73880000000000 RBX: 0000000000000000 RCX: 0000000000000001
    [  599.709340] RDX: ffffc9000665ba60 RSI: db73880000000000 RDI: ffffc9000665ba5f
    [  599.709340] RBP: ffffc9000665ba30 R08: 0000000000000001 R09: ffff88020dc5e098
    [  599.709340] R10: 0000000000001000 R11: 0000160000000000 R12: 6db6db6db6db6db7
    [  599.709340] R13: ffff880000000000 R14: 0000000000000000 R15: ffff88020dc5e088
    [  599.709340] FS:  00007f519555a8c0(0000) GS:ffff88023f3c0000(0000) knlGS:0000000000000000
    [  599.709340] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  599.709340] CR2: 00007f1411afd000 CR3: 0000000235f8e000 CR4: 00000000000006e0
    [  599.709340] Call Trace:
    [  599.709340]  btrfs_get_token_64+0x93/0xce [btrfs]
    [  599.709340]  ? printk+0x48/0x50
    [  599.709340]  btrfs_get_64+0xb/0xd [btrfs]
    [  599.709340]  process_extent+0x3a1/0x1106 [btrfs]
    [  599.709340]  ? btree_read_extent_buffer_pages+0x5/0xef [btrfs]
    [  599.709340]  changed_cb+0xb03/0xb3d [btrfs]
    [  599.709340]  ? btrfs_get_token_32+0x7a/0xcc [btrfs]
    [  599.709340]  btrfs_compare_trees+0x432/0x53d [btrfs]
    [  599.709340]  ? process_extent+0x1106/0x1106 [btrfs]
    [  599.709340]  btrfs_ioctl_send+0x960/0xe26 [btrfs]
    [  599.709340]  btrfs_ioctl+0x181b/0x1fed [btrfs]
    [  599.709340]  ? trace_hardirqs_on_caller+0x150/0x1ac
    [  599.709340]  vfs_ioctl+0x21/0x38
    [  599.709340]  ? vfs_ioctl+0x21/0x38
    [  599.709340]  do_vfs_ioctl+0x611/0x645
    [  599.709340]  ? rcu_read_unlock+0x5b/0x5d
    [  599.709340]  ? __fget+0x6d/0x79
    [  599.709340]  SyS_ioctl+0x57/0x7b
    [  599.709340]  entry_SYSCALL_64_fastpath+0x18/0xad
    [  599.709340] RIP: 0033:0x7f51945eec47
    [  599.709340] RSP: 002b:00007ffc21c13e98 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
    [  599.709340] RAX: ffffffffffffffda RBX: ffffffff81096459 RCX: 00007f51945eec47
    [  599.709340] RDX: 00007ffc21c13f20 RSI: 0000000040489426 RDI: 0000000000000004
    [  599.709340] RBP: ffffc9000665bf98 R08: 00007f519450d700 R09: 00007f519450d700
    [  599.709340] R10: 00007f519450d9d0 R11: 0000000000000202 R12: 0000000000000046
    [  599.709340] R13: ffffc9000665bf78 R14: 0000000000000000 R15: 00007f5195574040
    [  599.709340]  ? trace_hardirqs_off_caller+0x43/0xb1
    [  599.709340] Code: 29 f0 49 39 d8 4c 0f 47 c3 49 03 81 58 01 00 00 44 89 c1 4c 01 c2 4c 29 c3 48 c1 f8 03 49 0f af c4 48 c1 e0 0c 4c 01 e8 48 01 c6 <f3> a4 31 f6 4$
    [  599.709340] RIP: read_extent_buffer+0xdb/0xf4 [btrfs] RSP: ffffc9000665ba00
    [  599.762057] ---[ end trace fe00d7af61b9f49e ]---
    
    This is because the 'offset' field starts at an offset of 37 bytes
    (offsetof(struct btrfs_file_extent_item, offset)), has a length of 8
    bytes and therefore attemping to read it causes a 1 byte access beyond
    the end of the leaf, as the first item's content in a leaf is located
    at the tail of the leaf, the item size is 44 bytes and the offset of
    that field plus its length (37 + 8 = 45) goes beyond the item's size
    by 1 byte.
    
    So fix this by accessing the 'offset' and 'disk_bytenr' fields after
    jumping to the 'out' label if we are processing an inline extent. We
    move the reading operation of the 'disk_bytenr' field too because we
    have the same problem as for the 'offset' field explained above when
    the inline data is less then 8 bytes. The access to the 'generation'
    field is also moved but just for the sake of grouping access to all
    the fields.
    
    Fixes: e1cbfd7bf6da ("Btrfs: send, fix file hole not being preserved due to inline extent")
    Cc: <stable@vger.kernel.org>  # v4.12+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2185dbac9e81c1b757bc41bb77e7dd97edbf78e1
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Aug 23 10:43:02 2017 -0400

    tipc: Fix tipc_sk_reinit handling of -EAGAIN
    
    [ Upstream commit 6c7e983b220f89e03286dc70a41c7ef3a8b409df ]
    
    In 9dbbfb0ab6680c6a85609041011484e6658e7d3c function tipc_sk_reinit
    had additional logic added to loop in the event that function
    rhashtable_walk_next() returned -EAGAIN. No worries.
    
    However, if rhashtable_walk_start returns -EAGAIN, it does "continue",
    and therefore skips the call to rhashtable_walk_stop(). That has
    the effect of calling rcu_read_lock() without its paired call to
    rcu_read_unlock(). Since rcu_read_lock() may be nested, the problem
    may not be apparent for a while, especially since resize events may
    be rare. But the comments to rhashtable_walk_start() state:
    
     * ...Note that we take the RCU lock in all
     * cases including when we return an error.  So you must always call
     * rhashtable_walk_stop to clean up.
    
    This patch replaces the continue with a goto and label to ensure a
    matching call to rhashtable_walk_stop().
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 414fb21bd5e0b72ff76045e3b76cea9629b47ea0
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Tue Nov 29 13:09:45 2016 +0100

    l2tp: hold socket before dropping lock in l2tp_ip{, 6}_recv()
    
    [ Upstream commit a3c18422a4b4e108bcf6a2328f48867e1003fd95 ]
    
    Socket must be held while under the protection of the l2tp lock; there
    is no guarantee that sk remains valid after the read_unlock_bh() call.
    
    Same issue for l2tp_ip and l2tp_ip6.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit df26890c34710d79f47601f6399e5fd90c2d0860
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jan 22 22:47:14 2015 -0800

    rcu: Clear need_qs flag to prevent splat
    
    [ Upstream commit c0135d07b013fa8f7ba9ec91b4369c372e6a28cb ]
    
    If the scheduling-clock interrupt sets the current tasks need_qs flag,
    but if the current CPU passes through a quiescent state in the meantime,
    then rcu_preempt_qs() will fail to clear the need_qs flag, which can fool
    RCU into thinking that additional rcu_read_unlock_special() processing
    is needed.  This commit therefore clears the need_qs flag before checking
    for additional processing.
    
    For this problem to occur, we need rcu_preempt_data.passed_quiesce equal
    to true and current->rcu_read_unlock_special.b.need_qs also equal to true.
    This condition can occur as follows:
    
    1.      CPU 0 is aware of the current preemptible RCU grace period,
            but has not yet passed through a quiescent state.  Among other
            things, this means that rcu_preempt_data.passed_quiesce is false.
    
    2.      Task A running on CPU 0 enters a preemptible RCU read-side
            critical section.
    
    3.      CPU 0 takes a scheduling-clock interrupt, which notices the
            RCU read-side critical section and the need for a quiescent state,
            and thus sets current->rcu_read_unlock_special.b.need_qs to true.
    
    4.      Task A is preempted, enters the scheduler, eventually invoking
            rcu_preempt_note_context_switch() which in turn invokes
            rcu_preempt_qs().
    
            Because rcu_preempt_data.passed_quiesce is false,
            control enters the body of the "if" statement, which sets
            rcu_preempt_data.passed_quiesce to true.
    
    5.      At this point, CPU 0 takes an interrupt.  The interrupt
            handler contains an RCU read-side critical section, and
            the rcu_read_unlock() notes that current->rcu_read_unlock_special
            is nonzero, and thus invokes rcu_read_unlock_special().
    
    6.      Once in rcu_read_unlock_special(), the fact that
            current->rcu_read_unlock_special.b.need_qs is true becomes
            apparent, so rcu_read_unlock_special() invokes rcu_preempt_qs().
            Recursively, given that we interrupted out of that same
            function in the preceding step.
    
    7.      Because rcu_preempt_data.passed_quiesce is now true,
            rcu_preempt_qs() does nothing, and simply returns.
    
    8.      Upon return to rcu_read_unlock_special(), it is noted that
            current->rcu_read_unlock_special is still nonzero (because
            the interrupted rcu_preempt_qs() had not yet gotten around
            to clearing current->rcu_read_unlock_special.b.need_qs).
    
    9.      Execution proceeds to the WARN_ON_ONCE(), which notes that
            we are in an interrupt handler and thus duly splats.
    
    The solution, as noted above, is to make rcu_read_unlock_special()
    clear out current->rcu_read_unlock_special.b.need_qs after calling
    rcu_preempt_qs().  The interrupted rcu_preempt_qs() will clear it again,
    but this is harmless.  The worst that happens is that we clobber another
    attempt to set this field, but this is not a problem because we just
    got done reporting a quiescent state.
    
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Fix embarrassing build bug noted by Sasha Levin. ]
    Tested-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 706a680f49f47a25b8fba4d9e001a9d660ea1974
Author: Yu Zhao <yuzhao@google.com>
Date:   Fri Sep 28 17:04:30 2018 -0600

    net/usb: cancel pending work when unbinding smsc75xx
    
    [ Upstream commit f7b2a56e1f3dcbdb4cf09b2b63e859ffe0e09df8 ]
    
    Cancel pending work before freeing smsc75xx private data structure
    during binding. This fixes the following crash in the driver:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000050
    IP: mutex_lock+0x2b/0x3f
    <snipped>
    Workqueue: events smsc75xx_deferred_multicast_write [smsc75xx]
    task: ffff8caa83e85700 task.stack: ffff948b80518000
    RIP: 0010:mutex_lock+0x2b/0x3f
    <snipped>
    Call Trace:
     smsc75xx_deferred_multicast_write+0x40/0x1af [smsc75xx]
     process_one_work+0x18d/0x2fc
     worker_thread+0x1a2/0x269
     ? pr_cont_work+0x58/0x58
     kthread+0xfa/0x10a
     ? pr_cont_work+0x58/0x58
     ? rcu_read_unlock_sched_notrace+0x48/0x48
     ret_from_fork+0x22/0x40
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 492a81318e8cf41f18ad6845152b54f4a3387556
Author: Yu Zhao <yuzhao@google.com>
Date:   Thu Sep 27 17:05:04 2018 -0600

    cfg80211: fix use-after-free in reg_process_hint()
    
    [ Upstream commit 1db58529454742f67ebd96e3588315e880b72837 ]
    
    reg_process_hint_country_ie() can free regulatory_request and return
    REG_REQ_ALREADY_SET. We shouldn't use regulatory_request after it's
    called. KASAN error was observed when this happens.
    
    BUG: KASAN: use-after-free in reg_process_hint+0x839/0x8aa [cfg80211]
    Read of size 4 at addr ffff8800c430d434 by task kworker/1:3/89
    <snipped>
    Workqueue: events reg_todo [cfg80211]
    Call Trace:
     dump_stack+0xc1/0x10c
     ? _atomic_dec_and_lock+0x1ad/0x1ad
     ? _raw_spin_lock_irqsave+0xa0/0xd2
     print_address_description+0x86/0x26f
     ? reg_process_hint+0x839/0x8aa [cfg80211]
     kasan_report+0x241/0x29b
     reg_process_hint+0x839/0x8aa [cfg80211]
     reg_todo+0x204/0x5b9 [cfg80211]
     process_one_work+0x55f/0x8d0
     ? worker_detach_from_pool+0x1b5/0x1b5
     ? _raw_spin_unlock_irq+0x65/0xdd
     ? _raw_spin_unlock_irqrestore+0xf3/0xf3
     worker_thread+0x5dd/0x841
     ? kthread_parkme+0x1d/0x1d
     kthread+0x270/0x285
     ? pr_cont_work+0xe3/0xe3
     ? rcu_read_unlock_sched_notrace+0xca/0xca
     ret_from_fork+0x22/0x40
    
    Allocated by task 2718:
     set_track+0x63/0xfa
     __kmalloc+0x119/0x1ac
     regulatory_hint_country_ie+0x38/0x329 [cfg80211]
     __cfg80211_connect_result+0x854/0xadd [cfg80211]
     cfg80211_rx_assoc_resp+0x3bc/0x4f0 [cfg80211]
    smsc95xx v1.0.6
     ieee80211_sta_rx_queued_mgmt+0x1803/0x7ed5 [mac80211]
     ieee80211_iface_work+0x411/0x696 [mac80211]
     process_one_work+0x55f/0x8d0
     worker_thread+0x5dd/0x841
     kthread+0x270/0x285
     ret_from_fork+0x22/0x40
    
    Freed by task 89:
     set_track+0x63/0xfa
     kasan_slab_free+0x6a/0x87
     kfree+0xdc/0x470
     reg_process_hint+0x31e/0x8aa [cfg80211]
     reg_todo+0x204/0x5b9 [cfg80211]
     process_one_work+0x55f/0x8d0
     worker_thread+0x5dd/0x841
     kthread+0x270/0x285
     ret_from_fork+0x22/0x40
    <snipped>
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2dbf48f8ffb3af73628c67f7289112a56ffe8a69
Author: Yu Zhao <yuzhao@google.com>
Date:   Thu Sep 27 17:05:04 2018 -0600

    cfg80211: fix use-after-free in reg_process_hint()
    
    [ Upstream commit 1db58529454742f67ebd96e3588315e880b72837 ]
    
    reg_process_hint_country_ie() can free regulatory_request and return
    REG_REQ_ALREADY_SET. We shouldn't use regulatory_request after it's
    called. KASAN error was observed when this happens.
    
    BUG: KASAN: use-after-free in reg_process_hint+0x839/0x8aa [cfg80211]
    Read of size 4 at addr ffff8800c430d434 by task kworker/1:3/89
    <snipped>
    Workqueue: events reg_todo [cfg80211]
    Call Trace:
     dump_stack+0xc1/0x10c
     ? _atomic_dec_and_lock+0x1ad/0x1ad
     ? _raw_spin_lock_irqsave+0xa0/0xd2
     print_address_description+0x86/0x26f
     ? reg_process_hint+0x839/0x8aa [cfg80211]
     kasan_report+0x241/0x29b
     reg_process_hint+0x839/0x8aa [cfg80211]
     reg_todo+0x204/0x5b9 [cfg80211]
     process_one_work+0x55f/0x8d0
     ? worker_detach_from_pool+0x1b5/0x1b5
     ? _raw_spin_unlock_irq+0x65/0xdd
     ? _raw_spin_unlock_irqrestore+0xf3/0xf3
     worker_thread+0x5dd/0x841
     ? kthread_parkme+0x1d/0x1d
     kthread+0x270/0x285
     ? pr_cont_work+0xe3/0xe3
     ? rcu_read_unlock_sched_notrace+0xca/0xca
     ret_from_fork+0x22/0x40
    
    Allocated by task 2718:
     set_track+0x63/0xfa
     __kmalloc+0x119/0x1ac
     regulatory_hint_country_ie+0x38/0x329 [cfg80211]
     __cfg80211_connect_result+0x854/0xadd [cfg80211]
     cfg80211_rx_assoc_resp+0x3bc/0x4f0 [cfg80211]
    smsc95xx v1.0.6
     ieee80211_sta_rx_queued_mgmt+0x1803/0x7ed5 [mac80211]
     ieee80211_iface_work+0x411/0x696 [mac80211]
     process_one_work+0x55f/0x8d0
     worker_thread+0x5dd/0x841
     kthread+0x270/0x285
     ret_from_fork+0x22/0x40
    
    Freed by task 89:
     set_track+0x63/0xfa
     kasan_slab_free+0x6a/0x87
     kfree+0xdc/0x470
     reg_process_hint+0x31e/0x8aa [cfg80211]
     reg_todo+0x204/0x5b9 [cfg80211]
     process_one_work+0x55f/0x8d0
     worker_thread+0x5dd/0x841
     kthread+0x270/0x285
     ret_from_fork+0x22/0x40
    <snipped>
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0aa059ea2dacc7383052f9b2380edd3964f23033
Author: Yu Zhao <yuzhao@google.com>
Date:   Fri Sep 28 17:04:30 2018 -0600

    net/usb: cancel pending work when unbinding smsc75xx
    
    [ Upstream commit f7b2a56e1f3dcbdb4cf09b2b63e859ffe0e09df8 ]
    
    Cancel pending work before freeing smsc75xx private data structure
    during binding. This fixes the following crash in the driver:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000050
    IP: mutex_lock+0x2b/0x3f
    <snipped>
    Workqueue: events smsc75xx_deferred_multicast_write [smsc75xx]
    task: ffff8caa83e85700 task.stack: ffff948b80518000
    RIP: 0010:mutex_lock+0x2b/0x3f
    <snipped>
    Call Trace:
     smsc75xx_deferred_multicast_write+0x40/0x1af [smsc75xx]
     process_one_work+0x18d/0x2fc
     worker_thread+0x1a2/0x269
     ? pr_cont_work+0x58/0x58
     kthread+0xfa/0x10a
     ? pr_cont_work+0x58/0x58
     ? rcu_read_unlock_sched_notrace+0x48/0x48
     ret_from_fork+0x22/0x40
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit efef3f2073d166b7403380106eeeb2209cb65220
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Oct 2 12:35:05 2018 -0700

    inet: make sure to grab rcu_read_lock before using ireq->ireq_opt
    
    [ Upstream commit 2ab2ddd301a22ca3c5f0b743593e4ad2953dfa53 ]
    
    Timer handlers do not imply rcu_read_lock(), so my recent fix
    triggered a LOCKDEP warning when SYNACK is retransmit.
    
    Lets add rcu_read_lock()/rcu_read_unlock() pairs around ireq->ireq_opt
    usages instead of guessing what is done by callers, since it is
    not worth the pain.
    
    Get rid of ireq_opt_deref() helper since it hides the logic
    without real benefit, since it is now a standard rcu_dereference().
    
    Fixes: 1ad98e9d1bdf ("tcp/dccp: fix lockdep issue when SYN is backlogged")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0993dc028ed2138e27def53be58076297b199634
Author: Yu Zhao <yuzhao@google.com>
Date:   Fri Sep 28 17:04:30 2018 -0600

    net/usb: cancel pending work when unbinding smsc75xx
    
    [ Upstream commit f7b2a56e1f3dcbdb4cf09b2b63e859ffe0e09df8 ]
    
    Cancel pending work before freeing smsc75xx private data structure
    during binding. This fixes the following crash in the driver:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000050
    IP: mutex_lock+0x2b/0x3f
    <snipped>
    Workqueue: events smsc75xx_deferred_multicast_write [smsc75xx]
    task: ffff8caa83e85700 task.stack: ffff948b80518000
    RIP: 0010:mutex_lock+0x2b/0x3f
    <snipped>
    Call Trace:
     smsc75xx_deferred_multicast_write+0x40/0x1af [smsc75xx]
     process_one_work+0x18d/0x2fc
     worker_thread+0x1a2/0x269
     ? pr_cont_work+0x58/0x58
     kthread+0xfa/0x10a
     ? pr_cont_work+0x58/0x58
     ? rcu_read_unlock_sched_notrace+0x48/0x48
     ret_from_fork+0x22/0x40
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c5df58138946fe24d3cb0c99bb6ce04130c657b7
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Oct 2 12:35:05 2018 -0700

    inet: make sure to grab rcu_read_lock before using ireq->ireq_opt
    
    [ Upstream commit 2ab2ddd301a22ca3c5f0b743593e4ad2953dfa53 ]
    
    Timer handlers do not imply rcu_read_lock(), so my recent fix
    triggered a LOCKDEP warning when SYNACK is retransmit.
    
    Lets add rcu_read_lock()/rcu_read_unlock() pairs around ireq->ireq_opt
    usages instead of guessing what is done by callers, since it is
    not worth the pain.
    
    Get rid of ireq_opt_deref() helper since it hides the logic
    without real benefit, since it is now a standard rcu_dereference().
    
    Fixes: 1ad98e9d1bdf ("tcp/dccp: fix lockdep issue when SYN is backlogged")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 133aea0f2108f5c3b68a621f20caf275f7e90e64
Author: Yu Zhao <yuzhao@google.com>
Date:   Fri Sep 28 17:04:30 2018 -0600

    net/usb: cancel pending work when unbinding smsc75xx
    
    [ Upstream commit f7b2a56e1f3dcbdb4cf09b2b63e859ffe0e09df8 ]
    
    Cancel pending work before freeing smsc75xx private data structure
    during binding. This fixes the following crash in the driver:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000050
    IP: mutex_lock+0x2b/0x3f
    <snipped>
    Workqueue: events smsc75xx_deferred_multicast_write [smsc75xx]
    task: ffff8caa83e85700 task.stack: ffff948b80518000
    RIP: 0010:mutex_lock+0x2b/0x3f
    <snipped>
    Call Trace:
     smsc75xx_deferred_multicast_write+0x40/0x1af [smsc75xx]
     process_one_work+0x18d/0x2fc
     worker_thread+0x1a2/0x269
     ? pr_cont_work+0x58/0x58
     kthread+0xfa/0x10a
     ? pr_cont_work+0x58/0x58
     ? rcu_read_unlock_sched_notrace+0x48/0x48
     ret_from_fork+0x22/0x40
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6b2f36b94a0d57f5378742d482f4e46ae0acd78a
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Oct 2 12:35:05 2018 -0700

    inet: make sure to grab rcu_read_lock before using ireq->ireq_opt
    
    [ Upstream commit 2ab2ddd301a22ca3c5f0b743593e4ad2953dfa53 ]
    
    Timer handlers do not imply rcu_read_lock(), so my recent fix
    triggered a LOCKDEP warning when SYNACK is retransmit.
    
    Lets add rcu_read_lock()/rcu_read_unlock() pairs around ireq->ireq_opt
    usages instead of guessing what is done by callers, since it is
    not worth the pain.
    
    Get rid of ireq_opt_deref() helper since it hides the logic
    without real benefit, since it is now a standard rcu_dereference().
    
    Fixes: 1ad98e9d1bdf ("tcp/dccp: fix lockdep issue when SYN is backlogged")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 91c41e3f77fb4242538796570731255063f72782
Author: Yu Zhao <yuzhao@google.com>
Date:   Fri Sep 28 17:04:30 2018 -0600

    net/usb: cancel pending work when unbinding smsc75xx
    
    [ Upstream commit f7b2a56e1f3dcbdb4cf09b2b63e859ffe0e09df8 ]
    
    Cancel pending work before freeing smsc75xx private data structure
    during binding. This fixes the following crash in the driver:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000050
    IP: mutex_lock+0x2b/0x3f
    <snipped>
    Workqueue: events smsc75xx_deferred_multicast_write [smsc75xx]
    task: ffff8caa83e85700 task.stack: ffff948b80518000
    RIP: 0010:mutex_lock+0x2b/0x3f
    <snipped>
    Call Trace:
     smsc75xx_deferred_multicast_write+0x40/0x1af [smsc75xx]
     process_one_work+0x18d/0x2fc
     worker_thread+0x1a2/0x269
     ? pr_cont_work+0x58/0x58
     kthread+0xfa/0x10a
     ? pr_cont_work+0x58/0x58
     ? rcu_read_unlock_sched_notrace+0x48/0x48
     ret_from_fork+0x22/0x40
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 523983401644ebeb331c923c28c9591c07430a7d
Author: Liu Bo <bo.liu@linux.alibaba.com>
Date:   Wed Aug 22 05:54:37 2018 +0800

    Btrfs: kill btrfs_clear_path_blocking
    
    Btrfs's btree locking has two modes, spinning mode and blocking mode,
    while searching btree, locking is always acquired in spinning mode and
    then converted to blocking mode if necessary, and in some hot paths we may
    switch the locking back to spinning mode by btrfs_clear_path_blocking().
    
    When acquiring locks, both of reader and writer need to wait for blocking
    readers and writers to complete before doing read_lock()/write_lock().
    
    The problem is that btrfs_clear_path_blocking() needs to switch nodes
    in the path to blocking mode at first (by btrfs_set_path_blocking) to
    make lockdep happy before doing its actual clearing blocking job.
    
    When switching to blocking mode from spinning mode, it consists of
    
    step 1) bumping up blocking readers counter and
    step 2) read_unlock()/write_unlock(),
    
    this has caused serious ping-pong effect if there're a great amount of
    concurrent readers/writers, as waiters will be woken up and go to
    sleep immediately.
    
    1) Killing this kind of ping-pong results in a big improvement in my 1600k
    files creation script,
    
    MNT=/mnt/btrfs
    mkfs.btrfs -f /dev/sdf
    mount /dev/def $MNT
    time fsmark  -D  10000  -S0  -n  100000  -s  0  -L  1 -l /tmp/fs_log.txt \
            -d  $MNT/0  -d  $MNT/1 \
            -d  $MNT/2  -d  $MNT/3 \
            -d  $MNT/4  -d  $MNT/5 \
            -d  $MNT/6  -d  $MNT/7 \
            -d  $MNT/8  -d  $MNT/9 \
            -d  $MNT/10  -d  $MNT/11 \
            -d  $MNT/12  -d  $MNT/13 \
            -d  $MNT/14  -d  $MNT/15
    
    w/o patch:
    real    2m27.307s
    user    0m12.839s
    sys     13m42.831s
    
    w/ patch:
    real    1m2.273s
    user    0m15.802s
    sys     8m16.495s
    
    1.1) latency histogram from funclatency[1]
    
    Overall with the patch, there're ~50% less write lock acquisition and
    the 95% max latency that write lock takes also reduces to ~100ms from
    >500ms.
    
    --------------------------------------------
    w/o patch:
    --------------------------------------------
    Function = btrfs_tree_lock
         msecs               : count     distribution
             0 -> 1          : 2385222  |****************************************|
             2 -> 3          : 37147    |                                        |
             4 -> 7          : 20452    |                                        |
             8 -> 15         : 13131    |                                        |
            16 -> 31         : 3877     |                                        |
            32 -> 63         : 3900     |                                        |
            64 -> 127        : 2612     |                                        |
           128 -> 255        : 974      |                                        |
           256 -> 511        : 165      |                                        |
           512 -> 1023       : 13       |                                        |
    
    Function = btrfs_tree_read_lock
         msecs               : count     distribution
             0 -> 1          : 6743860  |****************************************|
             2 -> 3          : 2146     |                                        |
             4 -> 7          : 190      |                                        |
             8 -> 15         : 38       |                                        |
            16 -> 31         : 4        |                                        |
    
    --------------------------------------------
    w/ patch:
    --------------------------------------------
    Function = btrfs_tree_lock
         msecs               : count     distribution
             0 -> 1          : 1318454  |****************************************|
             2 -> 3          : 6800     |                                        |
             4 -> 7          : 3664     |                                        |
             8 -> 15         : 2145     |                                        |
            16 -> 31         : 809      |                                        |
            32 -> 63         : 219      |                                        |
            64 -> 127        : 10       |                                        |
    
    Function = btrfs_tree_read_lock
         msecs               : count     distribution
             0 -> 1          : 6854317  |****************************************|
             2 -> 3          : 2383     |                                        |
             4 -> 7          : 601      |                                        |
             8 -> 15         : 92       |                                        |
    
    2) dbench also proves the improvement,
    dbench -t 120 -D /mnt/btrfs 16
    
    w/o patch:
    Throughput 158.363 MB/sec
    
    w/ patch:
    Throughput 449.52 MB/sec
    
    3) xfstests didn't show any additional failures.
    
    One thing to note is that callers may set path->leave_spinning to have
    all nodes in the path stay in spinning mode, which means callers are
    ready to not sleep before releasing the path, but it won't cause
    problems if they don't want to sleep in blocking mode.
    
    [1]: https://github.com/iovisor/bcc/blob/master/tools/funclatency.py
    
    Signed-off-by: Liu Bo <bo.liu@linux.alibaba.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit f7b2a56e1f3dcbdb4cf09b2b63e859ffe0e09df8
Author: Yu Zhao <yuzhao@google.com>
Date:   Fri Sep 28 17:04:30 2018 -0600

    net/usb: cancel pending work when unbinding smsc75xx
    
    Cancel pending work before freeing smsc75xx private data structure
    during binding. This fixes the following crash in the driver:
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000050
    IP: mutex_lock+0x2b/0x3f
    <snipped>
    Workqueue: events smsc75xx_deferred_multicast_write [smsc75xx]
    task: ffff8caa83e85700 task.stack: ffff948b80518000
    RIP: 0010:mutex_lock+0x2b/0x3f
    <snipped>
    Call Trace:
     smsc75xx_deferred_multicast_write+0x40/0x1af [smsc75xx]
     process_one_work+0x18d/0x2fc
     worker_thread+0x1a2/0x269
     ? pr_cont_work+0x58/0x58
     kthread+0xfa/0x10a
     ? pr_cont_work+0x58/0x58
     ? rcu_read_unlock_sched_notrace+0x48/0x48
     ret_from_fork+0x22/0x40
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 2ab2ddd301a22ca3c5f0b743593e4ad2953dfa53
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Oct 2 12:35:05 2018 -0700

    inet: make sure to grab rcu_read_lock before using ireq->ireq_opt
    
    Timer handlers do not imply rcu_read_lock(), so my recent fix
    triggered a LOCKDEP warning when SYNACK is retransmit.
    
    Lets add rcu_read_lock()/rcu_read_unlock() pairs around ireq->ireq_opt
    usages instead of guessing what is done by callers, since it is
    not worth the pain.
    
    Get rid of ireq_opt_deref() helper since it hides the logic
    without real benefit, since it is now a standard rcu_dereference().
    
    Fixes: 1ad98e9d1bdf ("tcp/dccp: fix lockdep issue when SYN is backlogged")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Willem de Bruijn <willemb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1db58529454742f67ebd96e3588315e880b72837
Author: Yu Zhao <yuzhao@google.com>
Date:   Thu Sep 27 17:05:04 2018 -0600

    cfg80211: fix use-after-free in reg_process_hint()
    
    reg_process_hint_country_ie() can free regulatory_request and return
    REG_REQ_ALREADY_SET. We shouldn't use regulatory_request after it's
    called. KASAN error was observed when this happens.
    
    BUG: KASAN: use-after-free in reg_process_hint+0x839/0x8aa [cfg80211]
    Read of size 4 at addr ffff8800c430d434 by task kworker/1:3/89
    <snipped>
    Workqueue: events reg_todo [cfg80211]
    Call Trace:
     dump_stack+0xc1/0x10c
     ? _atomic_dec_and_lock+0x1ad/0x1ad
     ? _raw_spin_lock_irqsave+0xa0/0xd2
     print_address_description+0x86/0x26f
     ? reg_process_hint+0x839/0x8aa [cfg80211]
     kasan_report+0x241/0x29b
     reg_process_hint+0x839/0x8aa [cfg80211]
     reg_todo+0x204/0x5b9 [cfg80211]
     process_one_work+0x55f/0x8d0
     ? worker_detach_from_pool+0x1b5/0x1b5
     ? _raw_spin_unlock_irq+0x65/0xdd
     ? _raw_spin_unlock_irqrestore+0xf3/0xf3
     worker_thread+0x5dd/0x841
     ? kthread_parkme+0x1d/0x1d
     kthread+0x270/0x285
     ? pr_cont_work+0xe3/0xe3
     ? rcu_read_unlock_sched_notrace+0xca/0xca
     ret_from_fork+0x22/0x40
    
    Allocated by task 2718:
     set_track+0x63/0xfa
     __kmalloc+0x119/0x1ac
     regulatory_hint_country_ie+0x38/0x329 [cfg80211]
     __cfg80211_connect_result+0x854/0xadd [cfg80211]
     cfg80211_rx_assoc_resp+0x3bc/0x4f0 [cfg80211]
    smsc95xx v1.0.6
     ieee80211_sta_rx_queued_mgmt+0x1803/0x7ed5 [mac80211]
     ieee80211_iface_work+0x411/0x696 [mac80211]
     process_one_work+0x55f/0x8d0
     worker_thread+0x5dd/0x841
     kthread+0x270/0x285
     ret_from_fork+0x22/0x40
    
    Freed by task 89:
     set_track+0x63/0xfa
     kasan_slab_free+0x6a/0x87
     kfree+0xdc/0x470
     reg_process_hint+0x31e/0x8aa [cfg80211]
     reg_todo+0x204/0x5b9 [cfg80211]
     process_one_work+0x55f/0x8d0
     worker_thread+0x5dd/0x841
     kthread+0x270/0x285
     ret_from_fork+0x22/0x40
    <snipped>
    
    Signed-off-by: Yu Zhao <yuzhao@google.com>
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>

commit c8204cab9cb503bede29938785b3cdf26a275fa2
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Wed Sep 12 00:20:43 2018 +0900

    netfilter: nat: remove unnecessary rcu_read_lock in nf_nat_redirect_ipv{4/6}
    
    nf_nat_redirect_ipv4() and nf_nat_redirect_ipv6() are only called by
    netfilter hook point. so that rcu_read_lock and rcu_read_unlock() are
    unnecessary.
    
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 3d343258091119b53792beed2082bc87340ab5de
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:05 2017 +0300

    sch_tbf: fix two null pointer dereferences on init failure
    
    commit c2d6511e6a4f1f3673d711569c00c3849549e9b0 upstream.
    
    sch_tbf calls qdisc_watchdog_cancel() in both its ->reset and ->destroy
    callbacks but it may fail before the timer is initialized due to missing
    options (either not supplied by user-space or set as a default qdisc),
    also q->qdisc is used by ->reset and ->destroy so we need it initialized.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=tbf
    $ ip l set ethX up
    
    Crash log:
    [  959.160172] BUG: unable to handle kernel NULL pointer dereference at 0000000000000018
    [  959.160323] IP: qdisc_reset+0xa/0x5c
    [  959.160400] PGD 59cdb067
    [  959.160401] P4D 59cdb067
    [  959.160466] PUD 59ccb067
    [  959.160532] PMD 0
    [  959.160597]
    [  959.160706] Oops: 0000 [#1] SMP
    [  959.160778] Modules linked in: sch_tbf sch_sfb sch_prio sch_netem
    [  959.160891] CPU: 2 PID: 1562 Comm: ip Not tainted 4.13.0-rc6+ #62
    [  959.160998] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  959.161157] task: ffff880059c9a700 task.stack: ffff8800376d0000
    [  959.161263] RIP: 0010:qdisc_reset+0xa/0x5c
    [  959.161347] RSP: 0018:ffff8800376d3610 EFLAGS: 00010286
    [  959.161531] RAX: ffffffffa001b1dd RBX: ffff8800373a2800 RCX: 0000000000000000
    [  959.161733] RDX: ffffffff8215f160 RSI: ffffffff8215f160 RDI: 0000000000000000
    [  959.161939] RBP: ffff8800376d3618 R08: 00000000014080c0 R09: 00000000ffffffff
    [  959.162141] R10: ffff8800376d3578 R11: 0000000000000020 R12: ffffffffa001d2c0
    [  959.162343] R13: ffff880037538000 R14: 00000000ffffffff R15: 0000000000000001
    [  959.162546] FS:  00007fcc5126b740(0000) GS:ffff88005d900000(0000) knlGS:0000000000000000
    [  959.162844] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  959.163030] CR2: 0000000000000018 CR3: 000000005abc4000 CR4: 00000000000406e0
    [  959.163233] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  959.163436] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  959.163638] Call Trace:
    [  959.163788]  tbf_reset+0x19/0x64 [sch_tbf]
    [  959.163957]  qdisc_destroy+0x8b/0xe5
    [  959.164119]  qdisc_create_dflt+0x86/0x94
    [  959.164284]  ? dev_activate+0x129/0x129
    [  959.164449]  attach_one_default_qdisc+0x36/0x63
    [  959.164623]  netdev_for_each_tx_queue+0x3d/0x48
    [  959.164795]  dev_activate+0x4b/0x129
    [  959.164957]  __dev_open+0xe7/0x104
    [  959.165118]  __dev_change_flags+0xc6/0x15c
    [  959.165287]  dev_change_flags+0x25/0x59
    [  959.165451]  do_setlink+0x30c/0xb3f
    [  959.165613]  ? check_chain_key+0xb0/0xfd
    [  959.165782]  rtnl_newlink+0x3a4/0x729
    [  959.165947]  ? rtnl_newlink+0x117/0x729
    [  959.166121]  ? ns_capable_common+0xd/0xb1
    [  959.166288]  ? ns_capable+0x13/0x15
    [  959.166450]  rtnetlink_rcv_msg+0x188/0x197
    [  959.166617]  ? rcu_read_unlock+0x3e/0x5f
    [  959.166783]  ? rtnl_newlink+0x729/0x729
    [  959.166948]  netlink_rcv_skb+0x6c/0xce
    [  959.167113]  rtnetlink_rcv+0x23/0x2a
    [  959.167273]  netlink_unicast+0x103/0x181
    [  959.167439]  netlink_sendmsg+0x326/0x337
    [  959.167607]  sock_sendmsg_nosec+0x14/0x3f
    [  959.167772]  sock_sendmsg+0x29/0x2e
    [  959.167932]  ___sys_sendmsg+0x209/0x28b
    [  959.168098]  ? do_raw_spin_unlock+0xcd/0xf8
    [  959.168267]  ? _raw_spin_unlock+0x27/0x31
    [  959.168432]  ? __handle_mm_fault+0x651/0xdb1
    [  959.168602]  ? check_chain_key+0xb0/0xfd
    [  959.168773]  __sys_sendmsg+0x45/0x63
    [  959.168934]  ? __sys_sendmsg+0x45/0x63
    [  959.169100]  SyS_sendmsg+0x19/0x1b
    [  959.169260]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  959.169432] RIP: 0033:0x7fcc5097e690
    [  959.169592] RSP: 002b:00007ffd0d5c7b48 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  959.169887] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007fcc5097e690
    [  959.170089] RDX: 0000000000000000 RSI: 00007ffd0d5c7b90 RDI: 0000000000000003
    [  959.170292] RBP: ffff8800376d3f98 R08: 0000000000000001 R09: 0000000000000003
    [  959.170494] R10: 00007ffd0d5c7910 R11: 0000000000000246 R12: 0000000000000006
    [  959.170697] R13: 000000000066f1a0 R14: 00007ffd0d5cfc40 R15: 0000000000000000
    [  959.170900]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  959.171076] Code: 00 41 c7 84 24 14 01 00 00 00 00 00 00 41 c7 84 24
    98 00 00 00 00 00 00 00 41 5c 41 5d 41 5e 5d c3 66 66 66 66 90 55 48 89
    e5 53 <48> 8b 47 18 48 89 fb 48 8b 40 48 48 85 c0 74 02 ff d0 48 8b bb
    [  959.171637] RIP: qdisc_reset+0xa/0x5c RSP: ffff8800376d3610
    [  959.171821] CR2: 0000000000000018
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 977f75d5c361cce54b42c5e60c5ec4dc8bf034f3
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:03 2017 +0300

    sch_netem: avoid null pointer deref on init failure
    
    commit 634576a1844dba15bc5e6fc61d72f37e13a21615 upstream.
    
    netem can fail in ->init due to missing options (either not supplied by
    user-space or used as a default qdisc) causing a timer->base null
    pointer deref in its ->destroy() and ->reset() callbacks.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=netem
    $ ip l set ethX up
    
    Crash log:
    [ 1814.846943] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 1814.847181] IP: hrtimer_active+0x17/0x8a
    [ 1814.847270] PGD 59c34067
    [ 1814.847271] P4D 59c34067
    [ 1814.847337] PUD 37374067
    [ 1814.847403] PMD 0
    [ 1814.847468]
    [ 1814.847582] Oops: 0000 [#1] SMP
    [ 1814.847655] Modules linked in: sch_netem(O) sch_fq_codel(O)
    [ 1814.847761] CPU: 3 PID: 1573 Comm: ip Tainted: G           O 4.13.0-rc6+ #62
    [ 1814.847884] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 1814.848043] task: ffff88003723a700 task.stack: ffff88005adc8000
    [ 1814.848235] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 1814.848407] RSP: 0018:ffff88005adcb590 EFLAGS: 00010246
    [ 1814.848590] RAX: 0000000000000000 RBX: ffff880058e359d8 RCX: 0000000000000000
    [ 1814.848793] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff880058e359d8
    [ 1814.848998] RBP: ffff88005adcb5b0 R08: 00000000014080c0 R09: 00000000ffffffff
    [ 1814.849204] R10: ffff88005adcb660 R11: 0000000000000020 R12: 0000000000000000
    [ 1814.849410] R13: ffff880058e359d8 R14: 00000000ffffffff R15: 0000000000000001
    [ 1814.849616] FS:  00007f733bbca740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 1814.849919] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1814.850107] CR2: 0000000000000000 CR3: 0000000059f0d000 CR4: 00000000000406e0
    [ 1814.850313] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 1814.850518] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 1814.850723] Call Trace:
    [ 1814.850875]  hrtimer_try_to_cancel+0x1a/0x93
    [ 1814.851047]  hrtimer_cancel+0x15/0x20
    [ 1814.851211]  qdisc_watchdog_cancel+0x12/0x14
    [ 1814.851383]  netem_reset+0xe6/0xed [sch_netem]
    [ 1814.851561]  qdisc_destroy+0x8b/0xe5
    [ 1814.851723]  qdisc_create_dflt+0x86/0x94
    [ 1814.851890]  ? dev_activate+0x129/0x129
    [ 1814.852057]  attach_one_default_qdisc+0x36/0x63
    [ 1814.852232]  netdev_for_each_tx_queue+0x3d/0x48
    [ 1814.852406]  dev_activate+0x4b/0x129
    [ 1814.852569]  __dev_open+0xe7/0x104
    [ 1814.852730]  __dev_change_flags+0xc6/0x15c
    [ 1814.852899]  dev_change_flags+0x25/0x59
    [ 1814.853064]  do_setlink+0x30c/0xb3f
    [ 1814.853228]  ? check_chain_key+0xb0/0xfd
    [ 1814.853396]  ? check_chain_key+0xb0/0xfd
    [ 1814.853565]  rtnl_newlink+0x3a4/0x729
    [ 1814.853728]  ? rtnl_newlink+0x117/0x729
    [ 1814.853905]  ? ns_capable_common+0xd/0xb1
    [ 1814.854072]  ? ns_capable+0x13/0x15
    [ 1814.854234]  rtnetlink_rcv_msg+0x188/0x197
    [ 1814.854404]  ? rcu_read_unlock+0x3e/0x5f
    [ 1814.854572]  ? rtnl_newlink+0x729/0x729
    [ 1814.854737]  netlink_rcv_skb+0x6c/0xce
    [ 1814.854902]  rtnetlink_rcv+0x23/0x2a
    [ 1814.855064]  netlink_unicast+0x103/0x181
    [ 1814.855230]  netlink_sendmsg+0x326/0x337
    [ 1814.855398]  sock_sendmsg_nosec+0x14/0x3f
    [ 1814.855584]  sock_sendmsg+0x29/0x2e
    [ 1814.855747]  ___sys_sendmsg+0x209/0x28b
    [ 1814.855912]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 1814.856082]  ? _raw_spin_unlock+0x27/0x31
    [ 1814.856251]  ? __handle_mm_fault+0x651/0xdb1
    [ 1814.856421]  ? check_chain_key+0xb0/0xfd
    [ 1814.856592]  __sys_sendmsg+0x45/0x63
    [ 1814.856755]  ? __sys_sendmsg+0x45/0x63
    [ 1814.856923]  SyS_sendmsg+0x19/0x1b
    [ 1814.857083]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 1814.857256] RIP: 0033:0x7f733b2dd690
    [ 1814.857419] RSP: 002b:00007ffe1d3387d8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 1814.858238] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f733b2dd690
    [ 1814.858445] RDX: 0000000000000000 RSI: 00007ffe1d338820 RDI: 0000000000000003
    [ 1814.858651] RBP: ffff88005adcbf98 R08: 0000000000000001 R09: 0000000000000003
    [ 1814.858856] R10: 00007ffe1d3385a0 R11: 0000000000000246 R12: 0000000000000002
    [ 1814.859060] R13: 000000000066f1a0 R14: 00007ffe1d3408d0 R15: 0000000000000000
    [ 1814.859267]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 1814.859446] Code: 10 55 48 89 c7 48 89 e5 e8 45 a1 fb ff 31 c0 5d c3
    31 c0 c3 66 66 66 66 90 55 48 89 e5 41 56 41 55 41 54 53 49 89 fd 49 8b
    45 30 <4c> 8b 20 41 8b 5c 24 38 31 c9 31 d2 48 c7 c7 50 8e 1d 82 41 89
    [ 1814.860022] RIP: hrtimer_active+0x17/0x8a RSP: ffff88005adcb590
    [ 1814.860214] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bafe019d5ff66db88a7547b5a41592146966bb1d
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:59 2017 +0300

    sch_hhf: fix null pointer dereference on init failure
    
    commit 32db864d33c21fd70a217ba53cb7224889354ffb upstream.
    
    If sch_hhf fails in its ->init() function (either due to wrong
    user-space arguments as below or memory alloc failure of hh_flows) it
    will do a null pointer deref of q->hh_flows in its ->destroy() function.
    
    To reproduce the crash:
    $ tc qdisc add dev eth0 root hhf quantum 2000000 non_hh_weight 10000000
    
    Crash log:
    [  690.654882] BUG: unable to handle kernel NULL pointer dereference at (null)
    [  690.655565] IP: hhf_destroy+0x48/0xbc
    [  690.655944] PGD 37345067
    [  690.655948] P4D 37345067
    [  690.656252] PUD 58402067
    [  690.656554] PMD 0
    [  690.656857]
    [  690.657362] Oops: 0000 [#1] SMP
    [  690.657696] Modules linked in:
    [  690.658032] CPU: 3 PID: 920 Comm: tc Not tainted 4.13.0-rc6+ #57
    [  690.658525] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  690.659255] task: ffff880058578000 task.stack: ffff88005acbc000
    [  690.659747] RIP: 0010:hhf_destroy+0x48/0xbc
    [  690.660146] RSP: 0018:ffff88005acbf9e0 EFLAGS: 00010246
    [  690.660601] RAX: 0000000000000000 RBX: 0000000000000020 RCX: 0000000000000000
    [  690.661155] RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffffffff821f63f0
    [  690.661710] RBP: ffff88005acbfa08 R08: ffffffff81b10a90 R09: 0000000000000000
    [  690.662267] R10: 00000000f42b7019 R11: ffff880058578000 R12: 00000000ffffffea
    [  690.662820] R13: ffff8800372f6400 R14: 0000000000000000 R15: 0000000000000000
    [  690.663769] FS:  00007f8ae5e8b740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [  690.667069] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  690.667965] CR2: 0000000000000000 CR3: 0000000058523000 CR4: 00000000000406e0
    [  690.668918] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  690.669945] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  690.671003] Call Trace:
    [  690.671743]  qdisc_create+0x377/0x3fd
    [  690.672534]  tc_modify_qdisc+0x4d2/0x4fd
    [  690.673324]  rtnetlink_rcv_msg+0x188/0x197
    [  690.674204]  ? rcu_read_unlock+0x3e/0x5f
    [  690.675091]  ? rtnl_newlink+0x729/0x729
    [  690.675877]  netlink_rcv_skb+0x6c/0xce
    [  690.676648]  rtnetlink_rcv+0x23/0x2a
    [  690.677405]  netlink_unicast+0x103/0x181
    [  690.678179]  netlink_sendmsg+0x326/0x337
    [  690.678958]  sock_sendmsg_nosec+0x14/0x3f
    [  690.679743]  sock_sendmsg+0x29/0x2e
    [  690.680506]  ___sys_sendmsg+0x209/0x28b
    [  690.681283]  ? __handle_mm_fault+0xc7d/0xdb1
    [  690.681915]  ? check_chain_key+0xb0/0xfd
    [  690.682449]  __sys_sendmsg+0x45/0x63
    [  690.682954]  ? __sys_sendmsg+0x45/0x63
    [  690.683471]  SyS_sendmsg+0x19/0x1b
    [  690.683974]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  690.684516] RIP: 0033:0x7f8ae529d690
    [  690.685016] RSP: 002b:00007fff26d2d6b8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  690.685931] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f8ae529d690
    [  690.686573] RDX: 0000000000000000 RSI: 00007fff26d2d700 RDI: 0000000000000003
    [  690.687047] RBP: ffff88005acbff98 R08: 0000000000000001 R09: 0000000000000000
    [  690.687519] R10: 00007fff26d2d480 R11: 0000000000000246 R12: 0000000000000002
    [  690.687996] R13: 0000000001258070 R14: 0000000000000001 R15: 0000000000000000
    [  690.688475]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  690.688887] Code: 00 00 e8 2a 02 ae ff 49 8b bc 1d 60 02 00 00 48 83
    c3 08 e8 19 02 ae ff 48 83 fb 20 75 dc 45 31 f6 4d 89 f7 4d 03 bd 20 02
    00 00 <49> 8b 07 49 39 c7 75 24 49 83 c6 10 49 81 fe 00 40 00 00 75 e1
    [  690.690200] RIP: hhf_destroy+0x48/0xbc RSP: ffff88005acbf9e0
    [  690.690636] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 10239edf86f1 ("net-qdisc-hhf: Heavy-Hitter Filter (HHF) qdisc")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9db519dc793994d702876c815f1d903c29280ab5
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:58 2017 +0300

    sch_multiq: fix double free on init failure
    
    commit e89d469e3be3ed3d7124a803211a463ff83d0964 upstream.
    
    The below commit added a call to ->destroy() on init failure, but multiq
    still frees ->queues on error in init, but ->queues is also freed by
    ->destroy() thus we get double free and corrupted memory.
    
    Very easy to reproduce (eth0 not multiqueue):
    $ tc qdisc add dev eth0 root multiq
    RTNETLINK answers: Operation not supported
    $ ip l add dumdum type dummy
    (crash)
    
    Trace log:
    [ 3929.467747] general protection fault: 0000 [#1] SMP
    [ 3929.468083] Modules linked in:
    [ 3929.468302] CPU: 3 PID: 967 Comm: ip Not tainted 4.13.0-rc6+ #56
    [ 3929.468625] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 3929.469124] task: ffff88003716a700 task.stack: ffff88005872c000
    [ 3929.469449] RIP: 0010:__kmalloc_track_caller+0x117/0x1be
    [ 3929.469746] RSP: 0018:ffff88005872f6a0 EFLAGS: 00010246
    [ 3929.470042] RAX: 00000000000002de RBX: 0000000058a59000 RCX: 00000000000002df
    [ 3929.470406] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff821f7020
    [ 3929.470770] RBP: ffff88005872f6e8 R08: 000000000001f010 R09: 0000000000000000
    [ 3929.471133] R10: ffff88005872f730 R11: 0000000000008cdd R12: ff006d75646d7564
    [ 3929.471496] R13: 00000000014000c0 R14: ffff88005b403c00 R15: ffff88005b403c00
    [ 3929.471869] FS:  00007f0b70480740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 3929.472286] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3929.472677] CR2: 00007ffcee4f3000 CR3: 0000000059d45000 CR4: 00000000000406e0
    [ 3929.473209] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 3929.474109] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 3929.474873] Call Trace:
    [ 3929.475337]  ? kstrdup_const+0x23/0x25
    [ 3929.475863]  kstrdup+0x2e/0x4b
    [ 3929.476338]  kstrdup_const+0x23/0x25
    [ 3929.478084]  __kernfs_new_node+0x28/0xbc
    [ 3929.478478]  kernfs_new_node+0x35/0x55
    [ 3929.478929]  kernfs_create_link+0x23/0x76
    [ 3929.479478]  sysfs_do_create_link_sd.isra.2+0x85/0xd7
    [ 3929.480096]  sysfs_create_link+0x33/0x35
    [ 3929.480649]  device_add+0x200/0x589
    [ 3929.481184]  netdev_register_kobject+0x7c/0x12f
    [ 3929.481711]  register_netdevice+0x373/0x471
    [ 3929.482174]  rtnl_newlink+0x614/0x729
    [ 3929.482610]  ? rtnl_newlink+0x17f/0x729
    [ 3929.483080]  rtnetlink_rcv_msg+0x188/0x197
    [ 3929.483533]  ? rcu_read_unlock+0x3e/0x5f
    [ 3929.483984]  ? rtnl_newlink+0x729/0x729
    [ 3929.484420]  netlink_rcv_skb+0x6c/0xce
    [ 3929.484858]  rtnetlink_rcv+0x23/0x2a
    [ 3929.485291]  netlink_unicast+0x103/0x181
    [ 3929.485735]  netlink_sendmsg+0x326/0x337
    [ 3929.486181]  sock_sendmsg_nosec+0x14/0x3f
    [ 3929.486614]  sock_sendmsg+0x29/0x2e
    [ 3929.486973]  ___sys_sendmsg+0x209/0x28b
    [ 3929.487340]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 3929.487719]  ? _raw_spin_unlock+0x27/0x31
    [ 3929.488092]  ? __handle_mm_fault+0x651/0xdb1
    [ 3929.488471]  ? check_chain_key+0xb0/0xfd
    [ 3929.488847]  __sys_sendmsg+0x45/0x63
    [ 3929.489206]  ? __sys_sendmsg+0x45/0x63
    [ 3929.489576]  SyS_sendmsg+0x19/0x1b
    [ 3929.489901]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 3929.490172] RIP: 0033:0x7f0b6fb93690
    [ 3929.490423] RSP: 002b:00007ffcee4ed588 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 3929.490881] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f0b6fb93690
    [ 3929.491198] RDX: 0000000000000000 RSI: 00007ffcee4ed5d0 RDI: 0000000000000003
    [ 3929.491521] RBP: ffff88005872ff98 R08: 0000000000000001 R09: 0000000000000000
    [ 3929.491801] R10: 00007ffcee4ed350 R11: 0000000000000246 R12: 0000000000000002
    [ 3929.492075] R13: 000000000066f1a0 R14: 00007ffcee4f5680 R15: 0000000000000000
    [ 3929.492352]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 3929.492590] Code: 8b 45 c0 48 8b 45 b8 74 17 48 8b 4d c8 83 ca ff 44
    89 ee 4c 89 f7 e8 83 ca ff ff 49 89 c4 eb 49 49 63 56 20 48 8d 48 01 4d
    8b 06 <49> 8b 1c 14 48 89 c2 4c 89 e0 65 49 0f c7 08 0f 94 c0 83 f0 01
    [ 3929.493335] RIP: __kmalloc_track_caller+0x117/0x1be RSP: ffff88005872f6a0
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: f07d1501292b ("multiq: Further multiqueue cleanup")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [AmitP: Removed unused variable 'err' in multiq_init()]
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 951104e4805f9eeb236edf02f31096c43d68f6b8
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:57 2017 +0300

    sch_htb: fix crash on init failure
    
    commit 88c2ace69dbef696edba77712882af03879abc9c upstream.
    
    The commit below added a call to the ->destroy() callback for all qdiscs
    which failed in their ->init(), but some were not prepared for such
    change and can't handle partially initialized qdisc. HTB is one of them
    and if any error occurs before the qdisc watchdog timer and qdisc work are
    initialized then we can hit either a null ptr deref (timer->base) when
    canceling in ->destroy or lockdep error info about trying to register
    a non-static key and a stack dump. So to fix these two move the watchdog
    timer and workqueue init before anything that can err out.
    To reproduce userspace needs to send broken htb qdisc create request,
    tested with a modified tc (q_htb.c).
    
    Trace log:
    [ 2710.897602] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 2710.897977] IP: hrtimer_active+0x17/0x8a
    [ 2710.898174] PGD 58fab067
    [ 2710.898175] P4D 58fab067
    [ 2710.898353] PUD 586c0067
    [ 2710.898531] PMD 0
    [ 2710.898710]
    [ 2710.899045] Oops: 0000 [#1] SMP
    [ 2710.899232] Modules linked in:
    [ 2710.899419] CPU: 1 PID: 950 Comm: tc Not tainted 4.13.0-rc6+ #54
    [ 2710.899646] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 2710.900035] task: ffff880059ed2700 task.stack: ffff88005ad4c000
    [ 2710.900262] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 2710.900467] RSP: 0018:ffff88005ad4f960 EFLAGS: 00010246
    [ 2710.900684] RAX: 0000000000000000 RBX: ffff88003701e298 RCX: 0000000000000000
    [ 2710.900933] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff88003701e298
    [ 2710.901177] RBP: ffff88005ad4f980 R08: 0000000000000001 R09: 0000000000000001
    [ 2710.901419] R10: ffff88005ad4f800 R11: 0000000000000400 R12: 0000000000000000
    [ 2710.901663] R13: ffff88003701e298 R14: ffffffff822a4540 R15: ffff88005ad4fac0
    [ 2710.901907] FS:  00007f2f5e90f740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [ 2710.902277] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2710.902500] CR2: 0000000000000000 CR3: 0000000058ca3000 CR4: 00000000000406e0
    [ 2710.902744] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 2710.902977] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 2710.903180] Call Trace:
    [ 2710.903332]  hrtimer_try_to_cancel+0x1a/0x93
    [ 2710.903504]  hrtimer_cancel+0x15/0x20
    [ 2710.903667]  qdisc_watchdog_cancel+0x12/0x14
    [ 2710.903866]  htb_destroy+0x2e/0xf7
    [ 2710.904097]  qdisc_create+0x377/0x3fd
    [ 2710.904330]  tc_modify_qdisc+0x4d2/0x4fd
    [ 2710.904511]  rtnetlink_rcv_msg+0x188/0x197
    [ 2710.904682]  ? rcu_read_unlock+0x3e/0x5f
    [ 2710.904849]  ? rtnl_newlink+0x729/0x729
    [ 2710.905017]  netlink_rcv_skb+0x6c/0xce
    [ 2710.905183]  rtnetlink_rcv+0x23/0x2a
    [ 2710.905345]  netlink_unicast+0x103/0x181
    [ 2710.905511]  netlink_sendmsg+0x326/0x337
    [ 2710.905679]  sock_sendmsg_nosec+0x14/0x3f
    [ 2710.905847]  sock_sendmsg+0x29/0x2e
    [ 2710.906010]  ___sys_sendmsg+0x209/0x28b
    [ 2710.906176]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 2710.906346]  ? _raw_spin_unlock+0x27/0x31
    [ 2710.906514]  ? __handle_mm_fault+0x651/0xdb1
    [ 2710.906685]  ? check_chain_key+0xb0/0xfd
    [ 2710.906855]  __sys_sendmsg+0x45/0x63
    [ 2710.907018]  ? __sys_sendmsg+0x45/0x63
    [ 2710.907185]  SyS_sendmsg+0x19/0x1b
    [ 2710.907344]  entry_SYSCALL_64_fastpath+0x23/0xc2
    
    Note that probably this bug goes further back because the default qdisc
    handling always calls ->destroy on init failure too.
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit aa5d14953152307414b3039b02b3b5acf26d03bc
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:05 2017 +0300

    sch_tbf: fix two null pointer dereferences on init failure
    
    commit c2d6511e6a4f1f3673d711569c00c3849549e9b0 upstream.
    
    sch_tbf calls qdisc_watchdog_cancel() in both its ->reset and ->destroy
    callbacks but it may fail before the timer is initialized due to missing
    options (either not supplied by user-space or set as a default qdisc),
    also q->qdisc is used by ->reset and ->destroy so we need it initialized.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=tbf
    $ ip l set ethX up
    
    Crash log:
    [  959.160172] BUG: unable to handle kernel NULL pointer dereference at 0000000000000018
    [  959.160323] IP: qdisc_reset+0xa/0x5c
    [  959.160400] PGD 59cdb067
    [  959.160401] P4D 59cdb067
    [  959.160466] PUD 59ccb067
    [  959.160532] PMD 0
    [  959.160597]
    [  959.160706] Oops: 0000 [#1] SMP
    [  959.160778] Modules linked in: sch_tbf sch_sfb sch_prio sch_netem
    [  959.160891] CPU: 2 PID: 1562 Comm: ip Not tainted 4.13.0-rc6+ #62
    [  959.160998] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  959.161157] task: ffff880059c9a700 task.stack: ffff8800376d0000
    [  959.161263] RIP: 0010:qdisc_reset+0xa/0x5c
    [  959.161347] RSP: 0018:ffff8800376d3610 EFLAGS: 00010286
    [  959.161531] RAX: ffffffffa001b1dd RBX: ffff8800373a2800 RCX: 0000000000000000
    [  959.161733] RDX: ffffffff8215f160 RSI: ffffffff8215f160 RDI: 0000000000000000
    [  959.161939] RBP: ffff8800376d3618 R08: 00000000014080c0 R09: 00000000ffffffff
    [  959.162141] R10: ffff8800376d3578 R11: 0000000000000020 R12: ffffffffa001d2c0
    [  959.162343] R13: ffff880037538000 R14: 00000000ffffffff R15: 0000000000000001
    [  959.162546] FS:  00007fcc5126b740(0000) GS:ffff88005d900000(0000) knlGS:0000000000000000
    [  959.162844] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  959.163030] CR2: 0000000000000018 CR3: 000000005abc4000 CR4: 00000000000406e0
    [  959.163233] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  959.163436] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  959.163638] Call Trace:
    [  959.163788]  tbf_reset+0x19/0x64 [sch_tbf]
    [  959.163957]  qdisc_destroy+0x8b/0xe5
    [  959.164119]  qdisc_create_dflt+0x86/0x94
    [  959.164284]  ? dev_activate+0x129/0x129
    [  959.164449]  attach_one_default_qdisc+0x36/0x63
    [  959.164623]  netdev_for_each_tx_queue+0x3d/0x48
    [  959.164795]  dev_activate+0x4b/0x129
    [  959.164957]  __dev_open+0xe7/0x104
    [  959.165118]  __dev_change_flags+0xc6/0x15c
    [  959.165287]  dev_change_flags+0x25/0x59
    [  959.165451]  do_setlink+0x30c/0xb3f
    [  959.165613]  ? check_chain_key+0xb0/0xfd
    [  959.165782]  rtnl_newlink+0x3a4/0x729
    [  959.165947]  ? rtnl_newlink+0x117/0x729
    [  959.166121]  ? ns_capable_common+0xd/0xb1
    [  959.166288]  ? ns_capable+0x13/0x15
    [  959.166450]  rtnetlink_rcv_msg+0x188/0x197
    [  959.166617]  ? rcu_read_unlock+0x3e/0x5f
    [  959.166783]  ? rtnl_newlink+0x729/0x729
    [  959.166948]  netlink_rcv_skb+0x6c/0xce
    [  959.167113]  rtnetlink_rcv+0x23/0x2a
    [  959.167273]  netlink_unicast+0x103/0x181
    [  959.167439]  netlink_sendmsg+0x326/0x337
    [  959.167607]  sock_sendmsg_nosec+0x14/0x3f
    [  959.167772]  sock_sendmsg+0x29/0x2e
    [  959.167932]  ___sys_sendmsg+0x209/0x28b
    [  959.168098]  ? do_raw_spin_unlock+0xcd/0xf8
    [  959.168267]  ? _raw_spin_unlock+0x27/0x31
    [  959.168432]  ? __handle_mm_fault+0x651/0xdb1
    [  959.168602]  ? check_chain_key+0xb0/0xfd
    [  959.168773]  __sys_sendmsg+0x45/0x63
    [  959.168934]  ? __sys_sendmsg+0x45/0x63
    [  959.169100]  SyS_sendmsg+0x19/0x1b
    [  959.169260]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  959.169432] RIP: 0033:0x7fcc5097e690
    [  959.169592] RSP: 002b:00007ffd0d5c7b48 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  959.169887] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007fcc5097e690
    [  959.170089] RDX: 0000000000000000 RSI: 00007ffd0d5c7b90 RDI: 0000000000000003
    [  959.170292] RBP: ffff8800376d3f98 R08: 0000000000000001 R09: 0000000000000003
    [  959.170494] R10: 00007ffd0d5c7910 R11: 0000000000000246 R12: 0000000000000006
    [  959.170697] R13: 000000000066f1a0 R14: 00007ffd0d5cfc40 R15: 0000000000000000
    [  959.170900]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  959.171076] Code: 00 41 c7 84 24 14 01 00 00 00 00 00 00 41 c7 84 24
    98 00 00 00 00 00 00 00 41 5c 41 5d 41 5e 5d c3 66 66 66 66 90 55 48 89
    e5 53 <48> 8b 47 18 48 89 fb 48 8b 40 48 48 85 c0 74 02 ff d0 48 8b bb
    [  959.171637] RIP: qdisc_reset+0xa/0x5c RSP: ffff8800376d3610
    [  959.171821] CR2: 0000000000000018
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7a4eae7ae6f47f23aba15eca83f3798a6bc1b855
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:03 2017 +0300

    sch_netem: avoid null pointer deref on init failure
    
    commit 634576a1844dba15bc5e6fc61d72f37e13a21615 upstream.
    
    netem can fail in ->init due to missing options (either not supplied by
    user-space or used as a default qdisc) causing a timer->base null
    pointer deref in its ->destroy() and ->reset() callbacks.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=netem
    $ ip l set ethX up
    
    Crash log:
    [ 1814.846943] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 1814.847181] IP: hrtimer_active+0x17/0x8a
    [ 1814.847270] PGD 59c34067
    [ 1814.847271] P4D 59c34067
    [ 1814.847337] PUD 37374067
    [ 1814.847403] PMD 0
    [ 1814.847468]
    [ 1814.847582] Oops: 0000 [#1] SMP
    [ 1814.847655] Modules linked in: sch_netem(O) sch_fq_codel(O)
    [ 1814.847761] CPU: 3 PID: 1573 Comm: ip Tainted: G           O 4.13.0-rc6+ #62
    [ 1814.847884] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 1814.848043] task: ffff88003723a700 task.stack: ffff88005adc8000
    [ 1814.848235] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 1814.848407] RSP: 0018:ffff88005adcb590 EFLAGS: 00010246
    [ 1814.848590] RAX: 0000000000000000 RBX: ffff880058e359d8 RCX: 0000000000000000
    [ 1814.848793] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff880058e359d8
    [ 1814.848998] RBP: ffff88005adcb5b0 R08: 00000000014080c0 R09: 00000000ffffffff
    [ 1814.849204] R10: ffff88005adcb660 R11: 0000000000000020 R12: 0000000000000000
    [ 1814.849410] R13: ffff880058e359d8 R14: 00000000ffffffff R15: 0000000000000001
    [ 1814.849616] FS:  00007f733bbca740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 1814.849919] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1814.850107] CR2: 0000000000000000 CR3: 0000000059f0d000 CR4: 00000000000406e0
    [ 1814.850313] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 1814.850518] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 1814.850723] Call Trace:
    [ 1814.850875]  hrtimer_try_to_cancel+0x1a/0x93
    [ 1814.851047]  hrtimer_cancel+0x15/0x20
    [ 1814.851211]  qdisc_watchdog_cancel+0x12/0x14
    [ 1814.851383]  netem_reset+0xe6/0xed [sch_netem]
    [ 1814.851561]  qdisc_destroy+0x8b/0xe5
    [ 1814.851723]  qdisc_create_dflt+0x86/0x94
    [ 1814.851890]  ? dev_activate+0x129/0x129
    [ 1814.852057]  attach_one_default_qdisc+0x36/0x63
    [ 1814.852232]  netdev_for_each_tx_queue+0x3d/0x48
    [ 1814.852406]  dev_activate+0x4b/0x129
    [ 1814.852569]  __dev_open+0xe7/0x104
    [ 1814.852730]  __dev_change_flags+0xc6/0x15c
    [ 1814.852899]  dev_change_flags+0x25/0x59
    [ 1814.853064]  do_setlink+0x30c/0xb3f
    [ 1814.853228]  ? check_chain_key+0xb0/0xfd
    [ 1814.853396]  ? check_chain_key+0xb0/0xfd
    [ 1814.853565]  rtnl_newlink+0x3a4/0x729
    [ 1814.853728]  ? rtnl_newlink+0x117/0x729
    [ 1814.853905]  ? ns_capable_common+0xd/0xb1
    [ 1814.854072]  ? ns_capable+0x13/0x15
    [ 1814.854234]  rtnetlink_rcv_msg+0x188/0x197
    [ 1814.854404]  ? rcu_read_unlock+0x3e/0x5f
    [ 1814.854572]  ? rtnl_newlink+0x729/0x729
    [ 1814.854737]  netlink_rcv_skb+0x6c/0xce
    [ 1814.854902]  rtnetlink_rcv+0x23/0x2a
    [ 1814.855064]  netlink_unicast+0x103/0x181
    [ 1814.855230]  netlink_sendmsg+0x326/0x337
    [ 1814.855398]  sock_sendmsg_nosec+0x14/0x3f
    [ 1814.855584]  sock_sendmsg+0x29/0x2e
    [ 1814.855747]  ___sys_sendmsg+0x209/0x28b
    [ 1814.855912]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 1814.856082]  ? _raw_spin_unlock+0x27/0x31
    [ 1814.856251]  ? __handle_mm_fault+0x651/0xdb1
    [ 1814.856421]  ? check_chain_key+0xb0/0xfd
    [ 1814.856592]  __sys_sendmsg+0x45/0x63
    [ 1814.856755]  ? __sys_sendmsg+0x45/0x63
    [ 1814.856923]  SyS_sendmsg+0x19/0x1b
    [ 1814.857083]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 1814.857256] RIP: 0033:0x7f733b2dd690
    [ 1814.857419] RSP: 002b:00007ffe1d3387d8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 1814.858238] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f733b2dd690
    [ 1814.858445] RDX: 0000000000000000 RSI: 00007ffe1d338820 RDI: 0000000000000003
    [ 1814.858651] RBP: ffff88005adcbf98 R08: 0000000000000001 R09: 0000000000000003
    [ 1814.858856] R10: 00007ffe1d3385a0 R11: 0000000000000246 R12: 0000000000000002
    [ 1814.859060] R13: 000000000066f1a0 R14: 00007ffe1d3408d0 R15: 0000000000000000
    [ 1814.859267]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 1814.859446] Code: 10 55 48 89 c7 48 89 e5 e8 45 a1 fb ff 31 c0 5d c3
    31 c0 c3 66 66 66 66 90 55 48 89 e5 41 56 41 55 41 54 53 49 89 fd 49 8b
    45 30 <4c> 8b 20 41 8b 5c 24 38 31 c9 31 d2 48 c7 c7 50 8e 1d 82 41 89
    [ 1814.860022] RIP: hrtimer_active+0x17/0x8a RSP: ffff88005adcb590
    [ 1814.860214] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9dafa62c875599b077445866d2bd903afdc7e60e
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:59 2017 +0300

    sch_hhf: fix null pointer dereference on init failure
    
    commit 32db864d33c21fd70a217ba53cb7224889354ffb upstream.
    
    If sch_hhf fails in its ->init() function (either due to wrong
    user-space arguments as below or memory alloc failure of hh_flows) it
    will do a null pointer deref of q->hh_flows in its ->destroy() function.
    
    To reproduce the crash:
    $ tc qdisc add dev eth0 root hhf quantum 2000000 non_hh_weight 10000000
    
    Crash log:
    [  690.654882] BUG: unable to handle kernel NULL pointer dereference at (null)
    [  690.655565] IP: hhf_destroy+0x48/0xbc
    [  690.655944] PGD 37345067
    [  690.655948] P4D 37345067
    [  690.656252] PUD 58402067
    [  690.656554] PMD 0
    [  690.656857]
    [  690.657362] Oops: 0000 [#1] SMP
    [  690.657696] Modules linked in:
    [  690.658032] CPU: 3 PID: 920 Comm: tc Not tainted 4.13.0-rc6+ #57
    [  690.658525] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  690.659255] task: ffff880058578000 task.stack: ffff88005acbc000
    [  690.659747] RIP: 0010:hhf_destroy+0x48/0xbc
    [  690.660146] RSP: 0018:ffff88005acbf9e0 EFLAGS: 00010246
    [  690.660601] RAX: 0000000000000000 RBX: 0000000000000020 RCX: 0000000000000000
    [  690.661155] RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffffffff821f63f0
    [  690.661710] RBP: ffff88005acbfa08 R08: ffffffff81b10a90 R09: 0000000000000000
    [  690.662267] R10: 00000000f42b7019 R11: ffff880058578000 R12: 00000000ffffffea
    [  690.662820] R13: ffff8800372f6400 R14: 0000000000000000 R15: 0000000000000000
    [  690.663769] FS:  00007f8ae5e8b740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [  690.667069] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  690.667965] CR2: 0000000000000000 CR3: 0000000058523000 CR4: 00000000000406e0
    [  690.668918] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  690.669945] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  690.671003] Call Trace:
    [  690.671743]  qdisc_create+0x377/0x3fd
    [  690.672534]  tc_modify_qdisc+0x4d2/0x4fd
    [  690.673324]  rtnetlink_rcv_msg+0x188/0x197
    [  690.674204]  ? rcu_read_unlock+0x3e/0x5f
    [  690.675091]  ? rtnl_newlink+0x729/0x729
    [  690.675877]  netlink_rcv_skb+0x6c/0xce
    [  690.676648]  rtnetlink_rcv+0x23/0x2a
    [  690.677405]  netlink_unicast+0x103/0x181
    [  690.678179]  netlink_sendmsg+0x326/0x337
    [  690.678958]  sock_sendmsg_nosec+0x14/0x3f
    [  690.679743]  sock_sendmsg+0x29/0x2e
    [  690.680506]  ___sys_sendmsg+0x209/0x28b
    [  690.681283]  ? __handle_mm_fault+0xc7d/0xdb1
    [  690.681915]  ? check_chain_key+0xb0/0xfd
    [  690.682449]  __sys_sendmsg+0x45/0x63
    [  690.682954]  ? __sys_sendmsg+0x45/0x63
    [  690.683471]  SyS_sendmsg+0x19/0x1b
    [  690.683974]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  690.684516] RIP: 0033:0x7f8ae529d690
    [  690.685016] RSP: 002b:00007fff26d2d6b8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  690.685931] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f8ae529d690
    [  690.686573] RDX: 0000000000000000 RSI: 00007fff26d2d700 RDI: 0000000000000003
    [  690.687047] RBP: ffff88005acbff98 R08: 0000000000000001 R09: 0000000000000000
    [  690.687519] R10: 00007fff26d2d480 R11: 0000000000000246 R12: 0000000000000002
    [  690.687996] R13: 0000000001258070 R14: 0000000000000001 R15: 0000000000000000
    [  690.688475]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  690.688887] Code: 00 00 e8 2a 02 ae ff 49 8b bc 1d 60 02 00 00 48 83
    c3 08 e8 19 02 ae ff 48 83 fb 20 75 dc 45 31 f6 4d 89 f7 4d 03 bd 20 02
    00 00 <49> 8b 07 49 39 c7 75 24 49 83 c6 10 49 81 fe 00 40 00 00 75 e1
    [  690.690200] RIP: hhf_destroy+0x48/0xbc RSP: ffff88005acbf9e0
    [  690.690636] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 10239edf86f1 ("net-qdisc-hhf: Heavy-Hitter Filter (HHF) qdisc")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 68858be0c1b5a2387c93f5bd4de8efddac149cbb
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:58 2017 +0300

    sch_multiq: fix double free on init failure
    
    commit e89d469e3be3ed3d7124a803211a463ff83d0964 upstream.
    
    The below commit added a call to ->destroy() on init failure, but multiq
    still frees ->queues on error in init, but ->queues is also freed by
    ->destroy() thus we get double free and corrupted memory.
    
    Very easy to reproduce (eth0 not multiqueue):
    $ tc qdisc add dev eth0 root multiq
    RTNETLINK answers: Operation not supported
    $ ip l add dumdum type dummy
    (crash)
    
    Trace log:
    [ 3929.467747] general protection fault: 0000 [#1] SMP
    [ 3929.468083] Modules linked in:
    [ 3929.468302] CPU: 3 PID: 967 Comm: ip Not tainted 4.13.0-rc6+ #56
    [ 3929.468625] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 3929.469124] task: ffff88003716a700 task.stack: ffff88005872c000
    [ 3929.469449] RIP: 0010:__kmalloc_track_caller+0x117/0x1be
    [ 3929.469746] RSP: 0018:ffff88005872f6a0 EFLAGS: 00010246
    [ 3929.470042] RAX: 00000000000002de RBX: 0000000058a59000 RCX: 00000000000002df
    [ 3929.470406] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff821f7020
    [ 3929.470770] RBP: ffff88005872f6e8 R08: 000000000001f010 R09: 0000000000000000
    [ 3929.471133] R10: ffff88005872f730 R11: 0000000000008cdd R12: ff006d75646d7564
    [ 3929.471496] R13: 00000000014000c0 R14: ffff88005b403c00 R15: ffff88005b403c00
    [ 3929.471869] FS:  00007f0b70480740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 3929.472286] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3929.472677] CR2: 00007ffcee4f3000 CR3: 0000000059d45000 CR4: 00000000000406e0
    [ 3929.473209] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 3929.474109] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 3929.474873] Call Trace:
    [ 3929.475337]  ? kstrdup_const+0x23/0x25
    [ 3929.475863]  kstrdup+0x2e/0x4b
    [ 3929.476338]  kstrdup_const+0x23/0x25
    [ 3929.478084]  __kernfs_new_node+0x28/0xbc
    [ 3929.478478]  kernfs_new_node+0x35/0x55
    [ 3929.478929]  kernfs_create_link+0x23/0x76
    [ 3929.479478]  sysfs_do_create_link_sd.isra.2+0x85/0xd7
    [ 3929.480096]  sysfs_create_link+0x33/0x35
    [ 3929.480649]  device_add+0x200/0x589
    [ 3929.481184]  netdev_register_kobject+0x7c/0x12f
    [ 3929.481711]  register_netdevice+0x373/0x471
    [ 3929.482174]  rtnl_newlink+0x614/0x729
    [ 3929.482610]  ? rtnl_newlink+0x17f/0x729
    [ 3929.483080]  rtnetlink_rcv_msg+0x188/0x197
    [ 3929.483533]  ? rcu_read_unlock+0x3e/0x5f
    [ 3929.483984]  ? rtnl_newlink+0x729/0x729
    [ 3929.484420]  netlink_rcv_skb+0x6c/0xce
    [ 3929.484858]  rtnetlink_rcv+0x23/0x2a
    [ 3929.485291]  netlink_unicast+0x103/0x181
    [ 3929.485735]  netlink_sendmsg+0x326/0x337
    [ 3929.486181]  sock_sendmsg_nosec+0x14/0x3f
    [ 3929.486614]  sock_sendmsg+0x29/0x2e
    [ 3929.486973]  ___sys_sendmsg+0x209/0x28b
    [ 3929.487340]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 3929.487719]  ? _raw_spin_unlock+0x27/0x31
    [ 3929.488092]  ? __handle_mm_fault+0x651/0xdb1
    [ 3929.488471]  ? check_chain_key+0xb0/0xfd
    [ 3929.488847]  __sys_sendmsg+0x45/0x63
    [ 3929.489206]  ? __sys_sendmsg+0x45/0x63
    [ 3929.489576]  SyS_sendmsg+0x19/0x1b
    [ 3929.489901]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 3929.490172] RIP: 0033:0x7f0b6fb93690
    [ 3929.490423] RSP: 002b:00007ffcee4ed588 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 3929.490881] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f0b6fb93690
    [ 3929.491198] RDX: 0000000000000000 RSI: 00007ffcee4ed5d0 RDI: 0000000000000003
    [ 3929.491521] RBP: ffff88005872ff98 R08: 0000000000000001 R09: 0000000000000000
    [ 3929.491801] R10: 00007ffcee4ed350 R11: 0000000000000246 R12: 0000000000000002
    [ 3929.492075] R13: 000000000066f1a0 R14: 00007ffcee4f5680 R15: 0000000000000000
    [ 3929.492352]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 3929.492590] Code: 8b 45 c0 48 8b 45 b8 74 17 48 8b 4d c8 83 ca ff 44
    89 ee 4c 89 f7 e8 83 ca ff ff 49 89 c4 eb 49 49 63 56 20 48 8d 48 01 4d
    8b 06 <49> 8b 1c 14 48 89 c2 4c 89 e0 65 49 0f c7 08 0f 94 c0 83 f0 01
    [ 3929.493335] RIP: __kmalloc_track_caller+0x117/0x1be RSP: ffff88005872f6a0
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: f07d1501292b ("multiq: Further multiqueue cleanup")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [AmitP: Removed unused variable 'err' in multiq_init()]
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7edd04ddb3f37d8bdecae07f05aae5bb48416211
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:57 2017 +0300

    sch_htb: fix crash on init failure
    
    commit 88c2ace69dbef696edba77712882af03879abc9c upstream.
    
    The commit below added a call to the ->destroy() callback for all qdiscs
    which failed in their ->init(), but some were not prepared for such
    change and can't handle partially initialized qdisc. HTB is one of them
    and if any error occurs before the qdisc watchdog timer and qdisc work are
    initialized then we can hit either a null ptr deref (timer->base) when
    canceling in ->destroy or lockdep error info about trying to register
    a non-static key and a stack dump. So to fix these two move the watchdog
    timer and workqueue init before anything that can err out.
    To reproduce userspace needs to send broken htb qdisc create request,
    tested with a modified tc (q_htb.c).
    
    Trace log:
    [ 2710.897602] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 2710.897977] IP: hrtimer_active+0x17/0x8a
    [ 2710.898174] PGD 58fab067
    [ 2710.898175] P4D 58fab067
    [ 2710.898353] PUD 586c0067
    [ 2710.898531] PMD 0
    [ 2710.898710]
    [ 2710.899045] Oops: 0000 [#1] SMP
    [ 2710.899232] Modules linked in:
    [ 2710.899419] CPU: 1 PID: 950 Comm: tc Not tainted 4.13.0-rc6+ #54
    [ 2710.899646] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 2710.900035] task: ffff880059ed2700 task.stack: ffff88005ad4c000
    [ 2710.900262] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 2710.900467] RSP: 0018:ffff88005ad4f960 EFLAGS: 00010246
    [ 2710.900684] RAX: 0000000000000000 RBX: ffff88003701e298 RCX: 0000000000000000
    [ 2710.900933] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff88003701e298
    [ 2710.901177] RBP: ffff88005ad4f980 R08: 0000000000000001 R09: 0000000000000001
    [ 2710.901419] R10: ffff88005ad4f800 R11: 0000000000000400 R12: 0000000000000000
    [ 2710.901663] R13: ffff88003701e298 R14: ffffffff822a4540 R15: ffff88005ad4fac0
    [ 2710.901907] FS:  00007f2f5e90f740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [ 2710.902277] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2710.902500] CR2: 0000000000000000 CR3: 0000000058ca3000 CR4: 00000000000406e0
    [ 2710.902744] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 2710.902977] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 2710.903180] Call Trace:
    [ 2710.903332]  hrtimer_try_to_cancel+0x1a/0x93
    [ 2710.903504]  hrtimer_cancel+0x15/0x20
    [ 2710.903667]  qdisc_watchdog_cancel+0x12/0x14
    [ 2710.903866]  htb_destroy+0x2e/0xf7
    [ 2710.904097]  qdisc_create+0x377/0x3fd
    [ 2710.904330]  tc_modify_qdisc+0x4d2/0x4fd
    [ 2710.904511]  rtnetlink_rcv_msg+0x188/0x197
    [ 2710.904682]  ? rcu_read_unlock+0x3e/0x5f
    [ 2710.904849]  ? rtnl_newlink+0x729/0x729
    [ 2710.905017]  netlink_rcv_skb+0x6c/0xce
    [ 2710.905183]  rtnetlink_rcv+0x23/0x2a
    [ 2710.905345]  netlink_unicast+0x103/0x181
    [ 2710.905511]  netlink_sendmsg+0x326/0x337
    [ 2710.905679]  sock_sendmsg_nosec+0x14/0x3f
    [ 2710.905847]  sock_sendmsg+0x29/0x2e
    [ 2710.906010]  ___sys_sendmsg+0x209/0x28b
    [ 2710.906176]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 2710.906346]  ? _raw_spin_unlock+0x27/0x31
    [ 2710.906514]  ? __handle_mm_fault+0x651/0xdb1
    [ 2710.906685]  ? check_chain_key+0xb0/0xfd
    [ 2710.906855]  __sys_sendmsg+0x45/0x63
    [ 2710.907018]  ? __sys_sendmsg+0x45/0x63
    [ 2710.907185]  SyS_sendmsg+0x19/0x1b
    [ 2710.907344]  entry_SYSCALL_64_fastpath+0x23/0xc2
    
    Note that probably this bug goes further back because the default qdisc
    handling always calls ->destroy on init failure too.
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [AmitP: Rebased for linux-4.4.y]
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bd3a83160c0d9ef4c0901ebd14ed77bdab93df2e
Author: zhangyi (F) <yi.zhang@huawei.com>
Date:   Tue Aug 14 10:34:42 2018 +0800

    PM / sleep: wakeup: Fix build error caused by missing SRCU support
    
    commit 3df6f61fff49632492490fb6e42646b803a9958a upstream.
    
    Commit ea0212f40c6 (power: auto select CONFIG_SRCU) made the code in
    drivers/base/power/wakeup.c use SRCU instead of RCU, but it forgot to
    select CONFIG_SRCU in Kconfig, which leads to the following build
    error if CONFIG_SRCU is not selected somewhere else:
    
    drivers/built-in.o: In function `wakeup_source_remove':
    (.text+0x3c6fc): undefined reference to `synchronize_srcu'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c7a8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c84c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d1d8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d228): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d24c): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d29c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o:(.data+0x4158): undefined reference to `process_srcu'
    
    Fix this error by selecting CONFIG_SRCU when PM_SLEEP is enabled.
    
    Fixes: ea0212f40c6 (power: auto select CONFIG_SRCU)
    Cc: 4.2+ <stable@vger.kernel.org> # 4.2+
    Signed-off-by: zhangyi (F) <yi.zhang@huawei.com>
    [ rjw: Minor subject/changelog fixups ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 18c5d285a9d4a878313116c1e7095ea1c0869ebe
Author: zhangyi (F) <yi.zhang@huawei.com>
Date:   Tue Aug 14 10:34:42 2018 +0800

    PM / sleep: wakeup: Fix build error caused by missing SRCU support
    
    commit 3df6f61fff49632492490fb6e42646b803a9958a upstream.
    
    Commit ea0212f40c6 (power: auto select CONFIG_SRCU) made the code in
    drivers/base/power/wakeup.c use SRCU instead of RCU, but it forgot to
    select CONFIG_SRCU in Kconfig, which leads to the following build
    error if CONFIG_SRCU is not selected somewhere else:
    
    drivers/built-in.o: In function `wakeup_source_remove':
    (.text+0x3c6fc): undefined reference to `synchronize_srcu'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c7a8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c84c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d1d8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d228): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d24c): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d29c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o:(.data+0x4158): undefined reference to `process_srcu'
    
    Fix this error by selecting CONFIG_SRCU when PM_SLEEP is enabled.
    
    Fixes: ea0212f40c6 (power: auto select CONFIG_SRCU)
    Cc: 4.2+ <stable@vger.kernel.org> # 4.2+
    Signed-off-by: zhangyi (F) <yi.zhang@huawei.com>
    [ rjw: Minor subject/changelog fixups ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 015156f5017987d4164630d763937834dd44506e
Author: zhangyi (F) <yi.zhang@huawei.com>
Date:   Tue Aug 14 10:34:42 2018 +0800

    PM / sleep: wakeup: Fix build error caused by missing SRCU support
    
    commit 3df6f61fff49632492490fb6e42646b803a9958a upstream.
    
    Commit ea0212f40c6 (power: auto select CONFIG_SRCU) made the code in
    drivers/base/power/wakeup.c use SRCU instead of RCU, but it forgot to
    select CONFIG_SRCU in Kconfig, which leads to the following build
    error if CONFIG_SRCU is not selected somewhere else:
    
    drivers/built-in.o: In function `wakeup_source_remove':
    (.text+0x3c6fc): undefined reference to `synchronize_srcu'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c7a8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c84c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d1d8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d228): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d24c): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d29c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o:(.data+0x4158): undefined reference to `process_srcu'
    
    Fix this error by selecting CONFIG_SRCU when PM_SLEEP is enabled.
    
    Fixes: ea0212f40c6 (power: auto select CONFIG_SRCU)
    Cc: 4.2+ <stable@vger.kernel.org> # 4.2+
    Signed-off-by: zhangyi (F) <yi.zhang@huawei.com>
    [ rjw: Minor subject/changelog fixups ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cd67823c9d34351a72c0e40d40e6b5dc86db2fe4
Author: zhangyi (F) <yi.zhang@huawei.com>
Date:   Tue Aug 14 10:34:42 2018 +0800

    PM / sleep: wakeup: Fix build error caused by missing SRCU support
    
    commit 3df6f61fff49632492490fb6e42646b803a9958a upstream.
    
    Commit ea0212f40c6 (power: auto select CONFIG_SRCU) made the code in
    drivers/base/power/wakeup.c use SRCU instead of RCU, but it forgot to
    select CONFIG_SRCU in Kconfig, which leads to the following build
    error if CONFIG_SRCU is not selected somewhere else:
    
    drivers/built-in.o: In function `wakeup_source_remove':
    (.text+0x3c6fc): undefined reference to `synchronize_srcu'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c7a8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c84c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d1d8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d228): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d24c): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d29c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o:(.data+0x4158): undefined reference to `process_srcu'
    
    Fix this error by selecting CONFIG_SRCU when PM_SLEEP is enabled.
    
    Fixes: ea0212f40c6 (power: auto select CONFIG_SRCU)
    Cc: 4.2+ <stable@vger.kernel.org> # 4.2+
    Signed-off-by: zhangyi (F) <yi.zhang@huawei.com>
    [ rjw: Minor subject/changelog fixups ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b970d8a1c213d8f030feddb3cbf934df4302eb47
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jul 19 10:27:13 2018 +0800

    net: caif: Add a missing rcu_read_unlock() in caif_flow_cb
    
    [ Upstream commit 64119e05f7b31e83e2555f6782e6cdc8f81c63f4 ]
    
    Add a missing rcu_read_unlock in the error path
    
    Fixes: c95567c80352 ("caif: added check for potential null return")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit eca9953f31a7365767c17a4018c058951d2b056f
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jul 19 10:27:13 2018 +0800

    net: caif: Add a missing rcu_read_unlock() in caif_flow_cb
    
    [ Upstream commit 64119e05f7b31e83e2555f6782e6cdc8f81c63f4 ]
    
    Add a missing rcu_read_unlock in the error path
    
    Fixes: c95567c80352 ("caif: added check for potential null return")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7193329df84d8d346585e22ea1b800b8fa177124
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jul 19 10:27:13 2018 +0800

    net: caif: Add a missing rcu_read_unlock() in caif_flow_cb
    
    [ Upstream commit 64119e05f7b31e83e2555f6782e6cdc8f81c63f4 ]
    
    Add a missing rcu_read_unlock in the error path
    
    Fixes: c95567c80352 ("caif: added check for potential null return")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4794000789d6007de094dbbeb37feca05e05c0e2
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jul 19 10:27:13 2018 +0800

    net: caif: Add a missing rcu_read_unlock() in caif_flow_cb
    
    [ Upstream commit 64119e05f7b31e83e2555f6782e6cdc8f81c63f4 ]
    
    Add a missing rcu_read_unlock in the error path
    
    Fixes: c95567c80352 ("caif: added check for potential null return")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2ceebc035082a42f1416d4b47270c0acb5354949
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Jul 6 15:16:12 2018 -0700

    rcutorture: Add RCU-bh and RCU-sched support for extended readers
    
    Since there is now a single consolidated RCU flavor, rcutorture
    needs to test extending of RCU readers via rcu_read_lock_bh() and
    rcu_read_lock_sched().  This commit adds this support, with added checks
    (just like for local_bh_enable()) to ensure that rcu_read_unlock_bh()
    will not be invoked while interrupts are disabled.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 3e31009898699dfca823893054748d85048dc7b3
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jun 21 12:50:01 2018 -0700

    rcu: Defer reporting RCU-preempt quiescent states when disabled
    
    This commit defers reporting of RCU-preempt quiescent states at
    rcu_read_unlock_special() time when any of interrupts, softirq, or
    preemption are disabled.  These deferred quiescent states are reported
    at a later RCU_SOFTIRQ, context switch, idle entry, or CPU-hotplug
    offline operation.  Of course, if another RCU read-side critical
    section has started in the meantime, the reporting of the quiescent
    state will be further deferred.
    
    This also means that disabling preemption, interrupts, and/or
    softirqs will act as an RCU-preempt read-side critical section.
    This is enforced by checking preempt_count() as needed.
    
    Some special cases must be handled on an ad-hoc basis, for example,
    context switch is a quiescent state even though both the scheduler and
    do_exit() disable preemption.  In these cases, additional calls to
    rcu_preempt_deferred_qs() override the preemption disabling.  Similar
    logic overrides disabled interrupts in rcu_preempt_check_callbacks()
    because in this case the quiescent state happened just before the
    corresponding scheduling-clock interrupt.
    
    In theory, this change lifts a long-standing restriction that required
    that if interrupts were disabled across a call to rcu_read_unlock()
    that the matching rcu_read_lock() also be contained within that
    interrupts-disabled region of code.  Because the reporting of the
    corresponding RCU-preempt quiescent state is now deferred until
    after interrupts have been enabled, it is no longer possible for this
    situation to result in deadlocks involving the scheduler's runqueue and
    priority-inheritance locks.  This may allow some code simplification that
    might reduce interrupt latency a bit.  Unfortunately, in practice this
    would also defer deboosting a low-priority task that had been subjected
    to RCU priority boosting, so real-time-response considerations might
    well force this restriction to remain in place.
    
    Because RCU-preempt grace periods are now blocked not only by RCU
    read-side critical sections, but also by disabling of interrupts,
    preemption, and softirqs, it will be possible to eliminate RCU-bh and
    RCU-sched in favor of RCU-preempt in CONFIG_PREEMPT=y kernels.  This may
    require some additional plumbing to provide the network denial-of-service
    guarantees that have been traditionally provided by RCU-bh.  Once these
    are in place, CONFIG_PREEMPT=n kernels will be able to fold RCU-bh
    into RCU-sched.  This would mean that all kernels would have but
    one flavor of RCU, which would open the door to significant code
    cleanup.
    
    Moving to a single flavor of RCU would also have the beneficial effect
    of reducing the NOCB kthreads by at least a factor of two.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Apply rcu_read_unlock_special() preempt_count() feedback
      from Joel Fernandes. ]
    [ paulmck: Adjust rcu_eqs_enter() call to rcu_preempt_deferred_qs() in
      response to bug reports from kbuild test robot. ]
    [ paulmck: Fix bug located by kbuild test robot involving recursion
      via rcu_preempt_deferred_qs(). ]

commit 41089b6d3e44a895076cc8ce56b08e463cb4f796
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Tue Aug 21 21:54:30 2018 -0700

    proc: save 2 atomic ops on write to "/proc/*/attr/*"
    
    Code checks if write is done by current to its own attributes.
    For that get/put pair is unnecessary as it can be done under RCU.
    
    Note: rcu_read_unlock() can be done even earlier since pointer to a task
    is not dereferenced. It depends if /proc code should look scary or not:
    
            rcu_read_lock();
            task = pid_task(...);
            rcu_read_unlock();
            if (!task)
                    return -ESRCH;
            if (task != current)
                    return -EACCESS:
    
    P.S.: rename "length" variable. Code like this
    
            length = -EINVAL;
    
    should not exist.
    
    Link: http://lkml.kernel.org/r/20180627200218.GF18113@avx2
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit ae1e16da14b2bca94272c9f23c930be48994b2bb
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Fri Aug 17 15:46:05 2018 -0700

    mm: workingset: remove local_irq_disable() from count_shadow_nodes()
    
    Patch series "mm: use irq locking suffix instead local_irq_disable()".
    
    A small series which avoids using local_irq_disable()/local_irq_enable()
    but instead does spin_lock_irq()/spin_unlock_irq() so it is within the
    context of the lock which it belongs to.  Patch #1 is a cleanup where
    local_irq_.*() remained after the lock was removed.
    
    This patch (of 2):
    
    In 0c7c1bed7e13 ("mm: make counting of list_lru_one::nr_items lockless")
    the
    
            spin_lock(&nlru->lock);
    
    statement was replaced with
    
            rcu_read_lock();
    
    in __list_lru_count_one().  The comment in count_shadow_nodes() says
    that the local_irq_disable() is required because the lock must be
    acquired with disabled interrupts and (spin_lock()) does not do so.
    Since the lock is replaced with rcu_read_lock() the local_irq_disable()
    is no longer needed.  The code path is
    
      list_lru_shrink_count()
        -> list_lru_count_one()
          -> __list_lru_count_one()
            -> rcu_read_lock()
            -> list_lru_from_memcg_idx()
            -> rcu_read_unlock()
    
    Remove the local_irq_disable() statement.
    
    Link: http://lkml.kernel.org/r/20180622151221.28167-2-bigeasy@linutronix.de
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
    Reviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Acked-by: Vladimir Davydov <vdavydov.dev@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 3df6f61fff49632492490fb6e42646b803a9958a
Author: zhangyi (F) <yi.zhang@huawei.com>
Date:   Tue Aug 14 10:34:42 2018 +0800

    PM / sleep: wakeup: Fix build error caused by missing SRCU support
    
    Commit ea0212f40c6 (power: auto select CONFIG_SRCU) made the code in
    drivers/base/power/wakeup.c use SRCU instead of RCU, but it forgot to
    select CONFIG_SRCU in Kconfig, which leads to the following build
    error if CONFIG_SRCU is not selected somewhere else:
    
    drivers/built-in.o: In function `wakeup_source_remove':
    (.text+0x3c6fc): undefined reference to `synchronize_srcu'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c7a8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `pm_print_active_wakeup_sources':
    (.text+0x3c84c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d1d8): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_arm_wake_irqs':
    (.text+0x3d228): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d24c): undefined reference to `__srcu_read_lock'
    drivers/built-in.o: In function `device_wakeup_disarm_wake_irqs':
    (.text+0x3d29c): undefined reference to `__srcu_read_unlock'
    drivers/built-in.o:(.data+0x4158): undefined reference to `process_srcu'
    
    Fix this error by selecting CONFIG_SRCU when PM_SLEEP is enabled.
    
    Fixes: ea0212f40c6 (power: auto select CONFIG_SRCU)
    Cc: 4.2+ <stable@vger.kernel.org> # 4.2+
    Signed-off-by: zhangyi (F) <yi.zhang@huawei.com>
    [ rjw: Minor subject/changelog fixups ]
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit 0723090656a03940c5ea536342f109e34b8d1257
Merge: f89ed2f880cc 03bc7cab7d72
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 24 17:31:47 2018 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Pull networking fixes from David Miller:
    
     1) Handle stations tied to AP_VLANs properly during mac80211 hw
        reconfig. From Manikanta Pubbisetty.
    
     2) Fix jump stack depth validation in nf_tables, from Taehee Yoo.
    
     3) Fix quota handling in aRFS flow expiration of mlx5 driver, from Eran
        Ben Elisha.
    
     4) Exit path handling fix in powerpc64 BPF JIT, from Daniel Borkmann.
    
     5) Use ptr_ring_consume_bh() in page pool code, from Tariq Toukan.
    
     6) Fix cached netdev name leak in nf_tables, from Florian Westphal.
    
     7) Fix memory leaks on chain rename, also from Florian Westphal.
    
     8) Several fixes to DCTCP congestion control ACK handling, from Yuchunk
        Cheng.
    
     9) Missing rcu_read_unlock() in CAIF protocol code, from Yue Haibing.
    
    10) Fix link local address handling with VRF, from David Ahern.
    
    11) Don't clobber 'err' on a successful call to __skb_linearize() in
        skb_segment(). From Eric Dumazet.
    
    12) Fix vxlan fdb notification races, from Roopa Prabhu.
    
    13) Hash UDP fragments consistently, from Paolo Abeni.
    
    14) If TCP receives lots of out of order tiny packets, we do really
        silly stuff. Make the out-of-order queue ending more robust to this
        kind of behavior, from Eric Dumazet.
    
    15) Don't leak netlink dump state in nf_tables, from Florian Westphal.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net: (76 commits)
      net: axienet: Fix double deregister of mdio
      qmi_wwan: fix interface number for DW5821e production firmware
      ip: in cmsg IP(V6)_ORIGDSTADDR call pskb_may_pull
      bnx2x: Fix invalid memory access in rss hash config path.
      net/mlx4_core: Save the qpn from the input modifier in RST2INIT wrapper
      r8169: restore previous behavior to accept BIOS WoL settings
      cfg80211: never ignore user regulatory hint
      sock: fix sg page frag coalescing in sk_alloc_sg
      netfilter: nf_tables: move dumper state allocation into ->start
      tcp: add tcp_ooo_try_coalesce() helper
      tcp: call tcp_drop() from tcp_data_queue_ofo()
      tcp: detect malicious patterns in tcp_collapse_ofo_queue()
      tcp: avoid collapses in tcp_prune_queue() if possible
      tcp: free batches of packets in tcp_prune_ofo_queue()
      ip: hash fragments consistently
      ipv6: use fib6_info_hold_safe() when necessary
      can: xilinx_can: fix power management handling
      can: xilinx_can: fix incorrect clear of non-processed interrupts
      can: xilinx_can: fix RX overflow interrupt not being enabled
      can: xilinx_can: keep only 1-2 frames in TX FIFO to fix TX accounting
      ...

commit 64119e05f7b31e83e2555f6782e6cdc8f81c63f4
Author: YueHaibing <yuehaibing@huawei.com>
Date:   Thu Jul 19 10:27:13 2018 +0800

    net: caif: Add a missing rcu_read_unlock() in caif_flow_cb
    
    Add a missing rcu_read_unlock in the error path
    
    Fixes: c95567c80352 ("caif: added check for potential null return")
    Signed-off-by: YueHaibing <yuehaibing@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 15651201fa055ec81d3669b36ab7c2fb12c3ce36
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 16 14:41:41 2018 -0700

    rcu: Mark task as .need_qs less aggressively
    
    If any scheduling-clock interrupt interrupts an RCU-preempt read-side
    critical section, the interrupted task's ->rcu_read_unlock_special.b.need_qs
    field is set.  This causes the outermost rcu_read_unlock() to incur the
    extra overhead of calling into rcu_read_unlock_special().  This commit
    reduces that overhead by setting ->rcu_read_unlock_special.b.need_qs only
    if the grace period has been in effect for more than one second.
    
    Why one second?  Because this is comfortably smaller than the minimum
    RCU CPU stall-warning timeout of three seconds, but long enough that the
    .need_qs marking should happen quite rarely.  And if your RCU read-side
    critical section has run on-CPU for a full second, it is not unreasonable
    to invest some CPU time in ending the grace period quickly.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 3949fa9bac090ad217534c30bc3b6572289abf21
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue May 8 15:29:10 2018 -0700

    rcu: Make rcu_read_unlock_special() static
    
    Because rcu_read_unlock_special() is no longer used outside of
    kernel/rcu/tree_plugin.h, this commit makes it static.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 962aff03c315b508d980422db5b49b49e4382119
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed May 2 12:49:21 2018 -0700

    rcu: Clean up handling of tasks blocked across full-rcu_node offline
    
    Commit 0aa04b055e71 ("rcu: Process offlining and onlining only at
    grace-period start") deferred handling of CPU-hotplug events until the
    start of the next grace period, but consider the following sequence
    of events:
    
    1.      A task is preempted within an RCU-preempt read-side critical
            section.
    
    2.      The CPU that this task was running on goes offline, along with all
            other CPUs sharing the corresponding leaf rcu_node structure.
    
    3.      The task resumes execution.
    
    4.      One of those CPUs comes back online before a new grace period starts.
    
    In step 2, the code in the next rcu_gp_init() invocation will (correctly)
    defer removing the leaf rcu_node structure from the upper-level bitmasks,
    and will (correctly) set that structure's ->wait_blkd_tasks field.  During
    the ensuing interval, RCU will (correctly) track the tasks preempted on
    that structure because they must block any subsequent grace period.
    
    In step 3, the code in rcu_read_unlock_special() will (correctly) remove
    the task from the leaf rcu_node structure.  From this point forward, RCU
    need not pay attention to this structure, at least not until one of the
    corresponding CPUs comes back online.
    
    In step 4, the code in the next rcu_gp_init() invocation will
    (incorrectly) invoke rcu_init_new_rnp().  This is incorrect because
    the corresponding rcu_cleanup_dead_rnp() was never invoked.  This is
    nevertheless harmless because the upper-level bits are still set.
    So, no harm, no foul, right?
    
    At least, all is well until a little further into rcu_gp_init()
    invocation, which will notice that there are no longer any tasks blocked
    on the leaf rcu_node structure, conclude that there is no longer anything
    left over from step 2's offline operation, and will therefore invoke
    rcu_cleanup_dead_rnp().  But this invocation of rcu_cleanup_dead_rnp()
    is for the beginning of the earlier offline interval, and the previous
    invocation of rcu_init_new_rnp() is for the end of that same interval.
    That is right, they are invoked out of order.
    
    That cannot be good, can it?
    
    It turns out that this is not a (correctness!) problem because
    rcu_cleanup_dead_rnp() checks to see if any of the corresponding CPUs
    are online, and refuses to do anything if so.  In other words, in the
    case where rcu_init_new_rnp() and rcu_cleanup_dead_rnp() execute out of
    order, they both have no effect.
    
    But this is at best an accident waiting to happen.
    
    This commit therefore adds logic to rcu_gp_init() so that
    rcu_init_new_rnp() and rcu_cleanup_dead_rnp() are always invoked in
    order, and so that neither are invoked at all in cases where RCU had to
    pay attention to the leaf rcu_node structure during the entire time that
    all corresponding CPUs were offline.
    
    And, while in the area, this commit reduces confusion by using formal
    parameters rather than local variables that just happen to have the same
    value at that particular point in the code.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit fd55a281adf6c9b9723d369203fdd92e5ea62a09
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Apr 27 10:06:03 2018 -0700

    srcu: Introduce srcu_read_{un,}lock_notrace()
    
    Joel Fernandes is using SRCU to protect from-idle tracepoints, which
    requires notrace variants of srcu_read_lock() and srcu_read_unlock()
    in order to avoid problems with tracepoints in lockdep.  This commit
    therefore adds srcu_read_lock_notrace() and srcu_read_unlock_notrace().
    
    [1] http://lkml.kernel.org/r/20180427042656.190746-1-joelaf@google.com
    
    Reported-by: Joel Fernandes <joelaf@google.com>
    Intermittently-reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 80279158472a5e10191c8f16a32af884dd16e803
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    commit 3b821409632ab778d46e807516b457dfa72736ed upstream.
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 8d80a839c1793f2237b91df59a5c46d4b02e7eda
Author: Mathieu Xhonneux <m.xhonneux@gmail.com>
Date:   Fri May 25 13:29:41 2018 +0100

    ipv6: sr: fix memory OOB access in seg6_do_srh_encap/inline
    
    [ Upstream commit bbb40a0b75209734ff9286f3326171638c9f6569 ]
    
    seg6_do_srh_encap and seg6_do_srh_inline can possibly do an
    out-of-bounds access when adding the SRH to the packet. This no longer
    happen when expanding the skb not only by the size of the SRH (+
    outer IPv6 header), but also by skb->mac_len.
    
    [   53.793056] BUG: KASAN: use-after-free in seg6_do_srh_encap+0x284/0x620
    [   53.794564] Write of size 14 at addr ffff88011975ecfa by task ping/674
    
    [   53.796665] CPU: 0 PID: 674 Comm: ping Not tainted 4.17.0-rc3-ARCH+ #90
    [   53.796670] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS 1.11.0-20171110_100015-anatol 04/01/2014
    [   53.796673] Call Trace:
    [   53.796679]  <IRQ>
    [   53.796689]  dump_stack+0x71/0xab
    [   53.796700]  print_address_description+0x6a/0x270
    [   53.796707]  kasan_report+0x258/0x380
    [   53.796715]  ? seg6_do_srh_encap+0x284/0x620
    [   53.796722]  memmove+0x34/0x50
    [   53.796730]  seg6_do_srh_encap+0x284/0x620
    [   53.796741]  ? seg6_do_srh+0x29b/0x360
    [   53.796747]  seg6_do_srh+0x29b/0x360
    [   53.796756]  seg6_input+0x2e/0x2e0
    [   53.796765]  lwtunnel_input+0x93/0xd0
    [   53.796774]  ipv6_rcv+0x690/0x920
    [   53.796783]  ? ip6_input+0x170/0x170
    [   53.796791]  ? eth_gro_receive+0x2d0/0x2d0
    [   53.796800]  ? ip6_input+0x170/0x170
    [   53.796809]  __netif_receive_skb_core+0xcc0/0x13f0
    [   53.796820]  ? netdev_info+0x110/0x110
    [   53.796827]  ? napi_complete_done+0xb6/0x170
    [   53.796834]  ? e1000_clean+0x6da/0xf70
    [   53.796845]  ? process_backlog+0x129/0x2a0
    [   53.796853]  process_backlog+0x129/0x2a0
    [   53.796862]  net_rx_action+0x211/0x5c0
    [   53.796870]  ? napi_complete_done+0x170/0x170
    [   53.796887]  ? run_rebalance_domains+0x11f/0x150
    [   53.796891]  __do_softirq+0x10e/0x39e
    [   53.796894]  do_softirq_own_stack+0x2a/0x40
    [   53.796895]  </IRQ>
    [   53.796898]  do_softirq.part.16+0x54/0x60
    [   53.796900]  __local_bh_enable_ip+0x5b/0x60
    [   53.796903]  ip6_finish_output2+0x416/0x9f0
    [   53.796906]  ? ip6_dst_lookup_flow+0x110/0x110
    [   53.796909]  ? ip6_sk_dst_lookup_flow+0x390/0x390
    [   53.796911]  ? __rcu_read_unlock+0x66/0x80
    [   53.796913]  ? ip6_mtu+0x44/0xf0
    [   53.796916]  ? ip6_output+0xfc/0x220
    [   53.796918]  ip6_output+0xfc/0x220
    [   53.796921]  ? ip6_finish_output+0x2b0/0x2b0
    [   53.796923]  ? memcpy+0x34/0x50
    [   53.796926]  ip6_send_skb+0x43/0xc0
    [   53.796929]  rawv6_sendmsg+0x1216/0x1530
    [   53.796932]  ? __orc_find+0x6b/0xc0
    [   53.796934]  ? rawv6_rcv_skb+0x160/0x160
    [   53.796937]  ? __rcu_read_unlock+0x66/0x80
    [   53.796939]  ? __rcu_read_unlock+0x66/0x80
    [   53.796942]  ? is_bpf_text_address+0x1e/0x30
    [   53.796944]  ? kernel_text_address+0xec/0x100
    [   53.796946]  ? __kernel_text_address+0xe/0x30
    [   53.796948]  ? unwind_get_return_address+0x2f/0x50
    [   53.796950]  ? __save_stack_trace+0x92/0x100
    [   53.796954]  ? save_stack+0x89/0xb0
    [   53.796956]  ? kasan_kmalloc+0xa0/0xd0
    [   53.796958]  ? kmem_cache_alloc+0xd2/0x1f0
    [   53.796961]  ? prepare_creds+0x23/0x160
    [   53.796963]  ? __x64_sys_capset+0x252/0x3e0
    [   53.796966]  ? do_syscall_64+0x69/0x160
    [   53.796968]  ? entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.796971]  ? __alloc_pages_nodemask+0x170/0x380
    [   53.796973]  ? __alloc_pages_slowpath+0x12c0/0x12c0
    [   53.796977]  ? tty_vhangup+0x20/0x20
    [   53.796979]  ? policy_nodemask+0x1a/0x90
    [   53.796982]  ? __mod_node_page_state+0x8d/0xa0
    [   53.796986]  ? __check_object_size+0xe7/0x240
    [   53.796989]  ? __sys_sendto+0x229/0x290
    [   53.796991]  ? rawv6_rcv_skb+0x160/0x160
    [   53.796993]  __sys_sendto+0x229/0x290
    [   53.796996]  ? __ia32_sys_getpeername+0x50/0x50
    [   53.796999]  ? commit_creds+0x2de/0x520
    [   53.797002]  ? security_capset+0x57/0x70
    [   53.797004]  ? __x64_sys_capset+0x29f/0x3e0
    [   53.797007]  ? __x64_sys_rt_sigsuspend+0xe0/0xe0
    [   53.797011]  ? __do_page_fault+0x664/0x770
    [   53.797014]  __x64_sys_sendto+0x74/0x90
    [   53.797017]  do_syscall_64+0x69/0x160
    [   53.797019]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.797022] RIP: 0033:0x7f43b7a6714a
    [   53.797023] RSP: 002b:00007ffd891bd368 EFLAGS: 00000246 ORIG_RAX:
    000000000000002c
    [   53.797026] RAX: ffffffffffffffda RBX: 00000000006129c0 RCX: 00007f43b7a6714a
    [   53.797028] RDX: 0000000000000040 RSI: 00000000006129c0 RDI: 0000000000000004
    [   53.797029] RBP: 00007ffd891be640 R08: 0000000000610940 R09: 000000000000001c
    [   53.797030] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000040
    [   53.797032] R13: 000000000060e6a0 R14: 0000000000008004 R15: 000000000040b661
    
    [   53.797171] Allocated by task 642:
    [   53.797460]  kasan_kmalloc+0xa0/0xd0
    [   53.797463]  kmem_cache_alloc+0xd2/0x1f0
    [   53.797465]  getname_flags+0x40/0x210
    [   53.797467]  user_path_at_empty+0x1d/0x40
    [   53.797469]  do_faccessat+0x12a/0x320
    [   53.797471]  do_syscall_64+0x69/0x160
    [   53.797473]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [   53.797607] Freed by task 642:
    [   53.797869]  __kasan_slab_free+0x130/0x180
    [   53.797871]  kmem_cache_free+0xa8/0x230
    [   53.797872]  filename_lookup+0x15b/0x230
    [   53.797874]  do_faccessat+0x12a/0x320
    [   53.797876]  do_syscall_64+0x69/0x160
    [   53.797878]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [   53.798014] The buggy address belongs to the object at ffff88011975e600
                    which belongs to the cache names_cache of size 4096
    [   53.799043] The buggy address is located 1786 bytes inside of
                    4096-byte region [ffff88011975e600, ffff88011975f600)
    [   53.800013] The buggy address belongs to the page:
    [   53.800414] page:ffffea000465d600 count:1 mapcount:0
    mapping:0000000000000000 index:0x0 compound_mapcount: 0
    [   53.801259] flags: 0x17fff0000008100(slab|head)
    [   53.801640] raw: 017fff0000008100 0000000000000000 0000000000000000
    0000000100070007
    [   53.803147] raw: dead000000000100 dead000000000200 ffff88011b185a40
    0000000000000000
    [   53.803787] page dumped because: kasan: bad access detected
    
    [   53.804384] Memory state around the buggy address:
    [   53.804788]  ffff88011975eb80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.805384]  ffff88011975ec00: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.805979] >ffff88011975ec80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.806577]                                                                 ^
    [   53.807165]  ffff88011975ed00: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.807762]  ffff88011975ed80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.808356] ==================================================================
    [   53.808949] Disabling lock debugging due to kernel taint
    
    Fixes: 6c8702c60b88 ("ipv6: sr: add support for SRH encapsulation and injection with lwtunnels")
    Signed-off-by: David Lebrun <dlebrun@google.com>
    Signed-off-by: Mathieu Xhonneux <m.xhonneux@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3a16f3bcb21d657a5de27acff308a79b196c99d4
Author: Mathieu Xhonneux <m.xhonneux@gmail.com>
Date:   Fri May 25 13:29:41 2018 +0100

    ipv6: sr: fix memory OOB access in seg6_do_srh_encap/inline
    
    [ Upstream commit bbb40a0b75209734ff9286f3326171638c9f6569 ]
    
    seg6_do_srh_encap and seg6_do_srh_inline can possibly do an
    out-of-bounds access when adding the SRH to the packet. This no longer
    happen when expanding the skb not only by the size of the SRH (+
    outer IPv6 header), but also by skb->mac_len.
    
    [   53.793056] BUG: KASAN: use-after-free in seg6_do_srh_encap+0x284/0x620
    [   53.794564] Write of size 14 at addr ffff88011975ecfa by task ping/674
    
    [   53.796665] CPU: 0 PID: 674 Comm: ping Not tainted 4.17.0-rc3-ARCH+ #90
    [   53.796670] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS 1.11.0-20171110_100015-anatol 04/01/2014
    [   53.796673] Call Trace:
    [   53.796679]  <IRQ>
    [   53.796689]  dump_stack+0x71/0xab
    [   53.796700]  print_address_description+0x6a/0x270
    [   53.796707]  kasan_report+0x258/0x380
    [   53.796715]  ? seg6_do_srh_encap+0x284/0x620
    [   53.796722]  memmove+0x34/0x50
    [   53.796730]  seg6_do_srh_encap+0x284/0x620
    [   53.796741]  ? seg6_do_srh+0x29b/0x360
    [   53.796747]  seg6_do_srh+0x29b/0x360
    [   53.796756]  seg6_input+0x2e/0x2e0
    [   53.796765]  lwtunnel_input+0x93/0xd0
    [   53.796774]  ipv6_rcv+0x690/0x920
    [   53.796783]  ? ip6_input+0x170/0x170
    [   53.796791]  ? eth_gro_receive+0x2d0/0x2d0
    [   53.796800]  ? ip6_input+0x170/0x170
    [   53.796809]  __netif_receive_skb_core+0xcc0/0x13f0
    [   53.796820]  ? netdev_info+0x110/0x110
    [   53.796827]  ? napi_complete_done+0xb6/0x170
    [   53.796834]  ? e1000_clean+0x6da/0xf70
    [   53.796845]  ? process_backlog+0x129/0x2a0
    [   53.796853]  process_backlog+0x129/0x2a0
    [   53.796862]  net_rx_action+0x211/0x5c0
    [   53.796870]  ? napi_complete_done+0x170/0x170
    [   53.796887]  ? run_rebalance_domains+0x11f/0x150
    [   53.796891]  __do_softirq+0x10e/0x39e
    [   53.796894]  do_softirq_own_stack+0x2a/0x40
    [   53.796895]  </IRQ>
    [   53.796898]  do_softirq.part.16+0x54/0x60
    [   53.796900]  __local_bh_enable_ip+0x5b/0x60
    [   53.796903]  ip6_finish_output2+0x416/0x9f0
    [   53.796906]  ? ip6_dst_lookup_flow+0x110/0x110
    [   53.796909]  ? ip6_sk_dst_lookup_flow+0x390/0x390
    [   53.796911]  ? __rcu_read_unlock+0x66/0x80
    [   53.796913]  ? ip6_mtu+0x44/0xf0
    [   53.796916]  ? ip6_output+0xfc/0x220
    [   53.796918]  ip6_output+0xfc/0x220
    [   53.796921]  ? ip6_finish_output+0x2b0/0x2b0
    [   53.796923]  ? memcpy+0x34/0x50
    [   53.796926]  ip6_send_skb+0x43/0xc0
    [   53.796929]  rawv6_sendmsg+0x1216/0x1530
    [   53.796932]  ? __orc_find+0x6b/0xc0
    [   53.796934]  ? rawv6_rcv_skb+0x160/0x160
    [   53.796937]  ? __rcu_read_unlock+0x66/0x80
    [   53.796939]  ? __rcu_read_unlock+0x66/0x80
    [   53.796942]  ? is_bpf_text_address+0x1e/0x30
    [   53.796944]  ? kernel_text_address+0xec/0x100
    [   53.796946]  ? __kernel_text_address+0xe/0x30
    [   53.796948]  ? unwind_get_return_address+0x2f/0x50
    [   53.796950]  ? __save_stack_trace+0x92/0x100
    [   53.796954]  ? save_stack+0x89/0xb0
    [   53.796956]  ? kasan_kmalloc+0xa0/0xd0
    [   53.796958]  ? kmem_cache_alloc+0xd2/0x1f0
    [   53.796961]  ? prepare_creds+0x23/0x160
    [   53.796963]  ? __x64_sys_capset+0x252/0x3e0
    [   53.796966]  ? do_syscall_64+0x69/0x160
    [   53.796968]  ? entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.796971]  ? __alloc_pages_nodemask+0x170/0x380
    [   53.796973]  ? __alloc_pages_slowpath+0x12c0/0x12c0
    [   53.796977]  ? tty_vhangup+0x20/0x20
    [   53.796979]  ? policy_nodemask+0x1a/0x90
    [   53.796982]  ? __mod_node_page_state+0x8d/0xa0
    [   53.796986]  ? __check_object_size+0xe7/0x240
    [   53.796989]  ? __sys_sendto+0x229/0x290
    [   53.796991]  ? rawv6_rcv_skb+0x160/0x160
    [   53.796993]  __sys_sendto+0x229/0x290
    [   53.796996]  ? __ia32_sys_getpeername+0x50/0x50
    [   53.796999]  ? commit_creds+0x2de/0x520
    [   53.797002]  ? security_capset+0x57/0x70
    [   53.797004]  ? __x64_sys_capset+0x29f/0x3e0
    [   53.797007]  ? __x64_sys_rt_sigsuspend+0xe0/0xe0
    [   53.797011]  ? __do_page_fault+0x664/0x770
    [   53.797014]  __x64_sys_sendto+0x74/0x90
    [   53.797017]  do_syscall_64+0x69/0x160
    [   53.797019]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.797022] RIP: 0033:0x7f43b7a6714a
    [   53.797023] RSP: 002b:00007ffd891bd368 EFLAGS: 00000246 ORIG_RAX:
    000000000000002c
    [   53.797026] RAX: ffffffffffffffda RBX: 00000000006129c0 RCX: 00007f43b7a6714a
    [   53.797028] RDX: 0000000000000040 RSI: 00000000006129c0 RDI: 0000000000000004
    [   53.797029] RBP: 00007ffd891be640 R08: 0000000000610940 R09: 000000000000001c
    [   53.797030] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000040
    [   53.797032] R13: 000000000060e6a0 R14: 0000000000008004 R15: 000000000040b661
    
    [   53.797171] Allocated by task 642:
    [   53.797460]  kasan_kmalloc+0xa0/0xd0
    [   53.797463]  kmem_cache_alloc+0xd2/0x1f0
    [   53.797465]  getname_flags+0x40/0x210
    [   53.797467]  user_path_at_empty+0x1d/0x40
    [   53.797469]  do_faccessat+0x12a/0x320
    [   53.797471]  do_syscall_64+0x69/0x160
    [   53.797473]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [   53.797607] Freed by task 642:
    [   53.797869]  __kasan_slab_free+0x130/0x180
    [   53.797871]  kmem_cache_free+0xa8/0x230
    [   53.797872]  filename_lookup+0x15b/0x230
    [   53.797874]  do_faccessat+0x12a/0x320
    [   53.797876]  do_syscall_64+0x69/0x160
    [   53.797878]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [   53.798014] The buggy address belongs to the object at ffff88011975e600
                    which belongs to the cache names_cache of size 4096
    [   53.799043] The buggy address is located 1786 bytes inside of
                    4096-byte region [ffff88011975e600, ffff88011975f600)
    [   53.800013] The buggy address belongs to the page:
    [   53.800414] page:ffffea000465d600 count:1 mapcount:0
    mapping:0000000000000000 index:0x0 compound_mapcount: 0
    [   53.801259] flags: 0x17fff0000008100(slab|head)
    [   53.801640] raw: 017fff0000008100 0000000000000000 0000000000000000
    0000000100070007
    [   53.803147] raw: dead000000000100 dead000000000200 ffff88011b185a40
    0000000000000000
    [   53.803787] page dumped because: kasan: bad access detected
    
    [   53.804384] Memory state around the buggy address:
    [   53.804788]  ffff88011975eb80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.805384]  ffff88011975ec00: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.805979] >ffff88011975ec80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.806577]                                                                 ^
    [   53.807165]  ffff88011975ed00: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.807762]  ffff88011975ed80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.808356] ==================================================================
    [   53.808949] Disabling lock debugging due to kernel taint
    
    Fixes: 6c8702c60b88 ("ipv6: sr: add support for SRH encapsulation and injection with lwtunnels")
    Signed-off-by: David Lebrun <dlebrun@google.com>
    Signed-off-by: Mathieu Xhonneux <m.xhonneux@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a8a4021b776b4475e8a4657185a718cdfc07b88c
Merge: 3ca24ce9ff76 59dc6f3c6d81
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jun 10 08:30:35 2018 -0700

    Merge branch 'core-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull core fixes from Thomas Gleixner:
     "A small set of core updates:
    
       - Make objtool cope with GCC8 oddities some more
    
       - Remove a stale local_irq_save/restore sequence in the signal code
         along with the stale comment in the RCU code. The underlying issue
         which led to this has been solved long time ago, but nobody cared
         to cleanup the hackarounds"
    
    * 'core-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      signal: Remove no longer required irqsave/restore
      rcu: Update documentation of rcu_read_unlock()
      objtool: Fix GCC 8 cold subfunction detection for aliased functions

commit ec84b27f9b3b569f9235413d1945a2006b97b0aa
Author: Anna-Maria Gleixner <anna-maria@linutronix.de>
Date:   Fri May 25 11:05:06 2018 +0200

    rcu: Update documentation of rcu_read_unlock()
    
    Since commit b4abf91047cf ("rtmutex: Make wait_lock irq safe") the
    explanation in rcu_read_unlock() documentation about irq unsafe rtmutex
    wait_lock is no longer valid.
    
    Remove it to prevent kernel developers reading the documentation to rely on
    it.
    
    Suggested-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Anna-Maria Gleixner <anna-maria@linutronix.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: bigeasy@linutronix.de
    Link: https://lkml.kernel.org/r/20180525090507.22248-2-anna-maria@linutronix.de

commit 404cbeb36ef7f67e3c89b977df8c563dd1b92e96
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Fri Mar 16 11:35:51 2018 +0900

    xfrm: fix rcu_read_unlock usage in xfrm_local_error
    
    [ Upstream commit 46c0ef6e1eb95f619d9f62da4332749153db92f7 ]
    
    In the xfrm_local_error, rcu_read_unlock should be called when afinfo
    is not NULL. because xfrm_state_get_afinfo calls rcu_read_unlock
    if afinfo is NULL.
    
    Fixes: af5d27c4e12b ("xfrm: remove xfrm_state_put_afinfo")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 020c32a91ee0d2744479dad9b2f8aab8a7081024
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Feb 17 15:16:22 2018 +0800

    xfrm: do not call rcu_read_unlock when afinfo is NULL in xfrm_get_tos
    
    [ Upstream commit 143a4454daaf0e80a2b9f37159a0d6d2b61e64ed ]
    
    When xfrm_policy_get_afinfo returns NULL, it will not hold rcu
    read lock. In this case, rcu_read_unlock should not be called
    in xfrm_get_tos, just like other places where it's calling
    xfrm_policy_get_afinfo.
    
    Fixes: f5e2bb4f5b22 ("xfrm: policy: xfrm_get_tos cannot fail")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bbb40a0b75209734ff9286f3326171638c9f6569
Author: Mathieu Xhonneux <m.xhonneux@gmail.com>
Date:   Fri May 25 13:29:41 2018 +0100

    ipv6: sr: fix memory OOB access in seg6_do_srh_encap/inline
    
    seg6_do_srh_encap and seg6_do_srh_inline can possibly do an
    out-of-bounds access when adding the SRH to the packet. This no longer
    happen when expanding the skb not only by the size of the SRH (+
    outer IPv6 header), but also by skb->mac_len.
    
    [   53.793056] BUG: KASAN: use-after-free in seg6_do_srh_encap+0x284/0x620
    [   53.794564] Write of size 14 at addr ffff88011975ecfa by task ping/674
    
    [   53.796665] CPU: 0 PID: 674 Comm: ping Not tainted 4.17.0-rc3-ARCH+ #90
    [   53.796670] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS 1.11.0-20171110_100015-anatol 04/01/2014
    [   53.796673] Call Trace:
    [   53.796679]  <IRQ>
    [   53.796689]  dump_stack+0x71/0xab
    [   53.796700]  print_address_description+0x6a/0x270
    [   53.796707]  kasan_report+0x258/0x380
    [   53.796715]  ? seg6_do_srh_encap+0x284/0x620
    [   53.796722]  memmove+0x34/0x50
    [   53.796730]  seg6_do_srh_encap+0x284/0x620
    [   53.796741]  ? seg6_do_srh+0x29b/0x360
    [   53.796747]  seg6_do_srh+0x29b/0x360
    [   53.796756]  seg6_input+0x2e/0x2e0
    [   53.796765]  lwtunnel_input+0x93/0xd0
    [   53.796774]  ipv6_rcv+0x690/0x920
    [   53.796783]  ? ip6_input+0x170/0x170
    [   53.796791]  ? eth_gro_receive+0x2d0/0x2d0
    [   53.796800]  ? ip6_input+0x170/0x170
    [   53.796809]  __netif_receive_skb_core+0xcc0/0x13f0
    [   53.796820]  ? netdev_info+0x110/0x110
    [   53.796827]  ? napi_complete_done+0xb6/0x170
    [   53.796834]  ? e1000_clean+0x6da/0xf70
    [   53.796845]  ? process_backlog+0x129/0x2a0
    [   53.796853]  process_backlog+0x129/0x2a0
    [   53.796862]  net_rx_action+0x211/0x5c0
    [   53.796870]  ? napi_complete_done+0x170/0x170
    [   53.796887]  ? run_rebalance_domains+0x11f/0x150
    [   53.796891]  __do_softirq+0x10e/0x39e
    [   53.796894]  do_softirq_own_stack+0x2a/0x40
    [   53.796895]  </IRQ>
    [   53.796898]  do_softirq.part.16+0x54/0x60
    [   53.796900]  __local_bh_enable_ip+0x5b/0x60
    [   53.796903]  ip6_finish_output2+0x416/0x9f0
    [   53.796906]  ? ip6_dst_lookup_flow+0x110/0x110
    [   53.796909]  ? ip6_sk_dst_lookup_flow+0x390/0x390
    [   53.796911]  ? __rcu_read_unlock+0x66/0x80
    [   53.796913]  ? ip6_mtu+0x44/0xf0
    [   53.796916]  ? ip6_output+0xfc/0x220
    [   53.796918]  ip6_output+0xfc/0x220
    [   53.796921]  ? ip6_finish_output+0x2b0/0x2b0
    [   53.796923]  ? memcpy+0x34/0x50
    [   53.796926]  ip6_send_skb+0x43/0xc0
    [   53.796929]  rawv6_sendmsg+0x1216/0x1530
    [   53.796932]  ? __orc_find+0x6b/0xc0
    [   53.796934]  ? rawv6_rcv_skb+0x160/0x160
    [   53.796937]  ? __rcu_read_unlock+0x66/0x80
    [   53.796939]  ? __rcu_read_unlock+0x66/0x80
    [   53.796942]  ? is_bpf_text_address+0x1e/0x30
    [   53.796944]  ? kernel_text_address+0xec/0x100
    [   53.796946]  ? __kernel_text_address+0xe/0x30
    [   53.796948]  ? unwind_get_return_address+0x2f/0x50
    [   53.796950]  ? __save_stack_trace+0x92/0x100
    [   53.796954]  ? save_stack+0x89/0xb0
    [   53.796956]  ? kasan_kmalloc+0xa0/0xd0
    [   53.796958]  ? kmem_cache_alloc+0xd2/0x1f0
    [   53.796961]  ? prepare_creds+0x23/0x160
    [   53.796963]  ? __x64_sys_capset+0x252/0x3e0
    [   53.796966]  ? do_syscall_64+0x69/0x160
    [   53.796968]  ? entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.796971]  ? __alloc_pages_nodemask+0x170/0x380
    [   53.796973]  ? __alloc_pages_slowpath+0x12c0/0x12c0
    [   53.796977]  ? tty_vhangup+0x20/0x20
    [   53.796979]  ? policy_nodemask+0x1a/0x90
    [   53.796982]  ? __mod_node_page_state+0x8d/0xa0
    [   53.796986]  ? __check_object_size+0xe7/0x240
    [   53.796989]  ? __sys_sendto+0x229/0x290
    [   53.796991]  ? rawv6_rcv_skb+0x160/0x160
    [   53.796993]  __sys_sendto+0x229/0x290
    [   53.796996]  ? __ia32_sys_getpeername+0x50/0x50
    [   53.796999]  ? commit_creds+0x2de/0x520
    [   53.797002]  ? security_capset+0x57/0x70
    [   53.797004]  ? __x64_sys_capset+0x29f/0x3e0
    [   53.797007]  ? __x64_sys_rt_sigsuspend+0xe0/0xe0
    [   53.797011]  ? __do_page_fault+0x664/0x770
    [   53.797014]  __x64_sys_sendto+0x74/0x90
    [   53.797017]  do_syscall_64+0x69/0x160
    [   53.797019]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   53.797022] RIP: 0033:0x7f43b7a6714a
    [   53.797023] RSP: 002b:00007ffd891bd368 EFLAGS: 00000246 ORIG_RAX:
    000000000000002c
    [   53.797026] RAX: ffffffffffffffda RBX: 00000000006129c0 RCX: 00007f43b7a6714a
    [   53.797028] RDX: 0000000000000040 RSI: 00000000006129c0 RDI: 0000000000000004
    [   53.797029] RBP: 00007ffd891be640 R08: 0000000000610940 R09: 000000000000001c
    [   53.797030] R10: 0000000000000000 R11: 0000000000000246 R12: 0000000000000040
    [   53.797032] R13: 000000000060e6a0 R14: 0000000000008004 R15: 000000000040b661
    
    [   53.797171] Allocated by task 642:
    [   53.797460]  kasan_kmalloc+0xa0/0xd0
    [   53.797463]  kmem_cache_alloc+0xd2/0x1f0
    [   53.797465]  getname_flags+0x40/0x210
    [   53.797467]  user_path_at_empty+0x1d/0x40
    [   53.797469]  do_faccessat+0x12a/0x320
    [   53.797471]  do_syscall_64+0x69/0x160
    [   53.797473]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [   53.797607] Freed by task 642:
    [   53.797869]  __kasan_slab_free+0x130/0x180
    [   53.797871]  kmem_cache_free+0xa8/0x230
    [   53.797872]  filename_lookup+0x15b/0x230
    [   53.797874]  do_faccessat+0x12a/0x320
    [   53.797876]  do_syscall_64+0x69/0x160
    [   53.797878]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    [   53.798014] The buggy address belongs to the object at ffff88011975e600
                    which belongs to the cache names_cache of size 4096
    [   53.799043] The buggy address is located 1786 bytes inside of
                    4096-byte region [ffff88011975e600, ffff88011975f600)
    [   53.800013] The buggy address belongs to the page:
    [   53.800414] page:ffffea000465d600 count:1 mapcount:0
    mapping:0000000000000000 index:0x0 compound_mapcount: 0
    [   53.801259] flags: 0x17fff0000008100(slab|head)
    [   53.801640] raw: 017fff0000008100 0000000000000000 0000000000000000
    0000000100070007
    [   53.803147] raw: dead000000000100 dead000000000200 ffff88011b185a40
    0000000000000000
    [   53.803787] page dumped because: kasan: bad access detected
    
    [   53.804384] Memory state around the buggy address:
    [   53.804788]  ffff88011975eb80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.805384]  ffff88011975ec00: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.805979] >ffff88011975ec80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.806577]                                                                 ^
    [   53.807165]  ffff88011975ed00: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.807762]  ffff88011975ed80: fb fb fb fb fb fb fb fb fb fb fb fb
    fb fb fb fb
    [   53.808356] ==================================================================
    [   53.808949] Disabling lock debugging due to kernel taint
    
    Fixes: 6c8702c60b88 ("ipv6: sr: add support for SRH encapsulation and injection with lwtunnels")
    Signed-off-by: David Lebrun <dlebrun@google.com>
    Signed-off-by: Mathieu Xhonneux <m.xhonneux@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1991e5efbff53bb66f03467343980f9d3bbea556
Author: Petr Machata <petrm@mellanox.com>
Date:   Thu May 17 16:36:10 2018 +0200

    net: ip6_gre: Request headroom in __gre6_xmit()
    
    [ Upstream commit 01b8d064d58b4c1f0eff47f8fe8a8508cb3b3840 ]
    
    __gre6_xmit() pushes GRE headers before handing over to ip6_tnl_xmit()
    for generic IP-in-IP processing. However it doesn't make sure that there
    is enough headroom to push the header to. That can lead to the panic
    cited below. (Reproducer below that).
    
    Fix by requesting either needed_headroom if already primed, or just the
    bare minimum needed for the header otherwise.
    
    [  158.576725] kernel BUG at net/core/skbuff.c:104!
    [  158.581510] invalid opcode: 0000 [#1] PREEMPT SMP KASAN PTI
    [  158.587174] Modules linked in: act_mirred cls_matchall ip6_gre ip6_tunnel tunnel6 gre sch_ingress vrf veth x86_pkg_temp_thermal mlx_platform nfsd e1000e leds_mlxcpld
    [  158.602268] CPU: 1 PID: 16 Comm: ksoftirqd/1 Not tainted 4.17.0-rc4-net_master-custom-139 #10
    [  158.610938] Hardware name: Mellanox Technologies Ltd. "MSN2410-CB2F"/"SA000874", BIOS 4.6.5 03/08/2016
    [  158.620426] RIP: 0010:skb_panic+0xc3/0x100
    [  158.624586] RSP: 0018:ffff8801d3f27110 EFLAGS: 00010286
    [  158.629882] RAX: 0000000000000082 RBX: ffff8801c02cc040 RCX: 0000000000000000
    [  158.637127] RDX: 0000000000000082 RSI: dffffc0000000000 RDI: ffffed003a7e4e18
    [  158.644366] RBP: ffff8801bfec8020 R08: ffffed003aabce19 R09: ffffed003aabce19
    [  158.651574] R10: 000000000000000b R11: ffffed003aabce18 R12: ffff8801c364de66
    [  158.658786] R13: 000000000000002c R14: 00000000000000c0 R15: ffff8801c364de68
    [  158.666007] FS:  0000000000000000(0000) GS:ffff8801d5400000(0000) knlGS:0000000000000000
    [  158.674212] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  158.680036] CR2: 00007f4b3702dcd0 CR3: 0000000003228002 CR4: 00000000001606e0
    [  158.687228] Call Trace:
    [  158.689752]  ? __gre6_xmit+0x246/0xd80 [ip6_gre]
    [  158.694475]  ? __gre6_xmit+0x246/0xd80 [ip6_gre]
    [  158.699141]  skb_push+0x78/0x90
    [  158.702344]  __gre6_xmit+0x246/0xd80 [ip6_gre]
    [  158.706872]  ip6gre_tunnel_xmit+0x3bc/0x610 [ip6_gre]
    [  158.711992]  ? __gre6_xmit+0xd80/0xd80 [ip6_gre]
    [  158.716668]  ? debug_check_no_locks_freed+0x210/0x210
    [  158.721761]  ? print_irqtrace_events+0x120/0x120
    [  158.726461]  ? sched_clock_cpu+0x18/0x210
    [  158.730572]  ? sched_clock_cpu+0x18/0x210
    [  158.734692]  ? cyc2ns_read_end+0x10/0x10
    [  158.738705]  ? skb_network_protocol+0x76/0x200
    [  158.743216]  ? netif_skb_features+0x1b2/0x550
    [  158.747648]  dev_hard_start_xmit+0x137/0x770
    [  158.752010]  sch_direct_xmit+0x2ef/0x5d0
    [  158.755992]  ? pfifo_fast_dequeue+0x3fa/0x670
    [  158.760460]  ? pfifo_fast_change_tx_queue_len+0x810/0x810
    [  158.765975]  ? __lock_is_held+0xa0/0x160
    [  158.770002]  __qdisc_run+0x39e/0xfc0
    [  158.773673]  ? _raw_spin_unlock+0x29/0x40
    [  158.777781]  ? pfifo_fast_enqueue+0x24b/0x3e0
    [  158.782191]  ? sch_direct_xmit+0x5d0/0x5d0
    [  158.786372]  ? pfifo_fast_dequeue+0x670/0x670
    [  158.790818]  ? __dev_queue_xmit+0x172/0x1770
    [  158.795195]  ? preempt_count_sub+0xf/0xd0
    [  158.799313]  __dev_queue_xmit+0x410/0x1770
    [  158.803512]  ? ___slab_alloc+0x605/0x930
    [  158.807525]  ? ___slab_alloc+0x605/0x930
    [  158.811540]  ? memcpy+0x34/0x50
    [  158.814768]  ? netdev_pick_tx+0x1c0/0x1c0
    [  158.818895]  ? __skb_clone+0x2fd/0x3d0
    [  158.822712]  ? __copy_skb_header+0x270/0x270
    [  158.827079]  ? rcu_read_lock_sched_held+0x93/0xa0
    [  158.831903]  ? kmem_cache_alloc+0x344/0x4d0
    [  158.836199]  ? skb_clone+0x123/0x230
    [  158.839869]  ? skb_split+0x820/0x820
    [  158.843521]  ? tcf_mirred+0x554/0x930 [act_mirred]
    [  158.848407]  tcf_mirred+0x554/0x930 [act_mirred]
    [  158.853104]  ? tcf_mirred_act_wants_ingress.part.2+0x10/0x10 [act_mirred]
    [  158.860005]  ? __lock_acquire+0x706/0x26e0
    [  158.864162]  ? mark_lock+0x13d/0xb40
    [  158.867832]  tcf_action_exec+0xcf/0x2a0
    [  158.871736]  tcf_classify+0xfa/0x340
    [  158.875402]  __netif_receive_skb_core+0x8e1/0x1c60
    [  158.880334]  ? nf_ingress+0x500/0x500
    [  158.884059]  ? process_backlog+0x347/0x4b0
    [  158.888241]  ? lock_acquire+0xd8/0x320
    [  158.892050]  ? process_backlog+0x1b6/0x4b0
    [  158.896228]  ? process_backlog+0xc2/0x4b0
    [  158.900291]  process_backlog+0xc2/0x4b0
    [  158.904210]  net_rx_action+0x5cc/0x980
    [  158.908047]  ? napi_complete_done+0x2c0/0x2c0
    [  158.912525]  ? rcu_read_unlock+0x80/0x80
    [  158.916534]  ? __lock_is_held+0x34/0x160
    [  158.920541]  __do_softirq+0x1d4/0x9d2
    [  158.924308]  ? trace_event_raw_event_irq_handler_exit+0x140/0x140
    [  158.930515]  run_ksoftirqd+0x1d/0x40
    [  158.934152]  smpboot_thread_fn+0x32b/0x690
    [  158.938299]  ? sort_range+0x20/0x20
    [  158.941842]  ? preempt_count_sub+0xf/0xd0
    [  158.945940]  ? schedule+0x5b/0x140
    [  158.949412]  kthread+0x206/0x300
    [  158.952689]  ? sort_range+0x20/0x20
    [  158.956249]  ? kthread_stop+0x570/0x570
    [  158.960164]  ret_from_fork+0x3a/0x50
    [  158.963823] Code: 14 3e ff 8b 4b 78 55 4d 89 f9 41 56 41 55 48 c7 c7 a0 cf db 82 41 54 44 8b 44 24 2c 48 8b 54 24 30 48 8b 74 24 20 e8 16 94 13 ff <0f> 0b 48 c7 c7 60 8e 1f 85 48 83 c4 20 e8 55 ef a6 ff 89 74 24
    [  158.983235] RIP: skb_panic+0xc3/0x100 RSP: ffff8801d3f27110
    [  158.988935] ---[ end trace 5af56ee845aa6cc8 ]---
    [  158.993641] Kernel panic - not syncing: Fatal exception in interrupt
    [  159.000176] Kernel Offset: disabled
    [  159.003767] ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---
    
    Reproducer:
    
            ip link add h1 type veth peer name swp1
            ip link add h3 type veth peer name swp3
    
            ip link set dev h1 up
            ip address add 192.0.2.1/28 dev h1
    
            ip link add dev vh3 type vrf table 20
            ip link set dev h3 master vh3
            ip link set dev vh3 up
            ip link set dev h3 up
    
            ip link set dev swp3 up
            ip address add dev swp3 2001:db8:2::1/64
    
            ip link set dev swp1 up
            tc qdisc add dev swp1 clsact
    
            ip link add name gt6 type ip6gretap \
                    local 2001:db8:2::1 remote 2001:db8:2::2
            ip link set dev gt6 up
    
            sleep 1
    
            tc filter add dev swp1 ingress pref 1000 matchall skip_hw \
                    action mirred egress mirror dev gt6
            ping -I h1 192.0.2.2
    
    Fixes: c12b395a4664 ("gre: Support GRE over IPv6")
    Signed-off-by: Petr Machata <petrm@mellanox.com>
    Acked-by: William Tu <u9012063@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3608a43f99e9e3328ded0687583107f3d3349eee
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    [ Upstream commit 3b821409632ab778d46e807516b457dfa72736ed ]
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>

commit 3daa84b7a5dc723ce55f8fca9659028e8d173d38
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 18 16:09:06 2018 -0700

    radix tree: fix multi-order iteration race
    
    commit 9f418224e8114156d995b98fa4e0f4fd21f685fe upstream.
    
    Fix a race in the multi-order iteration code which causes the kernel to
    hit a GP fault.  This was first seen with a production v4.15 based
    kernel (4.15.6-300.fc27.x86_64) utilizing a DAX workload which used
    order 9 PMD DAX entries.
    
    The race has to do with how we tear down multi-order sibling entries
    when we are removing an item from the tree.  Remember for example that
    an order 2 entry looks like this:
    
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
    
    where 'entry' is in some slot in the struct radix_tree_node, and the
    three slots following 'entry' contain sibling pointers which point back
    to 'entry.'
    
    When we delete 'entry' from the tree, we call :
    
      radix_tree_delete()
        radix_tree_delete_item()
          __radix_tree_delete()
            replace_slot()
    
    replace_slot() first removes the siblings in order from the first to the
    last, then at then replaces 'entry' with NULL.  This means that for a
    brief period of time we end up with one or more of the siblings removed,
    so:
    
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
    
    This causes an issue if you have a reader iterating over the slots in
    the tree via radix_tree_for_each_slot() while only under
    rcu_read_lock()/rcu_read_unlock() protection.  This is a common case in
    mm/filemap.c.
    
    The issue is that when __radix_tree_next_slot() => skip_siblings() tries
    to skip over the sibling entries in the slots, it currently does so with
    an exact match on the slot directly preceding our current slot.
    Normally this works:
    
                                          V preceding slot
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
                                                  ^ current slot
    
    This lets you find the first sibling, and you skip them all in order.
    
    But in the case where one of the siblings is NULL, that slot is skipped
    and then our sibling detection is interrupted:
    
                                                 V preceding slot
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
                                                        ^ current slot
    
    This means that the sibling pointers aren't recognized since they point
    all the way back to 'entry', so we think that they are normal internal
    radix tree pointers.  This causes us to think we need to walk down to a
    struct radix_tree_node starting at the address of 'entry'.
    
    In a real running kernel this will crash the thread with a GP fault when
    you try and dereference the slots in your broken node starting at
    'entry'.
    
    We fix this race by fixing the way that skip_siblings() detects sibling
    nodes.  Instead of testing against the preceding slot we instead look
    for siblings via is_sibling_entry() which compares against the position
    of the struct radix_tree_node.slots[] array.  This ensures that sibling
    entries are properly identified, even if they are no longer contiguous
    with the 'entry' they point to.
    
    Link: http://lkml.kernel.org/r/20180503192430.7582-6-ross.zwisler@linux.intel.com
    Fixes: 148deab223b2 ("radix-tree: improve multiorder iterators")
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reported-by: CR, Sapthagirish <sapthagirish.cr@intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 572e2385ae35f56cdc06ce37d0a117e8487f9845
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 18 16:09:06 2018 -0700

    radix tree: fix multi-order iteration race
    
    commit 9f418224e8114156d995b98fa4e0f4fd21f685fe upstream.
    
    Fix a race in the multi-order iteration code which causes the kernel to
    hit a GP fault.  This was first seen with a production v4.15 based
    kernel (4.15.6-300.fc27.x86_64) utilizing a DAX workload which used
    order 9 PMD DAX entries.
    
    The race has to do with how we tear down multi-order sibling entries
    when we are removing an item from the tree.  Remember for example that
    an order 2 entry looks like this:
    
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
    
    where 'entry' is in some slot in the struct radix_tree_node, and the
    three slots following 'entry' contain sibling pointers which point back
    to 'entry.'
    
    When we delete 'entry' from the tree, we call :
    
      radix_tree_delete()
        radix_tree_delete_item()
          __radix_tree_delete()
            replace_slot()
    
    replace_slot() first removes the siblings in order from the first to the
    last, then at then replaces 'entry' with NULL.  This means that for a
    brief period of time we end up with one or more of the siblings removed,
    so:
    
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
    
    This causes an issue if you have a reader iterating over the slots in
    the tree via radix_tree_for_each_slot() while only under
    rcu_read_lock()/rcu_read_unlock() protection.  This is a common case in
    mm/filemap.c.
    
    The issue is that when __radix_tree_next_slot() => skip_siblings() tries
    to skip over the sibling entries in the slots, it currently does so with
    an exact match on the slot directly preceding our current slot.
    Normally this works:
    
                                          V preceding slot
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
                                                  ^ current slot
    
    This lets you find the first sibling, and you skip them all in order.
    
    But in the case where one of the siblings is NULL, that slot is skipped
    and then our sibling detection is interrupted:
    
                                                 V preceding slot
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
                                                        ^ current slot
    
    This means that the sibling pointers aren't recognized since they point
    all the way back to 'entry', so we think that they are normal internal
    radix tree pointers.  This causes us to think we need to walk down to a
    struct radix_tree_node starting at the address of 'entry'.
    
    In a real running kernel this will crash the thread with a GP fault when
    you try and dereference the slots in your broken node starting at
    'entry'.
    
    We fix this race by fixing the way that skip_siblings() detects sibling
    nodes.  Instead of testing against the preceding slot we instead look
    for siblings via is_sibling_entry() which compares against the position
    of the struct radix_tree_node.slots[] array.  This ensures that sibling
    entries are properly identified, even if they are no longer contiguous
    with the 'entry' they point to.
    
    Link: http://lkml.kernel.org/r/20180503192430.7582-6-ross.zwisler@linux.intel.com
    Fixes: 148deab223b2 ("radix-tree: improve multiorder iterators")
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reported-by: CR, Sapthagirish <sapthagirish.cr@intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9f418224e8114156d995b98fa4e0f4fd21f685fe
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 18 16:09:06 2018 -0700

    radix tree: fix multi-order iteration race
    
    Fix a race in the multi-order iteration code which causes the kernel to
    hit a GP fault.  This was first seen with a production v4.15 based
    kernel (4.15.6-300.fc27.x86_64) utilizing a DAX workload which used
    order 9 PMD DAX entries.
    
    The race has to do with how we tear down multi-order sibling entries
    when we are removing an item from the tree.  Remember for example that
    an order 2 entry looks like this:
    
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
    
    where 'entry' is in some slot in the struct radix_tree_node, and the
    three slots following 'entry' contain sibling pointers which point back
    to 'entry.'
    
    When we delete 'entry' from the tree, we call :
    
      radix_tree_delete()
        radix_tree_delete_item()
          __radix_tree_delete()
            replace_slot()
    
    replace_slot() first removes the siblings in order from the first to the
    last, then at then replaces 'entry' with NULL.  This means that for a
    brief period of time we end up with one or more of the siblings removed,
    so:
    
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
    
    This causes an issue if you have a reader iterating over the slots in
    the tree via radix_tree_for_each_slot() while only under
    rcu_read_lock()/rcu_read_unlock() protection.  This is a common case in
    mm/filemap.c.
    
    The issue is that when __radix_tree_next_slot() => skip_siblings() tries
    to skip over the sibling entries in the slots, it currently does so with
    an exact match on the slot directly preceding our current slot.
    Normally this works:
    
                                          V preceding slot
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
                                                  ^ current slot
    
    This lets you find the first sibling, and you skip them all in order.
    
    But in the case where one of the siblings is NULL, that slot is skipped
    and then our sibling detection is interrupted:
    
                                                 V preceding slot
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
                                                        ^ current slot
    
    This means that the sibling pointers aren't recognized since they point
    all the way back to 'entry', so we think that they are normal internal
    radix tree pointers.  This causes us to think we need to walk down to a
    struct radix_tree_node starting at the address of 'entry'.
    
    In a real running kernel this will crash the thread with a GP fault when
    you try and dereference the slots in your broken node starting at
    'entry'.
    
    We fix this race by fixing the way that skip_siblings() detects sibling
    nodes.  Instead of testing against the preceding slot we instead look
    for siblings via is_sibling_entry() which compares against the position
    of the struct radix_tree_node.slots[] array.  This ensures that sibling
    entries are properly identified, even if they are no longer contiguous
    with the 'entry' they point to.
    
    Link: http://lkml.kernel.org/r/20180503192430.7582-6-ross.zwisler@linux.intel.com
    Fixes: 148deab223b2 ("radix-tree: improve multiorder iterators")
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Reported-by: CR, Sapthagirish <sapthagirish.cr@intel.com>
    Reviewed-by: Jan Kara <jack@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit fd8f58c40b703e47697c9f12bc16c31f14c161f1
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 18 16:09:01 2018 -0700

    radix tree test suite: multi-order iteration race
    
    Add a test which shows a race in the multi-order iteration code.  This
    test reliably hits the race in under a second on my machine, and is the
    result of a real bug report against kernel a production v4.15 based
    kernel (4.15.6-300.fc27.x86_64).  With a real kernel this issue is hit
    when using order 9 PMD DAX radix tree entries.
    
    The race has to do with how we tear down multi-order sibling entries
    when we are removing an item from the tree.  Remember that an order 2
    entry looks like this:
    
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
    
    where 'entry' is in some slot in the struct radix_tree_node, and the
    three slots following 'entry' contain sibling pointers which point back
    to 'entry.'
    
    When we delete 'entry' from the tree, we call :
    
      radix_tree_delete()
        radix_tree_delete_item()
          __radix_tree_delete()
            replace_slot()
    
    replace_slot() first removes the siblings in order from the first to the
    last, then at then replaces 'entry' with NULL.  This means that for a
    brief period of time we end up with one or more of the siblings removed,
    so:
    
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
    
    This causes an issue if you have a reader iterating over the slots in
    the tree via radix_tree_for_each_slot() while only under
    rcu_read_lock()/rcu_read_unlock() protection.  This is a common case in
    mm/filemap.c.
    
    The issue is that when __radix_tree_next_slot() => skip_siblings() tries
    to skip over the sibling entries in the slots, it currently does so with
    an exact match on the slot directly preceding our current slot.
    Normally this works:
    
                                          V preceding slot
      struct radix_tree_node.slots[] = [entry][sibling][sibling][sibling]
                                                  ^ current slot
    
    This lets you find the first sibling, and you skip them all in order.
    
    But in the case where one of the siblings is NULL, that slot is skipped
    and then our sibling detection is interrupted:
    
                                                 V preceding slot
      struct radix_tree_node.slots[] = [entry][NULL][sibling][sibling]
                                                        ^ current slot
    
    This means that the sibling pointers aren't recognized since they point
    all the way back to 'entry', so we think that they are normal internal
    radix tree pointers.  This causes us to think we need to walk down to a
    struct radix_tree_node starting at the address of 'entry'.
    
    In a real running kernel this will crash the thread with a GP fault when
    you try and dereference the slots in your broken node starting at
    'entry'.
    
    In the radix tree test suite this will be caught by the address
    sanitizer:
    
      ==27063==ERROR: AddressSanitizer: heap-buffer-overflow on address
      0x60c0008ae400 at pc 0x00000040ce4f bp 0x7fa89b8fcad0 sp 0x7fa89b8fcac0
      READ of size 8 at 0x60c0008ae400 thread T3
          #0 0x40ce4e in __radix_tree_next_slot /home/rzwisler/project/linux/tools/testing/radix-tree/radix-tree.c:1660
          #1 0x4022cc in radix_tree_next_slot linux/../../../../include/linux/radix-tree.h:567
          #2 0x4022cc in iterator_func /home/rzwisler/project/linux/tools/testing/radix-tree/multiorder.c:655
          #3 0x7fa8a088d50a in start_thread (/lib64/libpthread.so.0+0x750a)
          #4 0x7fa8a03bd16e in clone (/lib64/libc.so.6+0xf516e)
    
    Link: http://lkml.kernel.org/r/20180503192430.7582-5-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: CR, Sapthagirish <sapthagirish.cr@intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 3e252fa7d4f711798e7a3f5ff2d7b62f0e2987ce
Author: Ross Zwisler <ross.zwisler@linux.intel.com>
Date:   Fri May 18 16:08:58 2018 -0700

    radix tree test suite: add item_delete_rcu()
    
    Currently the lifetime of "struct item" entries in the radix tree are
    not controlled by RCU, but are instead deleted inline as they are
    removed from the tree.
    
    In the following patches we add a test which has threads iterating over
    items pulled from the tree and verifying them in an
    rcu_read_lock()/rcu_read_unlock() section.  This means that though an
    item has been removed from the tree it could still be being worked on by
    other threads until the RCU grace period expires.  So, we need to
    actually free the "struct item" structures at the end of the grace
    period, just as we do with "struct radix_tree_node" items.
    
    Link: http://lkml.kernel.org/r/20180503192430.7582-4-ross.zwisler@linux.intel.com
    Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: CR, Sapthagirish <sapthagirish.cr@intel.com>
    Cc: Dan Williams <dan.j.williams@intel.com>
    Cc: Dave Chinner <david@fromorbit.com>
    Cc: Jan Kara <jack@suse.cz>
    Cc: Matthew Wilcox <willy@infradead.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 01b8d064d58b4c1f0eff47f8fe8a8508cb3b3840
Author: Petr Machata <petrm@mellanox.com>
Date:   Thu May 17 16:36:10 2018 +0200

    net: ip6_gre: Request headroom in __gre6_xmit()
    
    __gre6_xmit() pushes GRE headers before handing over to ip6_tnl_xmit()
    for generic IP-in-IP processing. However it doesn't make sure that there
    is enough headroom to push the header to. That can lead to the panic
    cited below. (Reproducer below that).
    
    Fix by requesting either needed_headroom if already primed, or just the
    bare minimum needed for the header otherwise.
    
    [  158.576725] kernel BUG at net/core/skbuff.c:104!
    [  158.581510] invalid opcode: 0000 [#1] PREEMPT SMP KASAN PTI
    [  158.587174] Modules linked in: act_mirred cls_matchall ip6_gre ip6_tunnel tunnel6 gre sch_ingress vrf veth x86_pkg_temp_thermal mlx_platform nfsd e1000e leds_mlxcpld
    [  158.602268] CPU: 1 PID: 16 Comm: ksoftirqd/1 Not tainted 4.17.0-rc4-net_master-custom-139 #10
    [  158.610938] Hardware name: Mellanox Technologies Ltd. "MSN2410-CB2F"/"SA000874", BIOS 4.6.5 03/08/2016
    [  158.620426] RIP: 0010:skb_panic+0xc3/0x100
    [  158.624586] RSP: 0018:ffff8801d3f27110 EFLAGS: 00010286
    [  158.629882] RAX: 0000000000000082 RBX: ffff8801c02cc040 RCX: 0000000000000000
    [  158.637127] RDX: 0000000000000082 RSI: dffffc0000000000 RDI: ffffed003a7e4e18
    [  158.644366] RBP: ffff8801bfec8020 R08: ffffed003aabce19 R09: ffffed003aabce19
    [  158.651574] R10: 000000000000000b R11: ffffed003aabce18 R12: ffff8801c364de66
    [  158.658786] R13: 000000000000002c R14: 00000000000000c0 R15: ffff8801c364de68
    [  158.666007] FS:  0000000000000000(0000) GS:ffff8801d5400000(0000) knlGS:0000000000000000
    [  158.674212] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  158.680036] CR2: 00007f4b3702dcd0 CR3: 0000000003228002 CR4: 00000000001606e0
    [  158.687228] Call Trace:
    [  158.689752]  ? __gre6_xmit+0x246/0xd80 [ip6_gre]
    [  158.694475]  ? __gre6_xmit+0x246/0xd80 [ip6_gre]
    [  158.699141]  skb_push+0x78/0x90
    [  158.702344]  __gre6_xmit+0x246/0xd80 [ip6_gre]
    [  158.706872]  ip6gre_tunnel_xmit+0x3bc/0x610 [ip6_gre]
    [  158.711992]  ? __gre6_xmit+0xd80/0xd80 [ip6_gre]
    [  158.716668]  ? debug_check_no_locks_freed+0x210/0x210
    [  158.721761]  ? print_irqtrace_events+0x120/0x120
    [  158.726461]  ? sched_clock_cpu+0x18/0x210
    [  158.730572]  ? sched_clock_cpu+0x18/0x210
    [  158.734692]  ? cyc2ns_read_end+0x10/0x10
    [  158.738705]  ? skb_network_protocol+0x76/0x200
    [  158.743216]  ? netif_skb_features+0x1b2/0x550
    [  158.747648]  dev_hard_start_xmit+0x137/0x770
    [  158.752010]  sch_direct_xmit+0x2ef/0x5d0
    [  158.755992]  ? pfifo_fast_dequeue+0x3fa/0x670
    [  158.760460]  ? pfifo_fast_change_tx_queue_len+0x810/0x810
    [  158.765975]  ? __lock_is_held+0xa0/0x160
    [  158.770002]  __qdisc_run+0x39e/0xfc0
    [  158.773673]  ? _raw_spin_unlock+0x29/0x40
    [  158.777781]  ? pfifo_fast_enqueue+0x24b/0x3e0
    [  158.782191]  ? sch_direct_xmit+0x5d0/0x5d0
    [  158.786372]  ? pfifo_fast_dequeue+0x670/0x670
    [  158.790818]  ? __dev_queue_xmit+0x172/0x1770
    [  158.795195]  ? preempt_count_sub+0xf/0xd0
    [  158.799313]  __dev_queue_xmit+0x410/0x1770
    [  158.803512]  ? ___slab_alloc+0x605/0x930
    [  158.807525]  ? ___slab_alloc+0x605/0x930
    [  158.811540]  ? memcpy+0x34/0x50
    [  158.814768]  ? netdev_pick_tx+0x1c0/0x1c0
    [  158.818895]  ? __skb_clone+0x2fd/0x3d0
    [  158.822712]  ? __copy_skb_header+0x270/0x270
    [  158.827079]  ? rcu_read_lock_sched_held+0x93/0xa0
    [  158.831903]  ? kmem_cache_alloc+0x344/0x4d0
    [  158.836199]  ? skb_clone+0x123/0x230
    [  158.839869]  ? skb_split+0x820/0x820
    [  158.843521]  ? tcf_mirred+0x554/0x930 [act_mirred]
    [  158.848407]  tcf_mirred+0x554/0x930 [act_mirred]
    [  158.853104]  ? tcf_mirred_act_wants_ingress.part.2+0x10/0x10 [act_mirred]
    [  158.860005]  ? __lock_acquire+0x706/0x26e0
    [  158.864162]  ? mark_lock+0x13d/0xb40
    [  158.867832]  tcf_action_exec+0xcf/0x2a0
    [  158.871736]  tcf_classify+0xfa/0x340
    [  158.875402]  __netif_receive_skb_core+0x8e1/0x1c60
    [  158.880334]  ? nf_ingress+0x500/0x500
    [  158.884059]  ? process_backlog+0x347/0x4b0
    [  158.888241]  ? lock_acquire+0xd8/0x320
    [  158.892050]  ? process_backlog+0x1b6/0x4b0
    [  158.896228]  ? process_backlog+0xc2/0x4b0
    [  158.900291]  process_backlog+0xc2/0x4b0
    [  158.904210]  net_rx_action+0x5cc/0x980
    [  158.908047]  ? napi_complete_done+0x2c0/0x2c0
    [  158.912525]  ? rcu_read_unlock+0x80/0x80
    [  158.916534]  ? __lock_is_held+0x34/0x160
    [  158.920541]  __do_softirq+0x1d4/0x9d2
    [  158.924308]  ? trace_event_raw_event_irq_handler_exit+0x140/0x140
    [  158.930515]  run_ksoftirqd+0x1d/0x40
    [  158.934152]  smpboot_thread_fn+0x32b/0x690
    [  158.938299]  ? sort_range+0x20/0x20
    [  158.941842]  ? preempt_count_sub+0xf/0xd0
    [  158.945940]  ? schedule+0x5b/0x140
    [  158.949412]  kthread+0x206/0x300
    [  158.952689]  ? sort_range+0x20/0x20
    [  158.956249]  ? kthread_stop+0x570/0x570
    [  158.960164]  ret_from_fork+0x3a/0x50
    [  158.963823] Code: 14 3e ff 8b 4b 78 55 4d 89 f9 41 56 41 55 48 c7 c7 a0 cf db 82 41 54 44 8b 44 24 2c 48 8b 54 24 30 48 8b 74 24 20 e8 16 94 13 ff <0f> 0b 48 c7 c7 60 8e 1f 85 48 83 c4 20 e8 55 ef a6 ff 89 74 24
    [  158.983235] RIP: skb_panic+0xc3/0x100 RSP: ffff8801d3f27110
    [  158.988935] ---[ end trace 5af56ee845aa6cc8 ]---
    [  158.993641] Kernel panic - not syncing: Fatal exception in interrupt
    [  159.000176] Kernel Offset: disabled
    [  159.003767] ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---
    
    Reproducer:
    
            ip link add h1 type veth peer name swp1
            ip link add h3 type veth peer name swp3
    
            ip link set dev h1 up
            ip address add 192.0.2.1/28 dev h1
    
            ip link add dev vh3 type vrf table 20
            ip link set dev h3 master vh3
            ip link set dev vh3 up
            ip link set dev h3 up
    
            ip link set dev swp3 up
            ip address add dev swp3 2001:db8:2::1/64
    
            ip link set dev swp1 up
            tc qdisc add dev swp1 clsact
    
            ip link add name gt6 type ip6gretap \
                    local 2001:db8:2::1 remote 2001:db8:2::2
            ip link set dev gt6 up
    
            sleep 1
    
            tc filter add dev swp1 ingress pref 1000 matchall skip_hw \
                    action mirred egress mirror dev gt6
            ping -I h1 192.0.2.2
    
    Fixes: c12b395a4664 ("gre: Support GRE over IPv6")
    Signed-off-by: Petr Machata <petrm@mellanox.com>
    Acked-by: William Tu <u9012063@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 0e5da22e3f809ab9e86a566b9537b02b9496408e
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Mar 19 08:05:04 2018 -0700

    rcu: Move __rcu_read_lock() and __rcu_read_unlock() to tree_plugin.h
    
    The __rcu_read_lock() and __rcu_read_unlock() functions were moved
    to kernel/rcu/update.c in order to implement tiny preemptible RCU.
    However, tiny preemptible RCU was removed from the kernel a long time
    ago, so this commit belatedly moves them back into the only remaining
    preemptible-RCU code.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Nicholas Piggin <npiggin@gmail.com>

commit 5781ac24bbd998ebb1ff30143bb06244d847af48
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jan 11 21:50:46 2017 -0500

    ext4: fix deadlock between inline_data and ext4_expand_extra_isize_ea()
    
    commit c755e251357a0cee0679081f08c3f4ba797a8009 upstream.
    
    The xattr_sem deadlock problems fixed in commit 2e81a4eeedca: "ext4:
    avoid deadlock when expanding inode size" didn't include the use of
    xattr_sem in fs/ext4/inline.c.  With the addition of project quota
    which added a new extra inode field, this exposed deadlocks in the
    inline_data code similar to the ones fixed by 2e81a4eeedca.
    
    The deadlock can be reproduced via:
    
       dmesg -n 7
       mke2fs -t ext4 -O inline_data -Fq -I 256 /dev/vdc 32768
       mount -t ext4 -o debug_want_extra_isize=24 /dev/vdc /vdc
       mkdir /vdc/a
       umount /vdc
       mount -t ext4 /dev/vdc /vdc
       echo foo > /vdc/a/foo
    
    and looks like this:
    
    [   11.158815]
    [   11.160276] =============================================
    [   11.161960] [ INFO: possible recursive locking detected ]
    [   11.161960] 4.10.0-rc3-00015-g011b30a8a3cf #160 Tainted: G        W
    [   11.161960] ---------------------------------------------
    [   11.161960] bash/2519 is trying to acquire lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1225a4b>] ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]
    [   11.161960] but task is already holding lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] other info that might help us debug this:
    [   11.161960]  Possible unsafe locking scenario:
    [   11.161960]
    [   11.161960]        CPU0
    [   11.161960]        ----
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]
    [   11.161960]  *** DEADLOCK ***
    [   11.161960]
    [   11.161960]  May be due to missing lock nesting notation
    [   11.161960]
    [   11.161960] 4 locks held by bash/2519:
    [   11.161960]  #0:  (sb_writers#3){.+.+.+}, at: [<c11a2414>] mnt_want_write+0x1e/0x3e
    [   11.161960]  #1:  (&type->i_mutex_dir_key){++++++}, at: [<c119508b>] path_openat+0x338/0x67a
    [   11.161960]  #2:  (jbd2_handle){++++..}, at: [<c123314a>] start_this_handle+0x582/0x622
    [   11.161960]  #3:  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] stack backtrace:
    [   11.161960] CPU: 0 PID: 2519 Comm: bash Tainted: G        W       4.10.0-rc3-00015-g011b30a8a3cf #160
    [   11.161960] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1 04/01/2014
    [   11.161960] Call Trace:
    [   11.161960]  dump_stack+0x72/0xa3
    [   11.161960]  __lock_acquire+0xb7c/0xcb9
    [   11.161960]  ? kvm_clock_read+0x1f/0x29
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  lock_acquire+0x106/0x18a
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  down_write+0x39/0x72
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ? _raw_read_unlock+0x22/0x2c
    [   11.161960]  ? jbd2_journal_extend+0x1e2/0x262
    [   11.161960]  ? __ext4_journal_get_write_access+0x3d/0x60
    [   11.161960]  ext4_mark_inode_dirty+0x17d/0x26d
    [   11.161960]  ? ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_try_add_inline_entry+0x69/0x152
    [   11.161960]  ext4_add_entry+0xa3/0x848
    [   11.161960]  ? __brelse+0x14/0x2f
    [   11.161960]  ? _raw_spin_unlock_irqrestore+0x44/0x4f
    [   11.161960]  ext4_add_nondir+0x17/0x5b
    [   11.161960]  ext4_create+0xcf/0x133
    [   11.161960]  ? ext4_mknod+0x12f/0x12f
    [   11.161960]  lookup_open+0x39e/0x3fb
    [   11.161960]  ? __wake_up+0x1a/0x40
    [   11.161960]  ? lock_acquire+0x11e/0x18a
    [   11.161960]  path_openat+0x35c/0x67a
    [   11.161960]  ? sched_clock_cpu+0xd7/0xf2
    [   11.161960]  do_filp_open+0x36/0x7c
    [   11.161960]  ? _raw_spin_unlock+0x22/0x2c
    [   11.161960]  ? __alloc_fd+0x169/0x173
    [   11.161960]  do_sys_open+0x59/0xcc
    [   11.161960]  SyS_open+0x1d/0x1f
    [   11.161960]  do_int80_syscall_32+0x4f/0x61
    [   11.161960]  entry_INT80_32+0x2f/0x2f
    [   11.161960] EIP: 0xb76ad469
    [   11.161960] EFLAGS: 00000286 CPU: 0
    [   11.161960] EAX: ffffffda EBX: 08168ac8 ECX: 00008241 EDX: 000001b6
    [   11.161960] ESI: b75e46bc EDI: b7755000 EBP: bfbdb108 ESP: bfbdafc0
    [   11.161960]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Cc: stable@vger.kernel.org # 3.10 (requires 2e81a4eeedca as a prereq)
    Reported-by: George Spelvin <linux@sciencehorizons.net>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Harsh Shandilya <harsh@prjkt.io>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9b06cce3ca4d60d442c39bfa7c058b71b1cee6c2
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jan 11 21:50:46 2017 -0500

    ext4: fix deadlock between inline_data and ext4_expand_extra_isize_ea()
    
    commit c755e251357a0cee0679081f08c3f4ba797a8009 upstream.
    
    The xattr_sem deadlock problems fixed in commit 2e81a4eeedca: "ext4:
    avoid deadlock when expanding inode size" didn't include the use of
    xattr_sem in fs/ext4/inline.c.  With the addition of project quota
    which added a new extra inode field, this exposed deadlocks in the
    inline_data code similar to the ones fixed by 2e81a4eeedca.
    
    The deadlock can be reproduced via:
    
       dmesg -n 7
       mke2fs -t ext4 -O inline_data -Fq -I 256 /dev/vdc 32768
       mount -t ext4 -o debug_want_extra_isize=24 /dev/vdc /vdc
       mkdir /vdc/a
       umount /vdc
       mount -t ext4 /dev/vdc /vdc
       echo foo > /vdc/a/foo
    
    and looks like this:
    
    [   11.158815]
    [   11.160276] =============================================
    [   11.161960] [ INFO: possible recursive locking detected ]
    [   11.161960] 4.10.0-rc3-00015-g011b30a8a3cf #160 Tainted: G        W
    [   11.161960] ---------------------------------------------
    [   11.161960] bash/2519 is trying to acquire lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1225a4b>] ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]
    [   11.161960] but task is already holding lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] other info that might help us debug this:
    [   11.161960]  Possible unsafe locking scenario:
    [   11.161960]
    [   11.161960]        CPU0
    [   11.161960]        ----
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]
    [   11.161960]  *** DEADLOCK ***
    [   11.161960]
    [   11.161960]  May be due to missing lock nesting notation
    [   11.161960]
    [   11.161960] 4 locks held by bash/2519:
    [   11.161960]  #0:  (sb_writers#3){.+.+.+}, at: [<c11a2414>] mnt_want_write+0x1e/0x3e
    [   11.161960]  #1:  (&type->i_mutex_dir_key){++++++}, at: [<c119508b>] path_openat+0x338/0x67a
    [   11.161960]  #2:  (jbd2_handle){++++..}, at: [<c123314a>] start_this_handle+0x582/0x622
    [   11.161960]  #3:  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] stack backtrace:
    [   11.161960] CPU: 0 PID: 2519 Comm: bash Tainted: G        W       4.10.0-rc3-00015-g011b30a8a3cf #160
    [   11.161960] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1 04/01/2014
    [   11.161960] Call Trace:
    [   11.161960]  dump_stack+0x72/0xa3
    [   11.161960]  __lock_acquire+0xb7c/0xcb9
    [   11.161960]  ? kvm_clock_read+0x1f/0x29
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  lock_acquire+0x106/0x18a
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  down_write+0x39/0x72
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ? _raw_read_unlock+0x22/0x2c
    [   11.161960]  ? jbd2_journal_extend+0x1e2/0x262
    [   11.161960]  ? __ext4_journal_get_write_access+0x3d/0x60
    [   11.161960]  ext4_mark_inode_dirty+0x17d/0x26d
    [   11.161960]  ? ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_try_add_inline_entry+0x69/0x152
    [   11.161960]  ext4_add_entry+0xa3/0x848
    [   11.161960]  ? __brelse+0x14/0x2f
    [   11.161960]  ? _raw_spin_unlock_irqrestore+0x44/0x4f
    [   11.161960]  ext4_add_nondir+0x17/0x5b
    [   11.161960]  ext4_create+0xcf/0x133
    [   11.161960]  ? ext4_mknod+0x12f/0x12f
    [   11.161960]  lookup_open+0x39e/0x3fb
    [   11.161960]  ? __wake_up+0x1a/0x40
    [   11.161960]  ? lock_acquire+0x11e/0x18a
    [   11.161960]  path_openat+0x35c/0x67a
    [   11.161960]  ? sched_clock_cpu+0xd7/0xf2
    [   11.161960]  do_filp_open+0x36/0x7c
    [   11.161960]  ? _raw_spin_unlock+0x22/0x2c
    [   11.161960]  ? __alloc_fd+0x169/0x173
    [   11.161960]  do_sys_open+0x59/0xcc
    [   11.161960]  SyS_open+0x1d/0x1f
    [   11.161960]  do_int80_syscall_32+0x4f/0x61
    [   11.161960]  entry_INT80_32+0x2f/0x2f
    [   11.161960] EIP: 0xb76ad469
    [   11.161960] EFLAGS: 00000286 CPU: 0
    [   11.161960] EAX: ffffffda EBX: 08168ac8 ECX: 00008241 EDX: 000001b6
    [   11.161960] ESI: b75e46bc EDI: b7755000 EBP: bfbdb108 ESP: bfbdafc0
    [   11.161960]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Cc: stable@vger.kernel.org # 3.10 (requires 2e81a4eeedca as a prereq)
    Reported-by: George Spelvin <linux@sciencehorizons.net>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Nathan Chancellor <natechancellor@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fe342cf77bc3c3ba89e8bb1e4eddbe614df4efa4
Author: David Howells <dhowells@redhat.com>
Date:   Mon Apr 9 21:12:31 2018 +0100

    afs: Fix checker warnings
    
    Fix warnings raised by checker, including:
    
     (*) Warnings raised by unequal comparison for the purposes of sorting,
         where the endianness doesn't matter:
    
    fs/afs/addr_list.c:246:21: warning: restricted __be16 degrades to integer
    fs/afs/addr_list.c:246:30: warning: restricted __be16 degrades to integer
    fs/afs/addr_list.c:248:21: warning: restricted __be32 degrades to integer
    fs/afs/addr_list.c:248:49: warning: restricted __be32 degrades to integer
    fs/afs/addr_list.c:283:21: warning: restricted __be16 degrades to integer
    fs/afs/addr_list.c:283:30: warning: restricted __be16 degrades to integer
    
     (*) afs_set_cb_interest() is not actually used and can be removed.
    
     (*) afs_cell_gc_delay() should be provided with a sysctl.
    
     (*) afs_cell_destroy() needs to use rcu_access_pointer() to read
         cell->vl_addrs.
    
     (*) afs_init_fs_cursor() should be static.
    
     (*) struct afs_vnode::permit_cache needs to be marked __rcu.
    
     (*) afs_server_rcu() needs to use rcu_access_pointer().
    
     (*) afs_destroy_server() should use rcu_access_pointer() on
         server->addresses as the server object is no longer accessible.
    
     (*) afs_find_server() casts __be16/__be32 values to int in order to
         directly compare them for the purpose of finding a match in a list,
         but is should also annotate the cast with __force to avoid checker
         warnings.
    
     (*) afs_check_permit() accesses vnode->permit_cache outside of the RCU
         readlock, though it doesn't then access the value; the extraneous
         access is deleted.
    
    False positives:
    
     (*) Conditional locking around the code in xdr_decode_AFSFetchStatus.  This
         can be dealt with in a separate patch.
    
    fs/afs/fsclient.c:148:9: warning: context imbalance in 'xdr_decode_AFSFetchStatus' - different lock contexts for basic block
    
     (*) Incorrect handling of seq-retry lock context balance:
    
    fs/afs/inode.c:455:38: warning: context imbalance in 'afs_getattr' - different
    lock contexts for basic block
    fs/afs/server.c:52:17: warning: context imbalance in 'afs_find_server' - different lock contexts for basic block
    fs/afs/server.c:128:17: warning: context imbalance in 'afs_find_server_by_uuid' - different lock contexts for basic block
    
    Errors:
    
     (*) afs_lookup_cell_rcu() needs to break out of the seq-retry loop, not go
         round again if it successfully found the workstation cell.
    
     (*) Fix UUID decode in afs_deliver_cb_probe_uuid().
    
     (*) afs_cache_permit() has a missing rcu_read_unlock() before one of the
         jumps to the someone_else_changed_it label.  Move the unlock to after
         the label.
    
     (*) afs_vl_get_addrs_u() is using ntohl() rather than htonl() when
         encoding to XDR.
    
     (*) afs_deliver_yfsvl_get_endpoints() is using htonl() rather than ntohl()
         when decoding from XDR.
    
    Signed-off-by: David Howells <dhowells@redhat.com>

commit 020295d95e13478ecbbbe2f44398ed4b4edb28df
Merge: b9fc828debc8 9a3fb9fb84cc
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Mar 29 10:12:47 2018 -0400

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec
    
    Steffen Klassert says:
    
    ====================
    pull request (net): ipsec 2018-03-29
    
    1) Fix a rcu_read_lock/rcu_read_unlock imbalance
       in the error path of xfrm_local_error().
       From Taehee Yoo.
    
    2) Some VTI MTU fixes. From Stefano Brivio.
    
    3) Fix a too early overwritten skb control buffer
       on xfrm transport mode.
    
    Please note that this pull request has a merge conflict
    in net/ipv4/ip_tunnel.c.
    
    The conflict is between
    
    commit f6cc9c054e77 ("ip_tunnel: Emit events for post-register MTU changes")
    
    from the net tree and
    
    commit 24fc79798b8d ("ip_tunnel: Clamp MTU to bounds on new link")
    
    from the ipsec tree.
    
    It can be solved as it is currently done in linux-next.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit e4353660cf59d49f2c75789081e97c9da21631ec
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    commit 3b821409632ab778d46e807516b457dfa72736ed upstream.
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8dc6893e8fadbd63c1549f411c20c96c53e3381f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    commit 3b821409632ab778d46e807516b457dfa72736ed upstream.
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 05f16fe9ae8c18f461b25fd6f31c77333c739f58
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    commit 3b821409632ab778d46e807516b457dfa72736ed upstream.
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b071bce3ff7eda34c4e4aa9f5d39067b9db33dd8
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    commit 3b821409632ab778d46e807516b457dfa72736ed upstream.
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2fa76b885ece6d2b8aaaa3e28ff445d5527d4f27
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    commit 3b821409632ab778d46e807516b457dfa72736ed upstream.
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4c6994806f708559c2812b73501406e21ae5dcd0
Author: Joseph Qi <joseph.qi@linux.alibaba.com>
Date:   Fri Mar 16 14:51:27 2018 +0800

    blk-throttle: fix race between blkcg_bio_issue_check() and cgroup_rmdir()
    
    We've triggered a WARNING in blk_throtl_bio() when throttling writeback
    io, which complains blkg->refcnt is already 0 when calling blkg_get(),
    and then kernel crashes with invalid page request.
    After investigating this issue, we've found it is caused by a race
    between blkcg_bio_issue_check() and cgroup_rmdir(), which is described
    below:
    
    writeback kworker               cgroup_rmdir
                                      cgroup_destroy_locked
                                        kill_css
                                          css_killed_ref_fn
                                            css_killed_work_fn
                                              offline_css
                                                blkcg_css_offline
      blkcg_bio_issue_check
        rcu_read_lock
        blkg_lookup
                                                  spin_trylock(q->queue_lock)
                                                  blkg_destroy
                                                  spin_unlock(q->queue_lock)
        blk_throtl_bio
        spin_lock_irq(q->queue_lock)
        ...
        spin_unlock_irq(q->queue_lock)
      rcu_read_unlock
    
    Since rcu can only prevent blkg from releasing when it is being used,
    the blkg->refcnt can be decreased to 0 during blkg_destroy() and schedule
    blkg release.
    Then trying to blkg_get() in blk_throtl_bio() will complains the WARNING.
    And then the corresponding blkg_put() will schedule blkg release again,
    which result in double free.
    This race is introduced by commit ae1188963611 ("blkcg: consolidate blkg
    creation in blkcg_bio_issue_check()"). Before this commit, it will
    lookup first and then try to lookup/create again with queue_lock. Since
    revive this logic is a bit drastic, so fix it by only offlining pd during
    blkcg_css_offline(), and move the rest destruction (especially
    blkg_put()) into blkcg_css_free(), which should be the right way as
    discussed.
    
    Fixes: ae1188963611 ("blkcg: consolidate blkg creation in blkcg_bio_issue_check()")
    Reported-by: Jiufei Xue <jiufei.xue@linux.alibaba.com>
    Signed-off-by: Joseph Qi <joseph.qi@linux.alibaba.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 46c0ef6e1eb95f619d9f62da4332749153db92f7
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Fri Mar 16 11:35:51 2018 +0900

    xfrm: fix rcu_read_unlock usage in xfrm_local_error
    
    In the xfrm_local_error, rcu_read_unlock should be called when afinfo
    is not NULL. because xfrm_state_get_afinfo calls rcu_read_unlock
    if afinfo is NULL.
    
    Fixes: af5d27c4e12b ("xfrm: remove xfrm_state_put_afinfo")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

commit d2ddf628e90ffb92b411757eeb8655314371b879
Merge: 5a9f8df68ee6 0dcd7876029b
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Mar 13 10:38:07 2018 -0400

    Merge branch 'master' of git://git.kernel.org/pub/scm/linux/kernel/git/klassert/ipsec
    
    Steffen Klassert says:
    
    ====================
    pull request (net): ipsec 2018-03-13
    
    1) Refuse to insert 32 bit userspace socket policies on 64
       bit systems like we do it for standard policies. We don't
       have a compat layer, so inserting socket policies from
       32 bit userspace will lead to a broken configuration.
    
    2) Make the policy hold queue work without the flowcache.
       Dummy bundles are not chached anymore, so we need to
       generate a new one on each lookup as long as the SAs
       are not yet in place.
    
    3) Fix the validation of the esn replay attribute. The
       The sanity check in verify_replay() is bypassed if
       the XFRM_STATE_ESN flag is not set. Fix this by doing
       the sanity check uncoditionally.
       From Florian Westphal.
    
    4) After most of the dst_entry garbage collection code
       is removed, we may leak xfrm_dst entries as they are
       neither cached nor tracked somewhere. Fix this by
       reusing the 'uncached_list' to track xfrm_dst entries
       too. From Xin Long.
    
    5) Fix a rcu_read_lock/rcu_read_unlock imbalance in
       xfrm_get_tos() From Xin Long.
    
    6) Fix an infinite loop in xfrm_get_dst_nexthop. On
       transport mode we fetch the child dst_entry after
       we continue, so this pointer is never updated.
       Fix this by fetching it before we continue.
    
    7) Fix ESN sequence number gap after IPsec GSO packets.
        We accidentally increment the sequence number counter
        on the xfrm_state by one packet too much in the ESN
        case. Fix this by setting the sequence number to the
        correct value.
    
    8) Reset the ethernet protocol after decapsulation only if a
       mac header was set. Otherwise it breaks configurations
       with TUN devices. From Yossi Kuperman.
    
    9) Fix __this_cpu_read() usage in preemptible code. Use
       this_cpu_read() instead in ipcomp_alloc_tfms().
       From Greg Hackmann.
    
    Please pull or let me know if there are problems.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6b0ef92fee2a3189eba6d6b827b247cb4f6da7e9
Author: Boqun Feng <boqun.feng@gmail.com>
Date:   Fri Mar 9 14:56:28 2018 +0800

    rtmutex: Make rt_mutex_futex_unlock() safe for irq-off callsites
    
    When running rcutorture with TREE03 config, CONFIG_PROVE_LOCKING=y, and
    kernel cmdline argument "rcutorture.gp_exp=1", lockdep reports a
    HARDIRQ-safe->HARDIRQ-unsafe deadlock:
    
     ================================
     WARNING: inconsistent lock state
     4.16.0-rc4+ #1 Not tainted
     --------------------------------
     inconsistent {IN-HARDIRQ-W} -> {HARDIRQ-ON-W} usage.
     takes:
     __schedule+0xbe/0xaf0
     {IN-HARDIRQ-W} state was registered at:
       _raw_spin_lock+0x2a/0x40
       scheduler_tick+0x47/0xf0
    ...
     other info that might help us debug this:
      Possible unsafe locking scenario:
            CPU0
            ----
       lock(&rq->lock);
       <Interrupt>
         lock(&rq->lock);
      *** DEADLOCK ***
     1 lock held by rcu_torture_rea/724:
     rcu_torture_read_lock+0x0/0x70
     stack backtrace:
     CPU: 2 PID: 724 Comm: rcu_torture_rea Not tainted 4.16.0-rc4+ #1
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.11.0-20171110_100015-anatol 04/01/2014
     Call Trace:
      lock_acquire+0x90/0x200
      ? __schedule+0xbe/0xaf0
      _raw_spin_lock+0x2a/0x40
      ? __schedule+0xbe/0xaf0
      __schedule+0xbe/0xaf0
      preempt_schedule_irq+0x2f/0x60
      retint_kernel+0x1b/0x2d
     RIP: 0010:rcu_read_unlock_special+0x0/0x680
      ? rcu_torture_read_unlock+0x60/0x60
      __rcu_read_unlock+0x64/0x70
      rcu_torture_read_unlock+0x17/0x60
      rcu_torture_reader+0x275/0x450
      ? rcutorture_booster_init+0x110/0x110
      ? rcu_torture_stall+0x230/0x230
      ? kthread+0x10e/0x130
      kthread+0x10e/0x130
      ? kthread_create_worker_on_cpu+0x70/0x70
      ? call_usermodehelper_exec_async+0x11a/0x150
      ret_from_fork+0x3a/0x50
    
    This happens with the following even sequence:
    
            preempt_schedule_irq();
              local_irq_enable();
              __schedule():
                local_irq_disable(); // irq off
                ...
                rcu_note_context_switch():
                  rcu_note_preempt_context_switch():
                    rcu_read_unlock_special():
                      local_irq_save(flags);
                      ...
                      raw_spin_unlock_irqrestore(...,flags); // irq remains off
                      rt_mutex_futex_unlock():
                        raw_spin_lock_irq();
                        ...
                        raw_spin_unlock_irq(); // accidentally set irq on
    
                <return to __schedule()>
                rq_lock():
                  raw_spin_lock(); // acquiring rq->lock with irq on
    
    which means rq->lock becomes a HARDIRQ-unsafe lock, which can cause
    deadlocks in scheduler code.
    
    This problem was introduced by commit 02a7c234e540 ("rcu: Suppress
    lockdep false-positive ->boost_mtx complaints"). That brought the user
    of rt_mutex_futex_unlock() with irq off.
    
    To fix this, replace the *lock_irq() in rt_mutex_futex_unlock() with
    *lock_irq{save,restore}() to make it safe to call rt_mutex_futex_unlock()
    with irq off.
    
    Fixes: 02a7c234e540 ("rcu: Suppress lockdep false-positive ->boost_mtx complaints")
    Signed-off-by: Boqun Feng <boqun.feng@gmail.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Lai Jiangshan <jiangshanlai@gmail.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Josh Triplett <josh@joshtriplett.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: "Paul E . McKenney" <paulmck@linux.vnet.ibm.com>
    Link: https://lkml.kernel.org/r/20180309065630.8283-1-boqun.feng@gmail.com

commit 41904439479e94dd61ac499312e8d8266b13f81d
Author: Bart Van Assche <bart.vanassche@wdc.com>
Date:   Mon Mar 5 09:58:33 2018 -0800

    IB/hfi1: Add a missing rcu_read_unlock()
    
    This patch avoids that sparse reports the following:
    
    drivers/infiniband/hw/hfi1/driver.c:251:13: warning: context imbalance in 'rcv_hdrerr' - different lock contexts for basic block
    
    Signed-off-by: Bart Van Assche <bart.vanassche@wdc.com>
    Cc: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Cc: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 1f250e929a9c9332fd6ea34da684afee73837cfe
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 28 15:56:10 2018 +0000

    Btrfs: fix log replay failure after unlink and link combination
    
    If we have a file with 2 (or more) hard links in the same directory,
    remove one of the hard links, create a new file (or link an existing file)
    in the same directory with the name of the removed hard link, and then
    finally fsync the new file, we end up with a log that fails to replay,
    causing a mount failure.
    
    Example:
    
      $ mkfs.btrfs -f /dev/sdb
      $ mount /dev/sdb /mnt
    
      $ mkdir /mnt/testdir
      $ touch /mnt/testdir/foo
      $ ln /mnt/testdir/foo /mnt/testdir/bar
    
      $ sync
    
      $ unlink /mnt/testdir/bar
      $ touch /mnt/testdir/bar
      $ xfs_io -c "fsync" /mnt/testdir/bar
    
      <power failure>
    
      $ mount /dev/sdb /mnt
      mount: mount(2) failed: /mnt: No such file or directory
    
    When replaying the log, for that example, we also see the following in
    dmesg/syslog:
    
      [71813.671307] BTRFS info (device dm-0): failed to delete reference to bar, inode 258 parent 257
      [71813.674204] ------------[ cut here ]------------
      [71813.675694] BTRFS: Transaction aborted (error -2)
      [71813.677236] WARNING: CPU: 1 PID: 13231 at fs/btrfs/inode.c:4128 __btrfs_unlink_inode+0x17b/0x355 [btrfs]
      [71813.679669] Modules linked in: btrfs xfs f2fs dm_flakey dm_mod dax ghash_clmulni_intel ppdev pcbc aesni_intel aes_x86_64 crypto_simd cryptd glue_helper evdev psmouse i2c_piix4 parport_pc i2c_core pcspkr sg serio_raw parport button sunrpc loop autofs4 ext4 crc16 mbcache jbd2 zstd_decompress zstd_compress xxhash raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c crc32c_generic raid1 raid0 multipath linear md_mod ata_generic sd_mod virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel floppy virtio e1000 scsi_mod [last unloaded: btrfs]
      [71813.679669] CPU: 1 PID: 13231 Comm: mount Tainted: G        W        4.15.0-rc9-btrfs-next-56+ #1
      [71813.679669] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
      [71813.679669] RIP: 0010:__btrfs_unlink_inode+0x17b/0x355 [btrfs]
      [71813.679669] RSP: 0018:ffffc90001cef738 EFLAGS: 00010286
      [71813.679669] RAX: 0000000000000025 RBX: ffff880217ce4708 RCX: 0000000000000001
      [71813.679669] RDX: 0000000000000000 RSI: ffffffff81c14bae RDI: 00000000ffffffff
      [71813.679669] RBP: ffffc90001cef7c0 R08: 0000000000000001 R09: 0000000000000001
      [71813.679669] R10: ffffc90001cef5e0 R11: ffffffff8343f007 R12: ffff880217d474c8
      [71813.679669] R13: 00000000fffffffe R14: ffff88021ccf1548 R15: 0000000000000101
      [71813.679669] FS:  00007f7cee84c480(0000) GS:ffff88023fc80000(0000) knlGS:0000000000000000
      [71813.679669] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
      [71813.679669] CR2: 00007f7cedc1abf9 CR3: 00000002354b4003 CR4: 00000000001606e0
      [71813.679669] Call Trace:
      [71813.679669]  btrfs_unlink_inode+0x17/0x41 [btrfs]
      [71813.679669]  drop_one_dir_item+0xfa/0x131 [btrfs]
      [71813.679669]  add_inode_ref+0x71e/0x851 [btrfs]
      [71813.679669]  ? __lock_is_held+0x39/0x71
      [71813.679669]  ? replay_one_buffer+0x53/0x53a [btrfs]
      [71813.679669]  replay_one_buffer+0x4a4/0x53a [btrfs]
      [71813.679669]  ? rcu_read_unlock+0x3a/0x57
      [71813.679669]  ? __lock_is_held+0x39/0x71
      [71813.679669]  walk_up_log_tree+0x101/0x1d2 [btrfs]
      [71813.679669]  walk_log_tree+0xad/0x188 [btrfs]
      [71813.679669]  btrfs_recover_log_trees+0x1fa/0x31e [btrfs]
      [71813.679669]  ? replay_one_extent+0x544/0x544 [btrfs]
      [71813.679669]  open_ctree+0x1cf6/0x2209 [btrfs]
      [71813.679669]  btrfs_mount_root+0x368/0x482 [btrfs]
      [71813.679669]  ? trace_hardirqs_on_caller+0x14c/0x1a6
      [71813.679669]  ? __lockdep_init_map+0x176/0x1c2
      [71813.679669]  ? mount_fs+0x64/0x10b
      [71813.679669]  mount_fs+0x64/0x10b
      [71813.679669]  vfs_kern_mount+0x68/0xce
      [71813.679669]  btrfs_mount+0x13e/0x772 [btrfs]
      [71813.679669]  ? trace_hardirqs_on_caller+0x14c/0x1a6
      [71813.679669]  ? __lockdep_init_map+0x176/0x1c2
      [71813.679669]  ? mount_fs+0x64/0x10b
      [71813.679669]  mount_fs+0x64/0x10b
      [71813.679669]  vfs_kern_mount+0x68/0xce
      [71813.679669]  do_mount+0x6e5/0x973
      [71813.679669]  ? memdup_user+0x3e/0x5c
      [71813.679669]  SyS_mount+0x72/0x98
      [71813.679669]  entry_SYSCALL_64_fastpath+0x1e/0x8b
      [71813.679669] RIP: 0033:0x7f7cedf150ba
      [71813.679669] RSP: 002b:00007ffca71da688 EFLAGS: 00000206
      [71813.679669] Code: 7f a0 e8 51 0c fd ff 48 8b 43 50 f0 0f ba a8 30 2c 00 00 02 72 17 41 83 fd fb 74 11 44 89 ee 48 c7 c7 7d 11 7f a0 e8 38 f5 8d e0 <0f> ff 44 89 e9 ba 20 10 00 00 eb 4d 48 8b 4d b0 48 8b 75 88 4c
      [71813.679669] ---[ end trace 83bd473fc5b4663b ]---
      [71813.854764] BTRFS: error (device dm-0) in __btrfs_unlink_inode:4128: errno=-2 No such entry
      [71813.886994] BTRFS: error (device dm-0) in btrfs_replay_log:2307: errno=-2 No such entry (Failed to recover log tree)
      [71813.903357] BTRFS error (device dm-0): cleaner transaction attach returned -30
      [71814.128078] BTRFS error (device dm-0): open_ctree failed
    
    This happens because the log has inode reference items for both inode 258
    (the first file we created) and inode 259 (the second file created), and
    when processing the reference item for inode 258, we replace the
    corresponding item in the subvolume tree (which has two names, "foo" and
    "bar") witht he one in the log (which only has one name, "foo") without
    removing the corresponding dir index keys from the parent directory.
    Later, when processing the inode reference item for inode 259, which has
    a name of "bar" associated to it, we notice that dir index entries exist
    for that name and for a different inode, so we attempt to unlink that
    name, which fails because the inode reference item for inode 258 no longer
    has the name "bar" associated to it, making a call to btrfs_unlink_inode()
    fail with a -ENOENT error.
    
    Fix this by unlinking all the names in an inode reference item from a
    subvolume tree that are not present in the inode reference item found in
    the log tree, before overwriting it with the item from the log tree.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit 2ce8a62d862e3bcd16d12d6d7d71c0a343f4f99a
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Wed Apr 19 15:11:00 2017 -0700

    nsfs: mark dentry with DCACHE_RCUACCESS
    
    [ Upstream commit 073c516ff73557a8f7315066856c04b50383ac34 ]
    
    Andrey reported a use-after-free in __ns_get_path():
    
      spin_lock include/linux/spinlock.h:299 [inline]
      lockref_get_not_dead+0x19/0x80 lib/lockref.c:179
      __ns_get_path+0x197/0x860 fs/nsfs.c:66
      open_related_ns+0xda/0x200 fs/nsfs.c:143
      sock_ioctl+0x39d/0x440 net/socket.c:1001
      vfs_ioctl fs/ioctl.c:45 [inline]
      do_vfs_ioctl+0x1bf/0x1780 fs/ioctl.c:685
      SYSC_ioctl fs/ioctl.c:700 [inline]
      SyS_ioctl+0x8f/0xc0 fs/ioctl.c:691
    
    We are under rcu read lock protection at that point:
    
            rcu_read_lock();
            d = atomic_long_read(&ns->stashed);
            if (!d)
                    goto slow;
            dentry = (struct dentry *)d;
            if (!lockref_get_not_dead(&dentry->d_lockref))
                    goto slow;
            rcu_read_unlock();
    
    but don't use a proper RCU API on the free path, therefore a parallel
    __d_free() could free it at the same time.  We need to mark the stashed
    dentry with DCACHE_RCUACCESS so that __d_free() will be called after all
    readers leave RCU.
    
    Fixes: e149ed2b805f ("take the targets of /proc/*/ns/* symlinks to separate fs")
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>

commit 26f288c21b60120f76882e1106ab80053a2516cc
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    [ Upstream commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba ]
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>

commit 1df9e416e647a427b8bea8a383625cc4d8c890cf
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Feb 21 14:45:20 2018 -0800

    Kbuild: always define endianess in kconfig.h
    
    commit 101110f6271ce956a049250c907bc960030577f8 upstream.
    
    Build testing with LTO found a couple of files that get compiled
    differently depending on whether asm/byteorder.h gets included early
    enough or not.  In particular, include/asm-generic/qrwlock_types.h is
    affected by this, but there are probably others as well.
    
    The symptom is a series of LTO link time warnings, including these:
    
        net/netlabel/netlabel_unlabeled.h:223: error: type of 'netlbl_unlhsh_add' does not match original declaration [-Werror=lto-type-mismatch]
         int netlbl_unlhsh_add(struct net *net,
        net/netlabel/netlabel_unlabeled.c:377: note: 'netlbl_unlhsh_add' was previously declared here
    
        include/net/ipv6.h:360: error: type of 'ipv6_renew_options_kern' does not match original declaration [-Werror=lto-type-mismatch]
         ipv6_renew_options_kern(struct sock *sk,
        net/ipv6/exthdrs.c:1162: note: 'ipv6_renew_options_kern' was previously declared here
    
        net/core/dev.c:761: note: 'dev_get_by_name_rcu' was previously declared here
         struct net_device *dev_get_by_name_rcu(struct net *net, const char *name)
        net/core/dev.c:761: note: code may be misoptimized unless -fno-strict-aliasing is used
    
        drivers/gpu/drm/i915/i915_drv.h:3377: error: type of 'i915_gem_object_set_to_wc_domain' does not match original declaration [-Werror=lto-type-mismatch]
         i915_gem_object_set_to_wc_domain(struct drm_i915_gem_object *obj, bool write);
        drivers/gpu/drm/i915/i915_gem.c:3639: note: 'i915_gem_object_set_to_wc_domain' was previously declared here
    
        include/linux/debugfs.h:92:9: error: type of 'debugfs_attr_read' does not match original declaration [-Werror=lto-type-mismatch]
         ssize_t debugfs_attr_read(struct file *file, char __user *buf,
        fs/debugfs/file.c:318: note: 'debugfs_attr_read' was previously declared here
    
        include/linux/rwlock_api_smp.h:30: error: type of '_raw_read_unlock' does not match original declaration [-Werror=lto-type-mismatch]
         void __lockfunc _raw_read_unlock(rwlock_t *lock) __releases(lock);
        kernel/locking/spinlock.c:246:26: note: '_raw_read_unlock' was previously declared here
    
        include/linux/fs.h:3308:5: error: type of 'simple_attr_open' does not match original declaration [-Werror=lto-type-mismatch]
         int simple_attr_open(struct inode *inode, struct file *file,
        fs/libfs.c:795: note: 'simple_attr_open' was previously declared here
    
    All of the above are caused by include/asm-generic/qrwlock_types.h
    failing to include asm/byteorder.h after commit e0d02285f16e
    ("locking/qrwlock: Use 'struct qrwlock' instead of 'struct __qrwlock'")
    in linux-4.15.
    
    Similar bugs may or may not exist in older kernels as well, but there is
    no easy way to test those with link-time optimizations, and kernels
    before 4.14 are harder to fix because they don't have Babu's patch
    series
    
    We had similar issues with CONFIG_ symbols in the past and ended up
    always including the configuration headers though linux/kconfig.h.  This
    works around the issue through that same file, defining either
    __BIG_ENDIAN or __LITTLE_ENDIAN depending on CONFIG_CPU_BIG_ENDIAN,
    which is now always set on all architectures since commit 4c97a0c8fee3
    ("arch: define CPU_BIG_ENDIAN for all fixed big endian archs").
    
    Link: http://lkml.kernel.org/r/20180202154104.1522809-2-arnd@arndb.de
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Babu Moger <babu.moger@amd.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2220b31092c0a55b17d023a2d65f67393194e4fb
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Wed Feb 14 12:35:40 2018 +0200

    RDMA/uverbs: Sanitize user entered port numbers prior to access it
    
    commit 5d4c05c3ee36f67ddc107ab5ea0898af01a62cc1 upstream.
    
    ==================================================================
    BUG: KASAN: use-after-free in copy_ah_attr_from_uverbs+0x6f2/0x8c0
    Read of size 4 at addr ffff88006476a198 by task syzkaller697701/265
    
    CPU: 0 PID: 265 Comm: syzkaller697701 Not tainted 4.15.0+ #90
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ? show_regs_print_info+0x17/0x17
     ? lock_contended+0x11a0/0x11a0
     print_address_description+0x83/0x3e0
     kasan_report+0x18c/0x4b0
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? lookup_get_idr_uobject+0x120/0x200
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? modify_qp+0xd0e/0x1350
     modify_qp+0xd0e/0x1350
     ib_uverbs_modify_qp+0xf9/0x170
     ? ib_uverbs_query_qp+0xa70/0xa70
     ib_uverbs_write+0x7f9/0xef0
     ? attach_entity_load_avg+0x8b0/0x8b0
     ? ib_uverbs_query_qp+0xa70/0xa70
     ? uverbs_devnode+0x110/0x110
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? sched_clock_cpu+0x18/0x200
     ? _raw_spin_unlock_irq+0x29/0x40
     ? _raw_spin_unlock_irq+0x29/0x40
     ? _raw_spin_unlock_irq+0x29/0x40
     ? time_hardirqs_on+0x27/0x670
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? _raw_spin_unlock_irq+0x29/0x40
     ? finish_task_switch+0x1bd/0x7a0
     ? finish_task_switch+0x194/0x7a0
     ? prandom_u32_state+0xe/0x180
     ? rcu_read_unlock+0x80/0x80
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433c29
    RSP: 002b:00007ffcf2be82a8 EFLAGS: 00000217
    
    Allocated by task 62:
     kasan_kmalloc+0xa0/0xd0
     kmem_cache_alloc+0x141/0x480
     dup_fd+0x101/0xcc0
     copy_process.part.62+0x166f/0x4390
     _do_fork+0x1cb/0xe90
     kernel_thread+0x34/0x40
     call_usermodehelper_exec_work+0x112/0x260
     process_one_work+0x929/0x1aa0
     worker_thread+0x5c6/0x12a0
     kthread+0x346/0x510
     ret_from_fork+0x3a/0x50
    
    Freed by task 259:
     kasan_slab_free+0x71/0xc0
     kmem_cache_free+0xf3/0x4c0
     put_files_struct+0x225/0x2c0
     exit_files+0x88/0xc0
     do_exit+0x67c/0x1520
     do_group_exit+0xe8/0x380
     SyS_exit_group+0x1e/0x20
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    
    The buggy address belongs to the object at ffff88006476a000
     which belongs to the cache files_cache of size 832
    The buggy address is located 408 bytes inside of
     832-byte region [ffff88006476a000, ffff88006476a340)
    The buggy address belongs to the page:
    page:ffffea000191da80 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
    flags: 0x4000000000008100(slab|head)
    raw: 4000000000008100 0000000000000000 0000000000000000 0000000100080008
    raw: 0000000000000000 0000000100000001 ffff88006bcf7a80 0000000000000000
    page dumped because: kasan: bad access detected
    
    Memory state around the buggy address:
     ffff88006476a080: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88006476a100: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    >ffff88006476a180: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                ^
     ffff88006476a200: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88006476a280: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    ==================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 4.11
    Fixes: 44c58487d51a ("IB/core: Define 'ib' and 'roce' rdma_ah_attr types")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0b82d316fa5b199125a22559fd457cf3100c34fc
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Feb 21 14:45:20 2018 -0800

    Kbuild: always define endianess in kconfig.h
    
    commit 101110f6271ce956a049250c907bc960030577f8 upstream.
    
    Build testing with LTO found a couple of files that get compiled
    differently depending on whether asm/byteorder.h gets included early
    enough or not.  In particular, include/asm-generic/qrwlock_types.h is
    affected by this, but there are probably others as well.
    
    The symptom is a series of LTO link time warnings, including these:
    
        net/netlabel/netlabel_unlabeled.h:223: error: type of 'netlbl_unlhsh_add' does not match original declaration [-Werror=lto-type-mismatch]
         int netlbl_unlhsh_add(struct net *net,
        net/netlabel/netlabel_unlabeled.c:377: note: 'netlbl_unlhsh_add' was previously declared here
    
        include/net/ipv6.h:360: error: type of 'ipv6_renew_options_kern' does not match original declaration [-Werror=lto-type-mismatch]
         ipv6_renew_options_kern(struct sock *sk,
        net/ipv6/exthdrs.c:1162: note: 'ipv6_renew_options_kern' was previously declared here
    
        net/core/dev.c:761: note: 'dev_get_by_name_rcu' was previously declared here
         struct net_device *dev_get_by_name_rcu(struct net *net, const char *name)
        net/core/dev.c:761: note: code may be misoptimized unless -fno-strict-aliasing is used
    
        drivers/gpu/drm/i915/i915_drv.h:3377: error: type of 'i915_gem_object_set_to_wc_domain' does not match original declaration [-Werror=lto-type-mismatch]
         i915_gem_object_set_to_wc_domain(struct drm_i915_gem_object *obj, bool write);
        drivers/gpu/drm/i915/i915_gem.c:3639: note: 'i915_gem_object_set_to_wc_domain' was previously declared here
    
        include/linux/debugfs.h:92:9: error: type of 'debugfs_attr_read' does not match original declaration [-Werror=lto-type-mismatch]
         ssize_t debugfs_attr_read(struct file *file, char __user *buf,
        fs/debugfs/file.c:318: note: 'debugfs_attr_read' was previously declared here
    
        include/linux/rwlock_api_smp.h:30: error: type of '_raw_read_unlock' does not match original declaration [-Werror=lto-type-mismatch]
         void __lockfunc _raw_read_unlock(rwlock_t *lock) __releases(lock);
        kernel/locking/spinlock.c:246:26: note: '_raw_read_unlock' was previously declared here
    
        include/linux/fs.h:3308:5: error: type of 'simple_attr_open' does not match original declaration [-Werror=lto-type-mismatch]
         int simple_attr_open(struct inode *inode, struct file *file,
        fs/libfs.c:795: note: 'simple_attr_open' was previously declared here
    
    All of the above are caused by include/asm-generic/qrwlock_types.h
    failing to include asm/byteorder.h after commit e0d02285f16e
    ("locking/qrwlock: Use 'struct qrwlock' instead of 'struct __qrwlock'")
    in linux-4.15.
    
    Similar bugs may or may not exist in older kernels as well, but there is
    no easy way to test those with link-time optimizations, and kernels
    before 4.14 are harder to fix because they don't have Babu's patch
    series
    
    We had similar issues with CONFIG_ symbols in the past and ended up
    always including the configuration headers though linux/kconfig.h.  This
    works around the issue through that same file, defining either
    __BIG_ENDIAN or __LITTLE_ENDIAN depending on CONFIG_CPU_BIG_ENDIAN,
    which is now always set on all architectures since commit 4c97a0c8fee3
    ("arch: define CPU_BIG_ENDIAN for all fixed big endian archs").
    
    Link: http://lkml.kernel.org/r/20180202154104.1522809-2-arnd@arndb.de
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Babu Moger <babu.moger@amd.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2492eca0a05b05736cbcf7fc1f234a666c4fcc52
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Wed Feb 14 12:35:40 2018 +0200

    RDMA/uverbs: Sanitize user entered port numbers prior to access it
    
    commit 5d4c05c3ee36f67ddc107ab5ea0898af01a62cc1 upstream.
    
    ==================================================================
    BUG: KASAN: use-after-free in copy_ah_attr_from_uverbs+0x6f2/0x8c0
    Read of size 4 at addr ffff88006476a198 by task syzkaller697701/265
    
    CPU: 0 PID: 265 Comm: syzkaller697701 Not tainted 4.15.0+ #90
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ? show_regs_print_info+0x17/0x17
     ? lock_contended+0x11a0/0x11a0
     print_address_description+0x83/0x3e0
     kasan_report+0x18c/0x4b0
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? lookup_get_idr_uobject+0x120/0x200
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? modify_qp+0xd0e/0x1350
     modify_qp+0xd0e/0x1350
     ib_uverbs_modify_qp+0xf9/0x170
     ? ib_uverbs_query_qp+0xa70/0xa70
     ib_uverbs_write+0x7f9/0xef0
     ? attach_entity_load_avg+0x8b0/0x8b0
     ? ib_uverbs_query_qp+0xa70/0xa70
     ? uverbs_devnode+0x110/0x110
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? sched_clock_cpu+0x18/0x200
     ? _raw_spin_unlock_irq+0x29/0x40
     ? _raw_spin_unlock_irq+0x29/0x40
     ? _raw_spin_unlock_irq+0x29/0x40
     ? time_hardirqs_on+0x27/0x670
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? _raw_spin_unlock_irq+0x29/0x40
     ? finish_task_switch+0x1bd/0x7a0
     ? finish_task_switch+0x194/0x7a0
     ? prandom_u32_state+0xe/0x180
     ? rcu_read_unlock+0x80/0x80
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433c29
    RSP: 002b:00007ffcf2be82a8 EFLAGS: 00000217
    
    Allocated by task 62:
     kasan_kmalloc+0xa0/0xd0
     kmem_cache_alloc+0x141/0x480
     dup_fd+0x101/0xcc0
     copy_process.part.62+0x166f/0x4390
     _do_fork+0x1cb/0xe90
     kernel_thread+0x34/0x40
     call_usermodehelper_exec_work+0x112/0x260
     process_one_work+0x929/0x1aa0
     worker_thread+0x5c6/0x12a0
     kthread+0x346/0x510
     ret_from_fork+0x3a/0x50
    
    Freed by task 259:
     kasan_slab_free+0x71/0xc0
     kmem_cache_free+0xf3/0x4c0
     put_files_struct+0x225/0x2c0
     exit_files+0x88/0xc0
     do_exit+0x67c/0x1520
     do_group_exit+0xe8/0x380
     SyS_exit_group+0x1e/0x20
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    
    The buggy address belongs to the object at ffff88006476a000
     which belongs to the cache files_cache of size 832
    The buggy address is located 408 bytes inside of
     832-byte region [ffff88006476a000, ffff88006476a340)
    The buggy address belongs to the page:
    page:ffffea000191da80 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
    flags: 0x4000000000008100(slab|head)
    raw: 4000000000008100 0000000000000000 0000000000000000 0000000100080008
    raw: 0000000000000000 0000000100000001 ffff88006bcf7a80 0000000000000000
    page dumped because: kasan: bad access detected
    
    Memory state around the buggy address:
     ffff88006476a080: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88006476a100: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    >ffff88006476a180: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                ^
     ffff88006476a200: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88006476a280: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    ==================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 4.11
    Fixes: 44c58487d51a ("IB/core: Define 'ib' and 'roce' rdma_ah_attr types")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3b821409632ab778d46e807516b457dfa72736ed
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Fri Feb 23 20:47:17 2018 -0500

    lock_parent() needs to recheck if dentry got __dentry_kill'ed under it
    
    In case when dentry passed to lock_parent() is protected from freeing only
    by the fact that it's on a shrink list and trylock of parent fails, we
    could get hit by __dentry_kill() (and subsequent dentry_kill(parent))
    between unlocking dentry and locking presumed parent.  We need to recheck
    that dentry is alive once we lock both it and parent *and* postpone
    rcu_read_unlock() until after that point.  Otherwise we could return
    a pointer to struct dentry that already is rcu-scheduled for freeing, with
    ->d_lock held on it; caller's subsequent attempt to unlock it can end
    up with memory corruption.
    
    Cc: stable@vger.kernel.org # 3.12+, counting backports
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 294975841483c08e84572713f348cd51b8408021
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon Feb 5 22:18:11 2018 -0500

    tracing: Fix parsing of globs with a wildcard at the beginning
    
    commit 07234021410bbc27b7c86c18de98616c29fbe667 upstream.
    
    Al Viro reported:
    
        For substring - sure, but what about something like "*a*b" and "a*b"?
        AFAICS, filter_parse_regex() ends up with identical results in both
        cases - MATCH_GLOB and *search = "a*b".  And no way for the caller
        to tell one from another.
    
    Testing this with the following:
    
     # cd /sys/kernel/tracing
     # echo '*raw*lock' > set_ftrace_filter
     bash: echo: write error: Invalid argument
    
    With this patch:
    
     # echo '*raw*lock' > set_ftrace_filter
     # cat set_ftrace_filter
    _raw_read_trylock
    _raw_write_trylock
    _raw_read_unlock
    _raw_spin_unlock
    _raw_write_unlock
    _raw_spin_trylock
    _raw_spin_lock
    _raw_write_lock
    _raw_read_lock
    
    Al recommended not setting the search buffer to skip the first '*' unless we
    know we are not using MATCH_GLOB. This implements his suggested logic.
    
    Link: http://lkml.kernel.org/r/20180127170748.GF13338@ZenIV.linux.org.uk
    
    Cc: stable@vger.kernel.org
    Fixes: 60f1d5e3bac44 ("ftrace: Support full glob matching")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Suggsted-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 95f92d0a0ca9dd0f4a92e9eb02b2b7b3d257d46f
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon Feb 5 22:18:11 2018 -0500

    tracing: Fix parsing of globs with a wildcard at the beginning
    
    commit 07234021410bbc27b7c86c18de98616c29fbe667 upstream.
    
    Al Viro reported:
    
        For substring - sure, but what about something like "*a*b" and "a*b"?
        AFAICS, filter_parse_regex() ends up with identical results in both
        cases - MATCH_GLOB and *search = "a*b".  And no way for the caller
        to tell one from another.
    
    Testing this with the following:
    
     # cd /sys/kernel/tracing
     # echo '*raw*lock' > set_ftrace_filter
     bash: echo: write error: Invalid argument
    
    With this patch:
    
     # echo '*raw*lock' > set_ftrace_filter
     # cat set_ftrace_filter
    _raw_read_trylock
    _raw_write_trylock
    _raw_read_unlock
    _raw_spin_unlock
    _raw_write_unlock
    _raw_spin_trylock
    _raw_spin_lock
    _raw_write_lock
    _raw_read_lock
    
    Al recommended not setting the search buffer to skip the first '*' unless we
    know we are not using MATCH_GLOB. This implements his suggested logic.
    
    Link: http://lkml.kernel.org/r/20180127170748.GF13338@ZenIV.linux.org.uk
    
    Cc: stable@vger.kernel.org
    Fixes: 60f1d5e3bac44 ("ftrace: Support full glob matching")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Suggsted-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 101110f6271ce956a049250c907bc960030577f8
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Wed Feb 21 14:45:20 2018 -0800

    Kbuild: always define endianess in kconfig.h
    
    Build testing with LTO found a couple of files that get compiled
    differently depending on whether asm/byteorder.h gets included early
    enough or not.  In particular, include/asm-generic/qrwlock_types.h is
    affected by this, but there are probably others as well.
    
    The symptom is a series of LTO link time warnings, including these:
    
        net/netlabel/netlabel_unlabeled.h:223: error: type of 'netlbl_unlhsh_add' does not match original declaration [-Werror=lto-type-mismatch]
         int netlbl_unlhsh_add(struct net *net,
        net/netlabel/netlabel_unlabeled.c:377: note: 'netlbl_unlhsh_add' was previously declared here
    
        include/net/ipv6.h:360: error: type of 'ipv6_renew_options_kern' does not match original declaration [-Werror=lto-type-mismatch]
         ipv6_renew_options_kern(struct sock *sk,
        net/ipv6/exthdrs.c:1162: note: 'ipv6_renew_options_kern' was previously declared here
    
        net/core/dev.c:761: note: 'dev_get_by_name_rcu' was previously declared here
         struct net_device *dev_get_by_name_rcu(struct net *net, const char *name)
        net/core/dev.c:761: note: code may be misoptimized unless -fno-strict-aliasing is used
    
        drivers/gpu/drm/i915/i915_drv.h:3377: error: type of 'i915_gem_object_set_to_wc_domain' does not match original declaration [-Werror=lto-type-mismatch]
         i915_gem_object_set_to_wc_domain(struct drm_i915_gem_object *obj, bool write);
        drivers/gpu/drm/i915/i915_gem.c:3639: note: 'i915_gem_object_set_to_wc_domain' was previously declared here
    
        include/linux/debugfs.h:92:9: error: type of 'debugfs_attr_read' does not match original declaration [-Werror=lto-type-mismatch]
         ssize_t debugfs_attr_read(struct file *file, char __user *buf,
        fs/debugfs/file.c:318: note: 'debugfs_attr_read' was previously declared here
    
        include/linux/rwlock_api_smp.h:30: error: type of '_raw_read_unlock' does not match original declaration [-Werror=lto-type-mismatch]
         void __lockfunc _raw_read_unlock(rwlock_t *lock) __releases(lock);
        kernel/locking/spinlock.c:246:26: note: '_raw_read_unlock' was previously declared here
    
        include/linux/fs.h:3308:5: error: type of 'simple_attr_open' does not match original declaration [-Werror=lto-type-mismatch]
         int simple_attr_open(struct inode *inode, struct file *file,
        fs/libfs.c:795: note: 'simple_attr_open' was previously declared here
    
    All of the above are caused by include/asm-generic/qrwlock_types.h
    failing to include asm/byteorder.h after commit e0d02285f16e
    ("locking/qrwlock: Use 'struct qrwlock' instead of 'struct __qrwlock'")
    in linux-4.15.
    
    Similar bugs may or may not exist in older kernels as well, but there is
    no easy way to test those with link-time optimizations, and kernels
    before 4.14 are harder to fix because they don't have Babu's patch
    series
    
    We had similar issues with CONFIG_ symbols in the past and ended up
    always including the configuration headers though linux/kconfig.h.  This
    works around the issue through that same file, defining either
    __BIG_ENDIAN or __LITTLE_ENDIAN depending on CONFIG_CPU_BIG_ENDIAN,
    which is now always set on all architectures since commit 4c97a0c8fee3
    ("arch: define CPU_BIG_ENDIAN for all fixed big endian archs").
    
    Link: http://lkml.kernel.org/r/20180202154104.1522809-2-arnd@arndb.de
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Cc: Babu Moger <babu.moger@amd.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
    Cc: Nicolas Pitre <nico@linaro.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 143a4454daaf0e80a2b9f37159a0d6d2b61e64ed
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sat Feb 17 15:16:22 2018 +0800

    xfrm: do not call rcu_read_unlock when afinfo is NULL in xfrm_get_tos
    
    When xfrm_policy_get_afinfo returns NULL, it will not hold rcu
    read lock. In this case, rcu_read_unlock should not be called
    in xfrm_get_tos, just like other places where it's calling
    xfrm_policy_get_afinfo.
    
    Fixes: f5e2bb4f5b22 ("xfrm: policy: xfrm_get_tos cannot fail")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

commit daaa81c48402da28cc9e32ad55c48fb05e61b005
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Wed Apr 19 15:11:00 2017 -0700

    nsfs: mark dentry with DCACHE_RCUACCESS
    
    commit 073c516ff73557a8f7315066856c04b50383ac34 upstream.
    
    Andrey reported a use-after-free in __ns_get_path():
    
      spin_lock include/linux/spinlock.h:299 [inline]
      lockref_get_not_dead+0x19/0x80 lib/lockref.c:179
      __ns_get_path+0x197/0x860 fs/nsfs.c:66
      open_related_ns+0xda/0x200 fs/nsfs.c:143
      sock_ioctl+0x39d/0x440 net/socket.c:1001
      vfs_ioctl fs/ioctl.c:45 [inline]
      do_vfs_ioctl+0x1bf/0x1780 fs/ioctl.c:685
      SYSC_ioctl fs/ioctl.c:700 [inline]
      SyS_ioctl+0x8f/0xc0 fs/ioctl.c:691
    
    We are under rcu read lock protection at that point:
    
            rcu_read_lock();
            d = atomic_long_read(&ns->stashed);
            if (!d)
                    goto slow;
            dentry = (struct dentry *)d;
            if (!lockref_get_not_dead(&dentry->d_lockref))
                    goto slow;
            rcu_read_unlock();
    
    but don't use a proper RCU API on the free path, therefore a parallel
    __d_free() could free it at the same time.  We need to mark the stashed
    dentry with DCACHE_RCUACCESS so that __d_free() will be called after all
    readers leave RCU.
    
    Fixes: e149ed2b805f ("take the targets of /proc/*/ns/* symlinks to separate fs")
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Eric Biggers <ebiggers3@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6598ee1deb37afa19a18d5dc31c6ad235df4fcd4
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    
    [ Upstream commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba ]
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 49ffe04fcdf29c8925344bce314d9398b2d7743d
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Wed Apr 19 15:11:00 2017 -0700

    nsfs: mark dentry with DCACHE_RCUACCESS
    
    commit 073c516ff73557a8f7315066856c04b50383ac34 upstream.
    
    Andrey reported a use-after-free in __ns_get_path():
    
      spin_lock include/linux/spinlock.h:299 [inline]
      lockref_get_not_dead+0x19/0x80 lib/lockref.c:179
      __ns_get_path+0x197/0x860 fs/nsfs.c:66
      open_related_ns+0xda/0x200 fs/nsfs.c:143
      sock_ioctl+0x39d/0x440 net/socket.c:1001
      vfs_ioctl fs/ioctl.c:45 [inline]
      do_vfs_ioctl+0x1bf/0x1780 fs/ioctl.c:685
      SYSC_ioctl fs/ioctl.c:700 [inline]
      SyS_ioctl+0x8f/0xc0 fs/ioctl.c:691
    
    We are under rcu read lock protection at that point:
    
            rcu_read_lock();
            d = atomic_long_read(&ns->stashed);
            if (!d)
                    goto slow;
            dentry = (struct dentry *)d;
            if (!lockref_get_not_dead(&dentry->d_lockref))
                    goto slow;
            rcu_read_unlock();
    
    but don't use a proper RCU API on the free path, therefore a parallel
    __d_free() could free it at the same time.  We need to mark the stashed
    dentry with DCACHE_RCUACCESS so that __d_free() will be called after all
    readers leave RCU.
    
    Fixes: e149ed2b805f ("take the targets of /proc/*/ns/* symlinks to separate fs")
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Eric Biggers <ebiggers3@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fff4f776df44afa3fd6ce043ca82c8b317294ad1
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    
    [ Upstream commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba ]
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5d4c05c3ee36f67ddc107ab5ea0898af01a62cc1
Author: Leon Romanovsky <leonro@mellanox.com>
Date:   Wed Feb 14 12:35:40 2018 +0200

    RDMA/uverbs: Sanitize user entered port numbers prior to access it
    
    ==================================================================
    BUG: KASAN: use-after-free in copy_ah_attr_from_uverbs+0x6f2/0x8c0
    Read of size 4 at addr ffff88006476a198 by task syzkaller697701/265
    
    CPU: 0 PID: 265 Comm: syzkaller697701 Not tainted 4.15.0+ #90
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ? show_regs_print_info+0x17/0x17
     ? lock_contended+0x11a0/0x11a0
     print_address_description+0x83/0x3e0
     kasan_report+0x18c/0x4b0
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? lookup_get_idr_uobject+0x120/0x200
     ? copy_ah_attr_from_uverbs+0x6f2/0x8c0
     copy_ah_attr_from_uverbs+0x6f2/0x8c0
     ? modify_qp+0xd0e/0x1350
     modify_qp+0xd0e/0x1350
     ib_uverbs_modify_qp+0xf9/0x170
     ? ib_uverbs_query_qp+0xa70/0xa70
     ib_uverbs_write+0x7f9/0xef0
     ? attach_entity_load_avg+0x8b0/0x8b0
     ? ib_uverbs_query_qp+0xa70/0xa70
     ? uverbs_devnode+0x110/0x110
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? sched_clock_cpu+0x18/0x200
     ? _raw_spin_unlock_irq+0x29/0x40
     ? _raw_spin_unlock_irq+0x29/0x40
     ? _raw_spin_unlock_irq+0x29/0x40
     ? time_hardirqs_on+0x27/0x670
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? _raw_spin_unlock_irq+0x29/0x40
     ? finish_task_switch+0x1bd/0x7a0
     ? finish_task_switch+0x194/0x7a0
     ? prandom_u32_state+0xe/0x180
     ? rcu_read_unlock+0x80/0x80
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433c29
    RSP: 002b:00007ffcf2be82a8 EFLAGS: 00000217
    
    Allocated by task 62:
     kasan_kmalloc+0xa0/0xd0
     kmem_cache_alloc+0x141/0x480
     dup_fd+0x101/0xcc0
     copy_process.part.62+0x166f/0x4390
     _do_fork+0x1cb/0xe90
     kernel_thread+0x34/0x40
     call_usermodehelper_exec_work+0x112/0x260
     process_one_work+0x929/0x1aa0
     worker_thread+0x5c6/0x12a0
     kthread+0x346/0x510
     ret_from_fork+0x3a/0x50
    
    Freed by task 259:
     kasan_slab_free+0x71/0xc0
     kmem_cache_free+0xf3/0x4c0
     put_files_struct+0x225/0x2c0
     exit_files+0x88/0xc0
     do_exit+0x67c/0x1520
     do_group_exit+0xe8/0x380
     SyS_exit_group+0x1e/0x20
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    
    The buggy address belongs to the object at ffff88006476a000
     which belongs to the cache files_cache of size 832
    The buggy address is located 408 bytes inside of
     832-byte region [ffff88006476a000, ffff88006476a340)
    The buggy address belongs to the page:
    page:ffffea000191da80 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
    flags: 0x4000000000008100(slab|head)
    raw: 4000000000008100 0000000000000000 0000000000000000 0000000100080008
    raw: 0000000000000000 0000000100000001 ffff88006bcf7a80 0000000000000000
    page dumped because: kasan: bad access detected
    
    Memory state around the buggy address:
     ffff88006476a080: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88006476a100: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    >ffff88006476a180: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                ^
     ffff88006476a200: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ffff88006476a280: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    ==================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 4.11
    Fixes: 44c58487d51a ("IB/core: Define 'ib' and 'roce' rdma_ah_attr types")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>

commit 9bcc0508576b2d50efd958f2ea1c5906749c2c89
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Fri Oct 27 16:51:52 2017 +0200

    l2tp: protect sock pointer of struct pppol2tp_session with RCU
    
    commit ee40fb2e1eb5bc0ddd3f2f83c6e39a454ef5a741 upstream.
    
    pppol2tp_session_create() registers sessions that can't have their
    corresponding socket initialised. This socket has to be created by
    userspace, then connected to the session by pppol2tp_connect().
    Therefore, we need to protect the pppol2tp socket pointer of L2TP
    sessions, so that it can safely be updated when userspace is connecting
    or closing the socket. This will eventually allow pppol2tp_connect()
    to avoid generating transient states while initialising its parts of the
    session.
    
    To this end, this patch protects the pppol2tp socket pointer using RCU.
    
    The pppol2tp socket pointer is still set in pppol2tp_connect(), but
    only once we know the function isn't going to fail. It's eventually
    reset by pppol2tp_release(), which now has to wait for a grace period
    to elapse before it can drop the last reference on the socket. This
    ensures that pppol2tp_session_get_sock() can safely grab a reference
    on the socket, even after ps->sk is reset to NULL but before this
    operation actually gets visible from pppol2tp_session_get_sock().
    
    The rest is standard RCU conversion: pppol2tp_recv(), which already
    runs in atomic context, is simply enclosed by rcu_read_lock() and
    rcu_read_unlock(), while other functions are converted to use
    pppol2tp_session_get_sock() followed by sock_put().
    pppol2tp_session_setsockopt() is a special case. It used to retrieve
    the pppol2tp socket from the L2TP session, which itself was retrieved
    from the pppol2tp socket. Therefore we can just avoid dereferencing
    ps->sk and directly use the original socket pointer instead.
    
    With all users of ps->sk now handling NULL and concurrent updates, the
    L2TP ->ref() and ->deref() callbacks aren't needed anymore. Therefore,
    rather than converting pppol2tp_session_sock_hold() and
    pppol2tp_session_sock_put(), we can just drop them.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit d36e5ba7bbed5d7bd26e8609ffed503c2def401b
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Fri Oct 27 16:51:52 2017 +0200

    l2tp: protect sock pointer of struct pppol2tp_session with RCU
    
    commit ee40fb2e1eb5bc0ddd3f2f83c6e39a454ef5a741 upstream.
    
    pppol2tp_session_create() registers sessions that can't have their
    corresponding socket initialised. This socket has to be created by
    userspace, then connected to the session by pppol2tp_connect().
    Therefore, we need to protect the pppol2tp socket pointer of L2TP
    sessions, so that it can safely be updated when userspace is connecting
    or closing the socket. This will eventually allow pppol2tp_connect()
    to avoid generating transient states while initialising its parts of the
    session.
    
    To this end, this patch protects the pppol2tp socket pointer using RCU.
    
    The pppol2tp socket pointer is still set in pppol2tp_connect(), but
    only once we know the function isn't going to fail. It's eventually
    reset by pppol2tp_release(), which now has to wait for a grace period
    to elapse before it can drop the last reference on the socket. This
    ensures that pppol2tp_session_get_sock() can safely grab a reference
    on the socket, even after ps->sk is reset to NULL but before this
    operation actually gets visible from pppol2tp_session_get_sock().
    
    The rest is standard RCU conversion: pppol2tp_recv(), which already
    runs in atomic context, is simply enclosed by rcu_read_lock() and
    rcu_read_unlock(), while other functions are converted to use
    pppol2tp_session_get_sock() followed by sock_put().
    pppol2tp_session_setsockopt() is a special case. It used to retrieve
    the pppol2tp socket from the L2TP session, which itself was retrieved
    from the pppol2tp socket. Therefore we can just avoid dereferencing
    ps->sk and directly use the original socket pointer instead.
    
    With all users of ps->sk now handling NULL and concurrent updates, the
    L2TP ->ref() and ->deref() callbacks aren't needed anymore. Therefore,
    rather than converting pppol2tp_session_sock_hold() and
    pppol2tp_session_sock_put(), we can just drop them.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 7d3d60ef2256f5fcfd4929963dd67f58028ebeee
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    
    [ Upstream commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba ]
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2726946dfcd2b2f1863dfae198687c6ec6d976dd
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    
    [ Upstream commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba ]
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6555d5440ba27956907f16405e87674e43762616
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    
    [ Upstream commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba ]
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07234021410bbc27b7c86c18de98616c29fbe667
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon Feb 5 22:18:11 2018 -0500

    tracing: Fix parsing of globs with a wildcard at the beginning
    
    Al Viro reported:
    
        For substring - sure, but what about something like "*a*b" and "a*b"?
        AFAICS, filter_parse_regex() ends up with identical results in both
        cases - MATCH_GLOB and *search = "a*b".  And no way for the caller
        to tell one from another.
    
    Testing this with the following:
    
     # cd /sys/kernel/tracing
     # echo '*raw*lock' > set_ftrace_filter
     bash: echo: write error: Invalid argument
    
    With this patch:
    
     # echo '*raw*lock' > set_ftrace_filter
     # cat set_ftrace_filter
    _raw_read_trylock
    _raw_write_trylock
    _raw_read_unlock
    _raw_spin_unlock
    _raw_write_unlock
    _raw_spin_trylock
    _raw_spin_lock
    _raw_write_lock
    _raw_read_lock
    
    Al recommended not setting the search buffer to skip the first '*' unless we
    know we are not using MATCH_GLOB. This implements his suggested logic.
    
    Link: http://lkml.kernel.org/r/20180127170748.GF13338@ZenIV.linux.org.uk
    
    Cc: stable@vger.kernel.org
    Fixes: 60f1d5e3bac44 ("ftrace: Support full glob matching")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Suggsted-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

commit 4adfa79fc254efb7b0eb3cd58f62c2c3f805f1ba
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Jan 31 16:29:30 2018 +0200

    ip6mr: fix stale iterator
    
    When we dump the ip6mr mfc entries via proc, we initialize an iterator
    with the table to dump but we don't clear the cache pointer which might
    be initialized from a prior read on the same descriptor that ended. This
    can result in lock imbalance (an unnecessary unlock) leading to other
    crashes and hangs. Clear the cache pointer like ipmr does to fix the issue.
    Thanks for the reliable reproducer.
    
    Here's syzbot's trace:
     WARNING: bad unlock balance detected!
     4.15.0-rc3+ #128 Not tainted
     syzkaller971460/3195 is trying to release lock (mrt_lock) at:
     [<000000006898068d>] ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
     but there are no more locks to release!
    
     other info that might help us debug this:
     1 lock held by syzkaller971460/3195:
      #0:  (&p->lock){+.+.}, at: [<00000000744a6565>] seq_read+0xd5/0x13d0
     fs/seq_file.c:165
    
     stack backtrace:
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      print_unlock_imbalance_bug+0x12f/0x140 kernel/locking/lockdep.c:3561
      __lock_release kernel/locking/lockdep.c:3775 [inline]
      lock_release+0x5f9/0xda0 kernel/locking/lockdep.c:4023
      __raw_read_unlock include/linux/rwlock_api_smp.h:225 [inline]
      _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
      ipmr_mfc_seq_stop+0xe1/0x130 net/ipv6/ip6mr.c:553
      traverse+0x3bc/0xa00 fs/seq_file.c:135
      seq_read+0x96a/0x13d0 fs/seq_file.c:189
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     BUG: sleeping function called from invalid context at lib/usercopy.c:25
     in_atomic(): 1, irqs_disabled(): 0, pid: 3195, name: syzkaller971460
     INFO: lockdep is turned off.
     CPU: 1 PID: 3195 Comm: syzkaller971460 Not tainted 4.15.0-rc3+ #128
     Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS
     Google 01/01/2011
     Call Trace:
      __dump_stack lib/dump_stack.c:17 [inline]
      dump_stack+0x194/0x257 lib/dump_stack.c:53
      ___might_sleep+0x2b2/0x470 kernel/sched/core.c:6060
      __might_sleep+0x95/0x190 kernel/sched/core.c:6013
      __might_fault+0xab/0x1d0 mm/memory.c:4525
      _copy_to_user+0x2c/0xc0 lib/usercopy.c:25
      copy_to_user include/linux/uaccess.h:155 [inline]
      seq_read+0xcb4/0x13d0 fs/seq_file.c:279
      proc_reg_read+0xef/0x170 fs/proc/inode.c:217
      do_loop_readv_writev fs/read_write.c:673 [inline]
      do_iter_read+0x3db/0x5b0 fs/read_write.c:897
      compat_readv+0x1bf/0x270 fs/read_write.c:1140
      do_compat_preadv64+0xdc/0x100 fs/read_write.c:1189
      C_SYSC_preadv fs/read_write.c:1209 [inline]
      compat_SyS_preadv+0x3b/0x50 fs/read_write.c:1203
      do_syscall_32_irqs_on arch/x86/entry/common.c:327 [inline]
      do_fast_syscall_32+0x3ee/0xf9d arch/x86/entry/common.c:389
      entry_SYSENTER_compat+0x51/0x60 arch/x86/entry/entry_64_compat.S:125
     RIP: 0023:0xf7f73c79
     RSP: 002b:00000000e574a15c EFLAGS: 00000292 ORIG_RAX: 000000000000014d
     RAX: ffffffffffffffda RBX: 000000000000000f RCX: 0000000020a3afb0
     RDX: 0000000000000001 RSI: 0000000000000067 RDI: 0000000000000000
     RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000000
     R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
     WARNING: CPU: 1 PID: 3195 at lib/usercopy.c:26 _copy_to_user+0xb5/0xc0
     lib/usercopy.c:26
    
    Reported-by: syzbot <bot+eceb3204562c41a438fa1f2335e0fe4f6886d669@syzkaller.appspotmail.com>
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 0c06bea919f3289368a023d1a62a1bc319617fa3
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Tue Jan 16 12:31:41 2018 +0300

    net: Fix possible race in peernet2id_alloc()
    
    peernet2id_alloc() is racy without rtnl_lock() as refcount_read(&peer->count)
    under net->nsid_lock does not guarantee, peer is alive:
    
    rcu_read_lock()
    peernet2id_alloc()                            ..
      spin_lock_bh(&net->nsid_lock)               ..
      refcount_read(&peer->count) (!= 0)          ..
      ..                                          put_net()
      ..                                            cleanup_net()
      ..                                              for_each_net(tmp)
      ..                                                spin_lock_bh(&tmp->nsid_lock)
      ..                                                __peernet2id(tmp, net) == -1
      ..                                                    ..
      ..                                                    ..
        __peernet2id_alloc(alloc == true)                   ..
      ..                                                    ..
    rcu_read_unlock()                                       ..
    ..                                                synchronize_rcu()
    ..                                                kmem_cache_free(net)
    
    After the above situation, net::netns_id contains id pointing to freed memory,
    and any other dereferencing by the id will operate with this freed memory.
    
    Currently, peernet2id_alloc() is used under rtnl_lock() everywhere except
    ovs_vport_cmd_fill_info(), and this race can't occur. But peernet2id_alloc()
    is generic interface, and better we fix it before someone really starts
    use it in wrong context.
    
    v2: Don't place refcount_read(&net->count) under net->nsid_lock
        as suggested by Eric W. Biederman <ebiederm@xmission.com>
    v3: Rebase on top of net-next
    
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5005c8514285ae4f28e862f8d91faaa2015e03a3
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Sat Jan 6 10:56:18 2018 +0000

    drm/i915: Don't adjust priority on an already signaled fence
    
    When we retire a signaled fence, we free the dependency tree. However,
    we skip clearing the list so that if we then try to adjust the priority
    of the signaled fence, we may walk the list of freed dependencies.
    
    [ 3083.156757] ==================================================================
    [ 3083.156806] BUG: KASAN: use-after-free in execlists_schedule+0x199/0x660 [i915]
    [ 3083.156810] Read of size 8 at addr ffff8806bf20f400 by task Xorg/831
    
    [ 3083.156815] CPU: 0 PID: 831 Comm: Xorg Not tainted 4.15.0-rc6-no-psn+ #1
    [ 3083.156817] Hardware name: Notebook                         N24_25BU/N24_25BU, BIOS 5.12 02/17/2017
    [ 3083.156818] Call Trace:
    [ 3083.156823]  dump_stack+0x5c/0x7a
    [ 3083.156827]  print_address_description+0x6b/0x290
    [ 3083.156830]  kasan_report+0x28f/0x380
    [ 3083.156872]  ? execlists_schedule+0x199/0x660 [i915]
    [ 3083.156914]  execlists_schedule+0x199/0x660 [i915]
    [ 3083.156956]  ? intel_crtc_atomic_check+0x146/0x4e0 [i915]
    [ 3083.156997]  ? execlists_submit_request+0xe0/0xe0 [i915]
    [ 3083.157038]  ? i915_vma_misplaced.part.4+0x25/0xb0 [i915]
    [ 3083.157079]  ? __i915_vma_do_pin+0x7c8/0xc80 [i915]
    [ 3083.157121]  ? intel_atomic_state_alloc+0x44/0x60 [i915]
    [ 3083.157130]  ? drm_atomic_helper_page_flip+0x3e/0xb0 [drm_kms_helper]
    [ 3083.157145]  ? drm_mode_page_flip_ioctl+0x7d2/0x850 [drm]
    [ 3083.157159]  ? drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.157172]  ? drm_ioctl+0x45b/0x560 [drm]
    [ 3083.157211]  i915_gem_object_wait_priority+0x14c/0x2c0 [i915]
    [ 3083.157251]  ? i915_gem_get_aperture_ioctl+0x150/0x150 [i915]
    [ 3083.157290]  ? i915_vma_pin_fence+0x1d8/0x320 [i915]
    [ 3083.157331]  ? intel_pin_and_fence_fb_obj+0x175/0x250 [i915]
    [ 3083.157372]  ? intel_rotation_info_size+0x60/0x60 [i915]
    [ 3083.157413]  ? intel_link_compute_m_n+0x80/0x80 [i915]
    [ 3083.157428]  ? drm_dev_printk+0x1b0/0x1b0 [drm]
    [ 3083.157443]  ? drm_dev_printk+0x1b0/0x1b0 [drm]
    [ 3083.157485]  intel_prepare_plane_fb+0x2f8/0x5a0 [i915]
    [ 3083.157527]  ? intel_crtc_get_vblank_counter+0x80/0x80 [i915]
    [ 3083.157536]  drm_atomic_helper_prepare_planes+0xa0/0x1c0 [drm_kms_helper]
    [ 3083.157587]  intel_atomic_commit+0x12e/0x4e0 [i915]
    [ 3083.157605]  drm_atomic_helper_page_flip+0xa2/0xb0 [drm_kms_helper]
    [ 3083.157621]  drm_mode_page_flip_ioctl+0x7d2/0x850 [drm]
    [ 3083.157638]  ? drm_mode_cursor2_ioctl+0x10/0x10 [drm]
    [ 3083.157652]  ? drm_lease_owner+0x1a/0x30 [drm]
    [ 3083.157668]  ? drm_mode_cursor2_ioctl+0x10/0x10 [drm]
    [ 3083.157681]  drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.157696]  drm_ioctl+0x45b/0x560 [drm]
    [ 3083.157711]  ? drm_mode_cursor2_ioctl+0x10/0x10 [drm]
    [ 3083.157725]  ? drm_getstats+0x20/0x20 [drm]
    [ 3083.157729]  ? timerqueue_del+0x49/0x80
    [ 3083.157732]  ? __remove_hrtimer+0x62/0xb0
    [ 3083.157735]  ? hrtimer_try_to_cancel+0x173/0x210
    [ 3083.157738]  do_vfs_ioctl+0x13b/0x880
    [ 3083.157741]  ? ioctl_preallocate+0x140/0x140
    [ 3083.157744]  ? _raw_spin_unlock_irq+0xe/0x30
    [ 3083.157746]  ? do_setitimer+0x234/0x370
    [ 3083.157750]  ? SyS_setitimer+0x19e/0x1b0
    [ 3083.157752]  ? SyS_alarm+0x140/0x140
    [ 3083.157755]  ? __rcu_read_unlock+0x66/0x80
    [ 3083.157757]  ? __fget+0xc4/0x100
    [ 3083.157760]  SyS_ioctl+0x74/0x80
    [ 3083.157763]  entry_SYSCALL_64_fastpath+0x1a/0x7d
    [ 3083.157765] RIP: 0033:0x7f6135d0c6a7
    [ 3083.157767] RSP: 002b:00007fff01451888 EFLAGS: 00003246 ORIG_RAX: 0000000000000010
    [ 3083.157769] RAX: ffffffffffffffda RBX: 0000000000000004 RCX: 00007f6135d0c6a7
    [ 3083.157771] RDX: 00007fff01451950 RSI: 00000000c01864b0 RDI: 000000000000000c
    [ 3083.157772] RBP: 00007f613076f600 R08: 0000000000000001 R09: 0000000000000000
    [ 3083.157773] R10: 0000000000000060 R11: 0000000000003246 R12: 0000000000000000
    [ 3083.157774] R13: 0000000000000060 R14: 000000000000001b R15: 0000000000000060
    
    [ 3083.157779] Allocated by task 831:
    [ 3083.157783]  kmem_cache_alloc+0xc0/0x200
    [ 3083.157822]  i915_gem_request_await_dma_fence+0x2c4/0x5d0 [i915]
    [ 3083.157861]  i915_gem_request_await_object+0x321/0x370 [i915]
    [ 3083.157900]  i915_gem_do_execbuffer+0x1165/0x19c0 [i915]
    [ 3083.157937]  i915_gem_execbuffer2+0x1ad/0x550 [i915]
    [ 3083.157950]  drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.157962]  drm_ioctl+0x45b/0x560 [drm]
    [ 3083.157964]  do_vfs_ioctl+0x13b/0x880
    [ 3083.157966]  SyS_ioctl+0x74/0x80
    [ 3083.157968]  entry_SYSCALL_64_fastpath+0x1a/0x7d
    
    [ 3083.157971] Freed by task 831:
    [ 3083.157973]  kmem_cache_free+0x77/0x220
    [ 3083.158012]  i915_gem_request_retire+0x72c/0xa70 [i915]
    [ 3083.158051]  i915_gem_request_alloc+0x1e9/0x8b0 [i915]
    [ 3083.158089]  i915_gem_do_execbuffer+0xa96/0x19c0 [i915]
    [ 3083.158127]  i915_gem_execbuffer2+0x1ad/0x550 [i915]
    [ 3083.158140]  drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.158153]  drm_ioctl+0x45b/0x560 [drm]
    [ 3083.158155]  do_vfs_ioctl+0x13b/0x880
    [ 3083.158156]  SyS_ioctl+0x74/0x80
    [ 3083.158158]  entry_SYSCALL_64_fastpath+0x1a/0x7d
    
    [ 3083.158162] The buggy address belongs to the object at ffff8806bf20f400
                    which belongs to the cache i915_dependency of size 64
    [ 3083.158166] The buggy address is located 0 bytes inside of
                    64-byte region [ffff8806bf20f400, ffff8806bf20f440)
    [ 3083.158168] The buggy address belongs to the page:
    [ 3083.158171] page:00000000d43decc4 count:1 mapcount:0 mapping:          (null) index:0x0
    [ 3083.158174] flags: 0x17ffe0000000100(slab)
    [ 3083.158179] raw: 017ffe0000000100 0000000000000000 0000000000000000 0000000180200020
    [ 3083.158182] raw: ffffea001afc16c0 0000000500000005 ffff880731b881c0 0000000000000000
    [ 3083.158184] page dumped because: kasan: bad access detected
    
    [ 3083.158187] Memory state around the buggy address:
    [ 3083.158190]  ffff8806bf20f300: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158192]  ffff8806bf20f380: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158195] >ffff8806bf20f400: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158196]                    ^
    [ 3083.158199]  ffff8806bf20f480: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158201]  ffff8806bf20f500: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158203] ==================================================================
    
    Reported-by: Alexandru Chirvasitu <achirvasub@gmail.com>
    Reported-by: Mike Keehan <mike@keehan.net>
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=104436
    Fixes: 1f181225f8ec ("drm/i915/execlists: Keep request->priority for its lifetime")
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Alexandru Chirvasitu <achirvasub@gmail.com>
    Cc: Micha Winiarski <michal.winiarski@intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Tested-by: Alexandru Chirvasitu <achirvasub@gmail.com>
    Reviewed-by: Micha Winiarski <michal.winiarski@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180106105618.13532-1-chris@chris-wilson.co.uk
    (cherry picked from commit c218ee03b9315073ce43992792554dafa0626eb8)
    Signed-off-by: Jani Nikula <jani.nikula@intel.com>

commit 08b5a6e2a769f720977b245431b45134c0bdd377
Author: Jens Axboe <axboe@kernel.dk>
Date:   Tue Jan 9 09:32:25 2018 -0700

    blk-mq: silence false positive warnings in hctx_unlock()
    
    In some stupider versions of gcc, it complains:
    
    block/blk-mq.c: In function blk_mq_complete_request:
    ./include/linux/srcu.h:175:2: warning: srcu_idx may be used uninitialized in this function [-Wmaybe-uninitialized]
      __srcu_read_unlock(sp, idx);
      ^
    block/blk-mq.c:620:6: note: srcu_idx was declared here
      int srcu_idx;
          ^
    
    which is completely bogus, since we only use srcu_idx when
    hctx->flags & BLK_MQ_F_BLOCKING is set, and that's the case where
    hctx_lock() has initialized it.
    
    Just set it to '0' in the normal path in hctx_lock() to silence
    this annoying warning.
    
    Fixes: 04ced159cec8 ("blk-mq: move hctx lock/unlock into a helper")
    Fixes: 5197c05e16b4 ("blk-mq: protect completion path with RCU")
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit c218ee03b9315073ce43992792554dafa0626eb8
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Sat Jan 6 10:56:18 2018 +0000

    drm/i915: Don't adjust priority on an already signaled fence
    
    When we retire a signaled fence, we free the dependency tree. However,
    we skip clearing the list so that if we then try to adjust the priority
    of the signaled fence, we may walk the list of freed dependencies.
    
    [ 3083.156757] ==================================================================
    [ 3083.156806] BUG: KASAN: use-after-free in execlists_schedule+0x199/0x660 [i915]
    [ 3083.156810] Read of size 8 at addr ffff8806bf20f400 by task Xorg/831
    
    [ 3083.156815] CPU: 0 PID: 831 Comm: Xorg Not tainted 4.15.0-rc6-no-psn+ #1
    [ 3083.156817] Hardware name: Notebook                         N24_25BU/N24_25BU, BIOS 5.12 02/17/2017
    [ 3083.156818] Call Trace:
    [ 3083.156823]  dump_stack+0x5c/0x7a
    [ 3083.156827]  print_address_description+0x6b/0x290
    [ 3083.156830]  kasan_report+0x28f/0x380
    [ 3083.156872]  ? execlists_schedule+0x199/0x660 [i915]
    [ 3083.156914]  execlists_schedule+0x199/0x660 [i915]
    [ 3083.156956]  ? intel_crtc_atomic_check+0x146/0x4e0 [i915]
    [ 3083.156997]  ? execlists_submit_request+0xe0/0xe0 [i915]
    [ 3083.157038]  ? i915_vma_misplaced.part.4+0x25/0xb0 [i915]
    [ 3083.157079]  ? __i915_vma_do_pin+0x7c8/0xc80 [i915]
    [ 3083.157121]  ? intel_atomic_state_alloc+0x44/0x60 [i915]
    [ 3083.157130]  ? drm_atomic_helper_page_flip+0x3e/0xb0 [drm_kms_helper]
    [ 3083.157145]  ? drm_mode_page_flip_ioctl+0x7d2/0x850 [drm]
    [ 3083.157159]  ? drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.157172]  ? drm_ioctl+0x45b/0x560 [drm]
    [ 3083.157211]  i915_gem_object_wait_priority+0x14c/0x2c0 [i915]
    [ 3083.157251]  ? i915_gem_get_aperture_ioctl+0x150/0x150 [i915]
    [ 3083.157290]  ? i915_vma_pin_fence+0x1d8/0x320 [i915]
    [ 3083.157331]  ? intel_pin_and_fence_fb_obj+0x175/0x250 [i915]
    [ 3083.157372]  ? intel_rotation_info_size+0x60/0x60 [i915]
    [ 3083.157413]  ? intel_link_compute_m_n+0x80/0x80 [i915]
    [ 3083.157428]  ? drm_dev_printk+0x1b0/0x1b0 [drm]
    [ 3083.157443]  ? drm_dev_printk+0x1b0/0x1b0 [drm]
    [ 3083.157485]  intel_prepare_plane_fb+0x2f8/0x5a0 [i915]
    [ 3083.157527]  ? intel_crtc_get_vblank_counter+0x80/0x80 [i915]
    [ 3083.157536]  drm_atomic_helper_prepare_planes+0xa0/0x1c0 [drm_kms_helper]
    [ 3083.157587]  intel_atomic_commit+0x12e/0x4e0 [i915]
    [ 3083.157605]  drm_atomic_helper_page_flip+0xa2/0xb0 [drm_kms_helper]
    [ 3083.157621]  drm_mode_page_flip_ioctl+0x7d2/0x850 [drm]
    [ 3083.157638]  ? drm_mode_cursor2_ioctl+0x10/0x10 [drm]
    [ 3083.157652]  ? drm_lease_owner+0x1a/0x30 [drm]
    [ 3083.157668]  ? drm_mode_cursor2_ioctl+0x10/0x10 [drm]
    [ 3083.157681]  drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.157696]  drm_ioctl+0x45b/0x560 [drm]
    [ 3083.157711]  ? drm_mode_cursor2_ioctl+0x10/0x10 [drm]
    [ 3083.157725]  ? drm_getstats+0x20/0x20 [drm]
    [ 3083.157729]  ? timerqueue_del+0x49/0x80
    [ 3083.157732]  ? __remove_hrtimer+0x62/0xb0
    [ 3083.157735]  ? hrtimer_try_to_cancel+0x173/0x210
    [ 3083.157738]  do_vfs_ioctl+0x13b/0x880
    [ 3083.157741]  ? ioctl_preallocate+0x140/0x140
    [ 3083.157744]  ? _raw_spin_unlock_irq+0xe/0x30
    [ 3083.157746]  ? do_setitimer+0x234/0x370
    [ 3083.157750]  ? SyS_setitimer+0x19e/0x1b0
    [ 3083.157752]  ? SyS_alarm+0x140/0x140
    [ 3083.157755]  ? __rcu_read_unlock+0x66/0x80
    [ 3083.157757]  ? __fget+0xc4/0x100
    [ 3083.157760]  SyS_ioctl+0x74/0x80
    [ 3083.157763]  entry_SYSCALL_64_fastpath+0x1a/0x7d
    [ 3083.157765] RIP: 0033:0x7f6135d0c6a7
    [ 3083.157767] RSP: 002b:00007fff01451888 EFLAGS: 00003246 ORIG_RAX: 0000000000000010
    [ 3083.157769] RAX: ffffffffffffffda RBX: 0000000000000004 RCX: 00007f6135d0c6a7
    [ 3083.157771] RDX: 00007fff01451950 RSI: 00000000c01864b0 RDI: 000000000000000c
    [ 3083.157772] RBP: 00007f613076f600 R08: 0000000000000001 R09: 0000000000000000
    [ 3083.157773] R10: 0000000000000060 R11: 0000000000003246 R12: 0000000000000000
    [ 3083.157774] R13: 0000000000000060 R14: 000000000000001b R15: 0000000000000060
    
    [ 3083.157779] Allocated by task 831:
    [ 3083.157783]  kmem_cache_alloc+0xc0/0x200
    [ 3083.157822]  i915_gem_request_await_dma_fence+0x2c4/0x5d0 [i915]
    [ 3083.157861]  i915_gem_request_await_object+0x321/0x370 [i915]
    [ 3083.157900]  i915_gem_do_execbuffer+0x1165/0x19c0 [i915]
    [ 3083.157937]  i915_gem_execbuffer2+0x1ad/0x550 [i915]
    [ 3083.157950]  drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.157962]  drm_ioctl+0x45b/0x560 [drm]
    [ 3083.157964]  do_vfs_ioctl+0x13b/0x880
    [ 3083.157966]  SyS_ioctl+0x74/0x80
    [ 3083.157968]  entry_SYSCALL_64_fastpath+0x1a/0x7d
    
    [ 3083.157971] Freed by task 831:
    [ 3083.157973]  kmem_cache_free+0x77/0x220
    [ 3083.158012]  i915_gem_request_retire+0x72c/0xa70 [i915]
    [ 3083.158051]  i915_gem_request_alloc+0x1e9/0x8b0 [i915]
    [ 3083.158089]  i915_gem_do_execbuffer+0xa96/0x19c0 [i915]
    [ 3083.158127]  i915_gem_execbuffer2+0x1ad/0x550 [i915]
    [ 3083.158140]  drm_ioctl_kernel+0xa7/0xf0 [drm]
    [ 3083.158153]  drm_ioctl+0x45b/0x560 [drm]
    [ 3083.158155]  do_vfs_ioctl+0x13b/0x880
    [ 3083.158156]  SyS_ioctl+0x74/0x80
    [ 3083.158158]  entry_SYSCALL_64_fastpath+0x1a/0x7d
    
    [ 3083.158162] The buggy address belongs to the object at ffff8806bf20f400
                    which belongs to the cache i915_dependency of size 64
    [ 3083.158166] The buggy address is located 0 bytes inside of
                    64-byte region [ffff8806bf20f400, ffff8806bf20f440)
    [ 3083.158168] The buggy address belongs to the page:
    [ 3083.158171] page:00000000d43decc4 count:1 mapcount:0 mapping:          (null) index:0x0
    [ 3083.158174] flags: 0x17ffe0000000100(slab)
    [ 3083.158179] raw: 017ffe0000000100 0000000000000000 0000000000000000 0000000180200020
    [ 3083.158182] raw: ffffea001afc16c0 0000000500000005 ffff880731b881c0 0000000000000000
    [ 3083.158184] page dumped because: kasan: bad access detected
    
    [ 3083.158187] Memory state around the buggy address:
    [ 3083.158190]  ffff8806bf20f300: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158192]  ffff8806bf20f380: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158195] >ffff8806bf20f400: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158196]                    ^
    [ 3083.158199]  ffff8806bf20f480: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158201]  ffff8806bf20f500: fb fb fb fb fb fb fb fb fc fc fc fc fc fc fc fc
    [ 3083.158203] ==================================================================
    
    Reported-by: Alexandru Chirvasitu <achirvasub@gmail.com>
    Reported-by: Mike Keehan <mike@keehan.net>
    Bugzilla: https://bugs.freedesktop.org/show_bug.cgi?id=104436
    Fixes: 1f181225f8ec ("drm/i915/execlists: Keep request->priority for its lifetime")
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Alexandru Chirvasitu <achirvasub@gmail.com>
    Cc: Micha Winiarski <michal.winiarski@intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
    Tested-by: Alexandru Chirvasitu <achirvasub@gmail.com>
    Reviewed-by: Micha Winiarski <michal.winiarski@intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20180106105618.13532-1-chris@chris-wilson.co.uk

commit e51abae8458a36b24b18162873578ef788412191
Author: Nikita V. Shirokov <tehnerd@fb.com>
Date:   Wed Dec 6 17:15:43 2017 -0800

    adding missing rcu_read_unlock in ipxip6_rcv
    
    
    [ Upstream commit 74c4b656c3d92ec4c824ea1a4afd726b7b6568c8 ]
    
    commit 8d79266bc48c ("ip6_tunnel: add collect_md mode to IPv6 tunnels")
    introduced new exit point in  ipxip6_rcv. however rcu_read_unlock is
    missing there. this diff is fixing this
    
    v1->v2:
     instead of doing rcu_read_unlock in place, we are going to "drop"
     section (to prevent skb leakage)
    
    Fixes: 8d79266bc48c ("ip6_tunnel: add collect_md mode to IPv6 tunnels")
    Signed-off-by: Nikita V. Shirokov <tehnerd@fb.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6d1c489810bcde9266ccdbedc0861a5dc9778f60
Author: Nikita V. Shirokov <tehnerd@fb.com>
Date:   Wed Dec 6 17:15:43 2017 -0800

    adding missing rcu_read_unlock in ipxip6_rcv
    
    
    [ Upstream commit 74c4b656c3d92ec4c824ea1a4afd726b7b6568c8 ]
    
    commit 8d79266bc48c ("ip6_tunnel: add collect_md mode to IPv6 tunnels")
    introduced new exit point in  ipxip6_rcv. however rcu_read_unlock is
    missing there. this diff is fixing this
    
    v1->v2:
     instead of doing rcu_read_unlock in place, we are going to "drop"
     section (to prevent skb leakage)
    
    Fixes: 8d79266bc48c ("ip6_tunnel: add collect_md mode to IPv6 tunnels")
    Signed-off-by: Nikita V. Shirokov <tehnerd@fb.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5ce8a2b88ea52f26ec5d0294f8bf7fa4cb5c1b64
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Tue Nov 29 13:09:45 2016 +0100

    l2tp: hold socket before dropping lock in l2tp_ip{, 6}_recv()
    
    commit a3c18422a4b4e108bcf6a2328f48867e1003fd95 upstream.
    
    Socket must be held while under the protection of the l2tp lock; there
    is no guarantee that sk remains valid after the read_unlock_bh() call.
    
    Same issue for l2tp_ip and l2tp_ip6.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 4ea094bb4db82122d8ebc84e9f10293e56453690
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Tue Nov 29 13:09:45 2016 +0100

    l2tp: hold socket before dropping lock in l2tp_ip{, 6}_recv()
    
    commit a3c18422a4b4e108bcf6a2328f48867e1003fd95 upstream.
    
    Socket must be held while under the protection of the l2tp lock; there
    is no guarantee that sk remains valid after the read_unlock_bh() call.
    
    Same issue for l2tp_ip and l2tp_ip6.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2:
     - Drop changes in l2tp_ip6.c
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 8e9d8e19b3d0c36d45161233eee3f2d368efe3ac
Author: Subhransu S. Prusty <subhransu.s.prusty@intel.com>
Date:   Mon Dec 18 10:46:49 2017 +0530

    ASoC: Intel: Skylake: Request IRQ late only after all context are initialized
    
    Sometimes during boot, panic is observed at sst_dsp_shim_read_unlocked().
    This happens when interrupt occurs before the context is initialized. So
    move the irq initialization only after the context is initialized
    completely.
    
    Signed-off-by: Subhransu S. Prusty <subhransu.s.prusty@intel.com>
    Signed-off-by: Pawse, GuruprasadX <guruprasadx.pawse@intel.com>
    Signed-off-by: Guneshwor Singh <guneshwor.o.singh@intel.com>
    Acked-By: Vinod Koul <vinod.koul@intel.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

commit 29d631e5941366ee5eb50b3b592ca99186115a63
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sun Nov 19 19:31:04 2017 +0800

    tun: fix rcu_read_lock imbalance in tun_build_skb
    
    
    [ Upstream commit 654d573845f35017dc397840fa03610fef3d08b0 ]
    
    rcu_read_lock in tun_build_skb is used to rcu_dereference tun->xdp_prog
    safely, rcu_read_unlock should be done in every return path.
    
    Now I could see one place missing it, where it returns NULL in switch-case
    XDP_REDIRECT,  another palce using rcu_read_lock wrongly, where it returns
    NULL in if (xdp_xmit) chunk.
    
    So fix both in this patch.
    
    Fixes: 761876c857cb ("tap: XDP support")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 74c4b656c3d92ec4c824ea1a4afd726b7b6568c8
Author: Nikita V. Shirokov <tehnerd@fb.com>
Date:   Wed Dec 6 17:15:43 2017 -0800

    adding missing rcu_read_unlock in ipxip6_rcv
    
    commit 8d79266bc48c ("ip6_tunnel: add collect_md mode to IPv6 tunnels")
    introduced new exit point in  ipxip6_rcv. however rcu_read_unlock is
    missing there. this diff is fixing this
    
    v1->v2:
     instead of doing rcu_read_unlock in place, we are going to "drop"
     section (to prevent skb leakage)
    
    Fixes: 8d79266bc48c ("ip6_tunnel: add collect_md mode to IPv6 tunnels")
    Signed-off-by: Nikita V. Shirokov <tehnerd@fb.com>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b40c232687596b14a8b3dcb22422c2674c167f76
Author: Jia-Ju Bai <baijiaju1990@163.com>
Date:   Fri Oct 27 11:12:30 2017 +0300

    wcn36xx: Remove unnecessary rcu_read_unlock in wcn36xx_bss_info_changed
    
    commit c0d5adc35c0b010120391117cb07be6623cf8940 upstream.
    
    No rcu_read_lock is called, but rcu_read_unlock is still called.
    Thus rcu_read_unlock should be removed.
    
    Signed-off-by: Jia-Ju Bai <baijiaju1990@163.com>
    Acked-by: Bjorn Andersson <bjorn.andersson@linaro.org>
    Signed-off-by: Kalle Valo <kvalo@qca.qualcomm.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 654d573845f35017dc397840fa03610fef3d08b0
Author: Xin Long <lucien.xin@gmail.com>
Date:   Sun Nov 19 19:31:04 2017 +0800

    tun: fix rcu_read_lock imbalance in tun_build_skb
    
    rcu_read_lock in tun_build_skb is used to rcu_dereference tun->xdp_prog
    safely, rcu_read_unlock should be done in every return path.
    
    Now I could see one place missing it, where it returns NULL in switch-case
    XDP_REDIRECT,  another palce using rcu_read_lock wrongly, where it returns
    NULL in if (xdp_xmit) chunk.
    
    So fix both in this patch.
    
    Fixes: 761876c857cb ("tap: XDP support")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit cc6db6b3a840a4914ba34e4507ac8fcfcca85500
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:05 2017 +0300

    sch_tbf: fix two null pointer dereferences on init failure
    
    commit c2d6511e6a4f1f3673d711569c00c3849549e9b0 upstream.
    
    sch_tbf calls qdisc_watchdog_cancel() in both its ->reset and ->destroy
    callbacks but it may fail before the timer is initialized due to missing
    options (either not supplied by user-space or set as a default qdisc),
    also q->qdisc is used by ->reset and ->destroy so we need it initialized.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=tbf
    $ ip l set ethX up
    
    Crash log:
    [  959.160172] BUG: unable to handle kernel NULL pointer dereference at 0000000000000018
    [  959.160323] IP: qdisc_reset+0xa/0x5c
    [  959.160400] PGD 59cdb067
    [  959.160401] P4D 59cdb067
    [  959.160466] PUD 59ccb067
    [  959.160532] PMD 0
    [  959.160597]
    [  959.160706] Oops: 0000 [#1] SMP
    [  959.160778] Modules linked in: sch_tbf sch_sfb sch_prio sch_netem
    [  959.160891] CPU: 2 PID: 1562 Comm: ip Not tainted 4.13.0-rc6+ #62
    [  959.160998] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  959.161157] task: ffff880059c9a700 task.stack: ffff8800376d0000
    [  959.161263] RIP: 0010:qdisc_reset+0xa/0x5c
    [  959.161347] RSP: 0018:ffff8800376d3610 EFLAGS: 00010286
    [  959.161531] RAX: ffffffffa001b1dd RBX: ffff8800373a2800 RCX: 0000000000000000
    [  959.161733] RDX: ffffffff8215f160 RSI: ffffffff8215f160 RDI: 0000000000000000
    [  959.161939] RBP: ffff8800376d3618 R08: 00000000014080c0 R09: 00000000ffffffff
    [  959.162141] R10: ffff8800376d3578 R11: 0000000000000020 R12: ffffffffa001d2c0
    [  959.162343] R13: ffff880037538000 R14: 00000000ffffffff R15: 0000000000000001
    [  959.162546] FS:  00007fcc5126b740(0000) GS:ffff88005d900000(0000) knlGS:0000000000000000
    [  959.162844] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  959.163030] CR2: 0000000000000018 CR3: 000000005abc4000 CR4: 00000000000406e0
    [  959.163233] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  959.163436] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  959.163638] Call Trace:
    [  959.163788]  tbf_reset+0x19/0x64 [sch_tbf]
    [  959.163957]  qdisc_destroy+0x8b/0xe5
    [  959.164119]  qdisc_create_dflt+0x86/0x94
    [  959.164284]  ? dev_activate+0x129/0x129
    [  959.164449]  attach_one_default_qdisc+0x36/0x63
    [  959.164623]  netdev_for_each_tx_queue+0x3d/0x48
    [  959.164795]  dev_activate+0x4b/0x129
    [  959.164957]  __dev_open+0xe7/0x104
    [  959.165118]  __dev_change_flags+0xc6/0x15c
    [  959.165287]  dev_change_flags+0x25/0x59
    [  959.165451]  do_setlink+0x30c/0xb3f
    [  959.165613]  ? check_chain_key+0xb0/0xfd
    [  959.165782]  rtnl_newlink+0x3a4/0x729
    [  959.165947]  ? rtnl_newlink+0x117/0x729
    [  959.166121]  ? ns_capable_common+0xd/0xb1
    [  959.166288]  ? ns_capable+0x13/0x15
    [  959.166450]  rtnetlink_rcv_msg+0x188/0x197
    [  959.166617]  ? rcu_read_unlock+0x3e/0x5f
    [  959.166783]  ? rtnl_newlink+0x729/0x729
    [  959.166948]  netlink_rcv_skb+0x6c/0xce
    [  959.167113]  rtnetlink_rcv+0x23/0x2a
    [  959.167273]  netlink_unicast+0x103/0x181
    [  959.167439]  netlink_sendmsg+0x326/0x337
    [  959.167607]  sock_sendmsg_nosec+0x14/0x3f
    [  959.167772]  sock_sendmsg+0x29/0x2e
    [  959.167932]  ___sys_sendmsg+0x209/0x28b
    [  959.168098]  ? do_raw_spin_unlock+0xcd/0xf8
    [  959.168267]  ? _raw_spin_unlock+0x27/0x31
    [  959.168432]  ? __handle_mm_fault+0x651/0xdb1
    [  959.168602]  ? check_chain_key+0xb0/0xfd
    [  959.168773]  __sys_sendmsg+0x45/0x63
    [  959.168934]  ? __sys_sendmsg+0x45/0x63
    [  959.169100]  SyS_sendmsg+0x19/0x1b
    [  959.169260]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  959.169432] RIP: 0033:0x7fcc5097e690
    [  959.169592] RSP: 002b:00007ffd0d5c7b48 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  959.169887] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007fcc5097e690
    [  959.170089] RDX: 0000000000000000 RSI: 00007ffd0d5c7b90 RDI: 0000000000000003
    [  959.170292] RBP: ffff8800376d3f98 R08: 0000000000000001 R09: 0000000000000003
    [  959.170494] R10: 00007ffd0d5c7910 R11: 0000000000000246 R12: 0000000000000006
    [  959.170697] R13: 000000000066f1a0 R14: 00007ffd0d5cfc40 R15: 0000000000000000
    [  959.170900]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  959.171076] Code: 00 41 c7 84 24 14 01 00 00 00 00 00 00 41 c7 84 24
    98 00 00 00 00 00 00 00 41 5c 41 5d 41 5e 5d c3 66 66 66 66 90 55 48 89
    e5 53 <48> 8b 47 18 48 89 fb 48 8b 40 48 48 85 c0 74 02 ff d0 48 8b bb
    [  959.171637] RIP: qdisc_reset+0xa/0x5c RSP: ffff8800376d3610
    [  959.171821] CR2: 0000000000000018
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit d1e4c9f184408fb9282a9c17a976cb8fe1fb49d8
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:03 2017 +0300

    sch_netem: avoid null pointer deref on init failure
    
    commit 634576a1844dba15bc5e6fc61d72f37e13a21615 upstream.
    
    netem can fail in ->init due to missing options (either not supplied by
    user-space or used as a default qdisc) causing a timer->base null
    pointer deref in its ->destroy() and ->reset() callbacks.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=netem
    $ ip l set ethX up
    
    Crash log:
    [ 1814.846943] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 1814.847181] IP: hrtimer_active+0x17/0x8a
    [ 1814.847270] PGD 59c34067
    [ 1814.847271] P4D 59c34067
    [ 1814.847337] PUD 37374067
    [ 1814.847403] PMD 0
    [ 1814.847468]
    [ 1814.847582] Oops: 0000 [#1] SMP
    [ 1814.847655] Modules linked in: sch_netem(O) sch_fq_codel(O)
    [ 1814.847761] CPU: 3 PID: 1573 Comm: ip Tainted: G           O 4.13.0-rc6+ #62
    [ 1814.847884] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 1814.848043] task: ffff88003723a700 task.stack: ffff88005adc8000
    [ 1814.848235] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 1814.848407] RSP: 0018:ffff88005adcb590 EFLAGS: 00010246
    [ 1814.848590] RAX: 0000000000000000 RBX: ffff880058e359d8 RCX: 0000000000000000
    [ 1814.848793] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff880058e359d8
    [ 1814.848998] RBP: ffff88005adcb5b0 R08: 00000000014080c0 R09: 00000000ffffffff
    [ 1814.849204] R10: ffff88005adcb660 R11: 0000000000000020 R12: 0000000000000000
    [ 1814.849410] R13: ffff880058e359d8 R14: 00000000ffffffff R15: 0000000000000001
    [ 1814.849616] FS:  00007f733bbca740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 1814.849919] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1814.850107] CR2: 0000000000000000 CR3: 0000000059f0d000 CR4: 00000000000406e0
    [ 1814.850313] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 1814.850518] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 1814.850723] Call Trace:
    [ 1814.850875]  hrtimer_try_to_cancel+0x1a/0x93
    [ 1814.851047]  hrtimer_cancel+0x15/0x20
    [ 1814.851211]  qdisc_watchdog_cancel+0x12/0x14
    [ 1814.851383]  netem_reset+0xe6/0xed [sch_netem]
    [ 1814.851561]  qdisc_destroy+0x8b/0xe5
    [ 1814.851723]  qdisc_create_dflt+0x86/0x94
    [ 1814.851890]  ? dev_activate+0x129/0x129
    [ 1814.852057]  attach_one_default_qdisc+0x36/0x63
    [ 1814.852232]  netdev_for_each_tx_queue+0x3d/0x48
    [ 1814.852406]  dev_activate+0x4b/0x129
    [ 1814.852569]  __dev_open+0xe7/0x104
    [ 1814.852730]  __dev_change_flags+0xc6/0x15c
    [ 1814.852899]  dev_change_flags+0x25/0x59
    [ 1814.853064]  do_setlink+0x30c/0xb3f
    [ 1814.853228]  ? check_chain_key+0xb0/0xfd
    [ 1814.853396]  ? check_chain_key+0xb0/0xfd
    [ 1814.853565]  rtnl_newlink+0x3a4/0x729
    [ 1814.853728]  ? rtnl_newlink+0x117/0x729
    [ 1814.853905]  ? ns_capable_common+0xd/0xb1
    [ 1814.854072]  ? ns_capable+0x13/0x15
    [ 1814.854234]  rtnetlink_rcv_msg+0x188/0x197
    [ 1814.854404]  ? rcu_read_unlock+0x3e/0x5f
    [ 1814.854572]  ? rtnl_newlink+0x729/0x729
    [ 1814.854737]  netlink_rcv_skb+0x6c/0xce
    [ 1814.854902]  rtnetlink_rcv+0x23/0x2a
    [ 1814.855064]  netlink_unicast+0x103/0x181
    [ 1814.855230]  netlink_sendmsg+0x326/0x337
    [ 1814.855398]  sock_sendmsg_nosec+0x14/0x3f
    [ 1814.855584]  sock_sendmsg+0x29/0x2e
    [ 1814.855747]  ___sys_sendmsg+0x209/0x28b
    [ 1814.855912]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 1814.856082]  ? _raw_spin_unlock+0x27/0x31
    [ 1814.856251]  ? __handle_mm_fault+0x651/0xdb1
    [ 1814.856421]  ? check_chain_key+0xb0/0xfd
    [ 1814.856592]  __sys_sendmsg+0x45/0x63
    [ 1814.856755]  ? __sys_sendmsg+0x45/0x63
    [ 1814.856923]  SyS_sendmsg+0x19/0x1b
    [ 1814.857083]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 1814.857256] RIP: 0033:0x7f733b2dd690
    [ 1814.857419] RSP: 002b:00007ffe1d3387d8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 1814.858238] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f733b2dd690
    [ 1814.858445] RDX: 0000000000000000 RSI: 00007ffe1d338820 RDI: 0000000000000003
    [ 1814.858651] RBP: ffff88005adcbf98 R08: 0000000000000001 R09: 0000000000000003
    [ 1814.858856] R10: 00007ffe1d3385a0 R11: 0000000000000246 R12: 0000000000000002
    [ 1814.859060] R13: 000000000066f1a0 R14: 00007ffe1d3408d0 R15: 0000000000000000
    [ 1814.859267]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 1814.859446] Code: 10 55 48 89 c7 48 89 e5 e8 45 a1 fb ff 31 c0 5d c3
    31 c0 c3 66 66 66 66 90 55 48 89 e5 41 56 41 55 41 54 53 49 89 fd 49 8b
    45 30 <4c> 8b 20 41 8b 5c 24 38 31 c9 31 d2 48 c7 c7 50 8e 1d 82 41 89
    [ 1814.860022] RIP: hrtimer_active+0x17/0x8a RSP: ffff88005adcb590
    [ 1814.860214] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit bab76fa57b0a989367a247dc415ced410367444a
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:01 2017 +0300

    sch_cbq: fix null pointer dereferences on init failure
    
    commit 3501d059921246ff617b43e86250a719c140bd97 upstream.
    
    CBQ can fail on ->init by wrong nl attributes or simply for missing any,
    f.e. if it's set as a default qdisc then TCA_OPTIONS (opt) will be NULL
    when it is activated. The first thing init does is parse opt but it will
    dereference a null pointer if used as a default qdisc, also since init
    failure at default qdisc invokes ->reset() which cancels all timers then
    we'll also dereference two more null pointers (timer->base) as they were
    never initialized.
    
    To reproduce:
    $ sysctl net.core.default_qdisc=cbq
    $ ip l set ethX up
    
    Crash log of the first null ptr deref:
    [44727.907454] BUG: unable to handle kernel NULL pointer dereference at (null)
    [44727.907600] IP: cbq_init+0x27/0x205
    [44727.907676] PGD 59ff4067
    [44727.907677] P4D 59ff4067
    [44727.907742] PUD 59c70067
    [44727.907807] PMD 0
    [44727.907873]
    [44727.907982] Oops: 0000 [#1] SMP
    [44727.908054] Modules linked in:
    [44727.908126] CPU: 1 PID: 21312 Comm: ip Not tainted 4.13.0-rc6+ #60
    [44727.908235] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [44727.908477] task: ffff88005ad42700 task.stack: ffff880037214000
    [44727.908672] RIP: 0010:cbq_init+0x27/0x205
    [44727.908838] RSP: 0018:ffff8800372175f0 EFLAGS: 00010286
    [44727.909018] RAX: ffffffff816c3852 RBX: ffff880058c53800 RCX: 0000000000000000
    [44727.909222] RDX: 0000000000000004 RSI: 0000000000000000 RDI: ffff8800372175f8
    [44727.909427] RBP: ffff880037217650 R08: ffffffff81b0f380 R09: 0000000000000000
    [44727.909631] R10: ffff880037217660 R11: 0000000000000020 R12: ffffffff822a44c0
    [44727.909835] R13: ffff880058b92000 R14: 00000000ffffffff R15: 0000000000000001
    [44727.910040] FS:  00007ff8bc583740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [44727.910339] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [44727.910525] CR2: 0000000000000000 CR3: 00000000371e5000 CR4: 00000000000406e0
    [44727.910731] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [44727.910936] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [44727.911141] Call Trace:
    [44727.911291]  ? lockdep_init_map+0xb6/0x1ba
    [44727.911461]  ? qdisc_alloc+0x14e/0x187
    [44727.911626]  qdisc_create_dflt+0x7a/0x94
    [44727.911794]  ? dev_activate+0x129/0x129
    [44727.911959]  attach_one_default_qdisc+0x36/0x63
    [44727.912132]  netdev_for_each_tx_queue+0x3d/0x48
    [44727.912305]  dev_activate+0x4b/0x129
    [44727.912468]  __dev_open+0xe7/0x104
    [44727.912631]  __dev_change_flags+0xc6/0x15c
    [44727.912799]  dev_change_flags+0x25/0x59
    [44727.912966]  do_setlink+0x30c/0xb3f
    [44727.913129]  ? check_chain_key+0xb0/0xfd
    [44727.913294]  ? check_chain_key+0xb0/0xfd
    [44727.913463]  rtnl_newlink+0x3a4/0x729
    [44727.913626]  ? rtnl_newlink+0x117/0x729
    [44727.913801]  ? ns_capable_common+0xd/0xb1
    [44727.913968]  ? ns_capable+0x13/0x15
    [44727.914131]  rtnetlink_rcv_msg+0x188/0x197
    [44727.914300]  ? rcu_read_unlock+0x3e/0x5f
    [44727.914465]  ? rtnl_newlink+0x729/0x729
    [44727.914630]  netlink_rcv_skb+0x6c/0xce
    [44727.914796]  rtnetlink_rcv+0x23/0x2a
    [44727.914956]  netlink_unicast+0x103/0x181
    [44727.915122]  netlink_sendmsg+0x326/0x337
    [44727.915291]  sock_sendmsg_nosec+0x14/0x3f
    [44727.915459]  sock_sendmsg+0x29/0x2e
    [44727.915619]  ___sys_sendmsg+0x209/0x28b
    [44727.915784]  ? do_raw_spin_unlock+0xcd/0xf8
    [44727.915954]  ? _raw_spin_unlock+0x27/0x31
    [44727.916121]  ? __handle_mm_fault+0x651/0xdb1
    [44727.916290]  ? check_chain_key+0xb0/0xfd
    [44727.916461]  __sys_sendmsg+0x45/0x63
    [44727.916626]  ? __sys_sendmsg+0x45/0x63
    [44727.916792]  SyS_sendmsg+0x19/0x1b
    [44727.916950]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [44727.917125] RIP: 0033:0x7ff8bbc96690
    [44727.917286] RSP: 002b:00007ffc360991e8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [44727.917579] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007ff8bbc96690
    [44727.917783] RDX: 0000000000000000 RSI: 00007ffc36099230 RDI: 0000000000000003
    [44727.917987] RBP: ffff880037217f98 R08: 0000000000000001 R09: 0000000000000003
    [44727.918190] R10: 00007ffc36098fb0 R11: 0000000000000246 R12: 0000000000000006
    [44727.918393] R13: 000000000066f1a0 R14: 00007ffc360a12e0 R15: 0000000000000000
    [44727.918597]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [44727.918774] Code: 41 5f 5d c3 66 66 66 66 90 55 48 8d 56 04 45 31 c9
    49 c7 c0 80 f3 b0 81 48 89 e5 41 55 41 54 53 48 89 fb 48 8d 7d a8 48 83
    ec 48 <0f> b7 0e be 07 00 00 00 83 e9 04 e8 e6 f7 d8 ff 85 c0 0f 88 bb
    [44727.919332] RIP: cbq_init+0x27/0x205 RSP: ffff8800372175f0
    [44727.919516] CR2: 0000000000000000
    
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2:
     - Keep using HRTIMER_MODE_ABS
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 1c2197aa2ed034eb01faf94aa0b4e3a972216244
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:58 2017 +0300

    sch_multiq: fix double free on init failure
    
    commit e89d469e3be3ed3d7124a803211a463ff83d0964 upstream.
    
    The below commit added a call to ->destroy() on init failure, but multiq
    still frees ->queues on error in init, but ->queues is also freed by
    ->destroy() thus we get double free and corrupted memory.
    
    Very easy to reproduce (eth0 not multiqueue):
    $ tc qdisc add dev eth0 root multiq
    RTNETLINK answers: Operation not supported
    $ ip l add dumdum type dummy
    (crash)
    
    Trace log:
    [ 3929.467747] general protection fault: 0000 [#1] SMP
    [ 3929.468083] Modules linked in:
    [ 3929.468302] CPU: 3 PID: 967 Comm: ip Not tainted 4.13.0-rc6+ #56
    [ 3929.468625] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 3929.469124] task: ffff88003716a700 task.stack: ffff88005872c000
    [ 3929.469449] RIP: 0010:__kmalloc_track_caller+0x117/0x1be
    [ 3929.469746] RSP: 0018:ffff88005872f6a0 EFLAGS: 00010246
    [ 3929.470042] RAX: 00000000000002de RBX: 0000000058a59000 RCX: 00000000000002df
    [ 3929.470406] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff821f7020
    [ 3929.470770] RBP: ffff88005872f6e8 R08: 000000000001f010 R09: 0000000000000000
    [ 3929.471133] R10: ffff88005872f730 R11: 0000000000008cdd R12: ff006d75646d7564
    [ 3929.471496] R13: 00000000014000c0 R14: ffff88005b403c00 R15: ffff88005b403c00
    [ 3929.471869] FS:  00007f0b70480740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 3929.472286] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3929.472677] CR2: 00007ffcee4f3000 CR3: 0000000059d45000 CR4: 00000000000406e0
    [ 3929.473209] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 3929.474109] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 3929.474873] Call Trace:
    [ 3929.475337]  ? kstrdup_const+0x23/0x25
    [ 3929.475863]  kstrdup+0x2e/0x4b
    [ 3929.476338]  kstrdup_const+0x23/0x25
    [ 3929.478084]  __kernfs_new_node+0x28/0xbc
    [ 3929.478478]  kernfs_new_node+0x35/0x55
    [ 3929.478929]  kernfs_create_link+0x23/0x76
    [ 3929.479478]  sysfs_do_create_link_sd.isra.2+0x85/0xd7
    [ 3929.480096]  sysfs_create_link+0x33/0x35
    [ 3929.480649]  device_add+0x200/0x589
    [ 3929.481184]  netdev_register_kobject+0x7c/0x12f
    [ 3929.481711]  register_netdevice+0x373/0x471
    [ 3929.482174]  rtnl_newlink+0x614/0x729
    [ 3929.482610]  ? rtnl_newlink+0x17f/0x729
    [ 3929.483080]  rtnetlink_rcv_msg+0x188/0x197
    [ 3929.483533]  ? rcu_read_unlock+0x3e/0x5f
    [ 3929.483984]  ? rtnl_newlink+0x729/0x729
    [ 3929.484420]  netlink_rcv_skb+0x6c/0xce
    [ 3929.484858]  rtnetlink_rcv+0x23/0x2a
    [ 3929.485291]  netlink_unicast+0x103/0x181
    [ 3929.485735]  netlink_sendmsg+0x326/0x337
    [ 3929.486181]  sock_sendmsg_nosec+0x14/0x3f
    [ 3929.486614]  sock_sendmsg+0x29/0x2e
    [ 3929.486973]  ___sys_sendmsg+0x209/0x28b
    [ 3929.487340]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 3929.487719]  ? _raw_spin_unlock+0x27/0x31
    [ 3929.488092]  ? __handle_mm_fault+0x651/0xdb1
    [ 3929.488471]  ? check_chain_key+0xb0/0xfd
    [ 3929.488847]  __sys_sendmsg+0x45/0x63
    [ 3929.489206]  ? __sys_sendmsg+0x45/0x63
    [ 3929.489576]  SyS_sendmsg+0x19/0x1b
    [ 3929.489901]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 3929.490172] RIP: 0033:0x7f0b6fb93690
    [ 3929.490423] RSP: 002b:00007ffcee4ed588 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 3929.490881] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f0b6fb93690
    [ 3929.491198] RDX: 0000000000000000 RSI: 00007ffcee4ed5d0 RDI: 0000000000000003
    [ 3929.491521] RBP: ffff88005872ff98 R08: 0000000000000001 R09: 0000000000000000
    [ 3929.491801] R10: 00007ffcee4ed350 R11: 0000000000000246 R12: 0000000000000002
    [ 3929.492075] R13: 000000000066f1a0 R14: 00007ffcee4f5680 R15: 0000000000000000
    [ 3929.492352]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 3929.492590] Code: 8b 45 c0 48 8b 45 b8 74 17 48 8b 4d c8 83 ca ff 44
    89 ee 4c 89 f7 e8 83 ca ff ff 49 89 c4 eb 49 49 63 56 20 48 8d 48 01 4d
    8b 06 <49> 8b 1c 14 48 89 c2 4c 89 e0 65 49 0f c7 08 0f 94 c0 83 f0 01
    [ 3929.493335] RIP: __kmalloc_track_caller+0x117/0x1be RSP: ffff88005872f6a0
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: f07d1501292b ("multiq: Further multiqueue cleanup")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: delete now-unused 'err' variable]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit dba1fd9993877e4a8ea0f2e8059d4140c7dcc0b6
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:57 2017 +0300

    sch_htb: fix crash on init failure
    
    commit 88c2ace69dbef696edba77712882af03879abc9c upstream.
    
    The commit below added a call to the ->destroy() callback for all qdiscs
    which failed in their ->init(), but some were not prepared for such
    change and can't handle partially initialized qdisc. HTB is one of them
    and if any error occurs before the qdisc watchdog timer and qdisc work are
    initialized then we can hit either a null ptr deref (timer->base) when
    canceling in ->destroy or lockdep error info about trying to register
    a non-static key and a stack dump. So to fix these two move the watchdog
    timer and workqueue init before anything that can err out.
    To reproduce userspace needs to send broken htb qdisc create request,
    tested with a modified tc (q_htb.c).
    
    Trace log:
    [ 2710.897602] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 2710.897977] IP: hrtimer_active+0x17/0x8a
    [ 2710.898174] PGD 58fab067
    [ 2710.898175] P4D 58fab067
    [ 2710.898353] PUD 586c0067
    [ 2710.898531] PMD 0
    [ 2710.898710]
    [ 2710.899045] Oops: 0000 [#1] SMP
    [ 2710.899232] Modules linked in:
    [ 2710.899419] CPU: 1 PID: 950 Comm: tc Not tainted 4.13.0-rc6+ #54
    [ 2710.899646] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 2710.900035] task: ffff880059ed2700 task.stack: ffff88005ad4c000
    [ 2710.900262] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 2710.900467] RSP: 0018:ffff88005ad4f960 EFLAGS: 00010246
    [ 2710.900684] RAX: 0000000000000000 RBX: ffff88003701e298 RCX: 0000000000000000
    [ 2710.900933] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff88003701e298
    [ 2710.901177] RBP: ffff88005ad4f980 R08: 0000000000000001 R09: 0000000000000001
    [ 2710.901419] R10: ffff88005ad4f800 R11: 0000000000000400 R12: 0000000000000000
    [ 2710.901663] R13: ffff88003701e298 R14: ffffffff822a4540 R15: ffff88005ad4fac0
    [ 2710.901907] FS:  00007f2f5e90f740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [ 2710.902277] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2710.902500] CR2: 0000000000000000 CR3: 0000000058ca3000 CR4: 00000000000406e0
    [ 2710.902744] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 2710.902977] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 2710.903180] Call Trace:
    [ 2710.903332]  hrtimer_try_to_cancel+0x1a/0x93
    [ 2710.903504]  hrtimer_cancel+0x15/0x20
    [ 2710.903667]  qdisc_watchdog_cancel+0x12/0x14
    [ 2710.903866]  htb_destroy+0x2e/0xf7
    [ 2710.904097]  qdisc_create+0x377/0x3fd
    [ 2710.904330]  tc_modify_qdisc+0x4d2/0x4fd
    [ 2710.904511]  rtnetlink_rcv_msg+0x188/0x197
    [ 2710.904682]  ? rcu_read_unlock+0x3e/0x5f
    [ 2710.904849]  ? rtnl_newlink+0x729/0x729
    [ 2710.905017]  netlink_rcv_skb+0x6c/0xce
    [ 2710.905183]  rtnetlink_rcv+0x23/0x2a
    [ 2710.905345]  netlink_unicast+0x103/0x181
    [ 2710.905511]  netlink_sendmsg+0x326/0x337
    [ 2710.905679]  sock_sendmsg_nosec+0x14/0x3f
    [ 2710.905847]  sock_sendmsg+0x29/0x2e
    [ 2710.906010]  ___sys_sendmsg+0x209/0x28b
    [ 2710.906176]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 2710.906346]  ? _raw_spin_unlock+0x27/0x31
    [ 2710.906514]  ? __handle_mm_fault+0x651/0xdb1
    [ 2710.906685]  ? check_chain_key+0xb0/0xfd
    [ 2710.906855]  __sys_sendmsg+0x45/0x63
    [ 2710.907018]  ? __sys_sendmsg+0x45/0x63
    [ 2710.907185]  SyS_sendmsg+0x19/0x1b
    [ 2710.907344]  entry_SYSCALL_64_fastpath+0x23/0xc2
    
    Note that probably this bug goes further back because the default qdisc
    handling always calls ->destroy on init failure too.
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 87d54a1143a7c349e51a2d1fdca7723521edb98e
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a upstream.
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 76fb491fac59fd94e17b5615250701e6f57af2de
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:05 2017 +0300

    sch_tbf: fix two null pointer dereferences on init failure
    
    commit c2d6511e6a4f1f3673d711569c00c3849549e9b0 upstream.
    
    sch_tbf calls qdisc_watchdog_cancel() in both its ->reset and ->destroy
    callbacks but it may fail before the timer is initialized due to missing
    options (either not supplied by user-space or set as a default qdisc),
    also q->qdisc is used by ->reset and ->destroy so we need it initialized.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=tbf
    $ ip l set ethX up
    
    Crash log:
    [  959.160172] BUG: unable to handle kernel NULL pointer dereference at 0000000000000018
    [  959.160323] IP: qdisc_reset+0xa/0x5c
    [  959.160400] PGD 59cdb067
    [  959.160401] P4D 59cdb067
    [  959.160466] PUD 59ccb067
    [  959.160532] PMD 0
    [  959.160597]
    [  959.160706] Oops: 0000 [#1] SMP
    [  959.160778] Modules linked in: sch_tbf sch_sfb sch_prio sch_netem
    [  959.160891] CPU: 2 PID: 1562 Comm: ip Not tainted 4.13.0-rc6+ #62
    [  959.160998] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  959.161157] task: ffff880059c9a700 task.stack: ffff8800376d0000
    [  959.161263] RIP: 0010:qdisc_reset+0xa/0x5c
    [  959.161347] RSP: 0018:ffff8800376d3610 EFLAGS: 00010286
    [  959.161531] RAX: ffffffffa001b1dd RBX: ffff8800373a2800 RCX: 0000000000000000
    [  959.161733] RDX: ffffffff8215f160 RSI: ffffffff8215f160 RDI: 0000000000000000
    [  959.161939] RBP: ffff8800376d3618 R08: 00000000014080c0 R09: 00000000ffffffff
    [  959.162141] R10: ffff8800376d3578 R11: 0000000000000020 R12: ffffffffa001d2c0
    [  959.162343] R13: ffff880037538000 R14: 00000000ffffffff R15: 0000000000000001
    [  959.162546] FS:  00007fcc5126b740(0000) GS:ffff88005d900000(0000) knlGS:0000000000000000
    [  959.162844] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  959.163030] CR2: 0000000000000018 CR3: 000000005abc4000 CR4: 00000000000406e0
    [  959.163233] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  959.163436] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  959.163638] Call Trace:
    [  959.163788]  tbf_reset+0x19/0x64 [sch_tbf]
    [  959.163957]  qdisc_destroy+0x8b/0xe5
    [  959.164119]  qdisc_create_dflt+0x86/0x94
    [  959.164284]  ? dev_activate+0x129/0x129
    [  959.164449]  attach_one_default_qdisc+0x36/0x63
    [  959.164623]  netdev_for_each_tx_queue+0x3d/0x48
    [  959.164795]  dev_activate+0x4b/0x129
    [  959.164957]  __dev_open+0xe7/0x104
    [  959.165118]  __dev_change_flags+0xc6/0x15c
    [  959.165287]  dev_change_flags+0x25/0x59
    [  959.165451]  do_setlink+0x30c/0xb3f
    [  959.165613]  ? check_chain_key+0xb0/0xfd
    [  959.165782]  rtnl_newlink+0x3a4/0x729
    [  959.165947]  ? rtnl_newlink+0x117/0x729
    [  959.166121]  ? ns_capable_common+0xd/0xb1
    [  959.166288]  ? ns_capable+0x13/0x15
    [  959.166450]  rtnetlink_rcv_msg+0x188/0x197
    [  959.166617]  ? rcu_read_unlock+0x3e/0x5f
    [  959.166783]  ? rtnl_newlink+0x729/0x729
    [  959.166948]  netlink_rcv_skb+0x6c/0xce
    [  959.167113]  rtnetlink_rcv+0x23/0x2a
    [  959.167273]  netlink_unicast+0x103/0x181
    [  959.167439]  netlink_sendmsg+0x326/0x337
    [  959.167607]  sock_sendmsg_nosec+0x14/0x3f
    [  959.167772]  sock_sendmsg+0x29/0x2e
    [  959.167932]  ___sys_sendmsg+0x209/0x28b
    [  959.168098]  ? do_raw_spin_unlock+0xcd/0xf8
    [  959.168267]  ? _raw_spin_unlock+0x27/0x31
    [  959.168432]  ? __handle_mm_fault+0x651/0xdb1
    [  959.168602]  ? check_chain_key+0xb0/0xfd
    [  959.168773]  __sys_sendmsg+0x45/0x63
    [  959.168934]  ? __sys_sendmsg+0x45/0x63
    [  959.169100]  SyS_sendmsg+0x19/0x1b
    [  959.169260]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  959.169432] RIP: 0033:0x7fcc5097e690
    [  959.169592] RSP: 002b:00007ffd0d5c7b48 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  959.169887] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007fcc5097e690
    [  959.170089] RDX: 0000000000000000 RSI: 00007ffd0d5c7b90 RDI: 0000000000000003
    [  959.170292] RBP: ffff8800376d3f98 R08: 0000000000000001 R09: 0000000000000003
    [  959.170494] R10: 00007ffd0d5c7910 R11: 0000000000000246 R12: 0000000000000006
    [  959.170697] R13: 000000000066f1a0 R14: 00007ffd0d5cfc40 R15: 0000000000000000
    [  959.170900]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  959.171076] Code: 00 41 c7 84 24 14 01 00 00 00 00 00 00 41 c7 84 24
    98 00 00 00 00 00 00 00 41 5c 41 5d 41 5e 5d c3 66 66 66 66 90 55 48 89
    e5 53 <48> 8b 47 18 48 89 fb 48 8b 40 48 48 85 c0 74 02 ff d0 48 8b bb
    [  959.171637] RIP: qdisc_reset+0xa/0x5c RSP: ffff8800376d3610
    [  959.171821] CR2: 0000000000000018
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.16: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 0ff978e604aaea9cadd885bd12df2e4538198f97
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:03 2017 +0300

    sch_netem: avoid null pointer deref on init failure
    
    commit 634576a1844dba15bc5e6fc61d72f37e13a21615 upstream.
    
    netem can fail in ->init due to missing options (either not supplied by
    user-space or used as a default qdisc) causing a timer->base null
    pointer deref in its ->destroy() and ->reset() callbacks.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=netem
    $ ip l set ethX up
    
    Crash log:
    [ 1814.846943] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 1814.847181] IP: hrtimer_active+0x17/0x8a
    [ 1814.847270] PGD 59c34067
    [ 1814.847271] P4D 59c34067
    [ 1814.847337] PUD 37374067
    [ 1814.847403] PMD 0
    [ 1814.847468]
    [ 1814.847582] Oops: 0000 [#1] SMP
    [ 1814.847655] Modules linked in: sch_netem(O) sch_fq_codel(O)
    [ 1814.847761] CPU: 3 PID: 1573 Comm: ip Tainted: G           O 4.13.0-rc6+ #62
    [ 1814.847884] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 1814.848043] task: ffff88003723a700 task.stack: ffff88005adc8000
    [ 1814.848235] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 1814.848407] RSP: 0018:ffff88005adcb590 EFLAGS: 00010246
    [ 1814.848590] RAX: 0000000000000000 RBX: ffff880058e359d8 RCX: 0000000000000000
    [ 1814.848793] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff880058e359d8
    [ 1814.848998] RBP: ffff88005adcb5b0 R08: 00000000014080c0 R09: 00000000ffffffff
    [ 1814.849204] R10: ffff88005adcb660 R11: 0000000000000020 R12: 0000000000000000
    [ 1814.849410] R13: ffff880058e359d8 R14: 00000000ffffffff R15: 0000000000000001
    [ 1814.849616] FS:  00007f733bbca740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 1814.849919] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1814.850107] CR2: 0000000000000000 CR3: 0000000059f0d000 CR4: 00000000000406e0
    [ 1814.850313] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 1814.850518] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 1814.850723] Call Trace:
    [ 1814.850875]  hrtimer_try_to_cancel+0x1a/0x93
    [ 1814.851047]  hrtimer_cancel+0x15/0x20
    [ 1814.851211]  qdisc_watchdog_cancel+0x12/0x14
    [ 1814.851383]  netem_reset+0xe6/0xed [sch_netem]
    [ 1814.851561]  qdisc_destroy+0x8b/0xe5
    [ 1814.851723]  qdisc_create_dflt+0x86/0x94
    [ 1814.851890]  ? dev_activate+0x129/0x129
    [ 1814.852057]  attach_one_default_qdisc+0x36/0x63
    [ 1814.852232]  netdev_for_each_tx_queue+0x3d/0x48
    [ 1814.852406]  dev_activate+0x4b/0x129
    [ 1814.852569]  __dev_open+0xe7/0x104
    [ 1814.852730]  __dev_change_flags+0xc6/0x15c
    [ 1814.852899]  dev_change_flags+0x25/0x59
    [ 1814.853064]  do_setlink+0x30c/0xb3f
    [ 1814.853228]  ? check_chain_key+0xb0/0xfd
    [ 1814.853396]  ? check_chain_key+0xb0/0xfd
    [ 1814.853565]  rtnl_newlink+0x3a4/0x729
    [ 1814.853728]  ? rtnl_newlink+0x117/0x729
    [ 1814.853905]  ? ns_capable_common+0xd/0xb1
    [ 1814.854072]  ? ns_capable+0x13/0x15
    [ 1814.854234]  rtnetlink_rcv_msg+0x188/0x197
    [ 1814.854404]  ? rcu_read_unlock+0x3e/0x5f
    [ 1814.854572]  ? rtnl_newlink+0x729/0x729
    [ 1814.854737]  netlink_rcv_skb+0x6c/0xce
    [ 1814.854902]  rtnetlink_rcv+0x23/0x2a
    [ 1814.855064]  netlink_unicast+0x103/0x181
    [ 1814.855230]  netlink_sendmsg+0x326/0x337
    [ 1814.855398]  sock_sendmsg_nosec+0x14/0x3f
    [ 1814.855584]  sock_sendmsg+0x29/0x2e
    [ 1814.855747]  ___sys_sendmsg+0x209/0x28b
    [ 1814.855912]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 1814.856082]  ? _raw_spin_unlock+0x27/0x31
    [ 1814.856251]  ? __handle_mm_fault+0x651/0xdb1
    [ 1814.856421]  ? check_chain_key+0xb0/0xfd
    [ 1814.856592]  __sys_sendmsg+0x45/0x63
    [ 1814.856755]  ? __sys_sendmsg+0x45/0x63
    [ 1814.856923]  SyS_sendmsg+0x19/0x1b
    [ 1814.857083]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 1814.857256] RIP: 0033:0x7f733b2dd690
    [ 1814.857419] RSP: 002b:00007ffe1d3387d8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 1814.858238] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f733b2dd690
    [ 1814.858445] RDX: 0000000000000000 RSI: 00007ffe1d338820 RDI: 0000000000000003
    [ 1814.858651] RBP: ffff88005adcbf98 R08: 0000000000000001 R09: 0000000000000003
    [ 1814.858856] R10: 00007ffe1d3385a0 R11: 0000000000000246 R12: 0000000000000002
    [ 1814.859060] R13: 000000000066f1a0 R14: 00007ffe1d3408d0 R15: 0000000000000000
    [ 1814.859267]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 1814.859446] Code: 10 55 48 89 c7 48 89 e5 e8 45 a1 fb ff 31 c0 5d c3
    31 c0 c3 66 66 66 66 90 55 48 89 e5 41 56 41 55 41 54 53 49 89 fd 49 8b
    45 30 <4c> 8b 20 41 8b 5c 24 38 31 c9 31 d2 48 c7 c7 50 8e 1d 82 41 89
    [ 1814.860022] RIP: hrtimer_active+0x17/0x8a RSP: ffff88005adcb590
    [ 1814.860214] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit addb3a32b0ed9de074b9c84b094b060141fcfa94
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:01 2017 +0300

    sch_cbq: fix null pointer dereferences on init failure
    
    commit 3501d059921246ff617b43e86250a719c140bd97 upstream.
    
    CBQ can fail on ->init by wrong nl attributes or simply for missing any,
    f.e. if it's set as a default qdisc then TCA_OPTIONS (opt) will be NULL
    when it is activated. The first thing init does is parse opt but it will
    dereference a null pointer if used as a default qdisc, also since init
    failure at default qdisc invokes ->reset() which cancels all timers then
    we'll also dereference two more null pointers (timer->base) as they were
    never initialized.
    
    To reproduce:
    $ sysctl net.core.default_qdisc=cbq
    $ ip l set ethX up
    
    Crash log of the first null ptr deref:
    [44727.907454] BUG: unable to handle kernel NULL pointer dereference at (null)
    [44727.907600] IP: cbq_init+0x27/0x205
    [44727.907676] PGD 59ff4067
    [44727.907677] P4D 59ff4067
    [44727.907742] PUD 59c70067
    [44727.907807] PMD 0
    [44727.907873]
    [44727.907982] Oops: 0000 [#1] SMP
    [44727.908054] Modules linked in:
    [44727.908126] CPU: 1 PID: 21312 Comm: ip Not tainted 4.13.0-rc6+ #60
    [44727.908235] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [44727.908477] task: ffff88005ad42700 task.stack: ffff880037214000
    [44727.908672] RIP: 0010:cbq_init+0x27/0x205
    [44727.908838] RSP: 0018:ffff8800372175f0 EFLAGS: 00010286
    [44727.909018] RAX: ffffffff816c3852 RBX: ffff880058c53800 RCX: 0000000000000000
    [44727.909222] RDX: 0000000000000004 RSI: 0000000000000000 RDI: ffff8800372175f8
    [44727.909427] RBP: ffff880037217650 R08: ffffffff81b0f380 R09: 0000000000000000
    [44727.909631] R10: ffff880037217660 R11: 0000000000000020 R12: ffffffff822a44c0
    [44727.909835] R13: ffff880058b92000 R14: 00000000ffffffff R15: 0000000000000001
    [44727.910040] FS:  00007ff8bc583740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [44727.910339] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [44727.910525] CR2: 0000000000000000 CR3: 00000000371e5000 CR4: 00000000000406e0
    [44727.910731] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [44727.910936] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [44727.911141] Call Trace:
    [44727.911291]  ? lockdep_init_map+0xb6/0x1ba
    [44727.911461]  ? qdisc_alloc+0x14e/0x187
    [44727.911626]  qdisc_create_dflt+0x7a/0x94
    [44727.911794]  ? dev_activate+0x129/0x129
    [44727.911959]  attach_one_default_qdisc+0x36/0x63
    [44727.912132]  netdev_for_each_tx_queue+0x3d/0x48
    [44727.912305]  dev_activate+0x4b/0x129
    [44727.912468]  __dev_open+0xe7/0x104
    [44727.912631]  __dev_change_flags+0xc6/0x15c
    [44727.912799]  dev_change_flags+0x25/0x59
    [44727.912966]  do_setlink+0x30c/0xb3f
    [44727.913129]  ? check_chain_key+0xb0/0xfd
    [44727.913294]  ? check_chain_key+0xb0/0xfd
    [44727.913463]  rtnl_newlink+0x3a4/0x729
    [44727.913626]  ? rtnl_newlink+0x117/0x729
    [44727.913801]  ? ns_capable_common+0xd/0xb1
    [44727.913968]  ? ns_capable+0x13/0x15
    [44727.914131]  rtnetlink_rcv_msg+0x188/0x197
    [44727.914300]  ? rcu_read_unlock+0x3e/0x5f
    [44727.914465]  ? rtnl_newlink+0x729/0x729
    [44727.914630]  netlink_rcv_skb+0x6c/0xce
    [44727.914796]  rtnetlink_rcv+0x23/0x2a
    [44727.914956]  netlink_unicast+0x103/0x181
    [44727.915122]  netlink_sendmsg+0x326/0x337
    [44727.915291]  sock_sendmsg_nosec+0x14/0x3f
    [44727.915459]  sock_sendmsg+0x29/0x2e
    [44727.915619]  ___sys_sendmsg+0x209/0x28b
    [44727.915784]  ? do_raw_spin_unlock+0xcd/0xf8
    [44727.915954]  ? _raw_spin_unlock+0x27/0x31
    [44727.916121]  ? __handle_mm_fault+0x651/0xdb1
    [44727.916290]  ? check_chain_key+0xb0/0xfd
    [44727.916461]  __sys_sendmsg+0x45/0x63
    [44727.916626]  ? __sys_sendmsg+0x45/0x63
    [44727.916792]  SyS_sendmsg+0x19/0x1b
    [44727.916950]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [44727.917125] RIP: 0033:0x7ff8bbc96690
    [44727.917286] RSP: 002b:00007ffc360991e8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [44727.917579] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007ff8bbc96690
    [44727.917783] RDX: 0000000000000000 RSI: 00007ffc36099230 RDI: 0000000000000003
    [44727.917987] RBP: ffff880037217f98 R08: 0000000000000001 R09: 0000000000000003
    [44727.918190] R10: 00007ffc36098fb0 R11: 0000000000000246 R12: 0000000000000006
    [44727.918393] R13: 000000000066f1a0 R14: 00007ffc360a12e0 R15: 0000000000000000
    [44727.918597]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [44727.918774] Code: 41 5f 5d c3 66 66 66 66 90 55 48 8d 56 04 45 31 c9
    49 c7 c0 80 f3 b0 81 48 89 e5 41 55 41 54 53 48 89 fb 48 8d 7d a8 48 83
    ec 48 <0f> b7 0e be 07 00 00 00 83 e9 04 e8 e6 f7 d8 ff 85 c0 0f 88 bb
    [44727.919332] RIP: cbq_init+0x27/0x205 RSP: ffff8800372175f0
    [44727.919516] CR2: 0000000000000000
    
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.16:
     - Keep using HRTIMER_MODE_ABS
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit a65830f1ab55943f1d60831fa7f3a82dacb57fba
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:59 2017 +0300

    sch_hhf: fix null pointer dereference on init failure
    
    commit 32db864d33c21fd70a217ba53cb7224889354ffb upstream.
    
    If sch_hhf fails in its ->init() function (either due to wrong
    user-space arguments as below or memory alloc failure of hh_flows) it
    will do a null pointer deref of q->hh_flows in its ->destroy() function.
    
    To reproduce the crash:
    $ tc qdisc add dev eth0 root hhf quantum 2000000 non_hh_weight 10000000
    
    Crash log:
    [  690.654882] BUG: unable to handle kernel NULL pointer dereference at (null)
    [  690.655565] IP: hhf_destroy+0x48/0xbc
    [  690.655944] PGD 37345067
    [  690.655948] P4D 37345067
    [  690.656252] PUD 58402067
    [  690.656554] PMD 0
    [  690.656857]
    [  690.657362] Oops: 0000 [#1] SMP
    [  690.657696] Modules linked in:
    [  690.658032] CPU: 3 PID: 920 Comm: tc Not tainted 4.13.0-rc6+ #57
    [  690.658525] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  690.659255] task: ffff880058578000 task.stack: ffff88005acbc000
    [  690.659747] RIP: 0010:hhf_destroy+0x48/0xbc
    [  690.660146] RSP: 0018:ffff88005acbf9e0 EFLAGS: 00010246
    [  690.660601] RAX: 0000000000000000 RBX: 0000000000000020 RCX: 0000000000000000
    [  690.661155] RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffffffff821f63f0
    [  690.661710] RBP: ffff88005acbfa08 R08: ffffffff81b10a90 R09: 0000000000000000
    [  690.662267] R10: 00000000f42b7019 R11: ffff880058578000 R12: 00000000ffffffea
    [  690.662820] R13: ffff8800372f6400 R14: 0000000000000000 R15: 0000000000000000
    [  690.663769] FS:  00007f8ae5e8b740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [  690.667069] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  690.667965] CR2: 0000000000000000 CR3: 0000000058523000 CR4: 00000000000406e0
    [  690.668918] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  690.669945] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  690.671003] Call Trace:
    [  690.671743]  qdisc_create+0x377/0x3fd
    [  690.672534]  tc_modify_qdisc+0x4d2/0x4fd
    [  690.673324]  rtnetlink_rcv_msg+0x188/0x197
    [  690.674204]  ? rcu_read_unlock+0x3e/0x5f
    [  690.675091]  ? rtnl_newlink+0x729/0x729
    [  690.675877]  netlink_rcv_skb+0x6c/0xce
    [  690.676648]  rtnetlink_rcv+0x23/0x2a
    [  690.677405]  netlink_unicast+0x103/0x181
    [  690.678179]  netlink_sendmsg+0x326/0x337
    [  690.678958]  sock_sendmsg_nosec+0x14/0x3f
    [  690.679743]  sock_sendmsg+0x29/0x2e
    [  690.680506]  ___sys_sendmsg+0x209/0x28b
    [  690.681283]  ? __handle_mm_fault+0xc7d/0xdb1
    [  690.681915]  ? check_chain_key+0xb0/0xfd
    [  690.682449]  __sys_sendmsg+0x45/0x63
    [  690.682954]  ? __sys_sendmsg+0x45/0x63
    [  690.683471]  SyS_sendmsg+0x19/0x1b
    [  690.683974]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  690.684516] RIP: 0033:0x7f8ae529d690
    [  690.685016] RSP: 002b:00007fff26d2d6b8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  690.685931] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f8ae529d690
    [  690.686573] RDX: 0000000000000000 RSI: 00007fff26d2d700 RDI: 0000000000000003
    [  690.687047] RBP: ffff88005acbff98 R08: 0000000000000001 R09: 0000000000000000
    [  690.687519] R10: 00007fff26d2d480 R11: 0000000000000246 R12: 0000000000000002
    [  690.687996] R13: 0000000001258070 R14: 0000000000000001 R15: 0000000000000000
    [  690.688475]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  690.688887] Code: 00 00 e8 2a 02 ae ff 49 8b bc 1d 60 02 00 00 48 83
    c3 08 e8 19 02 ae ff 48 83 fb 20 75 dc 45 31 f6 4d 89 f7 4d 03 bd 20 02
    00 00 <49> 8b 07 49 39 c7 75 24 49 83 c6 10 49 81 fe 00 40 00 00 75 e1
    [  690.690200] RIP: hhf_destroy+0x48/0xbc RSP: ffff88005acbf9e0
    [  690.690636] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 10239edf86f1 ("net-qdisc-hhf: Heavy-Hitter Filter (HHF) qdisc")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 859cc1d7c2230cb3eca91920560b136a6c5f7286
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:58 2017 +0300

    sch_multiq: fix double free on init failure
    
    commit e89d469e3be3ed3d7124a803211a463ff83d0964 upstream.
    
    The below commit added a call to ->destroy() on init failure, but multiq
    still frees ->queues on error in init, but ->queues is also freed by
    ->destroy() thus we get double free and corrupted memory.
    
    Very easy to reproduce (eth0 not multiqueue):
    $ tc qdisc add dev eth0 root multiq
    RTNETLINK answers: Operation not supported
    $ ip l add dumdum type dummy
    (crash)
    
    Trace log:
    [ 3929.467747] general protection fault: 0000 [#1] SMP
    [ 3929.468083] Modules linked in:
    [ 3929.468302] CPU: 3 PID: 967 Comm: ip Not tainted 4.13.0-rc6+ #56
    [ 3929.468625] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 3929.469124] task: ffff88003716a700 task.stack: ffff88005872c000
    [ 3929.469449] RIP: 0010:__kmalloc_track_caller+0x117/0x1be
    [ 3929.469746] RSP: 0018:ffff88005872f6a0 EFLAGS: 00010246
    [ 3929.470042] RAX: 00000000000002de RBX: 0000000058a59000 RCX: 00000000000002df
    [ 3929.470406] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff821f7020
    [ 3929.470770] RBP: ffff88005872f6e8 R08: 000000000001f010 R09: 0000000000000000
    [ 3929.471133] R10: ffff88005872f730 R11: 0000000000008cdd R12: ff006d75646d7564
    [ 3929.471496] R13: 00000000014000c0 R14: ffff88005b403c00 R15: ffff88005b403c00
    [ 3929.471869] FS:  00007f0b70480740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 3929.472286] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3929.472677] CR2: 00007ffcee4f3000 CR3: 0000000059d45000 CR4: 00000000000406e0
    [ 3929.473209] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 3929.474109] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 3929.474873] Call Trace:
    [ 3929.475337]  ? kstrdup_const+0x23/0x25
    [ 3929.475863]  kstrdup+0x2e/0x4b
    [ 3929.476338]  kstrdup_const+0x23/0x25
    [ 3929.478084]  __kernfs_new_node+0x28/0xbc
    [ 3929.478478]  kernfs_new_node+0x35/0x55
    [ 3929.478929]  kernfs_create_link+0x23/0x76
    [ 3929.479478]  sysfs_do_create_link_sd.isra.2+0x85/0xd7
    [ 3929.480096]  sysfs_create_link+0x33/0x35
    [ 3929.480649]  device_add+0x200/0x589
    [ 3929.481184]  netdev_register_kobject+0x7c/0x12f
    [ 3929.481711]  register_netdevice+0x373/0x471
    [ 3929.482174]  rtnl_newlink+0x614/0x729
    [ 3929.482610]  ? rtnl_newlink+0x17f/0x729
    [ 3929.483080]  rtnetlink_rcv_msg+0x188/0x197
    [ 3929.483533]  ? rcu_read_unlock+0x3e/0x5f
    [ 3929.483984]  ? rtnl_newlink+0x729/0x729
    [ 3929.484420]  netlink_rcv_skb+0x6c/0xce
    [ 3929.484858]  rtnetlink_rcv+0x23/0x2a
    [ 3929.485291]  netlink_unicast+0x103/0x181
    [ 3929.485735]  netlink_sendmsg+0x326/0x337
    [ 3929.486181]  sock_sendmsg_nosec+0x14/0x3f
    [ 3929.486614]  sock_sendmsg+0x29/0x2e
    [ 3929.486973]  ___sys_sendmsg+0x209/0x28b
    [ 3929.487340]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 3929.487719]  ? _raw_spin_unlock+0x27/0x31
    [ 3929.488092]  ? __handle_mm_fault+0x651/0xdb1
    [ 3929.488471]  ? check_chain_key+0xb0/0xfd
    [ 3929.488847]  __sys_sendmsg+0x45/0x63
    [ 3929.489206]  ? __sys_sendmsg+0x45/0x63
    [ 3929.489576]  SyS_sendmsg+0x19/0x1b
    [ 3929.489901]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 3929.490172] RIP: 0033:0x7f0b6fb93690
    [ 3929.490423] RSP: 002b:00007ffcee4ed588 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 3929.490881] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f0b6fb93690
    [ 3929.491198] RDX: 0000000000000000 RSI: 00007ffcee4ed5d0 RDI: 0000000000000003
    [ 3929.491521] RBP: ffff88005872ff98 R08: 0000000000000001 R09: 0000000000000000
    [ 3929.491801] R10: 00007ffcee4ed350 R11: 0000000000000246 R12: 0000000000000002
    [ 3929.492075] R13: 000000000066f1a0 R14: 00007ffcee4f5680 R15: 0000000000000000
    [ 3929.492352]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 3929.492590] Code: 8b 45 c0 48 8b 45 b8 74 17 48 8b 4d c8 83 ca ff 44
    89 ee 4c 89 f7 e8 83 ca ff ff 49 89 c4 eb 49 49 63 56 20 48 8d 48 01 4d
    8b 06 <49> 8b 1c 14 48 89 c2 4c 89 e0 65 49 0f c7 08 0f 94 c0 83 f0 01
    [ 3929.493335] RIP: __kmalloc_track_caller+0x117/0x1be RSP: ffff88005872f6a0
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: f07d1501292b ("multiq: Further multiqueue cleanup")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.16: delete now-unused 'err' variable]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 7de86dc840d6f03da5c272c6df3bdf18cd2b459e
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:57 2017 +0300

    sch_htb: fix crash on init failure
    
    commit 88c2ace69dbef696edba77712882af03879abc9c upstream.
    
    The commit below added a call to the ->destroy() callback for all qdiscs
    which failed in their ->init(), but some were not prepared for such
    change and can't handle partially initialized qdisc. HTB is one of them
    and if any error occurs before the qdisc watchdog timer and qdisc work are
    initialized then we can hit either a null ptr deref (timer->base) when
    canceling in ->destroy or lockdep error info about trying to register
    a non-static key and a stack dump. So to fix these two move the watchdog
    timer and workqueue init before anything that can err out.
    To reproduce userspace needs to send broken htb qdisc create request,
    tested with a modified tc (q_htb.c).
    
    Trace log:
    [ 2710.897602] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 2710.897977] IP: hrtimer_active+0x17/0x8a
    [ 2710.898174] PGD 58fab067
    [ 2710.898175] P4D 58fab067
    [ 2710.898353] PUD 586c0067
    [ 2710.898531] PMD 0
    [ 2710.898710]
    [ 2710.899045] Oops: 0000 [#1] SMP
    [ 2710.899232] Modules linked in:
    [ 2710.899419] CPU: 1 PID: 950 Comm: tc Not tainted 4.13.0-rc6+ #54
    [ 2710.899646] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 2710.900035] task: ffff880059ed2700 task.stack: ffff88005ad4c000
    [ 2710.900262] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 2710.900467] RSP: 0018:ffff88005ad4f960 EFLAGS: 00010246
    [ 2710.900684] RAX: 0000000000000000 RBX: ffff88003701e298 RCX: 0000000000000000
    [ 2710.900933] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff88003701e298
    [ 2710.901177] RBP: ffff88005ad4f980 R08: 0000000000000001 R09: 0000000000000001
    [ 2710.901419] R10: ffff88005ad4f800 R11: 0000000000000400 R12: 0000000000000000
    [ 2710.901663] R13: ffff88003701e298 R14: ffffffff822a4540 R15: ffff88005ad4fac0
    [ 2710.901907] FS:  00007f2f5e90f740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [ 2710.902277] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2710.902500] CR2: 0000000000000000 CR3: 0000000058ca3000 CR4: 00000000000406e0
    [ 2710.902744] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 2710.902977] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 2710.903180] Call Trace:
    [ 2710.903332]  hrtimer_try_to_cancel+0x1a/0x93
    [ 2710.903504]  hrtimer_cancel+0x15/0x20
    [ 2710.903667]  qdisc_watchdog_cancel+0x12/0x14
    [ 2710.903866]  htb_destroy+0x2e/0xf7
    [ 2710.904097]  qdisc_create+0x377/0x3fd
    [ 2710.904330]  tc_modify_qdisc+0x4d2/0x4fd
    [ 2710.904511]  rtnetlink_rcv_msg+0x188/0x197
    [ 2710.904682]  ? rcu_read_unlock+0x3e/0x5f
    [ 2710.904849]  ? rtnl_newlink+0x729/0x729
    [ 2710.905017]  netlink_rcv_skb+0x6c/0xce
    [ 2710.905183]  rtnetlink_rcv+0x23/0x2a
    [ 2710.905345]  netlink_unicast+0x103/0x181
    [ 2710.905511]  netlink_sendmsg+0x326/0x337
    [ 2710.905679]  sock_sendmsg_nosec+0x14/0x3f
    [ 2710.905847]  sock_sendmsg+0x29/0x2e
    [ 2710.906010]  ___sys_sendmsg+0x209/0x28b
    [ 2710.906176]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 2710.906346]  ? _raw_spin_unlock+0x27/0x31
    [ 2710.906514]  ? __handle_mm_fault+0x651/0xdb1
    [ 2710.906685]  ? check_chain_key+0xb0/0xfd
    [ 2710.906855]  __sys_sendmsg+0x45/0x63
    [ 2710.907018]  ? __sys_sendmsg+0x45/0x63
    [ 2710.907185]  SyS_sendmsg+0x19/0x1b
    [ 2710.907344]  entry_SYSCALL_64_fastpath+0x23/0xc2
    
    Note that probably this bug goes further back because the default qdisc
    handling always calls ->destroy on init failure too.
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.16: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 0a7b80709e11465d274d598195e5931fef78aa9e
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a upstream.
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.16: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 4071479bafd9b91d52d17151856036b8a57f58e7
Author: Liping Zhang <zlpnobody@gmail.com>
Date:   Sat Mar 25 08:53:12 2017 +0800

    netfilter: invoke synchronize_rcu after set the _hook_ to NULL
    
    [ Upstream commit 3b7dabf029478bb80507a6c4500ca94132a2bc0b ]
    
    Otherwise, another CPU may access the invalid pointer. For example:
        CPU0                CPU1
         -              rcu_read_lock();
         -              pfunc = _hook_;
      _hook_ = NULL;          -
      mod unload              -
         -                 pfunc(); // invalid, panic
         -             rcu_read_unlock();
    
    So we must call synchronize_rcu() to wait the rcu reader to finish.
    
    Also note, in nf_nat_snmp_basic_fini, synchronize_rcu() will be invoked
    by later nf_conntrack_helper_unregister, but I'm inclined to add a
    explicit synchronize_rcu after set the nf_nat_snmp_hook to NULL. Depend
    on such obscure assumptions is not a good idea.
    
    Last, in nfnetlink_cttimeout, we use kfree_rcu to free the time object,
    so in cttimeout_exit, invoking rcu_barrier() is not necessary at all,
    remove it too.
    
    Signed-off-by: Liping Zhang <zlpnobody@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>

commit 3cb637d2295a3f05c7fac17ccb9429f5b180772b
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a upstream.
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Willy Tarreau <w@1wt.eu>

commit 09ab11ebb7c1f9a66507e382aea696338304f83a
Author: Liping Zhang <zlpnobody@gmail.com>
Date:   Sat Mar 25 08:53:12 2017 +0800

    netfilter: invoke synchronize_rcu after set the _hook_ to NULL
    
    commit 3b7dabf029478bb80507a6c4500ca94132a2bc0b upstream.
    
    Otherwise, another CPU may access the invalid pointer. For example:
        CPU0                CPU1
         -              rcu_read_lock();
         -              pfunc = _hook_;
      _hook_ = NULL;          -
      mod unload              -
         -                 pfunc(); // invalid, panic
         -             rcu_read_unlock();
    
    So we must call synchronize_rcu() to wait the rcu reader to finish.
    
    Also note, in nf_nat_snmp_basic_fini, synchronize_rcu() will be invoked
    by later nf_conntrack_helper_unregister, but I'm inclined to add a
    explicit synchronize_rcu after set the nf_nat_snmp_hook to NULL. Depend
    on such obscure assumptions is not a good idea.
    
    Last, in nfnetlink_cttimeout, we use kfree_rcu to free the time object,
    so in cttimeout_exit, invoking rcu_barrier() is not necessary at all,
    remove it too.
    
    Signed-off-by: Liping Zhang <zlpnobody@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Willy Tarreau <w@1wt.eu>

commit 9c388a5ed1960b2ebbebd3dbe7553092b0c15ec1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Oct 31 22:32:00 2017 +0100

    watchdog/harclockup/perf: Revert a33d44843d45 ("watchdog/hardlockup/perf: Simplify deferred event destroy")
    
    Guenter reported a crash in the watchdog/perf code, which is caused by
    cleanup() and enable() running concurrently. The reason for this is:
    
    The watchdog functions are serialized via the watchdog_mutex and cpu
    hotplug locking, but the enable of the perf based watchdog happens in
    context of the unpark callback of the smpboot thread. But that unpark
    function is not synchronous inside the locking. The unparking of the thread
    just wakes it up and leaves so there is no guarantee when the thread is
    executing.
    
    If it starts running _before_ the cleanup happened then it will create a
    event and overwrite the dead event pointer. The new event is then cleaned
    up because the event is marked dead.
    
        lock(watchdog_mutex);
        lockup_detector_reconfigure();
            cpus_read_lock();
            stop();
               park()
            update();
            start();
               unpark()
            cpus_read_unlock();             thread runs()
                                              overwrite dead event ptr
            cleanup();
              free new event, which is active inside perf....
        unlock(watchdog_mutex);
    
    The park side is safe as that actually waits for the thread to reach
    parked state.
    
    Commit a33d44843d45 removed the protection against this kind of scenario
    under the stupid assumption that the hotplug serialization and the
    watchdog_mutex cover everything.
    
    Bring it back.
    
    Reverts: a33d44843d45 ("watchdog/hardlockup/perf: Simplify deferred event destroy")
    Reported-and-tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Thomas Feels-stupid Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Don Zickus <dzickus@redhat.com>
    Link: https://lkml.kernel.org/r/alpine.DEB.2.20.1710312145190.1942@nanos

commit 4f2ba5dc183b71362c3655b50c72f1b10ccac1c1
Merge: cb0631fd3cf9 2b7cda9c35d3
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Nov 1 08:29:01 2017 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Pull networking fixes from David Miller:
    
     1) Fix refcounting in xfrm_bundle_lookup() when using a dummy bundle,
        from Steffen Klassert.
    
     2) Fix crypto header handling in rx data frames in ath10k driver, from
        Vasanthakumar Thiagarajan.
    
     3) Fix use after free of qdisc when we defer tcp_chain_flush() to a
        workqueue. From Cong Wang.
    
     4) Fix double free in lapbether driver, from Pan Bian.
    
     5) Sanitize TUNSETSNDBUF values, from Craig Gallek.
    
     6) Fix refcounting when addrconf_permanent_addr() calls
        ipv6_del_addr(). From Eric Dumazet.
    
     7) Fix MTU probing bug in TCP that goes back to 2007, from Eric
        Dumazet.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net:
      tcp: fix tcp_mtu_probe() vs highest_sack
      ipv6: addrconf: increment ifp refcount before ipv6_del_addr()
      tun/tap: sanitize TUNSETSNDBUF input
      mlxsw: i2c: Fix buffer increment counter for write transaction
      mlxsw: reg: Add high and low temperature thresholds
      MAINTAINERS: Remove Yotam from mlxfw
      MAINTAINERS: Update Yotam's E-mail
      net: hns: set correct return value
      net: lapbether: fix double free
      bpf: remove SK_REDIRECT from UAPI
      net: phy: marvell: Only configure RGMII delays when using RGMII
      xfrm: Fix GSO for IPsec with GRE tunnel.
      tc-testing: fix arg to ip command: -s -> -n
      net_sched: remove tcf_block_put_deferred()
      l2tp: hold tunnel in pppol2tp_connect()
      Revert "ath10k: fix napi_poll budget overflow"
      ath10k: rebuild crypto header in rx data frames
      wcn36xx: Remove unnecessary rcu_read_unlock in wcn36xx_bss_info_changed
      xfrm: Clear sk_dst_cache when applying per-socket policy.
      xfrm: Fix xfrm_dst_cache memleak

commit b34a264fabdce972ca8d1cff38d1b48ecb963719
Merge: 518828fcdfc8 c29f56b9f425
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Nov 1 10:51:36 2017 +0900

    Merge tag 'wireless-drivers-for-davem-2017-10-31' of git://git.kernel.org/pub/scm/linux/kernel/git/kvalo/wireless-drivers
    
    Kalle Valo says:
    
    ====================
    wireless-drivers fixes for 4.14
    
    The most important here is the security vulnerabitility fix for
    ath10k.
    
    ath10k
    
    * fix security vulnerability with missing PN check on certain hardware
    
    * revert ath10k napi fix as it caused regressions on QCA6174
    
    wcn36xx
    
    * remove unnecessary rcu_read_unlock() from error path
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c29f56b9f425c63daa3f3163ee16493b1c67618b
Merge: a6127b4440d1 e48e9c429a95
Author: Kalle Valo <kvalo@codeaurora.org>
Date:   Tue Oct 31 16:26:48 2017 +0200

    Merge ath-current from ath.git
    
    ath.git fixes for 4.14. Major changes:
    
    ath10k
    
    * fix security vulnerability with missing PN check on certain hardware
    
    * revert ath10k napi fix as it caused regressions on QCA6174
    
    wcn36xx
    
    * remove unnecessary rcu_read_unlock() from error path

commit ee40fb2e1eb5bc0ddd3f2f83c6e39a454ef5a741
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Fri Oct 27 16:51:52 2017 +0200

    l2tp: protect sock pointer of struct pppol2tp_session with RCU
    
    pppol2tp_session_create() registers sessions that can't have their
    corresponding socket initialised. This socket has to be created by
    userspace, then connected to the session by pppol2tp_connect().
    Therefore, we need to protect the pppol2tp socket pointer of L2TP
    sessions, so that it can safely be updated when userspace is connecting
    or closing the socket. This will eventually allow pppol2tp_connect()
    to avoid generating transient states while initialising its parts of the
    session.
    
    To this end, this patch protects the pppol2tp socket pointer using RCU.
    
    The pppol2tp socket pointer is still set in pppol2tp_connect(), but
    only once we know the function isn't going to fail. It's eventually
    reset by pppol2tp_release(), which now has to wait for a grace period
    to elapse before it can drop the last reference on the socket. This
    ensures that pppol2tp_session_get_sock() can safely grab a reference
    on the socket, even after ps->sk is reset to NULL but before this
    operation actually gets visible from pppol2tp_session_get_sock().
    
    The rest is standard RCU conversion: pppol2tp_recv(), which already
    runs in atomic context, is simply enclosed by rcu_read_lock() and
    rcu_read_unlock(), while other functions are converted to use
    pppol2tp_session_get_sock() followed by sock_put().
    pppol2tp_session_setsockopt() is a special case. It used to retrieve
    the pppol2tp socket from the L2TP session, which itself was retrieved
    from the pppol2tp socket. Therefore we can just avoid dereferencing
    ps->sk and directly use the original socket pointer instead.
    
    With all users of ps->sk now handling NULL and concurrent updates, the
    L2TP ->ref() and ->deref() callbacks aren't needed anymore. Therefore,
    rather than converting pppol2tp_session_sock_hold() and
    pppol2tp_session_sock_put(), we can just drop them.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c0d5adc35c0b010120391117cb07be6623cf8940
Author: Jia-Ju Bai <baijiaju1990@163.com>
Date:   Fri Oct 27 11:12:30 2017 +0300

    wcn36xx: Remove unnecessary rcu_read_unlock in wcn36xx_bss_info_changed
    
    No rcu_read_lock is called, but rcu_read_unlock is still called.
    Thus rcu_read_unlock should be removed.
    
    Signed-off-by: Jia-Ju Bai <baijiaju1990@163.com>
    Acked-by: Bjorn Andersson <bjorn.andersson@linaro.org>
    Signed-off-by: Kalle Valo <kvalo@qca.qualcomm.com>

commit f3d9832e56c48e4ca50bab0457e21bcaade4536d
Author: David Ahern <dsahern@gmail.com>
Date:   Wed Oct 18 09:56:52 2017 -0700

    ipv6: addrconf: cleanup locking in ipv6_add_addr
    
    ipv6_add_addr is called in process context with rtnl lock held
    (e.g., manual config of an address) or during softirq processing
    (e.g., autoconf and address from a router advertisement).
    
    Currently, ipv6_add_addr calls rcu_read_lock_bh shortly after entry
    and does not call unlock until exit, minus the call around the address
    validator notifier. Similarly, addrconf_hash_lock is taken after the
    validator notifier and held until exit. This forces the allocation of
    inet6_ifaddr to always be atomic.
    
    Refactor ipv6_add_addr as follows:
    1. add an input boolean to discriminate the call path (process context
       or softirq). This new flag controls whether the alloc can be done
       with GFP_KERNEL or GFP_ATOMIC.
    
    2. Move the rcu_read_lock_bh and unlock calls only around functions that
       do rcu updates.
    
    3. Remove the in6_dev_hold and put added by 3ad7d2468f79f ("Ipvlan should
       return an error when an address is already in use."). This was done
       presumably because rcu_read_unlock_bh needs to be called before calling
       the validator. Since rcu_read_lock is not needed before the validator
       runs revert the hold and put added by 3ad7d2468f79f and only do the
       hold when setting ifp->idev.
    
    4. move duplicate address check and insertion of new address in the global
       address hash into a helper. The helper is called after an ifa is
       allocated and filled in.
    
    This allows the ifa for manually configured addresses to be done with
    GFP_KERNEL and reduces the overall amount of time with rcu_read_lock held
    and hash table spinlock held.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit bf6a119eea2f1427ac1c8b489bb187defa476ec6
Merge: a42317785c89 cc429c8f6fa7
Author: David S. Miller <davem@davemloft.net>
Date:   Sun Oct 8 21:16:31 2017 -0700

    Merge branch 'ipv6_dev_get_saddr-rcu'
    
    Eric Dumazet says:
    
    ====================
    ipv6: ipv6_dev_get_saddr() rcu works
    
    Sending IPv6 udp packets on non connected sockets is quite slow,
    because ipv6_dev_get_saddr() is still using an rwlock and silly
    references games on ifa.
    
    Tested:
    
    $ ./super_netperf 16 -H 4444::555:0786 -l 2000 -t UDP_STREAM -- -m 100 &
    [1] 12527
    
    Performance is boosted from 2.02 Mpps to 4.28 Mpps
    
    Kernel profile before patches :
      22.62%  [kernel]  [k] _raw_read_lock_bh
       7.04%  [kernel]  [k] refcount_sub_and_test
       6.56%  [kernel]  [k] ipv6_get_saddr_eval
       5.67%  [kernel]  [k] _raw_read_unlock_bh
       5.34%  [kernel]  [k] __ipv6_dev_get_saddr
       4.95%  [kernel]  [k] refcount_inc_not_zero
       4.03%  [kernel]  [k] __ip6addrlbl_match
       3.70%  [kernel]  [k] _raw_spin_lock
       3.44%  [kernel]  [k] ipv6_dev_get_saddr
       3.24%  [kernel]  [k] ip6_pol_route
       3.06%  [kernel]  [k] refcount_add_not_zero
       2.30%  [kernel]  [k] __local_bh_enable_ip
       1.81%  [kernel]  [k] mlx4_en_xmit
       1.20%  [kernel]  [k] __ip6_append_data
       1.12%  [kernel]  [k] __ip6_make_skb
       1.11%  [kernel]  [k] __dev_queue_xmit
       1.06%  [kernel]  [k] l3mdev_master_ifindex_rcu
    
    Kernel profile after patches :
      11.36%  [kernel]  [k] ip6_pol_route
       7.65%  [kernel]  [k] _raw_spin_lock
       7.16%  [kernel]  [k] __ipv6_dev_get_saddr
       6.49%  [kernel]  [k] ipv6_get_saddr_eval
       6.04%  [kernel]  [k] refcount_add_not_zero
       3.34%  [kernel]  [k] __ip6addrlbl_match
       2.62%  [kernel]  [k] __dev_queue_xmit
       2.37%  [kernel]  [k] mlx4_en_xmit
       2.26%  [kernel]  [k] dst_release
       1.89%  [kernel]  [k] __ip6_make_skb
       1.87%  [kernel]  [k] __ip6_append_data
       1.86%  [kernel]  [k] udpv6_sendmsg
       1.86%  [kernel]  [k] ip6t_do_table
       1.64%  [kernel]  [k] ipv6_dev_get_saddr
       1.64%  [kernel]  [k] find_match
       1.51%  [kernel]  [k] l3mdev_master_ifindex_rcu
       1.24%  [kernel]  [k] ipv6_addr_label
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f59c031e9134bb16c38980196a73d7ba40979baa
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Oct 7 19:30:27 2017 -0700

    ipv6: __ipv6_dev_get_saddr() rcu conversion
    
    Callers hold rcu_read_lock(), so we do not need
    the rcu_read_lock()/rcu_read_unlock() pair.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 146561a3f1c8d7f9ef9b77964c846da48c62a6ac
Author: Liping Zhang <zlpnobody@gmail.com>
Date:   Sat Mar 25 08:53:12 2017 +0800

    netfilter: invoke synchronize_rcu after set the _hook_ to NULL
    
    
    [ Upstream commit 3b7dabf029478bb80507a6c4500ca94132a2bc0b ]
    
    Otherwise, another CPU may access the invalid pointer. For example:
        CPU0                CPU1
         -              rcu_read_lock();
         -              pfunc = _hook_;
      _hook_ = NULL;          -
      mod unload              -
         -                 pfunc(); // invalid, panic
         -             rcu_read_unlock();
    
    So we must call synchronize_rcu() to wait the rcu reader to finish.
    
    Also note, in nf_nat_snmp_basic_fini, synchronize_rcu() will be invoked
    by later nf_conntrack_helper_unregister, but I'm inclined to add a
    explicit synchronize_rcu after set the nf_nat_snmp_hook to NULL. Depend
    on such obscure assumptions is not a good idea.
    
    Last, in nfnetlink_cttimeout, we use kfree_rcu to free the time object,
    so in cttimeout_exit, invoking rcu_barrier() is not necessary at all,
    remove it too.
    
    Signed-off-by: Liping Zhang <zlpnobody@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f7f46b3ba20def4321bfbe3a88cd1ae23eb40b07
Author: Liping Zhang <zlpnobody@gmail.com>
Date:   Sat Mar 25 08:53:12 2017 +0800

    netfilter: invoke synchronize_rcu after set the _hook_ to NULL
    
    
    [ Upstream commit 3b7dabf029478bb80507a6c4500ca94132a2bc0b ]
    
    Otherwise, another CPU may access the invalid pointer. For example:
        CPU0                CPU1
         -              rcu_read_lock();
         -              pfunc = _hook_;
      _hook_ = NULL;          -
      mod unload              -
         -                 pfunc(); // invalid, panic
         -             rcu_read_unlock();
    
    So we must call synchronize_rcu() to wait the rcu reader to finish.
    
    Also note, in nf_nat_snmp_basic_fini, synchronize_rcu() will be invoked
    by later nf_conntrack_helper_unregister, but I'm inclined to add a
    explicit synchronize_rcu after set the nf_nat_snmp_hook to NULL. Depend
    on such obscure assumptions is not a good idea.
    
    Last, in nfnetlink_cttimeout, we use kfree_rcu to free the time object,
    so in cttimeout_exit, invoking rcu_barrier() is not necessary at all,
    remove it too.
    
    Signed-off-by: Liping Zhang <zlpnobody@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c8cab6f202a1cecb5217706b6df631c87daf39e1
Author: Liping Zhang <zlpnobody@gmail.com>
Date:   Sat Mar 25 08:53:12 2017 +0800

    netfilter: invoke synchronize_rcu after set the _hook_ to NULL
    
    
    [ Upstream commit 3b7dabf029478bb80507a6c4500ca94132a2bc0b ]
    
    Otherwise, another CPU may access the invalid pointer. For example:
        CPU0                CPU1
         -              rcu_read_lock();
         -              pfunc = _hook_;
      _hook_ = NULL;          -
      mod unload              -
         -                 pfunc(); // invalid, panic
         -             rcu_read_unlock();
    
    So we must call synchronize_rcu() to wait the rcu reader to finish.
    
    Also note, in nf_nat_snmp_basic_fini, synchronize_rcu() will be invoked
    by later nf_conntrack_helper_unregister, but I'm inclined to add a
    explicit synchronize_rcu after set the nf_nat_snmp_hook to NULL. Depend
    on such obscure assumptions is not a good idea.
    
    Last, in nfnetlink_cttimeout, we use kfree_rcu to free the time object,
    so in cttimeout_exit, invoking rcu_barrier() is not necessary at all,
    remove it too.
    
    Signed-off-by: Liping Zhang <zlpnobody@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c86a65cf30ac5e8eaba4abe921b1b471d1fbe329
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Aug 23 10:43:02 2017 -0400

    tipc: Fix tipc_sk_reinit handling of -EAGAIN
    
    
    [ Upstream commit 6c7e983b220f89e03286dc70a41c7ef3a8b409df ]
    
    In 9dbbfb0ab6680c6a85609041011484e6658e7d3c function tipc_sk_reinit
    had additional logic added to loop in the event that function
    rhashtable_walk_next() returned -EAGAIN. No worries.
    
    However, if rhashtable_walk_start returns -EAGAIN, it does "continue",
    and therefore skips the call to rhashtable_walk_stop(). That has
    the effect of calling rcu_read_lock() without its paired call to
    rcu_read_unlock(). Since rcu_read_lock() may be nested, the problem
    may not be apparent for a while, especially since resize events may
    be rare. But the comments to rhashtable_walk_start() state:
    
     * ...Note that we take the RCU lock in all
     * cases including when we return an error.  So you must always call
     * rhashtable_walk_stop to clean up.
    
    This patch replaces the continue with a goto and label to ensure a
    matching call to rhashtable_walk_stop().
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5e7b05a3a1aed0d2b8ecd85188554a44161133b5
Author: Christoph Lameter <cl@linux.com>
Date:   Wed Mar 21 16:34:06 2012 -0700

    mm: fix move/migrate_pages() race on task struct
    
    commit 3268c63eded4612a3d07b56d1e02ce7731e6608e upstream.
    
    Migration functions perform the rcu_read_unlock too early.  As a result
    the task pointed to may change from under us.  This can result in an oops,
    as reported by Dave Hansen in https://lkml.org/lkml/2012/2/23/302.
    
    The following patch extend the period of the rcu_read_lock until after the
    permissions checks are done.  We also take a refcount so that the task
    reference is stable when calling security check functions and performing
    cpuset node validation (which takes a mutex).
    
    The refcount is dropped before actual page migration occurs so there is no
    change to the refcounts held during page migration.
    
    Also move the determination of the mm of the task struct to immediately
    before the do_migrate*() calls so that it is clear that we switch from
    handling the task during permission checks to the mm for the actual
    migration.  Since the determination is only done once and we then no
    longer use the task_struct we can be sure that we operate on a specific
    address space that will not change from under us.
    
    [akpm@linux-foundation.org: checkpatch fixes]
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Reported-by: Dave Hansen <dave@linux.vnet.ibm.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 2ae7cdab3948224b57addd6b82da796aa50d27f7
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed May 31 14:03:11 2017 +0200

    srcu: Allow use of Classic SRCU from both process and interrupt context
    
    commit 1123a6041654e8f889014659593bad4168e542c2 upstream.
    
    Linu Cherian reported a WARN in cleanup_srcu_struct() when shutting
    down a guest running iperf on a VFIO assigned device.  This happens
    because irqfd_wakeup() calls srcu_read_lock(&kvm->irq_srcu) in interrupt
    context, while a worker thread does the same inside kvm_set_irq().  If the
    interrupt happens while the worker thread is executing __srcu_read_lock(),
    updates to the Classic SRCU ->lock_count[] field or the Tree SRCU
    ->srcu_lock_count[] field can be lost.
    
    The docs say you are not supposed to call srcu_read_lock() and
    srcu_read_unlock() from irq context, but KVM interrupt injection happens
    from (host) interrupt context and it would be nice if SRCU supported the
    use case.  KVM is using SRCU here not really for the "sleepable" part,
    but rather due to its IPI-free fast detection of grace periods.  It is
    therefore not desirable to switch back to RCU, which would effectively
    revert commit 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING",
    2014-01-16).
    
    However, the docs are overly conservative.  You can have an SRCU instance
    only has users in irq context, and you can mix process and irq context
    as long as process context users disable interrupts.  In addition,
    __srcu_read_unlock() actually uses this_cpu_dec() on both Tree SRCU and
    Classic SRCU.  For those two implementations, only srcu_read_lock()
    is unsafe.
    
    When Classic SRCU's __srcu_read_unlock() was changed to use this_cpu_dec(),
    in commit 5a41344a3d83 ("srcu: Simplify __srcu_read_unlock() via
    this_cpu_dec()", 2012-11-29), __srcu_read_lock() did two increments.
    Therefore it kept __this_cpu_inc(), with preempt_disable/enable in
    the caller.  Tree SRCU however only does one increment, so on most
    architectures it is more efficient for __srcu_read_lock() to use
    this_cpu_inc(), and any performance differences appear to be down in
    the noise.
    
    Fixes: 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING")
    Reported-by: Linu Cherian <linuc.decode@gmail.com>
    Suggested-by: Linu Cherian <linuc.decode@gmail.com>
    Cc: kvm@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [bwh: Backported to 3.16: __srcu_read_lock() still updates two different
     counters.  So follow what  _this_cpu_generic_to_op() does and use
     raw_local_irq_{save,restore}() and raw_cpu_ptr().]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 8d07678e12833213b72804f839c6c662b526977d
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Fri May 12 19:11:31 2017 +0300

    pid_ns: Fix race between setns'ed fork() and zap_pid_ns_processes()
    
    commit 3fd37226216620c1a468afa999739d5016fbc349 upstream.
    
    Imagine we have a pid namespace and a task from its parent's pid_ns,
    which made setns() to the pid namespace. The task is doing fork(),
    while the pid namespace's child reaper is dying. We have the race
    between them:
    
    Task from parent pid_ns             Child reaper
    copy_process()                      ..
      alloc_pid()                       ..
      ..                                zap_pid_ns_processes()
      ..                                  disable_pid_allocation()
      ..                                  read_lock(&tasklist_lock)
      ..                                  iterate over pids in pid_ns
      ..                                    kill tasks linked to pids
      ..                                  read_unlock(&tasklist_lock)
      write_lock_irq(&tasklist_lock);   ..
      attach_pid(p, PIDTYPE_PID);       ..
      ..                                ..
    
    So, just created task p won't receive SIGKILL signal,
    and the pid namespace will be in contradictory state.
    Only manual kill will help there, but does the userspace
    care about this? I suppose, the most users just inject
    a task into a pid namespace and wait a SIGCHLD from it.
    
    The patch fixes the problem. It simply checks for
    (pid_ns->nr_hashed & PIDNS_HASH_ADDING) in copy_process().
    We do it under the tasklist_lock, and can't skip
    PIDNS_HASH_ADDING as noted by Oleg:
    
    "zap_pid_ns_processes() does disable_pid_allocation()
    and then takes tasklist_lock to kill the whole namespace.
    Given that copy_process() checks PIDNS_HASH_ADDING
    under write_lock(tasklist) they can't race;
    if copy_process() takes this lock first, the new child will
    be killed, otherwise copy_process() can't miss
    the change in ->nr_hashed."
    
    If allocation is disabled, we just return -ENOMEM
    like it's made for such cases in alloc_pid().
    
    v2: Do not move disable_pid_allocation(), do not
    introduce a new variable in copy_process() and simplify
    the patch as suggested by Oleg Nesterov.
    Account the problem with double irq enabling
    found by Eric W. Biederman.
    
    Fixes: c876ad768215 ("pidns: Stop pid allocation when init dies")
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    CC: Andrew Morton <akpm@linux-foundation.org>
    CC: Ingo Molnar <mingo@kernel.org>
    CC: Peter Zijlstra <peterz@infradead.org>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Mike Rapoport <rppt@linux.vnet.ibm.com>
    CC: Michal Hocko <mhocko@suse.com>
    CC: Andy Lutomirski <luto@kernel.org>
    CC: "Eric W. Biederman" <ebiederm@xmission.com>
    CC: Andrei Vagin <avagin@openvz.org>
    CC: Cyrill Gorcunov <gorcunov@openvz.org>
    CC: Serge Hallyn <serge@hallyn.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    [bwh: Backported to 3.16: the proper cleanup label is bad_fork_free_pid, not
     bad_fork_cancel_cgroup]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit da8ab57863ed7e912d10b179b6bdc652f635bd19
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Sep 11 15:58:38 2017 -0700

    tcp/dccp: remove reqsk_put() from inet_child_forget()
    
    Back in linux-4.4, I inadvertently put a call to reqsk_put() in
    inet_child_forget(), forgetting it could be called from two different
    points.
    
    In the case it is called from inet_csk_reqsk_queue_add(), we want to
    keep the reference on the request socket, since it is released later by
    the caller (tcp_v{4|6}_rcv())
    
    This bug never showed up because atomic_dec_and_test() was not signaling
    the underflow, and SLAB_DESTROY_BY RCU semantic for request sockets
    prevented the request to be put in quarantine.
    
    Recent conversion of socket refcount from atomic_t to refcount_t finally
    exposed the bug.
    
    So move the reqsk_put() to inet_csk_listen_stop() to fix this.
    
    Thanks to Shankara Pailoor for using syzkaller and providing
    a nice set of .config and C repro.
    
    WARNING: CPU: 2 PID: 4277 at lib/refcount.c:186
    refcount_sub_and_test+0x167/0x1b0 lib/refcount.c:186
    Kernel panic - not syncing: panic_on_warn set ...
    
    CPU: 2 PID: 4277 Comm: syz-executor0 Not tainted 4.13.0-rc7 #3
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    Ubuntu-1.8.2-1ubuntu1 04/01/2014
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0xf7/0x1aa lib/dump_stack.c:52
     panic+0x1ae/0x3a7 kernel/panic.c:180
     __warn+0x1c4/0x1d9 kernel/panic.c:541
     report_bug+0x211/0x2d0 lib/bug.c:183
     fixup_bug+0x40/0x90 arch/x86/kernel/traps.c:190
     do_trap_no_signal arch/x86/kernel/traps.c:224 [inline]
     do_trap+0x260/0x390 arch/x86/kernel/traps.c:273
     do_error_trap+0x118/0x340 arch/x86/kernel/traps.c:310
     do_invalid_op+0x1b/0x20 arch/x86/kernel/traps.c:323
     invalid_op+0x18/0x20 arch/x86/entry/entry_64.S:846
    RIP: 0010:refcount_sub_and_test+0x167/0x1b0 lib/refcount.c:186
    RSP: 0018:ffff88006e006b60 EFLAGS: 00010286
    RAX: 0000000000000026 RBX: 0000000000000000 RCX: 0000000000000000
    RDX: 0000000000000026 RSI: 1ffff1000dc00d2c RDI: ffffed000dc00d60
    RBP: ffff88006e006bf0 R08: 0000000000000001 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000000 R12: 1ffff1000dc00d6d
    R13: 00000000ffffffff R14: 0000000000000001 R15: ffff88006ce9d340
     refcount_dec_and_test+0x1a/0x20 lib/refcount.c:211
     reqsk_put+0x71/0x2b0 include/net/request_sock.h:123
     tcp_v4_rcv+0x259e/0x2e20 net/ipv4/tcp_ipv4.c:1729
     ip_local_deliver_finish+0x2e2/0xba0 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:248 [inline]
     ip_local_deliver+0x1ce/0x6d0 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:477 [inline]
     ip_rcv_finish+0x8db/0x19c0 net/ipv4/ip_input.c:397
     NF_HOOK include/linux/netfilter.h:248 [inline]
     ip_rcv+0xc3f/0x17d0 net/ipv4/ip_input.c:488
     __netif_receive_skb_core+0x1fb7/0x31f0 net/core/dev.c:4298
     __netif_receive_skb+0x2c/0x1b0 net/core/dev.c:4336
     process_backlog+0x1c5/0x6d0 net/core/dev.c:5102
     napi_poll net/core/dev.c:5499 [inline]
     net_rx_action+0x6d3/0x14a0 net/core/dev.c:5565
     __do_softirq+0x2cb/0xb2d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:898
     </IRQ>
     do_softirq.part.16+0x63/0x80 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x84/0x90 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:705 [inline]
     ip_finish_output2+0x8ad/0x1360 net/ipv4/ip_output.c:231
     ip_finish_output+0x74e/0xb80 net/ipv4/ip_output.c:317
     NF_HOOK_COND include/linux/netfilter.h:237 [inline]
     ip_output+0x1cc/0x850 net/ipv4/ip_output.c:405
     dst_output include/net/dst.h:471 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x8c6/0x1810 net/ipv4/ip_output.c:504
     tcp_transmit_skb+0x1963/0x3320 net/ipv4/tcp_output.c:1123
     tcp_send_ack.part.35+0x38c/0x620 net/ipv4/tcp_output.c:3575
     tcp_send_ack+0x49/0x60 net/ipv4/tcp_output.c:3545
     tcp_rcv_synsent_state_process net/ipv4/tcp_input.c:5795 [inline]
     tcp_rcv_state_process+0x4876/0x4b60 net/ipv4/tcp_input.c:5930
     tcp_v4_do_rcv+0x58a/0x820 net/ipv4/tcp_ipv4.c:1483
     sk_backlog_rcv include/net/sock.h:907 [inline]
     __release_sock+0x124/0x360 net/core/sock.c:2223
     release_sock+0xa4/0x2a0 net/core/sock.c:2715
     inet_wait_for_connect net/ipv4/af_inet.c:557 [inline]
     __inet_stream_connect+0x671/0xf00 net/ipv4/af_inet.c:643
     inet_stream_connect+0x58/0xa0 net/ipv4/af_inet.c:682
     SYSC_connect+0x204/0x470 net/socket.c:1628
     SyS_connect+0x24/0x30 net/socket.c:1609
     entry_SYSCALL_64_fastpath+0x18/0xad
    RIP: 0033:0x451e59
    RSP: 002b:00007f474843fc08 EFLAGS: 00000216 ORIG_RAX: 000000000000002a
    RAX: ffffffffffffffda RBX: 0000000000718000 RCX: 0000000000451e59
    RDX: 0000000000000010 RSI: 0000000020002000 RDI: 0000000000000007
    RBP: 0000000000000046 R08: 0000000000000000 R09: 0000000000000000
    R10: 0000000000000000 R11: 0000000000000216 R12: 0000000000000000
    R13: 00007ffc040a0f8f R14: 00007f47484409c0 R15: 0000000000000000
    
    Fixes: ebb516af60e1 ("tcp/dccp: fix race at listener dismantle phase")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Shankara Pailoor <sp3485@columbia.edu>
    Tested-by: Shankara Pailoor <sp3485@columbia.edu>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 943eb7384e1a4910ea02365591be1d9685adc3c3
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    [ Upstream commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a ]
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>

commit c2d6511e6a4f1f3673d711569c00c3849549e9b0
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:05 2017 +0300

    sch_tbf: fix two null pointer dereferences on init failure
    
    sch_tbf calls qdisc_watchdog_cancel() in both its ->reset and ->destroy
    callbacks but it may fail before the timer is initialized due to missing
    options (either not supplied by user-space or set as a default qdisc),
    also q->qdisc is used by ->reset and ->destroy so we need it initialized.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=tbf
    $ ip l set ethX up
    
    Crash log:
    [  959.160172] BUG: unable to handle kernel NULL pointer dereference at 0000000000000018
    [  959.160323] IP: qdisc_reset+0xa/0x5c
    [  959.160400] PGD 59cdb067
    [  959.160401] P4D 59cdb067
    [  959.160466] PUD 59ccb067
    [  959.160532] PMD 0
    [  959.160597]
    [  959.160706] Oops: 0000 [#1] SMP
    [  959.160778] Modules linked in: sch_tbf sch_sfb sch_prio sch_netem
    [  959.160891] CPU: 2 PID: 1562 Comm: ip Not tainted 4.13.0-rc6+ #62
    [  959.160998] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  959.161157] task: ffff880059c9a700 task.stack: ffff8800376d0000
    [  959.161263] RIP: 0010:qdisc_reset+0xa/0x5c
    [  959.161347] RSP: 0018:ffff8800376d3610 EFLAGS: 00010286
    [  959.161531] RAX: ffffffffa001b1dd RBX: ffff8800373a2800 RCX: 0000000000000000
    [  959.161733] RDX: ffffffff8215f160 RSI: ffffffff8215f160 RDI: 0000000000000000
    [  959.161939] RBP: ffff8800376d3618 R08: 00000000014080c0 R09: 00000000ffffffff
    [  959.162141] R10: ffff8800376d3578 R11: 0000000000000020 R12: ffffffffa001d2c0
    [  959.162343] R13: ffff880037538000 R14: 00000000ffffffff R15: 0000000000000001
    [  959.162546] FS:  00007fcc5126b740(0000) GS:ffff88005d900000(0000) knlGS:0000000000000000
    [  959.162844] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  959.163030] CR2: 0000000000000018 CR3: 000000005abc4000 CR4: 00000000000406e0
    [  959.163233] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  959.163436] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  959.163638] Call Trace:
    [  959.163788]  tbf_reset+0x19/0x64 [sch_tbf]
    [  959.163957]  qdisc_destroy+0x8b/0xe5
    [  959.164119]  qdisc_create_dflt+0x86/0x94
    [  959.164284]  ? dev_activate+0x129/0x129
    [  959.164449]  attach_one_default_qdisc+0x36/0x63
    [  959.164623]  netdev_for_each_tx_queue+0x3d/0x48
    [  959.164795]  dev_activate+0x4b/0x129
    [  959.164957]  __dev_open+0xe7/0x104
    [  959.165118]  __dev_change_flags+0xc6/0x15c
    [  959.165287]  dev_change_flags+0x25/0x59
    [  959.165451]  do_setlink+0x30c/0xb3f
    [  959.165613]  ? check_chain_key+0xb0/0xfd
    [  959.165782]  rtnl_newlink+0x3a4/0x729
    [  959.165947]  ? rtnl_newlink+0x117/0x729
    [  959.166121]  ? ns_capable_common+0xd/0xb1
    [  959.166288]  ? ns_capable+0x13/0x15
    [  959.166450]  rtnetlink_rcv_msg+0x188/0x197
    [  959.166617]  ? rcu_read_unlock+0x3e/0x5f
    [  959.166783]  ? rtnl_newlink+0x729/0x729
    [  959.166948]  netlink_rcv_skb+0x6c/0xce
    [  959.167113]  rtnetlink_rcv+0x23/0x2a
    [  959.167273]  netlink_unicast+0x103/0x181
    [  959.167439]  netlink_sendmsg+0x326/0x337
    [  959.167607]  sock_sendmsg_nosec+0x14/0x3f
    [  959.167772]  sock_sendmsg+0x29/0x2e
    [  959.167932]  ___sys_sendmsg+0x209/0x28b
    [  959.168098]  ? do_raw_spin_unlock+0xcd/0xf8
    [  959.168267]  ? _raw_spin_unlock+0x27/0x31
    [  959.168432]  ? __handle_mm_fault+0x651/0xdb1
    [  959.168602]  ? check_chain_key+0xb0/0xfd
    [  959.168773]  __sys_sendmsg+0x45/0x63
    [  959.168934]  ? __sys_sendmsg+0x45/0x63
    [  959.169100]  SyS_sendmsg+0x19/0x1b
    [  959.169260]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  959.169432] RIP: 0033:0x7fcc5097e690
    [  959.169592] RSP: 002b:00007ffd0d5c7b48 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  959.169887] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007fcc5097e690
    [  959.170089] RDX: 0000000000000000 RSI: 00007ffd0d5c7b90 RDI: 0000000000000003
    [  959.170292] RBP: ffff8800376d3f98 R08: 0000000000000001 R09: 0000000000000003
    [  959.170494] R10: 00007ffd0d5c7910 R11: 0000000000000246 R12: 0000000000000006
    [  959.170697] R13: 000000000066f1a0 R14: 00007ffd0d5cfc40 R15: 0000000000000000
    [  959.170900]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  959.171076] Code: 00 41 c7 84 24 14 01 00 00 00 00 00 00 41 c7 84 24
    98 00 00 00 00 00 00 00 41 5c 41 5d 41 5e 5d c3 66 66 66 66 90 55 48 89
    e5 53 <48> 8b 47 18 48 89 fb 48 8b 40 48 48 85 c0 74 02 ff d0 48 8b bb
    [  959.171637] RIP: qdisc_reset+0xa/0x5c RSP: ffff8800376d3610
    [  959.171821] CR2: 0000000000000018
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 634576a1844dba15bc5e6fc61d72f37e13a21615
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:03 2017 +0300

    sch_netem: avoid null pointer deref on init failure
    
    netem can fail in ->init due to missing options (either not supplied by
    user-space or used as a default qdisc) causing a timer->base null
    pointer deref in its ->destroy() and ->reset() callbacks.
    
    Reproduce:
    $ sysctl net.core.default_qdisc=netem
    $ ip l set ethX up
    
    Crash log:
    [ 1814.846943] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 1814.847181] IP: hrtimer_active+0x17/0x8a
    [ 1814.847270] PGD 59c34067
    [ 1814.847271] P4D 59c34067
    [ 1814.847337] PUD 37374067
    [ 1814.847403] PMD 0
    [ 1814.847468]
    [ 1814.847582] Oops: 0000 [#1] SMP
    [ 1814.847655] Modules linked in: sch_netem(O) sch_fq_codel(O)
    [ 1814.847761] CPU: 3 PID: 1573 Comm: ip Tainted: G           O 4.13.0-rc6+ #62
    [ 1814.847884] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 1814.848043] task: ffff88003723a700 task.stack: ffff88005adc8000
    [ 1814.848235] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 1814.848407] RSP: 0018:ffff88005adcb590 EFLAGS: 00010246
    [ 1814.848590] RAX: 0000000000000000 RBX: ffff880058e359d8 RCX: 0000000000000000
    [ 1814.848793] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff880058e359d8
    [ 1814.848998] RBP: ffff88005adcb5b0 R08: 00000000014080c0 R09: 00000000ffffffff
    [ 1814.849204] R10: ffff88005adcb660 R11: 0000000000000020 R12: 0000000000000000
    [ 1814.849410] R13: ffff880058e359d8 R14: 00000000ffffffff R15: 0000000000000001
    [ 1814.849616] FS:  00007f733bbca740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 1814.849919] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1814.850107] CR2: 0000000000000000 CR3: 0000000059f0d000 CR4: 00000000000406e0
    [ 1814.850313] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 1814.850518] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 1814.850723] Call Trace:
    [ 1814.850875]  hrtimer_try_to_cancel+0x1a/0x93
    [ 1814.851047]  hrtimer_cancel+0x15/0x20
    [ 1814.851211]  qdisc_watchdog_cancel+0x12/0x14
    [ 1814.851383]  netem_reset+0xe6/0xed [sch_netem]
    [ 1814.851561]  qdisc_destroy+0x8b/0xe5
    [ 1814.851723]  qdisc_create_dflt+0x86/0x94
    [ 1814.851890]  ? dev_activate+0x129/0x129
    [ 1814.852057]  attach_one_default_qdisc+0x36/0x63
    [ 1814.852232]  netdev_for_each_tx_queue+0x3d/0x48
    [ 1814.852406]  dev_activate+0x4b/0x129
    [ 1814.852569]  __dev_open+0xe7/0x104
    [ 1814.852730]  __dev_change_flags+0xc6/0x15c
    [ 1814.852899]  dev_change_flags+0x25/0x59
    [ 1814.853064]  do_setlink+0x30c/0xb3f
    [ 1814.853228]  ? check_chain_key+0xb0/0xfd
    [ 1814.853396]  ? check_chain_key+0xb0/0xfd
    [ 1814.853565]  rtnl_newlink+0x3a4/0x729
    [ 1814.853728]  ? rtnl_newlink+0x117/0x729
    [ 1814.853905]  ? ns_capable_common+0xd/0xb1
    [ 1814.854072]  ? ns_capable+0x13/0x15
    [ 1814.854234]  rtnetlink_rcv_msg+0x188/0x197
    [ 1814.854404]  ? rcu_read_unlock+0x3e/0x5f
    [ 1814.854572]  ? rtnl_newlink+0x729/0x729
    [ 1814.854737]  netlink_rcv_skb+0x6c/0xce
    [ 1814.854902]  rtnetlink_rcv+0x23/0x2a
    [ 1814.855064]  netlink_unicast+0x103/0x181
    [ 1814.855230]  netlink_sendmsg+0x326/0x337
    [ 1814.855398]  sock_sendmsg_nosec+0x14/0x3f
    [ 1814.855584]  sock_sendmsg+0x29/0x2e
    [ 1814.855747]  ___sys_sendmsg+0x209/0x28b
    [ 1814.855912]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 1814.856082]  ? _raw_spin_unlock+0x27/0x31
    [ 1814.856251]  ? __handle_mm_fault+0x651/0xdb1
    [ 1814.856421]  ? check_chain_key+0xb0/0xfd
    [ 1814.856592]  __sys_sendmsg+0x45/0x63
    [ 1814.856755]  ? __sys_sendmsg+0x45/0x63
    [ 1814.856923]  SyS_sendmsg+0x19/0x1b
    [ 1814.857083]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 1814.857256] RIP: 0033:0x7f733b2dd690
    [ 1814.857419] RSP: 002b:00007ffe1d3387d8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 1814.858238] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f733b2dd690
    [ 1814.858445] RDX: 0000000000000000 RSI: 00007ffe1d338820 RDI: 0000000000000003
    [ 1814.858651] RBP: ffff88005adcbf98 R08: 0000000000000001 R09: 0000000000000003
    [ 1814.858856] R10: 00007ffe1d3385a0 R11: 0000000000000246 R12: 0000000000000002
    [ 1814.859060] R13: 000000000066f1a0 R14: 00007ffe1d3408d0 R15: 0000000000000000
    [ 1814.859267]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 1814.859446] Code: 10 55 48 89 c7 48 89 e5 e8 45 a1 fb ff 31 c0 5d c3
    31 c0 c3 66 66 66 66 90 55 48 89 e5 41 56 41 55 41 54 53 49 89 fd 49 8b
    45 30 <4c> 8b 20 41 8b 5c 24 38 31 c9 31 d2 48 c7 c7 50 8e 1d 82 41 89
    [ 1814.860022] RIP: hrtimer_active+0x17/0x8a RSP: ffff88005adcb590
    [ 1814.860214] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 3501d059921246ff617b43e86250a719c140bd97
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:49:01 2017 +0300

    sch_cbq: fix null pointer dereferences on init failure
    
    CBQ can fail on ->init by wrong nl attributes or simply for missing any,
    f.e. if it's set as a default qdisc then TCA_OPTIONS (opt) will be NULL
    when it is activated. The first thing init does is parse opt but it will
    dereference a null pointer if used as a default qdisc, also since init
    failure at default qdisc invokes ->reset() which cancels all timers then
    we'll also dereference two more null pointers (timer->base) as they were
    never initialized.
    
    To reproduce:
    $ sysctl net.core.default_qdisc=cbq
    $ ip l set ethX up
    
    Crash log of the first null ptr deref:
    [44727.907454] BUG: unable to handle kernel NULL pointer dereference at (null)
    [44727.907600] IP: cbq_init+0x27/0x205
    [44727.907676] PGD 59ff4067
    [44727.907677] P4D 59ff4067
    [44727.907742] PUD 59c70067
    [44727.907807] PMD 0
    [44727.907873]
    [44727.907982] Oops: 0000 [#1] SMP
    [44727.908054] Modules linked in:
    [44727.908126] CPU: 1 PID: 21312 Comm: ip Not tainted 4.13.0-rc6+ #60
    [44727.908235] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [44727.908477] task: ffff88005ad42700 task.stack: ffff880037214000
    [44727.908672] RIP: 0010:cbq_init+0x27/0x205
    [44727.908838] RSP: 0018:ffff8800372175f0 EFLAGS: 00010286
    [44727.909018] RAX: ffffffff816c3852 RBX: ffff880058c53800 RCX: 0000000000000000
    [44727.909222] RDX: 0000000000000004 RSI: 0000000000000000 RDI: ffff8800372175f8
    [44727.909427] RBP: ffff880037217650 R08: ffffffff81b0f380 R09: 0000000000000000
    [44727.909631] R10: ffff880037217660 R11: 0000000000000020 R12: ffffffff822a44c0
    [44727.909835] R13: ffff880058b92000 R14: 00000000ffffffff R15: 0000000000000001
    [44727.910040] FS:  00007ff8bc583740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [44727.910339] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [44727.910525] CR2: 0000000000000000 CR3: 00000000371e5000 CR4: 00000000000406e0
    [44727.910731] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [44727.910936] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [44727.911141] Call Trace:
    [44727.911291]  ? lockdep_init_map+0xb6/0x1ba
    [44727.911461]  ? qdisc_alloc+0x14e/0x187
    [44727.911626]  qdisc_create_dflt+0x7a/0x94
    [44727.911794]  ? dev_activate+0x129/0x129
    [44727.911959]  attach_one_default_qdisc+0x36/0x63
    [44727.912132]  netdev_for_each_tx_queue+0x3d/0x48
    [44727.912305]  dev_activate+0x4b/0x129
    [44727.912468]  __dev_open+0xe7/0x104
    [44727.912631]  __dev_change_flags+0xc6/0x15c
    [44727.912799]  dev_change_flags+0x25/0x59
    [44727.912966]  do_setlink+0x30c/0xb3f
    [44727.913129]  ? check_chain_key+0xb0/0xfd
    [44727.913294]  ? check_chain_key+0xb0/0xfd
    [44727.913463]  rtnl_newlink+0x3a4/0x729
    [44727.913626]  ? rtnl_newlink+0x117/0x729
    [44727.913801]  ? ns_capable_common+0xd/0xb1
    [44727.913968]  ? ns_capable+0x13/0x15
    [44727.914131]  rtnetlink_rcv_msg+0x188/0x197
    [44727.914300]  ? rcu_read_unlock+0x3e/0x5f
    [44727.914465]  ? rtnl_newlink+0x729/0x729
    [44727.914630]  netlink_rcv_skb+0x6c/0xce
    [44727.914796]  rtnetlink_rcv+0x23/0x2a
    [44727.914956]  netlink_unicast+0x103/0x181
    [44727.915122]  netlink_sendmsg+0x326/0x337
    [44727.915291]  sock_sendmsg_nosec+0x14/0x3f
    [44727.915459]  sock_sendmsg+0x29/0x2e
    [44727.915619]  ___sys_sendmsg+0x209/0x28b
    [44727.915784]  ? do_raw_spin_unlock+0xcd/0xf8
    [44727.915954]  ? _raw_spin_unlock+0x27/0x31
    [44727.916121]  ? __handle_mm_fault+0x651/0xdb1
    [44727.916290]  ? check_chain_key+0xb0/0xfd
    [44727.916461]  __sys_sendmsg+0x45/0x63
    [44727.916626]  ? __sys_sendmsg+0x45/0x63
    [44727.916792]  SyS_sendmsg+0x19/0x1b
    [44727.916950]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [44727.917125] RIP: 0033:0x7ff8bbc96690
    [44727.917286] RSP: 002b:00007ffc360991e8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [44727.917579] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007ff8bbc96690
    [44727.917783] RDX: 0000000000000000 RSI: 00007ffc36099230 RDI: 0000000000000003
    [44727.917987] RBP: ffff880037217f98 R08: 0000000000000001 R09: 0000000000000003
    [44727.918190] R10: 00007ffc36098fb0 R11: 0000000000000246 R12: 0000000000000006
    [44727.918393] R13: 000000000066f1a0 R14: 00007ffc360a12e0 R15: 0000000000000000
    [44727.918597]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [44727.918774] Code: 41 5f 5d c3 66 66 66 66 90 55 48 8d 56 04 45 31 c9
    49 c7 c0 80 f3 b0 81 48 89 e5 41 55 41 54 53 48 89 fb 48 8d 7d a8 48 83
    ec 48 <0f> b7 0e be 07 00 00 00 83 e9 04 e8 e6 f7 d8 ff 85 c0 0f 88 bb
    [44727.919332] RIP: cbq_init+0x27/0x205 RSP: ffff8800372175f0
    [44727.919516] CR2: 0000000000000000
    
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 32db864d33c21fd70a217ba53cb7224889354ffb
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:59 2017 +0300

    sch_hhf: fix null pointer dereference on init failure
    
    If sch_hhf fails in its ->init() function (either due to wrong
    user-space arguments as below or memory alloc failure of hh_flows) it
    will do a null pointer deref of q->hh_flows in its ->destroy() function.
    
    To reproduce the crash:
    $ tc qdisc add dev eth0 root hhf quantum 2000000 non_hh_weight 10000000
    
    Crash log:
    [  690.654882] BUG: unable to handle kernel NULL pointer dereference at (null)
    [  690.655565] IP: hhf_destroy+0x48/0xbc
    [  690.655944] PGD 37345067
    [  690.655948] P4D 37345067
    [  690.656252] PUD 58402067
    [  690.656554] PMD 0
    [  690.656857]
    [  690.657362] Oops: 0000 [#1] SMP
    [  690.657696] Modules linked in:
    [  690.658032] CPU: 3 PID: 920 Comm: tc Not tainted 4.13.0-rc6+ #57
    [  690.658525] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [  690.659255] task: ffff880058578000 task.stack: ffff88005acbc000
    [  690.659747] RIP: 0010:hhf_destroy+0x48/0xbc
    [  690.660146] RSP: 0018:ffff88005acbf9e0 EFLAGS: 00010246
    [  690.660601] RAX: 0000000000000000 RBX: 0000000000000020 RCX: 0000000000000000
    [  690.661155] RDX: 0000000000000000 RSI: 0000000000000001 RDI: ffffffff821f63f0
    [  690.661710] RBP: ffff88005acbfa08 R08: ffffffff81b10a90 R09: 0000000000000000
    [  690.662267] R10: 00000000f42b7019 R11: ffff880058578000 R12: 00000000ffffffea
    [  690.662820] R13: ffff8800372f6400 R14: 0000000000000000 R15: 0000000000000000
    [  690.663769] FS:  00007f8ae5e8b740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [  690.667069] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  690.667965] CR2: 0000000000000000 CR3: 0000000058523000 CR4: 00000000000406e0
    [  690.668918] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [  690.669945] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [  690.671003] Call Trace:
    [  690.671743]  qdisc_create+0x377/0x3fd
    [  690.672534]  tc_modify_qdisc+0x4d2/0x4fd
    [  690.673324]  rtnetlink_rcv_msg+0x188/0x197
    [  690.674204]  ? rcu_read_unlock+0x3e/0x5f
    [  690.675091]  ? rtnl_newlink+0x729/0x729
    [  690.675877]  netlink_rcv_skb+0x6c/0xce
    [  690.676648]  rtnetlink_rcv+0x23/0x2a
    [  690.677405]  netlink_unicast+0x103/0x181
    [  690.678179]  netlink_sendmsg+0x326/0x337
    [  690.678958]  sock_sendmsg_nosec+0x14/0x3f
    [  690.679743]  sock_sendmsg+0x29/0x2e
    [  690.680506]  ___sys_sendmsg+0x209/0x28b
    [  690.681283]  ? __handle_mm_fault+0xc7d/0xdb1
    [  690.681915]  ? check_chain_key+0xb0/0xfd
    [  690.682449]  __sys_sendmsg+0x45/0x63
    [  690.682954]  ? __sys_sendmsg+0x45/0x63
    [  690.683471]  SyS_sendmsg+0x19/0x1b
    [  690.683974]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [  690.684516] RIP: 0033:0x7f8ae529d690
    [  690.685016] RSP: 002b:00007fff26d2d6b8 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [  690.685931] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f8ae529d690
    [  690.686573] RDX: 0000000000000000 RSI: 00007fff26d2d700 RDI: 0000000000000003
    [  690.687047] RBP: ffff88005acbff98 R08: 0000000000000001 R09: 0000000000000000
    [  690.687519] R10: 00007fff26d2d480 R11: 0000000000000246 R12: 0000000000000002
    [  690.687996] R13: 0000000001258070 R14: 0000000000000001 R15: 0000000000000000
    [  690.688475]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [  690.688887] Code: 00 00 e8 2a 02 ae ff 49 8b bc 1d 60 02 00 00 48 83
    c3 08 e8 19 02 ae ff 48 83 fb 20 75 dc 45 31 f6 4d 89 f7 4d 03 bd 20 02
    00 00 <49> 8b 07 49 39 c7 75 24 49 83 c6 10 49 81 fe 00 40 00 00 75 e1
    [  690.690200] RIP: hhf_destroy+0x48/0xbc RSP: ffff88005acbf9e0
    [  690.690636] CR2: 0000000000000000
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 10239edf86f1 ("net-qdisc-hhf: Heavy-Hitter Filter (HHF) qdisc")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit e89d469e3be3ed3d7124a803211a463ff83d0964
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:58 2017 +0300

    sch_multiq: fix double free on init failure
    
    The below commit added a call to ->destroy() on init failure, but multiq
    still frees ->queues on error in init, but ->queues is also freed by
    ->destroy() thus we get double free and corrupted memory.
    
    Very easy to reproduce (eth0 not multiqueue):
    $ tc qdisc add dev eth0 root multiq
    RTNETLINK answers: Operation not supported
    $ ip l add dumdum type dummy
    (crash)
    
    Trace log:
    [ 3929.467747] general protection fault: 0000 [#1] SMP
    [ 3929.468083] Modules linked in:
    [ 3929.468302] CPU: 3 PID: 967 Comm: ip Not tainted 4.13.0-rc6+ #56
    [ 3929.468625] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 3929.469124] task: ffff88003716a700 task.stack: ffff88005872c000
    [ 3929.469449] RIP: 0010:__kmalloc_track_caller+0x117/0x1be
    [ 3929.469746] RSP: 0018:ffff88005872f6a0 EFLAGS: 00010246
    [ 3929.470042] RAX: 00000000000002de RBX: 0000000058a59000 RCX: 00000000000002df
    [ 3929.470406] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff821f7020
    [ 3929.470770] RBP: ffff88005872f6e8 R08: 000000000001f010 R09: 0000000000000000
    [ 3929.471133] R10: ffff88005872f730 R11: 0000000000008cdd R12: ff006d75646d7564
    [ 3929.471496] R13: 00000000014000c0 R14: ffff88005b403c00 R15: ffff88005b403c00
    [ 3929.471869] FS:  00007f0b70480740(0000) GS:ffff88005d980000(0000) knlGS:0000000000000000
    [ 3929.472286] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 3929.472677] CR2: 00007ffcee4f3000 CR3: 0000000059d45000 CR4: 00000000000406e0
    [ 3929.473209] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 3929.474109] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 3929.474873] Call Trace:
    [ 3929.475337]  ? kstrdup_const+0x23/0x25
    [ 3929.475863]  kstrdup+0x2e/0x4b
    [ 3929.476338]  kstrdup_const+0x23/0x25
    [ 3929.478084]  __kernfs_new_node+0x28/0xbc
    [ 3929.478478]  kernfs_new_node+0x35/0x55
    [ 3929.478929]  kernfs_create_link+0x23/0x76
    [ 3929.479478]  sysfs_do_create_link_sd.isra.2+0x85/0xd7
    [ 3929.480096]  sysfs_create_link+0x33/0x35
    [ 3929.480649]  device_add+0x200/0x589
    [ 3929.481184]  netdev_register_kobject+0x7c/0x12f
    [ 3929.481711]  register_netdevice+0x373/0x471
    [ 3929.482174]  rtnl_newlink+0x614/0x729
    [ 3929.482610]  ? rtnl_newlink+0x17f/0x729
    [ 3929.483080]  rtnetlink_rcv_msg+0x188/0x197
    [ 3929.483533]  ? rcu_read_unlock+0x3e/0x5f
    [ 3929.483984]  ? rtnl_newlink+0x729/0x729
    [ 3929.484420]  netlink_rcv_skb+0x6c/0xce
    [ 3929.484858]  rtnetlink_rcv+0x23/0x2a
    [ 3929.485291]  netlink_unicast+0x103/0x181
    [ 3929.485735]  netlink_sendmsg+0x326/0x337
    [ 3929.486181]  sock_sendmsg_nosec+0x14/0x3f
    [ 3929.486614]  sock_sendmsg+0x29/0x2e
    [ 3929.486973]  ___sys_sendmsg+0x209/0x28b
    [ 3929.487340]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 3929.487719]  ? _raw_spin_unlock+0x27/0x31
    [ 3929.488092]  ? __handle_mm_fault+0x651/0xdb1
    [ 3929.488471]  ? check_chain_key+0xb0/0xfd
    [ 3929.488847]  __sys_sendmsg+0x45/0x63
    [ 3929.489206]  ? __sys_sendmsg+0x45/0x63
    [ 3929.489576]  SyS_sendmsg+0x19/0x1b
    [ 3929.489901]  entry_SYSCALL_64_fastpath+0x23/0xc2
    [ 3929.490172] RIP: 0033:0x7f0b6fb93690
    [ 3929.490423] RSP: 002b:00007ffcee4ed588 EFLAGS: 00000246 ORIG_RAX: 000000000000002e
    [ 3929.490881] RAX: ffffffffffffffda RBX: ffffffff810d278c RCX: 00007f0b6fb93690
    [ 3929.491198] RDX: 0000000000000000 RSI: 00007ffcee4ed5d0 RDI: 0000000000000003
    [ 3929.491521] RBP: ffff88005872ff98 R08: 0000000000000001 R09: 0000000000000000
    [ 3929.491801] R10: 00007ffcee4ed350 R11: 0000000000000246 R12: 0000000000000002
    [ 3929.492075] R13: 000000000066f1a0 R14: 00007ffcee4f5680 R15: 0000000000000000
    [ 3929.492352]  ? trace_hardirqs_off_caller+0xa7/0xcf
    [ 3929.492590] Code: 8b 45 c0 48 8b 45 b8 74 17 48 8b 4d c8 83 ca ff 44
    89 ee 4c 89 f7 e8 83 ca ff ff 49 89 c4 eb 49 49 63 56 20 48 8d 48 01 4d
    8b 06 <49> 8b 1c 14 48 89 c2 4c 89 e0 65 49 0f c7 08 0f 94 c0 83 f0 01
    [ 3929.493335] RIP: __kmalloc_track_caller+0x117/0x1be RSP: ffff88005872f6a0
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: f07d1501292b ("multiq: Further multiqueue cleanup")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 88c2ace69dbef696edba77712882af03879abc9c
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Wed Aug 30 12:48:57 2017 +0300

    sch_htb: fix crash on init failure
    
    The commit below added a call to the ->destroy() callback for all qdiscs
    which failed in their ->init(), but some were not prepared for such
    change and can't handle partially initialized qdisc. HTB is one of them
    and if any error occurs before the qdisc watchdog timer and qdisc work are
    initialized then we can hit either a null ptr deref (timer->base) when
    canceling in ->destroy or lockdep error info about trying to register
    a non-static key and a stack dump. So to fix these two move the watchdog
    timer and workqueue init before anything that can err out.
    To reproduce userspace needs to send broken htb qdisc create request,
    tested with a modified tc (q_htb.c).
    
    Trace log:
    [ 2710.897602] BUG: unable to handle kernel NULL pointer dereference at (null)
    [ 2710.897977] IP: hrtimer_active+0x17/0x8a
    [ 2710.898174] PGD 58fab067
    [ 2710.898175] P4D 58fab067
    [ 2710.898353] PUD 586c0067
    [ 2710.898531] PMD 0
    [ 2710.898710]
    [ 2710.899045] Oops: 0000 [#1] SMP
    [ 2710.899232] Modules linked in:
    [ 2710.899419] CPU: 1 PID: 950 Comm: tc Not tainted 4.13.0-rc6+ #54
    [ 2710.899646] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 2710.900035] task: ffff880059ed2700 task.stack: ffff88005ad4c000
    [ 2710.900262] RIP: 0010:hrtimer_active+0x17/0x8a
    [ 2710.900467] RSP: 0018:ffff88005ad4f960 EFLAGS: 00010246
    [ 2710.900684] RAX: 0000000000000000 RBX: ffff88003701e298 RCX: 0000000000000000
    [ 2710.900933] RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff88003701e298
    [ 2710.901177] RBP: ffff88005ad4f980 R08: 0000000000000001 R09: 0000000000000001
    [ 2710.901419] R10: ffff88005ad4f800 R11: 0000000000000400 R12: 0000000000000000
    [ 2710.901663] R13: ffff88003701e298 R14: ffffffff822a4540 R15: ffff88005ad4fac0
    [ 2710.901907] FS:  00007f2f5e90f740(0000) GS:ffff88005d880000(0000) knlGS:0000000000000000
    [ 2710.902277] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2710.902500] CR2: 0000000000000000 CR3: 0000000058ca3000 CR4: 00000000000406e0
    [ 2710.902744] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    [ 2710.902977] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400
    [ 2710.903180] Call Trace:
    [ 2710.903332]  hrtimer_try_to_cancel+0x1a/0x93
    [ 2710.903504]  hrtimer_cancel+0x15/0x20
    [ 2710.903667]  qdisc_watchdog_cancel+0x12/0x14
    [ 2710.903866]  htb_destroy+0x2e/0xf7
    [ 2710.904097]  qdisc_create+0x377/0x3fd
    [ 2710.904330]  tc_modify_qdisc+0x4d2/0x4fd
    [ 2710.904511]  rtnetlink_rcv_msg+0x188/0x197
    [ 2710.904682]  ? rcu_read_unlock+0x3e/0x5f
    [ 2710.904849]  ? rtnl_newlink+0x729/0x729
    [ 2710.905017]  netlink_rcv_skb+0x6c/0xce
    [ 2710.905183]  rtnetlink_rcv+0x23/0x2a
    [ 2710.905345]  netlink_unicast+0x103/0x181
    [ 2710.905511]  netlink_sendmsg+0x326/0x337
    [ 2710.905679]  sock_sendmsg_nosec+0x14/0x3f
    [ 2710.905847]  sock_sendmsg+0x29/0x2e
    [ 2710.906010]  ___sys_sendmsg+0x209/0x28b
    [ 2710.906176]  ? do_raw_spin_unlock+0xcd/0xf8
    [ 2710.906346]  ? _raw_spin_unlock+0x27/0x31
    [ 2710.906514]  ? __handle_mm_fault+0x651/0xdb1
    [ 2710.906685]  ? check_chain_key+0xb0/0xfd
    [ 2710.906855]  __sys_sendmsg+0x45/0x63
    [ 2710.907018]  ? __sys_sendmsg+0x45/0x63
    [ 2710.907185]  SyS_sendmsg+0x19/0x1b
    [ 2710.907344]  entry_SYSCALL_64_fastpath+0x23/0xc2
    
    Note that probably this bug goes further back because the default qdisc
    handling always calls ->destroy on init failure too.
    
    Fixes: 87b60cfacf9f ("net_sched: fix error recovery at qdisc creation")
    Fixes: 0fbbeb1ba43b ("[PKT_SCHED]: Fix missing qdisc_destroy() in qdisc_create_dflt()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 991ca84daa001193066554fa49f3a934746317d6
Author: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
Date:   Thu Aug 24 16:31:24 2017 +0200

    tipc: context imbalance at node read unlock
    
    If we fail to find a valid bearer in tipc_node_get_linkname(),
    node_read_unlock() is called without holding the node read lock.
    
    This commit fixes this error.
    
    Signed-off-by: Parthasarathy Bhuvaragan <parthasarathy.bhuvaragan@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6c7e983b220f89e03286dc70a41c7ef3a8b409df
Author: Bob Peterson <rpeterso@redhat.com>
Date:   Wed Aug 23 10:43:02 2017 -0400

    tipc: Fix tipc_sk_reinit handling of -EAGAIN
    
    In 9dbbfb0ab6680c6a85609041011484e6658e7d3c function tipc_sk_reinit
    had additional logic added to loop in the event that function
    rhashtable_walk_next() returned -EAGAIN. No worries.
    
    However, if rhashtable_walk_start returns -EAGAIN, it does "continue",
    and therefore skips the call to rhashtable_walk_stop(). That has
    the effect of calling rcu_read_lock() without its paired call to
    rcu_read_unlock(). Since rcu_read_lock() may be nested, the problem
    may not be apparent for a while, especially since resize events may
    be rare. But the comments to rhashtable_walk_start() state:
    
     * ...Note that we take the RCU lock in all
     * cases including when we return an error.  So you must always call
     * rhashtable_walk_stop to clean up.
    
    This patch replaces the continue with a goto and label to ensure a
    matching call to rhashtable_walk_stop().
    
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5a9a8eca7996d5947905f853ab0c6717b4f2b7a0
Author: Stephen Barber <smbarber@chromium.org>
Date:   Thu Aug 17 15:17:46 2017 -0700

    ALSA: usb-audio: don't retry snd_usb_ctl_msg after timeout
    
    A few calls to snd_usb_ctl_msg wrap the function in a retry loop. In
    the worst case, the timeout for snd_usb_ctl_msg is 5 seconds, which when
    retried 10 times (for example, if a device is removed) could cause a
    probe to hang for ~50 seconds.
    
    Example stack trace from 3.14 which triggered a hung task timeout:
    Call Trace:
     [<ffffffffa2c1f720>] ? inet6_set_link_af.part.35+0x12/0x12
     [<ffffffffa2c20309>] schedule+0x6e/0x70
     [<ffffffffa2c1f81c>] schedule_timeout+0xfc/0x13c
     [<ffffffffa2667bbc>] ? rcu_read_unlock_sched_notrace+0x17/0x17
     [<ffffffffa2c20d68>] __wait_for_common+0x153/0x190
     [<ffffffffa2c20d68>] ? __wait_for_common+0x153/0x190
     [<ffffffffa26890e5>] ? wake_up_state+0x12/0x12
     [<ffffffffa2c20e0e>] wait_for_completion_timeout+0x1d/0x1f
     [<ffffffffa2a07c70>] usb_start_wait_urb+0x93/0xf1
     [<ffffffffa2a07daf>] usb_control_msg+0xe1/0x11d
     [<ffffffffc02cd254>] snd_usb_ctl_msg+0x9c/0xf1 [snd_usb_audio]
     [<ffffffffc02ce191>] snd_usb_mixer_set_ctl_value+0x124/0xab1 [snd_usb_audio]
     [<ffffffffc02ce230>] snd_usb_mixer_set_ctl_value+0x1c3/0xab1 [snd_usb_audio]
     [<ffffffffc02ce58e>] snd_usb_mixer_set_ctl_value+0x521/0xab1 [snd_usb_audio]
     [<ffffffffc02cee88>] snd_usb_mixer_add_control+0x36a/0x1264 [snd_usb_audio]
     [<ffffffffc02cf323>] snd_usb_mixer_add_control+0x805/0x1264 [snd_usb_audio]
     [<ffffffffa2a06e11>] ? usb_free_urb+0x1a/0x1c
     [<ffffffffc02cfcf7>] snd_usb_mixer_add_control+0x11d9/0x1264 [snd_usb_audio]
     [<ffffffffc02d000f>] snd_usb_create_mixer+0xbc/0x286 [snd_usb_audio]
     [<ffffffffc02cac18>] 0xffffffffc02cac17
     [<ffffffffa2a0aaf1>] usb_probe_interface+0x17c/0x21c
     [<ffffffffa29a65bc>] driver_probe_device+0xae/0x1fa
     [<ffffffffa29a6767>] __device_attach_driver+0x5f/0x66
     [<ffffffffa29a6708>] ? driver_probe_device+0x1fa/0x1fa
     [<ffffffffa29a4a60>] bus_for_each_drv+0x87/0xaa
     [<ffffffffa29a688a>] __device_attach+0x9d/0x101
     [<ffffffffa29a6913>] device_initial_probe+0x13/0x15
     [<ffffffffa29a5ae6>] bus_probe_device+0x33/0x96
     [<ffffffffa29a3d19>] device_add+0x328/0x547
     [<ffffffffa2a09355>] usb_set_configuration+0x624/0x674
     [<ffffffffa2a11949>] generic_probe+0x45/0x77
     [<ffffffffa2a0a962>] usb_probe_device+0x2d/0x40
     [<ffffffffa29a65bc>] driver_probe_device+0xae/0x1fa
     [<ffffffffa29a6767>] __device_attach_driver+0x5f/0x66
     [<ffffffffa29a6708>] ? driver_probe_device+0x1fa/0x1fa
     [<ffffffffa29a4a60>] bus_for_each_drv+0x87/0xaa
     [<ffffffffa29a688a>] __device_attach+0x9d/0x101
     [<ffffffffa29a6913>] device_initial_probe+0x13/0x15
     [<ffffffffa29a5ae6>] bus_probe_device+0x33/0x96
     [<ffffffffa29a3d19>] device_add+0x328/0x547
     [<ffffffffa29030bc>] ? add_device_randomness+0x111/0x130
     [<ffffffffa2a00967>] usb_new_device+0x2a2/0x3c0
     [<ffffffffa2a02ddc>] hub_thread+0xa3d/0xeed
     [<ffffffffa2c2010d>] ? __schedule+0x41e/0x5ac
     [<ffffffffa26957ce>] ? finish_wait+0x62/0x62
     [<ffffffffa2a0239f>] ? usb_reset_device+0x16a/0x16a
     [<ffffffffa267b255>] kthread+0x108/0x110
     [<ffffffffa267b14d>] ? __kthread_parkme+0x67/0x67
     [<ffffffffa2c23b2c>] ret_from_fork+0x7c/0xb0
     [<ffffffffa267b14d>] ? __kthread_parkme+0x67/0x67
    
    Signed-off-by: Stephen Barber <smbarber@chromium.org>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>

commit c5ebe66ce774126b888617cab658f6556d23365e
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Jun 19 10:32:23 2017 -0700

    rcu: Add event tracing to ->gp_tasks update at GP start
    
    There is currently event tracing to track when a task is preempted
    within a preemptible RCU read-side critical section, and also when that
    task subsequently reaches its outermost rcu_read_unlock(), but none
    indicating when a new grace period starts when that grace period must
    wait on pre-existing readers that have been been preempted at least once
    since the beginning of their current RCU read-side critical sections.
    
    This commit therefore adds an event trace at grace-period start in
    the case where there are such readers.  Note that only the first
    reader in the list is traced.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

commit 6f1b77b21fd5fb90c47a3603c2b5992c62ac7449
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    
    [ Upstream commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a ]
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2bac20a4ae9ce90e187ce15cca51c242ee5b2ca3
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    
    [ Upstream commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a ]
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cc6f1486f2cb053a647db3a51cba5fbeabaa4a3f
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    
    [ Upstream commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a ]
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2e50111fedaff324f26d42c2cfa5504dd69279a8
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    
    [ Upstream commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a ]
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0515480ad424f2d6853ffe448f444ba3c756c057
Author: Andreas Gruenbacher <agruenba@redhat.com>
Date:   Tue Aug 1 11:18:26 2017 -0500

    gfs2: gfs2_glock_get: Wait on freeing glocks
    
    Keep glocks in their hash table until they are freed instead of removing
    them when their last reference is dropped.  This allows to wait for any
    previous instances of a glock to go away in gfs2_glock_get before
    creating a new glocks.
    
    Special thanks to Andy Price for finding and fixing a problem which also
    required us to delete the rcu_read_unlock from the error case in function
    gfs2_glock_get.
    
    Signed-off-by: Andreas Gruenbacher <agruenba@redhat.com>
    Signed-off-by: Bob Peterson <rpeterso@redhat.com>

commit 114571a8a2bca1b418dab9b0391c42de521ed753
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jul 6 15:31:46 2017 +0100

    Btrfs: incremental send, fix invalid memory access
    
    commit 24e52b11e0ca788513b945a87b57cc0522a92933 upstream.
    
    When doing an incremental send, while processing an extent that changed
    between the parent and send snapshots and that extent was an inline extent
    in the parent snapshot, it's possible to access a memory region beyond
    the end of leaf if the inline extent is very small and it is the first
    item in a leaf.
    
    An example scenario is described below.
    
    The send snapshot has the following leaf:
    
     leaf 33865728 items 33 free space 773 generation 46 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            (...)
            item 14 key (335 EXTENT_DATA 0) itemoff 3052 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 12791808 nr 4096
                    extent data offset 0 nr 4096 ram 4096
                    extent compression 0 (none)
            item 15 key (335 EXTENT_DATA 8192) itemoff 2999 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 138170368 nr 225280
                    extent data offset 0 nr 225280 ram 225280
                    extent compression 0 (none)
            (...)
    
    And the parent snapshot has the following leaf:
    
     leaf 31272960 items 17 free space 17 generation 31 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            item 0 key (335 EXTENT_DATA 0) itemoff 3951 itemsize 44
                    generation 31 type 0 (inline)
                    inline extent data size 23 ram_bytes 613 compression 1 (zlib)
            (...)
    
    When computing the send stream, it is detected that the extent of inode
    335, at file offset 0, and at fs/btrfs/send.c:is_extent_unchanged() we
    grab the leaf from the parent snapshot and access the inline extent item.
    However, before jumping to the 'out' label, we access the 'offset' and
    'disk_bytenr' fields of the extent item, which should not be done for
    inline extents since the inlined data starts at the offset of the
    'disk_bytenr' field and can be very small. For example accessing the
    'offset' field of the file extent item results in the following trace:
    
    [  599.705368] general protection fault: 0000 [#1] PREEMPT SMP
    [  599.706296] Modules linked in: btrfs psmouse i2c_piix4 ppdev acpi_cpufreq serio_raw parport_pc i2c_core evdev tpm_tis tpm_tis_core sg pcspkr parport tpm button su$
    [  599.709340] CPU: 7 PID: 5283 Comm: btrfs Not tainted 4.10.0-rc8-btrfs-next-46+ #1
    [  599.709340] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  599.709340] task: ffff88023eedd040 task.stack: ffffc90006658000
    [  599.709340] RIP: 0010:read_extent_buffer+0xdb/0xf4 [btrfs]
    [  599.709340] RSP: 0018:ffffc9000665ba00 EFLAGS: 00010286
    [  599.709340] RAX: db73880000000000 RBX: 0000000000000000 RCX: 0000000000000001
    [  599.709340] RDX: ffffc9000665ba60 RSI: db73880000000000 RDI: ffffc9000665ba5f
    [  599.709340] RBP: ffffc9000665ba30 R08: 0000000000000001 R09: ffff88020dc5e098
    [  599.709340] R10: 0000000000001000 R11: 0000160000000000 R12: 6db6db6db6db6db7
    [  599.709340] R13: ffff880000000000 R14: 0000000000000000 R15: ffff88020dc5e088
    [  599.709340] FS:  00007f519555a8c0(0000) GS:ffff88023f3c0000(0000) knlGS:0000000000000000
    [  599.709340] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  599.709340] CR2: 00007f1411afd000 CR3: 0000000235f8e000 CR4: 00000000000006e0
    [  599.709340] Call Trace:
    [  599.709340]  btrfs_get_token_64+0x93/0xce [btrfs]
    [  599.709340]  ? printk+0x48/0x50
    [  599.709340]  btrfs_get_64+0xb/0xd [btrfs]
    [  599.709340]  process_extent+0x3a1/0x1106 [btrfs]
    [  599.709340]  ? btree_read_extent_buffer_pages+0x5/0xef [btrfs]
    [  599.709340]  changed_cb+0xb03/0xb3d [btrfs]
    [  599.709340]  ? btrfs_get_token_32+0x7a/0xcc [btrfs]
    [  599.709340]  btrfs_compare_trees+0x432/0x53d [btrfs]
    [  599.709340]  ? process_extent+0x1106/0x1106 [btrfs]
    [  599.709340]  btrfs_ioctl_send+0x960/0xe26 [btrfs]
    [  599.709340]  btrfs_ioctl+0x181b/0x1fed [btrfs]
    [  599.709340]  ? trace_hardirqs_on_caller+0x150/0x1ac
    [  599.709340]  vfs_ioctl+0x21/0x38
    [  599.709340]  ? vfs_ioctl+0x21/0x38
    [  599.709340]  do_vfs_ioctl+0x611/0x645
    [  599.709340]  ? rcu_read_unlock+0x5b/0x5d
    [  599.709340]  ? __fget+0x6d/0x79
    [  599.709340]  SyS_ioctl+0x57/0x7b
    [  599.709340]  entry_SYSCALL_64_fastpath+0x18/0xad
    [  599.709340] RIP: 0033:0x7f51945eec47
    [  599.709340] RSP: 002b:00007ffc21c13e98 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
    [  599.709340] RAX: ffffffffffffffda RBX: ffffffff81096459 RCX: 00007f51945eec47
    [  599.709340] RDX: 00007ffc21c13f20 RSI: 0000000040489426 RDI: 0000000000000004
    [  599.709340] RBP: ffffc9000665bf98 R08: 00007f519450d700 R09: 00007f519450d700
    [  599.709340] R10: 00007f519450d9d0 R11: 0000000000000202 R12: 0000000000000046
    [  599.709340] R13: ffffc9000665bf78 R14: 0000000000000000 R15: 00007f5195574040
    [  599.709340]  ? trace_hardirqs_off_caller+0x43/0xb1
    [  599.709340] Code: 29 f0 49 39 d8 4c 0f 47 c3 49 03 81 58 01 00 00 44 89 c1 4c 01 c2 4c 29 c3 48 c1 f8 03 49 0f af c4 48 c1 e0 0c 4c 01 e8 48 01 c6 <f3> a4 31 f6 4$
    [  599.709340] RIP: read_extent_buffer+0xdb/0xf4 [btrfs] RSP: ffffc9000665ba00
    [  599.762057] ---[ end trace fe00d7af61b9f49e ]---
    
    This is because the 'offset' field starts at an offset of 37 bytes
    (offsetof(struct btrfs_file_extent_item, offset)), has a length of 8
    bytes and therefore attemping to read it causes a 1 byte access beyond
    the end of the leaf, as the first item's content in a leaf is located
    at the tail of the leaf, the item size is 44 bytes and the offset of
    that field plus its length (37 + 8 = 45) goes beyond the item's size
    by 1 byte.
    
    So fix this by accessing the 'offset' and 'disk_bytenr' fields after
    jumping to the 'out' label if we are processing an inline extent. We
    move the reading operation of the 'disk_bytenr' field too because we
    have the same problem as for the 'offset' field explained above when
    the inline data is less then 8 bytes. The access to the 'generation'
    field is also moved but just for the sake of grouping access to all
    the fields.
    
    Fixes: e1cbfd7bf6da ("Btrfs: send, fix file hole not being preserved due to inline extent")
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5e741fa9e9698f4010bb85eff252186f7a4071f4
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Jun 6 12:52:44 2017 -0700

    rcutorture: Enable SRCU readers from timer handler
    
    Now that it is legal to invoke srcu_read_lock() and srcu_read_unlock()
    for a given srcu_struct from both process context and {soft,}irq
    handlers, it is time to test it.  This commit therefore enables
    testing of SRCU readers from rcutorture's timer handler, using in_task()
    to determine whether or not it is safe to sleep in the SRCU read-side
    critical sections.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 0b35f6031a00329800bacc04085188c300c3a4d8
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Wed Jul 19 14:27:33 2017 +0900

    netfilter: Remove duplicated rcu_read_lock.
    
    This patch removes duplicate rcu_read_lock().
    
    1. IPVS part:
    
    According to Julian Anastasov's mention, contexts of ipvs are described
    at: http://marc.info/?l=netfilter-devel&m=149562884514072&w=2, in summary:
    
     - packet RX/TX: does not need locks because packets come from hooks.
     - sync msg RX: backup server uses RCU locks while registering new
       connections.
     - ip_vs_ctl.c: configuration get/set, RCU locks needed.
     - xt_ipvs.c: It is a netfilter match, running from hook context.
    
    As result, rcu_read_lock and rcu_read_unlock can be removed from:
    
     - ip_vs_core.c: all
     - ip_vs_ctl.c:
       - only from ip_vs_has_real_service
     - ip_vs_ftp.c: all
     - ip_vs_proto_sctp.c: all
     - ip_vs_proto_tcp.c: all
     - ip_vs_proto_udp.c: all
     - ip_vs_xmit.c: all (contains only packet processing)
    
    2. Netfilter part:
    
    There are three types of functions that are guaranteed the rcu_read_lock().
    First, as result, functions are only called by nf_hook():
    
     - nf_conntrack_broadcast_help(), pptp_expectfn(), set_expected_rtp_rtcp().
     - tcpmss_reverse_mtu(), tproxy_laddr4(), tproxy_laddr6().
     - match_lookup_rt6(), check_hlist(), hashlimit_mt_common().
     - xt_osf_match_packet().
    
    Second, functions that caller already held the rcu_read_lock().
     - destroy_conntrack(), ctnetlink_conntrack_event().
     - ctnl_timeout_find_get(), nfqnl_nf_hook_drop().
    
    Third, functions that are mixed with type1 and type2.
    
    These functions are called by nf_hook() also these are called by
    ordinary functions that already held the rcu_read_lock():
    
     - __ctnetlink_glue_build(), ctnetlink_expect_event().
     - ctnetlink_proto_size().
    
    Applied files are below:
    
    - nf_conntrack_broadcast.c, nf_conntrack_core.c, nf_conntrack_netlink.c.
    - nf_conntrack_pptp.c, nf_conntrack_sip.c, nfnetlink_cttimeout.c.
    - nfnetlink_queue.c, xt_TCPMSS.c, xt_TPROXY.c, xt_addrtype.c.
    - xt_connlimit.c, xt_hashlimit.c, xt_osf.c
    
    Detailed calltrace can be found at:
    http://marc.info/?l=netfilter-devel&m=149667610710350&w=2
    
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Acked-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit b1f5bfc27a19f214006b9b4db7b9126df2dfdf5a
Author: Alexander Potapenko <glider@google.com>
Date:   Fri Jul 14 18:32:45 2017 +0200

    sctp: don't dereference ptr before leaving _sctp_walk_{params, errors}()
    
    If the length field of the iterator (|pos.p| or |err|) is past the end
    of the chunk, we shouldn't access it.
    
    This bug has been detected by KMSAN. For the following pair of system
    calls:
    
      socket(PF_INET6, SOCK_STREAM, 0x84 /* IPPROTO_??? */) = 3
      sendto(3, "A", 1, MSG_OOB, {sa_family=AF_INET6, sin6_port=htons(0),
             inet_pton(AF_INET6, "::1", &sin6_addr), sin6_flowinfo=0,
             sin6_scope_id=0}, 28) = 1
    
    the tool has reported a use of uninitialized memory:
    
      ==================================================================
      BUG: KMSAN: use of uninitialized memory in sctp_rcv+0x17b8/0x43b0
      CPU: 1 PID: 2940 Comm: probe Not tainted 4.11.0-rc5+ #2926
      Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
      01/01/2011
      Call Trace:
       <IRQ>
       __dump_stack lib/dump_stack.c:16
       dump_stack+0x172/0x1c0 lib/dump_stack.c:52
       kmsan_report+0x12a/0x180 mm/kmsan/kmsan.c:927
       __msan_warning_32+0x61/0xb0 mm/kmsan/kmsan_instr.c:469
       __sctp_rcv_init_lookup net/sctp/input.c:1074
       __sctp_rcv_lookup_harder net/sctp/input.c:1233
       __sctp_rcv_lookup net/sctp/input.c:1255
       sctp_rcv+0x17b8/0x43b0 net/sctp/input.c:170
       sctp6_rcv+0x32/0x70 net/sctp/ipv6.c:984
       ip6_input_finish+0x82f/0x1ee0 net/ipv6/ip6_input.c:279
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_input+0x239/0x290 net/ipv6/ip6_input.c:322
       dst_input ./include/net/dst.h:492
       ip6_rcv_finish net/ipv6/ip6_input.c:69
       NF_HOOK ./include/linux/netfilter.h:257
       ipv6_rcv+0x1dbd/0x22e0 net/ipv6/ip6_input.c:203
       __netif_receive_skb_core+0x2f6f/0x3a20 net/core/dev.c:4208
       __netif_receive_skb net/core/dev.c:4246
       process_backlog+0x667/0xba0 net/core/dev.c:4866
       napi_poll net/core/dev.c:5268
       net_rx_action+0xc95/0x1590 net/core/dev.c:5333
       __do_softirq+0x485/0x942 kernel/softirq.c:284
       do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
       </IRQ>
       do_softirq kernel/softirq.c:328
       __local_bh_enable_ip+0x25b/0x290 kernel/softirq.c:181
       local_bh_enable+0x37/0x40 ./include/linux/bottom_half.h:31
       rcu_read_unlock_bh ./include/linux/rcupdate.h:931
       ip6_finish_output2+0x19b2/0x1cf0 net/ipv6/ip6_output.c:124
       ip6_finish_output+0x764/0x970 net/ipv6/ip6_output.c:149
       NF_HOOK_COND ./include/linux/netfilter.h:246
       ip6_output+0x456/0x520 net/ipv6/ip6_output.c:163
       dst_output ./include/net/dst.h:486
       NF_HOOK ./include/linux/netfilter.h:257
       ip6_xmit+0x1841/0x1c00 net/ipv6/ip6_output.c:261
       sctp_v6_xmit+0x3b7/0x470 net/sctp/ipv6.c:225
       sctp_packet_transmit+0x38cb/0x3a20 net/sctp/output.c:632
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       entry_SYSCALL64_slow_path+0x25/0x25 arch/x86/entry/entry_64.S:246
      RIP: 0033:0x401133
      RSP: 002b:00007fff6d99cd38 EFLAGS: 00000246 ORIG_RAX: 000000000000002c
      RAX: ffffffffffffffda RBX: 00000000004002b0 RCX: 0000000000401133
      RDX: 0000000000000001 RSI: 0000000000494088 RDI: 0000000000000003
      RBP: 00007fff6d99cd90 R08: 00007fff6d99cd50 R09: 000000000000001c
      R10: 0000000000000001 R11: 0000000000000246 R12: 0000000000000000
      R13: 00000000004063d0 R14: 0000000000406460 R15: 0000000000000000
      origin:
       save_stack_trace+0x37/0x40 arch/x86/kernel/stacktrace.c:59
       kmsan_save_stack_with_flags mm/kmsan/kmsan.c:302
       kmsan_internal_poison_shadow+0xb1/0x1a0 mm/kmsan/kmsan.c:198
       kmsan_poison_shadow+0x6d/0xc0 mm/kmsan/kmsan.c:211
       slab_alloc_node mm/slub.c:2743
       __kmalloc_node_track_caller+0x200/0x360 mm/slub.c:4351
       __kmalloc_reserve net/core/skbuff.c:138
       __alloc_skb+0x26b/0x840 net/core/skbuff.c:231
       alloc_skb ./include/linux/skbuff.h:933
       sctp_packet_transmit+0x31e/0x3a20 net/sctp/output.c:570
       sctp_outq_flush+0xeb3/0x46e0 net/sctp/outqueue.c:885
       sctp_outq_uncork+0xb2/0xd0 net/sctp/outqueue.c:750
       sctp_side_effects net/sctp/sm_sideeffect.c:1773
       sctp_do_sm+0x6962/0x6ec0 net/sctp/sm_sideeffect.c:1147
       sctp_primitive_ASSOCIATE+0x12c/0x160 net/sctp/primitive.c:88
       sctp_sendmsg+0x43e5/0x4f90 net/sctp/socket.c:1954
       inet_sendmsg+0x498/0x670 net/ipv4/af_inet.c:762
       sock_sendmsg_nosec net/socket.c:633
       sock_sendmsg net/socket.c:643
       SYSC_sendto+0x608/0x710 net/socket.c:1696
       SyS_sendto+0x8a/0xb0 net/socket.c:1664
       do_syscall_64+0xe6/0x130 arch/x86/entry/common.c:285
       return_from_SYSCALL_64+0x0/0x6a arch/x86/entry/entry_64.S:246
      ==================================================================
    
    Signed-off-by: Alexander Potapenko <glider@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 24e52b11e0ca788513b945a87b57cc0522a92933
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Jul 6 15:31:46 2017 +0100

    Btrfs: incremental send, fix invalid memory access
    
    When doing an incremental send, while processing an extent that changed
    between the parent and send snapshots and that extent was an inline extent
    in the parent snapshot, it's possible to access a memory region beyond
    the end of leaf if the inline extent is very small and it is the first
    item in a leaf.
    
    An example scenario is described below.
    
    The send snapshot has the following leaf:
    
     leaf 33865728 items 33 free space 773 generation 46 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            (...)
            item 14 key (335 EXTENT_DATA 0) itemoff 3052 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 12791808 nr 4096
                    extent data offset 0 nr 4096 ram 4096
                    extent compression 0 (none)
            item 15 key (335 EXTENT_DATA 8192) itemoff 2999 itemsize 53
                    generation 36 type 1 (regular)
                    extent data disk byte 138170368 nr 225280
                    extent data offset 0 nr 225280 ram 225280
                    extent compression 0 (none)
            (...)
    
    And the parent snapshot has the following leaf:
    
     leaf 31272960 items 17 free space 17 generation 31 owner 5
     fs uuid ab7090d8-dafd-4fb9-9246-723b6d2e2fb7
     chunk uuid 2d16478c-c704-4ab9-b574-68bff2281b1f
            item 0 key (335 EXTENT_DATA 0) itemoff 3951 itemsize 44
                    generation 31 type 0 (inline)
                    inline extent data size 23 ram_bytes 613 compression 1 (zlib)
            (...)
    
    When computing the send stream, it is detected that the extent of inode
    335, at file offset 0, and at fs/btrfs/send.c:is_extent_unchanged() we
    grab the leaf from the parent snapshot and access the inline extent item.
    However, before jumping to the 'out' label, we access the 'offset' and
    'disk_bytenr' fields of the extent item, which should not be done for
    inline extents since the inlined data starts at the offset of the
    'disk_bytenr' field and can be very small. For example accessing the
    'offset' field of the file extent item results in the following trace:
    
    [  599.705368] general protection fault: 0000 [#1] PREEMPT SMP
    [  599.706296] Modules linked in: btrfs psmouse i2c_piix4 ppdev acpi_cpufreq serio_raw parport_pc i2c_core evdev tpm_tis tpm_tis_core sg pcspkr parport tpm button su$
    [  599.709340] CPU: 7 PID: 5283 Comm: btrfs Not tainted 4.10.0-rc8-btrfs-next-46+ #1
    [  599.709340] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.1-0-gb3ef39f-prebuilt.qemu-project.org 04/01/2014
    [  599.709340] task: ffff88023eedd040 task.stack: ffffc90006658000
    [  599.709340] RIP: 0010:read_extent_buffer+0xdb/0xf4 [btrfs]
    [  599.709340] RSP: 0018:ffffc9000665ba00 EFLAGS: 00010286
    [  599.709340] RAX: db73880000000000 RBX: 0000000000000000 RCX: 0000000000000001
    [  599.709340] RDX: ffffc9000665ba60 RSI: db73880000000000 RDI: ffffc9000665ba5f
    [  599.709340] RBP: ffffc9000665ba30 R08: 0000000000000001 R09: ffff88020dc5e098
    [  599.709340] R10: 0000000000001000 R11: 0000160000000000 R12: 6db6db6db6db6db7
    [  599.709340] R13: ffff880000000000 R14: 0000000000000000 R15: ffff88020dc5e088
    [  599.709340] FS:  00007f519555a8c0(0000) GS:ffff88023f3c0000(0000) knlGS:0000000000000000
    [  599.709340] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  599.709340] CR2: 00007f1411afd000 CR3: 0000000235f8e000 CR4: 00000000000006e0
    [  599.709340] Call Trace:
    [  599.709340]  btrfs_get_token_64+0x93/0xce [btrfs]
    [  599.709340]  ? printk+0x48/0x50
    [  599.709340]  btrfs_get_64+0xb/0xd [btrfs]
    [  599.709340]  process_extent+0x3a1/0x1106 [btrfs]
    [  599.709340]  ? btree_read_extent_buffer_pages+0x5/0xef [btrfs]
    [  599.709340]  changed_cb+0xb03/0xb3d [btrfs]
    [  599.709340]  ? btrfs_get_token_32+0x7a/0xcc [btrfs]
    [  599.709340]  btrfs_compare_trees+0x432/0x53d [btrfs]
    [  599.709340]  ? process_extent+0x1106/0x1106 [btrfs]
    [  599.709340]  btrfs_ioctl_send+0x960/0xe26 [btrfs]
    [  599.709340]  btrfs_ioctl+0x181b/0x1fed [btrfs]
    [  599.709340]  ? trace_hardirqs_on_caller+0x150/0x1ac
    [  599.709340]  vfs_ioctl+0x21/0x38
    [  599.709340]  ? vfs_ioctl+0x21/0x38
    [  599.709340]  do_vfs_ioctl+0x611/0x645
    [  599.709340]  ? rcu_read_unlock+0x5b/0x5d
    [  599.709340]  ? __fget+0x6d/0x79
    [  599.709340]  SyS_ioctl+0x57/0x7b
    [  599.709340]  entry_SYSCALL_64_fastpath+0x18/0xad
    [  599.709340] RIP: 0033:0x7f51945eec47
    [  599.709340] RSP: 002b:00007ffc21c13e98 EFLAGS: 00000202 ORIG_RAX: 0000000000000010
    [  599.709340] RAX: ffffffffffffffda RBX: ffffffff81096459 RCX: 00007f51945eec47
    [  599.709340] RDX: 00007ffc21c13f20 RSI: 0000000040489426 RDI: 0000000000000004
    [  599.709340] RBP: ffffc9000665bf98 R08: 00007f519450d700 R09: 00007f519450d700
    [  599.709340] R10: 00007f519450d9d0 R11: 0000000000000202 R12: 0000000000000046
    [  599.709340] R13: ffffc9000665bf78 R14: 0000000000000000 R15: 00007f5195574040
    [  599.709340]  ? trace_hardirqs_off_caller+0x43/0xb1
    [  599.709340] Code: 29 f0 49 39 d8 4c 0f 47 c3 49 03 81 58 01 00 00 44 89 c1 4c 01 c2 4c 29 c3 48 c1 f8 03 49 0f af c4 48 c1 e0 0c 4c 01 e8 48 01 c6 <f3> a4 31 f6 4$
    [  599.709340] RIP: read_extent_buffer+0xdb/0xf4 [btrfs] RSP: ffffc9000665ba00
    [  599.762057] ---[ end trace fe00d7af61b9f49e ]---
    
    This is because the 'offset' field starts at an offset of 37 bytes
    (offsetof(struct btrfs_file_extent_item, offset)), has a length of 8
    bytes and therefore attemping to read it causes a 1 byte access beyond
    the end of the leaf, as the first item's content in a leaf is located
    at the tail of the leaf, the item size is 44 bytes and the offset of
    that field plus its length (37 + 8 = 45) goes beyond the item's size
    by 1 byte.
    
    So fix this by accessing the 'offset' and 'disk_bytenr' fields after
    jumping to the 'out' label if we are processing an inline extent. We
    move the reading operation of the 'disk_bytenr' field too because we
    have the same problem as for the 'offset' field explained above when
    the inline data is less then 8 bytes. The access to the 'generation'
    field is also moved but just for the sake of grouping access to all
    the fields.
    
    Fixes: e1cbfd7bf6da ("Btrfs: send, fix file hole not being preserved due to inline extent")
    Cc: <stable@vger.kernel.org>  # v4.12+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

commit 842c08846420baa619fe3cb8c9af538efdb89428
Author: Petr Mladek <pmladek@suse.com>
Date:   Wed Jun 14 10:54:52 2017 +0200

    livepatch: Fix stacking of patches with respect to RCU
    
    rcu_read_(un)lock(), list_*_rcu(), and synchronize_rcu() are used for a secure
    access and manipulation of the list of patches that modify the same function.
    In particular, it is the variable func_stack that is accessible from the ftrace
    handler via struct ftrace_ops and klp_ops.
    
    Of course, it synchronizes also some states of the patch on the top of the
    stack, e.g. func->transition in klp_ftrace_handler.
    
    At the same time, this mechanism guards also the manipulation of
    task->patch_state. It is modified according to the state of the transition and
    the state of the process.
    
    Now, all this works well as long as RCU works well. Sadly livepatching might
    get into some corner cases when this is not true. For example, RCU is not
    watching when rcu_read_lock() is taken in idle threads.  It is because they
    might sleep and prevent reaching the grace period for too long.
    
    There are ways how to make RCU watching even in idle threads, see
    rcu_irq_enter(). But there is a small location inside RCU infrastructure when
    even this does not work.
    
    This small problematic location can be detected either before calling
    rcu_irq_enter() by rcu_irq_enter_disabled() or later by rcu_is_watching().
    Sadly, there is no safe way how to handle it.  Once we detect that RCU was not
    watching, we might see inconsistent state of the function stack and the related
    variables in klp_ftrace_handler(). Then we could do a wrong decision, use an
    incompatible implementation of the function and break the consistency of the
    system. We could warn but we could not avoid the damage.
    
    Fortunately, ftrace has similar problems and they seem to be solved well there.
    It uses a heavy weight implementation of some RCU operations. In particular, it
    replaces:
    
      + rcu_read_lock() with preempt_disable_notrace()
      + rcu_read_unlock() with preempt_enable_notrace()
      + synchronize_rcu() with schedule_on_each_cpu(sync_work)
    
    My understanding is that this is RCU implementation from a stone age. It meets
    the core RCU requirements but it is rather ineffective. Especially, it does not
    allow to batch or speed up the synchronize calls.
    
    On the other hand, it is very trivial. It allows to safely trace and/or
    livepatch even the RCU core infrastructure.  And the effectiveness is a not a
    big issue because using ftrace or livepatches on productive systems is a rare
    operation.  The safety is much more important than a negligible extra load.
    
    Note that the alternative implementation follows the RCU principles. Therefore,
         we could and actually must use list_*_rcu() variants when manipulating the
         func_stack.  These functions allow to access the pointers in the right
         order and with the right barriers. But they do not use any other
         information that would be set only by rcu_read_lock().
    
    Also note that there are actually two problems solved in ftrace:
    
    First, it cares about the consistency of RCU read sections.  It is being solved
    the way as described and used in this patch.
    
    Second, ftrace needs to make sure that nobody is inside the dynamic trampoline
    when it is being freed. For this, it also calls synchronize_rcu_tasks() in
    preemptive kernel in ftrace_shutdown().
    
    Livepatch has similar problem but it is solved by ftrace for free.
    klp_ftrace_handler() is a good guy and never sleeps. In addition, it is
    registered with FTRACE_OPS_FL_DYNAMIC. It causes that
    unregister_ftrace_function() calls:
    
            * schedule_on_each_cpu(ftrace_sync) - always
            * synchronize_rcu_tasks() - in preemptive kernel
    
    The effect is that nobody is neither inside the dynamic trampoline nor inside
    the ftrace handler after unregister_ftrace_function() returns.
    
    [jkosina@suse.cz: reformat changelog, fix comment]
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Acked-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

commit 78b83e8b12b4467540ca501c7c019e9d46051957
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Sun Jun 18 23:23:01 2017 +0900

    perf ftrace: Add option for function filtering
    
    The -T/--trace-funcs and -N/--notrace-funcs options are to specify
    functions to enable/disable tracing dynamically.
    
    The -G/--graph-funcs and -g/--nograph-funcs options are to set filters
    for function graph tracer.
    
    For example, to trace fault handling functions only:
    
      $ sudo perf ftrace -T *fault hello
       0)               |  __do_page_fault() {
       0)               |    handle_mm_fault() {
       0)   2.117 us    |      __handle_mm_fault();
       0)   3.627 us    |    }
       0)   7.811 us    |  }
       0)               |  __do_page_fault() {
       0)               |    handle_mm_fault() {
       0)   2.014 us    |      __handle_mm_fault();
       0)   2.424 us    |    }
       0)   2.951 us    |  }
       ...
    
    To trace all functions executed in __do_page_fault:
    
      $ sudo perf ftrace -G __do_page_fault hello
       2)               |  __do_page_fault() {
       3)   0.060 us    |    down_read_trylock();
       3)               |    find_vma() {
       3)   0.075 us    |      vmacache_find();
       3)   0.053 us    |      vmacache_update();
       3)   1.246 us    |    }
       3)               |    handle_mm_fault() {
       3)   0.063 us    |      __rcu_read_lock();
       3)   0.056 us    |      mem_cgroup_from_task();
       3)   0.057 us    |      __rcu_read_unlock();
       3)               |      __handle_mm_fault() {
       3)               |        filemap_map_pages() {
       3)   0.058 us    |          __rcu_read_lock();
       3)               |          alloc_set_pte() {
       ...
    
    But don't want to show details in handle_mm_fault:
    
      $ sudo perf ftrace -G __do_page_fault -g handle_mm_fault hello
       3)               |  __do_page_fault() {
       3)   0.049 us    |    down_read_trylock();
       3)               |    find_vma() {
       3)   0.048 us    |      vmacache_find();
       3)   0.041 us    |      vmacache_update();
       3)   0.680 us    |    }
       3)   0.036 us    |    up_read();
       3)   4.547 us    |  } /* __do_page_fault */
       ...
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Masami Hiramatsu <mhiramat@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: kernel-team@lge.com
    Link: http://lkml.kernel.org/r/20170618142302.25390-3-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit cadb844501f1822a5b18a093126e7af1cdf5d67a
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed May 31 14:03:11 2017 +0200

    srcu: Allow use of Classic SRCU from both process and interrupt context
    
    commit 1123a6041654e8f889014659593bad4168e542c2 upstream.
    
    Linu Cherian reported a WARN in cleanup_srcu_struct() when shutting
    down a guest running iperf on a VFIO assigned device.  This happens
    because irqfd_wakeup() calls srcu_read_lock(&kvm->irq_srcu) in interrupt
    context, while a worker thread does the same inside kvm_set_irq().  If the
    interrupt happens while the worker thread is executing __srcu_read_lock(),
    updates to the Classic SRCU ->lock_count[] field or the Tree SRCU
    ->srcu_lock_count[] field can be lost.
    
    The docs say you are not supposed to call srcu_read_lock() and
    srcu_read_unlock() from irq context, but KVM interrupt injection happens
    from (host) interrupt context and it would be nice if SRCU supported the
    use case.  KVM is using SRCU here not really for the "sleepable" part,
    but rather due to its IPI-free fast detection of grace periods.  It is
    therefore not desirable to switch back to RCU, which would effectively
    revert commit 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING",
    2014-01-16).
    
    However, the docs are overly conservative.  You can have an SRCU instance
    only has users in irq context, and you can mix process and irq context
    as long as process context users disable interrupts.  In addition,
    __srcu_read_unlock() actually uses this_cpu_dec() on both Tree SRCU and
    Classic SRCU.  For those two implementations, only srcu_read_lock()
    is unsafe.
    
    When Classic SRCU's __srcu_read_unlock() was changed to use this_cpu_dec(),
    in commit 5a41344a3d83 ("srcu: Simplify __srcu_read_unlock() via
    this_cpu_dec()", 2012-11-29), __srcu_read_lock() did two increments.
    Therefore it kept __this_cpu_inc(), with preempt_disable/enable in
    the caller.  Tree SRCU however only does one increment, so on most
    architectures it is more efficient for __srcu_read_lock() to use
    this_cpu_inc(), and any performance differences appear to be down in
    the noise.
    
    Fixes: 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING")
    Reported-by: Linu Cherian <linuc.decode@gmail.com>
    Suggested-by: Linu Cherian <linuc.decode@gmail.com>
    Cc: kvm@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8affb06737ae565722764c2b309eb0e892538344
Merge: b29794ec95c6 1123a6041654
Author: Ingo Molnar <mingo@kernel.org>
Date:   Fri Jun 9 08:17:10 2017 +0200

    Merge branch 'rcu/urgent' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu into rcu/urgent
    
    Pull RCU fix from Paul E. McKenney:
    
    " This series enables srcu_read_lock() and srcu_read_unlock() to be used from
      interrupt handlers, which fixes a bug in KVM's use of SRCU in delivery
      of interrupts to guest OSes. "
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 881ec9d209d5371c21db89ca1bb19afd3fcadab3
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Apr 12 15:16:50 2017 -0700

    srcu: Eliminate possibility of destructive counter overflow
    
    Earlier versions of Tree SRCU were subject to a counter overflow bug that
    could theoretically result in too-short grace periods.  This commit
    eliminates this problem by adding an update-side memory barrier.
    The short explanation is that if the updater sums the unlock counts
    too late to see a given __srcu_read_unlock() increment, that CPU's
    next __srcu_read_lock() must see the new value of ->srcu_idx, thus
    incrementing the other bank of counters.  This eliminates the possibility
    of destructive counter overflow as long as the srcu_read_lock() nesting
    level does not exceed floor(ULONG_MAX/NR_CPUS/2), which should be an
    eminently reasonable nesting limit, especially on 64-bit systems.
    
    Reported-by: Lance Roy <ldr709@gmail.com>
    Suggested-by: Lance Roy <ldr709@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 1123a6041654e8f889014659593bad4168e542c2
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed May 31 14:03:11 2017 +0200

    srcu: Allow use of Classic SRCU from both process and interrupt context
    
    Linu Cherian reported a WARN in cleanup_srcu_struct() when shutting
    down a guest running iperf on a VFIO assigned device.  This happens
    because irqfd_wakeup() calls srcu_read_lock(&kvm->irq_srcu) in interrupt
    context, while a worker thread does the same inside kvm_set_irq().  If the
    interrupt happens while the worker thread is executing __srcu_read_lock(),
    updates to the Classic SRCU ->lock_count[] field or the Tree SRCU
    ->srcu_lock_count[] field can be lost.
    
    The docs say you are not supposed to call srcu_read_lock() and
    srcu_read_unlock() from irq context, but KVM interrupt injection happens
    from (host) interrupt context and it would be nice if SRCU supported the
    use case.  KVM is using SRCU here not really for the "sleepable" part,
    but rather due to its IPI-free fast detection of grace periods.  It is
    therefore not desirable to switch back to RCU, which would effectively
    revert commit 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING",
    2014-01-16).
    
    However, the docs are overly conservative.  You can have an SRCU instance
    only has users in irq context, and you can mix process and irq context
    as long as process context users disable interrupts.  In addition,
    __srcu_read_unlock() actually uses this_cpu_dec() on both Tree SRCU and
    Classic SRCU.  For those two implementations, only srcu_read_lock()
    is unsafe.
    
    When Classic SRCU's __srcu_read_unlock() was changed to use this_cpu_dec(),
    in commit 5a41344a3d83 ("srcu: Simplify __srcu_read_unlock() via
    this_cpu_dec()", 2012-11-29), __srcu_read_lock() did two increments.
    Therefore it kept __this_cpu_inc(), with preempt_disable/enable in
    the caller.  Tree SRCU however only does one increment, so on most
    architectures it is more efficient for __srcu_read_lock() to use
    this_cpu_inc(), and any performance differences appear to be down in
    the noise.
    
    Cc: stable@vger.kernel.org
    Fixes: 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING")
    Reported-by: Linu Cherian <linuc.decode@gmail.com>
    Suggested-by: Linu Cherian <linuc.decode@gmail.com>
    Cc: kvm@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit cdf7abc4610a7f1c43d06cda246c5f748a4fd267
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Wed May 31 14:03:10 2017 +0200

    srcu: Allow use of Tiny/Tree SRCU from both process and interrupt context
    
    Linu Cherian reported a WARN in cleanup_srcu_struct() when shutting
    down a guest running iperf on a VFIO assigned device.  This happens
    because irqfd_wakeup() calls srcu_read_lock(&kvm->irq_srcu) in interrupt
    context, while a worker thread does the same inside kvm_set_irq().  If the
    interrupt happens while the worker thread is executing __srcu_read_lock(),
    updates to the Classic SRCU ->lock_count[] field or the Tree SRCU
    ->srcu_lock_count[] field can be lost.
    
    The docs say you are not supposed to call srcu_read_lock() and
    srcu_read_unlock() from irq context, but KVM interrupt injection happens
    from (host) interrupt context and it would be nice if SRCU supported the
    use case.  KVM is using SRCU here not really for the "sleepable" part,
    but rather due to its IPI-free fast detection of grace periods.  It is
    therefore not desirable to switch back to RCU, which would effectively
    revert commit 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING",
    2014-01-16).
    
    However, the docs are overly conservative.  You can have an SRCU instance
    only has users in irq context, and you can mix process and irq context
    as long as process context users disable interrupts.  In addition,
    __srcu_read_unlock() actually uses this_cpu_dec() on both Tree SRCU and
    Classic SRCU.  For those two implementations, only srcu_read_lock()
    is unsafe.
    
    When Classic SRCU's __srcu_read_unlock() was changed to use this_cpu_dec(),
    in commit 5a41344a3d83 ("srcu: Simplify __srcu_read_unlock() via
    this_cpu_dec()", 2012-11-29), __srcu_read_lock() did two increments.
    Therefore it kept __this_cpu_inc(), with preempt_disable/enable in
    the caller.  Tree SRCU however only does one increment, so on most
    architectures it is more efficient for __srcu_read_lock() to use
    this_cpu_inc(), and any performance differences appear to be down in
    the noise.
    
    Unlike Classic and Tree SRCU, Tiny SRCU does increments and decrements on
    a single variable.  Therefore, as Peter Zijlstra pointed out, Tiny SRCU's
    implementation already supports mixed-context use of srcu_read_lock()
    and srcu_read_unlock(), at least as long as uses of srcu_read_lock()
    and srcu_read_unlock() in each handler are nested and paired properly.
    In other words, it is still illegal to (say) invoke srcu_read_lock()
    in an interrupt handler and to invoke the matching srcu_read_unlock()
    in a softirq handler.  Therefore, the only change required for Tiny SRCU
    is to its comments.
    
    Fixes: 719d93cd5f5c ("kvm/irqchip: Speed up KVM_SET_GSI_ROUTING")
    Reported-by: Linu Cherian <linuc.decode@gmail.com>
    Suggested-by: Linu Cherian <linuc.decode@gmail.com>
    Cc: kvm@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Paolo Bonzini <pbonzini@redhat.com>

commit 3e96c3fdcfccb321a9e1623f78cc71b44593e965
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jan 11 21:50:46 2017 -0500

    ext4: fix deadlock between inline_data and ext4_expand_extra_isize_ea()
    
    commit c755e251357a0cee0679081f08c3f4ba797a8009 upstream.
    
    The xattr_sem deadlock problems fixed in commit 2e81a4eeedca: "ext4:
    avoid deadlock when expanding inode size" didn't include the use of
    xattr_sem in fs/ext4/inline.c.  With the addition of project quota
    which added a new extra inode field, this exposed deadlocks in the
    inline_data code similar to the ones fixed by 2e81a4eeedca.
    
    The deadlock can be reproduced via:
    
       dmesg -n 7
       mke2fs -t ext4 -O inline_data -Fq -I 256 /dev/vdc 32768
       mount -t ext4 -o debug_want_extra_isize=24 /dev/vdc /vdc
       mkdir /vdc/a
       umount /vdc
       mount -t ext4 /dev/vdc /vdc
       echo foo > /vdc/a/foo
    
    and looks like this:
    
    [   11.158815]
    [   11.160276] =============================================
    [   11.161960] [ INFO: possible recursive locking detected ]
    [   11.161960] 4.10.0-rc3-00015-g011b30a8a3cf #160 Tainted: G        W
    [   11.161960] ---------------------------------------------
    [   11.161960] bash/2519 is trying to acquire lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1225a4b>] ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]
    [   11.161960] but task is already holding lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] other info that might help us debug this:
    [   11.161960]  Possible unsafe locking scenario:
    [   11.161960]
    [   11.161960]        CPU0
    [   11.161960]        ----
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]
    [   11.161960]  *** DEADLOCK ***
    [   11.161960]
    [   11.161960]  May be due to missing lock nesting notation
    [   11.161960]
    [   11.161960] 4 locks held by bash/2519:
    [   11.161960]  #0:  (sb_writers#3){.+.+.+}, at: [<c11a2414>] mnt_want_write+0x1e/0x3e
    [   11.161960]  #1:  (&type->i_mutex_dir_key){++++++}, at: [<c119508b>] path_openat+0x338/0x67a
    [   11.161960]  #2:  (jbd2_handle){++++..}, at: [<c123314a>] start_this_handle+0x582/0x622
    [   11.161960]  #3:  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] stack backtrace:
    [   11.161960] CPU: 0 PID: 2519 Comm: bash Tainted: G        W       4.10.0-rc3-00015-g011b30a8a3cf #160
    [   11.161960] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1 04/01/2014
    [   11.161960] Call Trace:
    [   11.161960]  dump_stack+0x72/0xa3
    [   11.161960]  __lock_acquire+0xb7c/0xcb9
    [   11.161960]  ? kvm_clock_read+0x1f/0x29
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  lock_acquire+0x106/0x18a
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  down_write+0x39/0x72
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ? _raw_read_unlock+0x22/0x2c
    [   11.161960]  ? jbd2_journal_extend+0x1e2/0x262
    [   11.161960]  ? __ext4_journal_get_write_access+0x3d/0x60
    [   11.161960]  ext4_mark_inode_dirty+0x17d/0x26d
    [   11.161960]  ? ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_try_add_inline_entry+0x69/0x152
    [   11.161960]  ext4_add_entry+0xa3/0x848
    [   11.161960]  ? __brelse+0x14/0x2f
    [   11.161960]  ? _raw_spin_unlock_irqrestore+0x44/0x4f
    [   11.161960]  ext4_add_nondir+0x17/0x5b
    [   11.161960]  ext4_create+0xcf/0x133
    [   11.161960]  ? ext4_mknod+0x12f/0x12f
    [   11.161960]  lookup_open+0x39e/0x3fb
    [   11.161960]  ? __wake_up+0x1a/0x40
    [   11.161960]  ? lock_acquire+0x11e/0x18a
    [   11.161960]  path_openat+0x35c/0x67a
    [   11.161960]  ? sched_clock_cpu+0xd7/0xf2
    [   11.161960]  do_filp_open+0x36/0x7c
    [   11.161960]  ? _raw_spin_unlock+0x22/0x2c
    [   11.161960]  ? __alloc_fd+0x169/0x173
    [   11.161960]  do_sys_open+0x59/0xcc
    [   11.161960]  SyS_open+0x1d/0x1f
    [   11.161960]  do_int80_syscall_32+0x4f/0x61
    [   11.161960]  entry_INT80_32+0x2f/0x2f
    [   11.161960] EIP: 0xb76ad469
    [   11.161960] EFLAGS: 00000286 CPU: 0
    [   11.161960] EAX: ffffffda EBX: 08168ac8 ECX: 00008241 EDX: 000001b6
    [   11.161960] ESI: b75e46bc EDI: b7755000 EBP: bfbdb108 ESP: bfbdafc0
    [   11.161960]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Reported-by: George Spelvin <linux@sciencehorizons.net>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    [bwh: Backported to 3.16: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 5510cdf7be042a1943222e19912f13a396c0b914
Author: David Ahern <dsahern@gmail.com>
Date:   Thu May 25 10:42:34 2017 -0700

    net: ipv4: refactor ip_route_input_noref
    
    A later patch wants access to the fib result on an input route lookup
    with the rcu lock held. Refactor ip_route_input_noref pushing the logic
    between rcu_read_lock ... rcu_read_unlock into a new helper that takes
    the fib_result as an input arg.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 3abd1ade6765e8edcccad6a9e1039cc709e65dde
Author: David Ahern <dsahern@gmail.com>
Date:   Thu May 25 10:42:33 2017 -0700

    net: ipv4: refactor __ip_route_output_key_hash
    
    A later patch wants access to the fib result on an output route lookup
    with the rcu lock held. Refactor __ip_route_output_key_hash, pushing
    the logic between rcu_read_lock ... rcu_read_unlock into a new helper
    with the fib_result as an input arg.
    
    To keep the name length under control remove the leading underscores
    from the name and add _rcu to the name of the new helper indicating it
    is called with the rcu read lock held.
    
    Signed-off-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: Roopa Prabhu <roopa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 15e4ed2a46587a8e3085299ae443c96459ce8856
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Fri May 12 19:11:31 2017 +0300

    pid_ns: Fix race between setns'ed fork() and zap_pid_ns_processes()
    
    commit 3fd37226216620c1a468afa999739d5016fbc349 upstream.
    
    Imagine we have a pid namespace and a task from its parent's pid_ns,
    which made setns() to the pid namespace. The task is doing fork(),
    while the pid namespace's child reaper is dying. We have the race
    between them:
    
    Task from parent pid_ns             Child reaper
    copy_process()                      ..
      alloc_pid()                       ..
      ..                                zap_pid_ns_processes()
      ..                                  disable_pid_allocation()
      ..                                  read_lock(&tasklist_lock)
      ..                                  iterate over pids in pid_ns
      ..                                    kill tasks linked to pids
      ..                                  read_unlock(&tasklist_lock)
      write_lock_irq(&tasklist_lock);   ..
      attach_pid(p, PIDTYPE_PID);       ..
      ..                                ..
    
    So, just created task p won't receive SIGKILL signal,
    and the pid namespace will be in contradictory state.
    Only manual kill will help there, but does the userspace
    care about this? I suppose, the most users just inject
    a task into a pid namespace and wait a SIGCHLD from it.
    
    The patch fixes the problem. It simply checks for
    (pid_ns->nr_hashed & PIDNS_HASH_ADDING) in copy_process().
    We do it under the tasklist_lock, and can't skip
    PIDNS_HASH_ADDING as noted by Oleg:
    
    "zap_pid_ns_processes() does disable_pid_allocation()
    and then takes tasklist_lock to kill the whole namespace.
    Given that copy_process() checks PIDNS_HASH_ADDING
    under write_lock(tasklist) they can't race;
    if copy_process() takes this lock first, the new child will
    be killed, otherwise copy_process() can't miss
    the change in ->nr_hashed."
    
    If allocation is disabled, we just return -ENOMEM
    like it's made for such cases in alloc_pid().
    
    v2: Do not move disable_pid_allocation(), do not
    introduce a new variable in copy_process() and simplify
    the patch as suggested by Oleg Nesterov.
    Account the problem with double irq enabling
    found by Eric W. Biederman.
    
    Fixes: c876ad768215 ("pidns: Stop pid allocation when init dies")
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    CC: Andrew Morton <akpm@linux-foundation.org>
    CC: Ingo Molnar <mingo@kernel.org>
    CC: Peter Zijlstra <peterz@infradead.org>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Mike Rapoport <rppt@linux.vnet.ibm.com>
    CC: Michal Hocko <mhocko@suse.com>
    CC: Andy Lutomirski <luto@kernel.org>
    CC: "Eric W. Biederman" <ebiederm@xmission.com>
    CC: Andrei Vagin <avagin@openvz.org>
    CC: Cyrill Gorcunov <gorcunov@openvz.org>
    CC: Serge Hallyn <serge@hallyn.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2ea2f891fa85a6b8fd2fd6991e16844be39da888
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Fri May 12 19:11:31 2017 +0300

    pid_ns: Fix race between setns'ed fork() and zap_pid_ns_processes()
    
    commit 3fd37226216620c1a468afa999739d5016fbc349 upstream.
    
    Imagine we have a pid namespace and a task from its parent's pid_ns,
    which made setns() to the pid namespace. The task is doing fork(),
    while the pid namespace's child reaper is dying. We have the race
    between them:
    
    Task from parent pid_ns             Child reaper
    copy_process()                      ..
      alloc_pid()                       ..
      ..                                zap_pid_ns_processes()
      ..                                  disable_pid_allocation()
      ..                                  read_lock(&tasklist_lock)
      ..                                  iterate over pids in pid_ns
      ..                                    kill tasks linked to pids
      ..                                  read_unlock(&tasklist_lock)
      write_lock_irq(&tasklist_lock);   ..
      attach_pid(p, PIDTYPE_PID);       ..
      ..                                ..
    
    So, just created task p won't receive SIGKILL signal,
    and the pid namespace will be in contradictory state.
    Only manual kill will help there, but does the userspace
    care about this? I suppose, the most users just inject
    a task into a pid namespace and wait a SIGCHLD from it.
    
    The patch fixes the problem. It simply checks for
    (pid_ns->nr_hashed & PIDNS_HASH_ADDING) in copy_process().
    We do it under the tasklist_lock, and can't skip
    PIDNS_HASH_ADDING as noted by Oleg:
    
    "zap_pid_ns_processes() does disable_pid_allocation()
    and then takes tasklist_lock to kill the whole namespace.
    Given that copy_process() checks PIDNS_HASH_ADDING
    under write_lock(tasklist) they can't race;
    if copy_process() takes this lock first, the new child will
    be killed, otherwise copy_process() can't miss
    the change in ->nr_hashed."
    
    If allocation is disabled, we just return -ENOMEM
    like it's made for such cases in alloc_pid().
    
    v2: Do not move disable_pid_allocation(), do not
    introduce a new variable in copy_process() and simplify
    the patch as suggested by Oleg Nesterov.
    Account the problem with double irq enabling
    found by Eric W. Biederman.
    
    Fixes: c876ad768215 ("pidns: Stop pid allocation when init dies")
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    CC: Andrew Morton <akpm@linux-foundation.org>
    CC: Ingo Molnar <mingo@kernel.org>
    CC: Peter Zijlstra <peterz@infradead.org>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Mike Rapoport <rppt@linux.vnet.ibm.com>
    CC: Michal Hocko <mhocko@suse.com>
    CC: Andy Lutomirski <luto@kernel.org>
    CC: "Eric W. Biederman" <ebiederm@xmission.com>
    CC: Andrei Vagin <avagin@openvz.org>
    CC: Cyrill Gorcunov <gorcunov@openvz.org>
    CC: Serge Hallyn <serge@hallyn.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6a70a5833ecc9147d8257e80f39e11d582810082
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Fri May 12 19:11:31 2017 +0300

    pid_ns: Fix race between setns'ed fork() and zap_pid_ns_processes()
    
    commit 3fd37226216620c1a468afa999739d5016fbc349 upstream.
    
    Imagine we have a pid namespace and a task from its parent's pid_ns,
    which made setns() to the pid namespace. The task is doing fork(),
    while the pid namespace's child reaper is dying. We have the race
    between them:
    
    Task from parent pid_ns             Child reaper
    copy_process()                      ..
      alloc_pid()                       ..
      ..                                zap_pid_ns_processes()
      ..                                  disable_pid_allocation()
      ..                                  read_lock(&tasklist_lock)
      ..                                  iterate over pids in pid_ns
      ..                                    kill tasks linked to pids
      ..                                  read_unlock(&tasklist_lock)
      write_lock_irq(&tasklist_lock);   ..
      attach_pid(p, PIDTYPE_PID);       ..
      ..                                ..
    
    So, just created task p won't receive SIGKILL signal,
    and the pid namespace will be in contradictory state.
    Only manual kill will help there, but does the userspace
    care about this? I suppose, the most users just inject
    a task into a pid namespace and wait a SIGCHLD from it.
    
    The patch fixes the problem. It simply checks for
    (pid_ns->nr_hashed & PIDNS_HASH_ADDING) in copy_process().
    We do it under the tasklist_lock, and can't skip
    PIDNS_HASH_ADDING as noted by Oleg:
    
    "zap_pid_ns_processes() does disable_pid_allocation()
    and then takes tasklist_lock to kill the whole namespace.
    Given that copy_process() checks PIDNS_HASH_ADDING
    under write_lock(tasklist) they can't race;
    if copy_process() takes this lock first, the new child will
    be killed, otherwise copy_process() can't miss
    the change in ->nr_hashed."
    
    If allocation is disabled, we just return -ENOMEM
    like it's made for such cases in alloc_pid().
    
    v2: Do not move disable_pid_allocation(), do not
    introduce a new variable in copy_process() and simplify
    the patch as suggested by Oleg Nesterov.
    Account the problem with double irq enabling
    found by Eric W. Biederman.
    
    Fixes: c876ad768215 ("pidns: Stop pid allocation when init dies")
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    CC: Andrew Morton <akpm@linux-foundation.org>
    CC: Ingo Molnar <mingo@kernel.org>
    CC: Peter Zijlstra <peterz@infradead.org>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Mike Rapoport <rppt@linux.vnet.ibm.com>
    CC: Michal Hocko <mhocko@suse.com>
    CC: Andy Lutomirski <luto@kernel.org>
    CC: "Eric W. Biederman" <ebiederm@xmission.com>
    CC: Andrei Vagin <avagin@openvz.org>
    CC: Cyrill Gorcunov <gorcunov@openvz.org>
    CC: Serge Hallyn <serge@hallyn.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a91891444d171f66fe371048c9d3e4a6fad3db6e
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Dec 7 08:25:21 2015 -0800

    ipv6: sctp: fix lockdep splat in sctp_v6_get_dst()
    
    commit 69ce6487dcd364245a3d26322fc8f4ffd1e8d947 upstream.
    
    While cooking the sctp np->opt rcu fixes, I forgot to move
    one rcu_read_unlock() after the added rcu_dereference() in
    sctp_v6_get_dst()
    
    This gave lockdep warnings reported by Dave Jones.
    
    Fixes: c836a8ba9386 ("ipv6: sctp: add rcu protection around np->opt")
    Reported-by: Dave Jones <davej@codemonkey.org.uk>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b9ef0326c05a008c3c576bd4d676208b50c344d5
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Wed May 17 11:14:35 2017 -0400

    tracing: Move postpone selftests to core from early_initcall
    
    I hit the following lockdep splat when booting with ftrace selftests
    enabled, as well as CONFIG_PREEMPT and LOCKDEP.
    
     Testing dynamic ftrace ops #1:
     (1 0 1 0 0)
     (1 1 2 0 0)
     (2 1 3 0 169)
     (2 2 4 0 50066)
     ------------[ cut here ]------------
     WARNING: CPU: 0 PID: 13 at kernel/rcu/srcutree.c:202 check_init_srcu_struct+0x60/0x70
     Modules linked in:
     CPU: 0 PID: 13 Comm: rcu_tasks_kthre Not tainted 4.12.0-rc1-test+ #587
     Hardware name: Hewlett-Packard HP Compaq Pro 6300 SFF/339A, BIOS K01 v02.05 05/07/2012
     task: ffff880119628040 task.stack: ffffc900006a4000
     RIP: 0010:check_init_srcu_struct+0x60/0x70
     RSP: 0000:ffffc900006a7d98 EFLAGS: 00010246
     RAX: 0000000000000246 RBX: 0000000000000000 RCX: 0000000000000000
     RDX: ffff880119628040 RSI: 00000000ffffffff RDI: ffffffff81e5fb40
     RBP: ffffc900006a7e20 R08: 00000023b403c000 R09: 0000000000000001
     R10: ffffc900006a7e40 R11: 0000000000000000 R12: ffffffff81e5fb40
     R13: 0000000000000286 R14: ffff880119628040 R15: ffffc900006a7e98
     FS:  0000000000000000(0000) GS:ffff88011ea00000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
     CR2: ffff88011edff000 CR3: 0000000001e0f000 CR4: 00000000001406f0
     Call Trace:
      ? __synchronize_srcu+0x6e/0x140
      ? lock_acquire+0xdc/0x1d0
      ? ktime_get_mono_fast_ns+0x5d/0xb0
      synchronize_srcu+0x6f/0x110
      ? synchronize_srcu+0x6f/0x110
      rcu_tasks_kthread+0x20a/0x540
      kthread+0x114/0x150
      ? __rcu_read_unlock+0x70/0x70
      ? kthread_create_on_node+0x40/0x40
      ret_from_fork+0x2e/0x40
     Code: f6 83 70 06 00 00 03 49 89 c5 74 0d be 01 00 00 00 48 89 df e8 42 fa ff ff 4c 89 ee 4c 89 e7 e8 b7 42 75 00 5b 41 5c 41 5d 5d c3 <0f> ff eb aa 66 90 66 2e 0f 1f 84 00 00 00 00 00 0f 1f 44 00 00
     ---[ end trace 5c3f4206ce50f6ac ]---
    
    What happens is that the selftests include a creating of a dynamically
    allocated ftrace_ops, which requires the use of synchronize_rcu_tasks()
    which uses srcu, and triggers the above warning.
    
    It appears that synchronize_rcu_tasks() is not set up at early_initcall(),
    but it is at core_initcall(). By moving the tests down to that location
    works out properly.
    
    Link: http://lkml.kernel.org/r/20170517111435.7388c033@gandalf.local.home
    
    Acked-by: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

commit 929575fd0dfdaf7de326991fb56d1d11b95e86e6
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 3 06:39:31 2017 -0700

    tcp: do not inherit fastopen_req from parent
    
    [ Upstream commit 8b485ce69876c65db12ed390e7f9c0d2a64eff2c ]
    
    Under fuzzer stress, it is possible that a child gets a non NULL
    fastopen_req pointer from its parent at accept() time, when/if parent
    morphs from listener to active session.
    
    We need to make sure this can not happen, by clearing the field after
    socket cloning.
    
    BUG: Double free or freeing an invalid pointer
    Unexpected shadow byte: 0xFB
    CPU: 3 PID: 20933 Comm: syz-executor3 Not tainted 4.11.0+ #306
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
    01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x292/0x395 lib/dump_stack.c:52
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:164
     kasan_report_double_free+0x5c/0x70 mm/kasan/report.c:185
     kasan_slab_free+0x9d/0xc0 mm/kasan/kasan.c:580
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     inet_child_forget+0xb8/0x600 net/ipv4/inet_connection_sock.c:898
     inet_csk_reqsk_queue_add+0x1e7/0x250
    net/ipv4/inet_connection_sock.c:928
     tcp_get_cookie_sock+0x21a/0x510 net/ipv4/syncookies.c:217
     cookie_v4_check+0x1a19/0x28b0 net/ipv4/syncookies.c:384
     tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1384 [inline]
     tcp_v4_do_rcv+0x731/0x940 net/ipv4/tcp_ipv4.c:1421
     tcp_v4_rcv+0x2dc0/0x31c0 net/ipv4/tcp_ipv4.c:1715
     ip_local_deliver_finish+0x4cc/0xc20 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_local_deliver+0x1ce/0x700 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:492 [inline]
     ip_rcv_finish+0xb1d/0x20b0 net/ipv4/ip_input.c:396
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_rcv+0xd8c/0x19c0 net/ipv4/ip_input.c:487
     __netif_receive_skb_core+0x1ad1/0x3400 net/core/dev.c:4210
     __netif_receive_skb+0x2a/0x1a0 net/core/dev.c:4248
     process_backlog+0xe5/0x6c0 net/core/dev.c:4868
     napi_poll net/core/dev.c:5270 [inline]
     net_rx_action+0xe70/0x18e0 net/core/dev.c:5335
     __do_softirq+0x2fb/0xb99 kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:899
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1cf/0x1e0 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:931 [inline]
     ip_finish_output2+0x9ab/0x15e0 net/ipv4/ip_output.c:230
     ip_finish_output+0xa35/0xdf0 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f6/0x7b0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x9a8/0x1a10 net/ipv4/ip_output.c:503
     tcp_transmit_skb+0x1ade/0x3470 net/ipv4/tcp_output.c:1057
     tcp_write_xmit+0x79e/0x55b0 net/ipv4/tcp_output.c:2265
     __tcp_push_pending_frames+0xfa/0x3a0 net/ipv4/tcp_output.c:2450
     tcp_push+0x4ee/0x780 net/ipv4/tcp.c:683
     tcp_sendmsg+0x128d/0x39b0 net/ipv4/tcp.c:1342
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    RIP: 0033:0x446059
    RSP: 002b:00007faa6761fb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 0000000000446059
    RDX: 0000000000000001 RSI: 0000000020ba3fcd RDI: 0000000000000017
    RBP: 00000000006e40a0 R08: 0000000020ba4ff0 R09: 0000000000000010
    R10: 0000000020000000 R11: 0000000000000282 R12: 0000000000708150
    R13: 0000000000000000 R14: 00007faa676209c0 R15: 00007faa67620700
    Object at ffff88003b5bbcb8, in cache kmalloc-64 size: 64
    Allocated:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:616
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2745
     kmalloc include/linux/slab.h:490 [inline]
     kzalloc include/linux/slab.h:663 [inline]
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1094 [inline]
     tcp_sendmsg+0x221a/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    Freed:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:589
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     __inet_stream_connect+0x20c/0xf90 net/ipv4/af_inet.c:593
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1111 [inline]
     tcp_sendmsg+0x23a8/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    
    Fixes: e994b2f0fb92 ("tcp: do not lock listener to process SYN packets")
    Fixes: 7db92362d2fe ("tcp: fix potential double free issue for fastopen_req")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Acked-by: Wei Wang <weiwan@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 86a9a0884d287a9417193179fcd10e7b63f136c2
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 3 06:39:31 2017 -0700

    tcp: do not inherit fastopen_req from parent
    
    [ Upstream commit 8b485ce69876c65db12ed390e7f9c0d2a64eff2c ]
    
    Under fuzzer stress, it is possible that a child gets a non NULL
    fastopen_req pointer from its parent at accept() time, when/if parent
    morphs from listener to active session.
    
    We need to make sure this can not happen, by clearing the field after
    socket cloning.
    
    BUG: Double free or freeing an invalid pointer
    Unexpected shadow byte: 0xFB
    CPU: 3 PID: 20933 Comm: syz-executor3 Not tainted 4.11.0+ #306
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
    01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x292/0x395 lib/dump_stack.c:52
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:164
     kasan_report_double_free+0x5c/0x70 mm/kasan/report.c:185
     kasan_slab_free+0x9d/0xc0 mm/kasan/kasan.c:580
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     inet_child_forget+0xb8/0x600 net/ipv4/inet_connection_sock.c:898
     inet_csk_reqsk_queue_add+0x1e7/0x250
    net/ipv4/inet_connection_sock.c:928
     tcp_get_cookie_sock+0x21a/0x510 net/ipv4/syncookies.c:217
     cookie_v4_check+0x1a19/0x28b0 net/ipv4/syncookies.c:384
     tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1384 [inline]
     tcp_v4_do_rcv+0x731/0x940 net/ipv4/tcp_ipv4.c:1421
     tcp_v4_rcv+0x2dc0/0x31c0 net/ipv4/tcp_ipv4.c:1715
     ip_local_deliver_finish+0x4cc/0xc20 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_local_deliver+0x1ce/0x700 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:492 [inline]
     ip_rcv_finish+0xb1d/0x20b0 net/ipv4/ip_input.c:396
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_rcv+0xd8c/0x19c0 net/ipv4/ip_input.c:487
     __netif_receive_skb_core+0x1ad1/0x3400 net/core/dev.c:4210
     __netif_receive_skb+0x2a/0x1a0 net/core/dev.c:4248
     process_backlog+0xe5/0x6c0 net/core/dev.c:4868
     napi_poll net/core/dev.c:5270 [inline]
     net_rx_action+0xe70/0x18e0 net/core/dev.c:5335
     __do_softirq+0x2fb/0xb99 kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:899
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1cf/0x1e0 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:931 [inline]
     ip_finish_output2+0x9ab/0x15e0 net/ipv4/ip_output.c:230
     ip_finish_output+0xa35/0xdf0 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f6/0x7b0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x9a8/0x1a10 net/ipv4/ip_output.c:503
     tcp_transmit_skb+0x1ade/0x3470 net/ipv4/tcp_output.c:1057
     tcp_write_xmit+0x79e/0x55b0 net/ipv4/tcp_output.c:2265
     __tcp_push_pending_frames+0xfa/0x3a0 net/ipv4/tcp_output.c:2450
     tcp_push+0x4ee/0x780 net/ipv4/tcp.c:683
     tcp_sendmsg+0x128d/0x39b0 net/ipv4/tcp.c:1342
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    RIP: 0033:0x446059
    RSP: 002b:00007faa6761fb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 0000000000446059
    RDX: 0000000000000001 RSI: 0000000020ba3fcd RDI: 0000000000000017
    RBP: 00000000006e40a0 R08: 0000000020ba4ff0 R09: 0000000000000010
    R10: 0000000020000000 R11: 0000000000000282 R12: 0000000000708150
    R13: 0000000000000000 R14: 00007faa676209c0 R15: 00007faa67620700
    Object at ffff88003b5bbcb8, in cache kmalloc-64 size: 64
    Allocated:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:616
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2745
     kmalloc include/linux/slab.h:490 [inline]
     kzalloc include/linux/slab.h:663 [inline]
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1094 [inline]
     tcp_sendmsg+0x221a/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    Freed:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:589
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     __inet_stream_connect+0x20c/0xf90 net/ipv4/af_inet.c:593
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1111 [inline]
     tcp_sendmsg+0x23a8/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    
    Fixes: e994b2f0fb92 ("tcp: do not lock listener to process SYN packets")
    Fixes: 7db92362d2fe ("tcp: fix potential double free issue for fastopen_req")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Acked-by: Wei Wang <weiwan@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 747a00193f261f952c9dac86621441ba53e20f58
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 3 06:39:31 2017 -0700

    tcp: do not inherit fastopen_req from parent
    
    [ Upstream commit 8b485ce69876c65db12ed390e7f9c0d2a64eff2c ]
    
    Under fuzzer stress, it is possible that a child gets a non NULL
    fastopen_req pointer from its parent at accept() time, when/if parent
    morphs from listener to active session.
    
    We need to make sure this can not happen, by clearing the field after
    socket cloning.
    
    BUG: Double free or freeing an invalid pointer
    Unexpected shadow byte: 0xFB
    CPU: 3 PID: 20933 Comm: syz-executor3 Not tainted 4.11.0+ #306
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
    01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x292/0x395 lib/dump_stack.c:52
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:164
     kasan_report_double_free+0x5c/0x70 mm/kasan/report.c:185
     kasan_slab_free+0x9d/0xc0 mm/kasan/kasan.c:580
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     inet_child_forget+0xb8/0x600 net/ipv4/inet_connection_sock.c:898
     inet_csk_reqsk_queue_add+0x1e7/0x250
    net/ipv4/inet_connection_sock.c:928
     tcp_get_cookie_sock+0x21a/0x510 net/ipv4/syncookies.c:217
     cookie_v4_check+0x1a19/0x28b0 net/ipv4/syncookies.c:384
     tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1384 [inline]
     tcp_v4_do_rcv+0x731/0x940 net/ipv4/tcp_ipv4.c:1421
     tcp_v4_rcv+0x2dc0/0x31c0 net/ipv4/tcp_ipv4.c:1715
     ip_local_deliver_finish+0x4cc/0xc20 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_local_deliver+0x1ce/0x700 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:492 [inline]
     ip_rcv_finish+0xb1d/0x20b0 net/ipv4/ip_input.c:396
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_rcv+0xd8c/0x19c0 net/ipv4/ip_input.c:487
     __netif_receive_skb_core+0x1ad1/0x3400 net/core/dev.c:4210
     __netif_receive_skb+0x2a/0x1a0 net/core/dev.c:4248
     process_backlog+0xe5/0x6c0 net/core/dev.c:4868
     napi_poll net/core/dev.c:5270 [inline]
     net_rx_action+0xe70/0x18e0 net/core/dev.c:5335
     __do_softirq+0x2fb/0xb99 kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:899
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1cf/0x1e0 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:931 [inline]
     ip_finish_output2+0x9ab/0x15e0 net/ipv4/ip_output.c:230
     ip_finish_output+0xa35/0xdf0 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f6/0x7b0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x9a8/0x1a10 net/ipv4/ip_output.c:503
     tcp_transmit_skb+0x1ade/0x3470 net/ipv4/tcp_output.c:1057
     tcp_write_xmit+0x79e/0x55b0 net/ipv4/tcp_output.c:2265
     __tcp_push_pending_frames+0xfa/0x3a0 net/ipv4/tcp_output.c:2450
     tcp_push+0x4ee/0x780 net/ipv4/tcp.c:683
     tcp_sendmsg+0x128d/0x39b0 net/ipv4/tcp.c:1342
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    RIP: 0033:0x446059
    RSP: 002b:00007faa6761fb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 0000000000446059
    RDX: 0000000000000001 RSI: 0000000020ba3fcd RDI: 0000000000000017
    RBP: 00000000006e40a0 R08: 0000000020ba4ff0 R09: 0000000000000010
    R10: 0000000020000000 R11: 0000000000000282 R12: 0000000000708150
    R13: 0000000000000000 R14: 00007faa676209c0 R15: 00007faa67620700
    Object at ffff88003b5bbcb8, in cache kmalloc-64 size: 64
    Allocated:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:616
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2745
     kmalloc include/linux/slab.h:490 [inline]
     kzalloc include/linux/slab.h:663 [inline]
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1094 [inline]
     tcp_sendmsg+0x221a/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    Freed:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:589
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     __inet_stream_connect+0x20c/0xf90 net/ipv4/af_inet.c:593
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1111 [inline]
     tcp_sendmsg+0x23a8/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    
    Fixes: e994b2f0fb92 ("tcp: do not lock listener to process SYN packets")
    Fixes: 7db92362d2fe ("tcp: fix potential double free issue for fastopen_req")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Acked-by: Wei Wang <weiwan@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 483109649520a8b1ee0a055f0680f0e38a04faa3
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 3 06:39:31 2017 -0700

    tcp: do not inherit fastopen_req from parent
    
    [ Upstream commit 8b485ce69876c65db12ed390e7f9c0d2a64eff2c ]
    
    Under fuzzer stress, it is possible that a child gets a non NULL
    fastopen_req pointer from its parent at accept() time, when/if parent
    morphs from listener to active session.
    
    We need to make sure this can not happen, by clearing the field after
    socket cloning.
    
    BUG: Double free or freeing an invalid pointer
    Unexpected shadow byte: 0xFB
    CPU: 3 PID: 20933 Comm: syz-executor3 Not tainted 4.11.0+ #306
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
    01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x292/0x395 lib/dump_stack.c:52
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:164
     kasan_report_double_free+0x5c/0x70 mm/kasan/report.c:185
     kasan_slab_free+0x9d/0xc0 mm/kasan/kasan.c:580
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     inet_child_forget+0xb8/0x600 net/ipv4/inet_connection_sock.c:898
     inet_csk_reqsk_queue_add+0x1e7/0x250
    net/ipv4/inet_connection_sock.c:928
     tcp_get_cookie_sock+0x21a/0x510 net/ipv4/syncookies.c:217
     cookie_v4_check+0x1a19/0x28b0 net/ipv4/syncookies.c:384
     tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1384 [inline]
     tcp_v4_do_rcv+0x731/0x940 net/ipv4/tcp_ipv4.c:1421
     tcp_v4_rcv+0x2dc0/0x31c0 net/ipv4/tcp_ipv4.c:1715
     ip_local_deliver_finish+0x4cc/0xc20 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_local_deliver+0x1ce/0x700 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:492 [inline]
     ip_rcv_finish+0xb1d/0x20b0 net/ipv4/ip_input.c:396
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_rcv+0xd8c/0x19c0 net/ipv4/ip_input.c:487
     __netif_receive_skb_core+0x1ad1/0x3400 net/core/dev.c:4210
     __netif_receive_skb+0x2a/0x1a0 net/core/dev.c:4248
     process_backlog+0xe5/0x6c0 net/core/dev.c:4868
     napi_poll net/core/dev.c:5270 [inline]
     net_rx_action+0xe70/0x18e0 net/core/dev.c:5335
     __do_softirq+0x2fb/0xb99 kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:899
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1cf/0x1e0 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:931 [inline]
     ip_finish_output2+0x9ab/0x15e0 net/ipv4/ip_output.c:230
     ip_finish_output+0xa35/0xdf0 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f6/0x7b0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x9a8/0x1a10 net/ipv4/ip_output.c:503
     tcp_transmit_skb+0x1ade/0x3470 net/ipv4/tcp_output.c:1057
     tcp_write_xmit+0x79e/0x55b0 net/ipv4/tcp_output.c:2265
     __tcp_push_pending_frames+0xfa/0x3a0 net/ipv4/tcp_output.c:2450
     tcp_push+0x4ee/0x780 net/ipv4/tcp.c:683
     tcp_sendmsg+0x128d/0x39b0 net/ipv4/tcp.c:1342
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    RIP: 0033:0x446059
    RSP: 002b:00007faa6761fb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 0000000000446059
    RDX: 0000000000000001 RSI: 0000000020ba3fcd RDI: 0000000000000017
    RBP: 00000000006e40a0 R08: 0000000020ba4ff0 R09: 0000000000000010
    R10: 0000000020000000 R11: 0000000000000282 R12: 0000000000708150
    R13: 0000000000000000 R14: 00007faa676209c0 R15: 00007faa67620700
    Object at ffff88003b5bbcb8, in cache kmalloc-64 size: 64
    Allocated:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:616
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2745
     kmalloc include/linux/slab.h:490 [inline]
     kzalloc include/linux/slab.h:663 [inline]
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1094 [inline]
     tcp_sendmsg+0x221a/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    Freed:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:589
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     __inet_stream_connect+0x20c/0xf90 net/ipv4/af_inet.c:593
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1111 [inline]
     tcp_sendmsg+0x23a8/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    
    Fixes: e994b2f0fb92 ("tcp: do not lock listener to process SYN packets")
    Fixes: 7db92362d2fe ("tcp: fix potential double free issue for fastopen_req")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Acked-by: Wei Wang <weiwan@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3fd37226216620c1a468afa999739d5016fbc349
Author: Kirill Tkhai <ktkhai@virtuozzo.com>
Date:   Fri May 12 19:11:31 2017 +0300

    pid_ns: Fix race between setns'ed fork() and zap_pid_ns_processes()
    
    Imagine we have a pid namespace and a task from its parent's pid_ns,
    which made setns() to the pid namespace. The task is doing fork(),
    while the pid namespace's child reaper is dying. We have the race
    between them:
    
    Task from parent pid_ns             Child reaper
    copy_process()                      ..
      alloc_pid()                       ..
      ..                                zap_pid_ns_processes()
      ..                                  disable_pid_allocation()
      ..                                  read_lock(&tasklist_lock)
      ..                                  iterate over pids in pid_ns
      ..                                    kill tasks linked to pids
      ..                                  read_unlock(&tasklist_lock)
      write_lock_irq(&tasklist_lock);   ..
      attach_pid(p, PIDTYPE_PID);       ..
      ..                                ..
    
    So, just created task p won't receive SIGKILL signal,
    and the pid namespace will be in contradictory state.
    Only manual kill will help there, but does the userspace
    care about this? I suppose, the most users just inject
    a task into a pid namespace and wait a SIGCHLD from it.
    
    The patch fixes the problem. It simply checks for
    (pid_ns->nr_hashed & PIDNS_HASH_ADDING) in copy_process().
    We do it under the tasklist_lock, and can't skip
    PIDNS_HASH_ADDING as noted by Oleg:
    
    "zap_pid_ns_processes() does disable_pid_allocation()
    and then takes tasklist_lock to kill the whole namespace.
    Given that copy_process() checks PIDNS_HASH_ADDING
    under write_lock(tasklist) they can't race;
    if copy_process() takes this lock first, the new child will
    be killed, otherwise copy_process() can't miss
    the change in ->nr_hashed."
    
    If allocation is disabled, we just return -ENOMEM
    like it's made for such cases in alloc_pid().
    
    v2: Do not move disable_pid_allocation(), do not
    introduce a new variable in copy_process() and simplify
    the patch as suggested by Oleg Nesterov.
    Account the problem with double irq enabling
    found by Eric W. Biederman.
    
    Fixes: c876ad768215 ("pidns: Stop pid allocation when init dies")
    Signed-off-by: Kirill Tkhai <ktkhai@virtuozzo.com>
    CC: Andrew Morton <akpm@linux-foundation.org>
    CC: Ingo Molnar <mingo@kernel.org>
    CC: Peter Zijlstra <peterz@infradead.org>
    CC: Oleg Nesterov <oleg@redhat.com>
    CC: Mike Rapoport <rppt@linux.vnet.ibm.com>
    CC: Michal Hocko <mhocko@suse.com>
    CC: Andy Lutomirski <luto@kernel.org>
    CC: "Eric W. Biederman" <ebiederm@xmission.com>
    CC: Andrei Vagin <avagin@openvz.org>
    CC: Cyrill Gorcunov <gorcunov@openvz.org>
    CC: Serge Hallyn <serge@hallyn.com>
    Cc: stable@vger.kernel.org
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>

commit 8b485ce69876c65db12ed390e7f9c0d2a64eff2c
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed May 3 06:39:31 2017 -0700

    tcp: do not inherit fastopen_req from parent
    
    Under fuzzer stress, it is possible that a child gets a non NULL
    fastopen_req pointer from its parent at accept() time, when/if parent
    morphs from listener to active session.
    
    We need to make sure this can not happen, by clearing the field after
    socket cloning.
    
    BUG: Double free or freeing an invalid pointer
    Unexpected shadow byte: 0xFB
    CPU: 3 PID: 20933 Comm: syz-executor3 Not tainted 4.11.0+ #306
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs
    01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x292/0x395 lib/dump_stack.c:52
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:164
     kasan_report_double_free+0x5c/0x70 mm/kasan/report.c:185
     kasan_slab_free+0x9d/0xc0 mm/kasan/kasan.c:580
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     inet_child_forget+0xb8/0x600 net/ipv4/inet_connection_sock.c:898
     inet_csk_reqsk_queue_add+0x1e7/0x250
    net/ipv4/inet_connection_sock.c:928
     tcp_get_cookie_sock+0x21a/0x510 net/ipv4/syncookies.c:217
     cookie_v4_check+0x1a19/0x28b0 net/ipv4/syncookies.c:384
     tcp_v4_cookie_check net/ipv4/tcp_ipv4.c:1384 [inline]
     tcp_v4_do_rcv+0x731/0x940 net/ipv4/tcp_ipv4.c:1421
     tcp_v4_rcv+0x2dc0/0x31c0 net/ipv4/tcp_ipv4.c:1715
     ip_local_deliver_finish+0x4cc/0xc20 net/ipv4/ip_input.c:216
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_local_deliver+0x1ce/0x700 net/ipv4/ip_input.c:257
     dst_input include/net/dst.h:492 [inline]
     ip_rcv_finish+0xb1d/0x20b0 net/ipv4/ip_input.c:396
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip_rcv+0xd8c/0x19c0 net/ipv4/ip_input.c:487
     __netif_receive_skb_core+0x1ad1/0x3400 net/core/dev.c:4210
     __netif_receive_skb+0x2a/0x1a0 net/core/dev.c:4248
     process_backlog+0xe5/0x6c0 net/core/dev.c:4868
     napi_poll net/core/dev.c:5270 [inline]
     net_rx_action+0xe70/0x18e0 net/core/dev.c:5335
     __do_softirq+0x2fb/0xb99 kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:899
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1cf/0x1e0 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:931 [inline]
     ip_finish_output2+0x9ab/0x15e0 net/ipv4/ip_output.c:230
     ip_finish_output+0xa35/0xdf0 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f6/0x7b0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x160 net/ipv4/ip_output.c:124
     ip_queue_xmit+0x9a8/0x1a10 net/ipv4/ip_output.c:503
     tcp_transmit_skb+0x1ade/0x3470 net/ipv4/tcp_output.c:1057
     tcp_write_xmit+0x79e/0x55b0 net/ipv4/tcp_output.c:2265
     __tcp_push_pending_frames+0xfa/0x3a0 net/ipv4/tcp_output.c:2450
     tcp_push+0x4ee/0x780 net/ipv4/tcp.c:683
     tcp_sendmsg+0x128d/0x39b0 net/ipv4/tcp.c:1342
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    RIP: 0033:0x446059
    RSP: 002b:00007faa6761fb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 0000000000446059
    RDX: 0000000000000001 RSI: 0000000020ba3fcd RDI: 0000000000000017
    RBP: 00000000006e40a0 R08: 0000000020ba4ff0 R09: 0000000000000010
    R10: 0000000020000000 R11: 0000000000000282 R12: 0000000000708150
    R13: 0000000000000000 R14: 00007faa676209c0 R15: 00007faa67620700
    Object at ffff88003b5bbcb8, in cache kmalloc-64 size: 64
    Allocated:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:616
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2745
     kmalloc include/linux/slab.h:490 [inline]
     kzalloc include/linux/slab.h:663 [inline]
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1094 [inline]
     tcp_sendmsg+0x221a/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    Freed:
    PID = 20909
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:59
     save_stack+0x43/0xd0 mm/kasan/kasan.c:513
     set_track mm/kasan/kasan.c:525 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:589
     slab_free_hook mm/slub.c:1357 [inline]
     slab_free_freelist_hook mm/slub.c:1379 [inline]
     slab_free mm/slub.c:2961 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3882
     tcp_free_fastopen_req net/ipv4/tcp.c:1077 [inline]
     tcp_disconnect+0xc15/0x13e0 net/ipv4/tcp.c:2328
     __inet_stream_connect+0x20c/0xf90 net/ipv4/af_inet.c:593
     tcp_sendmsg_fastopen net/ipv4/tcp.c:1111 [inline]
     tcp_sendmsg+0x23a8/0x39b0 net/ipv4/tcp.c:1139
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:762
     sock_sendmsg_nosec net/socket.c:633 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:643
     SYSC_sendto+0x660/0x810 net/socket.c:1696
     SyS_sendto+0x40/0x50 net/socket.c:1664
     entry_SYSCALL_64_fastpath+0x1f/0xbe
    
    Fixes: e994b2f0fb92 ("tcp: do not lock listener to process SYN packets")
    Fixes: 7db92362d2fe ("tcp: fix potential double free issue for fastopen_req")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Acked-by: Wei Wang <weiwan@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c9afc1834e8132783772d73007706d3ae3848483
Author: Jose Abreu <Jose.Abreu@synopsys.com>
Date:   Fri Apr 28 10:55:25 2017 +0100

    ASoC: dwc: Disallow building designware_pcm as a module
    
    Designware PCM is an extension to Designware I2S and they are dependent
    on each other. For this reason, make Designware PCM a boolean which will
    compile with Desigwnare I2S module. The name of the module is not changed
    but the name of the files need to be changed.
    
    Also, without this commit we get errors when probbing designware_i2s module
    because of unspecified license:
    
    designware_pcm: module license 'unspecified' taints kernel.
    Disabling lock debugging due to kernel taint
    designware_pcm: Unknown symbol __rcu_read_lock (err 0)
    designware_pcm: Unknown symbol devm_snd_soc_register_platform (err 0)
    designware_pcm: Unknown symbol synchronize_rcu (err 0)
    designware_pcm: Unknown symbol __rcu_read_unlock (err 0)
    designware_pcm: Unknown symbol snd_soc_set_runtime_hwparams (err 0)
    
    So, this is really needed as a fix.
    
    Fixes: 79361b2b98b7 ("ASoC: dwc: Add PIO PCM extension")
    Signed-off-by: Lubomir Rintel <lkundrak@v3.sk>
    Signed-off-by: Jose Abreu <joabreu@synopsys.com>
    Signed-off-by: Mark Brown <broonie@kernel.org>

commit 073c516ff73557a8f7315066856c04b50383ac34
Author: Cong Wang <xiyou.wangcong@gmail.com>
Date:   Wed Apr 19 15:11:00 2017 -0700

    nsfs: mark dentry with DCACHE_RCUACCESS
    
    Andrey reported a use-after-free in __ns_get_path():
    
      spin_lock include/linux/spinlock.h:299 [inline]
      lockref_get_not_dead+0x19/0x80 lib/lockref.c:179
      __ns_get_path+0x197/0x860 fs/nsfs.c:66
      open_related_ns+0xda/0x200 fs/nsfs.c:143
      sock_ioctl+0x39d/0x440 net/socket.c:1001
      vfs_ioctl fs/ioctl.c:45 [inline]
      do_vfs_ioctl+0x1bf/0x1780 fs/ioctl.c:685
      SYSC_ioctl fs/ioctl.c:700 [inline]
      SyS_ioctl+0x8f/0xc0 fs/ioctl.c:691
    
    We are under rcu read lock protection at that point:
    
            rcu_read_lock();
            d = atomic_long_read(&ns->stashed);
            if (!d)
                    goto slow;
            dentry = (struct dentry *)d;
            if (!lockref_get_not_dead(&dentry->d_lockref))
                    goto slow;
            rcu_read_unlock();
    
    but don't use a proper RCU API on the free path, therefore a parallel
    __d_free() could free it at the same time.  We need to mark the stashed
    dentry with DCACHE_RCUACCESS so that __d_free() will be called after all
    readers leave RCU.
    
    Fixes: e149ed2b805f ("take the targets of /proc/*/ns/* symlinks to separate fs")
    Cc: Alexander Viro <viro@zeniv.linux.org.uk>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 3b7dabf029478bb80507a6c4500ca94132a2bc0b
Author: Liping Zhang <zlpnobody@gmail.com>
Date:   Sat Mar 25 08:53:12 2017 +0800

    netfilter: invoke synchronize_rcu after set the _hook_ to NULL
    
    Otherwise, another CPU may access the invalid pointer. For example:
        CPU0                CPU1
         -              rcu_read_lock();
         -              pfunc = _hook_;
      _hook_ = NULL;          -
      mod unload              -
         -                 pfunc(); // invalid, panic
         -             rcu_read_unlock();
    
    So we must call synchronize_rcu() to wait the rcu reader to finish.
    
    Also note, in nf_nat_snmp_basic_fini, synchronize_rcu() will be invoked
    by later nf_conntrack_helper_unregister, but I'm inclined to add a
    explicit synchronize_rcu after set the nf_nat_snmp_hook to NULL. Depend
    on such obscure assumptions is not a good idea.
    
    Last, in nfnetlink_cttimeout, we use kfree_rcu to free the time object,
    so in cttimeout_exit, invoking rcu_barrier() is not necessary at all,
    remove it too.
    
    Signed-off-by: Liping Zhang <zlpnobody@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 4ad23a976413aa57fe5ba7a25953dc35ccca5b71
Author: NeilBrown <neilb@suse.com>
Date:   Wed Mar 15 14:05:14 2017 +1100

    MD: use per-cpu counter for writes_pending
    
    The 'writes_pending' counter is used to determine when the
    array is stable so that it can be marked in the superblock
    as "Clean".  Consequently it needs to be updated frequently
    but only checked for zero occasionally.  Recent changes to
    raid5 cause the count to be updated even more often - once
    per 4K rather than once per bio.  This provided
    justification for making the updates more efficient.
    
    So we replace the atomic counter a percpu-refcount.
    This can be incremented and decremented cheaply most of the
    time, and can be switched to "atomic" mode when more
    precise counting is needed.  As it is possible for multiple
    threads to want a precise count, we introduce a
    "sync_checker" counter to count the number of threads
    in "set_in_sync()", and only switch the refcount back
    to percpu mode when that is zero.
    
    We need to be careful about races between set_in_sync()
    setting ->in_sync to 1, and md_write_start() setting it
    to zero.  md_write_start() holds the rcu_read_lock()
    while checking if the refcount is in percpu mode.  If
    it is, then we know a switch to 'atomic' will not happen until
    after we call rcu_read_unlock(), in which case set_in_sync()
    will see the elevated count, and not set in_sync to 1.
    If it is not in percpu mode, we take the mddev->lock to
    ensure proper synchronization.
    
    It is no longer possible to quickly check if the count is zero, which
    we previously did to update a timer or to schedule the md_thread.
    So now we do these every time we decrement that counter, but make
    sure they are fast.
    
    mod_timer() already optimizes the case where the timeout value doesn't
    actually change.  We leverage that further by always rounding off the
    jiffies to the timeout value.  This may delay the marking of 'clean'
    slightly, but ensure we only perform atomic operation here when absolutely
    needed.
    
    md_wakeup_thread() current always calls wake_up(), even if
    THREAD_WAKEUP is already set.  That too can be optimised to avoid
    calls to wake_up().
    
    Signed-off-by: NeilBrown <neilb@suse.com>
    Signed-off-by: Shaohua Li <shli@fb.com>

commit 92ab4dea27c10c9ed44830d8a4d7a1b625838289
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Mar 5 10:52:16 2017 -0800

    dccp: fix use-after-free in dccp_feat_activate_values
    
    [ Upstream commit 62f8f4d9066c1c6f2474845d1ca7e2891f2ae3fd ]
    
    Dmitry reported crashes in DCCP stack [1]
    
    Problem here is that when I got rid of listener spinlock, I missed the
    fact that DCCP stores a complex state in struct dccp_request_sock,
    while TCP does not.
    
    Since multiple cpus could access it at the same time, we need to add
    protection.
    
    [1]
    BUG: KASAN: use-after-free in dccp_feat_activate_values+0x967/0xab0
    net/dccp/feat.c:1541 at addr ffff88003713be68
    Read of size 8 by task syz-executor2/8457
    CPU: 2 PID: 8457 Comm: syz-executor2 Not tainted 4.10.0-rc7+ #127
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:15 [inline]
     dump_stack+0x292/0x398 lib/dump_stack.c:51
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:162
     print_address_description mm/kasan/report.c:200 [inline]
     kasan_report_error mm/kasan/report.c:289 [inline]
     kasan_report.part.1+0x20e/0x4e0 mm/kasan/report.c:311
     kasan_report mm/kasan/report.c:332 [inline]
     __asan_report_load8_noabort+0x29/0x30 mm/kasan/report.c:332
     dccp_feat_activate_values+0x967/0xab0 net/dccp/feat.c:1541
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1f2/0x200 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:971 [inline]
     ip6_finish_output2+0xbb0/0x23d0 net/ipv6/ip6_output.c:123
     ip6_finish_output+0x302/0x960 net/ipv6/ip6_output.c:148
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip6_output+0x1cb/0x8d0 net/ipv6/ip6_output.c:162
     ip6_xmit+0xcdf/0x20d0 include/net/dst.h:501
     inet6_csk_xmit+0x320/0x5f0 net/ipv6/inet6_connection_sock.c:179
     dccp_transmit_skb+0xb09/0x1120 net/dccp/output.c:141
     dccp_xmit_packet+0x215/0x760 net/dccp/output.c:280
     dccp_write_xmit+0x168/0x1d0 net/dccp/output.c:362
     dccp_sendmsg+0x79c/0xb10 net/dccp/proto.c:796
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:744
     sock_sendmsg_nosec net/socket.c:635 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:645
     SYSC_sendto+0x660/0x810 net/socket.c:1687
     SyS_sendto+0x40/0x50 net/socket.c:1655
     entry_SYSCALL_64_fastpath+0x1f/0xc2
    RIP: 0033:0x4458b9
    RSP: 002b:00007f8ceb77bb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 00000000004458b9
    RDX: 0000000000000023 RSI: 0000000020e60000 RDI: 0000000000000017
    RBP: 00000000006e1b90 R08: 00000000200f9fe1 R09: 0000000000000020
    R10: 0000000000008010 R11: 0000000000000282 R12: 00000000007080a8
    R13: 0000000000000000 R14: 00007f8ceb77c9c0 R15: 00007f8ceb77c700
    Object at ffff88003713be50, in cache kmalloc-64 size: 64
    Allocated:
    PID = 8446
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:605
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2738
     kmalloc include/linux/slab.h:490 [inline]
     dccp_feat_entry_new+0x214/0x410 net/dccp/feat.c:467
     dccp_feat_push_change+0x38/0x220 net/dccp/feat.c:487
     __feat_register_sp+0x223/0x2f0 net/dccp/feat.c:741
     dccp_feat_propagate_ccid+0x22b/0x2b0 net/dccp/feat.c:949
     dccp_feat_server_ccid_dependencies+0x1b3/0x250 net/dccp/feat.c:1012
     dccp_make_response+0x1f1/0xc90 net/dccp/output.c:423
     dccp_v6_send_response+0x4ec/0xc20 net/dccp/ipv6.c:217
     dccp_v6_conn_request+0xaba/0x11b0 net/dccp/ipv6.c:377
     dccp_rcv_state_process+0x51e/0x1650 net/dccp/input.c:606
     dccp_v6_do_rcv+0x213/0x350 net/dccp/ipv6.c:632
     sk_backlog_rcv include/net/sock.h:893 [inline]
     __sk_receive_skb+0x36f/0xcc0 net/core/sock.c:479
     dccp_v6_rcv+0xba5/0x1d00 net/dccp/ipv6.c:742
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Freed:
    PID = 15
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:578
     slab_free_hook mm/slub.c:1355 [inline]
     slab_free_freelist_hook mm/slub.c:1377 [inline]
     slab_free mm/slub.c:2954 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3874
     dccp_feat_entry_destructor.part.4+0x48/0x60 net/dccp/feat.c:418
     dccp_feat_entry_destructor net/dccp/feat.c:416 [inline]
     dccp_feat_list_pop net/dccp/feat.c:541 [inline]
     dccp_feat_activate_values+0x57f/0xab0 net/dccp/feat.c:1543
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Memory state around the buggy address:
     ffff88003713bd00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     ffff88003713bd80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    >ffff88003713be00: fc fc fc fc fc fc fc fc fc fc fb fb fb fb fb fb
                                                              ^
    
    Fixes: 079096f103fa ("tcp/dccp: install syn_recv requests into ehash table")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a6ff06211b846bc812b22f0c2422bd5bbc41ec83
Author: Alexey Khoroshilov <khoroshilov@ispras.ru>
Date:   Sun Mar 5 03:01:55 2017 +0300

    net/sched: act_skbmod: remove unneeded rcu_read_unlock in tcf_skbmod_dump
    
    [ Upstream commit 6c4dc75c251721f517e9daeb5370ea606b5b35ce ]
    
    Found by Linux Driver Verification project (linuxtesting.org).
    
    Signed-off-by: Alexey Khoroshilov <khoroshilov@ispras.ru>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7c0eaeec84d14d4b85773ccac8bffe8b2eafea7c
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Mar 5 10:52:16 2017 -0800

    dccp: fix use-after-free in dccp_feat_activate_values
    
    [ Upstream commit 62f8f4d9066c1c6f2474845d1ca7e2891f2ae3fd ]
    
    Dmitry reported crashes in DCCP stack [1]
    
    Problem here is that when I got rid of listener spinlock, I missed the
    fact that DCCP stores a complex state in struct dccp_request_sock,
    while TCP does not.
    
    Since multiple cpus could access it at the same time, we need to add
    protection.
    
    [1]
    BUG: KASAN: use-after-free in dccp_feat_activate_values+0x967/0xab0
    net/dccp/feat.c:1541 at addr ffff88003713be68
    Read of size 8 by task syz-executor2/8457
    CPU: 2 PID: 8457 Comm: syz-executor2 Not tainted 4.10.0-rc7+ #127
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:15 [inline]
     dump_stack+0x292/0x398 lib/dump_stack.c:51
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:162
     print_address_description mm/kasan/report.c:200 [inline]
     kasan_report_error mm/kasan/report.c:289 [inline]
     kasan_report.part.1+0x20e/0x4e0 mm/kasan/report.c:311
     kasan_report mm/kasan/report.c:332 [inline]
     __asan_report_load8_noabort+0x29/0x30 mm/kasan/report.c:332
     dccp_feat_activate_values+0x967/0xab0 net/dccp/feat.c:1541
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1f2/0x200 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:971 [inline]
     ip6_finish_output2+0xbb0/0x23d0 net/ipv6/ip6_output.c:123
     ip6_finish_output+0x302/0x960 net/ipv6/ip6_output.c:148
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip6_output+0x1cb/0x8d0 net/ipv6/ip6_output.c:162
     ip6_xmit+0xcdf/0x20d0 include/net/dst.h:501
     inet6_csk_xmit+0x320/0x5f0 net/ipv6/inet6_connection_sock.c:179
     dccp_transmit_skb+0xb09/0x1120 net/dccp/output.c:141
     dccp_xmit_packet+0x215/0x760 net/dccp/output.c:280
     dccp_write_xmit+0x168/0x1d0 net/dccp/output.c:362
     dccp_sendmsg+0x79c/0xb10 net/dccp/proto.c:796
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:744
     sock_sendmsg_nosec net/socket.c:635 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:645
     SYSC_sendto+0x660/0x810 net/socket.c:1687
     SyS_sendto+0x40/0x50 net/socket.c:1655
     entry_SYSCALL_64_fastpath+0x1f/0xc2
    RIP: 0033:0x4458b9
    RSP: 002b:00007f8ceb77bb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 00000000004458b9
    RDX: 0000000000000023 RSI: 0000000020e60000 RDI: 0000000000000017
    RBP: 00000000006e1b90 R08: 00000000200f9fe1 R09: 0000000000000020
    R10: 0000000000008010 R11: 0000000000000282 R12: 00000000007080a8
    R13: 0000000000000000 R14: 00007f8ceb77c9c0 R15: 00007f8ceb77c700
    Object at ffff88003713be50, in cache kmalloc-64 size: 64
    Allocated:
    PID = 8446
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:605
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2738
     kmalloc include/linux/slab.h:490 [inline]
     dccp_feat_entry_new+0x214/0x410 net/dccp/feat.c:467
     dccp_feat_push_change+0x38/0x220 net/dccp/feat.c:487
     __feat_register_sp+0x223/0x2f0 net/dccp/feat.c:741
     dccp_feat_propagate_ccid+0x22b/0x2b0 net/dccp/feat.c:949
     dccp_feat_server_ccid_dependencies+0x1b3/0x250 net/dccp/feat.c:1012
     dccp_make_response+0x1f1/0xc90 net/dccp/output.c:423
     dccp_v6_send_response+0x4ec/0xc20 net/dccp/ipv6.c:217
     dccp_v6_conn_request+0xaba/0x11b0 net/dccp/ipv6.c:377
     dccp_rcv_state_process+0x51e/0x1650 net/dccp/input.c:606
     dccp_v6_do_rcv+0x213/0x350 net/dccp/ipv6.c:632
     sk_backlog_rcv include/net/sock.h:893 [inline]
     __sk_receive_skb+0x36f/0xcc0 net/core/sock.c:479
     dccp_v6_rcv+0xba5/0x1d00 net/dccp/ipv6.c:742
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Freed:
    PID = 15
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:578
     slab_free_hook mm/slub.c:1355 [inline]
     slab_free_freelist_hook mm/slub.c:1377 [inline]
     slab_free mm/slub.c:2954 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3874
     dccp_feat_entry_destructor.part.4+0x48/0x60 net/dccp/feat.c:418
     dccp_feat_entry_destructor net/dccp/feat.c:416 [inline]
     dccp_feat_list_pop net/dccp/feat.c:541 [inline]
     dccp_feat_activate_values+0x57f/0xab0 net/dccp/feat.c:1543
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Memory state around the buggy address:
     ffff88003713bd00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     ffff88003713bd80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    >ffff88003713be00: fc fc fc fc fc fc fc fc fc fc fb fb fb fb fb fb
                                                              ^
    
    Fixes: 079096f103fa ("tcp/dccp: install syn_recv requests into ehash table")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5f79aab41dedaa869ef3c706e4c0872318665884
Author: Alexey Khoroshilov <khoroshilov@ispras.ru>
Date:   Sun Mar 5 03:01:55 2017 +0300

    net/sched: act_skbmod: remove unneeded rcu_read_unlock in tcf_skbmod_dump
    
    [ Upstream commit 6c4dc75c251721f517e9daeb5370ea606b5b35ce ]
    
    Found by Linux Driver Verification project (linuxtesting.org).
    
    Signed-off-by: Alexey Khoroshilov <khoroshilov@ispras.ru>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d0ebde92fbeb98eedbfce15cef3c86b652846d25
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Mar 5 10:52:16 2017 -0800

    dccp: fix use-after-free in dccp_feat_activate_values
    
    [ Upstream commit 62f8f4d9066c1c6f2474845d1ca7e2891f2ae3fd ]
    
    Dmitry reported crashes in DCCP stack [1]
    
    Problem here is that when I got rid of listener spinlock, I missed the
    fact that DCCP stores a complex state in struct dccp_request_sock,
    while TCP does not.
    
    Since multiple cpus could access it at the same time, we need to add
    protection.
    
    [1]
    BUG: KASAN: use-after-free in dccp_feat_activate_values+0x967/0xab0
    net/dccp/feat.c:1541 at addr ffff88003713be68
    Read of size 8 by task syz-executor2/8457
    CPU: 2 PID: 8457 Comm: syz-executor2 Not tainted 4.10.0-rc7+ #127
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:15 [inline]
     dump_stack+0x292/0x398 lib/dump_stack.c:51
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:162
     print_address_description mm/kasan/report.c:200 [inline]
     kasan_report_error mm/kasan/report.c:289 [inline]
     kasan_report.part.1+0x20e/0x4e0 mm/kasan/report.c:311
     kasan_report mm/kasan/report.c:332 [inline]
     __asan_report_load8_noabort+0x29/0x30 mm/kasan/report.c:332
     dccp_feat_activate_values+0x967/0xab0 net/dccp/feat.c:1541
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1f2/0x200 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:971 [inline]
     ip6_finish_output2+0xbb0/0x23d0 net/ipv6/ip6_output.c:123
     ip6_finish_output+0x302/0x960 net/ipv6/ip6_output.c:148
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip6_output+0x1cb/0x8d0 net/ipv6/ip6_output.c:162
     ip6_xmit+0xcdf/0x20d0 include/net/dst.h:501
     inet6_csk_xmit+0x320/0x5f0 net/ipv6/inet6_connection_sock.c:179
     dccp_transmit_skb+0xb09/0x1120 net/dccp/output.c:141
     dccp_xmit_packet+0x215/0x760 net/dccp/output.c:280
     dccp_write_xmit+0x168/0x1d0 net/dccp/output.c:362
     dccp_sendmsg+0x79c/0xb10 net/dccp/proto.c:796
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:744
     sock_sendmsg_nosec net/socket.c:635 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:645
     SYSC_sendto+0x660/0x810 net/socket.c:1687
     SyS_sendto+0x40/0x50 net/socket.c:1655
     entry_SYSCALL_64_fastpath+0x1f/0xc2
    RIP: 0033:0x4458b9
    RSP: 002b:00007f8ceb77bb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 00000000004458b9
    RDX: 0000000000000023 RSI: 0000000020e60000 RDI: 0000000000000017
    RBP: 00000000006e1b90 R08: 00000000200f9fe1 R09: 0000000000000020
    R10: 0000000000008010 R11: 0000000000000282 R12: 00000000007080a8
    R13: 0000000000000000 R14: 00007f8ceb77c9c0 R15: 00007f8ceb77c700
    Object at ffff88003713be50, in cache kmalloc-64 size: 64
    Allocated:
    PID = 8446
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:605
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2738
     kmalloc include/linux/slab.h:490 [inline]
     dccp_feat_entry_new+0x214/0x410 net/dccp/feat.c:467
     dccp_feat_push_change+0x38/0x220 net/dccp/feat.c:487
     __feat_register_sp+0x223/0x2f0 net/dccp/feat.c:741
     dccp_feat_propagate_ccid+0x22b/0x2b0 net/dccp/feat.c:949
     dccp_feat_server_ccid_dependencies+0x1b3/0x250 net/dccp/feat.c:1012
     dccp_make_response+0x1f1/0xc90 net/dccp/output.c:423
     dccp_v6_send_response+0x4ec/0xc20 net/dccp/ipv6.c:217
     dccp_v6_conn_request+0xaba/0x11b0 net/dccp/ipv6.c:377
     dccp_rcv_state_process+0x51e/0x1650 net/dccp/input.c:606
     dccp_v6_do_rcv+0x213/0x350 net/dccp/ipv6.c:632
     sk_backlog_rcv include/net/sock.h:893 [inline]
     __sk_receive_skb+0x36f/0xcc0 net/core/sock.c:479
     dccp_v6_rcv+0xba5/0x1d00 net/dccp/ipv6.c:742
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Freed:
    PID = 15
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:578
     slab_free_hook mm/slub.c:1355 [inline]
     slab_free_freelist_hook mm/slub.c:1377 [inline]
     slab_free mm/slub.c:2954 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3874
     dccp_feat_entry_destructor.part.4+0x48/0x60 net/dccp/feat.c:418
     dccp_feat_entry_destructor net/dccp/feat.c:416 [inline]
     dccp_feat_list_pop net/dccp/feat.c:541 [inline]
     dccp_feat_activate_values+0x57f/0xab0 net/dccp/feat.c:1543
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Memory state around the buggy address:
     ffff88003713bd00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     ffff88003713bd80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    >ffff88003713be00: fc fc fc fc fc fc fc fc fc fc fb fb fb fb fb fb
                                                              ^
    
    Fixes: 079096f103fa ("tcp/dccp: install syn_recv requests into ehash table")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7cf6b709b6412afd1d93b2c4b37163c3602e3b95
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jan 11 21:50:46 2017 -0500

    ext4: fix deadlock between inline_data and ext4_expand_extra_isize_ea()
    
    commit c755e251357a0cee0679081f08c3f4ba797a8009 upstream.
    
    The xattr_sem deadlock problems fixed in commit 2e81a4eeedca: "ext4:
    avoid deadlock when expanding inode size" didn't include the use of
    xattr_sem in fs/ext4/inline.c.  With the addition of project quota
    which added a new extra inode field, this exposed deadlocks in the
    inline_data code similar to the ones fixed by 2e81a4eeedca.
    
    The deadlock can be reproduced via:
    
       dmesg -n 7
       mke2fs -t ext4 -O inline_data -Fq -I 256 /dev/vdc 32768
       mount -t ext4 -o debug_want_extra_isize=24 /dev/vdc /vdc
       mkdir /vdc/a
       umount /vdc
       mount -t ext4 /dev/vdc /vdc
       echo foo > /vdc/a/foo
    
    and looks like this:
    
    [   11.158815]
    [   11.160276] =============================================
    [   11.161960] [ INFO: possible recursive locking detected ]
    [   11.161960] 4.10.0-rc3-00015-g011b30a8a3cf #160 Tainted: G        W
    [   11.161960] ---------------------------------------------
    [   11.161960] bash/2519 is trying to acquire lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1225a4b>] ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]
    [   11.161960] but task is already holding lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] other info that might help us debug this:
    [   11.161960]  Possible unsafe locking scenario:
    [   11.161960]
    [   11.161960]        CPU0
    [   11.161960]        ----
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]
    [   11.161960]  *** DEADLOCK ***
    [   11.161960]
    [   11.161960]  May be due to missing lock nesting notation
    [   11.161960]
    [   11.161960] 4 locks held by bash/2519:
    [   11.161960]  #0:  (sb_writers#3){.+.+.+}, at: [<c11a2414>] mnt_want_write+0x1e/0x3e
    [   11.161960]  #1:  (&type->i_mutex_dir_key){++++++}, at: [<c119508b>] path_openat+0x338/0x67a
    [   11.161960]  #2:  (jbd2_handle){++++..}, at: [<c123314a>] start_this_handle+0x582/0x622
    [   11.161960]  #3:  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] stack backtrace:
    [   11.161960] CPU: 0 PID: 2519 Comm: bash Tainted: G        W       4.10.0-rc3-00015-g011b30a8a3cf #160
    [   11.161960] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1 04/01/2014
    [   11.161960] Call Trace:
    [   11.161960]  dump_stack+0x72/0xa3
    [   11.161960]  __lock_acquire+0xb7c/0xcb9
    [   11.161960]  ? kvm_clock_read+0x1f/0x29
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  lock_acquire+0x106/0x18a
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  down_write+0x39/0x72
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ? _raw_read_unlock+0x22/0x2c
    [   11.161960]  ? jbd2_journal_extend+0x1e2/0x262
    [   11.161960]  ? __ext4_journal_get_write_access+0x3d/0x60
    [   11.161960]  ext4_mark_inode_dirty+0x17d/0x26d
    [   11.161960]  ? ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_try_add_inline_entry+0x69/0x152
    [   11.161960]  ext4_add_entry+0xa3/0x848
    [   11.161960]  ? __brelse+0x14/0x2f
    [   11.161960]  ? _raw_spin_unlock_irqrestore+0x44/0x4f
    [   11.161960]  ext4_add_nondir+0x17/0x5b
    [   11.161960]  ext4_create+0xcf/0x133
    [   11.161960]  ? ext4_mknod+0x12f/0x12f
    [   11.161960]  lookup_open+0x39e/0x3fb
    [   11.161960]  ? __wake_up+0x1a/0x40
    [   11.161960]  ? lock_acquire+0x11e/0x18a
    [   11.161960]  path_openat+0x35c/0x67a
    [   11.161960]  ? sched_clock_cpu+0xd7/0xf2
    [   11.161960]  do_filp_open+0x36/0x7c
    [   11.161960]  ? _raw_spin_unlock+0x22/0x2c
    [   11.161960]  ? __alloc_fd+0x169/0x173
    [   11.161960]  do_sys_open+0x59/0xcc
    [   11.161960]  SyS_open+0x1d/0x1f
    [   11.161960]  do_int80_syscall_32+0x4f/0x61
    [   11.161960]  entry_INT80_32+0x2f/0x2f
    [   11.161960] EIP: 0xb76ad469
    [   11.161960] EFLAGS: 00000286 CPU: 0
    [   11.161960] EAX: ffffffda EBX: 08168ac8 ECX: 00008241 EDX: 000001b6
    [   11.161960] ESI: b75e46bc EDI: b7755000 EBP: bfbdb108 ESP: bfbdafc0
    [   11.161960]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Reported-by: George Spelvin <linux@sciencehorizons.net>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit da1e40237f8f3516581b534c484c236a79ccfd14
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jan 11 21:50:46 2017 -0500

    ext4: fix deadlock between inline_data and ext4_expand_extra_isize_ea()
    
    commit c755e251357a0cee0679081f08c3f4ba797a8009 upstream.
    
    The xattr_sem deadlock problems fixed in commit 2e81a4eeedca: "ext4:
    avoid deadlock when expanding inode size" didn't include the use of
    xattr_sem in fs/ext4/inline.c.  With the addition of project quota
    which added a new extra inode field, this exposed deadlocks in the
    inline_data code similar to the ones fixed by 2e81a4eeedca.
    
    The deadlock can be reproduced via:
    
       dmesg -n 7
       mke2fs -t ext4 -O inline_data -Fq -I 256 /dev/vdc 32768
       mount -t ext4 -o debug_want_extra_isize=24 /dev/vdc /vdc
       mkdir /vdc/a
       umount /vdc
       mount -t ext4 /dev/vdc /vdc
       echo foo > /vdc/a/foo
    
    and looks like this:
    
    [   11.158815]
    [   11.160276] =============================================
    [   11.161960] [ INFO: possible recursive locking detected ]
    [   11.161960] 4.10.0-rc3-00015-g011b30a8a3cf #160 Tainted: G        W
    [   11.161960] ---------------------------------------------
    [   11.161960] bash/2519 is trying to acquire lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1225a4b>] ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]
    [   11.161960] but task is already holding lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] other info that might help us debug this:
    [   11.161960]  Possible unsafe locking scenario:
    [   11.161960]
    [   11.161960]        CPU0
    [   11.161960]        ----
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]
    [   11.161960]  *** DEADLOCK ***
    [   11.161960]
    [   11.161960]  May be due to missing lock nesting notation
    [   11.161960]
    [   11.161960] 4 locks held by bash/2519:
    [   11.161960]  #0:  (sb_writers#3){.+.+.+}, at: [<c11a2414>] mnt_want_write+0x1e/0x3e
    [   11.161960]  #1:  (&type->i_mutex_dir_key){++++++}, at: [<c119508b>] path_openat+0x338/0x67a
    [   11.161960]  #2:  (jbd2_handle){++++..}, at: [<c123314a>] start_this_handle+0x582/0x622
    [   11.161960]  #3:  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] stack backtrace:
    [   11.161960] CPU: 0 PID: 2519 Comm: bash Tainted: G        W       4.10.0-rc3-00015-g011b30a8a3cf #160
    [   11.161960] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1 04/01/2014
    [   11.161960] Call Trace:
    [   11.161960]  dump_stack+0x72/0xa3
    [   11.161960]  __lock_acquire+0xb7c/0xcb9
    [   11.161960]  ? kvm_clock_read+0x1f/0x29
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  lock_acquire+0x106/0x18a
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  down_write+0x39/0x72
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ? _raw_read_unlock+0x22/0x2c
    [   11.161960]  ? jbd2_journal_extend+0x1e2/0x262
    [   11.161960]  ? __ext4_journal_get_write_access+0x3d/0x60
    [   11.161960]  ext4_mark_inode_dirty+0x17d/0x26d
    [   11.161960]  ? ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_try_add_inline_entry+0x69/0x152
    [   11.161960]  ext4_add_entry+0xa3/0x848
    [   11.161960]  ? __brelse+0x14/0x2f
    [   11.161960]  ? _raw_spin_unlock_irqrestore+0x44/0x4f
    [   11.161960]  ext4_add_nondir+0x17/0x5b
    [   11.161960]  ext4_create+0xcf/0x133
    [   11.161960]  ? ext4_mknod+0x12f/0x12f
    [   11.161960]  lookup_open+0x39e/0x3fb
    [   11.161960]  ? __wake_up+0x1a/0x40
    [   11.161960]  ? lock_acquire+0x11e/0x18a
    [   11.161960]  path_openat+0x35c/0x67a
    [   11.161960]  ? sched_clock_cpu+0xd7/0xf2
    [   11.161960]  do_filp_open+0x36/0x7c
    [   11.161960]  ? _raw_spin_unlock+0x22/0x2c
    [   11.161960]  ? __alloc_fd+0x169/0x173
    [   11.161960]  do_sys_open+0x59/0xcc
    [   11.161960]  SyS_open+0x1d/0x1f
    [   11.161960]  do_int80_syscall_32+0x4f/0x61
    [   11.161960]  entry_INT80_32+0x2f/0x2f
    [   11.161960] EIP: 0xb76ad469
    [   11.161960] EFLAGS: 00000286 CPU: 0
    [   11.161960] EAX: ffffffda EBX: 08168ac8 ECX: 00008241 EDX: 000001b6
    [   11.161960] ESI: b75e46bc EDI: b7755000 EBP: bfbdb108 ESP: bfbdafc0
    [   11.161960]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Reported-by: George Spelvin <linux@sciencehorizons.net>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 62f8f4d9066c1c6f2474845d1ca7e2891f2ae3fd
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Mar 5 10:52:16 2017 -0800

    dccp: fix use-after-free in dccp_feat_activate_values
    
    Dmitry reported crashes in DCCP stack [1]
    
    Problem here is that when I got rid of listener spinlock, I missed the
    fact that DCCP stores a complex state in struct dccp_request_sock,
    while TCP does not.
    
    Since multiple cpus could access it at the same time, we need to add
    protection.
    
    [1]
    BUG: KASAN: use-after-free in dccp_feat_activate_values+0x967/0xab0
    net/dccp/feat.c:1541 at addr ffff88003713be68
    Read of size 8 by task syz-executor2/8457
    CPU: 2 PID: 8457 Comm: syz-executor2 Not tainted 4.10.0-rc7+ #127
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:15 [inline]
     dump_stack+0x292/0x398 lib/dump_stack.c:51
     kasan_object_err+0x1c/0x70 mm/kasan/report.c:162
     print_address_description mm/kasan/report.c:200 [inline]
     kasan_report_error mm/kasan/report.c:289 [inline]
     kasan_report.part.1+0x20e/0x4e0 mm/kasan/report.c:311
     kasan_report mm/kasan/report.c:332 [inline]
     __asan_report_load8_noabort+0x29/0x30 mm/kasan/report.c:332
     dccp_feat_activate_values+0x967/0xab0 net/dccp/feat.c:1541
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
     do_softirq_own_stack+0x1c/0x30 arch/x86/entry/entry_64.S:902
     </IRQ>
     do_softirq.part.17+0x1e8/0x230 kernel/softirq.c:328
     do_softirq kernel/softirq.c:176 [inline]
     __local_bh_enable_ip+0x1f2/0x200 kernel/softirq.c:181
     local_bh_enable include/linux/bottom_half.h:31 [inline]
     rcu_read_unlock_bh include/linux/rcupdate.h:971 [inline]
     ip6_finish_output2+0xbb0/0x23d0 net/ipv6/ip6_output.c:123
     ip6_finish_output+0x302/0x960 net/ipv6/ip6_output.c:148
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip6_output+0x1cb/0x8d0 net/ipv6/ip6_output.c:162
     ip6_xmit+0xcdf/0x20d0 include/net/dst.h:501
     inet6_csk_xmit+0x320/0x5f0 net/ipv6/inet6_connection_sock.c:179
     dccp_transmit_skb+0xb09/0x1120 net/dccp/output.c:141
     dccp_xmit_packet+0x215/0x760 net/dccp/output.c:280
     dccp_write_xmit+0x168/0x1d0 net/dccp/output.c:362
     dccp_sendmsg+0x79c/0xb10 net/dccp/proto.c:796
     inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:744
     sock_sendmsg_nosec net/socket.c:635 [inline]
     sock_sendmsg+0xca/0x110 net/socket.c:645
     SYSC_sendto+0x660/0x810 net/socket.c:1687
     SyS_sendto+0x40/0x50 net/socket.c:1655
     entry_SYSCALL_64_fastpath+0x1f/0xc2
    RIP: 0033:0x4458b9
    RSP: 002b:00007f8ceb77bb58 EFLAGS: 00000282 ORIG_RAX: 000000000000002c
    RAX: ffffffffffffffda RBX: 0000000000000017 RCX: 00000000004458b9
    RDX: 0000000000000023 RSI: 0000000020e60000 RDI: 0000000000000017
    RBP: 00000000006e1b90 R08: 00000000200f9fe1 R09: 0000000000000020
    R10: 0000000000008010 R11: 0000000000000282 R12: 00000000007080a8
    R13: 0000000000000000 R14: 00007f8ceb77c9c0 R15: 00007f8ceb77c700
    Object at ffff88003713be50, in cache kmalloc-64 size: 64
    Allocated:
    PID = 8446
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_kmalloc+0xad/0xe0 mm/kasan/kasan.c:605
     kmem_cache_alloc_trace+0x82/0x270 mm/slub.c:2738
     kmalloc include/linux/slab.h:490 [inline]
     dccp_feat_entry_new+0x214/0x410 net/dccp/feat.c:467
     dccp_feat_push_change+0x38/0x220 net/dccp/feat.c:487
     __feat_register_sp+0x223/0x2f0 net/dccp/feat.c:741
     dccp_feat_propagate_ccid+0x22b/0x2b0 net/dccp/feat.c:949
     dccp_feat_server_ccid_dependencies+0x1b3/0x250 net/dccp/feat.c:1012
     dccp_make_response+0x1f1/0xc90 net/dccp/output.c:423
     dccp_v6_send_response+0x4ec/0xc20 net/dccp/ipv6.c:217
     dccp_v6_conn_request+0xaba/0x11b0 net/dccp/ipv6.c:377
     dccp_rcv_state_process+0x51e/0x1650 net/dccp/input.c:606
     dccp_v6_do_rcv+0x213/0x350 net/dccp/ipv6.c:632
     sk_backlog_rcv include/net/sock.h:893 [inline]
     __sk_receive_skb+0x36f/0xcc0 net/core/sock.c:479
     dccp_v6_rcv+0xba5/0x1d00 net/dccp/ipv6.c:742
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Freed:
    PID = 15
     save_stack_trace+0x16/0x20 arch/x86/kernel/stacktrace.c:57
     save_stack+0x43/0xd0 mm/kasan/kasan.c:502
     set_track mm/kasan/kasan.c:514 [inline]
     kasan_slab_free+0x73/0xc0 mm/kasan/kasan.c:578
     slab_free_hook mm/slub.c:1355 [inline]
     slab_free_freelist_hook mm/slub.c:1377 [inline]
     slab_free mm/slub.c:2954 [inline]
     kfree+0xe8/0x2b0 mm/slub.c:3874
     dccp_feat_entry_destructor.part.4+0x48/0x60 net/dccp/feat.c:418
     dccp_feat_entry_destructor net/dccp/feat.c:416 [inline]
     dccp_feat_list_pop net/dccp/feat.c:541 [inline]
     dccp_feat_activate_values+0x57f/0xab0 net/dccp/feat.c:1543
     dccp_create_openreq_child+0x464/0x610 net/dccp/minisocks.c:121
     dccp_v6_request_recv_sock+0x1f6/0x1960 net/dccp/ipv6.c:457
     dccp_check_req+0x335/0x5a0 net/dccp/minisocks.c:186
     dccp_v6_rcv+0x69e/0x1d00 net/dccp/ipv6.c:711
     ip6_input_finish+0x46d/0x17a0 net/ipv6/ip6_input.c:279
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ip6_input+0xdb/0x590 net/ipv6/ip6_input.c:322
     dst_input include/net/dst.h:507 [inline]
     ip6_rcv_finish+0x289/0x890 net/ipv6/ip6_input.c:69
     NF_HOOK include/linux/netfilter.h:257 [inline]
     ipv6_rcv+0x12ec/0x23d0 net/ipv6/ip6_input.c:203
     __netif_receive_skb_core+0x1ae5/0x3400 net/core/dev.c:4190
     __netif_receive_skb+0x2a/0x170 net/core/dev.c:4228
     process_backlog+0xe5/0x6c0 net/core/dev.c:4839
     napi_poll net/core/dev.c:5202 [inline]
     net_rx_action+0xe70/0x1900 net/core/dev.c:5267
     __do_softirq+0x2fb/0xb7d kernel/softirq.c:284
    Memory state around the buggy address:
     ffff88003713bd00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     ffff88003713bd80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    >ffff88003713be00: fc fc fc fc fc fc fc fc fc fc fb fb fb fb fb fb
                                                              ^
    
    Fixes: 079096f103fa ("tcp/dccp: install syn_recv requests into ehash table")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Tested-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6c4dc75c251721f517e9daeb5370ea606b5b35ce
Author: Alexey Khoroshilov <khoroshilov@ispras.ru>
Date:   Sun Mar 5 03:01:55 2017 +0300

    net/sched: act_skbmod: remove unneeded rcu_read_unlock in tcf_skbmod_dump
    
    Found by Linux Driver Verification project (linuxtesting.org).
    
    Signed-off-by: Alexey Khoroshilov <khoroshilov@ispras.ru>
    Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b1517622f2524f531113b12c27b9a0ea69c38983
Author: Filipe Manana <fdmanana@suse.com>
Date:   Tue Feb 21 17:14:52 2017 +0000

    Btrfs: fix deadlock between dedup on same file and starting writeback
    
    If we are deduping two ranges of the same file we need to make sure that
    we lock all pages in ascending order, that is, lock first the pages from
    the range with lower offset and then the pages from the other range, as
    otherwise we can deadlock with a concurrent task that is starting delalloc
    (writeback). Example trace:
    
    [74073.052218] INFO: task kworker/u32:10:17997 blocked for more than 120 seconds.
    [74073.053889]       Tainted: G        W       4.9.0-rc7-btrfs-next-36+ #1
    [74073.055071] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [74073.056696] kworker/u32:10  D    0 17997      2 0x00000000
    [74073.058606] Workqueue: writeback wb_workfn (flush-btrfs-53176)
    [74073.061370]  ffff880031e79858 ffff8802159d2580 ffff880237004580 ffff880031e79240
    [74073.064784]  ffff88023f4978c0 ffffc9000817b638 ffffffff814c15e1 0000000000000000
    [74073.068386]  ffff88023f4978d8 ffff88023f4978c0 000000000017b620 ffff880031e79240
    [74073.071712] Call Trace:
    [74073.072884]  [<ffffffff814c15e1>] ? __schedule+0x48f/0x6f4
    [74073.075395]  [<ffffffff814c1c8b>] ? bit_wait+0x2f/0x2f
    [74073.077511]  [<ffffffff814c18d2>] schedule+0x8c/0xa0
    [74073.079440]  [<ffffffff814c4b36>] schedule_timeout+0x43/0xff
    [74073.081637]  [<ffffffff8110953e>] ? time_hardirqs_on+0x9/0x14
    [74073.083809]  [<ffffffff81095c67>] ? trace_hardirqs_on_caller+0x16/0x197
    [74073.086314]  [<ffffffff810bde98>] ? timekeeping_get_ns+0x1e/0x32
    [74073.100654]  [<ffffffff810be048>] ? ktime_get+0x41/0x52
    [74073.102619]  [<ffffffff814c10f0>] io_schedule_timeout+0xa0/0x102
    [74073.104771]  [<ffffffff814c10f0>] ? io_schedule_timeout+0xa0/0x102
    [74073.106969]  [<ffffffff814c1ca6>] bit_wait_io+0x1b/0x39
    [74073.108954]  [<ffffffff814c1fb8>] __wait_on_bit_lock+0x4f/0x99
    [74073.110981]  [<ffffffff8112b692>] __lock_page+0x6b/0x6d
    [74073.112833]  [<ffffffff8108ceb4>] ? autoremove_wake_function+0x3a/0x3a
    [74073.115010]  [<ffffffffa031178b>] lock_page+0x2f/0x32 [btrfs]
    [74073.116999]  [<ffffffffa0311d9f>] lock_delalloc_pages+0xc7/0x1a0 [btrfs]
    [74073.119243]  [<ffffffffa0313d15>] find_lock_delalloc_range+0xc3/0x1a4 [btrfs]
    [74073.121636]  [<ffffffffa0313e81>] writepage_delalloc.isra.31+0x8b/0x134 [btrfs]
    [74073.124229]  [<ffffffffa0315d69>] __extent_writepage+0x1c1/0x2bf [btrfs]
    [74073.126372]  [<ffffffffa03160f2>] extent_write_cache_pages.isra.30.constprop.49+0x28b/0x36c [btrfs]
    [74073.129371]  [<ffffffffa03165b9>] extent_writepages+0x4b/0x5c [btrfs]
    [74073.131440]  [<ffffffffa02fcb59>] ? insert_reserved_file_extent.constprop.42+0x261/0x261 [btrfs]
    [74073.134303]  [<ffffffff811b4ce4>] ? writeback_sb_inodes+0xe0/0x4a1
    [74073.136298]  [<ffffffffa02fab7f>] btrfs_writepages+0x28/0x2a [btrfs]
    [74073.138248]  [<ffffffff81138200>] do_writepages+0x23/0x2c
    [74073.139910]  [<ffffffff811b3cab>] __writeback_single_inode+0x105/0x6d2
    [74073.142003]  [<ffffffff811b4e96>] writeback_sb_inodes+0x292/0x4a1
    [74073.136298]  [<ffffffffa02fab7f>] btrfs_writepages+0x28/0x2a [btrfs]
    [74073.138248]  [<ffffffff81138200>] do_writepages+0x23/0x2c
    [74073.139910]  [<ffffffff811b3cab>] __writeback_single_inode+0x105/0x6d2
    [74073.142003]  [<ffffffff811b4e96>] writeback_sb_inodes+0x292/0x4a1
    [74073.143911]  [<ffffffff811b511b>] __writeback_inodes_wb+0x76/0xae
    [74073.145787]  [<ffffffff811b53ca>] wb_writeback+0x1cc/0x4d7
    [74073.147452]  [<ffffffff811b60cd>] wb_workfn+0x194/0x37d
    [74073.149084]  [<ffffffff811b60cd>] ? wb_workfn+0x194/0x37d
    [74073.150726]  [<ffffffff8106ce77>] ? process_one_work+0x154/0x4e4
    [74073.152694]  [<ffffffff8106cf96>] process_one_work+0x273/0x4e4
    [74073.154452]  [<ffffffff8106d6db>] worker_thread+0x1eb/0x2ca
    [74073.156138]  [<ffffffff8106d4f0>] ? rescuer_thread+0x2b6/0x2b6
    [74073.157837]  [<ffffffff81072a81>] kthread+0xd5/0xdd
    [74073.159339]  [<ffffffff810729ac>] ? __kthread_unpark+0x5a/0x5a
    [74073.161088]  [<ffffffff814c6257>] ret_from_fork+0x27/0x40
    [74073.162680] INFO: lockdep is turned off.
    [74073.163855] INFO: task do-dedup:30264 blocked for more than 120 seconds.
    [74073.181180]       Tainted: G        W       4.9.0-rc7-btrfs-next-36+ #1
    [74073.181180] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [74073.185296] fdm-stress      D    0 30264  29974 0x00000000
    [74073.186810]  ffff880089595118 ffff880211b8eac0 ffff880237030380 ffff880089594b00
    [74073.188998]  ffff88023f2978c0 ffffc900063abb68 ffffffff814c15e1 0000000000000000
    [74073.191070]  ffff88023f2978d8 ffff88023f2978c0 00000000003abb50 ffff880089594b00
    [74073.193286] Call Trace:
    [74073.193990]  [<ffffffff814c15e1>] ? __schedule+0x48f/0x6f4
    [74073.195418]  [<ffffffff814c1c8b>] ? bit_wait+0x2f/0x2f
    [74073.196796]  [<ffffffff814c18d2>] schedule+0x8c/0xa0
    [74073.198163]  [<ffffffff814c4b36>] schedule_timeout+0x43/0xff
    [74073.199621]  [<ffffffff81095df5>] ? trace_hardirqs_on+0xd/0xf
    [74073.201100]  [<ffffffff810bde98>] ? timekeeping_get_ns+0x1e/0x32
    [74073.202686]  [<ffffffff810be048>] ? ktime_get+0x41/0x52
    [74073.204051]  [<ffffffff814c10f0>] io_schedule_timeout+0xa0/0x102
    [74073.205585]  [<ffffffff814c10f0>] ? io_schedule_timeout+0xa0/0x102
    [74073.207123]  [<ffffffff814c1ca6>] bit_wait_io+0x1b/0x39
    [74073.208238]  [<ffffffff814c1fb8>] __wait_on_bit_lock+0x4f/0x99
    [74073.208871]  [<ffffffff8112b692>] __lock_page+0x6b/0x6d
    [74073.209430]  [<ffffffff8108ceb4>] ? autoremove_wake_function+0x3a/0x3a
    [74073.210101]  [<ffffffff8112b800>] lock_page+0x2f/0x32
    [74073.210636]  [<ffffffff8112c502>] pagecache_get_page+0x5e/0x153
    [74073.211270]  [<ffffffffa03257eb>] gather_extent_pages+0x4e/0x109 [btrfs]
    [74073.212166]  [<ffffffffa032a04c>] btrfs_dedupe_file_range+0x1e1/0x4dd [btrfs]
    [74073.213257]  [<ffffffff8118d9b5>] vfs_dedupe_file_range+0x1c1/0x221
    [74073.214086]  [<ffffffff8119e0c4>] do_vfs_ioctl+0x442/0x600
    [74073.214767]  [<ffffffff811a7874>] ? rcu_read_unlock+0x5b/0x5d
    [74073.215619]  [<ffffffff811a7953>] ? __fget+0x6b/0x77
    [74073.216338]  [<ffffffff8119e2d9>] SyS_ioctl+0x57/0x79
    [74073.217149]  [<ffffffff814c5fea>] entry_SYSCALL_64_fastpath+0x18/0xad
    [74073.218102]  [<ffffffff81109552>] ? time_hardirqs_off+0x9/0x14
    [74073.218968]  [<ffffffff810938ce>] ? trace_hardirqs_off_caller+0x1f/0xaa
    [74073.219938] INFO: lockdep is turned off.
    
    What happened was the following:
    
          CPU 1                                       CPU 2
    
                                                 btrfs_dedupe_file_range()
                                                   --> using same inode as source
                                                       and target
                                                   --> src range is [768K, 1Mb[
                                                   --> dst range is [0, 256K[
                                                  btrfs_cmp_data_prepare()
                                                   --> calls gather_extent_pages()
                                                       for range [768K, 1Mb[ and
                                                       locks all pages in that range
    
     do_writepages()
      btrfs_writepages()
       extent_writepages()
        extent_write_cache_pages()
         __extent_writepage()
          writepage_delalloc()
           find_lock_delalloc_range()
             --> finds range [0, 1Mb[
             lock_delalloc_pages()
              --> locks all pages in the
                  range [0, 768K[
              --> tries to lock page at
                  offset 768K
                    --> deadlock
    
                                                   --> calls gather_extent_pages()
                                                       to lock pages in the range
                                                       [0, 256K[
                                                        --> deadlock, task at CPU 1
                                                            already locked that
                                                            range and it's trying
                                                            to lock the range we
                                                            locked previously
    
    So fix this by making sure that during a dedup we always lock first the
    pages from the range with lower offset.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Chris Mason <clm@fb.com>

commit daa86e50f649fccadafc53994ddc4254d75a008b
Author: Shannon Nelson <shannon.nelson@oracle.com>
Date:   Mon Feb 13 10:57:02 2017 -0800

    sunvnet: remove extra rcu_read_unlocks
    
    The RCU read lock is grabbed first thing in sunvnet_start_xmit_common()
    so it always needs to be released.  This removes the conditional release
    in the dropped packet error path and removes a couple of superfluous
    calls in the middle of the code.
    
    Reported-by: Bijan Mottahedeh <bijan.mottahedeh@oracle.com>
    Signed-off-by: Shannon Nelson <shannon.nelson@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a1668c25a8e1b53d00b2997ef5bc5e25c7a77235
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Fri Feb 10 16:36:11 2017 +0900

    perf diff: Add 'delta-abs' compute method
    
    The 'delta-abs' compute method is same as 'delta' but shows entries with
    bigger absolute delta first instead of sorting numerically.  This is
    only useful together with -o option.
    
    Below is default output (-c delta):
    
      $ perf diff -o 1 -c delta | grep -v ^# | head
        42.22%   +4.97%  [kernel.kallsyms]  [k] cfb_imageblit
         0.62%   +1.23%  [kernel.kallsyms]  [k] mutex_lock
                 +1.15%  [kernel.kallsyms]  [k] copy_user_generic_string
         2.40%   +0.95%  [kernel.kallsyms]  [k] bit_putcs
         0.31%   +0.79%  [kernel.kallsyms]  [k] link_path_walk
                 +0.64%  [kernel.kallsyms]  [k] kmem_cache_alloc
         0.00%   +0.57%  [kernel.kallsyms]  [k] __rcu_read_unlock
                 +0.45%  [kernel.kallsyms]  [k] alloc_set_pte
         0.16%   +0.45%  [kernel.kallsyms]  [k] menu_select
                 +0.41%  ld-2.24.so         [.] do_lookup_x
    
    Now with 'delta-abs' it shows entries have bigger delta value either
    positive or negative.
    
      $ perf diff -o 1 -c delta-abs | grep -v ^# | head
        42.22%   +4.97%  [kernel.kallsyms]  [k] cfb_imageblit
        12.72%   -3.01%  [kernel.kallsyms]  [k] intel_idle
         9.72%   -1.31%  [unknown]          [.] 0x0000000000411343
         0.62%   +1.23%  [kernel.kallsyms]  [k] mutex_lock
         2.40%   +0.95%  [kernel.kallsyms]  [k] bit_putcs
         0.31%   +0.79%  [kernel.kallsyms]  [k] link_path_walk
         1.35%   -0.71%  [kernel.kallsyms]  [k] smp_call_function_single
         0.00%   +0.57%  [kernel.kallsyms]  [k] __rcu_read_unlock
         0.16%   +0.45%  [kernel.kallsyms]  [k] menu_select
         0.72%   -0.44%  [kernel.kallsyms]  [k] lookup_fast
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/20170210073614.24584-2-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 7f554a3d05bea9f6b7bf8e0b041d09447f82d74a
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Jan 24 08:51:34 2017 -0800

    srcu: Reduce probability of SRCU ->unlock_count[] counter overflow
    
    Because there are no memory barriers between the srcu_flip() ->completed
    increment and the summation of the read-side ->unlock_count[] counters,
    both the compiler and the CPU can reorder the summation with the
    ->completed increment.  If the updater is preempted long enough during
    this process, the read-side counters could overflow, resulting in a
    too-short grace period.
    
    This commit therefore adds a memory barrier just after the ->completed
    increment, ensuring that if the summation misses an increment of
    ->unlock_count[] from __srcu_read_unlock(), the next __srcu_read_lock()
    will see the new value of ->completed, thus bounding the number of
    ->unlock_count[] increments that can be missed to NR_CPUS.  The actual
    overflow computation is more complex due to the possibility of nesting
    of __srcu_read_lock().
    
    Reported-by: Lance Roy <ldr709@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit ed3cc329c7bc82c0f29735d81b26f96287dbe08a
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 15 23:05:52 2016 +0800

    sctp: sctp_transport_lookup_process should rcu_read_unlock when transport is null
    
    [ Upstream commit 08abb79542c9e8c367d1d8e44fe1026868d3f0a7 ]
    
    Prior to this patch, sctp_transport_lookup_process didn't rcu_read_unlock
    when it failed to find a transport by sctp_addrs_lookup_transport.
    
    This patch is to fix it by moving up rcu_read_unlock right before checking
    transport and also to remove the out path.
    
    Fixes: 1cceda784980 ("sctp: fix the issue sctp_diag uses lock_sock in rcu_read_lock")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c755e251357a0cee0679081f08c3f4ba797a8009
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Wed Jan 11 21:50:46 2017 -0500

    ext4: fix deadlock between inline_data and ext4_expand_extra_isize_ea()
    
    The xattr_sem deadlock problems fixed in commit 2e81a4eeedca: "ext4:
    avoid deadlock when expanding inode size" didn't include the use of
    xattr_sem in fs/ext4/inline.c.  With the addition of project quota
    which added a new extra inode field, this exposed deadlocks in the
    inline_data code similar to the ones fixed by 2e81a4eeedca.
    
    The deadlock can be reproduced via:
    
       dmesg -n 7
       mke2fs -t ext4 -O inline_data -Fq -I 256 /dev/vdc 32768
       mount -t ext4 -o debug_want_extra_isize=24 /dev/vdc /vdc
       mkdir /vdc/a
       umount /vdc
       mount -t ext4 /dev/vdc /vdc
       echo foo > /vdc/a/foo
    
    and looks like this:
    
    [   11.158815]
    [   11.160276] =============================================
    [   11.161960] [ INFO: possible recursive locking detected ]
    [   11.161960] 4.10.0-rc3-00015-g011b30a8a3cf #160 Tainted: G        W
    [   11.161960] ---------------------------------------------
    [   11.161960] bash/2519 is trying to acquire lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1225a4b>] ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]
    [   11.161960] but task is already holding lock:
    [   11.161960]  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] other info that might help us debug this:
    [   11.161960]  Possible unsafe locking scenario:
    [   11.161960]
    [   11.161960]        CPU0
    [   11.161960]        ----
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]   lock(&ei->xattr_sem);
    [   11.161960]
    [   11.161960]  *** DEADLOCK ***
    [   11.161960]
    [   11.161960]  May be due to missing lock nesting notation
    [   11.161960]
    [   11.161960] 4 locks held by bash/2519:
    [   11.161960]  #0:  (sb_writers#3){.+.+.+}, at: [<c11a2414>] mnt_want_write+0x1e/0x3e
    [   11.161960]  #1:  (&type->i_mutex_dir_key){++++++}, at: [<c119508b>] path_openat+0x338/0x67a
    [   11.161960]  #2:  (jbd2_handle){++++..}, at: [<c123314a>] start_this_handle+0x582/0x622
    [   11.161960]  #3:  (&ei->xattr_sem){++++..}, at: [<c1227941>] ext4_try_add_inline_entry+0x3a/0x152
    [   11.161960]
    [   11.161960] stack backtrace:
    [   11.161960] CPU: 0 PID: 2519 Comm: bash Tainted: G        W       4.10.0-rc3-00015-g011b30a8a3cf #160
    [   11.161960] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.1-1 04/01/2014
    [   11.161960] Call Trace:
    [   11.161960]  dump_stack+0x72/0xa3
    [   11.161960]  __lock_acquire+0xb7c/0xcb9
    [   11.161960]  ? kvm_clock_read+0x1f/0x29
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  ? __lock_is_held+0x36/0x66
    [   11.161960]  lock_acquire+0x106/0x18a
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  down_write+0x39/0x72
    [   11.161960]  ? ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ext4_expand_extra_isize_ea+0x3d/0x4cd
    [   11.161960]  ? _raw_read_unlock+0x22/0x2c
    [   11.161960]  ? jbd2_journal_extend+0x1e2/0x262
    [   11.161960]  ? __ext4_journal_get_write_access+0x3d/0x60
    [   11.161960]  ext4_mark_inode_dirty+0x17d/0x26d
    [   11.161960]  ? ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_add_dirent_to_inline.isra.12+0xa5/0xb2
    [   11.161960]  ext4_try_add_inline_entry+0x69/0x152
    [   11.161960]  ext4_add_entry+0xa3/0x848
    [   11.161960]  ? __brelse+0x14/0x2f
    [   11.161960]  ? _raw_spin_unlock_irqrestore+0x44/0x4f
    [   11.161960]  ext4_add_nondir+0x17/0x5b
    [   11.161960]  ext4_create+0xcf/0x133
    [   11.161960]  ? ext4_mknod+0x12f/0x12f
    [   11.161960]  lookup_open+0x39e/0x3fb
    [   11.161960]  ? __wake_up+0x1a/0x40
    [   11.161960]  ? lock_acquire+0x11e/0x18a
    [   11.161960]  path_openat+0x35c/0x67a
    [   11.161960]  ? sched_clock_cpu+0xd7/0xf2
    [   11.161960]  do_filp_open+0x36/0x7c
    [   11.161960]  ? _raw_spin_unlock+0x22/0x2c
    [   11.161960]  ? __alloc_fd+0x169/0x173
    [   11.161960]  do_sys_open+0x59/0xcc
    [   11.161960]  SyS_open+0x1d/0x1f
    [   11.161960]  do_int80_syscall_32+0x4f/0x61
    [   11.161960]  entry_INT80_32+0x2f/0x2f
    [   11.161960] EIP: 0xb76ad469
    [   11.161960] EFLAGS: 00000286 CPU: 0
    [   11.161960] EAX: ffffffda EBX: 08168ac8 ECX: 00008241 EDX: 000001b6
    [   11.161960] ESI: b75e46bc EDI: b7755000 EBP: bfbdb108 ESP: bfbdafc0
    [   11.161960]  DS: 007b ES: 007b FS: 0000 GS: 0033 SS: 007b
    
    Cc: stable@vger.kernel.org # 3.10 (requires 2e81a4eeedca as a prereq)
    Reported-by: George Spelvin <linux@sciencehorizons.net>
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>

commit 75cda62d9ca2cd3fab0412d438fcd1bfa0580b3d
Author: Florian Westphal <fw@strlen.de>
Date:   Mon Jan 9 14:20:49 2017 +0100

    xfrm: state: simplify rcu_read_unlock handling in two spots
    
    Instead of:
      if (foo) {
          unlock();
          return bar();
       }
       unlock();
    do:
       unlock();
       if (foo)
           return bar();
    
    This is ok because rcu protected structure is only dereferenced before
    the conditional.
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

commit af5d27c4e12b804c065c0e7c87507fea5683dab4
Author: Florian Westphal <fw@strlen.de>
Date:   Mon Jan 9 14:20:47 2017 +0100

    xfrm: remove xfrm_state_put_afinfo
    
    commit 44abdc3047aecafc141dfbaf1ed
    ("xfrm: replace rwlock on xfrm_state_afinfo with rcu") made
    xfrm_state_put_afinfo equivalent to rcu_read_unlock.
    
    Use spatch to replace it with direct calls to rcu_read_unlock:
    
    @@
    struct xfrm_state_afinfo *a;
    @@
    
    -  xfrm_state_put_afinfo(a);
    +  rcu_read_unlock();
    
    old:
     text    data     bss     dec     hex filename
    22570      72     424   23066    5a1a xfrm_state.o
     1612       0       0    1612     64c xfrm_output.o
    new:
    22554      72     424   23050    5a0a xfrm_state.o
     1596       0       0    1596     63c xfrm_output.o
    
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>

commit 71717a3ef900dafe6e9854320491de5b8e972b08
Author: Tobias Klausmann <tobias.johannes.klausmann@mni.thm.de>
Date:   Tue Dec 13 18:08:07 2016 +0100

    ath9k: do not return early to fix rcu unlocking
    
    commit d1f1c0e289e1bc46cd6873ba6dd6c627f459e7fa upstream.
    
    Starting with commit d94a461d7a7d ("ath9k: use ieee80211_tx_status_noskb
    where possible") the driver uses rcu_read_lock() && rcu_read_unlock(), yet on
    returning early in ath_tx_edma_tasklet() the unlock is missing leading to stalls
    and suspicious RCU usage:
    
     ===============================
     [ INFO: suspicious RCU usage. ]
     4.9.0-rc8 #11 Not tainted
     -------------------------------
     kernel/rcu/tree.c:705 Illegal idle entry in RCU read-side critical section.!
    
     other info that might help us debug this:
    
     RCU used illegally from idle CPU!
     rcu_scheduler_active = 1, debug_locks = 0
     RCU used illegally from extended quiescent state!
     1 lock held by swapper/7/0:
     #0:
      (
     rcu_read_lock
     ){......}
     , at:
     [<ffffffffa06ed110>] ath_tx_edma_tasklet+0x0/0x450 [ath9k]
    
     stack backtrace:
     CPU: 7 PID: 0 Comm: swapper/7 Not tainted 4.9.0-rc8 #11
     Hardware name: Acer Aspire V3-571G/VA50_HC_CR, BIOS V2.21 12/16/2013
      ffff88025efc3f38 ffffffff8132b1e5 ffff88017ede4540 0000000000000001
      ffff88025efc3f68 ffffffff810a25f7 ffff88025efcee60 ffff88017edebdd8
      ffff88025eeb5400 0000000000000091 ffff88025efc3f88 ffffffff810c3cd4
     Call Trace:
      <IRQ>
      [<ffffffff8132b1e5>] dump_stack+0x68/0x93
      [<ffffffff810a25f7>] lockdep_rcu_suspicious+0xd7/0x110
      [<ffffffff810c3cd4>] rcu_eqs_enter_common.constprop.85+0x154/0x200
      [<ffffffff810c5a54>] rcu_irq_exit+0x44/0xa0
      [<ffffffff81058631>] irq_exit+0x61/0xd0
      [<ffffffff81018d25>] do_IRQ+0x65/0x110
      [<ffffffff81672189>] common_interrupt+0x89/0x89
      <EOI>
      [<ffffffff814ffe11>] ? cpuidle_enter_state+0x151/0x200
      [<ffffffff814ffee2>] cpuidle_enter+0x12/0x20
      [<ffffffff8109a6ae>] call_cpuidle+0x1e/0x40
      [<ffffffff8109a8f6>] cpu_startup_entry+0x146/0x220
      [<ffffffff810336f8>] start_secondary+0x148/0x170
    
    Signed-off-by: Tobias Klausmann <tobias.johannes.klausmann@mni.thm.de>
    Fixes: d94a461d7a7d ("ath9k: use ieee80211_tx_status_noskb where possible")
    Acked-by: Felix Fietkau <nbd@nbd.name>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Gabriel Craciunescu <nix.or.die@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@qca.qualcomm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d1f1c0e289e1bc46cd6873ba6dd6c627f459e7fa
Author: Tobias Klausmann <tobias.johannes.klausmann@mni.thm.de>
Date:   Tue Dec 13 18:08:07 2016 +0100

    ath9k: do not return early to fix rcu unlocking
    
    Starting with commit d94a461d7a7d ("ath9k: use ieee80211_tx_status_noskb
    where possible") the driver uses rcu_read_lock() && rcu_read_unlock(), yet on
    returning early in ath_tx_edma_tasklet() the unlock is missing leading to stalls
    and suspicious RCU usage:
    
     ===============================
     [ INFO: suspicious RCU usage. ]
     4.9.0-rc8 #11 Not tainted
     -------------------------------
     kernel/rcu/tree.c:705 Illegal idle entry in RCU read-side critical section.!
    
     other info that might help us debug this:
    
     RCU used illegally from idle CPU!
     rcu_scheduler_active = 1, debug_locks = 0
     RCU used illegally from extended quiescent state!
     1 lock held by swapper/7/0:
     #0:
      (
     rcu_read_lock
     ){......}
     , at:
     [<ffffffffa06ed110>] ath_tx_edma_tasklet+0x0/0x450 [ath9k]
    
     stack backtrace:
     CPU: 7 PID: 0 Comm: swapper/7 Not tainted 4.9.0-rc8 #11
     Hardware name: Acer Aspire V3-571G/VA50_HC_CR, BIOS V2.21 12/16/2013
      ffff88025efc3f38 ffffffff8132b1e5 ffff88017ede4540 0000000000000001
      ffff88025efc3f68 ffffffff810a25f7 ffff88025efcee60 ffff88017edebdd8
      ffff88025eeb5400 0000000000000091 ffff88025efc3f88 ffffffff810c3cd4
     Call Trace:
      <IRQ>
      [<ffffffff8132b1e5>] dump_stack+0x68/0x93
      [<ffffffff810a25f7>] lockdep_rcu_suspicious+0xd7/0x110
      [<ffffffff810c3cd4>] rcu_eqs_enter_common.constprop.85+0x154/0x200
      [<ffffffff810c5a54>] rcu_irq_exit+0x44/0xa0
      [<ffffffff81058631>] irq_exit+0x61/0xd0
      [<ffffffff81018d25>] do_IRQ+0x65/0x110
      [<ffffffff81672189>] common_interrupt+0x89/0x89
      <EOI>
      [<ffffffff814ffe11>] ? cpuidle_enter_state+0x151/0x200
      [<ffffffff814ffee2>] cpuidle_enter+0x12/0x20
      [<ffffffff8109a6ae>] call_cpuidle+0x1e/0x40
      [<ffffffff8109a8f6>] cpu_startup_entry+0x146/0x220
      [<ffffffff810336f8>] start_secondary+0x148/0x170
    
    Signed-off-by: Tobias Klausmann <tobias.johannes.klausmann@mni.thm.de>
    Fixes: d94a461d7a7d ("ath9k: use ieee80211_tx_status_noskb where possible")
    Cc: <stable@vger.kernel.org> # v4.9
    Acked-by: Felix Fietkau <nbd@nbd.name>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Tested-by: Gabriel Craciunescu <nix.or.die@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@qca.qualcomm.com>

commit 08abb79542c9e8c367d1d8e44fe1026868d3f0a7
Author: Xin Long <lucien.xin@gmail.com>
Date:   Thu Dec 15 23:05:52 2016 +0800

    sctp: sctp_transport_lookup_process should rcu_read_unlock when transport is null
    
    Prior to this patch, sctp_transport_lookup_process didn't rcu_read_unlock
    when it failed to find a transport by sctp_addrs_lookup_transport.
    
    This patch is to fix it by moving up rcu_read_unlock right before checking
    transport and also to remove the out path.
    
    Fixes: 1cceda784980 ("sctp: fix the issue sctp_diag uses lock_sock in rcu_read_lock")
    Signed-off-by: Xin Long <lucien.xin@gmail.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 7b9dc3f75fc8be046e76387a22a21f421ce55b53
Merge: 36869cb93d36 bbc17bb8a89b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 13 10:41:53 2016 -0800

    Merge tag 'pm-4.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Pull power management updates from Rafael Wysocki:
     "Again, cpufreq gets more changes than the other parts this time (one
      new driver, one old driver less, a bunch of enhancements of the
      existing code, new CPU IDs, fixes, cleanups)
    
      There also are some changes in cpuidle (idle injection rework, a
      couple of new CPU IDs, online/offline rework in intel_idle, fixes and
      cleanups), in the generic power domains framework (mostly related to
      supporting power domains containing CPUs), and in the Operating
      Performance Points (OPP) library (mostly related to supporting devices
      with multiple voltage regulators)
    
      In addition to that, the system sleep state selection interface is
      modified to make it easier for distributions with unchanged user space
      to support suspend-to-idle as the default system suspend method, some
      issues are fixed in the PM core, the latency tolerance PM QoS
      framework is improved a bit, the Intel RAPL power capping driver is
      cleaned up and there are some fixes and cleanups in the devfreq
      subsystem
    
      Specifics:
    
       - New cpufreq driver for Broadcom STB SoCs and a Device Tree binding
         for it (Markus Mayer)
    
       - Support for ARM Integrator/AP and Integrator/CP in the generic DT
         cpufreq driver and elimination of the old Integrator cpufreq driver
         (Linus Walleij)
    
       - Support for the zx296718, r8a7743 and r8a7745, Socionext UniPhier,
         and PXA SoCs in the the generic DT cpufreq driver (Baoyou Xie,
         Geert Uytterhoeven, Masahiro Yamada, Robert Jarzmik)
    
       - cpufreq core fix to eliminate races that may lead to using inactive
         policy objects and related cleanups (Rafael Wysocki)
    
       - cpufreq schedutil governor update to make it use SCHED_FIFO kernel
         threads (instead of regular workqueues) for doing delayed work (to
         reduce the response latency in some cases) and related cleanups
         (Viresh Kumar)
    
       - New cpufreq sysfs attribute for resetting statistics (Markus Mayer)
    
       - cpufreq governors fixes and cleanups (Chen Yu, Stratos Karafotis,
         Viresh Kumar)
    
       - Support for using generic cpufreq governors in the intel_pstate
         driver (Rafael Wysocki)
    
       - Support for per-logical-CPU P-state limits and the EPP/EPB (Energy
         Performance Preference/Energy Performance Bias) knobs in the
         intel_pstate driver (Srinivas Pandruvada)
    
       - New CPU ID for Knights Mill in intel_pstate (Piotr Luc)
    
       - intel_pstate driver modification to use the P-state selection
         algorithm based on CPU load on platforms with the system profile in
         the ACPI tables set to "mobile" (Srinivas Pandruvada)
    
       - intel_pstate driver cleanups (Arnd Bergmann, Rafael Wysocki,
         Srinivas Pandruvada)
    
       - cpufreq powernv driver updates including fast switching support
         (for the schedutil governor), fixes and cleanus (Akshay Adiga,
         Andrew Donnellan, Denis Kirjanov)
    
       - acpi-cpufreq driver rework to switch it over to the new CPU
         offline/online state machine (Sebastian Andrzej Siewior)
    
       - Assorted cleanups in cpufreq drivers (Wei Yongjun, Prashanth
         Prakash)
    
       - Idle injection rework (to make it use the regular idle path instead
         of a home-grown custom one) and related powerclamp thermal driver
         updates (Peter Zijlstra, Jacob Pan, Petr Mladek, Sebastian Andrzej
         Siewior)
    
       - New CPU IDs for Atom Z34xx and Knights Mill in intel_idle (Andy
         Shevchenko, Piotr Luc)
    
       - intel_idle driver cleanups and switch over to using the new CPU
         offline/online state machine (Anna-Maria Gleixner, Sebastian
         Andrzej Siewior)
    
       - cpuidle DT driver update to support suspend-to-idle properly
         (Sudeep Holla)
    
       - cpuidle core cleanups and misc updates (Daniel Lezcano, Pan Bian,
         Rafael Wysocki)
    
       - Preliminary support for power domains including CPUs in the generic
         power domains (genpd) framework and related DT bindings (Lina Iyer)
    
       - Assorted fixes and cleanups in the generic power domains (genpd)
         framework (Colin Ian King, Dan Carpenter, Geert Uytterhoeven)
    
       - Preliminary support for devices with multiple voltage regulators
         and related fixes and cleanups in the Operating Performance Points
         (OPP) library (Viresh Kumar, Masahiro Yamada, Stephen Boyd)
    
       - System sleep state selection interface rework to make it easier to
         support suspend-to-idle as the default system suspend method
         (Rafael Wysocki)
    
       - PM core fixes and cleanups, mostly related to the interactions
         between the system suspend and runtime PM frameworks (Ulf Hansson,
         Sahitya Tummala, Tony Lindgren)
    
       - Latency tolerance PM QoS framework imorovements (Andrew Lutomirski)
    
       - New Knights Mill CPU ID for the Intel RAPL power capping driver
         (Piotr Luc)
    
       - Intel RAPL power capping driver fixes, cleanups and switch over to
         using the new CPU offline/online state machine (Jacob Pan, Thomas
         Gleixner, Sebastian Andrzej Siewior)
    
       - Fixes and cleanups in the exynos-ppmu, exynos-nocp, rk3399_dmc,
         rockchip-dfi devfreq drivers and the devfreq core (Axel Lin,
         Chanwoo Choi, Javier Martinez Canillas, MyungJoo Ham, Viresh Kumar)
    
       - Fix for false-positive KASAN warnings during resume from ACPI S3
         (suspend-to-RAM) on x86 (Josh Poimboeuf)
    
       - Memory map verification during resume from hibernation on x86 to
         ensure a consistent address space layout (Chen Yu)
    
       - Wakeup sources debugging enhancement (Xing Wei)
    
       - rockchip-io AVS driver cleanup (Shawn Lin)"
    
    * tag 'pm-4.10-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm: (127 commits)
      devfreq: rk3399_dmc: Don't use OPP structures outside of RCU locks
      devfreq: rk3399_dmc: Remove dangling rcu_read_unlock()
      devfreq: exynos: Don't use OPP structures outside of RCU locks
      Documentation: intel_pstate: Document HWP energy/performance hints
      cpufreq: intel_pstate: Support for energy performance hints with HWP
      cpufreq: intel_pstate: Add locking around HWP requests
      PM / sleep: Print active wakeup sources when blocking on wakeup_count reads
      PM / core: Fix bug in the error handling of async suspend
      PM / wakeirq: Fix dedicated wakeirq for drivers not using autosuspend
      PM / Domains: Fix compatible for domain idle state
      PM / OPP: Don't WARN on multiple calls to dev_pm_opp_set_regulators()
      PM / OPP: Allow platform specific custom set_opp() callbacks
      PM / OPP: Separate out _generic_set_opp()
      PM / OPP: Add infrastructure to manage multiple regulators
      PM / OPP: Pass struct dev_pm_opp_supply to _set_opp_voltage()
      PM / OPP: Manage supply's voltage/current in a separate structure
      PM / OPP: Don't use OPP structure outside of rcu protected section
      PM / OPP: Reword binding supporting multiple regulators per device
      PM / OPP: Fix incorrect cpu-supply property in binding
      cpuidle: Add a kerneldoc comment to cpuidle_use_deepest_state()
      ..

commit bbc17bb8a89b3eb31520abf3a9b362d5ee54f908
Merge: 631ddaba5905 e37d35082e75
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Dec 12 20:46:48 2016 +0100

    Merge branch 'pm-devfreq'
    
    * pm-devfreq:
      devfreq: rk3399_dmc: Don't use OPP structures outside of RCU locks
      devfreq: rk3399_dmc: Remove dangling rcu_read_unlock()
      devfreq: exynos: Don't use OPP structures outside of RCU locks
      PM / devfreq: rk3399_dmc: Use the resource-managed function to add devfreq dev
      PM / devfreq: correct comment typo.
      PM / devfreq: exynos-ppmu: Remove unused mutex from struct exynos_ppmu
      PM / devfreq: exynos-ppmu: ppmu_events array should not be NULL terminated
      PM / devfreq: exynos-ppmu: Fix module autoload
      PM / devfreq: rockchip-dfi: Fix module autoload
      PM / devfreq: exynos-nocp: Fix module autoload
      PM / devfreq: rk3399_dmc: Fix module autoload

commit d8323de3d4062e1b5a5aa7e9c0f935138405a582
Author: Viresh Kumar <viresh.kumar@linaro.org>
Date:   Thu Dec 1 16:12:14 2016 +0530

    devfreq: rk3399_dmc: Remove dangling rcu_read_unlock()
    
    This call never had the rcu_read_lock() counterpart. Remove the unlock
    part as well.
    
    Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
    Reviewed-by: Chanwoo Choi <cw00.choi@samsung.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit a3c18422a4b4e108bcf6a2328f48867e1003fd95
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Tue Nov 29 13:09:45 2016 +0100

    l2tp: hold socket before dropping lock in l2tp_ip{, 6}_recv()
    
    Socket must be held while under the protection of the l2tp lock; there
    is no guarantee that sk remains valid after the read_unlock_bh() call.
    
    Same issue for l2tp_ip and l2tp_ip6.
    
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 93636d1f1f162ae89ae4f2a22a83bf4fd960724e
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Nov 2 20:21:20 2016 -0700

    netlink: netlink_diag_dump() runs without locks
    
    A recent commit removed locking from netlink_diag_dump() but forgot
    one error case.
    
    =====================================
    [ BUG: bad unlock balance detected! ]
    4.9.0-rc3+ #336 Not tainted
    -------------------------------------
    syz-executor/4018 is trying to release lock ([   36.220068] nl_table_lock
    ) at:
    [<ffffffff82dc8683>] netlink_diag_dump+0x1a3/0x250 net/netlink/diag.c:182
    but there are no more locks to release!
    
    other info that might help us debug this:
    3 locks held by syz-executor/4018:
     #0: [   36.220068]  (
    sock_diag_mutex[   36.220068] ){+.+.+.}
    , at: [   36.220068] [<ffffffff82c3873b>] sock_diag_rcv+0x1b/0x40
     #1: [   36.220068]  (
    sock_diag_table_mutex[   36.220068] ){+.+.+.}
    , at: [   36.220068] [<ffffffff82c38e00>] sock_diag_rcv_msg+0x140/0x3a0
     #2: [   36.220068]  (
    nlk->cb_mutex[   36.220068] ){+.+.+.}
    , at: [   36.220068] [<ffffffff82db6600>] netlink_dump+0x50/0xac0
    
    stack backtrace:
    CPU: 1 PID: 4018 Comm: syz-executor Not tainted 4.9.0-rc3+ #336
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
     ffff8800645df688 ffffffff81b46934 ffffffff84eb3e78 ffff88006ad85800
     ffffffff82dc8683 ffffffff84eb3e78 ffff8800645df6b8 ffffffff812043ca
     dffffc0000000000 ffff88006ad85ff8 ffff88006ad85fd0 00000000ffffffff
    Call Trace:
     [<     inline     >] __dump_stack lib/dump_stack.c:15
     [<ffffffff81b46934>] dump_stack+0xb3/0x10f lib/dump_stack.c:51
     [<ffffffff812043ca>] print_unlock_imbalance_bug+0x17a/0x1a0
    kernel/locking/lockdep.c:3388
     [<     inline     >] __lock_release kernel/locking/lockdep.c:3512
     [<ffffffff8120cfd8>] lock_release+0x8e8/0xc60 kernel/locking/lockdep.c:3765
     [<     inline     >] __raw_read_unlock ./include/linux/rwlock_api_smp.h:225
     [<ffffffff83fc001a>] _raw_read_unlock+0x1a/0x30 kernel/locking/spinlock.c:255
     [<ffffffff82dc8683>] netlink_diag_dump+0x1a3/0x250 net/netlink/diag.c:182
     [<ffffffff82db6947>] netlink_dump+0x397/0xac0 net/netlink/af_netlink.c:2110
    
    Fixes: ad202074320c ("netlink: Use rhashtable walk interface in diag dump")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Andrey Konovalov <andreyknvl@google.com>
    Tested-by: Andrey Konovalov <andreyknvl@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b200d3a9ae76e764ee622761d87c7d521ed6c198
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Fri Aug 12 09:50:51 2016 +0200

    net/sctp: always initialise sctp_ht_iter::start_fail
    
    [ Upstream commit 54236ab09e9696a27baaae693c288920a26e8588 ]
    
    sctp_transport_seq_start() does not currently clear iter->start_fail on
    success, but relies on it being zero when it is allocated (by
    seq_open_net()).
    
    This can be a problem in the following sequence:
    
        open() // allocates iter (and implicitly sets iter->start_fail = 0)
        read()
         - iter->start() // fails and sets iter->start_fail = 1
         - iter->stop() // doesn't call sctp_transport_walk_stop() (correct)
        read() again
         - iter->start() // succeeds, but doesn't change iter->start_fail
         - iter->stop() // doesn't call sctp_transport_walk_stop() (wrong)
    
    We should initialize sctp_ht_iter::start_fail to zero if ->start()
    succeeds, otherwise it's possible that we leave an old value of 1 there,
    which will cause ->stop() to not call sctp_transport_walk_stop(), which
    causes all sorts of problems like not calling rcu_read_unlock() (and
    preempt_enable()), eventually leading to more warnings like this:
    
        BUG: sleeping function called from invalid context at mm/slab.h:388
        in_atomic(): 0, irqs_disabled(): 0, pid: 16551, name: trinity-c2
        Preemption disabled at:[<ffffffff819bceb6>] rhashtable_walk_start+0x46/0x150
    
         [<ffffffff81149abb>] preempt_count_add+0x1fb/0x280
         [<ffffffff83295892>] _raw_spin_lock+0x12/0x40
         [<ffffffff819bceb6>] rhashtable_walk_start+0x46/0x150
         [<ffffffff82ec665f>] sctp_transport_walk_start+0x2f/0x60
         [<ffffffff82edda1d>] sctp_transport_seq_start+0x4d/0x150
         [<ffffffff81439e50>] traverse+0x170/0x850
         [<ffffffff8143aeec>] seq_read+0x7cc/0x1180
         [<ffffffff814f996c>] proc_reg_read+0xbc/0x180
         [<ffffffff813d0384>] do_loop_readv_writev+0x134/0x210
         [<ffffffff813d2a95>] do_readv_writev+0x565/0x660
         [<ffffffff813d6857>] vfs_readv+0x67/0xa0
         [<ffffffff813d6c16>] do_preadv+0x126/0x170
         [<ffffffff813d710c>] SyS_preadv+0xc/0x10
         [<ffffffff8100334c>] do_syscall_64+0x19c/0x410
         [<ffffffff83296225>] return_from_SYSCALL_64+0x0/0x6a
         [<ffffffffffffffff>] 0xffffffffffffffff
    
    Notice that this is a subtly different stacktrace from the one in commit
    5fc382d875 ("net/sctp: terminate rhashtable walk correctly").
    
    Cc: Xin Long <lucien.xin@gmail.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-By: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 89a27b9679c1929df52a966c44e1653f5b141636
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Mon Aug 22 12:47:43 2016 +0200

    bdev: fix NULL pointer dereference
    
    commit e9e5e3fae8da7e237049e00e0bfc9e32fd808fe8 upstream.
    
    I got this:
    
        kasan: GPF could be caused by NULL-ptr deref or user memory access
        general protection fault: 0000 [#1] PREEMPT SMP KASAN
        Dumping ftrace buffer:
           (ftrace buffer empty)
        CPU: 0 PID: 5505 Comm: syz-executor Not tainted 4.8.0-rc2+ #161
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.3-0-ge2fc41e-prebuilt.qemu-project.org 04/01/2014
        task: ffff880113415940 task.stack: ffff880118350000
        RIP: 0010:[<ffffffff8172cb32>]  [<ffffffff8172cb32>] bd_mount+0x52/0xa0
        RSP: 0018:ffff880118357ca0  EFLAGS: 00010207
        RAX: dffffc0000000000 RBX: ffffffffffffffff RCX: ffffc90000bb6000
        RDX: 0000000000000018 RSI: ffffffff846d6b20 RDI: 00000000000000c7
        RBP: ffff880118357cb0 R08: ffff880115967c68 R09: 0000000000000000
        R10: 0000000000000000 R11: 0000000000000000 R12: ffff8801188211e8
        R13: ffffffff847baa20 R14: ffff8801139cb000 R15: 0000000000000080
        FS:  00007fa3ff6c0700(0000) GS:ffff88011aa00000(0000) knlGS:0000000000000000
        CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
        CR2: 00007fc1d8cc7e78 CR3: 0000000109f20000 CR4: 00000000000006f0
        DR0: 000000000000001e DR1: 000000000000001e DR2: 0000000000000000
        DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000600
        Stack:
         ffff880112cfd6c0 ffff8801188211e8 ffff880118357cf0 ffffffff8167f207
         ffffffff816d7a1e ffff880112a413c0 ffffffff847baa20 ffff8801188211e8
         0000000000000080 ffff880112cfd6c0 ffff880118357d38 ffffffff816dce0a
        Call Trace:
         [<ffffffff8167f207>] mount_fs+0x97/0x2e0
         [<ffffffff816d7a1e>] ? alloc_vfsmnt+0x55e/0x760
         [<ffffffff816dce0a>] vfs_kern_mount+0x7a/0x300
         [<ffffffff83c3247c>] ? _raw_read_unlock+0x2c/0x50
         [<ffffffff816dfc87>] do_mount+0x3d7/0x2730
         [<ffffffff81235fd4>] ? trace_do_page_fault+0x1f4/0x3a0
         [<ffffffff816df8b0>] ? copy_mount_string+0x40/0x40
         [<ffffffff8161ea81>] ? memset+0x31/0x40
         [<ffffffff816df73e>] ? copy_mount_options+0x1ee/0x320
         [<ffffffff816e2a02>] SyS_mount+0xb2/0x120
         [<ffffffff816e2950>] ? copy_mnt_ns+0x970/0x970
         [<ffffffff81005524>] do_syscall_64+0x1c4/0x4e0
         [<ffffffff83c3282a>] entry_SYSCALL64_slow_path+0x25/0x25
        Code: 83 e8 63 1b fc ff 48 85 c0 48 89 c3 74 4c e8 56 35 d1 ff 48 8d bb c8 00 00 00 48 b8 00 00 00 00 00 fc ff df 48 89 fa 48 c1 ea 03 <80> 3c 02 00 75 36 4c 8b a3 c8 00 00 00 48 b8 00 00 00 00 00 fc
        RIP  [<ffffffff8172cb32>] bd_mount+0x52/0xa0
         RSP <ffff880118357ca0>
        ---[ end trace 13690ad962168b98 ]---
    
    mount_pseudo() returns ERR_PTR(), not NULL, on error.
    
    Fixes: 3684aa7099e0 ("block-dev: enable writeback cgroup support")
    Cc: Shaohua Li <shli@fb.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@fb.com>
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 379d9ecb3cc9d5d043216185904c00e54c736a96
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jun 30 10:37:20 2016 -0700

    sched: Make wake_up_nohz_cpu() handle CPUs going offline
    
    Both timers and hrtimers are maintained on the outgoing CPU until
    CPU_DEAD time, at which point they are migrated to a surviving CPU.  If a
    mod_timer() executes between CPU_DYING and CPU_DEAD time, x86 systems
    will splat in native_smp_send_reschedule() when attempting to wake up
    the just-now-offlined CPU, as shown below from a NO_HZ_FULL kernel:
    
    [ 7976.741556] WARNING: CPU: 0 PID: 661 at /home/paulmck/public_git/linux-rcu/arch/x86/kernel/smp.c:125 native_smp_send_reschedule+0x39/0x40
    [ 7976.741595] Modules linked in:
    [ 7976.741595] CPU: 0 PID: 661 Comm: rcu_torture_rea Not tainted 4.7.0-rc2+ #1
    [ 7976.741595] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011
    [ 7976.741595]  0000000000000000 ffff88000002fcc8 ffffffff8138ab2e 0000000000000000
    [ 7976.741595]  0000000000000000 ffff88000002fd08 ffffffff8105cabc 0000007d1fd0ee18
    [ 7976.741595]  0000000000000001 ffff88001fd16d40 ffff88001fd0ee00 ffff88001fd0ee00
    [ 7976.741595] Call Trace:
    [ 7976.741595]  [<ffffffff8138ab2e>] dump_stack+0x67/0x99
    [ 7976.741595]  [<ffffffff8105cabc>] __warn+0xcc/0xf0
    [ 7976.741595]  [<ffffffff8105cb98>] warn_slowpath_null+0x18/0x20
    [ 7976.741595]  [<ffffffff8103cba9>] native_smp_send_reschedule+0x39/0x40
    [ 7976.741595]  [<ffffffff81089bc2>] wake_up_nohz_cpu+0x82/0x190
    [ 7976.741595]  [<ffffffff810d275a>] internal_add_timer+0x7a/0x80
    [ 7976.741595]  [<ffffffff810d3ee7>] mod_timer+0x187/0x2b0
    [ 7976.741595]  [<ffffffff810c89dd>] rcu_torture_reader+0x33d/0x380
    [ 7976.741595]  [<ffffffff810c66f0>] ? sched_torture_read_unlock+0x30/0x30
    [ 7976.741595]  [<ffffffff810c86a0>] ? rcu_bh_torture_read_lock+0x80/0x80
    [ 7976.741595]  [<ffffffff8108068f>] kthread+0xdf/0x100
    [ 7976.741595]  [<ffffffff819dd83f>] ret_from_fork+0x1f/0x40
    [ 7976.741595]  [<ffffffff810805b0>] ? kthread_create_on_node+0x200/0x200
    
    However, in this case, the wakeup is redundant, because the timer
    migration will reprogram timer hardware as needed.  Note that the fact
    that preemption is disabled does not avoid the splat, as the offline
    operation has already passed both the synchronize_sched() and the
    stop_machine() that would be blocked by disabled preemption.
    
    This commit therefore modifies wake_up_nohz_cpu() to avoid attempting
    to wake up offline CPUs.  It also adds a comment stating that the
    caller must tolerate lost wakeups when the target CPU is going offline,
    and suggesting the CPU_DEAD notifier as a recovery mechanism.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>

commit e9e5e3fae8da7e237049e00e0bfc9e32fd808fe8
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Mon Aug 22 12:47:43 2016 +0200

    bdev: fix NULL pointer dereference
    
    I got this:
    
        kasan: GPF could be caused by NULL-ptr deref or user memory access
        general protection fault: 0000 [#1] PREEMPT SMP KASAN
        Dumping ftrace buffer:
           (ftrace buffer empty)
        CPU: 0 PID: 5505 Comm: syz-executor Not tainted 4.8.0-rc2+ #161
        Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.9.3-0-ge2fc41e-prebuilt.qemu-project.org 04/01/2014
        task: ffff880113415940 task.stack: ffff880118350000
        RIP: 0010:[<ffffffff8172cb32>]  [<ffffffff8172cb32>] bd_mount+0x52/0xa0
        RSP: 0018:ffff880118357ca0  EFLAGS: 00010207
        RAX: dffffc0000000000 RBX: ffffffffffffffff RCX: ffffc90000bb6000
        RDX: 0000000000000018 RSI: ffffffff846d6b20 RDI: 00000000000000c7
        RBP: ffff880118357cb0 R08: ffff880115967c68 R09: 0000000000000000
        R10: 0000000000000000 R11: 0000000000000000 R12: ffff8801188211e8
        R13: ffffffff847baa20 R14: ffff8801139cb000 R15: 0000000000000080
        FS:  00007fa3ff6c0700(0000) GS:ffff88011aa00000(0000) knlGS:0000000000000000
        CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
        CR2: 00007fc1d8cc7e78 CR3: 0000000109f20000 CR4: 00000000000006f0
        DR0: 000000000000001e DR1: 000000000000001e DR2: 0000000000000000
        DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000600
        Stack:
         ffff880112cfd6c0 ffff8801188211e8 ffff880118357cf0 ffffffff8167f207
         ffffffff816d7a1e ffff880112a413c0 ffffffff847baa20 ffff8801188211e8
         0000000000000080 ffff880112cfd6c0 ffff880118357d38 ffffffff816dce0a
        Call Trace:
         [<ffffffff8167f207>] mount_fs+0x97/0x2e0
         [<ffffffff816d7a1e>] ? alloc_vfsmnt+0x55e/0x760
         [<ffffffff816dce0a>] vfs_kern_mount+0x7a/0x300
         [<ffffffff83c3247c>] ? _raw_read_unlock+0x2c/0x50
         [<ffffffff816dfc87>] do_mount+0x3d7/0x2730
         [<ffffffff81235fd4>] ? trace_do_page_fault+0x1f4/0x3a0
         [<ffffffff816df8b0>] ? copy_mount_string+0x40/0x40
         [<ffffffff8161ea81>] ? memset+0x31/0x40
         [<ffffffff816df73e>] ? copy_mount_options+0x1ee/0x320
         [<ffffffff816e2a02>] SyS_mount+0xb2/0x120
         [<ffffffff816e2950>] ? copy_mnt_ns+0x970/0x970
         [<ffffffff81005524>] do_syscall_64+0x1c4/0x4e0
         [<ffffffff83c3282a>] entry_SYSCALL64_slow_path+0x25/0x25
        Code: 83 e8 63 1b fc ff 48 85 c0 48 89 c3 74 4c e8 56 35 d1 ff 48 8d bb c8 00 00 00 48 b8 00 00 00 00 00 fc ff df 48 89 fa 48 c1 ea 03 <80> 3c 02 00 75 36 4c 8b a3 c8 00 00 00 48 b8 00 00 00 00 00 fc
        RIP  [<ffffffff8172cb32>] bd_mount+0x52/0xa0
         RSP <ffff880118357ca0>
        ---[ end trace 13690ad962168b98 ]---
    
    mount_pseudo() returns ERR_PTR(), not NULL, on error.
    
    Fixes: 3684aa7099e0 ("block-dev: enable writeback cgroup support")
    Cc: Shaohua Li <shli@fb.com>
    Cc: Tejun Heo <tj@kernel.org>
    Cc: Jens Axboe <axboe@fb.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Signed-off-by: Jens Axboe <axboe@fb.com>

commit 77719251041381423bf6fb4ae9d529e2a42adb55
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Sat Jul 23 09:42:35 2016 +0200

    net/sctp: terminate rhashtable walk correctly
    
    [ Upstream commit 5fc382d87517707ad77ea4c9c12e2a3fde2c838a ]
    
    I was seeing a lot of these:
    
        BUG: sleeping function called from invalid context at mm/slab.h:388
        in_atomic(): 0, irqs_disabled(): 0, pid: 14971, name: trinity-c2
        Preemption disabled at:[<ffffffff819bcd46>] rhashtable_walk_start+0x46/0x150
    
         [<ffffffff81149abb>] preempt_count_add+0x1fb/0x280
         [<ffffffff83295722>] _raw_spin_lock+0x12/0x40
         [<ffffffff811aac87>] console_unlock+0x2f7/0x930
         [<ffffffff811ab5bb>] vprintk_emit+0x2fb/0x520
         [<ffffffff811aba6a>] vprintk_default+0x1a/0x20
         [<ffffffff812c171a>] printk+0x94/0xb0
         [<ffffffff811d6ed0>] print_stack_trace+0xe0/0x170
         [<ffffffff8115835e>] ___might_sleep+0x3be/0x460
         [<ffffffff81158490>] __might_sleep+0x90/0x1a0
         [<ffffffff8139b823>] kmem_cache_alloc+0x153/0x1e0
         [<ffffffff819bca1e>] rhashtable_walk_init+0xfe/0x2d0
         [<ffffffff82ec64de>] sctp_transport_walk_start+0x1e/0x60
         [<ffffffff82edd8ad>] sctp_transport_seq_start+0x4d/0x150
         [<ffffffff8143a82b>] seq_read+0x27b/0x1180
         [<ffffffff814f97fc>] proc_reg_read+0xbc/0x180
         [<ffffffff813d471b>] __vfs_read+0xdb/0x610
         [<ffffffff813d4d3a>] vfs_read+0xea/0x2d0
         [<ffffffff813d615b>] SyS_pread64+0x11b/0x150
         [<ffffffff8100334c>] do_syscall_64+0x19c/0x410
         [<ffffffff832960a5>] return_from_SYSCALL_64+0x0/0x6a
         [<ffffffffffffffff>] 0xffffffffffffffff
    
    Apparently we always need to call rhashtable_walk_stop(), even when
    rhashtable_walk_start() fails:
    
     * rhashtable_walk_start - Start a hash table walk
     * @iter:       Hash table iterator
     *
     * Start a hash table walk.  Note that we take the RCU lock in all
     * cases including when we return an error.  So you must always call
     * rhashtable_walk_stop to clean up.
    
    otherwise we never call rcu_read_unlock() and we get the splat above.
    
    Fixes: 53fa1036 ("sctp: fix some rhashtable functions using in sctp proc/diag")
    See-also: 53fa1036 ("sctp: fix some rhashtable functions using in sctp proc/diag")
    See-also: f2dba9c6 ("rhashtable: Introduce rhashtable_walk_*")
    Cc: Xin Long <lucien.xin@gmail.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: stable@vger.kernel.org
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 54236ab09e9696a27baaae693c288920a26e8588
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Fri Aug 12 09:50:51 2016 +0200

    net/sctp: always initialise sctp_ht_iter::start_fail
    
    sctp_transport_seq_start() does not currently clear iter->start_fail on
    success, but relies on it being zero when it is allocated (by
    seq_open_net()).
    
    This can be a problem in the following sequence:
    
        open() // allocates iter (and implicitly sets iter->start_fail = 0)
        read()
         - iter->start() // fails and sets iter->start_fail = 1
         - iter->stop() // doesn't call sctp_transport_walk_stop() (correct)
        read() again
         - iter->start() // succeeds, but doesn't change iter->start_fail
         - iter->stop() // doesn't call sctp_transport_walk_stop() (wrong)
    
    We should initialize sctp_ht_iter::start_fail to zero if ->start()
    succeeds, otherwise it's possible that we leave an old value of 1 there,
    which will cause ->stop() to not call sctp_transport_walk_stop(), which
    causes all sorts of problems like not calling rcu_read_unlock() (and
    preempt_enable()), eventually leading to more warnings like this:
    
        BUG: sleeping function called from invalid context at mm/slab.h:388
        in_atomic(): 0, irqs_disabled(): 0, pid: 16551, name: trinity-c2
        Preemption disabled at:[<ffffffff819bceb6>] rhashtable_walk_start+0x46/0x150
    
         [<ffffffff81149abb>] preempt_count_add+0x1fb/0x280
         [<ffffffff83295892>] _raw_spin_lock+0x12/0x40
         [<ffffffff819bceb6>] rhashtable_walk_start+0x46/0x150
         [<ffffffff82ec665f>] sctp_transport_walk_start+0x2f/0x60
         [<ffffffff82edda1d>] sctp_transport_seq_start+0x4d/0x150
         [<ffffffff81439e50>] traverse+0x170/0x850
         [<ffffffff8143aeec>] seq_read+0x7cc/0x1180
         [<ffffffff814f996c>] proc_reg_read+0xbc/0x180
         [<ffffffff813d0384>] do_loop_readv_writev+0x134/0x210
         [<ffffffff813d2a95>] do_readv_writev+0x565/0x660
         [<ffffffff813d6857>] vfs_readv+0x67/0xa0
         [<ffffffff813d6c16>] do_preadv+0x126/0x170
         [<ffffffff813d710c>] SyS_preadv+0xc/0x10
         [<ffffffff8100334c>] do_syscall_64+0x19c/0x410
         [<ffffffff83296225>] return_from_SYSCALL_64+0x0/0x6a
         [<ffffffffffffffff>] 0xffffffffffffffff
    
    Notice that this is a subtly different stacktrace from the one in commit
    5fc382d875 ("net/sctp: terminate rhashtable walk correctly").
    
    Cc: Xin Long <lucien.xin@gmail.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-By: Neil Horman <nhorman@tuxdriver.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6a468737c8c00bd6cdb208ca0b7f841e8970d466
Author: Munehisa Kamata <kamatam@amazon.com>
Date:   Mon Oct 26 19:10:52 2015 -0700

    netfilter: nf_nat_redirect: add missing NULL pointer check
    
    [ Upstream commit 94f9cd81436c85d8c3a318ba92e236ede73752fc ]
    
    Commit 8b13eddfdf04cbfa561725cfc42d6868fe896f56 ("netfilter: refactor NAT
    redirect IPv4 to use it from nf_tables") has introduced a trivial logic
    change which can result in the following crash.
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000030
    IP: [<ffffffffa033002d>] nf_nat_redirect_ipv4+0x2d/0xa0 [nf_nat_redirect]
    PGD 3ba662067 PUD 3ba661067 PMD 0
    Oops: 0000 [#1] SMP
    Modules linked in: ipv6(E) xt_REDIRECT(E) nf_nat_redirect(E) xt_tcpudp(E) iptable_nat(E) nf_conntrack_ipv4(E) nf_defrag_ipv4(E) nf_nat_ipv4(E) nf_nat(E) nf_conntrack(E) ip_tables(E) x_tables(E) binfmt_misc(E) xfs(E) libcrc32c(E) evbug(E) evdev(E) psmouse(E) i2c_piix4(E) i2c_core(E) acpi_cpufreq(E) button(E) ext4(E) crc16(E) jbd2(E) mbcache(E) dm_mirror(E) dm_region_hash(E) dm_log(E) dm_mod(E)
    CPU: 0 PID: 2536 Comm: ip Tainted: G            E   4.1.7-15.23.amzn1.x86_64 #1
    Hardware name: Xen HVM domU, BIOS 4.2.amazon 05/06/2015
    task: ffff8800eb438000 ti: ffff8803ba664000 task.ti: ffff8803ba664000
    [...]
    Call Trace:
     <IRQ>
     [<ffffffffa0334065>] redirect_tg4+0x15/0x20 [xt_REDIRECT]
     [<ffffffffa02e2e99>] ipt_do_table+0x2b9/0x5e1 [ip_tables]
     [<ffffffffa0328045>] iptable_nat_do_chain+0x25/0x30 [iptable_nat]
     [<ffffffffa031777d>] nf_nat_ipv4_fn+0x13d/0x1f0 [nf_nat_ipv4]
     [<ffffffffa0328020>] ? iptable_nat_ipv4_fn+0x20/0x20 [iptable_nat]
     [<ffffffffa031785e>] nf_nat_ipv4_in+0x2e/0x90 [nf_nat_ipv4]
     [<ffffffffa03280a5>] iptable_nat_ipv4_in+0x15/0x20 [iptable_nat]
     [<ffffffff81449137>] nf_iterate+0x57/0x80
     [<ffffffff814491f7>] nf_hook_slow+0x97/0x100
     [<ffffffff814504d4>] ip_rcv+0x314/0x400
    
    unsigned int
    nf_nat_redirect_ipv4(struct sk_buff *skb,
    ...
    {
    ...
                    rcu_read_lock();
                    indev = __in_dev_get_rcu(skb->dev);
                    if (indev != NULL) {
                            ifa = indev->ifa_list;
                            newdst = ifa->ifa_local; <---
                    }
                    rcu_read_unlock();
    ...
    }
    
    Before the commit, 'ifa' had been always checked before access. After the
    commit, however, it could be accessed even if it's NULL. Interestingly,
    this was once fixed in 2003.
    
    http://marc.info/?l=netfilter-devel&m=106668497403047&w=2
    
    In addition to the original one, we have seen the crash when packets that
    need to be redirected somehow arrive on an interface which hasn't been
    yet fully configured.
    
    This change just reverts the logic to the old behavior to avoid the crash.
    
    Fixes: 8b13eddfdf04 ("netfilter: refactor NAT redirect IPv4 to use it from nf_tables")
    Signed-off-by: Munehisa Kamata <kamatam@amazon.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>

commit 6b65bc29721dee21e963cde3a83369bd09ba5358
Author: Wei Yongjun <weiyj.lk@gmail.com>
Date:   Thu Jul 28 02:07:49 2016 +0000

    tipc: fix imbalance read_unlock_bh in __tipc_nl_add_monitor()
    
    In the error handling case of nla_nest_start() failed read_unlock_bh()
    is called  to unlock a lock that had not been taken yet. sparse warns
    about the context imbalance as the following:
    
    net/tipc/monitor.c:799:23: warning:
     context imbalance in '__tipc_nl_add_monitor' - different lock contexts for basic block
    
    Fixes: cf6f7e1d5109 ('tipc: dump monitor attributes')
    Signed-off-by: Wei Yongjun <weiyj.lk@gmail.com>
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5fc382d87517707ad77ea4c9c12e2a3fde2c838a
Author: Vegard Nossum <vegard.nossum@oracle.com>
Date:   Sat Jul 23 09:42:35 2016 +0200

    net/sctp: terminate rhashtable walk correctly
    
    I was seeing a lot of these:
    
        BUG: sleeping function called from invalid context at mm/slab.h:388
        in_atomic(): 0, irqs_disabled(): 0, pid: 14971, name: trinity-c2
        Preemption disabled at:[<ffffffff819bcd46>] rhashtable_walk_start+0x46/0x150
    
         [<ffffffff81149abb>] preempt_count_add+0x1fb/0x280
         [<ffffffff83295722>] _raw_spin_lock+0x12/0x40
         [<ffffffff811aac87>] console_unlock+0x2f7/0x930
         [<ffffffff811ab5bb>] vprintk_emit+0x2fb/0x520
         [<ffffffff811aba6a>] vprintk_default+0x1a/0x20
         [<ffffffff812c171a>] printk+0x94/0xb0
         [<ffffffff811d6ed0>] print_stack_trace+0xe0/0x170
         [<ffffffff8115835e>] ___might_sleep+0x3be/0x460
         [<ffffffff81158490>] __might_sleep+0x90/0x1a0
         [<ffffffff8139b823>] kmem_cache_alloc+0x153/0x1e0
         [<ffffffff819bca1e>] rhashtable_walk_init+0xfe/0x2d0
         [<ffffffff82ec64de>] sctp_transport_walk_start+0x1e/0x60
         [<ffffffff82edd8ad>] sctp_transport_seq_start+0x4d/0x150
         [<ffffffff8143a82b>] seq_read+0x27b/0x1180
         [<ffffffff814f97fc>] proc_reg_read+0xbc/0x180
         [<ffffffff813d471b>] __vfs_read+0xdb/0x610
         [<ffffffff813d4d3a>] vfs_read+0xea/0x2d0
         [<ffffffff813d615b>] SyS_pread64+0x11b/0x150
         [<ffffffff8100334c>] do_syscall_64+0x19c/0x410
         [<ffffffff832960a5>] return_from_SYSCALL_64+0x0/0x6a
         [<ffffffffffffffff>] 0xffffffffffffffff
    
    Apparently we always need to call rhashtable_walk_stop(), even when
    rhashtable_walk_start() fails:
    
     * rhashtable_walk_start - Start a hash table walk
     * @iter:       Hash table iterator
     *
     * Start a hash table walk.  Note that we take the RCU lock in all
     * cases including when we return an error.  So you must always call
     * rhashtable_walk_stop to clean up.
    
    otherwise we never call rcu_read_unlock() and we get the splat above.
    
    Fixes: 53fa1036 ("sctp: fix some rhashtable functions using in sctp proc/diag")
    See-also: 53fa1036 ("sctp: fix some rhashtable functions using in sctp proc/diag")
    See-also: f2dba9c6 ("rhashtable: Introduce rhashtable_walk_*")
    Cc: Xin Long <lucien.xin@gmail.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: stable@vger.kernel.org
    Signed-off-by: Vegard Nossum <vegard.nossum@oracle.com>
    Acked-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 150593bf869393d10a79f6bd3df2585ecc20a9bb
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed May 18 19:02:18 2016 +0200

    sched/api: Introduce task_rcu_dereference() and try_get_task_struct()
    
    Generally task_struct is only protected by RCU if it was found on a
    RCU protected list (say, for_each_process() or find_task_by_vpid()).
    
    As Kirill pointed out rq->curr isn't protected by RCU, the scheduler
    drops the (potentially) last reference without RCU gp, this means
    that we need to fix the code which uses foreign_rq->curr under
    rcu_read_lock().
    
    Add a new helper which can be used to dereference rq->curr or any
    other pointer to task_struct assuming that it should be cleared or
    updated before the final put_task_struct(). It returns non-NULL
    only if this task can't go away before rcu_read_unlock().
    
    ( Also add try_get_task_struct() to make it easier to use this API
      correctly. )
    
    Suggested-by: Kirill Tkhai <ktkhai@parallels.com>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    [ Updated comments; added try_get_task_struct()]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Christoph Lameter <cl@linux.com>
    Cc: Kirill Tkhai <tkhai@yandex.ru>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Vladimir Davydov <vdavydov@parallels.com>
    Link: http://lkml.kernel.org/r/20160518170218.GY3192@twins.programming.kicks-ass.net
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit ce7791ffee1e1ee9f97193b817c7dd1fa6746aad
Author: Filipe Manana <fdmanana@suse.com>
Date:   Fri May 20 01:57:20 2016 +0100

    Btrfs: fix race between readahead and device replace/removal
    
    The list of devices is protected by the device_list_mutex and the device
    replace code, in its finishing phase correctly takes that mutex before
    removing the source device from that list. However the readahead code was
    iterating that list without acquiring the respective mutex leading to
    crashes later on due to invalid memory accesses:
    
    [125671.831036] general protection fault: 0000 [#1] PREEMPT SMP
    [125671.832129] Modules linked in: btrfs dm_flakey dm_mod crc32c_generic xor raid6_pq acpi_cpufreq tpm_tis tpm ppdev evdev parport_pc psmouse sg parport
    processor ser
    [125671.834973] CPU: 10 PID: 19603 Comm: kworker/u32:19 Tainted: G        W       4.6.0-rc7-btrfs-next-29+ #1
    [125671.834973] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [125671.834973] Workqueue: btrfs-readahead btrfs_readahead_helper [btrfs]
    [125671.834973] task: ffff8801ac520540 ti: ffff8801ac918000 task.ti: ffff8801ac918000
    [125671.834973] RIP: 0010:[<ffffffff81270479>]  [<ffffffff81270479>] __radix_tree_lookup+0x6a/0x105
    [125671.834973] RSP: 0018:ffff8801ac91bc28  EFLAGS: 00010206
    [125671.834973] RAX: 0000000000000000 RBX: 6b6b6b6b6b6b6b6a RCX: 0000000000000000
    [125671.834973] RDX: 0000000000000000 RSI: 00000000000c1bff RDI: ffff88002ebd62a8
    [125671.834973] RBP: ffff8801ac91bc70 R08: 0000000000000001 R09: 0000000000000000
    [125671.834973] R10: ffff8801ac91bc70 R11: 0000000000000000 R12: ffff88002ebd62a8
    [125671.834973] R13: 0000000000000000 R14: 0000000000000000 R15: 00000000000c1bff
    [125671.834973] FS:  0000000000000000(0000) GS:ffff88023fd40000(0000) knlGS:0000000000000000
    [125671.834973] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [125671.834973] CR2: 000000000073cae4 CR3: 00000000b7723000 CR4: 00000000000006e0
    [125671.834973] Stack:
    [125671.834973]  0000000000000000 ffff8801422d5600 ffff8802286bbc00 0000000000000000
    [125671.834973]  0000000000000001 ffff8802286bbc00 00000000000c1bff 0000000000000000
    [125671.834973]  ffff88002e639eb8 ffff8801ac91bc80 ffffffff81270541 ffff8801ac91bcb0
    [125671.834973] Call Trace:
    [125671.834973]  [<ffffffff81270541>] radix_tree_lookup+0xd/0xf
    [125671.834973]  [<ffffffffa04ae6a6>] reada_peer_zones_set_lock+0x3e/0x60 [btrfs]
    [125671.834973]  [<ffffffffa04ae8b9>] reada_pick_zone+0x29/0x103 [btrfs]
    [125671.834973]  [<ffffffffa04af42f>] reada_start_machine_worker+0x129/0x2d3 [btrfs]
    [125671.834973]  [<ffffffffa04880be>] btrfs_scrubparity_helper+0x185/0x3aa [btrfs]
    [125671.834973]  [<ffffffffa0488341>] btrfs_readahead_helper+0xe/0x10 [btrfs]
    [125671.834973]  [<ffffffff81069691>] process_one_work+0x271/0x4e9
    [125671.834973]  [<ffffffff81069dda>] worker_thread+0x1eb/0x2c9
    [125671.834973]  [<ffffffff81069bef>] ? rescuer_thread+0x2b3/0x2b3
    [125671.834973]  [<ffffffff8106f403>] kthread+0xd4/0xdc
    [125671.834973]  [<ffffffff8149e242>] ret_from_fork+0x22/0x40
    [125671.834973]  [<ffffffff8106f32f>] ? kthread_stop+0x286/0x286
    
    So fix this by taking the device_list_mutex in the readahead code. We
    can't use here the lighter approach of using a rcu_read_lock() and
    rcu_read_unlock() pair together with a list_for_each_entry_rcu() call
    because we end up doing calls to sleeping functions (kzalloc()) in the
    respective code path.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Josef Bacik <jbacik@fb.com>

commit 6112a300c9e41993cc0dc56ac393743d28381284
Author: Soumya PN <soumya.p.n@hpe.com>
Date:   Tue May 17 21:31:14 2016 +0530

    ftrace: Don't disable irqs when taking the tasklist_lock read_lock
    
    In ftrace.c inside the function alloc_retstack_tasklist() (which will be
    invoked when function_graph tracing is on) the tasklist_lock is being
    held as reader while iterating through a list of threads. Here the lock
    is being held as reader with irqs disabled. The tasklist_lock is never
    write_locked in interrupt context so it is safe to not disable interrupts
    for the duration of read_lock in this block which, can be significant,
    given the block of code iterates through all threads. Hence changing the
    code to call read_lock() and read_unlock() instead of read_lock_irqsave()
    and read_unlock_irqrestore().
    
    A similar change was made in commits: 8063e41d2ffc ("tracing: Change
    syscall_*regfunc() to check PF_KTHREAD and use for_each_process_thread()")'
    and 3472eaa1f12e ("sched: normalize_rt_tasks(): Don't use _irqsave for
    tasklist_lock, use task_rq_lock()")'
    
    Link: http://lkml.kernel.org/r/1463500874-77480-1-git-send-email-soumya.p.n@hpe.com
    
    Signed-off-by: Soumya PN <soumya.p.n@hpe.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

commit 8eb64c913af6f50933b6a332123d7bb8688b7244
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Feb 18 14:28:55 2016 +0000

    Btrfs: fix deadlock between direct IO reads and buffered writes
    
    commit ade770294df29e08f913e5d733a756893128f45e upstream.
    
    While running a test with a mix of buffered IO and direct IO against
    the same files I hit a deadlock reported by the following trace:
    
    [11642.140352] INFO: task kworker/u32:3:15282 blocked for more than 120 seconds.
    [11642.142452]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.143982] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.146332] kworker/u32:3   D ffff880230ef7988 [11642.147737] systemd-journald[571]: Sent WATCHDOG=1 notification.
    [11642.149771]     0 15282      2 0x00000000
    [11642.151205] Workqueue: btrfs-flush_delalloc btrfs_flush_delalloc_helper [btrfs]
    [11642.154074]  ffff880230ef7988 0000000000000246 0000000000014ec0 ffff88023ec94ec0
    [11642.156722]  ffff880233fe8f80 ffff880230ef8000 ffff88023ec94ec0 7fffffffffffffff
    [11642.159205]  0000000000000002 ffffffff8147b7f9 ffff880230ef79a0 ffffffff8147b541
    [11642.161403] Call Trace:
    [11642.162129]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.163396]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.164871]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.167020]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.167931]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.182320]  [<ffffffff8108affa>] ? trace_hardirqs_on+0xd/0xf
    [11642.183762]  [<ffffffff810b079b>] ? timekeeping_get_ns+0xe/0x33
    [11642.185308]  [<ffffffff810b0f61>] ? ktime_get+0x41/0x52
    [11642.186782]  [<ffffffff8147ac08>] io_schedule_timeout+0xa0/0x102
    [11642.188217]  [<ffffffff8147ac08>] ? io_schedule_timeout+0xa0/0x102
    [11642.189626]  [<ffffffff8147b814>] bit_wait_io+0x1b/0x39
    [11642.190803]  [<ffffffff8147bb21>] __wait_on_bit_lock+0x4c/0x90
    [11642.192158]  [<ffffffff8111829f>] __lock_page+0x66/0x68
    [11642.193379]  [<ffffffff81082f29>] ? autoremove_wake_function+0x3a/0x3a
    [11642.194831]  [<ffffffffa0450ddd>] lock_page+0x31/0x34 [btrfs]
    [11642.197068]  [<ffffffffa0454e3b>] extent_write_cache_pages.isra.19.constprop.35+0x1af/0x2f4 [btrfs]
    [11642.199188]  [<ffffffffa0455373>] extent_writepages+0x4b/0x5c [btrfs]
    [11642.200723]  [<ffffffffa043c913>] ? btrfs_writepage_start_hook+0xce/0xce [btrfs]
    [11642.202465]  [<ffffffffa043aa82>] btrfs_writepages+0x28/0x2a [btrfs]
    [11642.203836]  [<ffffffff811236bc>] do_writepages+0x23/0x2c
    [11642.205624]  [<ffffffff811198c9>] __filemap_fdatawrite_range+0x5a/0x61
    [11642.207057]  [<ffffffff81119946>] filemap_fdatawrite_range+0x13/0x15
    [11642.208529]  [<ffffffffa044f87e>] btrfs_start_ordered_extent+0xd0/0x1a1 [btrfs]
    [11642.210375]  [<ffffffffa0462613>] ? btrfs_scrubparity_helper+0x140/0x33a [btrfs]
    [11642.212132]  [<ffffffffa044f974>] btrfs_run_ordered_extent_work+0x25/0x34 [btrfs]
    [11642.213837]  [<ffffffffa046262f>] btrfs_scrubparity_helper+0x15c/0x33a [btrfs]
    [11642.215457]  [<ffffffffa046293b>] btrfs_flush_delalloc_helper+0xe/0x10 [btrfs]
    [11642.217095]  [<ffffffff8106483e>] process_one_work+0x256/0x48b
    [11642.218324]  [<ffffffff81064f20>] worker_thread+0x1f5/0x2a7
    [11642.219466]  [<ffffffff81064d2b>] ? rescuer_thread+0x289/0x289
    [11642.220801]  [<ffffffff8106a500>] kthread+0xd4/0xdc
    [11642.222032]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.223190]  [<ffffffff8147fdef>] ret_from_fork+0x3f/0x70
    [11642.224394]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.226295] 2 locks held by kworker/u32:3/15282:
    [11642.227273]  #0:  ("%s-%s""btrfs", name){++++.+}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.229412]  #1:  ((&work->normal_work)){+.+.+.}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.231414] INFO: task kworker/u32:8:15289 blocked for more than 120 seconds.
    [11642.232872]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.234109] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.235776] kworker/u32:8   D ffff88020de5f848     0 15289      2 0x00000000
    [11642.237412] Workqueue: writeback wb_workfn (flush-btrfs-481)
    [11642.238670]  ffff88020de5f848 0000000000000246 0000000000014ec0 ffff88023ed54ec0
    [11642.240475]  ffff88021b1ece40 ffff88020de60000 ffff88023ed54ec0 7fffffffffffffff
    [11642.242154]  0000000000000002 ffffffff8147b7f9 ffff88020de5f860 ffffffff8147b541
    [11642.243715] Call Trace:
    [11642.244390]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.245432]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.246392]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.247479]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.248551]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.249968]  [<ffffffff8108affa>] ? trace_hardirqs_on+0xd/0xf
    [11642.251043]  [<ffffffff810b079b>] ? timekeeping_get_ns+0xe/0x33
    [11642.252202]  [<ffffffff810b0f61>] ? ktime_get+0x41/0x52
    [11642.253210]  [<ffffffff8147ac08>] io_schedule_timeout+0xa0/0x102
    [11642.254307]  [<ffffffff8147ac08>] ? io_schedule_timeout+0xa0/0x102
    [11642.256118]  [<ffffffff8147b814>] bit_wait_io+0x1b/0x39
    [11642.257131]  [<ffffffff8147bb21>] __wait_on_bit_lock+0x4c/0x90
    [11642.258200]  [<ffffffff8111829f>] __lock_page+0x66/0x68
    [11642.259168]  [<ffffffff81082f29>] ? autoremove_wake_function+0x3a/0x3a
    [11642.260516]  [<ffffffffa0450ddd>] lock_page+0x31/0x34 [btrfs]
    [11642.261841]  [<ffffffffa0454e3b>] extent_write_cache_pages.isra.19.constprop.35+0x1af/0x2f4 [btrfs]
    [11642.263531]  [<ffffffffa0455373>] extent_writepages+0x4b/0x5c [btrfs]
    [11642.264747]  [<ffffffffa043c913>] ? btrfs_writepage_start_hook+0xce/0xce [btrfs]
    [11642.266148]  [<ffffffffa043aa82>] btrfs_writepages+0x28/0x2a [btrfs]
    [11642.267264]  [<ffffffff811236bc>] do_writepages+0x23/0x2c
    [11642.268280]  [<ffffffff81192a2b>] __writeback_single_inode+0xda/0x5ba
    [11642.269407]  [<ffffffff811939f0>] writeback_sb_inodes+0x27b/0x43d
    [11642.270476]  [<ffffffff81193c28>] __writeback_inodes_wb+0x76/0xae
    [11642.271547]  [<ffffffff81193ea6>] wb_writeback+0x19e/0x41c
    [11642.272588]  [<ffffffff81194821>] wb_workfn+0x201/0x341
    [11642.273523]  [<ffffffff81194821>] ? wb_workfn+0x201/0x341
    [11642.274479]  [<ffffffff8106483e>] process_one_work+0x256/0x48b
    [11642.275497]  [<ffffffff81064f20>] worker_thread+0x1f5/0x2a7
    [11642.276518]  [<ffffffff81064d2b>] ? rescuer_thread+0x289/0x289
    [11642.277520]  [<ffffffff81064d2b>] ? rescuer_thread+0x289/0x289
    [11642.278517]  [<ffffffff8106a500>] kthread+0xd4/0xdc
    [11642.279371]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.280468]  [<ffffffff8147fdef>] ret_from_fork+0x3f/0x70
    [11642.281607]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.282604] 3 locks held by kworker/u32:8/15289:
    [11642.283423]  #0:  ("writeback"){++++.+}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.285629]  #1:  ((&(&wb->dwork)->work)){+.+.+.}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.287538]  #2:  (&type->s_umount_key#37){+++++.}, at: [<ffffffff81171217>] trylock_super+0x1b/0x4b
    [11642.289423] INFO: task fdm-stress:26848 blocked for more than 120 seconds.
    [11642.290547]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.291453] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.292864] fdm-stress      D ffff88022c107c20     0 26848  26591 0x00000000
    [11642.294118]  ffff88022c107c20 000000038108affa 0000000000014ec0 ffff88023ed54ec0
    [11642.295602]  ffff88013ab1ca40 ffff88022c108000 ffff8800b2fc19d0 00000000000e0fff
    [11642.297098]  ffff8800b2fc19b0 ffff88022c107c88 ffff88022c107c38 ffffffff8147b541
    [11642.298433] Call Trace:
    [11642.298896]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.299738]  [<ffffffffa045225d>] lock_extent_bits+0xfe/0x1a3 [btrfs]
    [11642.300833]  [<ffffffff81082eef>] ? add_wait_queue_exclusive+0x44/0x44
    [11642.301943]  [<ffffffffa0447516>] lock_and_cleanup_extent_if_need+0x68/0x18e [btrfs]
    [11642.303270]  [<ffffffffa04485ba>] __btrfs_buffered_write+0x238/0x4c1 [btrfs]
    [11642.304552]  [<ffffffffa044b50a>] ? btrfs_file_write_iter+0x17c/0x408 [btrfs]
    [11642.305782]  [<ffffffffa044b682>] btrfs_file_write_iter+0x2f4/0x408 [btrfs]
    [11642.306878]  [<ffffffff8116e298>] __vfs_write+0x7c/0xa5
    [11642.307729]  [<ffffffff8116e7d1>] vfs_write+0x9d/0xe8
    [11642.308602]  [<ffffffff8116efbb>] SyS_write+0x50/0x7e
    [11642.309410]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.310403] 3 locks held by fdm-stress/26848:
    [11642.311108]  #0:  (&f->f_pos_lock){+.+.+.}, at: [<ffffffff811877e8>] __fdget_pos+0x3a/0x40
    [11642.312578]  #1:  (sb_writers#11){.+.+.+}, at: [<ffffffff811706ee>] __sb_start_write+0x5f/0xb0
    [11642.314170]  #2:  (&sb->s_type->i_mutex_key#15){+.+.+.}, at: [<ffffffffa044b401>] btrfs_file_write_iter+0x73/0x408 [btrfs]
    [11642.316796] INFO: task fdm-stress:26849 blocked for more than 120 seconds.
    [11642.317842]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.318691] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.319959] fdm-stress      D ffff8801964ffa68     0 26849  26591 0x00000000
    [11642.321312]  ffff8801964ffa68 00ff8801e9975f80 0000000000014ec0 ffff88023ed94ec0
    [11642.322555]  ffff8800b00b4840 ffff880196500000 ffff8801e9975f20 0000000000000002
    [11642.323715]  ffff8801e9975f18 ffff8800b00b4840 ffff8801964ffa80 ffffffff8147b541
    [11642.325096] Call Trace:
    [11642.325532]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.326303]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.327180]  [<ffffffff8108ae40>] ? mark_held_locks+0x5e/0x74
    [11642.328114]  [<ffffffff8147f30e>] ? _raw_spin_unlock_irq+0x2c/0x4a
    [11642.329051]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.330053]  [<ffffffff8147bceb>] __wait_for_common+0x109/0x147
    [11642.330952]  [<ffffffff8147bceb>] ? __wait_for_common+0x109/0x147
    [11642.331869]  [<ffffffff8147e7bb>] ? usleep_range+0x4a/0x4a
    [11642.332925]  [<ffffffff81074075>] ? wake_up_q+0x47/0x47
    [11642.333736]  [<ffffffff8147bd4d>] wait_for_completion+0x24/0x26
    [11642.334672]  [<ffffffffa044f5ce>] btrfs_wait_ordered_extents+0x1c8/0x217 [btrfs]
    [11642.335858]  [<ffffffffa0465b5a>] btrfs_mksubvol+0x224/0x45d [btrfs]
    [11642.336854]  [<ffffffff81082eef>] ? add_wait_queue_exclusive+0x44/0x44
    [11642.337820]  [<ffffffffa0465edb>] btrfs_ioctl_snap_create_transid+0x148/0x17a [btrfs]
    [11642.339026]  [<ffffffffa046603b>] btrfs_ioctl_snap_create_v2+0xc7/0x110 [btrfs]
    [11642.340214]  [<ffffffffa0468582>] btrfs_ioctl+0x590/0x27bd [btrfs]
    [11642.341123]  [<ffffffff8147dc00>] ? mutex_unlock+0xe/0x10
    [11642.341934]  [<ffffffffa00fa6e9>] ? ext4_file_write_iter+0x2a3/0x36f [ext4]
    [11642.342936]  [<ffffffff8108895d>] ? __lock_is_held+0x3c/0x57
    [11642.343772]  [<ffffffff81186a1d>] ? rcu_read_unlock+0x3e/0x5d
    [11642.344673]  [<ffffffff8117dc95>] do_vfs_ioctl+0x458/0x4dc
    [11642.346024]  [<ffffffff81186bbe>] ? __fget_light+0x62/0x71
    [11642.346873]  [<ffffffff8117dd70>] SyS_ioctl+0x57/0x79
    [11642.347720]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.350222] 4 locks held by fdm-stress/26849:
    [11642.350898]  #0:  (sb_writers#11){.+.+.+}, at: [<ffffffff811706ee>] __sb_start_write+0x5f/0xb0
    [11642.352375]  #1:  (&type->i_mutex_dir_key#4/1){+.+.+.}, at: [<ffffffffa0465981>] btrfs_mksubvol+0x4b/0x45d [btrfs]
    [11642.354072]  #2:  (&fs_info->subvol_sem){++++..}, at: [<ffffffffa0465a2a>] btrfs_mksubvol+0xf4/0x45d [btrfs]
    [11642.355647]  #3:  (&root->ordered_extent_mutex){+.+...}, at: [<ffffffffa044f456>] btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.357516] INFO: task fdm-stress:26850 blocked for more than 120 seconds.
    [11642.358508]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.359376] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.368625] fdm-stress      D ffff88021f167688     0 26850  26591 0x00000000
    [11642.369716]  ffff88021f167688 0000000000000001 0000000000014ec0 ffff88023edd4ec0
    [11642.370950]  ffff880128a98680 ffff88021f168000 ffff88023edd4ec0 7fffffffffffffff
    [11642.372210]  0000000000000002 ffffffff8147b7f9 ffff88021f1676a0 ffffffff8147b541
    [11642.373430] Call Trace:
    [11642.373853]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.374623]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.375948]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.376862]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.377637]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.378610]  [<ffffffff8108affa>] ? trace_hardirqs_on+0xd/0xf
    [11642.379457]  [<ffffffff810b079b>] ? timekeeping_get_ns+0xe/0x33
    [11642.380366]  [<ffffffff810b0f61>] ? ktime_get+0x41/0x52
    [11642.381353]  [<ffffffff8147ac08>] io_schedule_timeout+0xa0/0x102
    [11642.382255]  [<ffffffff8147ac08>] ? io_schedule_timeout+0xa0/0x102
    [11642.383162]  [<ffffffff8147b814>] bit_wait_io+0x1b/0x39
    [11642.383945]  [<ffffffff8147bb21>] __wait_on_bit_lock+0x4c/0x90
    [11642.384875]  [<ffffffff8111829f>] __lock_page+0x66/0x68
    [11642.385749]  [<ffffffff81082f29>] ? autoremove_wake_function+0x3a/0x3a
    [11642.386721]  [<ffffffffa0450ddd>] lock_page+0x31/0x34 [btrfs]
    [11642.387596]  [<ffffffffa0454e3b>] extent_write_cache_pages.isra.19.constprop.35+0x1af/0x2f4 [btrfs]
    [11642.389030]  [<ffffffffa0455373>] extent_writepages+0x4b/0x5c [btrfs]
    [11642.389973]  [<ffffffff810a25ad>] ? rcu_read_lock_sched_held+0x61/0x69
    [11642.390939]  [<ffffffffa043c913>] ? btrfs_writepage_start_hook+0xce/0xce [btrfs]
    [11642.392271]  [<ffffffffa0451c32>] ? __clear_extent_bit+0x26e/0x2c0 [btrfs]
    [11642.393305]  [<ffffffffa043aa82>] btrfs_writepages+0x28/0x2a [btrfs]
    [11642.394239]  [<ffffffff811236bc>] do_writepages+0x23/0x2c
    [11642.395045]  [<ffffffff811198c9>] __filemap_fdatawrite_range+0x5a/0x61
    [11642.395991]  [<ffffffff81119946>] filemap_fdatawrite_range+0x13/0x15
    [11642.397144]  [<ffffffffa044f87e>] btrfs_start_ordered_extent+0xd0/0x1a1 [btrfs]
    [11642.398392]  [<ffffffffa0452094>] ? clear_extent_bit+0x17/0x19 [btrfs]
    [11642.399363]  [<ffffffffa0445945>] btrfs_get_blocks_direct+0x12b/0x61c [btrfs]
    [11642.400445]  [<ffffffff8119f7a1>] ? dio_bio_add_page+0x3d/0x54
    [11642.401309]  [<ffffffff8119fa93>] ? submit_page_section+0x7b/0x111
    [11642.402213]  [<ffffffff811a0258>] do_blockdev_direct_IO+0x685/0xc24
    [11642.403139]  [<ffffffffa044581a>] ? btrfs_page_exists_in_range+0x1a1/0x1a1 [btrfs]
    [11642.404360]  [<ffffffffa043d267>] ? btrfs_get_extent_fiemap+0x1c0/0x1c0 [btrfs]
    [11642.406187]  [<ffffffff811a0828>] __blockdev_direct_IO+0x31/0x33
    [11642.407070]  [<ffffffff811a0828>] ? __blockdev_direct_IO+0x31/0x33
    [11642.407990]  [<ffffffffa043d267>] ? btrfs_get_extent_fiemap+0x1c0/0x1c0 [btrfs]
    [11642.409192]  [<ffffffffa043b4ca>] btrfs_direct_IO+0x1c7/0x27e [btrfs]
    [11642.410146]  [<ffffffffa043d267>] ? btrfs_get_extent_fiemap+0x1c0/0x1c0 [btrfs]
    [11642.411291]  [<ffffffff81119a2c>] generic_file_read_iter+0x89/0x4e1
    [11642.412263]  [<ffffffff8108ac05>] ? mark_lock+0x24/0x201
    [11642.413057]  [<ffffffff8116e1f8>] __vfs_read+0x79/0x9d
    [11642.413897]  [<ffffffff8116e6f1>] vfs_read+0x8f/0xd2
    [11642.414708]  [<ffffffff8116ef3d>] SyS_read+0x50/0x7e
    [11642.415573]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.416572] 1 lock held by fdm-stress/26850:
    [11642.417345]  #0:  (&f->f_pos_lock){+.+.+.}, at: [<ffffffff811877e8>] __fdget_pos+0x3a/0x40
    [11642.418703] INFO: task fdm-stress:26851 blocked for more than 120 seconds.
    [11642.419698]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.420612] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.421807] fdm-stress      D ffff880196483d28     0 26851  26591 0x00000000
    [11642.422878]  ffff880196483d28 00ff8801c8f60740 0000000000014ec0 ffff88023ed94ec0
    [11642.424149]  ffff8801c8f60740 ffff880196484000 0000000000000246 ffff8801c8f60740
    [11642.425374]  ffff8801bb711840 ffff8801bb711878 ffff880196483d40 ffffffff8147b541
    [11642.426591] Call Trace:
    [11642.427013]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.427856]  [<ffffffff8147b6d5>] schedule_preempt_disabled+0x18/0x24
    [11642.428852]  [<ffffffff8147c23a>] mutex_lock_nested+0x1d7/0x3b4
    [11642.429743]  [<ffffffffa044f456>] ? btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.430911]  [<ffffffffa044f456>] btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.432102]  [<ffffffffa044f674>] ? btrfs_wait_ordered_roots+0x57/0x191 [btrfs]
    [11642.433259]  [<ffffffffa044f456>] ? btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.434431]  [<ffffffffa044f6ea>] btrfs_wait_ordered_roots+0xcd/0x191 [btrfs]
    [11642.436079]  [<ffffffffa0410cab>] btrfs_sync_fs+0xe0/0x1ad [btrfs]
    [11642.437009]  [<ffffffff81197900>] ? SyS_tee+0x23c/0x23c
    [11642.437860]  [<ffffffff81197920>] sync_fs_one_sb+0x20/0x22
    [11642.438723]  [<ffffffff81171435>] iterate_supers+0x75/0xc2
    [11642.439597]  [<ffffffff81197d00>] sys_sync+0x52/0x80
    [11642.440454]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.441533] 3 locks held by fdm-stress/26851:
    [11642.442370]  #0:  (&type->s_umount_key#37){+++++.}, at: [<ffffffff8117141f>] iterate_supers+0x5f/0xc2
    [11642.444043]  #1:  (&fs_info->ordered_operations_mutex){+.+...}, at: [<ffffffffa044f661>] btrfs_wait_ordered_roots+0x44/0x191 [btrfs]
    [11642.446010]  #2:  (&root->ordered_extent_mutex){+.+...}, at: [<ffffffffa044f456>] btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    
    This happened because under specific timings the path for direct IO reads
    can deadlock with concurrent buffered writes. The diagram below shows how
    this happens for an example file that has the following layout:
    
         [  extent A  ]  [  extent B  ]  [ ....
         0K              4K              8K
    
         CPU 1                                               CPU 2                             CPU 3
    
    DIO read against range
     [0K, 8K[ starts
    
    btrfs_direct_IO()
      --> calls btrfs_get_blocks_direct()
          which finds the extent map for the
          extent A and leaves the range
          [0K, 4K[ locked in the inode's
          io tree
    
                                                       buffered write against
                                                       range [4K, 8K[ starts
    
                                                       __btrfs_buffered_write()
                                                         --> dirties page at 4K
    
                                                                                         a user space
                                                                                         task calls sync
                                                                                         for e.g or
                                                                                         writepages() is
                                                                                         invoked by mm
    
                                                                                         writepages()
                                                                                           run_delalloc_range()
                                                                                             cow_file_range()
                                                                                               --> ordered extent X
                                                                                                   for the buffered
                                                                                                   write is created
                                                                                                   and
                                                                                                   writeback starts
    
      --> calls btrfs_get_blocks_direct()
          again, without submitting first
          a bio for reading extent A, and
          finds the extent map for extent B
    
      --> calls lock_extent_direct()
    
          --> locks range [4K, 8K[
          --> finds ordered extent X
              covering range [4K, 8K[
          --> unlocks range [4K, 8K[
    
                                                      buffered write against
                                                      range [0K, 8K[ starts
    
                                                      __btrfs_buffered_write()
                                                        prepare_pages()
                                                          --> locks pages with
                                                              offsets 0 and 4K
                                                        lock_and_cleanup_extent_if_need()
                                                          --> blocks attempting to
                                                              lock range [0K, 8K[ in
                                                              the inode's io tree,
                                                              because the range [0, 4K[
                                                              is already locked by the
                                                              direct IO task at CPU 1
    
          --> calls
              btrfs_start_ordered_extent(oe X)
    
              btrfs_start_ordered_extent(oe X)
    
                --> At this point writeback for ordered
                    extent X has not finished yet
    
                filemap_fdatawrite_range()
                  btrfs_writepages()
                    extent_writepages()
                      extent_write_cache_pages()
                        --> finds page with offset 0
                            with the writeback tag
                            (and not dirty)
                        --> tries to lock it
                             --> deadlock, task at CPU 2
                                 has the page locked and
                                 is blocked on the io range
                                 [0, 4K[ that was locked
                                 earlier by this task
    
    So fix this by falling back to a buffered read in the direct IO read path
    when an ordered extent for a buffered write is found.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 68517c93716826992dc91db6a65c57c7919a3484
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Dec 22 17:25:17 2015 +0200

    stm class: Select CONFIG_SRCU
    
    commit 042d4460b5b4379a12f375045ff9065cf6758735 upstream.
    
    The newly added STM code uses SRCU, but does not ensure that
    this code is part of the kernel:
    
    drivers/built-in.o: In function `stm_source_link_show':
    include/linux/srcu.h:221: undefined reference to `__srcu_read_lock'
    include/linux/srcu.h:238: undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `stm_source_link_drop':
    include/linux/srcu.h:221: undefined reference to `__srcu_read_lock'
    include/linux/srcu.h:238: undefined reference to `__srcu_read_unlock'
    
    This adds a Kconfig 'select' statement like all the other SRCU using
    drivers have.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Fixes: 7bd1d4093c2f ("stm class: Introduce an abstraction for System Trace Module devices")
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f4b1d0a9a3f4291ba4ab48dd27efd01d3775d7f6
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Dec 22 17:25:17 2015 +0200

    stm class: Select CONFIG_SRCU
    
    commit 042d4460b5b4379a12f375045ff9065cf6758735 upstream.
    
    The newly added STM code uses SRCU, but does not ensure that
    this code is part of the kernel:
    
    drivers/built-in.o: In function `stm_source_link_show':
    include/linux/srcu.h:221: undefined reference to `__srcu_read_lock'
    include/linux/srcu.h:238: undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `stm_source_link_drop':
    include/linux/srcu.h:221: undefined reference to `__srcu_read_lock'
    include/linux/srcu.h:238: undefined reference to `__srcu_read_unlock'
    
    This adds a Kconfig 'select' statement like all the other SRCU using
    drivers have.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Fixes: 7bd1d4093c2f ("stm class: Introduce an abstraction for System Trace Module devices")
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2d331915a04144dad738e725769d8fac06ef6155
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Apr 1 08:52:15 2016 -0700

    tcp/dccp: use rcu locking in inet_diag_find_one_icsk()
    
    RX packet processing holds rcu_read_lock(), so we can remove
    pairs of rcu_read_lock()/rcu_read_unlock() in lookup functions
    if inet_diag also holds rcu before calling them.
    
    This is needed anyway as __inet_lookup_listener() and
    inet6_lookup_listener() will soon no longer increment
    refcount on the found listener.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit d8936c0b7e29510ce8f5c85ff5fcc592a938e860
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Feb 15 17:29:47 2016 -0800

    documentation: Explain why rcu_read_lock() needs no barrier()
    
    This commit adds a Quick Quiz whose answer explains why the compiler
    code reordering enabled by CONFIG_PREEMPT=n's empty rcu_read_lock()
    and rcu_read_unlock() functions does not hinder RCU's ability to figure
    out which RCU read-side critical sections have completed and not.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 47252cfbac03644ee4a3adfa50c77896aa94f2bb
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Mon Mar 21 11:23:39 2016 -0400

    sched/core: Add preempt checks in preempt_schedule() code
    
    While testing the tracer preemptoff, I hit this strange trace:
    
       <...>-259     0...1    0us : schedule <-worker_thread
       <...>-259     0d..1    0us : rcu_note_context_switch <-__schedule
       <...>-259     0d..1    0us : rcu_sched_qs <-rcu_note_context_switch
       <...>-259     0d..1    0us : rcu_preempt_qs <-rcu_note_context_switch
       <...>-259     0d..1    0us : _raw_spin_lock <-__schedule
       <...>-259     0d..1    0us : preempt_count_add <-_raw_spin_lock
       <...>-259     0d..2    0us : do_raw_spin_lock <-_raw_spin_lock
       <...>-259     0d..2    1us : deactivate_task <-__schedule
       <...>-259     0d..2    1us : update_rq_clock.part.84 <-deactivate_task
       <...>-259     0d..2    1us : dequeue_task_fair <-deactivate_task
       <...>-259     0d..2    1us : dequeue_entity <-dequeue_task_fair
       <...>-259     0d..2    1us : update_curr <-dequeue_entity
       <...>-259     0d..2    1us : update_min_vruntime <-update_curr
       <...>-259     0d..2    1us : cpuacct_charge <-update_curr
       <...>-259     0d..2    1us : __rcu_read_lock <-cpuacct_charge
       <...>-259     0d..2    1us : __rcu_read_unlock <-cpuacct_charge
       <...>-259     0d..2    1us : clear_buddies <-dequeue_entity
       <...>-259     0d..2    1us : account_entity_dequeue <-dequeue_entity
       <...>-259     0d..2    2us : update_min_vruntime <-dequeue_entity
       <...>-259     0d..2    2us : update_cfs_shares <-dequeue_entity
       <...>-259     0d..2    2us : hrtick_update <-dequeue_task_fair
       <...>-259     0d..2    2us : wq_worker_sleeping <-__schedule
       <...>-259     0d..2    2us : kthread_data <-wq_worker_sleeping
       <...>-259     0d..2    2us : pick_next_task_fair <-__schedule
       <...>-259     0d..2    2us : check_cfs_rq_runtime <-pick_next_task_fair
       <...>-259     0d..2    2us : pick_next_entity <-pick_next_task_fair
       <...>-259     0d..2    2us : clear_buddies <-pick_next_entity
       <...>-259     0d..2    2us : pick_next_entity <-pick_next_task_fair
       <...>-259     0d..2    2us : clear_buddies <-pick_next_entity
       <...>-259     0d..2    2us : set_next_entity <-pick_next_task_fair
       <...>-259     0d..2    3us : put_prev_entity <-pick_next_task_fair
       <...>-259     0d..2    3us : check_cfs_rq_runtime <-put_prev_entity
       <...>-259     0d..2    3us : set_next_entity <-pick_next_task_fair
    gnome-sh-1031    0d..2    3us : finish_task_switch <-__schedule
    gnome-sh-1031    0d..2    3us : _raw_spin_unlock_irq <-finish_task_switch
    gnome-sh-1031    0d..2    3us : do_raw_spin_unlock <-_raw_spin_unlock_irq
    gnome-sh-1031    0...2    3us!: preempt_count_sub <-_raw_spin_unlock_irq
    gnome-sh-1031    0...1  582us : do_raw_spin_lock <-_raw_spin_lock
    gnome-sh-1031    0...1  583us : _raw_spin_unlock <-drm_gem_object_lookup
    gnome-sh-1031    0...1  583us : do_raw_spin_unlock <-_raw_spin_unlock
    gnome-sh-1031    0...1  583us : preempt_count_sub <-_raw_spin_unlock
    gnome-sh-1031    0...1  584us : _raw_spin_unlock <-drm_gem_object_lookup
    gnome-sh-1031    0...1  584us+: trace_preempt_on <-drm_gem_object_lookup
    gnome-sh-1031    0...1  603us : <stack trace>
     => preempt_count_sub
     => _raw_spin_unlock
     => drm_gem_object_lookup
     => i915_gem_madvise_ioctl
     => drm_ioctl
     => do_vfs_ioctl
     => SyS_ioctl
     => entry_SYSCALL_64_fastpath
    
    As I'm tracing preemption disabled, it seemed incorrect that the trace
    would go across a schedule and report not being in the scheduler.
    Looking into this I discovered the problem.
    
    schedule() calls preempt_disable() but the preempt_schedule() calls
    preempt_enable_notrace(). What happened above was that the gnome-shell
    task was preempted on another CPU, migrated over to the idle cpu. The
    tracer stared with idle calling schedule(), which called
    preempt_disable(), but then gnome-shell finished, and it enabled
    preemption with preempt_enable_notrace() that does stop the trace, even
    though preemption was enabled.
    
    The purpose of the preempt_disable_notrace() in the preempt_schedule()
    is to prevent function tracing from going into an infinite loop.
    Because function tracing can trace the preempt_enable/disable() calls
    that are traced. The problem with function tracing is:
    
      NEED_RESCHED set
      preempt_schedule()
        preempt_disable()
          preempt_count_inc()
            function trace (before incrementing preempt count)
              preempt_disable_notrace()
              preempt_enable_notrace()
                sees NEED_RESCHED set
                   preempt_schedule() (repeat)
    
    Now by breaking out the preempt off/on tracing into their own code:
    preempt_disable_check() and preempt_enable_check(), we can add these to
    the preempt_schedule() code. As preemption would then be disabled, even
    if they were to be traced by the function tracer, the disabled
    preemption would prevent the recursion.
    
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20160321112339.6dc78ad6@gandalf.local.home
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 1cefc2cd20f1d2b4e84bba14d5a5bf5d44936dc6
Author: Harish Chegondi <harish.chegondi@intel.com>
Date:   Wed Feb 3 14:20:19 2016 -0800

    IB/qib: Remove qib_lookup_qpn and use rvt_lookup_qpn instead
    
    Add calls to rcu_read_lock()/rcu_read_unlock() as rvt_lookup_qpn callers
    must hold the rcu_read_lock before calling and keep the lock until the
    returned qp is no longer in use.
    
    Remove lookaside qp and some qp refcount atomics in the sdma send code
    that is redundant with the s_dma_busy refcount, which will also stall
    the state processing to the reset state.
    
    Change the qpn hash function to hash_32 which is hash function used
    in rvt_lookup_qpn. qpn_hash function would be eliminated in later patches.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
    Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit 286adf77d94e8b57a620e6cdbdcc72d99d8609b3
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 29 08:54:52 2014 -0400

    shrink_dentry_list(): take parent's ->d_lock earlier
    
    commit 046b961b45f93a92e4c70525a12f3d378bced130 upstream.
    
    The cause of livelocks there is that we are taking ->d_lock on
    dentry and its parent in the wrong order, forcing us to use
    trylock on the parent's one.  d_walk() takes them in the right
    order, and unfortunately it's not hard to create a situation
    when shrink_dentry_list() can't make progress since trylock
    keeps failing, and shrink_dcache_parent() or check_submounts_and_drop()
    keeps calling d_walk() disrupting the very shrink_dentry_list() it's
    waiting for.
    
    Solution is straightforward - if that trylock fails, let's unlock
    the dentry itself and take locks in the right order.  We need to
    stabilize ->d_parent without holding ->d_lock, but that's doable
    using RCU.  And we'd better do that in the very beginning of the
    loop in shrink_dentry_list(), since the checks on refcount, etc.
    would need to be redone anyway.
    
    That deals with a half of the problem - killing dentries on the
    shrink list itself.  Another one (dropping their parents) is
    in the next commit.
    
    locking parent is interesting - it would be easy to do rcu_read_lock(),
    lock whatever we think is a parent, lock dentry itself and check
    if the parent is still the right one.  Except that we need to check
    that *before* locking the dentry, or we are risking taking ->d_lock
    out of order.  Fortunately, once the D1 is locked, we can check if
    D2->d_parent is equal to D1 without the need to lock D2; D2->d_parent
    can start or stop pointing to D1 only under D1->d_lock, so taking
    D1->d_lock is enough.  In other words, the right solution is
    rcu_read_lock/lock what looks like parent right now/check if it's
    still our parent/rcu_read_unlock/lock the child.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fb87262aec0685ef7fe89ae50a5ee900d48db4d4
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    [ Upstream commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e ]
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>

commit ade770294df29e08f913e5d733a756893128f45e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Thu Feb 18 14:28:55 2016 +0000

    Btrfs: fix deadlock between direct IO reads and buffered writes
    
    While running a test with a mix of buffered IO and direct IO against
    the same files I hit a deadlock reported by the following trace:
    
    [11642.140352] INFO: task kworker/u32:3:15282 blocked for more than 120 seconds.
    [11642.142452]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.143982] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.146332] kworker/u32:3   D ffff880230ef7988 [11642.147737] systemd-journald[571]: Sent WATCHDOG=1 notification.
    [11642.149771]     0 15282      2 0x00000000
    [11642.151205] Workqueue: btrfs-flush_delalloc btrfs_flush_delalloc_helper [btrfs]
    [11642.154074]  ffff880230ef7988 0000000000000246 0000000000014ec0 ffff88023ec94ec0
    [11642.156722]  ffff880233fe8f80 ffff880230ef8000 ffff88023ec94ec0 7fffffffffffffff
    [11642.159205]  0000000000000002 ffffffff8147b7f9 ffff880230ef79a0 ffffffff8147b541
    [11642.161403] Call Trace:
    [11642.162129]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.163396]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.164871]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.167020]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.167931]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.182320]  [<ffffffff8108affa>] ? trace_hardirqs_on+0xd/0xf
    [11642.183762]  [<ffffffff810b079b>] ? timekeeping_get_ns+0xe/0x33
    [11642.185308]  [<ffffffff810b0f61>] ? ktime_get+0x41/0x52
    [11642.186782]  [<ffffffff8147ac08>] io_schedule_timeout+0xa0/0x102
    [11642.188217]  [<ffffffff8147ac08>] ? io_schedule_timeout+0xa0/0x102
    [11642.189626]  [<ffffffff8147b814>] bit_wait_io+0x1b/0x39
    [11642.190803]  [<ffffffff8147bb21>] __wait_on_bit_lock+0x4c/0x90
    [11642.192158]  [<ffffffff8111829f>] __lock_page+0x66/0x68
    [11642.193379]  [<ffffffff81082f29>] ? autoremove_wake_function+0x3a/0x3a
    [11642.194831]  [<ffffffffa0450ddd>] lock_page+0x31/0x34 [btrfs]
    [11642.197068]  [<ffffffffa0454e3b>] extent_write_cache_pages.isra.19.constprop.35+0x1af/0x2f4 [btrfs]
    [11642.199188]  [<ffffffffa0455373>] extent_writepages+0x4b/0x5c [btrfs]
    [11642.200723]  [<ffffffffa043c913>] ? btrfs_writepage_start_hook+0xce/0xce [btrfs]
    [11642.202465]  [<ffffffffa043aa82>] btrfs_writepages+0x28/0x2a [btrfs]
    [11642.203836]  [<ffffffff811236bc>] do_writepages+0x23/0x2c
    [11642.205624]  [<ffffffff811198c9>] __filemap_fdatawrite_range+0x5a/0x61
    [11642.207057]  [<ffffffff81119946>] filemap_fdatawrite_range+0x13/0x15
    [11642.208529]  [<ffffffffa044f87e>] btrfs_start_ordered_extent+0xd0/0x1a1 [btrfs]
    [11642.210375]  [<ffffffffa0462613>] ? btrfs_scrubparity_helper+0x140/0x33a [btrfs]
    [11642.212132]  [<ffffffffa044f974>] btrfs_run_ordered_extent_work+0x25/0x34 [btrfs]
    [11642.213837]  [<ffffffffa046262f>] btrfs_scrubparity_helper+0x15c/0x33a [btrfs]
    [11642.215457]  [<ffffffffa046293b>] btrfs_flush_delalloc_helper+0xe/0x10 [btrfs]
    [11642.217095]  [<ffffffff8106483e>] process_one_work+0x256/0x48b
    [11642.218324]  [<ffffffff81064f20>] worker_thread+0x1f5/0x2a7
    [11642.219466]  [<ffffffff81064d2b>] ? rescuer_thread+0x289/0x289
    [11642.220801]  [<ffffffff8106a500>] kthread+0xd4/0xdc
    [11642.222032]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.223190]  [<ffffffff8147fdef>] ret_from_fork+0x3f/0x70
    [11642.224394]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.226295] 2 locks held by kworker/u32:3/15282:
    [11642.227273]  #0:  ("%s-%s""btrfs", name){++++.+}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.229412]  #1:  ((&work->normal_work)){+.+.+.}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.231414] INFO: task kworker/u32:8:15289 blocked for more than 120 seconds.
    [11642.232872]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.234109] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.235776] kworker/u32:8   D ffff88020de5f848     0 15289      2 0x00000000
    [11642.237412] Workqueue: writeback wb_workfn (flush-btrfs-481)
    [11642.238670]  ffff88020de5f848 0000000000000246 0000000000014ec0 ffff88023ed54ec0
    [11642.240475]  ffff88021b1ece40 ffff88020de60000 ffff88023ed54ec0 7fffffffffffffff
    [11642.242154]  0000000000000002 ffffffff8147b7f9 ffff88020de5f860 ffffffff8147b541
    [11642.243715] Call Trace:
    [11642.244390]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.245432]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.246392]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.247479]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.248551]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.249968]  [<ffffffff8108affa>] ? trace_hardirqs_on+0xd/0xf
    [11642.251043]  [<ffffffff810b079b>] ? timekeeping_get_ns+0xe/0x33
    [11642.252202]  [<ffffffff810b0f61>] ? ktime_get+0x41/0x52
    [11642.253210]  [<ffffffff8147ac08>] io_schedule_timeout+0xa0/0x102
    [11642.254307]  [<ffffffff8147ac08>] ? io_schedule_timeout+0xa0/0x102
    [11642.256118]  [<ffffffff8147b814>] bit_wait_io+0x1b/0x39
    [11642.257131]  [<ffffffff8147bb21>] __wait_on_bit_lock+0x4c/0x90
    [11642.258200]  [<ffffffff8111829f>] __lock_page+0x66/0x68
    [11642.259168]  [<ffffffff81082f29>] ? autoremove_wake_function+0x3a/0x3a
    [11642.260516]  [<ffffffffa0450ddd>] lock_page+0x31/0x34 [btrfs]
    [11642.261841]  [<ffffffffa0454e3b>] extent_write_cache_pages.isra.19.constprop.35+0x1af/0x2f4 [btrfs]
    [11642.263531]  [<ffffffffa0455373>] extent_writepages+0x4b/0x5c [btrfs]
    [11642.264747]  [<ffffffffa043c913>] ? btrfs_writepage_start_hook+0xce/0xce [btrfs]
    [11642.266148]  [<ffffffffa043aa82>] btrfs_writepages+0x28/0x2a [btrfs]
    [11642.267264]  [<ffffffff811236bc>] do_writepages+0x23/0x2c
    [11642.268280]  [<ffffffff81192a2b>] __writeback_single_inode+0xda/0x5ba
    [11642.269407]  [<ffffffff811939f0>] writeback_sb_inodes+0x27b/0x43d
    [11642.270476]  [<ffffffff81193c28>] __writeback_inodes_wb+0x76/0xae
    [11642.271547]  [<ffffffff81193ea6>] wb_writeback+0x19e/0x41c
    [11642.272588]  [<ffffffff81194821>] wb_workfn+0x201/0x341
    [11642.273523]  [<ffffffff81194821>] ? wb_workfn+0x201/0x341
    [11642.274479]  [<ffffffff8106483e>] process_one_work+0x256/0x48b
    [11642.275497]  [<ffffffff81064f20>] worker_thread+0x1f5/0x2a7
    [11642.276518]  [<ffffffff81064d2b>] ? rescuer_thread+0x289/0x289
    [11642.277520]  [<ffffffff81064d2b>] ? rescuer_thread+0x289/0x289
    [11642.278517]  [<ffffffff8106a500>] kthread+0xd4/0xdc
    [11642.279371]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.280468]  [<ffffffff8147fdef>] ret_from_fork+0x3f/0x70
    [11642.281607]  [<ffffffff8106a42c>] ? kthread_parkme+0x24/0x24
    [11642.282604] 3 locks held by kworker/u32:8/15289:
    [11642.283423]  #0:  ("writeback"){++++.+}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.285629]  #1:  ((&(&wb->dwork)->work)){+.+.+.}, at: [<ffffffff8106474d>] process_one_work+0x165/0x48b
    [11642.287538]  #2:  (&type->s_umount_key#37){+++++.}, at: [<ffffffff81171217>] trylock_super+0x1b/0x4b
    [11642.289423] INFO: task fdm-stress:26848 blocked for more than 120 seconds.
    [11642.290547]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.291453] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.292864] fdm-stress      D ffff88022c107c20     0 26848  26591 0x00000000
    [11642.294118]  ffff88022c107c20 000000038108affa 0000000000014ec0 ffff88023ed54ec0
    [11642.295602]  ffff88013ab1ca40 ffff88022c108000 ffff8800b2fc19d0 00000000000e0fff
    [11642.297098]  ffff8800b2fc19b0 ffff88022c107c88 ffff88022c107c38 ffffffff8147b541
    [11642.298433] Call Trace:
    [11642.298896]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.299738]  [<ffffffffa045225d>] lock_extent_bits+0xfe/0x1a3 [btrfs]
    [11642.300833]  [<ffffffff81082eef>] ? add_wait_queue_exclusive+0x44/0x44
    [11642.301943]  [<ffffffffa0447516>] lock_and_cleanup_extent_if_need+0x68/0x18e [btrfs]
    [11642.303270]  [<ffffffffa04485ba>] __btrfs_buffered_write+0x238/0x4c1 [btrfs]
    [11642.304552]  [<ffffffffa044b50a>] ? btrfs_file_write_iter+0x17c/0x408 [btrfs]
    [11642.305782]  [<ffffffffa044b682>] btrfs_file_write_iter+0x2f4/0x408 [btrfs]
    [11642.306878]  [<ffffffff8116e298>] __vfs_write+0x7c/0xa5
    [11642.307729]  [<ffffffff8116e7d1>] vfs_write+0x9d/0xe8
    [11642.308602]  [<ffffffff8116efbb>] SyS_write+0x50/0x7e
    [11642.309410]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.310403] 3 locks held by fdm-stress/26848:
    [11642.311108]  #0:  (&f->f_pos_lock){+.+.+.}, at: [<ffffffff811877e8>] __fdget_pos+0x3a/0x40
    [11642.312578]  #1:  (sb_writers#11){.+.+.+}, at: [<ffffffff811706ee>] __sb_start_write+0x5f/0xb0
    [11642.314170]  #2:  (&sb->s_type->i_mutex_key#15){+.+.+.}, at: [<ffffffffa044b401>] btrfs_file_write_iter+0x73/0x408 [btrfs]
    [11642.316796] INFO: task fdm-stress:26849 blocked for more than 120 seconds.
    [11642.317842]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.318691] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.319959] fdm-stress      D ffff8801964ffa68     0 26849  26591 0x00000000
    [11642.321312]  ffff8801964ffa68 00ff8801e9975f80 0000000000014ec0 ffff88023ed94ec0
    [11642.322555]  ffff8800b00b4840 ffff880196500000 ffff8801e9975f20 0000000000000002
    [11642.323715]  ffff8801e9975f18 ffff8800b00b4840 ffff8801964ffa80 ffffffff8147b541
    [11642.325096] Call Trace:
    [11642.325532]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.326303]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.327180]  [<ffffffff8108ae40>] ? mark_held_locks+0x5e/0x74
    [11642.328114]  [<ffffffff8147f30e>] ? _raw_spin_unlock_irq+0x2c/0x4a
    [11642.329051]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.330053]  [<ffffffff8147bceb>] __wait_for_common+0x109/0x147
    [11642.330952]  [<ffffffff8147bceb>] ? __wait_for_common+0x109/0x147
    [11642.331869]  [<ffffffff8147e7bb>] ? usleep_range+0x4a/0x4a
    [11642.332925]  [<ffffffff81074075>] ? wake_up_q+0x47/0x47
    [11642.333736]  [<ffffffff8147bd4d>] wait_for_completion+0x24/0x26
    [11642.334672]  [<ffffffffa044f5ce>] btrfs_wait_ordered_extents+0x1c8/0x217 [btrfs]
    [11642.335858]  [<ffffffffa0465b5a>] btrfs_mksubvol+0x224/0x45d [btrfs]
    [11642.336854]  [<ffffffff81082eef>] ? add_wait_queue_exclusive+0x44/0x44
    [11642.337820]  [<ffffffffa0465edb>] btrfs_ioctl_snap_create_transid+0x148/0x17a [btrfs]
    [11642.339026]  [<ffffffffa046603b>] btrfs_ioctl_snap_create_v2+0xc7/0x110 [btrfs]
    [11642.340214]  [<ffffffffa0468582>] btrfs_ioctl+0x590/0x27bd [btrfs]
    [11642.341123]  [<ffffffff8147dc00>] ? mutex_unlock+0xe/0x10
    [11642.341934]  [<ffffffffa00fa6e9>] ? ext4_file_write_iter+0x2a3/0x36f [ext4]
    [11642.342936]  [<ffffffff8108895d>] ? __lock_is_held+0x3c/0x57
    [11642.343772]  [<ffffffff81186a1d>] ? rcu_read_unlock+0x3e/0x5d
    [11642.344673]  [<ffffffff8117dc95>] do_vfs_ioctl+0x458/0x4dc
    [11642.346024]  [<ffffffff81186bbe>] ? __fget_light+0x62/0x71
    [11642.346873]  [<ffffffff8117dd70>] SyS_ioctl+0x57/0x79
    [11642.347720]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.350222] 4 locks held by fdm-stress/26849:
    [11642.350898]  #0:  (sb_writers#11){.+.+.+}, at: [<ffffffff811706ee>] __sb_start_write+0x5f/0xb0
    [11642.352375]  #1:  (&type->i_mutex_dir_key#4/1){+.+.+.}, at: [<ffffffffa0465981>] btrfs_mksubvol+0x4b/0x45d [btrfs]
    [11642.354072]  #2:  (&fs_info->subvol_sem){++++..}, at: [<ffffffffa0465a2a>] btrfs_mksubvol+0xf4/0x45d [btrfs]
    [11642.355647]  #3:  (&root->ordered_extent_mutex){+.+...}, at: [<ffffffffa044f456>] btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.357516] INFO: task fdm-stress:26850 blocked for more than 120 seconds.
    [11642.358508]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.359376] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.368625] fdm-stress      D ffff88021f167688     0 26850  26591 0x00000000
    [11642.369716]  ffff88021f167688 0000000000000001 0000000000014ec0 ffff88023edd4ec0
    [11642.370950]  ffff880128a98680 ffff88021f168000 ffff88023edd4ec0 7fffffffffffffff
    [11642.372210]  0000000000000002 ffffffff8147b7f9 ffff88021f1676a0 ffffffff8147b541
    [11642.373430] Call Trace:
    [11642.373853]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.374623]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.375948]  [<ffffffff8147e7fe>] schedule_timeout+0x43/0x109
    [11642.376862]  [<ffffffff8147b7f9>] ? bit_wait+0x2f/0x2f
    [11642.377637]  [<ffffffff8108afd1>] ? trace_hardirqs_on_caller+0x17b/0x197
    [11642.378610]  [<ffffffff8108affa>] ? trace_hardirqs_on+0xd/0xf
    [11642.379457]  [<ffffffff810b079b>] ? timekeeping_get_ns+0xe/0x33
    [11642.380366]  [<ffffffff810b0f61>] ? ktime_get+0x41/0x52
    [11642.381353]  [<ffffffff8147ac08>] io_schedule_timeout+0xa0/0x102
    [11642.382255]  [<ffffffff8147ac08>] ? io_schedule_timeout+0xa0/0x102
    [11642.383162]  [<ffffffff8147b814>] bit_wait_io+0x1b/0x39
    [11642.383945]  [<ffffffff8147bb21>] __wait_on_bit_lock+0x4c/0x90
    [11642.384875]  [<ffffffff8111829f>] __lock_page+0x66/0x68
    [11642.385749]  [<ffffffff81082f29>] ? autoremove_wake_function+0x3a/0x3a
    [11642.386721]  [<ffffffffa0450ddd>] lock_page+0x31/0x34 [btrfs]
    [11642.387596]  [<ffffffffa0454e3b>] extent_write_cache_pages.isra.19.constprop.35+0x1af/0x2f4 [btrfs]
    [11642.389030]  [<ffffffffa0455373>] extent_writepages+0x4b/0x5c [btrfs]
    [11642.389973]  [<ffffffff810a25ad>] ? rcu_read_lock_sched_held+0x61/0x69
    [11642.390939]  [<ffffffffa043c913>] ? btrfs_writepage_start_hook+0xce/0xce [btrfs]
    [11642.392271]  [<ffffffffa0451c32>] ? __clear_extent_bit+0x26e/0x2c0 [btrfs]
    [11642.393305]  [<ffffffffa043aa82>] btrfs_writepages+0x28/0x2a [btrfs]
    [11642.394239]  [<ffffffff811236bc>] do_writepages+0x23/0x2c
    [11642.395045]  [<ffffffff811198c9>] __filemap_fdatawrite_range+0x5a/0x61
    [11642.395991]  [<ffffffff81119946>] filemap_fdatawrite_range+0x13/0x15
    [11642.397144]  [<ffffffffa044f87e>] btrfs_start_ordered_extent+0xd0/0x1a1 [btrfs]
    [11642.398392]  [<ffffffffa0452094>] ? clear_extent_bit+0x17/0x19 [btrfs]
    [11642.399363]  [<ffffffffa0445945>] btrfs_get_blocks_direct+0x12b/0x61c [btrfs]
    [11642.400445]  [<ffffffff8119f7a1>] ? dio_bio_add_page+0x3d/0x54
    [11642.401309]  [<ffffffff8119fa93>] ? submit_page_section+0x7b/0x111
    [11642.402213]  [<ffffffff811a0258>] do_blockdev_direct_IO+0x685/0xc24
    [11642.403139]  [<ffffffffa044581a>] ? btrfs_page_exists_in_range+0x1a1/0x1a1 [btrfs]
    [11642.404360]  [<ffffffffa043d267>] ? btrfs_get_extent_fiemap+0x1c0/0x1c0 [btrfs]
    [11642.406187]  [<ffffffff811a0828>] __blockdev_direct_IO+0x31/0x33
    [11642.407070]  [<ffffffff811a0828>] ? __blockdev_direct_IO+0x31/0x33
    [11642.407990]  [<ffffffffa043d267>] ? btrfs_get_extent_fiemap+0x1c0/0x1c0 [btrfs]
    [11642.409192]  [<ffffffffa043b4ca>] btrfs_direct_IO+0x1c7/0x27e [btrfs]
    [11642.410146]  [<ffffffffa043d267>] ? btrfs_get_extent_fiemap+0x1c0/0x1c0 [btrfs]
    [11642.411291]  [<ffffffff81119a2c>] generic_file_read_iter+0x89/0x4e1
    [11642.412263]  [<ffffffff8108ac05>] ? mark_lock+0x24/0x201
    [11642.413057]  [<ffffffff8116e1f8>] __vfs_read+0x79/0x9d
    [11642.413897]  [<ffffffff8116e6f1>] vfs_read+0x8f/0xd2
    [11642.414708]  [<ffffffff8116ef3d>] SyS_read+0x50/0x7e
    [11642.415573]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.416572] 1 lock held by fdm-stress/26850:
    [11642.417345]  #0:  (&f->f_pos_lock){+.+.+.}, at: [<ffffffff811877e8>] __fdget_pos+0x3a/0x40
    [11642.418703] INFO: task fdm-stress:26851 blocked for more than 120 seconds.
    [11642.419698]       Not tainted 4.4.0-rc6-btrfs-next-21+ #1
    [11642.420612] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [11642.421807] fdm-stress      D ffff880196483d28     0 26851  26591 0x00000000
    [11642.422878]  ffff880196483d28 00ff8801c8f60740 0000000000014ec0 ffff88023ed94ec0
    [11642.424149]  ffff8801c8f60740 ffff880196484000 0000000000000246 ffff8801c8f60740
    [11642.425374]  ffff8801bb711840 ffff8801bb711878 ffff880196483d40 ffffffff8147b541
    [11642.426591] Call Trace:
    [11642.427013]  [<ffffffff8147b541>] schedule+0x82/0x9a
    [11642.427856]  [<ffffffff8147b6d5>] schedule_preempt_disabled+0x18/0x24
    [11642.428852]  [<ffffffff8147c23a>] mutex_lock_nested+0x1d7/0x3b4
    [11642.429743]  [<ffffffffa044f456>] ? btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.430911]  [<ffffffffa044f456>] btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.432102]  [<ffffffffa044f674>] ? btrfs_wait_ordered_roots+0x57/0x191 [btrfs]
    [11642.433259]  [<ffffffffa044f456>] ? btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    [11642.434431]  [<ffffffffa044f6ea>] btrfs_wait_ordered_roots+0xcd/0x191 [btrfs]
    [11642.436079]  [<ffffffffa0410cab>] btrfs_sync_fs+0xe0/0x1ad [btrfs]
    [11642.437009]  [<ffffffff81197900>] ? SyS_tee+0x23c/0x23c
    [11642.437860]  [<ffffffff81197920>] sync_fs_one_sb+0x20/0x22
    [11642.438723]  [<ffffffff81171435>] iterate_supers+0x75/0xc2
    [11642.439597]  [<ffffffff81197d00>] sys_sync+0x52/0x80
    [11642.440454]  [<ffffffff8147fa97>] entry_SYSCALL_64_fastpath+0x12/0x6b
    [11642.441533] 3 locks held by fdm-stress/26851:
    [11642.442370]  #0:  (&type->s_umount_key#37){+++++.}, at: [<ffffffff8117141f>] iterate_supers+0x5f/0xc2
    [11642.444043]  #1:  (&fs_info->ordered_operations_mutex){+.+...}, at: [<ffffffffa044f661>] btrfs_wait_ordered_roots+0x44/0x191 [btrfs]
    [11642.446010]  #2:  (&root->ordered_extent_mutex){+.+...}, at: [<ffffffffa044f456>] btrfs_wait_ordered_extents+0x50/0x217 [btrfs]
    
    This happened because under specific timings the path for direct IO reads
    can deadlock with concurrent buffered writes. The diagram below shows how
    this happens for an example file that has the following layout:
    
         [  extent A  ]  [  extent B  ]  [ ....
         0K              4K              8K
    
         CPU 1                                               CPU 2                             CPU 3
    
    DIO read against range
     [0K, 8K[ starts
    
    btrfs_direct_IO()
      --> calls btrfs_get_blocks_direct()
          which finds the extent map for the
          extent A and leaves the range
          [0K, 4K[ locked in the inode's
          io tree
    
                                                       buffered write against
                                                       range [4K, 8K[ starts
    
                                                       __btrfs_buffered_write()
                                                         --> dirties page at 4K
    
                                                                                         a user space
                                                                                         task calls sync
                                                                                         for e.g or
                                                                                         writepages() is
                                                                                         invoked by mm
    
                                                                                         writepages()
                                                                                           run_delalloc_range()
                                                                                             cow_file_range()
                                                                                               --> ordered extent X
                                                                                                   for the buffered
                                                                                                   write is created
                                                                                                   and
                                                                                                   writeback starts
    
      --> calls btrfs_get_blocks_direct()
          again, without submitting first
          a bio for reading extent A, and
          finds the extent map for extent B
    
      --> calls lock_extent_direct()
    
          --> locks range [4K, 8K[
          --> finds ordered extent X
              covering range [4K, 8K[
          --> unlocks range [4K, 8K[
    
                                                      buffered write against
                                                      range [0K, 8K[ starts
    
                                                      __btrfs_buffered_write()
                                                        prepare_pages()
                                                          --> locks pages with
                                                              offsets 0 and 4K
                                                        lock_and_cleanup_extent_if_need()
                                                          --> blocks attempting to
                                                              lock range [0K, 8K[ in
                                                              the inode's io tree,
                                                              because the range [0, 4K[
                                                              is already locked by the
                                                              direct IO task at CPU 1
    
          --> calls
              btrfs_start_ordered_extent(oe X)
    
              btrfs_start_ordered_extent(oe X)
    
                --> At this point writeback for ordered
                    extent X has not finished yet
    
                filemap_fdatawrite_range()
                  btrfs_writepages()
                    extent_writepages()
                      extent_write_cache_pages()
                        --> finds page with offset 0
                            with the writeback tag
                            (and not dirty)
                        --> tries to lock it
                             --> deadlock, task at CPU 2
                                 has the page locked and
                                 is blocked on the io range
                                 [0, 4K[ that was locked
                                 earlier by this task
    
    So fix this by falling back to a buffered read in the direct IO read path
    when an ordered extent for a buffered write is found.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Reviewed-by: Liu Bo <bo.li.liu@oracle.com>
    Signed-off-by: Chris Mason <clm@fb.com>

commit 79179a68458a7fddcf35adb16d1f7a7880aa41e7
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    [ Upstream commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e ]
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Sasha Levin <sasha.levin@oracle.com>

commit e8eced78e0252040c4e6bb633b40afb11a176416
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e upstream.
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit df567e6dcd22097d2f31b6a8bf481959f1352b6a
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 27 10:20:58 2016 +0000

    Btrfs: fix invalid page accesses in extent_same (dedup) ioctl
    
    commit e0bd70c67bf996b360f706b6c643000f2e384681 upstream.
    
    In the extent_same ioctl we are getting the pages for the source and
    target ranges and unlocking them immediately after, which is incorrect
    because later we attempt to map them (with kmap_atomic) and access their
    contents at btrfs_cmp_data(). When we do such access the pages might have
    been relocated or removed from memory, which leads to an invalid memory
    access. This issue is detected on a kernel with CONFIG_DEBUG_PAGEALLOC=y
    which produces a trace like the following:
    
    186736.677437] general protection fault: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [186736.680382] Modules linked in: btrfs dm_flakey dm_mod ppdev xor raid6_pq sha256_generic hmac drbg ansi_cprng acpi_cpufreq evdev sg aesni_intel aes_x86_64
    parport_pc ablk_helper tpm_tis psmouse parport i2c_piix4 tpm cryptd i2c_core lrw processor button serio_raw pcspkr gf128mul glue_helper loop autofs4 ext4
    crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last
    unloaded: btrfs]
    [186736.681319] CPU: 13 PID: 10222 Comm: duperemove Tainted: G        W       4.4.0-rc6-btrfs-next-18+ #1
    [186736.681319] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [186736.681319] task: ffff880132600400 ti: ffff880362284000 task.ti: ffff880362284000
    [186736.681319] RIP: 0010:[<ffffffff81264d00>]  [<ffffffff81264d00>] memcmp+0xb/0x22
    [186736.681319] RSP: 0018:ffff880362287d70  EFLAGS: 00010287
    [186736.681319] RAX: 000002c002468acf RBX: 0000000012345678 RCX: 0000000000000000
    [186736.681319] RDX: 0000000000001000 RSI: 0005d129c5cf9000 RDI: 0005d129c5cf9000
    [186736.681319] RBP: ffff880362287d70 R08: 0000000000000000 R09: 0000000000001000
    [186736.681319] R10: ffff880000000000 R11: 0000000000000476 R12: 0000000000001000
    [186736.681319] R13: ffff8802f91d4c88 R14: ffff8801f2a77830 R15: ffff880352e83e40
    [186736.681319] FS:  00007f27b37fe700(0000) GS:ffff88043dda0000(0000) knlGS:0000000000000000
    [186736.681319] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [186736.681319] CR2: 00007f27a406a000 CR3: 0000000217421000 CR4: 00000000001406e0
    [186736.681319] Stack:
    [186736.681319]  ffff880362287ea0 ffffffffa048d0bd 000000000009f000 0000000000001000
    [186736.681319]  0100000000000000 ffff8801f2a77850 ffff8802f91d49b0 ffff880132600400
    [186736.681319]  00000000000004f8 ffff8801c1efbe41 0000000000000000 0000000000000038
    [186736.681319] Call Trace:
    [186736.681319]  [<ffffffffa048d0bd>] btrfs_ioctl+0x24cb/0x2731 [btrfs]
    [186736.681319]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [186736.681319]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [186736.681319]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [186736.681319]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [186736.681319]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [186736.681319]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [186736.681319] Code: 0a 3c 6e 74 0d 3c 79 74 04 3c 59 75 0c c6 06 01 eb 03 c6 06 00 31 c0 eb 05 b8 ea ff ff ff 5d c3 55 31 c9 48 89 e5 48 39 d1 74 13 <0f> b6
    04 0f 44 0f b6 04 0e 48 ff c1 44 29 c0 74 ea eb 02 31 c0
    
    (gdb) list *(btrfs_ioctl+0x24cb)
    0x5e0e1 is in btrfs_ioctl (fs/btrfs/ioctl.c:2972).
    2967                    dst_addr = kmap_atomic(dst_page);
    2968
    2969                    flush_dcache_page(src_page);
    2970                    flush_dcache_page(dst_page);
    2971
    2972                    if (memcmp(addr, dst_addr, cmp_len))
    2973                            ret = BTRFS_SAME_DATA_DIFFERS;
    2974
    2975                    kunmap_atomic(addr);
    2976                    kunmap_atomic(dst_addr);
    
    So fix this by making sure we keep the pages locked and respect the same
    locking order as everywhere else: get and lock the pages first and then
    lock the range in the inode's io tree (like for example at
    __btrfs_buffered_write() and extent_readpages()). If an ordered extent
    is found after locking the range in the io tree, unlock the range,
    unlock the pages, wait for the ordered extent to complete and repeat the
    entire locking process until no overlapping ordered extents are found.
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5d5b6db240e5689761a92e294c0a18b1afff20d1
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e upstream.
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 590a2f0b8c5d10279bf8cb6d07ca426e6086b349
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e upstream.
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b10a62d6c00ee83c2614fda9e8d8e7178ef53020
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e upstream.
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Luis Henriques <luis.henriques@canonical.com>

commit 2c0d636da649546fde114db32cd70b7f56e8d11b
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e upstream.
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Signed-off-by: Filipe Manana <fdmanana@suse.com>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit 042d4460b5b4379a12f375045ff9065cf6758735
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Tue Dec 22 17:25:17 2015 +0200

    stm class: Select CONFIG_SRCU
    
    The newly added STM code uses SRCU, but does not ensure that
    this code is part of the kernel:
    
    drivers/built-in.o: In function `stm_source_link_show':
    include/linux/srcu.h:221: undefined reference to `__srcu_read_lock'
    include/linux/srcu.h:238: undefined reference to `__srcu_read_unlock'
    drivers/built-in.o: In function `stm_source_link_drop':
    include/linux/srcu.h:221: undefined reference to `__srcu_read_lock'
    include/linux/srcu.h:238: undefined reference to `__srcu_read_unlock'
    
    This adds a Kconfig 'select' statement like all the other SRCU using
    drivers have.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Fixes: 7bd1d4093c2f ("stm class: Introduce an abstraction for System Trace Module devices")
    Signed-off-by: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c0fe3b0fa45082cd752553fdb3a4b42503a118e
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Feb 3 19:17:27 2016 +0000

    Btrfs: fix hang on extent buffer lock caused by the inode_paths ioctl
    
    While doing some tests I ran into an hang on an extent buffer's rwlock
    that produced the following trace:
    
    [39389.800012] NMI watchdog: BUG: soft lockup - CPU#15 stuck for 22s! [fdm-stress:32166]
    [39389.800016] NMI watchdog: BUG: soft lockup - CPU#14 stuck for 22s! [fdm-stress:32165]
    [39389.800016] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800016] irq event stamp: 0
    [39389.800016] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800016] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800016] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800016] CPU: 14 PID: 32165 Comm: fdm-stress Not tainted 4.4.0-rc6-btrfs-next-18+ #1
    [39389.800016] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800016] task: ffff880175b1ca40 ti: ffff8800a185c000 task.ti: ffff8800a185c000
    [39389.800016] RIP: 0010:[<ffffffff810902af>]  [<ffffffff810902af>] queued_spin_lock_slowpath+0x57/0x158
    [39389.800016] RSP: 0018:ffff8800a185fb80  EFLAGS: 00000202
    [39389.800016] RAX: 0000000000000101 RBX: ffff8801710c4e9c RCX: 0000000000000101
    [39389.800016] RDX: 0000000000000100 RSI: 0000000000000001 RDI: 0000000000000001
    [39389.800016] RBP: ffff8800a185fb98 R08: 0000000000000001 R09: 0000000000000000
    [39389.800016] R10: ffff8800a185fb68 R11: 6db6db6db6db6db7 R12: ffff8801710c4e98
    [39389.800016] R13: ffff880175b1ca40 R14: ffff8800a185fc10 R15: ffff880175b1ca40
    [39389.800016] FS:  00007f6d37fff700(0000) GS:ffff8802be9c0000(0000) knlGS:0000000000000000
    [39389.800016] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800016] CR2: 00007f6d300019b8 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800016] Stack:
    [39389.800016]  ffff8801710c4e98 ffff8801710c4e98 ffff880175b1ca40 ffff8800a185fbb0
    [39389.800016]  ffffffff81091e11 ffff8801710c4e98 ffff8800a185fbc8 ffffffff81091895
    [39389.800016]  ffff8801710c4e98 ffff8800a185fbe8 ffffffff81486c5c ffffffffa067288c
    [39389.800016] Call Trace:
    [39389.800016]  [<ffffffff81091e11>] queued_read_lock_slowpath+0x46/0x60
    [39389.800016]  [<ffffffff81091895>] do_raw_read_lock+0x3e/0x41
    [39389.800016]  [<ffffffff81486c5c>] _raw_read_lock+0x3d/0x44
    [39389.800016]  [<ffffffffa067288c>] ? btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa067288c>] btrfs_tree_read_lock+0x54/0x125 [btrfs]
    [39389.800016]  [<ffffffffa0622ced>] ? btrfs_find_item+0xa7/0xd2 [btrfs]
    [39389.800016]  [<ffffffffa069363f>] btrfs_ref_to_path+0xd6/0x174 [btrfs]
    [39389.800016]  [<ffffffffa0693730>] inode_to_path+0x53/0xa2 [btrfs]
    [39389.800016]  [<ffffffffa0693e2e>] paths_from_inode+0x117/0x2ec [btrfs]
    [39389.800016]  [<ffffffffa0670cff>] btrfs_ioctl+0xd5b/0x2793 [btrfs]
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff81276727>] ? __this_cpu_preempt_check+0x13/0x15
    [39389.800016]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800016]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800016]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800016]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800016]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800016]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800016] Code: b9 01 01 00 00 f7 c6 00 ff ff ff 75 32 83 fe 01 89 ca 89 f0 0f 45 d7 f0 0f b1 13 39 f0 74 04 89 c6 eb e2 ff ca 0f 84 fa 00 00 00 <8b> 03 84 c0 74 04 f3 90 eb f6 66 c7 03 01 00 e9 e6 00 00 00 e8
    [39389.800012] Modules linked in: btrfs dm_mod ppdev xor sha256_generic hmac raid6_pq drbg ansi_cprng aesni_intel i2c_piix4 acpi_cpufreq aes_x86_64 ablk_helper tpm_tis parport_pc i2c_core sg cryptd evdev psmouse lrw tpm parport gf128mul serio_raw pcspkr glue_helper processor button loop autofs4 ext4 crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last unloaded: btrfs]
    [39389.800012] irq event stamp: 0
    [39389.800012] hardirqs last  enabled at (0): [<          (null)>]           (null)
    [39389.800012] hardirqs last disabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last  enabled at (0): [<ffffffff8104e58d>] copy_process+0x638/0x1a35
    [39389.800012] softirqs last disabled at (0): [<          (null)>]           (null)
    [39389.800012] CPU: 15 PID: 32166 Comm: fdm-stress Tainted: G             L  4.4.0-rc6-btrfs-next-18+ #1
    [39389.800012] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [39389.800012] task: ffff880179294380 ti: ffff880034a60000 task.ti: ffff880034a60000
    [39389.800012] RIP: 0010:[<ffffffff81091e8d>]  [<ffffffff81091e8d>] queued_write_lock_slowpath+0x62/0x72
    [39389.800012] RSP: 0018:ffff880034a639f0  EFLAGS: 00000206
    [39389.800012] RAX: 0000000000000101 RBX: ffff8801710c4e98 RCX: 0000000000000000
    [39389.800012] RDX: 00000000000000ff RSI: 0000000000000000 RDI: ffff8801710c4e9c
    [39389.800012] RBP: ffff880034a639f8 R08: 0000000000000001 R09: 0000000000000000
    [39389.800012] R10: ffff880034a639b0 R11: 0000000000001000 R12: ffff8801710c4e98
    [39389.800012] R13: 0000000000000001 R14: ffff880172cbc000 R15: ffff8801710c4e00
    [39389.800012] FS:  00007f6d377fe700(0000) GS:ffff8802be9e0000(0000) knlGS:0000000000000000
    [39389.800012] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [39389.800012] CR2: 00007f6d3d3c1000 CR3: 0000000037c93000 CR4: 00000000001406e0
    [39389.800012] Stack:
    [39389.800012]  ffff8801710c4e98 ffff880034a63a10 ffffffff81091963 ffff8801710c4e98
    [39389.800012]  ffff880034a63a30 ffffffff81486f1b ffffffffa0672cb3 ffff8801710c4e00
    [39389.800012]  ffff880034a63a78 ffffffffa0672cb3 ffff8801710c4e00 ffff880034a63a58
    [39389.800012] Call Trace:
    [39389.800012]  [<ffffffff81091963>] do_raw_write_lock+0x72/0x8c
    [39389.800012]  [<ffffffff81486f1b>] _raw_write_lock+0x3a/0x41
    [39389.800012]  [<ffffffffa0672cb3>] ? btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa0672cb3>] btrfs_tree_lock+0x119/0x251 [btrfs]
    [39389.800012]  [<ffffffffa061aeba>] ? rcu_read_unlock+0x5b/0x5d [btrfs]
    [39389.800012]  [<ffffffffa061ce13>] ? btrfs_root_node+0xda/0xe6 [btrfs]
    [39389.800012]  [<ffffffffa061ce83>] btrfs_lock_root_node+0x22/0x42 [btrfs]
    [39389.800012]  [<ffffffffa062046b>] btrfs_search_slot+0x1b8/0x758 [btrfs]
    [39389.800012]  [<ffffffff810fc6b0>] ? time_hardirqs_on+0x15/0x28
    [39389.800012]  [<ffffffffa06365db>] btrfs_lookup_inode+0x31/0x95 [btrfs]
    [39389.800012]  [<ffffffff8108d62f>] ? trace_hardirqs_on+0xd/0xf
    [39389.800012]  [<ffffffff8148482b>] ? mutex_lock_nested+0x397/0x3bc
    [39389.800012]  [<ffffffffa068821b>] __btrfs_update_delayed_inode+0x59/0x1c0 [btrfs]
    [39389.800012]  [<ffffffffa068858e>] __btrfs_commit_inode_delayed_items+0x194/0x5aa [btrfs]
    [39389.800012]  [<ffffffff81486ab7>] ? _raw_spin_unlock+0x31/0x44
    [39389.800012]  [<ffffffffa0688a48>] __btrfs_run_delayed_items+0xa4/0x15c [btrfs]
    [39389.800012]  [<ffffffffa0688d62>] btrfs_run_delayed_items+0x11/0x13 [btrfs]
    [39389.800012]  [<ffffffffa064048e>] btrfs_commit_transaction+0x234/0x96e [btrfs]
    [39389.800012]  [<ffffffffa0618d10>] btrfs_sync_fs+0x145/0x1ad [btrfs]
    [39389.800012]  [<ffffffffa0671176>] btrfs_ioctl+0x11d2/0x2793 [btrfs]
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff81140261>] ? __might_fault+0x4c/0xa7
    [39389.800012]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [39389.800012]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [39389.800012]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [39389.800012]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [39389.800012]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [39389.800012]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [39389.800012] Code: f0 0f b1 13 85 c0 75 ef eb 2a f3 90 8a 03 84 c0 75 f8 f0 0f b0 13 84 c0 75 f0 ba ff 00 00 00 eb 0a f0 0f b1 13 ff c8 74 0b f3 90 <8b> 03 83 f8 01 75 f7 eb ed c6 43 04 00 5b 5d c3 0f 1f 44 00 00
    
    This happens because in the code path executed by the inode_paths ioctl we
    end up nesting two calls to read lock a leaf's rwlock when after the first
    call to read_lock() and before the second call to read_lock(), another
    task (running the delayed items as part of a transaction commit) has
    already called write_lock() against the leaf's rwlock. This situation is
    illustrated by the following diagram:
    
             Task A                       Task B
    
      btrfs_ref_to_path()               btrfs_commit_transaction()
        read_lock(&eb->lock);
    
                                          btrfs_run_delayed_items()
                                            __btrfs_commit_inode_delayed_items()
                                              __btrfs_update_delayed_inode()
                                                btrfs_lookup_inode()
    
                                                  write_lock(&eb->lock);
                                                    --> task waits for lock
    
        read_lock(&eb->lock);
        --> makes this task hang
            forever (and task B too
            of course)
    
    So fix this by avoiding doing the nested read lock, which is easily
    avoidable. This issue does not happen if task B calls write_lock() after
    task A does the second call to read_lock(), however there does not seem
    to exist anything in the documentation that mentions what is the expected
    behaviour for recursive locking of rwlocks (leaving the idea that doing
    so is not a good usage of rwlocks).
    
    Also, as a side effect necessary for this fix, make sure we do not
    needlessly read lock extent buffers when the input path has skip_locking
    set (used when called from send).
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

commit e0bd70c67bf996b360f706b6c643000f2e384681
Author: Filipe Manana <fdmanana@suse.com>
Date:   Wed Jan 27 10:20:58 2016 +0000

    Btrfs: fix invalid page accesses in extent_same (dedup) ioctl
    
    In the extent_same ioctl we are getting the pages for the source and
    target ranges and unlocking them immediately after, which is incorrect
    because later we attempt to map them (with kmap_atomic) and access their
    contents at btrfs_cmp_data(). When we do such access the pages might have
    been relocated or removed from memory, which leads to an invalid memory
    access. This issue is detected on a kernel with CONFIG_DEBUG_PAGEALLOC=y
    which produces a trace like the following:
    
    186736.677437] general protection fault: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC
    [186736.680382] Modules linked in: btrfs dm_flakey dm_mod ppdev xor raid6_pq sha256_generic hmac drbg ansi_cprng acpi_cpufreq evdev sg aesni_intel aes_x86_64
    parport_pc ablk_helper tpm_tis psmouse parport i2c_piix4 tpm cryptd i2c_core lrw processor button serio_raw pcspkr gf128mul glue_helper loop autofs4 ext4
    crc16 mbcache jbd2 sd_mod sr_mod cdrom ata_generic virtio_scsi ata_piix libata virtio_pci virtio_ring crc32c_intel scsi_mod e1000 virtio floppy [last
    unloaded: btrfs]
    [186736.681319] CPU: 13 PID: 10222 Comm: duperemove Tainted: G        W       4.4.0-rc6-btrfs-next-18+ #1
    [186736.681319] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS by qemu-project.org 04/01/2014
    [186736.681319] task: ffff880132600400 ti: ffff880362284000 task.ti: ffff880362284000
    [186736.681319] RIP: 0010:[<ffffffff81264d00>]  [<ffffffff81264d00>] memcmp+0xb/0x22
    [186736.681319] RSP: 0018:ffff880362287d70  EFLAGS: 00010287
    [186736.681319] RAX: 000002c002468acf RBX: 0000000012345678 RCX: 0000000000000000
    [186736.681319] RDX: 0000000000001000 RSI: 0005d129c5cf9000 RDI: 0005d129c5cf9000
    [186736.681319] RBP: ffff880362287d70 R08: 0000000000000000 R09: 0000000000001000
    [186736.681319] R10: ffff880000000000 R11: 0000000000000476 R12: 0000000000001000
    [186736.681319] R13: ffff8802f91d4c88 R14: ffff8801f2a77830 R15: ffff880352e83e40
    [186736.681319] FS:  00007f27b37fe700(0000) GS:ffff88043dda0000(0000) knlGS:0000000000000000
    [186736.681319] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [186736.681319] CR2: 00007f27a406a000 CR3: 0000000217421000 CR4: 00000000001406e0
    [186736.681319] Stack:
    [186736.681319]  ffff880362287ea0 ffffffffa048d0bd 000000000009f000 0000000000001000
    [186736.681319]  0100000000000000 ffff8801f2a77850 ffff8802f91d49b0 ffff880132600400
    [186736.681319]  00000000000004f8 ffff8801c1efbe41 0000000000000000 0000000000000038
    [186736.681319] Call Trace:
    [186736.681319]  [<ffffffffa048d0bd>] btrfs_ioctl+0x24cb/0x2731 [btrfs]
    [186736.681319]  [<ffffffff8108a8b0>] ? arch_local_irq_save+0x9/0xc
    [186736.681319]  [<ffffffff8118b3d4>] ? rcu_read_unlock+0x3e/0x5d
    [186736.681319]  [<ffffffff811822f8>] do_vfs_ioctl+0x42b/0x4ea
    [186736.681319]  [<ffffffff8118b4f3>] ? __fget_light+0x62/0x71
    [186736.681319]  [<ffffffff8118240e>] SyS_ioctl+0x57/0x79
    [186736.681319]  [<ffffffff814872d7>] entry_SYSCALL_64_fastpath+0x12/0x6f
    [186736.681319] Code: 0a 3c 6e 74 0d 3c 79 74 04 3c 59 75 0c c6 06 01 eb 03 c6 06 00 31 c0 eb 05 b8 ea ff ff ff 5d c3 55 31 c9 48 89 e5 48 39 d1 74 13 <0f> b6
    04 0f 44 0f b6 04 0e 48 ff c1 44 29 c0 74 ea eb 02 31 c0
    
    (gdb) list *(btrfs_ioctl+0x24cb)
    0x5e0e1 is in btrfs_ioctl (fs/btrfs/ioctl.c:2972).
    2967                    dst_addr = kmap_atomic(dst_page);
    2968
    2969                    flush_dcache_page(src_page);
    2970                    flush_dcache_page(dst_page);
    2971
    2972                    if (memcmp(addr, dst_addr, cmp_len))
    2973                            ret = BTRFS_SAME_DATA_DIFFERS;
    2974
    2975                    kunmap_atomic(addr);
    2976                    kunmap_atomic(dst_addr);
    
    So fix this by making sure we keep the pages locked and respect the same
    locking order as everywhere else: get and lock the pages first and then
    lock the range in the inode's io tree (like for example at
    __btrfs_buffered_write() and extent_readpages()). If an ordered extent
    is found after locking the range in the io tree, unlock the range,
    unlock the pages, wait for the ordered extent to complete and repeat the
    entire locking process until no overlapping ordered extents are found.
    
    Cc: stable@vger.kernel.org   # 4.2+
    Signed-off-by: Filipe Manana <fdmanana@suse.com>

commit bbfb239a106d41d793f58befdaf5c806e34ea97e
Merge: 30e4c9ad04a7 b4abf91047cf
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Jan 31 15:29:37 2016 -0800

    Merge branch 'locking-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull locking fix from Thomas Gleixner:
     "A single commit, which makes the rtmutex.wait_lock an irq safe lock.
    
      This prevents a potential deadlock which can be triggered by the rcu
      boosting code from rcu_read_unlock()"
    
    * 'locking-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      rtmutex: Make wait_lock irq safe

commit b4abf91047cf054f203dcfac97e1038388826937
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Jan 13 11:25:38 2016 +0100

    rtmutex: Make wait_lock irq safe
    
    Sasha reported a lockdep splat about a potential deadlock between RCU boosting
    rtmutex and the posix timer it_lock.
    
    CPU0                                    CPU1
    
    rtmutex_lock(&rcu->rt_mutex)
      spin_lock(&rcu->rt_mutex.wait_lock)
                                            local_irq_disable()
                                            spin_lock(&timer->it_lock)
                                            spin_lock(&rcu->mutex.wait_lock)
    --> Interrupt
        spin_lock(&timer->it_lock)
    
    This is caused by the following code sequence on CPU1
    
         rcu_read_lock()
         x = lookup();
         if (x)
            spin_lock_irqsave(&x->it_lock);
         rcu_read_unlock();
         return x;
    
    We could fix that in the posix timer code by keeping rcu read locked across
    the spinlocked and irq disabled section, but the above sequence is common and
    there is no reason not to support it.
    
    Taking rt_mutex.wait_lock irq safe prevents the deadlock.
    
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>

commit f41bb6edb46b30f79ae7fc5d714faa607758a8d5
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Dec 7 08:25:21 2015 -0800

    ipv6: sctp: fix lockdep splat in sctp_v6_get_dst()
    
    commit 69ce6487dcd364245a3d26322fc8f4ffd1e8d947 upstream.
    
    While cooking the sctp np->opt rcu fixes, I forgot to move
    one rcu_read_unlock() after the added rcu_dereference() in
    sctp_v6_get_dst()
    
    This gave lockdep warnings reported by Dave Jones.
    
    Fixes: c836a8ba9386 ("ipv6: sctp: add rcu protection around np->opt")
    Reported-by: Dave Jones <davej@codemonkey.org.uk>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 0bd0f1e6d40aa16c4d507b1fff27163a7e7711f5
Merge: a80c47daa818 ab5cdc31630c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Dec 10 14:42:22 2015 -0800

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma
    
    Pull rdma fixes from Doug Ledford:
     "Most are minor to important fixes.
    
      There is one performance enhancement that I took on the grounds that
      failing to check if other processes can run before running what's
      intended to be a background, idle-time task is a bug, even though the
      primary effect of the fix is to improve performance (and it was a very
      simple patch)"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/dledford/rdma:
      IB/mlx5: Postpone remove_keys under knowledge of coming preemption
      IB/mlx4: Use vmalloc for WR buffers when needed
      IB/mlx4: Use correct order of variables in log message
      iser-target: Remove explicit mlx4 work-around
      mlx4: Expose correct max_sge_rd limit
      IB/mad: Require CM send method for everything except ClassPortInfo
      IB/cma: Add a missing rcu_read_unlock()
      IB core: Fix ib_sg_to_pages()
      IB/srp: Fix srp_map_sg_fr()
      IB/srp: Fix indirect data buffer rkey endianness
      IB/srp: Initialize dma_length in srp_map_idb
      IB/srp: Fix possible send queue overflow
      IB/srp: Fix a memory leak
      IB/sa: Put netlink request into the request list before sending
      IB/iser: use sector_div instead of do_div
      IB/core: use RCU for uverbs id lookup
      IB/qib: Minor fixes to qib per SFF 8636
      IB/core: Fix user mode post wr corruption
      IB/qib: Fix qib_mr structure

commit d3632493c70b6a866a77264cd8cfdeb89958b906
Author: Bart Van Assche <bart.vanassche@sandisk.com>
Date:   Fri Nov 20 11:04:12 2015 -0800

    IB/cma: Add a missing rcu_read_unlock()
    
    Ensure that validate_ipv4_net_dev() calls rcu_read_unlock() if
    fib_lookup() fails. Detected by sparse. Compile-tested only.
    
    Fixes: "IB/cma: Validate routing of incoming requests" (commit f887f2ac87c2).
    Cc: Haggai Eran <haggaie@mellanox.com>
    Cc: stable <stable@vger.kernel.org>
    Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
    Reviewed-by: Haggai Eran <haggaie@mellanox.com>
    Reviewed-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit 69ce6487dcd364245a3d26322fc8f4ffd1e8d947
Author: Eric Dumazet <edumazet@google.com>
Date:   Mon Dec 7 08:25:21 2015 -0800

    ipv6: sctp: fix lockdep splat in sctp_v6_get_dst()
    
    While cooking the sctp np->opt rcu fixes, I forgot to move
    one rcu_read_unlock() after the added rcu_dereference() in
    sctp_v6_get_dst()
    
    This gave lockdep warnings reported by Dave Jones.
    
    Fixes: c836a8ba9386 ("ipv6: sctp: add rcu protection around np->opt")
    Reported-by: Dave Jones <davej@codemonkey.org.uk>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit d144da8c6f51f48ec39d891ea9dff80169c45f3b
Author: Mike Marciniszyn <mike.marciniszyn@intel.com>
Date:   Mon Nov 2 12:13:25 2015 -0500

    IB/core: use RCU for uverbs id lookup
    
    The current implementation gets a spin_lock, and at any scale with
    qib and hfi1 post send, the lock contention grows exponentially
    with the number of QPs.
    
    idr_find() is RCU compatibile, so read doesn't need the lock.
    
    Change to use rcu_read_lock() and rcu_read_unlock() in
    __idr_get_uobj().
    
    kfree_rcu() is used to insure a grace period between the
    idr removal and actual free.
    
    Reviewed-by: Ira Weiny <ira.weiny@intel.com>
    Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
    Reviewed-By: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit c64c4b0f9a183e4c73abff848378afa6edf796c5
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Nov 6 23:05:32 2015 -0800

    documentation: Update RCU requirements based on expedited changes
    
    Because RCU-sched expedited grace periods now use IPIs and interact
    with rcu_read_unlock(), it is no longer sufficient to disable preemption
    across RCU read-side critical sections that acquire and hold scheduler
    locks.  It is now necessary to instead disable interrupts.  This commit
    documents this change.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 8ba9153b2c3ab733d64e22adb57820ccb6afc496
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Sep 29 07:55:41 2015 -0700

    rcu: Remove lock-acquisition loop from rcu_read_unlock_special()
    
    Several releases have come and gone without the warning triggering,
    so remove the lock-acquisition loop.  Retain the WARN_ON_ONCE()
    out of sheer paranoia.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 2fd59077755c44dbbd9b2fa89cf988235a3a6a2b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Nov 4 05:48:38 2015 -0800

    perf: Disable IRQs across RCU RS CS that acquires scheduler lock
    
    The perf_lock_task_context() function disables preemption across its
    RCU read-side critical section because that critical section acquires
    a scheduler lock.  If there was a preemption during that RCU read-side
    critical section, the rcu_read_unlock() could attempt to acquire scheduler
    locks, resulting in deadlock.
    
    However, recent optimizations to expedited grace periods mean that IPI
    handlers that execute during preemptible RCU read-side critical sections
    can now cause the subsequent rcu_read_unlock() to acquire scheduler locks.
    Disabling preemption does nothiing to prevent these IPI handlers from
    executing, so these optimizations introduced a deadlock.  In theory,
    this deadlock could be avoided by pulling all wakeups and printk()s out
    from rnp->lock critical sections, but in practice this would re-introduce
    some RCU CPU stall warning bugs.
    
    Given that acquiring scheduler locks entails disabling interrupts, these
    deadlocks can be avoided by disabling interrupts (instead of disabling
    preemption) across any RCU read-side critical that acquires scheduler
    locks and holds them across the rcu_read_unlock().  This commit therefore
    makes this change for perf_lock_task_context().
    
    Reported-by: Dave Jones <davej@codemonkey.org.uk>
    Reported-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Stephane Eranian <eranian@gmail.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20151104134838.GR29027@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 94f9cd81436c85d8c3a318ba92e236ede73752fc
Author: Munehisa Kamata <kamatam@amazon.com>
Date:   Mon Oct 26 19:10:52 2015 -0700

    netfilter: nf_nat_redirect: add missing NULL pointer check
    
    Commit 8b13eddfdf04cbfa561725cfc42d6868fe896f56 ("netfilter: refactor NAT
    redirect IPv4 to use it from nf_tables") has introduced a trivial logic
    change which can result in the following crash.
    
    BUG: unable to handle kernel NULL pointer dereference at 0000000000000030
    IP: [<ffffffffa033002d>] nf_nat_redirect_ipv4+0x2d/0xa0 [nf_nat_redirect]
    PGD 3ba662067 PUD 3ba661067 PMD 0
    Oops: 0000 [#1] SMP
    Modules linked in: ipv6(E) xt_REDIRECT(E) nf_nat_redirect(E) xt_tcpudp(E) iptable_nat(E) nf_conntrack_ipv4(E) nf_defrag_ipv4(E) nf_nat_ipv4(E) nf_nat(E) nf_conntrack(E) ip_tables(E) x_tables(E) binfmt_misc(E) xfs(E) libcrc32c(E) evbug(E) evdev(E) psmouse(E) i2c_piix4(E) i2c_core(E) acpi_cpufreq(E) button(E) ext4(E) crc16(E) jbd2(E) mbcache(E) dm_mirror(E) dm_region_hash(E) dm_log(E) dm_mod(E)
    CPU: 0 PID: 2536 Comm: ip Tainted: G            E   4.1.7-15.23.amzn1.x86_64 #1
    Hardware name: Xen HVM domU, BIOS 4.2.amazon 05/06/2015
    task: ffff8800eb438000 ti: ffff8803ba664000 task.ti: ffff8803ba664000
    [...]
    Call Trace:
     <IRQ>
     [<ffffffffa0334065>] redirect_tg4+0x15/0x20 [xt_REDIRECT]
     [<ffffffffa02e2e99>] ipt_do_table+0x2b9/0x5e1 [ip_tables]
     [<ffffffffa0328045>] iptable_nat_do_chain+0x25/0x30 [iptable_nat]
     [<ffffffffa031777d>] nf_nat_ipv4_fn+0x13d/0x1f0 [nf_nat_ipv4]
     [<ffffffffa0328020>] ? iptable_nat_ipv4_fn+0x20/0x20 [iptable_nat]
     [<ffffffffa031785e>] nf_nat_ipv4_in+0x2e/0x90 [nf_nat_ipv4]
     [<ffffffffa03280a5>] iptable_nat_ipv4_in+0x15/0x20 [iptable_nat]
     [<ffffffff81449137>] nf_iterate+0x57/0x80
     [<ffffffff814491f7>] nf_hook_slow+0x97/0x100
     [<ffffffff814504d4>] ip_rcv+0x314/0x400
    
    unsigned int
    nf_nat_redirect_ipv4(struct sk_buff *skb,
    ...
    {
    ...
                    rcu_read_lock();
                    indev = __in_dev_get_rcu(skb->dev);
                    if (indev != NULL) {
                            ifa = indev->ifa_list;
                            newdst = ifa->ifa_local; <---
                    }
                    rcu_read_unlock();
    ...
    }
    
    Before the commit, 'ifa' had been always checked before access. After the
    commit, however, it could be accessed even if it's NULL. Interestingly,
    this was once fixed in 2003.
    
    http://marc.info/?l=netfilter-devel&m=106668497403047&w=2
    
    In addition to the original one, we have seen the crash when packets that
    need to be redirected somehow arrive on an interface which hasn't been
    yet fully configured.
    
    This change just reverts the logic to the old behavior to avoid the crash.
    
    Fixes: 8b13eddfdf04 ("netfilter: refactor NAT redirect IPv4 to use it from nf_tables")
    Signed-off-by: Munehisa Kamata <kamatam@amazon.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit cc6a7aab5570beef884ff95f7cade6634bf815a1
Author: Arnd Bergmann <arnd@arndb.de>
Date:   Fri Oct 9 16:13:45 2015 +0200

    sunrpc: avoid warning in gss_key_timeout
    
    The gss_key_timeout() function causes a harmless warning in some
    configurations, e.g. ARM imx_v6_v7_defconfig with gcc-5.2, if the
    compiler cannot figure out the state of the 'expire' variable across
    an rcu_read_unlock():
    
    net/sunrpc/auth_gss/auth_gss.c: In function 'gss_key_timeout':
    net/sunrpc/auth_gss/auth_gss.c:1422:211: warning: 'expire' may be used uninitialized in this function [-Wmaybe-uninitialized]
    
    To avoid this warning without adding a bogus initialization, this
    rewrites the function so the comparison is done inside of the
    critical section. As a side-effect, it also becomes slightly
    easier to understand because the implementation now more closely
    resembles the comment above it.
    
    Signed-off-by: Arnd Bergmann <arnd@arndb.de>
    Fixes: c5e6aecd034e7 ("sunrpc: fix RCU handling of gc_ctx field")
    Signed-off-by: J. Bruce Fields <bfields@redhat.com>

commit 51161aa98d0aa4eb20952e16d6c6dbb1d085330e
Author: David Ahern <dsa@cumulusnetworks.com>
Date:   Wed Oct 14 16:44:00 2015 -0700

    net: Fix suspicious RCU usage in fib_rebalance
    
    This command:
      ip route add 192.168.1.0/24 nexthop via 10.2.1.5 dev eth1 nexthop via 10.2.2.5 dev eth2
    
    generated this suspicious RCU usage message:
    
    [ 63.249262]
    [ 63.249939] ===============================
    [ 63.251571] [ INFO: suspicious RCU usage. ]
    [ 63.253250] 4.3.0-rc3+ #298 Not tainted
    [ 63.254724] -------------------------------
    [ 63.256401] ../include/linux/inetdevice.h:205 suspicious rcu_dereference_check() usage!
    [ 63.259450]
    [ 63.259450] other info that might help us debug this:
    [ 63.259450]
    [ 63.262297]
    [ 63.262297] rcu_scheduler_active = 1, debug_locks = 1
    [ 63.264647] 1 lock held by ip/2870:
    [ 63.265896] #0: (rtnl_mutex){+.+.+.}, at: [<ffffffff813ebfb7>] rtnl_lock+0x12/0x14
    [ 63.268858]
    [ 63.268858] stack backtrace:
    [ 63.270409] CPU: 4 PID: 2870 Comm: ip Not tainted 4.3.0-rc3+ #298
    [ 63.272478] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
    [ 63.275745] 0000000000000001 ffff8800b8c9f8b8 ffffffff8125f73c ffff88013afcf301
    [ 63.278185] ffff8800bab7a380 ffff8800b8c9f8e8 ffffffff8107bf30 ffff8800bb728000
    [ 63.280634] ffff880139fe9a60 0000000000000000 ffff880139fe9a00 ffff8800b8c9f908
    [ 63.283177] Call Trace:
    [ 63.283959] [<ffffffff8125f73c>] dump_stack+0x4c/0x68
    [ 63.285593] [<ffffffff8107bf30>] lockdep_rcu_suspicious+0xfa/0x103
    [ 63.287500] [<ffffffff8144d752>] __in_dev_get_rcu+0x48/0x4f
    [ 63.289169] [<ffffffff8144d797>] fib_rebalance+0x3e/0x127
    [ 63.290753] [<ffffffff8144d986>] ? rcu_read_unlock+0x3e/0x5f
    [ 63.292442] [<ffffffff8144ea45>] fib_create_info+0xaf9/0xdcc
    [ 63.294093] [<ffffffff8106c12f>] ? sched_clock_local+0x12/0x75
    [ 63.295791] [<ffffffff8145236a>] fib_table_insert+0x8c/0x451
    [ 63.297493] [<ffffffff8144bf9c>] ? fib_get_table+0x36/0x43
    [ 63.299109] [<ffffffff8144c3ca>] inet_rtm_newroute+0x43/0x51
    [ 63.300709] [<ffffffff813ef684>] rtnetlink_rcv_msg+0x182/0x195
    [ 63.302334] [<ffffffff8107d04c>] ? trace_hardirqs_on+0xd/0xf
    [ 63.303888] [<ffffffff813ebfb7>] ? rtnl_lock+0x12/0x14
    [ 63.305346] [<ffffffff813ef502>] ? __rtnl_unlock+0x12/0x12
    [ 63.306878] [<ffffffff81407c4c>] netlink_rcv_skb+0x3d/0x90
    [ 63.308437] [<ffffffff813ec00e>] rtnetlink_rcv+0x21/0x28
    [ 63.309916] [<ffffffff81407742>] netlink_unicast+0xfa/0x17f
    [ 63.311447] [<ffffffff81407a5e>] netlink_sendmsg+0x297/0x2dc
    [ 63.313029] [<ffffffff813c6cd4>] sock_sendmsg_nosec+0x12/0x1d
    [ 63.314597] [<ffffffff813c835b>] ___sys_sendmsg+0x196/0x21b
    [ 63.316125] [<ffffffff8100bf9f>] ? native_sched_clock+0x1f/0x3c
    [ 63.317671] [<ffffffff8106c12f>] ? sched_clock_local+0x12/0x75
    [ 63.319185] [<ffffffff8106c397>] ? sched_clock_cpu+0x9d/0xb6
    [ 63.320693] [<ffffffff8107e2d7>] ? __lock_is_held+0x32/0x54
    [ 63.322145] [<ffffffff81159fcb>] ? __fget_light+0x4b/0x77
    [ 63.323541] [<ffffffff813c8726>] __sys_sendmsg+0x3d/0x5b
    [ 63.324947] [<ffffffff813c8751>] SyS_sendmsg+0xd/0x19
    [ 63.326274] [<ffffffff814c8f57>] entry_SYSCALL_64_fastpath+0x12/0x6f
    
    It looks like all of the code paths to fib_rebalance are under rtnl.
    
    Fixes: 0e884c78ee19 ("ipv4: L3 hash-based multipath")
    Cc: Peter Nrlund <pch@ordbogen.com>
    Signed-off-by: David Ahern <dsa@cumulusnetworks.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 27566139b6e2f6cfe273e8bb0e538d7616c2ea00
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sat Aug 1 10:45:26 2015 -0700

    documentation: No acquire/release for RCU readers
    
    Documentation/memory-barriers.txt calls out RCU as one of the sets
    of primitives associated with ACQUIRE and RELEASE.  There really
    is an association in that rcu_assign_pointer() includes a RELEASE
    operation, but a quick read can convince people that rcu_read_lock() and
    rcu_read_unlock() have ACQUIRE and RELEASE semantics, which they do not.
    
    This commit therefore removes RCU from this list in order to avoid
    this confusion.
    
    Reported-by: Boqun Feng <boqun.feng@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit bb73c52bad3666997ed2ec83c0c80c3f8ef55008
Author: Boqun Feng <boqun.feng@gmail.com>
Date:   Thu Jul 30 16:55:38 2015 -0700

    rcu: Don't disable preemption for Tiny and Tree RCU readers
    
    Because preempt_disable() maps to barrier() for non-debug builds,
    it forces the compiler to spill and reload registers.  Because Tree
    RCU and Tiny RCU now only appear in CONFIG_PREEMPT=n builds, these
    barrier() instances generate needless extra code for each instance of
    rcu_read_lock() and rcu_read_unlock().  This extra code slows down Tree
    RCU and bloats Tiny RCU.
    
    This commit therefore removes the preempt_disable() and preempt_enable()
    from the non-preemptible implementations of __rcu_read_lock() and
    __rcu_read_unlock(), respectively.  However, for debug purposes,
    preempt_disable() and preempt_enable() are still invoked if
    CONFIG_PREEMPT_COUNT=y, because this allows detection of sleeping inside
    atomic sections in non-preemptible kernels.
    
    However, Tiny and Tree RCU operates by coalescing all RCU read-side
    critical sections on a given CPU that lie between successive quiescent
    states.  It is therefore necessary to compensate for removing barriers
    from __rcu_read_lock() and __rcu_read_unlock() by adding them to a
    couple of the RCU functions invoked during quiescent states, namely to
    rcu_all_qs() and rcu_note_context_switch().  However, note that the latter
    is more paranoia than necessity, at least until link-time optimizations
    become more aggressive.
    
    This is based on an earlier patch by Paul E. McKenney, fixing
    a bug encountered in kernels built with CONFIG_PREEMPT=n and
    CONFIG_PREEMPT_COUNT=y.
    
    Signed-off-by: Boqun Feng <boqun.feng@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 1c626cf472fce757a69a4c70f038867907b5b808
Author: Arend van Spriel <arend@broadcom.com>
Date:   Wed Aug 26 22:14:56 2015 +0200

    brcmfmac: only call brcmf_cfg80211_detach() when attach was successful
    
    In brcmf_bus_start() the function brcmf_cfg80211_attach() is called which
    may fail. If this happens we should not call brcmf_cfg80211_detach() in
    the failure path as it will result in NULL pointer dereference:
    
      brcmf_fweh_activate_events: Set event_msgs error (-5)
      brcmf_bus_start: failed: -5
      brcmf_sdio_firmware_callback: dongle is not responding
      BUG: unable to handle kernel NULL pointer dereference at 0000000000000068
      IP: [<ffffffff811e8f08>] kernfs_find_ns+0x18/0xd0
      PGD 0
      Oops: 0000 [#1] SMP
      Modules linked in: brcmfmac(O) brcmutil(O) cfg80211 auth_rpcgss
      CPU: 1 PID: 45 Comm: kworker/1:1 Tainted: G           O
      Hardware name: Dell Inc. Latitude E6410/07XJP9, BIOS A07 02/15/2011
      Workqueue: events request_firmware_work_func
      task: ffff880036c09ac0 ti: ffff880036dd4000 task.ti: ffff880036dd4000
      RIP: 0010:[<ffffffff811e8f08>]  [<ffffffff811e8f08>] kernfs_find_ns+0x18/0xd0
      RSP: 0018:ffff880036dd7a28  EFLAGS: 00010246
      RAX: ffff880036c09ac0 RBX: 0000000000000000 RCX: 000000007fffffff
      RDX: 0000000000000000 RSI: ffffffff816578b9 RDI: 0000000000000000
      RBP: ffff880036dd7a48 R08: 0000000000000000 R09: ffff880036c0b340
      R10: 00000000000002ec R11: ffff880036dd7b08 R12: ffffffff816578b9
      R13: 0000000000000000 R14: ffffffff816578b9 R15: ffff8800c6c87000
      FS:  0000000000000000(0000) GS:ffff88012bc40000(0000) knlGS:0000000000000000
      CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
      CR2: 0000000000000068 CR3: 0000000001a0b000 CR4: 00000000000006e0
      Stack:
       0000000000000000 ffffffff816578b9 0000000000000000 ffff8800c0d003c8
       ffff880036dd7a78 ffffffff811e8ff5 0000000ffffffff1 ffffffff81a9b060
       ffff8800c789f880 ffff8800c0d00000 ffff880036dd7a98 ffffffff811ebe0d
      Call Trace:
       [<ffffffff811e8ff5>] kernfs_find_and_get_ns+0x35/0x60
       [<ffffffff811ebe0d>] sysfs_unmerge_group+0x1d/0x60
       [<ffffffff81404ef2>] dpm_sysfs_remove+0x22/0x60
       [<ffffffff813f9db9>] device_del+0x49/0x240
       [<ffffffff815da768>] rfkill_unregister+0x58/0xc0
       [<ffffffffa06bd91b>] wiphy_unregister+0xab/0x2f0 [cfg80211]
       [<ffffffffa0742fe3>] brcmf_cfg80211_detach+0x23/0x50 [brcmfmac]
       [<ffffffffa074d986>] brcmf_detach+0x86/0xe0 [brcmfmac]
       [<ffffffffa0757de8>] brcmf_sdio_remove+0x48/0x120 [brcmfmac]
       [<ffffffffa0758ed9>] brcmf_sdiod_remove+0x29/0xd0 [brcmfmac]
       [<ffffffffa0759031>] brcmf_ops_sdio_remove+0xb1/0x110 [brcmfmac]
       [<ffffffffa001c267>] sdio_bus_remove+0x37/0x100 [mmc_core]
       [<ffffffff813fe026>] __device_release_driver+0x96/0x130
       [<ffffffff813fe0e3>] device_release_driver+0x23/0x30
       [<ffffffffa0754bc8>] brcmf_sdio_firmware_callback+0x2a8/0x5d0 [brcmfmac]
       [<ffffffffa074deaf>] brcmf_fw_request_nvram_done+0x15f/0x5e0 [brcmfmac]
       [<ffffffff8140142f>] ? devres_add+0x3f/0x50
       [<ffffffff810642b5>] ? usermodehelper_read_unlock+0x15/0x20
       [<ffffffff81400000>] ? platform_match+0x70/0xa0
       [<ffffffff8140f400>] request_firmware_work_func+0x30/0x60
       [<ffffffff8106828c>] process_one_work+0x14c/0x3d0
       [<ffffffff8106862a>] worker_thread+0x11a/0x450
       [<ffffffff81068510>] ? process_one_work+0x3d0/0x3d0
       [<ffffffff8106d692>] kthread+0xd2/0xf0
       [<ffffffff8106d5c0>] ? kthread_create_on_node+0x180/0x180
       [<ffffffff815ed35f>] ret_from_fork+0x3f/0x70
       [<ffffffff8106d5c0>] ? kthread_create_on_node+0x180/0x180
      Code: e9 40 fe ff ff 48 89 d8 eb 87 66 0f 1f 84 00 00 00 00 00 66 66 66 66
            90 55 48 89 e5 41 56 49 89 f6 41 55 49 89 d5 31 d2 41 54 53 <0f> b7
            47 68 48 8b 5f 48 66 c1 e8 05 83 e0 01 4d 85 ed 0f b6 c8
      RIP  [<ffffffff811e8f08>] kernfs_find_ns+0x18/0xd0
       RSP <ffff880036dd7a28>
      CR2: 0000000000000068
      ---[ end trace 87d6ec0d3fe46740 ]---
    
    Reported-by: Daniel (Deognyoun) Kim <dekim@broadcom.com>
    Reviewed-by: Hante Meuleman <meuleman@broadcom.com>
    Reviewed-by: Franky (Zhenhui) Lin <frankyl@broadcom.com>
    Reviewed-by: Pieter-Paul Giesberts <pieterpg@broadcom.com>
    Signed-off-by: Arend van Spriel <arend@broadcom.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>

commit 8203d6d0ee784cfb2ebf89053f7fe399abc867d7
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun Aug 2 13:53:17 2015 -0700

    rcu: Use single-stage IPI algorithm for RCU expedited grace period
    
    The current preemptible-RCU expedited grace-period algorithm invokes
    synchronize_sched_expedited() to enqueue all tasks currently running
    in a preemptible-RCU read-side critical section, then waits for all the
    ->blkd_tasks lists to drain.  This works, but results in both an IPI and
    a double context switch even on CPUs that do not happen to be running
    in a preemptible RCU read-side critical section.
    
    This commit implements a new algorithm that causes less OS jitter.
    This new algorithm IPIs all online CPUs that are not idle (from an
    RCU perspective), but refrains from self-IPIs.  If a CPU receiving
    this IPI is not in a preemptible RCU read-side critical section (or
    is just now exiting one), it pushes quiescence up the rcu_node tree,
    otherwise, it sets a flag that will be handled by the upcoming outermost
    rcu_read_unlock(), which will then push quiescence up the tree.
    
    The expedited grace period must of course wait on any pre-existing blocked
    readers, and newly blocked readers must be queued carefully based on
    the state of both the normal and the expedited grace periods.  This
    new queueing approach also avoids the need to update boost state,
    courtesy of the fact that blocked tasks are no longer ever migrated to
    the root rcu_node structure.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 5b25b13ab08f616efd566347d809b4ece54570d1
Author: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
Date:   Fri Sep 11 13:07:39 2015 -0700

    sys_membarrier(): system-wide memory barrier (generic, x86)
    
    Here is an implementation of a new system call, sys_membarrier(), which
    executes a memory barrier on all threads running on the system.  It is
    implemented by calling synchronize_sched().  It can be used to
    distribute the cost of user-space memory barriers asymmetrically by
    transforming pairs of memory barriers into pairs consisting of
    sys_membarrier() and a compiler barrier.  For synchronization primitives
    that distinguish between read-side and write-side (e.g.  userspace RCU
    [1], rwlocks), the read-side can be accelerated significantly by moving
    the bulk of the memory barrier overhead to the write-side.
    
    The existing applications of which I am aware that would be improved by
    this system call are as follows:
    
    * Through Userspace RCU library (http://urcu.so)
      - DNS server (Knot DNS) https://www.knot-dns.cz/
      - Network sniffer (http://netsniff-ng.org/)
      - Distributed object storage (https://sheepdog.github.io/sheepdog/)
      - User-space tracing (http://lttng.org)
      - Network storage system (https://www.gluster.org/)
      - Virtual routers (https://events.linuxfoundation.org/sites/events/files/slides/DPDK_RCU_0MQ.pdf)
      - Financial software (https://lkml.org/lkml/2015/3/23/189)
    
    Those projects use RCU in userspace to increase read-side speed and
    scalability compared to locking.  Especially in the case of RCU used by
    libraries, sys_membarrier can speed up the read-side by moving the bulk of
    the memory barrier cost to synchronize_rcu().
    
    * Direct users of sys_membarrier
      - core dotnet garbage collector (https://github.com/dotnet/coreclr/issues/198)
    
    Microsoft core dotnet GC developers are planning to use the mprotect()
    side-effect of issuing memory barriers through IPIs as a way to implement
    Windows FlushProcessWriteBuffers() on Linux.  They are referring to
    sys_membarrier in their github thread, specifically stating that
    sys_membarrier() is what they are looking for.
    
    To explain the benefit of this scheme, let's introduce two example threads:
    
    Thread A (non-frequent, e.g. executing liburcu synchronize_rcu())
    Thread B (frequent, e.g. executing liburcu
    rcu_read_lock()/rcu_read_unlock())
    
    In a scheme where all smp_mb() in thread A are ordering memory accesses
    with respect to smp_mb() present in Thread B, we can change each
    smp_mb() within Thread A into calls to sys_membarrier() and each
    smp_mb() within Thread B into compiler barriers "barrier()".
    
    Before the change, we had, for each smp_mb() pairs:
    
    Thread A                    Thread B
    previous mem accesses       previous mem accesses
    smp_mb()                    smp_mb()
    following mem accesses      following mem accesses
    
    After the change, these pairs become:
    
    Thread A                    Thread B
    prev mem accesses           prev mem accesses
    sys_membarrier()            barrier()
    follow mem accesses         follow mem accesses
    
    As we can see, there are two possible scenarios: either Thread B memory
    accesses do not happen concurrently with Thread A accesses (1), or they
    do (2).
    
    1) Non-concurrent Thread A vs Thread B accesses:
    
    Thread A                    Thread B
    prev mem accesses
    sys_membarrier()
    follow mem accesses
                                prev mem accesses
                                barrier()
                                follow mem accesses
    
    In this case, thread B accesses will be weakly ordered. This is OK,
    because at that point, thread A is not particularly interested in
    ordering them with respect to its own accesses.
    
    2) Concurrent Thread A vs Thread B accesses
    
    Thread A                    Thread B
    prev mem accesses           prev mem accesses
    sys_membarrier()            barrier()
    follow mem accesses         follow mem accesses
    
    In this case, thread B accesses, which are ensured to be in program
    order thanks to the compiler barrier, will be "upgraded" to full
    smp_mb() by synchronize_sched().
    
    * Benchmarks
    
    On Intel Xeon E5405 (8 cores)
    (one thread is calling sys_membarrier, the other 7 threads are busy
    looping)
    
    1000 non-expedited sys_membarrier calls in 33s =3D 33 milliseconds/call.
    
    * User-space user of this system call: Userspace RCU library
    
    Both the signal-based and the sys_membarrier userspace RCU schemes
    permit us to remove the memory barrier from the userspace RCU
    rcu_read_lock() and rcu_read_unlock() primitives, thus significantly
    accelerating them. These memory barriers are replaced by compiler
    barriers on the read-side, and all matching memory barriers on the
    write-side are turned into an invocation of a memory barrier on all
    active threads in the process. By letting the kernel perform this
    synchronization rather than dumbly sending a signal to every process
    threads (as we currently do), we diminish the number of unnecessary wake
    ups and only issue the memory barriers on active threads. Non-running
    threads do not need to execute such barrier anyway, because these are
    implied by the scheduler context switches.
    
    Results in liburcu:
    
    Operations in 10s, 6 readers, 2 writers:
    
    memory barriers in reader:    1701557485 reads, 2202847 writes
    signal-based scheme:          9830061167 reads,    6700 writes
    sys_membarrier:               9952759104 reads,     425 writes
    sys_membarrier (dyn. check):  7970328887 reads,     425 writes
    
    The dynamic sys_membarrier availability check adds some overhead to
    the read-side compared to the signal-based scheme, but besides that,
    sys_membarrier slightly outperforms the signal-based scheme. However,
    this non-expedited sys_membarrier implementation has a much slower grace
    period than signal and memory barrier schemes.
    
    Besides diminishing the number of wake-ups, one major advantage of the
    membarrier system call over the signal-based scheme is that it does not
    need to reserve a signal. This plays much more nicely with libraries,
    and with processes injected into for tracing purposes, for which we
    cannot expect that signals will be unused by the application.
    
    An expedited version of this system call can be added later on to speed
    up the grace period. Its implementation will likely depend on reading
    the cpu_curr()->mm without holding each CPU's rq lock.
    
    This patch adds the system call to x86 and to asm-generic.
    
    [1] http://urcu.so
    
    membarrier(2) man page:
    
    MEMBARRIER(2)              Linux Programmer's Manual             MEMBARRIER(2)
    
    NAME
           membarrier - issue memory barriers on a set of threads
    
    SYNOPSIS
           #include <linux/membarrier.h>
    
           int membarrier(int cmd, int flags);
    
    DESCRIPTION
           The cmd argument is one of the following:
    
           MEMBARRIER_CMD_QUERY
                  Query  the  set  of  supported commands. It returns a bitmask of
                  supported commands.
    
           MEMBARRIER_CMD_SHARED
                  Execute a memory barrier on all threads running on  the  system.
                  Upon  return from system call, the caller thread is ensured that
                  all running threads have passed through a state where all memory
                  accesses  to  user-space  addresses  match program order between
                  entry to and return from the system  call  (non-running  threads
                  are de facto in such a state). This covers threads from all pro=E2=80=90
                  cesses running on the system.  This command returns 0.
    
           The flags argument needs to be 0. For future extensions.
    
           All memory accesses performed  in  program  order  from  each  targeted
           thread is guaranteed to be ordered with respect to sys_membarrier(). If
           we use the semantic "barrier()" to represent a compiler barrier forcing
           memory  accesses  to  be performed in program order across the barrier,
           and smp_mb() to represent explicit memory barriers forcing full  memory
           ordering  across  the barrier, we have the following ordering table for
           each pair of barrier(), sys_membarrier() and smp_mb():
    
           The pair ordering is detailed as (O: ordered, X: not ordered):
    
                                  barrier()   smp_mb() sys_membarrier()
                  barrier()          X           X            O
                  smp_mb()           X           O            O
                  sys_membarrier()   O           O            O
    
    RETURN VALUE
           On success, these system calls return zero.  On error, -1 is  returned,
           and errno is set appropriately. For a given command, with flags
           argument set to 0, this system call is guaranteed to always return the
           same value until reboot.
    
    ERRORS
           ENOSYS System call is not implemented.
    
           EINVAL Invalid arguments.
    
    Linux                             2015-04-15                     MEMBARRIER(2)
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Nicholas Miell <nmiell@comcast.net>
    Cc: Ingo Molnar <mingo@redhat.com>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Stephen Hemminger <stephen@networkplumber.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Pranith Kumar <bobby.prani@gmail.com>
    Cc: Michael Kerrisk <mtk.manpages@gmail.com>
    Cc: Shuah Khan <shuahkh@osg.samsung.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit b0d4943eec9a42c7ba2065f6cfa949894204dd4a
Author: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
Date:   Fri Aug 28 15:05:32 2015 -0700

    bonding: fix bond_poll_controller bh_enable warning
    
    The problem is rcu_read_unlock_bh() which triggers a warning when irqs are
    disabled. ndo_poll_controller should run with irqs disabled always so we
    can drop the rcu_read_lock_bh.
    
    [   98.502922] bond0: making interface eth1 the new active one
    [   98.503039] ------------[ cut here ]------------
    [   98.503039] WARNING: CPU: 0 PID: 1744 at kernel/softirq.c:150 __local_bh_enable_ip+0x96/0xc0()
    [   98.503039] Modules linked in: bonding(OE) rpcsec_gss_krb5 nfsv4 dns_resolver nfs fscache netconsole ppdev joydev parport_pc serio_raw parport i2c_piix4 video acpi_cpufreq nfsd auth_rpcgss nfs_acl lockd grace sunrpc virtio_net e1000 ata_generic pcnet32 mii virtio_pci virtio_ring virtio pata_acpi
    [   98.503039] CPU: 0 PID: 1744 Comm: ifenslave Tainted: G           OE   4.2.0-rc7+ #56
    [   98.503039] Hardware name: innotek GmbH VirtualBox/VirtualBox, BIOS VirtualBox 12/01/2006
    [   98.503039]  0000000000000000 00000000e96ba230 ffff880020c236b8 ffffffff8183f105
    [   98.503039]  0000000000000000 0000000000000000 ffff880020c236f8 ffffffff810a9496
    [   98.503039]  ffff88002ea99e08 0000000000000200 ffffffffa02a8e06 ffff88002ea99e08
    [   98.503039] Call Trace:
    [   98.503039]  [<ffffffff8183f105>] dump_stack+0x4c/0x65
    [   98.503039]  [<ffffffff810a9496>] warn_slowpath_common+0x86/0xc0
    [   98.503039]  [<ffffffffa02a8e06>] ? bond_poll_controller+0x146/0x250 [bonding]
    [   98.503039]  [<ffffffff810a95ca>] warn_slowpath_null+0x1a/0x20
    [   98.503039]  [<ffffffff810ae376>] __local_bh_enable_ip+0x96/0xc0
    [   98.503039]  [<ffffffffa02a8e2f>] bond_poll_controller+0x16f/0x250 [bonding]
    [   98.503039]  [<ffffffffa02a8cf3>] ? bond_poll_controller+0x33/0x250 [bonding]
    [   98.503039]  [<ffffffff810feaed>] ? trace_hardirqs_off+0xd/0x10
    [   98.503039]  [<ffffffff81848afb>] ? _raw_spin_unlock_irqrestore+0x5b/0x60
    [   98.503039]  [<ffffffff816ec48e>] netpoll_poll_dev+0x6e/0x350
    [   98.503039]  [<ffffffff816eb977>] ? netpoll_start_xmit+0x137/0x1d0
    [   98.503039]  [<ffffffff816b2e8b>] ? __alloc_skb+0x5b/0x210
    [   98.503039]  [<ffffffff816ec89d>] netpoll_send_skb_on_dev+0x12d/0x2a0
    [   98.503039]  [<ffffffff816eccde>] netpoll_send_udp+0x2ce/0x430
    [   98.503039]  [<ffffffffa0190850>] write_msg+0xb0/0xf0 [netconsole]
    [   98.503039]  [<ffffffff81116b63>] call_console_drivers.constprop.25+0x133/0x260
    [   98.503039]  [<ffffffff81117934>] console_unlock+0x2f4/0x580
    [   98.503039]  [<ffffffff81117ea5>] ? vprintk_emit+0x2e5/0x630
    [   98.503039]  [<ffffffff81117ee5>] vprintk_emit+0x325/0x630
    [   98.503039]  [<ffffffff81118379>] vprintk_default+0x29/0x40
    [   98.503039]  [<ffffffff8183de4f>] printk+0x55/0x6b
    [   98.503039]  [<ffffffff816c754c>] __netdev_printk+0x16c/0x260
    [   98.503039]  [<ffffffff816c7a12>] netdev_info+0x62/0x80
    [   98.503039]  [<ffffffffa02ab464>] bond_change_active_slave+0x134/0x6a0 [bonding]
    [   98.503039]  [<ffffffffa02aba95>] bond_select_active_slave+0xc5/0x310 [bonding]
    [   98.503039]  [<ffffffffa02aeb78>] bond_enslave+0x1088/0x10c0 [bonding]
    [   98.503039]  [<ffffffffa02af46b>] bond_do_ioctl+0x37b/0x400 [bonding]
    [   98.503039]  [<ffffffff81101d8d>] ? trace_hardirqs_on+0xd/0x10
    [   98.503039]  [<ffffffff816dc437>] ? rtnl_lock+0x17/0x20
    [   98.503039]  [<ffffffff816e5fd1>] dev_ifsioc+0x331/0x3e0
    [   98.503039]  [<ffffffff816e62dc>] dev_ioctl+0xec/0x6c0
    [   98.503039]  [<ffffffff816a6c6a>] sock_do_ioctl+0x4a/0x60
    [   98.503039]  [<ffffffff816a7300>] sock_ioctl+0x1c0/0x250
    [   98.503039]  [<ffffffff81271bfe>] do_vfs_ioctl+0x2ee/0x540
    [   98.503039]  [<ffffffff810fd943>] ? up_read+0x23/0x40
    [   98.503039]  [<ffffffff81070993>] ? __do_page_fault+0x1d3/0x420
    [   98.503039]  [<ffffffff8127e246>] ? __fget_light+0x66/0x90
    [   98.503039]  [<ffffffff81271ec9>] SyS_ioctl+0x79/0x90
    [   98.503039]  [<ffffffff8184936e>] entry_SYSCALL_64_fastpath+0x12/0x76
    [   98.503039] ---[ end trace 00cfa804b0670051 ]---
    
    Fixes: 616f45416ca0 ("bonding: implement bond_poll_controller()")
    Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
    Acked-by: Mahesh Bandewar <maheshb@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 9c7370a166b4e157137bfbfe2ad296d57147547c
Author: Martin KaFai Lau <kafai@fb.com>
Date:   Fri Aug 14 11:05:54 2015 -0700

    ipv6: Fix a potential deadlock when creating pcpu rt
    
    rt6_make_pcpu_route() is called under read_lock(&table->tb6_lock).
    rt6_make_pcpu_route() calls ip6_rt_pcpu_alloc(rt) which then
    calls dst_alloc().  dst_alloc() _may_ call ip6_dst_gc() which takes
    the write_lock(&tabl->tb6_lock).  A visualized version:
    
    read_lock(&table->tb6_lock);
    rt6_make_pcpu_route();
    => ip6_rt_pcpu_alloc();
    => dst_alloc();
    => ip6_dst_gc();
    => write_lock(&table->tb6_lock); /* oops */
    
    The fix is to do a read_unlock first before calling ip6_rt_pcpu_alloc().
    
    A reported stack:
    
    [141625.537638] INFO: rcu_sched self-detected stall on CPU { 27}  (t=60000 jiffies g=4159086 c=4159085 q=2139)
    [141625.547469] Task dump for CPU 27:
    [141625.550881] mtr             R  running task        0 22121  22081 0x00000008
    [141625.558069]  0000000000000000 ffff88103f363d98 ffffffff8106e488 000000000000001b
    [141625.565641]  ffffffff81684900 ffff88103f363db8 ffffffff810702b0 0000000008000000
    [141625.573220]  ffffffff81684900 ffff88103f363de8 ffffffff8108df9f ffff88103f375a00
    [141625.580803] Call Trace:
    [141625.583345]  <IRQ>  [<ffffffff8106e488>] sched_show_task+0xc1/0xc6
    [141625.589650]  [<ffffffff810702b0>] dump_cpu_task+0x35/0x39
    [141625.595144]  [<ffffffff8108df9f>] rcu_dump_cpu_stacks+0x6a/0x8c
    [141625.601320]  [<ffffffff81090606>] rcu_check_callbacks+0x1f6/0x5d4
    [141625.607669]  [<ffffffff810940c8>] update_process_times+0x2a/0x4f
    [141625.613925]  [<ffffffff8109fbee>] tick_sched_handle+0x32/0x3e
    [141625.619923]  [<ffffffff8109fc2f>] tick_sched_timer+0x35/0x5c
    [141625.625830]  [<ffffffff81094a1f>] __hrtimer_run_queues+0x8f/0x18d
    [141625.632171]  [<ffffffff81094c9e>] hrtimer_interrupt+0xa0/0x166
    [141625.638258]  [<ffffffff8102bf2a>] local_apic_timer_interrupt+0x4e/0x52
    [141625.645036]  [<ffffffff8102c36f>] smp_apic_timer_interrupt+0x39/0x4a
    [141625.651643]  [<ffffffff8140b9e8>] apic_timer_interrupt+0x68/0x70
    [141625.657895]  <EOI>  [<ffffffff81346ee8>] ? dst_destroy+0x7c/0xb5
    [141625.664188]  [<ffffffff813d45b5>] ? fib6_flush_trees+0x20/0x20
    [141625.670272]  [<ffffffff81082b45>] ? queue_write_lock_slowpath+0x60/0x6f
    [141625.677140]  [<ffffffff8140aa33>] _raw_write_lock_bh+0x23/0x25
    [141625.683218]  [<ffffffff813d4553>] __fib6_clean_all+0x40/0x82
    [141625.689124]  [<ffffffff813d45b5>] ? fib6_flush_trees+0x20/0x20
    [141625.695207]  [<ffffffff813d6058>] fib6_clean_all+0xe/0x10
    [141625.700854]  [<ffffffff813d60d3>] fib6_run_gc+0x79/0xc8
    [141625.706329]  [<ffffffff813d0510>] ip6_dst_gc+0x85/0xf9
    [141625.711718]  [<ffffffff81346d68>] dst_alloc+0x55/0x159
    [141625.717105]  [<ffffffff813d09b5>] __ip6_dst_alloc.isra.32+0x19/0x63
    [141625.723620]  [<ffffffff813d1830>] ip6_pol_route+0x36a/0x3e8
    [141625.729441]  [<ffffffff813d18d6>] ip6_pol_route_output+0x11/0x13
    [141625.735700]  [<ffffffff813f02c8>] fib6_rule_action+0xa7/0x1bf
    [141625.741698]  [<ffffffff813d18c5>] ? ip6_pol_route_input+0x17/0x17
    [141625.748043]  [<ffffffff81357c48>] fib_rules_lookup+0xb5/0x12a
    [141625.754050]  [<ffffffff81141628>] ? poll_select_copy_remaining+0xf9/0xf9
    [141625.761002]  [<ffffffff813f0535>] fib6_rule_lookup+0x37/0x5c
    [141625.766914]  [<ffffffff813d18c5>] ? ip6_pol_route_input+0x17/0x17
    [141625.773260]  [<ffffffff813d008c>] ip6_route_output+0x7a/0x82
    [141625.779177]  [<ffffffff813c44c8>] ip6_dst_lookup_tail+0x53/0x112
    [141625.785437]  [<ffffffff813c45c3>] ip6_dst_lookup_flow+0x2a/0x6b
    [141625.791604]  [<ffffffff813ddaab>] rawv6_sendmsg+0x407/0x9b6
    [141625.797423]  [<ffffffff813d7914>] ? do_ipv6_setsockopt.isra.8+0xd87/0xde2
    [141625.804464]  [<ffffffff8139d4b4>] inet_sendmsg+0x57/0x8e
    [141625.810028]  [<ffffffff81329ba3>] sock_sendmsg+0x2e/0x3c
    [141625.815588]  [<ffffffff8132be57>] SyS_sendto+0xfe/0x143
    [141625.821063]  [<ffffffff813dd551>] ? rawv6_setsockopt+0x5e/0x67
    [141625.827146]  [<ffffffff8132c9f8>] ? sock_common_setsockopt+0xf/0x11
    [141625.833660]  [<ffffffff8132c08c>] ? SyS_setsockopt+0x81/0xa2
    [141625.839565]  [<ffffffff8140ac17>] entry_SYSCALL_64_fastpath+0x12/0x6a
    
    Fixes: d52d3997f843 ("pv6: Create percpu rt6_info")
    Signed-off-by: Martin KaFai Lau <kafai@fb.com>
    CC: Hannes Frederic Sowa <hannes@stressinduktion.org>
    Reported-by: Steinar H. Gunderson <sgunderson@bigfoot.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 454d3a2500a4eb33be85dde3bfba9e5f6b5efadc
Author: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date:   Wed Jul 22 17:59:11 2015 +0200

    cpufreq: Remove cpufreq_rwsem
    
    cpufreq_rwsem was introduced in commit 6eed9404ab3c4 ("cpufreq: Use
    rwsem for protecting critical sections) in order to replace
    try_module_get() on the cpu-freq driver. That try_module_get() worked
    well until the refcount was so heavily used that module removal became
    more or less impossible.
    
    Though when looking at the various (undocumented) protection
    mechanisms in that code, the randomly sprinkeled around cpufreq_rwsem
    locking sites are superfluous.
    
    The policy, which is acquired in cpufreq_cpu_get() and released in
    cpufreq_cpu_put() is sufficiently protected already.
    
      cpufreq_cpu_get(cpu)
        /* Protects against concurrent driver removal */
        read_lock_irqsave(&cpufreq_driver_lock, flags);
        policy = per_cpu(cpufreq_cpu_data, cpu);
        kobject_get(&policy->kobj);
        read_unlock_irqrestore(&cpufreq_driver_lock, flags);
    
    The reference on the policy serializes versus module unload already:
    
      cpufreq_unregister_driver()
        subsys_interface_unregister()
          __cpufreq_remove_dev_finish()
            per_cpu(cpufreq_cpu_data) = NULL;
            cpufreq_policy_put_kobj()
    
    If there is a reference held on the policy, i.e. obtained prior to the
    unregister call, then cpufreq_policy_put_kobj() will wait until that
    reference is dropped. So once subsys_interface_unregister() returns
    there is no policy pointer in flight and no new reference can be
    obtained. So that rwsem protection is useless.
    
    The other usage of cpufreq_rwsem in show()/store() of the sysfs
    interface is redundant as well because sysfs already does the proper
    kobject_get()/put() pairs.
    
    That leaves CPU hotplug versus module removal. The current
    down_write() around the write_lock() in cpufreq_unregister_driver() is
    silly at best as it protects actually nothing.
    
    The trivial solution to this is to prevent hotplug across
    cpufreq_unregister_driver completely.
    
    Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit 0fba37a3af03a7e74bf9e75473729adb98da49c3
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Tue Jul 14 16:35:54 2015 +0300

    ipvlan: use rcu_deference_bh() in ipvlan_queue_xmit()
    
    In tx path rcu_read_lock_bh() is held, so we need rcu_deference_bh().
    This fixes the following warning:
    
     ===============================
     [ INFO: suspicious RCU usage. ]
     4.1.0-rc1+ #1007 Not tainted
     -------------------------------
     drivers/net/ipvlan/ipvlan.h:106 suspicious rcu_dereference_check() usage!
    
     other info that might help us debug this:
    
     rcu_scheduler_active = 1, debug_locks = 0
     1 lock held by dhclient/1076:
      #0:  (rcu_read_lock_bh){......}, at: [<ffffffff817e8d84>] rcu_lock_acquire+0x0/0x26
    
     stack backtrace:
     CPU: 2 PID: 1076 Comm: dhclient Not tainted 4.1.0-rc1+ #1007
     Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
      0000000000000001 ffff8800d381bac8 ffffffff81a4154f 000000003c1a3c19
      ffff8800d4d0a690 ffff8800d381baf8 ffffffff810b849f ffff880117d41148
      ffff880117d40000 ffff880117d40068 0000000000000156 ffff8800d381bb18
     Call Trace:
      [<ffffffff81a4154f>] dump_stack+0x4c/0x65
      [<ffffffff810b849f>] lockdep_rcu_suspicious+0x107/0x110
      [<ffffffff8165a522>] ipvlan_port_get_rcu+0x47/0x4e
      [<ffffffff8165ad14>] ipvlan_queue_xmit+0x35/0x450
      [<ffffffff817ea45d>] ? rcu_read_unlock+0x3e/0x5f
      [<ffffffff810a20bf>] ? local_clock+0x19/0x22
      [<ffffffff810b4781>] ? __lock_is_held+0x39/0x52
      [<ffffffff8165b64c>] ipvlan_start_xmit+0x1b/0x44
      [<ffffffff817edf7f>] dev_hard_start_xmit+0x2ae/0x467
      [<ffffffff817ee642>] __dev_queue_xmit+0x50a/0x60c
      [<ffffffff817ee7a7>] dev_queue_xmit_sk+0x13/0x15
      [<ffffffff81997596>] dev_queue_xmit+0x10/0x12
      [<ffffffff8199b41c>] packet_sendmsg+0xb6b/0xbdf
      [<ffffffff810b5ea7>] ? mark_lock+0x2e/0x226
      [<ffffffff810a1fcc>] ? sched_clock_cpu+0x9e/0xb7
      [<ffffffff817d56f9>] sock_sendmsg_nosec+0x12/0x1d
      [<ffffffff817d7257>] sock_sendmsg+0x29/0x2e
      [<ffffffff817d72cc>] sock_write_iter+0x70/0x91
      [<ffffffff81199563>] __vfs_write+0x7e/0xa7
      [<ffffffff811996bc>] vfs_write+0x92/0xe8
      [<ffffffff811997d7>] SyS_write+0x47/0x7e
      [<ffffffff81a4d517>] system_call_fastpath+0x12/0x6f
    
    Fixes: 2ad7bf363841 ("ipvlan: Initial check-in of the IPVLAN driver.")
    Cc: Mahesh Bandewar <maheshb@google.com>
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Acked-by: Mahesh Bandewar <maheshb@google.com>
    Acked-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f10c969c1fd328323f45ac953c992b756b25f31b
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon Mar 23 16:31:09 2015 -0700

    net: use for_each_netdev_safe() in rtnl_group_changelink()
    
    commit d079535d5e1bf5e2e7c856bae2483414ea21e137 upstream.
    
    In case we move the whole dev group to another netns,
    we should call for_each_netdev_safe(), otherwise we get
    a soft lockup:
    
     NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [ip:798]
     irq event stamp: 255424
     hardirqs last  enabled at (255423): [<ffffffff81a2aa95>] restore_args+0x0/0x30
     hardirqs last disabled at (255424): [<ffffffff81a2ad5a>] apic_timer_interrupt+0x6a/0x80
     softirqs last  enabled at (255422): [<ffffffff81079ebc>] __do_softirq+0x2c1/0x3a9
     softirqs last disabled at (255417): [<ffffffff8107a190>] irq_exit+0x41/0x95
     CPU: 0 PID: 798 Comm: ip Not tainted 4.0.0-rc4+ #881
     Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
     task: ffff8800d1b88000 ti: ffff880119530000 task.ti: ffff880119530000
     RIP: 0010:[<ffffffff810cad11>]  [<ffffffff810cad11>] debug_lockdep_rcu_enabled+0x28/0x30
     RSP: 0018:ffff880119533778  EFLAGS: 00000246
     RAX: ffff8800d1b88000 RBX: 0000000000000002 RCX: 0000000000000038
     RDX: 0000000000000000 RSI: ffff8800d1b888c8 RDI: ffff8800d1b888c8
     RBP: ffff880119533778 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 000000000000b5c2 R12: 0000000000000246
     R13: ffff880119533708 R14: 00000000001d5a40 R15: ffff88011a7d5a40
     FS:  00007fc01315f740(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: 00007f367a120988 CR3: 000000011849c000 CR4: 00000000000007f0
     Stack:
      ffff880119533798 ffffffff811ac868 ffffffff811ac831 ffffffff811ac828
      ffff8801195337c8 ffffffff811ac8c9 ffff8801195339b0 ffff8801197633e0
      0000000000000000 ffff8801195339b0 ffff8801195337d8 ffffffff811ad2d7
     Call Trace:
      [<ffffffff811ac868>] rcu_read_lock+0x37/0x6e
      [<ffffffff811ac831>] ? rcu_read_unlock+0x5f/0x5f
      [<ffffffff811ac828>] ? rcu_read_unlock+0x56/0x5f
      [<ffffffff811ac8c9>] __fget+0x2a/0x7a
      [<ffffffff811ad2d7>] fget+0x13/0x15
      [<ffffffff811be732>] proc_ns_fget+0xe/0x38
      [<ffffffff817c7714>] get_net_ns_by_fd+0x11/0x59
      [<ffffffff817df359>] rtnl_link_get_net+0x33/0x3e
      [<ffffffff817df3d7>] do_setlink+0x73/0x87b
      [<ffffffff810b28ce>] ? trace_hardirqs_off+0xd/0xf
      [<ffffffff81a2aa95>] ? retint_restore_args+0xe/0xe
      [<ffffffff817e0301>] rtnl_newlink+0x40c/0x699
      [<ffffffff817dffe0>] ? rtnl_newlink+0xeb/0x699
      [<ffffffff81a29246>] ? _raw_spin_unlock+0x28/0x33
      [<ffffffff8143ed1e>] ? security_capable+0x18/0x1a
      [<ffffffff8107da51>] ? ns_capable+0x4d/0x65
      [<ffffffff817de5ce>] rtnetlink_rcv_msg+0x181/0x194
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de44d>] ? __rtnl_unlock+0x17/0x17
      [<ffffffff818327c6>] netlink_rcv_skb+0x4d/0x93
      [<ffffffff817de42f>] rtnetlink_rcv+0x26/0x2d
      [<ffffffff81830f18>] netlink_unicast+0xcb/0x150
      [<ffffffff8183198e>] netlink_sendmsg+0x501/0x523
      [<ffffffff8115cba9>] ? might_fault+0x59/0xa9
      [<ffffffff817b5398>] ? copy_from_user+0x2a/0x2c
      [<ffffffff817b7b74>] sock_sendmsg+0x34/0x3c
      [<ffffffff817b7f6d>] ___sys_sendmsg+0x1b8/0x255
      [<ffffffff8115c5eb>] ? handle_pte_fault+0xbd5/0xd4a
      [<ffffffff8100a2b0>] ? native_sched_clock+0x35/0x37
      [<ffffffff8109e94b>] ? sched_clock_local+0x12/0x72
      [<ffffffff8109eb9c>] ? sched_clock_cpu+0x9e/0xb7
      [<ffffffff810cadbf>] ? rcu_read_lock_held+0x3b/0x3d
      [<ffffffff811ac1d8>] ? __fcheck_files+0x4c/0x58
      [<ffffffff811ac946>] ? __fget_light+0x2d/0x52
      [<ffffffff817b8adc>] __sys_sendmsg+0x42/0x60
      [<ffffffff817b8b0c>] SyS_sendmsg+0x12/0x1c
      [<ffffffff81a29e32>] system_call_fastpath+0x12/0x17
    
    Fixes: e7ed828f10bd8 ("netlink: support setting devgroup parameters")
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Zefan Li <lizefan@huawei.com>

commit 18f84d41d34fa35d0d64bbaea01fe664553ecc06
Author: Jozsef Kadlecsik <kadlec@blackhole.kfki.hu>
Date:   Sat Jun 13 17:29:56 2015 +0200

    netfilter: ipset: Introduce RCU locking in hash:* types
    
    Three types of data need to be protected in the case of the hash types:
    
    a. The hash buckets: standard rcu pointer operations are used.
    b. The element blobs in the hash buckets are stored in an array and
       a bitmap is used for book-keeping to tell which elements in the array
       are used or free.
    c. Networks per cidr values and the cidr values themselves are stored
       in fix sized arrays and need no protection. The values are modified
       in such an order that in the worst case an element testing is repeated
       once with the same cidr value.
    
    The ipset hash approach uses arrays instead of lists and therefore is
    incompatible with rhashtable.
    
    Performance is tested by Jesper Dangaard Brouer:
    
    Simple drop in FORWARD
    ~~~~~~~~~~~~~~~~~~~~~~
    
    Dropping via simple iptables net-mask match::
    
     iptables -t raw -N simple || iptables -t raw -F simple
     iptables -t raw -I simple  -s 198.18.0.0/15 -j DROP
     iptables -t raw -D PREROUTING -j simple
     iptables -t raw -I PREROUTING -j simple
    
    Drop performance in "raw": 11.3Mpps
    
    Generator: sending 12.2Mpps (tx:12264083 pps)
    
    Drop via original ipset in RAW table
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
    Create a set with lots of elements::
    
     sudo ./ipset destroy test
     echo "create test hash:ip hashsize 65536" > test.set
     for x in `seq 0 255`; do
        for y in `seq 0 255`; do
            echo "add test 198.18.$x.$y" >> test.set
        done
     done
     sudo ./ipset restore < test.set
    
    Dropping via ipset::
    
     iptables -t raw -F
     iptables -t raw -N net198 || iptables -t raw -F net198
     iptables -t raw -I net198 -m set --match-set test src -j DROP
     iptables -t raw -I PREROUTING -j net198
    
    Drop performance in "raw" with ipset: 8Mpps
    
    Perf report numbers ipset drop in "raw"::
    
     +   24.65%  ksoftirqd/1  [ip_set]           [k] ip_set_test
     -   21.42%  ksoftirqd/1  [kernel.kallsyms]  [k] _raw_read_lock_bh
        - _raw_read_lock_bh
           + 99.88% ip_set_test
     -   19.42%  ksoftirqd/1  [kernel.kallsyms]  [k] _raw_read_unlock_bh
        - _raw_read_unlock_bh
           + 99.72% ip_set_test
     +    4.31%  ksoftirqd/1  [ip_set_hash_ip]   [k] hash_ip4_kadt
     +    2.27%  ksoftirqd/1  [ixgbe]            [k] ixgbe_fetch_rx_buffer
     +    2.18%  ksoftirqd/1  [ip_tables]        [k] ipt_do_table
     +    1.81%  ksoftirqd/1  [ip_set_hash_ip]   [k] hash_ip4_test
     +    1.61%  ksoftirqd/1  [kernel.kallsyms]  [k] __netif_receive_skb_core
     +    1.44%  ksoftirqd/1  [kernel.kallsyms]  [k] build_skb
     +    1.42%  ksoftirqd/1  [kernel.kallsyms]  [k] ip_rcv
     +    1.36%  ksoftirqd/1  [kernel.kallsyms]  [k] __local_bh_enable_ip
     +    1.16%  ksoftirqd/1  [kernel.kallsyms]  [k] dev_gro_receive
     +    1.09%  ksoftirqd/1  [kernel.kallsyms]  [k] __rcu_read_unlock
     +    0.96%  ksoftirqd/1  [ixgbe]            [k] ixgbe_clean_rx_irq
     +    0.95%  ksoftirqd/1  [kernel.kallsyms]  [k] __netdev_alloc_frag
     +    0.88%  ksoftirqd/1  [kernel.kallsyms]  [k] kmem_cache_alloc
     +    0.87%  ksoftirqd/1  [xt_set]           [k] set_match_v3
     +    0.85%  ksoftirqd/1  [kernel.kallsyms]  [k] inet_gro_receive
     +    0.83%  ksoftirqd/1  [kernel.kallsyms]  [k] nf_iterate
     +    0.76%  ksoftirqd/1  [kernel.kallsyms]  [k] put_compound_page
     +    0.75%  ksoftirqd/1  [kernel.kallsyms]  [k] __rcu_read_lock
    
    Drop via ipset in RAW table with RCU-locking
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    
    With RCU locking, the RW-lock is gone.
    
    Drop performance in "raw" with ipset with RCU-locking: 11.3Mpps
    
    Performance-tested-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Jozsef Kadlecsik <kadlec@blackhole.kfki.hu>

commit f548d99ef4f5ec8f7080e88ad07c44d16d058ddc
Author: Alexey Kodanev <alexey.kodanev@oracle.com>
Date:   Sat Mar 7 03:06:53 2015 +0300

    locktorture: fix deadlock in 'rw_lock_irq' type
    
    torture_rwlock_read_unlock_irq() must use read_unlock_irqrestore()
    instead of write_unlock_irqrestore().
    
    Use read_unlock_irqrestore() instead of write_unlock_irqrestore().
    
    Signed-off-by: Alexey Kodanev <alexey.kodanev@oracle.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit 0a0ba1c93f8a0ff28bacec0d1d018081e762e2f0
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun Mar 8 14:20:30 2015 -0700

    rcu: Adjust ->lock acquisition for tasks no longer migrating
    
    Tasks are no longer migrated away from a given rcu_node structure
    when all CPUs corresponding to that rcu_node structure have gone offline.
    This means that rcu_read_unlock_special() no longer needs to loop
    retrying rcu_node ->lock acquisition because the current task is
    guaranteed to stay put.
    
    This commit takes a small and paranoid step towards relying on this
    guarantee by placing a WARN_ON_ONCE() just after the early exit from
    the lock-acquisition loop.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit bda0be7ad994812960e9f8f2d2757f72cb4a96cb
Author: NeilBrown <neilb@suse.de>
Date:   Mon Mar 23 13:37:39 2015 +1100

    security: make inode_follow_link RCU-walk aware
    
    inode_follow_link now takes an inode and rcu flag as well as the
    dentry.
    
    inode is used in preference to d_backing_inode(dentry), particularly
    in RCU-walk mode.
    
    selinux_inode_follow_link() gets dentry_has_perm() and
    inode_has_perm() open-coded into it so that it can call
    avc_has_perm_flags() in way that is safe if LOOKUP_RCU is set.
    
    Calling avc_has_perm_flags() with rcu_read_lock() held means
    that when avc_has_perm_noaudit calls avc_compute_av(), the attempt
    to rcu_read_unlock() before calling security_compute_av() will not
    actually drop the RCU read-lock.
    
    However as security_compute_av() is completely in a read_lock()ed
    region, it should be safe with the RCU read-lock held.
    
    Signed-off-by: NeilBrown <neilb@suse.de>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 2b14e138905fd23ec74ee713a490a48ea5ccac3d
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon Mar 23 16:31:09 2015 -0700

    net: use for_each_netdev_safe() in rtnl_group_changelink()
    
    commit d079535d5e1bf5e2e7c856bae2483414ea21e137 upstream.
    
    In case we move the whole dev group to another netns,
    we should call for_each_netdev_safe(), otherwise we get
    a soft lockup:
    
     NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [ip:798]
     irq event stamp: 255424
     hardirqs last  enabled at (255423): [<ffffffff81a2aa95>] restore_args+0x0/0x30
     hardirqs last disabled at (255424): [<ffffffff81a2ad5a>] apic_timer_interrupt+0x6a/0x80
     softirqs last  enabled at (255422): [<ffffffff81079ebc>] __do_softirq+0x2c1/0x3a9
     softirqs last disabled at (255417): [<ffffffff8107a190>] irq_exit+0x41/0x95
     CPU: 0 PID: 798 Comm: ip Not tainted 4.0.0-rc4+ #881
     Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
     task: ffff8800d1b88000 ti: ffff880119530000 task.ti: ffff880119530000
     RIP: 0010:[<ffffffff810cad11>]  [<ffffffff810cad11>] debug_lockdep_rcu_enabled+0x28/0x30
     RSP: 0018:ffff880119533778  EFLAGS: 00000246
     RAX: ffff8800d1b88000 RBX: 0000000000000002 RCX: 0000000000000038
     RDX: 0000000000000000 RSI: ffff8800d1b888c8 RDI: ffff8800d1b888c8
     RBP: ffff880119533778 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 000000000000b5c2 R12: 0000000000000246
     R13: ffff880119533708 R14: 00000000001d5a40 R15: ffff88011a7d5a40
     FS:  00007fc01315f740(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: 00007f367a120988 CR3: 000000011849c000 CR4: 00000000000007f0
     Stack:
      ffff880119533798 ffffffff811ac868 ffffffff811ac831 ffffffff811ac828
      ffff8801195337c8 ffffffff811ac8c9 ffff8801195339b0 ffff8801197633e0
      0000000000000000 ffff8801195339b0 ffff8801195337d8 ffffffff811ad2d7
     Call Trace:
      [<ffffffff811ac868>] rcu_read_lock+0x37/0x6e
      [<ffffffff811ac831>] ? rcu_read_unlock+0x5f/0x5f
      [<ffffffff811ac828>] ? rcu_read_unlock+0x56/0x5f
      [<ffffffff811ac8c9>] __fget+0x2a/0x7a
      [<ffffffff811ad2d7>] fget+0x13/0x15
      [<ffffffff811be732>] proc_ns_fget+0xe/0x38
      [<ffffffff817c7714>] get_net_ns_by_fd+0x11/0x59
      [<ffffffff817df359>] rtnl_link_get_net+0x33/0x3e
      [<ffffffff817df3d7>] do_setlink+0x73/0x87b
      [<ffffffff810b28ce>] ? trace_hardirqs_off+0xd/0xf
      [<ffffffff81a2aa95>] ? retint_restore_args+0xe/0xe
      [<ffffffff817e0301>] rtnl_newlink+0x40c/0x699
      [<ffffffff817dffe0>] ? rtnl_newlink+0xeb/0x699
      [<ffffffff81a29246>] ? _raw_spin_unlock+0x28/0x33
      [<ffffffff8143ed1e>] ? security_capable+0x18/0x1a
      [<ffffffff8107da51>] ? ns_capable+0x4d/0x65
      [<ffffffff817de5ce>] rtnetlink_rcv_msg+0x181/0x194
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de44d>] ? __rtnl_unlock+0x17/0x17
      [<ffffffff818327c6>] netlink_rcv_skb+0x4d/0x93
      [<ffffffff817de42f>] rtnetlink_rcv+0x26/0x2d
      [<ffffffff81830f18>] netlink_unicast+0xcb/0x150
      [<ffffffff8183198e>] netlink_sendmsg+0x501/0x523
      [<ffffffff8115cba9>] ? might_fault+0x59/0xa9
      [<ffffffff817b5398>] ? copy_from_user+0x2a/0x2c
      [<ffffffff817b7b74>] sock_sendmsg+0x34/0x3c
      [<ffffffff817b7f6d>] ___sys_sendmsg+0x1b8/0x255
      [<ffffffff8115c5eb>] ? handle_pte_fault+0xbd5/0xd4a
      [<ffffffff8100a2b0>] ? native_sched_clock+0x35/0x37
      [<ffffffff8109e94b>] ? sched_clock_local+0x12/0x72
      [<ffffffff8109eb9c>] ? sched_clock_cpu+0x9e/0xb7
      [<ffffffff810cadbf>] ? rcu_read_lock_held+0x3b/0x3d
      [<ffffffff811ac1d8>] ? __fcheck_files+0x4c/0x58
      [<ffffffff811ac946>] ? __fget_light+0x2d/0x52
      [<ffffffff817b8adc>] __sys_sendmsg+0x42/0x60
      [<ffffffff817b8b0c>] SyS_sendmsg+0x12/0x1c
      [<ffffffff81a29e32>] system_call_fastpath+0x12/0x17
    
    Fixes: e7ed828f10bd8 ("netlink: support setting devgroup parameters")
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 2a4e90b18c256d52a7f3f77d58114f6d4e4a7f9f
Author: Denys Vlasenko <dvlasenk@redhat.com>
Date:   Fri May 8 12:26:02 2015 +0200

    x86: Force inlining of atomic ops
    
    With both gcc 4.7.2 and 4.9.2, sometimes gcc mysteriously
    doesn't inline very small functions we expect to be inlined:
    
    $ nm --size-sort vmlinux | grep -iF ' t ' | uniq -c | grep -v '^
    *1 ' | sort -rn     473 000000000000000b t spin_unlock_irqrestore
        449 000000000000005f t rcu_read_unlock
        355 0000000000000009 t atomic_inc                <== THIS
        353 000000000000006e t rcu_read_lock
        350 0000000000000075 t rcu_read_lock_sched_held
        291 000000000000000b t spin_unlock
        266 0000000000000019 t arch_local_irq_restore
        215 000000000000000b t spin_lock
        180 0000000000000011 t kzalloc
        165 0000000000000012 t list_add_tail
        161 0000000000000019 t arch_local_save_flags
        153 0000000000000016 t test_and_set_bit
        134 000000000000000b t spin_unlock_irq
        134 0000000000000009 t atomic_dec                <== THIS
        130 000000000000000b t spin_unlock_bh
        122 0000000000000010 t brelse
        120 0000000000000016 t test_and_clear_bit
        120 000000000000000b t spin_lock_irq
        119 000000000000001e t get_dma_ops
        117 0000000000000053 t cpumask_next
        116 0000000000000036 t kref_get
        114 000000000000001a t schedule_work
        106 000000000000000b t spin_lock_bh
        103 0000000000000019 t arch_local_irq_disable
    ...
    
    Note sizes of marked functions. They are merely 9 bytes long!
    Selecting function with 'atomic' in their names:
    
        355 0000000000000009 t atomic_inc
        134 0000000000000009 t atomic_dec
         98 0000000000000014 t atomic_dec_and_test
         31 000000000000000e t atomic_add_return
         27 000000000000000a t atomic64_inc
         26 000000000000002f t kmap_atomic
         24 0000000000000009 t atomic_add
         12 0000000000000009 t atomic_sub
         10 0000000000000021 t __atomic_add_unless
         10 000000000000000a t atomic64_add
          5 000000000000001f t __atomic_add_unless.constprop.7
          5 000000000000000a t atomic64_dec
          4 000000000000001f t __atomic_add_unless.constprop.18
          4 000000000000001f t __atomic_add_unless.constprop.12
          4 000000000000001f t __atomic_add_unless.constprop.10
          3 000000000000001f t __atomic_add_unless.constprop.13
          3 0000000000000011 t atomic64_add_return
          2 000000000000001f t __atomic_add_unless.constprop.9
          2 000000000000001f t __atomic_add_unless.constprop.8
          2 000000000000001f t __atomic_add_unless.constprop.6
          2 000000000000001f t __atomic_add_unless.constprop.5
          2 000000000000001f t __atomic_add_unless.constprop.3
          2 000000000000001f t __atomic_add_unless.constprop.22
          2 000000000000001f t __atomic_add_unless.constprop.14
          2 000000000000001f t __atomic_add_unless.constprop.11
          2 000000000000001e t atomic_dec_if_positive
          2 0000000000000014 t atomic_inc_and_test
          2 0000000000000011 t atomic_add_return.constprop.4
          2 0000000000000011 t atomic_add_return.constprop.17
          2 0000000000000011 t atomic_add_return.constprop.16
          2 000000000000000d t atomic_inc.constprop.4
          2 000000000000000c t atomic_cmpxchg
    
    This patch fixes this for x86 atomic ops via
    s/inline/__always_inline/. This decreases allyesconfig kernel by
    about 25k:
    
        text     data      bss       dec     hex filename
    82399481 22255416 20627456 125282353 777a831 vmlinux.before
    82375570 22255544 20627456 125258570 7774b4a vmlinux
    
    Signed-off-by: Denys Vlasenko <dvlasenk@redhat.com>
    Cc: Alexei Starovoitov <ast@plumgrid.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@amacapital.net>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Kees Cook <keescook@chromium.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Drewry <wad@chromium.org>
    Link: http://lkml.kernel.org/r/1431080762-17797-1-git-send-email-dvlasenk@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit c190d250d8db5620218d5d56999580ed8488ec24
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Wed Feb 11 03:16:35 2015 +0000

    dcache: Fix locking bugs in backported "deal with deadlock in d_walk()"
    
    commit 20defcec264ceab2630356fb9d397f3d237b5e6d upstream in 3.2-stable
    
    Steven Rostedt reported:
    > Porting -rt to the latest 3.2 stable tree I triggered this bug:
    >
    > =====================================
    > [ BUG: bad unlock balance detected! ]
    > -------------------------------------
    > rm/1638 is trying to release lock (rcu_read_lock) at:
    > [<c04fde6c>] rcu_read_unlock+0x0/0x23
    > but there are no more locks to release!
    >
    > other info that might help us debug this:
    > 2 locks held by rm/1638:
    >  #0:  (&sb->s_type->i_mutex_key#9/1){+.+.+.}, at: [<c04f93eb>] do_rmdir+0x5f/0xd2
    >  #1:  (&sb->s_type->i_mutex_key#9){+.+.+.}, at: [<c04f9329>] vfs_rmdir+0x49/0xac
    >
    > stack backtrace:
    > Pid: 1638, comm: rm Not tainted 3.2.66-test-rt96+ #2
    > Call Trace:
    >  [<c083f390>] ? printk+0x1d/0x1f
    >  [<c0463cdf>] print_unlock_inbalance_bug+0xc3/0xcd
    >  [<c04653a8>] lock_release_non_nested+0x98/0x1ec
    >  [<c046228d>] ? trace_hardirqs_off_caller+0x18/0x90
    >  [<c0456f1c>] ? local_clock+0x2d/0x50
    >  [<c04fde6c>] ? d_hash+0x2f/0x2f
    >  [<c04fde6c>] ? d_hash+0x2f/0x2f
    >  [<c046568e>] lock_release+0x192/0x1ad
    >  [<c04fde83>] rcu_read_unlock+0x17/0x23
    >  [<c04ff344>] shrink_dcache_parent+0x227/0x270
    >  [<c04f9348>] vfs_rmdir+0x68/0xac
    >  [<c04f9424>] do_rmdir+0x98/0xd2
    >  [<c04f03ad>] ? fput+0x1a3/0x1ab
    >  [<c084dd42>] ? sysenter_exit+0xf/0x1a
    >  [<c0465b58>] ? trace_hardirqs_on_caller+0x118/0x149
    >  [<c04fa3e0>] sys_unlinkat+0x2b/0x35
    >  [<c084dd13>] sysenter_do_call+0x12/0x12
    >
    >
    >
    >
    > There's a path to calling rcu_read_unlock() without calling
    > rcu_read_lock() in have_submounts().
    >
    >       goto positive;
    >
    > positive:
    >       if (!locked && read_seqretry(&rename_lock, seq))
    >               goto rename_retry;
    >
    > rename_retry:
    >       rcu_read_unlock();
    >
    > in the above path, rcu_read_lock() is never done before calling
    > rcu_read_unlock();
    
    I reviewed locking contexts in all three functions that I changed when
    backporting "deal with deadlock in d_walk()".  It's actually worse
    than this:
    
    - We don't hold this_parent->d_lock at the 'positive' label in
      have_submounts(), but it is unlocked after 'rename_retry'.
    - There is an rcu_read_unlock() after the 'out' label in
      select_parent(), but it's not held at the 'goto out'.
    
    Fix all three lock imbalances.
    
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Tested-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b0f741c5d11b1b2bafd8392f0cb4d8ac25be9164
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [lizf: Backported to 3.4: adjust context]
    Signed-off-by: Zefan Li <lizefan@huawei.com>

commit c3bd57cd08b19ae8704a5ecdef76dc2a2623d7a4
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon Mar 23 16:31:09 2015 -0700

    net: use for_each_netdev_safe() in rtnl_group_changelink()
    
    commit d079535d5e1bf5e2e7c856bae2483414ea21e137 upstream.
    
    In case we move the whole dev group to another netns,
    we should call for_each_netdev_safe(), otherwise we get
    a soft lockup:
    
     NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [ip:798]
     irq event stamp: 255424
     hardirqs last  enabled at (255423): [<ffffffff81a2aa95>] restore_args+0x0/0x30
     hardirqs last disabled at (255424): [<ffffffff81a2ad5a>] apic_timer_interrupt+0x6a/0x80
     softirqs last  enabled at (255422): [<ffffffff81079ebc>] __do_softirq+0x2c1/0x3a9
     softirqs last disabled at (255417): [<ffffffff8107a190>] irq_exit+0x41/0x95
     CPU: 0 PID: 798 Comm: ip Not tainted 4.0.0-rc4+ #881
     Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
     task: ffff8800d1b88000 ti: ffff880119530000 task.ti: ffff880119530000
     RIP: 0010:[<ffffffff810cad11>]  [<ffffffff810cad11>] debug_lockdep_rcu_enabled+0x28/0x30
     RSP: 0018:ffff880119533778  EFLAGS: 00000246
     RAX: ffff8800d1b88000 RBX: 0000000000000002 RCX: 0000000000000038
     RDX: 0000000000000000 RSI: ffff8800d1b888c8 RDI: ffff8800d1b888c8
     RBP: ffff880119533778 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 000000000000b5c2 R12: 0000000000000246
     R13: ffff880119533708 R14: 00000000001d5a40 R15: ffff88011a7d5a40
     FS:  00007fc01315f740(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: 00007f367a120988 CR3: 000000011849c000 CR4: 00000000000007f0
     Stack:
      ffff880119533798 ffffffff811ac868 ffffffff811ac831 ffffffff811ac828
      ffff8801195337c8 ffffffff811ac8c9 ffff8801195339b0 ffff8801197633e0
      0000000000000000 ffff8801195339b0 ffff8801195337d8 ffffffff811ad2d7
     Call Trace:
      [<ffffffff811ac868>] rcu_read_lock+0x37/0x6e
      [<ffffffff811ac831>] ? rcu_read_unlock+0x5f/0x5f
      [<ffffffff811ac828>] ? rcu_read_unlock+0x56/0x5f
      [<ffffffff811ac8c9>] __fget+0x2a/0x7a
      [<ffffffff811ad2d7>] fget+0x13/0x15
      [<ffffffff811be732>] proc_ns_fget+0xe/0x38
      [<ffffffff817c7714>] get_net_ns_by_fd+0x11/0x59
      [<ffffffff817df359>] rtnl_link_get_net+0x33/0x3e
      [<ffffffff817df3d7>] do_setlink+0x73/0x87b
      [<ffffffff810b28ce>] ? trace_hardirqs_off+0xd/0xf
      [<ffffffff81a2aa95>] ? retint_restore_args+0xe/0xe
      [<ffffffff817e0301>] rtnl_newlink+0x40c/0x699
      [<ffffffff817dffe0>] ? rtnl_newlink+0xeb/0x699
      [<ffffffff81a29246>] ? _raw_spin_unlock+0x28/0x33
      [<ffffffff8143ed1e>] ? security_capable+0x18/0x1a
      [<ffffffff8107da51>] ? ns_capable+0x4d/0x65
      [<ffffffff817de5ce>] rtnetlink_rcv_msg+0x181/0x194
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de44d>] ? __rtnl_unlock+0x17/0x17
      [<ffffffff818327c6>] netlink_rcv_skb+0x4d/0x93
      [<ffffffff817de42f>] rtnetlink_rcv+0x26/0x2d
      [<ffffffff81830f18>] netlink_unicast+0xcb/0x150
      [<ffffffff8183198e>] netlink_sendmsg+0x501/0x523
      [<ffffffff8115cba9>] ? might_fault+0x59/0xa9
      [<ffffffff817b5398>] ? copy_from_user+0x2a/0x2c
      [<ffffffff817b7b74>] sock_sendmsg+0x34/0x3c
      [<ffffffff817b7f6d>] ___sys_sendmsg+0x1b8/0x255
      [<ffffffff8115c5eb>] ? handle_pte_fault+0xbd5/0xd4a
      [<ffffffff8100a2b0>] ? native_sched_clock+0x35/0x37
      [<ffffffff8109e94b>] ? sched_clock_local+0x12/0x72
      [<ffffffff8109eb9c>] ? sched_clock_cpu+0x9e/0xb7
      [<ffffffff810cadbf>] ? rcu_read_lock_held+0x3b/0x3d
      [<ffffffff811ac1d8>] ? __fcheck_files+0x4c/0x58
      [<ffffffff811ac946>] ? __fget_light+0x2d/0x52
      [<ffffffff817b8adc>] __sys_sendmsg+0x42/0x60
      [<ffffffff817b8b0c>] SyS_sendmsg+0x12/0x1c
      [<ffffffff81a29e32>] system_call_fastpath+0x12/0x17
    
    Fixes: e7ed828f10bd8 ("netlink: support setting devgroup parameters")
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Luis Henriques <luis.henriques@canonical.com>

commit 80f03e27a309f3e32ebdd9629ac0320005a2180b
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Mar 24 15:58:52 2015 -0700

    tcp: md5: fix rcu lockdep splat
    
    While timer handler effectively runs a rcu read locked section,
    there is no explicit rcu_read_lock()/rcu_read_unlock() annotations
    and lockdep can be confused here :
    
    net/ipv4/tcp_ipv4.c-906-        /* caller either holds rcu_read_lock() or socket lock */
    net/ipv4/tcp_ipv4.c:907:        md5sig = rcu_dereference_check(tp->md5sig_info,
    net/ipv4/tcp_ipv4.c-908-                                       sock_owned_by_user(sk) ||
    net/ipv4/tcp_ipv4.c-909-                                       lockdep_is_held(&sk->sk_lock.slock));
    
    Let's explicitely acquire rcu_read_lock() in tcp_make_synack()
    
    Before commit fa76ce7328b ("inet: get rid of central tcp/dccp listener
    timer"), we were holding listener lock so lockdep was happy.
    
    Fixes: fa76ce7328b ("inet: get rid of central tcp/dccp listener timer")
    Signed-off-by: Eric DUmazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit d079535d5e1bf5e2e7c856bae2483414ea21e137
Author: WANG Cong <xiyou.wangcong@gmail.com>
Date:   Mon Mar 23 16:31:09 2015 -0700

    net: use for_each_netdev_safe() in rtnl_group_changelink()
    
    In case we move the whole dev group to another netns,
    we should call for_each_netdev_safe(), otherwise we get
    a soft lockup:
    
     NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s! [ip:798]
     irq event stamp: 255424
     hardirqs last  enabled at (255423): [<ffffffff81a2aa95>] restore_args+0x0/0x30
     hardirqs last disabled at (255424): [<ffffffff81a2ad5a>] apic_timer_interrupt+0x6a/0x80
     softirqs last  enabled at (255422): [<ffffffff81079ebc>] __do_softirq+0x2c1/0x3a9
     softirqs last disabled at (255417): [<ffffffff8107a190>] irq_exit+0x41/0x95
     CPU: 0 PID: 798 Comm: ip Not tainted 4.0.0-rc4+ #881
     Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
     task: ffff8800d1b88000 ti: ffff880119530000 task.ti: ffff880119530000
     RIP: 0010:[<ffffffff810cad11>]  [<ffffffff810cad11>] debug_lockdep_rcu_enabled+0x28/0x30
     RSP: 0018:ffff880119533778  EFLAGS: 00000246
     RAX: ffff8800d1b88000 RBX: 0000000000000002 RCX: 0000000000000038
     RDX: 0000000000000000 RSI: ffff8800d1b888c8 RDI: ffff8800d1b888c8
     RBP: ffff880119533778 R08: 0000000000000000 R09: 0000000000000000
     R10: 0000000000000000 R11: 000000000000b5c2 R12: 0000000000000246
     R13: ffff880119533708 R14: 00000000001d5a40 R15: ffff88011a7d5a40
     FS:  00007fc01315f740(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
     CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
     CR2: 00007f367a120988 CR3: 000000011849c000 CR4: 00000000000007f0
     Stack:
      ffff880119533798 ffffffff811ac868 ffffffff811ac831 ffffffff811ac828
      ffff8801195337c8 ffffffff811ac8c9 ffff8801195339b0 ffff8801197633e0
      0000000000000000 ffff8801195339b0 ffff8801195337d8 ffffffff811ad2d7
     Call Trace:
      [<ffffffff811ac868>] rcu_read_lock+0x37/0x6e
      [<ffffffff811ac831>] ? rcu_read_unlock+0x5f/0x5f
      [<ffffffff811ac828>] ? rcu_read_unlock+0x56/0x5f
      [<ffffffff811ac8c9>] __fget+0x2a/0x7a
      [<ffffffff811ad2d7>] fget+0x13/0x15
      [<ffffffff811be732>] proc_ns_fget+0xe/0x38
      [<ffffffff817c7714>] get_net_ns_by_fd+0x11/0x59
      [<ffffffff817df359>] rtnl_link_get_net+0x33/0x3e
      [<ffffffff817df3d7>] do_setlink+0x73/0x87b
      [<ffffffff810b28ce>] ? trace_hardirqs_off+0xd/0xf
      [<ffffffff81a2aa95>] ? retint_restore_args+0xe/0xe
      [<ffffffff817e0301>] rtnl_newlink+0x40c/0x699
      [<ffffffff817dffe0>] ? rtnl_newlink+0xeb/0x699
      [<ffffffff81a29246>] ? _raw_spin_unlock+0x28/0x33
      [<ffffffff8143ed1e>] ? security_capable+0x18/0x1a
      [<ffffffff8107da51>] ? ns_capable+0x4d/0x65
      [<ffffffff817de5ce>] rtnetlink_rcv_msg+0x181/0x194
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de407>] ? rtnl_lock+0x17/0x19
      [<ffffffff817de44d>] ? __rtnl_unlock+0x17/0x17
      [<ffffffff818327c6>] netlink_rcv_skb+0x4d/0x93
      [<ffffffff817de42f>] rtnetlink_rcv+0x26/0x2d
      [<ffffffff81830f18>] netlink_unicast+0xcb/0x150
      [<ffffffff8183198e>] netlink_sendmsg+0x501/0x523
      [<ffffffff8115cba9>] ? might_fault+0x59/0xa9
      [<ffffffff817b5398>] ? copy_from_user+0x2a/0x2c
      [<ffffffff817b7b74>] sock_sendmsg+0x34/0x3c
      [<ffffffff817b7f6d>] ___sys_sendmsg+0x1b8/0x255
      [<ffffffff8115c5eb>] ? handle_pte_fault+0xbd5/0xd4a
      [<ffffffff8100a2b0>] ? native_sched_clock+0x35/0x37
      [<ffffffff8109e94b>] ? sched_clock_local+0x12/0x72
      [<ffffffff8109eb9c>] ? sched_clock_cpu+0x9e/0xb7
      [<ffffffff810cadbf>] ? rcu_read_lock_held+0x3b/0x3d
      [<ffffffff811ac1d8>] ? __fcheck_files+0x4c/0x58
      [<ffffffff811ac946>] ? __fget_light+0x2d/0x52
      [<ffffffff817b8adc>] __sys_sendmsg+0x42/0x60
      [<ffffffff817b8b0c>] SyS_sendmsg+0x12/0x1c
      [<ffffffff81a29e32>] system_call_fastpath+0x12/0x17
    
    Fixes: e7ed828f10bd8 ("netlink: support setting devgroup parameters")
    Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit cc99a310caf811aebbd0986f433d824e4a5e7ce5
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Feb 23 08:59:29 2015 -0800

    rcu: Move rcu_report_unblock_qs_rnp() to common code
    
    The rcu_report_unblock_qs_rnp() function is invoked when the
    last task blocking the current grace period exits its outermost
    RCU read-side critical section.  Previously, this was called only
    from rcu_read_unlock_special(), and was therefore defined only when
    CONFIG_RCU_PREEMPT=y.  However, this function will be invoked even when
    CONFIG_RCU_PREEMPT=n once CPU-hotplug operations are processed only at
    the beginnings of RCU grace periods.  The reason for this change is that
    the last task on a given leaf rcu_node structure's ->blkd_tasks list
    might well exit its RCU read-side critical section between the time that
    recent CPU-hotplug operations were applied and when the new grace period
    was initialized.  This situation could result in RCU waiting forever on
    that leaf rcu_node structure, because if all that structure's CPUs were
    already offline, there would be no quiescent-state events to drive that
    structure's part of the grace period.
    
    This commit therefore moves rcu_report_unblock_qs_rnp() to common code
    that is built unconditionally so that the quiescent-state-forcing code
    can clean up after this situation, avoiding the grace-period stall.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 87c8b28d291de9999e9da2ef5d4165861983eb83
Author: Johan Hedberg <johan.hedberg@intel.com>
Date:   Wed Mar 11 08:55:51 2015 +0200

    Bluetooth: Fix missing rcu_read_unlock() in hci_bdaddr_is_paired()
    
    When finding a matching LTK the rcu_read_unlock() function was failing
    to release the RCU read lock. This patch adds the missing call to
    rcu_reaD_unlock().
    
    Signed-off-by: Johan Hedberg <johan.hedberg@intel.com>
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>

commit a7e53531234dc206bb75abb5305a72665dd4d75d
Author: Alexander Duyck <alexander.h.duyck@redhat.com>
Date:   Wed Mar 4 15:02:44 2015 -0800

    fib_trie: Make fib_table rcu safe
    
    The fib_table was wrapped in several places with an
    rcu_read_lock/rcu_read_unlock however after looking over the code I found
    several spots where the tables were being accessed as just standard
    pointers without any protections.  This change fixes that so that all of
    the proper protections are in place when accessing the table to take RCU
    replacement or removal of the table into account.
    
    Signed-off-by: Alexander Duyck <alexander.h.duyck@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit d24209bb689e2c7f7418faec9b4a948e922d24da
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Jan 21 15:26:03 2015 -0800

    rcu: Improve diagnostics for blocked critical sections in irq
    
    If an RCU read-side critical section occurs within an interrupt handler
    or a softirq handler, it cannot have been preempted.  Therefore, there is
    a check in rcu_read_unlock_special() checking for this error.  However,
    when this check triggers, it lacks diagnostic information.  This commit
    therefore moves rcu_read_unlock()'s lockdep annotation to follow the
    call to __rcu_read_unlock() and changes rcu_read_unlock_special()'s
    WARN_ON_ONCE() to an lockdep_rcu_suspicious() in order to locate where
    the offending RCU read-side critical section began.  In addition, the
    value of the ->rcu_read_unlock_special field is printed.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit c4ce0da8ec62d83c96e29db7dadd6d3985344bb3
Author: Petr Mladek <pmladek@suse.cz>
Date:   Wed Feb 18 18:02:13 2015 +0100

    livepatch: RCU protect struct klp_func all the time when used in klp_ftrace_handler()
    
    func->new_func has been accessed after rcu_read_unlock() in klp_ftrace_handler()
    and therefore the access was not protected.
    
    Signed-off-by: Petr Mladek <pmladek@suse.cz>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>

commit 20defcec264ceab2630356fb9d397f3d237b5e6d
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Wed Feb 11 03:16:35 2015 +0000

    dcache: Fix locking bugs in backported "deal with deadlock in d_walk()"
    
    Steven Rostedt reported:
    > Porting -rt to the latest 3.2 stable tree I triggered this bug:
    >
    > =====================================
    > [ BUG: bad unlock balance detected! ]
    > -------------------------------------
    > rm/1638 is trying to release lock (rcu_read_lock) at:
    > [<c04fde6c>] rcu_read_unlock+0x0/0x23
    > but there are no more locks to release!
    >
    > other info that might help us debug this:
    > 2 locks held by rm/1638:
    >  #0:  (&sb->s_type->i_mutex_key#9/1){+.+.+.}, at: [<c04f93eb>] do_rmdir+0x5f/0xd2
    >  #1:  (&sb->s_type->i_mutex_key#9){+.+.+.}, at: [<c04f9329>] vfs_rmdir+0x49/0xac
    >
    > stack backtrace:
    > Pid: 1638, comm: rm Not tainted 3.2.66-test-rt96+ #2
    > Call Trace:
    >  [<c083f390>] ? printk+0x1d/0x1f
    >  [<c0463cdf>] print_unlock_inbalance_bug+0xc3/0xcd
    >  [<c04653a8>] lock_release_non_nested+0x98/0x1ec
    >  [<c046228d>] ? trace_hardirqs_off_caller+0x18/0x90
    >  [<c0456f1c>] ? local_clock+0x2d/0x50
    >  [<c04fde6c>] ? d_hash+0x2f/0x2f
    >  [<c04fde6c>] ? d_hash+0x2f/0x2f
    >  [<c046568e>] lock_release+0x192/0x1ad
    >  [<c04fde83>] rcu_read_unlock+0x17/0x23
    >  [<c04ff344>] shrink_dcache_parent+0x227/0x270
    >  [<c04f9348>] vfs_rmdir+0x68/0xac
    >  [<c04f9424>] do_rmdir+0x98/0xd2
    >  [<c04f03ad>] ? fput+0x1a3/0x1ab
    >  [<c084dd42>] ? sysenter_exit+0xf/0x1a
    >  [<c0465b58>] ? trace_hardirqs_on_caller+0x118/0x149
    >  [<c04fa3e0>] sys_unlinkat+0x2b/0x35
    >  [<c084dd13>] sysenter_do_call+0x12/0x12
    >
    >
    >
    >
    > There's a path to calling rcu_read_unlock() without calling
    > rcu_read_lock() in have_submounts().
    >
    >       goto positive;
    >
    > positive:
    >       if (!locked && read_seqretry(&rename_lock, seq))
    >               goto rename_retry;
    >
    > rename_retry:
    >       rcu_read_unlock();
    >
    > in the above path, rcu_read_lock() is never done before calling
    > rcu_read_unlock();
    
    I reviewed locking contexts in all three functions that I changed when
    backporting "deal with deadlock in d_walk()".  It's actually worse
    than this:
    
    - We don't hold this_parent->d_lock at the 'positive' label in
      have_submounts(), but it is unlocked after 'rename_retry'.
    - There is an rcu_read_unlock() after the 'out' label in
      select_parent(), but it's not held at the 'goto out'.
    
    Fix all three lock imbalances.
    
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Tested-by: Steven Rostedt <rostedt@goodmis.org>

commit 1a118ccfd60fc78e64c0a3ab9e85075545839d6e
Author: Chao Yu <chao2.yu@samsung.com>
Date:   Wed Feb 11 18:20:38 2015 +0800

    f2fs: use spinlock for segmap_lock instead of rwlock
    
    rwlock can provide better concurrency when there are much more readers than
    writers because readers can hold the rwlock simultaneously.
    
    But now, for segmap_lock rwlock in struct free_segmap_info, there is only one
    reader 'mount' from below call path:
    ->f2fs_fill_super
      ->build_segment_manager
        ->build_dirty_segmap
          ->init_dirty_segmap
            ->find_next_inuse
              read_lock
              ...
              read_unlock
    
    Now that our concurrency can not be improved since there is no other reader for
    this lock, we do not need to use rwlock_t type for segmap_lock, let's replace it
    with spinlock_t type.
    
    Signed-off-by: Chao Yu <chao2.yu@samsung.com>
    Signed-off-by: Jaegeuk Kim <jaegeuk@kernel.org>

commit c0135d07b013fa8f7ba9ec91b4369c372e6a28cb
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Jan 22 22:47:14 2015 -0800

    rcu: Clear need_qs flag to prevent splat
    
    If the scheduling-clock interrupt sets the current tasks need_qs flag,
    but if the current CPU passes through a quiescent state in the meantime,
    then rcu_preempt_qs() will fail to clear the need_qs flag, which can fool
    RCU into thinking that additional rcu_read_unlock_special() processing
    is needed.  This commit therefore clears the need_qs flag before checking
    for additional processing.
    
    For this problem to occur, we need rcu_preempt_data.passed_quiesce equal
    to true and current->rcu_read_unlock_special.b.need_qs also equal to true.
    This condition can occur as follows:
    
    1.      CPU 0 is aware of the current preemptible RCU grace period,
            but has not yet passed through a quiescent state.  Among other
            things, this means that rcu_preempt_data.passed_quiesce is false.
    
    2.      Task A running on CPU 0 enters a preemptible RCU read-side
            critical section.
    
    3.      CPU 0 takes a scheduling-clock interrupt, which notices the
            RCU read-side critical section and the need for a quiescent state,
            and thus sets current->rcu_read_unlock_special.b.need_qs to true.
    
    4.      Task A is preempted, enters the scheduler, eventually invoking
            rcu_preempt_note_context_switch() which in turn invokes
            rcu_preempt_qs().
    
            Because rcu_preempt_data.passed_quiesce is false,
            control enters the body of the "if" statement, which sets
            rcu_preempt_data.passed_quiesce to true.
    
    5.      At this point, CPU 0 takes an interrupt.  The interrupt
            handler contains an RCU read-side critical section, and
            the rcu_read_unlock() notes that current->rcu_read_unlock_special
            is nonzero, and thus invokes rcu_read_unlock_special().
    
    6.      Once in rcu_read_unlock_special(), the fact that
            current->rcu_read_unlock_special.b.need_qs is true becomes
            apparent, so rcu_read_unlock_special() invokes rcu_preempt_qs().
            Recursively, given that we interrupted out of that same
            function in the preceding step.
    
    7.      Because rcu_preempt_data.passed_quiesce is now true,
            rcu_preempt_qs() does nothing, and simply returns.
    
    8.      Upon return to rcu_read_unlock_special(), it is noted that
            current->rcu_read_unlock_special is still nonzero (because
            the interrupted rcu_preempt_qs() had not yet gotten around
            to clearing current->rcu_read_unlock_special.b.need_qs).
    
    9.      Execution proceeds to the WARN_ON_ONCE(), which notes that
            we are in an interrupt handler and thus duly splats.
    
    The solution, as noted above, is to make rcu_read_unlock_special()
    clear out current->rcu_read_unlock_special.b.need_qs after calling
    rcu_preempt_qs().  The interrupted rcu_preempt_qs() will clear it again,
    but this is harmless.  The worst that happens is that we clobber another
    attempt to set this field, but this is not a problem because we just
    got done reporting a quiescent state.
    
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    [ paulmck: Fix embarrassing build bug noted by Sasha Levin. ]
    Tested-by: Sasha Levin <sasha.levin@oracle.com>

commit cbc42af9f6d80d270ce02c6f5daf21afed3fcb71
Author: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Date:   Wed Aug 6 16:05:06 2014 -0700

    vmalloc: use rcu list iterator to reduce vmap_area_lock contention
    
    commit 474750aba88817c53f39424e5567b8e4acc4b39b upstream.
    
    Richard Yao reported a month ago that his system have a trouble with
    vmap_area_lock contention during performance analysis by /proc/meminfo.
    Andrew asked why his analysis checks /proc/meminfo stressfully, but he
    didn't answer it.
    
      https://lkml.org/lkml/2014/4/10/416
    
    Although I'm not sure that this is right usage or not, there is a
    solution reducing vmap_area_lock contention with no side-effect.  That
    is just to use rcu list iterator in get_vmalloc_info().
    
    rcu can be used in this function because all RCU protocol is already
    respected by writers, since Nick Piggin commit db64fe02258f1 ("mm:
    rewrite vmap layer") back in linux-2.6.28
    
    Specifically :
       insertions use list_add_rcu(),
       deletions use list_del_rcu() and kfree_rcu().
    
    Note the rb tree is not used from rcu reader (it would not be safe),
    only the vmap_area_list has full RCU protection.
    
    Note that __purge_vmap_area_lazy() already uses this rcu protection.
    
            rcu_read_lock();
            list_for_each_entry_rcu(va, &vmap_area_list, list) {
                    if (va->flags & VM_LAZY_FREE) {
                            if (va->va_start < *start)
                                    *start = va->va_start;
                            if (va->va_end > *end)
                                    *end = va->va_end;
                            nr += (va->va_end - va->va_start) >> PAGE_SHIFT;
                            list_add_tail(&va->purge_list, &valist);
                            va->flags |= VM_LAZY_FREEING;
                            va->flags &= ~VM_LAZY_FREE;
                    }
            }
            rcu_read_unlock();
    
    Peter:
    
    : While rcu list traversal over the vmap_area_list is safe, this may
    : arrive at different results than the spinlocked version. The rcu list
    : traversal version will not be a 'snapshot' of a single, valid instant
    : of the entire vmap_area_list, but rather a potential amalgam of
    : different list states.
    
    Joonsoo:
    
    : Yes, you are right, but I don't think that we should be strict here.
    : Meminfo is already not a 'snapshot' at specific time.  While we try to get
    : certain stats, the other stats can change.  And, although we may arrive at
    : different results than the spinlocked version, the difference would not be
    : large and would not make serious side-effect.
    
    [edumazet@google.com: add more commit description]
    Signed-off-by: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Reported-by: Richard Yao <ryao@gentoo.org>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Cc: Peter Hurley <peter@hurleysoftware.com>
    Cc: Zhang Yanfei <zhangyanfei.yes@gmail.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec3d07cb630da5da3ccfdf2b2f5472cadedb9470
Author: Namhyung Kim <namhyung@kernel.org>
Date:   Sat Dec 27 14:06:31 2014 +0900

    perf diff: Print diff result more precisely
    
    Current perf diff result is somewhat confusing since it sometimes hide
    small result and sometimes there's no result.  So do not hide small
    result (less than 0.01%) and print "N/A" if baseline is not
    recorded (for ratio and wdiff only).  Blank means the baseline is
    available but its pairs are not.
    
    Before:
    
      # Baseline    Delta  Shared Object      Symbol
      # ........  .......  .................  .........................
      #
           ...
           0.01%   -0.01%  [kernel.kallsyms]  [k] native_write_msr_safe
           0.01%           [kernel.kallsyms]  [k] scheduler_tick
           0.01%           [kernel.kallsyms]  [k] native_read_msr_safe
           0.00%           [kernel.kallsyms]  [k] __rcu_read_unlock
                           [kernel.kallsyms]  [k] _raw_spin_lock
                   +0.01%  [kernel.kallsyms]  [k] apic_timer_interrupt
                           [kernel.kallsyms]  [k] read_tsc
    
    After:
    
      # Baseline    Delta  Shared Object      Symbol
      # ........  .......  .................  .........................
      #
           ...
           0.01%   -0.01%  [kernel.kallsyms]  [k] native_write_msr_safe
           0.01%           [kernel.kallsyms]  [k] scheduler_tick
           0.01%           [kernel.kallsyms]  [k] native_read_msr_safe
           0.00%           [kernel.kallsyms]  [k] __rcu_read_unlock
                   +0.01%  [kernel.kallsyms]  [k] _raw_spin_lock
                   +0.01%  [kernel.kallsyms]  [k] apic_timer_interrupt
                   +0.01%  [kernel.kallsyms]  [k] read_tsc
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Acked-by: Jiri Olsa <jolsa@kernel.org>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: http://lkml.kernel.org/r/1419656793-32756-3-git-send-email-namhyung@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit abaf3f9d275b8d856ae5e47531e40c0bfeac012b
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Tue Nov 18 16:30:01 2014 +0800

    rcu: Revert "Allow post-unlock reference for rt_mutex" to avoid priority-inversion
    
    The patch dfeb9765ce3c ("Allow post-unlock reference for rt_mutex")
    ensured rcu-boost safe even the rt_mutex has post-unlock reference.
    
    But rt_mutex allowing post-unlock reference is definitely a bug and it was
    fixed by the commit 27e35715df54 ("rtmutex: Plug slow unlock race").
    This fix made the previous patch (dfeb9765ce3c) useless.
    
    And even worse, the priority-inversion introduced by the the previous
    patch still exists.
    
    rcu_read_unlock_special() {
            rt_mutex_unlock(&rnp->boost_mtx);
            /* Priority-Inversion:
             * the current task had been deboosted and preempted as a low
             * priority task immediately, it could wait long before reschedule in,
             * and the rcu-booster also waits on this low priority task and sleeps.
             * This priority-inversion makes rcu-booster can't work
             * as expected.
             */
            complete(&rnp->boost_completion);
    }
    
    Just revert the patch to avoid it.
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit d19fb8d1f3f66cc342d30aa48f090c70afb753ed
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Oct 31 12:56:16 2014 -0700

    rcu: Don't migrate blocked tasks even if all corresponding CPUs offline
    
    When the last CPU associated with a given leaf rcu_node structure
    goes offline, something must be done about the tasks queued on that
    rcu_node structure.  Each of these tasks has been preempted on one of
    the leaf rcu_node structure's CPUs while in an RCU read-side critical
    section that it have not yet exited.  Handling these tasks is the job of
    rcu_preempt_offline_tasks(), which migrates them from the leaf rcu_node
    structure to the root rcu_node structure.
    
    Unfortunately, this migration has to be done one task at a time because
    each tasks allegiance must be shifted from the original leaf rcu_node to
    the root, so that future attempts to deal with these tasks will acquire
    the root rcu_node structure's ->lock rather than that of the leaf.
    Worse yet, this migration must be done with interrupts disabled, which
    is not so good for realtime response, especially given that there is
    no bound on the number of tasks on a given rcu_node structure's list.
    (OK, OK, there is a bound, it is just that it is unreasonably large,
    especially on 64-bit systems.)  This was not considered a problem back
    when rcu_preempt_offline_tasks() was first written because realtime
    systems were assumed not to do CPU-hotplug operations while real-time
    applications were running.  This assumption has proved of dubious validity
    given that people are starting to run multiple realtime applications
    on a single SMP system and that it is common practice to offline then
    online a CPU before starting its real-time application in order to clear
    extraneous processing off of that CPU.  So we now need CPU hotplug
    operations to avoid undue latencies.
    
    This commit therefore avoids migrating these tasks, instead letting
    them be dequeued one by one from the original leaf rcu_node structure
    by rcu_read_unlock_special().  This means that the clearing of bits
    from the upper-level rcu_node structures must be deferred until the
    last such task has been dequeued, because otherwise subsequent grace
    periods won't wait on them.  This commit has the beneficial side effect
    of simplifying the CPU-hotplug code for TREE_PREEMPT_RCU, especially in
    CONFIG_RCU_BOOST builds.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit b6a932d1d9840727eee619d455bdeeedaa205be9
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Oct 31 12:05:04 2014 -0700

    rcu: Make rcu_read_unlock_special() propagate ->qsmaskinit bit clearing
    
    This commit causes rcu_read_unlock_special() to propagate ->qsmaskinit
    bit clearing up the rcu_node tree once a given rcu_node structure's
    blkd_tasks list becomes empty.  This is the final commit in preparation
    for the rework of RCU priority boosting:  It enables preempted tasks to
    remain queued on their rcu_node structure even after all of that rcu_node
    structure's CPUs have gone offline.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 8af3a5e78cfb63abe8813743946b7bd5a8a3134c
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Oct 31 11:22:37 2014 -0700

    rcu: Abstract rcu_cleanup_dead_rnp() from rcu_cleanup_dead_cpu()
    
    This commit abstracts rcu_cleanup_dead_rnp() from rcu_cleanup_dead_cpu()
    in preparation for the rework of RCU priority boosting.  This new function
    will be invoked from rcu_read_unlock_special() in the reworked scheme,
    which is why rcu_cleanup_dead_rnp() assumes that the leaf rcu_node
    structure's ->qsmaskinit field has already been updated.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 4af1036df4dd4f0d59fad9d82ed456bfa2e73fa6
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Dec 10 15:45:10 2014 -0800

    proc: task_state: read cred->group_info outside of task_lock()
    
    task_state() reads cred->group_info under task_lock() because a long ago
    it was task_struct->group_info and it was actually protected by
    task->alloc_lock.  Today this task_unlock() after rcu_read_unlock() just
    adds the confusion, move task_unlock() up.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: Aaron Tomlin <atomlin@redhat.com>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>,
    Cc: Sterling Alexander <stalexan@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Roland McGrath <roland@hack.frob.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit c30110608cfba7efff3a5e71914aee7c816115c5
Merge: 9c37f95936b6 d360b78f99e5
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Dec 9 20:23:19 2014 -0800

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     "These are the main changes in this cycle:
    
        - Streamline RCU's use of per-CPU variables, shifting from "cpu"
          arguments to functions to "this_"-style per-CPU variable
          accessors.
    
        - signal-handling RCU updates.
    
        - real-time updates.
    
        - torture-test updates.
    
        - miscellaneous fixes.
    
        - documentation updates"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (34 commits)
      rcu: Fix FIXME in rcu_tasks_kthread()
      rcu: More info about potential deadlocks with rcu_read_unlock()
      rcu: Optimize cond_resched_rcu_qs()
      rcu: Add sparse check for RCU_INIT_POINTER()
      documentation: memory-barriers.txt: Correct example for reorderings
      documentation: Add atomic_long_t to atomic_ops.txt
      documentation: Additional restriction for control dependencies
      documentation: Document RCU self test boot params
      rcutorture: Fix rcu_torture_cbflood() memory leak
      rcutorture: Remove obsolete kversion param in kvm.sh
      rcutorture: Remove stale test configurations
      rcutorture: Enable RCU self test in configs
      rcutorture: Add early boot self tests
      torture: Run Linux-kernel binary out of results directory
      cpu: Avoid puts_pending overflow
      rcu: Remove "cpu" argument to rcu_cleanup_after_idle()
      rcu: Remove "cpu" argument to rcu_prepare_for_idle()
      rcu: Remove "cpu" argument to rcu_needs_cpu()
      rcu: Remove "cpu" argument to rcu_note_context_switch()
      rcu: Remove "cpu" argument to rcu_preempt_check_callbacks()
      ...

commit 9cdfe2c709c4f6076249ced6844b2bea420739c4
Author: David L Stevens <david.stevens@oracle.com>
Date:   Mon Dec 8 21:46:09 2014 -0500

    sunvnet: fix incorrect rcu_read_unlock() in vnet_start_xmit()
    
    This patch removes an extra rcu_read_unlock() on an allocation failure
    in vnet_skb_shape(). The needed rcu_read_unlock() is already done in
    the out_dropped label.
    
    Reported-by: Rashmi Narasimhan <rashmi.narasimhan@oracle.com>
    Signed-off-by: David L Stevens <david.stevens@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4290973d9aa3a5ff64acb03e004762260e8271a4
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb upstream.
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Guillaume Nault <g.nault@alphalink.fr>
    Signed-off-by: Zefan Li <lizefan@huawei.com>

commit 856839b76836a2ee524a8638f568275da57f719c
Author: Eunbong Song <eunb.song@samsung.com>
Date:   Wed Oct 22 06:39:56 2014 +0000

    MIPS: Add arch_trigger_all_cpu_backtrace() function
    
    Currently, arch_trigger_all_cpu_backtrace() is defined in only x86 and
    sparc which have an NMI.  But in case of softlockup, it could be possible
    to dump backtrace of all cpus. and this could be helpful for debugging.
    
    for example, if system has 2 cpus.
    
            CPU 0                           CPU 1
     acquire read_lock()
    
                                    try to do write_lock()
    
     ,,,
     missing read_unlock()
    
    In this case, softlockup will occur becasuse CPU 0 does not call
    read_unlock().  And dump_stack() print only backtrace for "CPU 0". If
    CPU1's backtrace is printed it's very helpful.
    
    [ralf@linux-mips.org: Fixed whitespace and formatting issues.]
    
    Signed-off-by: Ralf Baechle <ralf@linux-mips.org>
    Cc: linux-mips@linux-mips.org
    Cc: linux-kernel@vger.kernel.org
    Patchwork: https://patchwork.linux-mips.org/patch/8200/

commit 237d7b2521815c41c245ca22219f4cca2ec75058
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    (cherry picked from commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74)
    Signed-off-by: Willy Tarreau <w@1wt.eu>

commit 35e95fae72ddb67ef94395d99abc48589ce17875
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Josh Boyer <jwboyer@fedoraproject.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e36b6ac9e011205eb7ad3af329dbd27a21bacd50
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Josh Boyer <jwboyer@fedoraproject.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cda702df4736ab981f81ea4b529d14a2858fdc36
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Josh Boyer <jwboyer@fedoraproject.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bbd951a21e0fd555cd9ede44c7196af09d04d171
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Josh Boyer <jwboyer@fedoraproject.org>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit ce36f2f3eb6613a73bc6f3a5256bde7dd3f95710
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Sun Sep 28 23:44:21 2014 +0200

    rcu: More info about potential deadlocks with rcu_read_unlock()
    
    The comment above rcu_read_unlock() explains the potential deadlock
    if the caller holds one of the locks taken by rt_mutex_unlock() paths,
    but it is not clear from this documentation that any lock which can
    be taken from interrupt can lead to deadlock as well and we need to
    take rt_mutex_lock() into account too.
    
    The problem is that rt_mutex_lock() takes wait_lock without disabling
    irqs, and thus an interrupt taking some LOCK can obviously race with
    rcu_read_unlock_special() called with the same LOCK held.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 240432f953757528abd23c5f76abfb092f05fc86
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Luis Henriques <luis.henriques@canonical.com>

commit d21385fadabf249afd2e288a1eae1f093ce9fa38
Merge: 6f6e741f6de5 df20286ab1e3
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Nov 10 21:05:43 2014 -0500

    Merge branch 'sunvnet-next'
    
    Sowmini Varadhan says:
    
    ====================
    sunvnet: edge-case/race-conditions bug fixes
    
    This patch series contains fixes for race-conditions in sunvnet,
    that can encountered when there is a difference in latency between
    producer and consumer.
    
    Patch 1 addresses a case when the STOPPED LDC ack from a peer is
    processed before vnet_start_xmit can finish updating the dr->prod
    state.
    
    Patch 2 fixes the edge-case when outgoing data and incoming
    stopped-ack cross each other in flight.
    
    Patch 3 adds a missing rcu_read_unlock(), found by code-inspection.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit df20286ab1e36eaaf1f6c7e5e2c56bea1ffc26c0
Author: Sowmini Varadhan <sowmini.varadhan@oracle.com>
Date:   Sat Nov 8 20:42:20 2014 -0500

    sunvnet: Add missing rcu_read_unlock() in vnet_start_xmit
    
    The out_dropped label will only do rcu_read_unlock for non-null port.
    So add the missing rcu_read_unlock() when bailing due to non-null port.
    
    Signed-off-by: Sowmini Varadhan <sowmini.varadhan@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 544bd1bf08f824dc972832fba6d92b34a5a93f69
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb upstream.
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit aa001b043dde50e2856fe9460bc819d2a70dc309
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74 upstream.
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2:
     - Adjust context
     - sctp_sf_violation_paramlen() doesn't take a struct net * parameter]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 8d09d4afe2735d152447903f521623dc54ddafa4
Author: David Matlack <dmatlack@google.com>
Date:   Mon Aug 18 15:46:06 2014 -0700

    kvm: fix potentially corrupt mmio cache
    
    commit ee3d1570b58677885b4552bce8217fda7b226a68 upstream.
    
    vcpu exits and memslot mutations can run concurrently as long as the
    vcpu does not aquire the slots mutex. Thus it is theoretically possible
    for memslots to change underneath a vcpu that is handling an exit.
    
    If we increment the memslot generation number again after
    synchronize_srcu_expedited(), vcpus can safely cache memslot generation
    without maintaining a single rcu_dereference through an entire vm exit.
    And much of the x86/kvm code does not maintain a single rcu_dereference
    of the current memslots during each exit.
    
    We can prevent the following case:
    
       vcpu (CPU 0)                             | thread (CPU 1)
    --------------------------------------------+--------------------------
    1  vm exit                                  |
    2  srcu_read_unlock(&kvm->srcu)             |
    3  decide to cache something based on       |
         old memslots                           |
    4                                           | change memslots
                                                | (increments generation)
    5                                           | synchronize_srcu(&kvm->srcu);
    6  retrieve generation # from new memslots  |
    7  tag cache with new memslot generation    |
    8  srcu_read_unlock(&kvm->srcu)             |
    ...                                         |
       <action based on cache occurs even       |
        though the caching decision was based   |
        on the old memslots>                    |
    ...                                         |
       <action *continues* to occur until next  |
        memslot generation change, which may    |
        be never>                               |
                                                |
    
    By incrementing the generation after synchronizing with kvm->srcu readers,
    we ensure that the generation retrieved in (6) will become invalid soon
    after (8).
    
    Keeping the existing increment is not strictly necessary, but we
    do keep it and just move it for consistency from update_memslots to
    install_new_memslots.  It invalidates old cached MMIOs immediately,
    instead of having to wait for the end of synchronize_srcu_expedited,
    which makes the code more clearly correct in case CPU 1 is preempted
    right after synchronize_srcu() returns.
    
    To avoid halving the generation space in SPTEs, always presume that the
    low bit of the generation is zero when reconstructing a generation number
    out of an SPTE.  This effectively disables MMIO caching in SPTEs during
    the call to synchronize_srcu_expedited.  Using the low bit this way is
    somewhat like a seqcount---where the protected thing is a cache, and
    instead of retrying we can simply punt if we observe the low bit to be 1.
    
    Signed-off-by: David Matlack <dmatlack@google.com>
    Reviewed-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Reviewed-by: David Matlack <dmatlack@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit f0d0762945b54220e4dc34672f8841918a81cd95
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 29 08:54:52 2014 -0400

    shrink_dentry_list(): take parent's ->d_lock earlier
    
    commit 046b961b45f93a92e4c70525a12f3d378bced130 upstream.
    
    The cause of livelocks there is that we are taking ->d_lock on
    dentry and its parent in the wrong order, forcing us to use
    trylock on the parent's one.  d_walk() takes them in the right
    order, and unfortunately it's not hard to create a situation
    when shrink_dentry_list() can't make progress since trylock
    keeps failing, and shrink_dcache_parent() or check_submounts_and_drop()
    keeps calling d_walk() disrupting the very shrink_dentry_list() it's
    waiting for.
    
    Solution is straightforward - if that trylock fails, let's unlock
    the dentry itself and take locks in the right order.  We need to
    stabilize ->d_parent without holding ->d_lock, but that's doable
    using RCU.  And we'd better do that in the very beginning of the
    loop in shrink_dentry_list(), since the checks on refcount, etc.
    would need to be redone anyway.
    
    That deals with a half of the problem - killing dentries on the
    shrink list itself.  Another one (dropping their parents) is
    in the next commit.
    
    locking parent is interesting - it would be easy to do rcu_read_lock(),
    lock whatever we think is a parent, lock dentry itself and check
    if the parent is still the right one.  Except that we need to check
    that *before* locking the dentry, or we are risking taking ->d_lock
    out of order.  Fortunately, once the D1 is locked, we can check if
    D2->d_parent is equal to D1 without the need to lock D2; D2->d_parent
    can start or stop pointing to D1 only under D1->d_lock, so taking
    D1->d_lock is enough.  In other words, the right solution is
    rcu_read_lock/lock what looks like parent right now/check if it's
    still our parent/rcu_read_unlock/lock the child.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit 0e31fc03c3475a0f336106926ecb577cdd1b7324
Author: David Matlack <dmatlack@google.com>
Date:   Mon Aug 18 15:46:06 2014 -0700

    kvm: fix potentially corrupt mmio cache
    
    commit ee3d1570b58677885b4552bce8217fda7b226a68 upstream.
    
    vcpu exits and memslot mutations can run concurrently as long as the
    vcpu does not aquire the slots mutex. Thus it is theoretically possible
    for memslots to change underneath a vcpu that is handling an exit.
    
    If we increment the memslot generation number again after
    synchronize_srcu_expedited(), vcpus can safely cache memslot generation
    without maintaining a single rcu_dereference through an entire vm exit.
    And much of the x86/kvm code does not maintain a single rcu_dereference
    of the current memslots during each exit.
    
    We can prevent the following case:
    
       vcpu (CPU 0)                             | thread (CPU 1)
    --------------------------------------------+--------------------------
    1  vm exit                                  |
    2  srcu_read_unlock(&kvm->srcu)             |
    3  decide to cache something based on       |
         old memslots                           |
    4                                           | change memslots
                                                | (increments generation)
    5                                           | synchronize_srcu(&kvm->srcu);
    6  retrieve generation # from new memslots  |
    7  tag cache with new memslot generation    |
    8  srcu_read_unlock(&kvm->srcu)             |
    ...                                         |
       <action based on cache occurs even       |
        though the caching decision was based   |
        on the old memslots>                    |
    ...                                         |
       <action *continues* to occur until next  |
        memslot generation change, which may    |
        be never>                               |
                                                |
    
    By incrementing the generation after synchronizing with kvm->srcu readers,
    we ensure that the generation retrieved in (6) will become invalid soon
    after (8).
    
    Keeping the existing increment is not strictly necessary, but we
    do keep it and just move it for consistency from update_memslots to
    install_new_memslots.  It invalidates old cached MMIOs immediately,
    instead of having to wait for the end of synchronize_srcu_expedited,
    which makes the code more clearly correct in case CPU 1 is preempted
    right after synchronize_srcu() returns.
    
    To avoid halving the generation space in SPTEs, always presume that the
    low bit of the generation is zero when reconstructing a generation number
    out of an SPTE.  This effectively disables MMIO caching in SPTEs during
    the call to synchronize_srcu_expedited.  Using the low bit this way is
    somewhat like a seqcount---where the protected thing is a cache, and
    instead of retrying we can simply punt if we observe the low bit to be 1.
    
    Signed-off-by: David Matlack <dmatlack@google.com>
    Reviewed-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Reviewed-by: David Matlack <dmatlack@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 553de4db2e53d670bad8c23bbc181bca7e9fbaf8
Author: David Matlack <dmatlack@google.com>
Date:   Mon Aug 18 15:46:06 2014 -0700

    kvm: fix potentially corrupt mmio cache
    
    commit ee3d1570b58677885b4552bce8217fda7b226a68 upstream.
    
    vcpu exits and memslot mutations can run concurrently as long as the
    vcpu does not aquire the slots mutex. Thus it is theoretically possible
    for memslots to change underneath a vcpu that is handling an exit.
    
    If we increment the memslot generation number again after
    synchronize_srcu_expedited(), vcpus can safely cache memslot generation
    without maintaining a single rcu_dereference through an entire vm exit.
    And much of the x86/kvm code does not maintain a single rcu_dereference
    of the current memslots during each exit.
    
    We can prevent the following case:
    
       vcpu (CPU 0)                             | thread (CPU 1)
    --------------------------------------------+--------------------------
    1  vm exit                                  |
    2  srcu_read_unlock(&kvm->srcu)             |
    3  decide to cache something based on       |
         old memslots                           |
    4                                           | change memslots
                                                | (increments generation)
    5                                           | synchronize_srcu(&kvm->srcu);
    6  retrieve generation # from new memslots  |
    7  tag cache with new memslot generation    |
    8  srcu_read_unlock(&kvm->srcu)             |
    ...                                         |
       <action based on cache occurs even       |
        though the caching decision was based   |
        on the old memslots>                    |
    ...                                         |
       <action *continues* to occur until next  |
        memslot generation change, which may    |
        be never>                               |
                                                |
    
    By incrementing the generation after synchronizing with kvm->srcu readers,
    we ensure that the generation retrieved in (6) will become invalid soon
    after (8).
    
    Keeping the existing increment is not strictly necessary, but we
    do keep it and just move it for consistency from update_memslots to
    install_new_memslots.  It invalidates old cached MMIOs immediately,
    instead of having to wait for the end of synchronize_srcu_expedited,
    which makes the code more clearly correct in case CPU 1 is preempted
    right after synchronize_srcu() returns.
    
    To avoid halving the generation space in SPTEs, always presume that the
    low bit of the generation is zero when reconstructing a generation number
    out of an SPTE.  This effectively disables MMIO caching in SPTEs during
    the call to synchronize_srcu_expedited.  Using the low bit this way is
    somewhat like a seqcount---where the protected thing is a cache, and
    instead of retrying we can simply punt if we observe the low bit to be 1.
    
    Signed-off-by: David Matlack <dmatlack@google.com>
    Reviewed-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Reviewed-by: David Matlack <dmatlack@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 55eb96ec53e7b041f10ffcc7b1442a31d89d4488
Author: David Matlack <dmatlack@google.com>
Date:   Mon Aug 18 15:46:06 2014 -0700

    kvm: fix potentially corrupt mmio cache
    
    commit ee3d1570b58677885b4552bce8217fda7b226a68 upstream.
    
    vcpu exits and memslot mutations can run concurrently as long as the
    vcpu does not aquire the slots mutex. Thus it is theoretically possible
    for memslots to change underneath a vcpu that is handling an exit.
    
    If we increment the memslot generation number again after
    synchronize_srcu_expedited(), vcpus can safely cache memslot generation
    without maintaining a single rcu_dereference through an entire vm exit.
    And much of the x86/kvm code does not maintain a single rcu_dereference
    of the current memslots during each exit.
    
    We can prevent the following case:
    
       vcpu (CPU 0)                             | thread (CPU 1)
    --------------------------------------------+--------------------------
    1  vm exit                                  |
    2  srcu_read_unlock(&kvm->srcu)             |
    3  decide to cache something based on       |
         old memslots                           |
    4                                           | change memslots
                                                | (increments generation)
    5                                           | synchronize_srcu(&kvm->srcu);
    6  retrieve generation # from new memslots  |
    7  tag cache with new memslot generation    |
    8  srcu_read_unlock(&kvm->srcu)             |
    ...                                         |
       <action based on cache occurs even       |
        though the caching decision was based   |
        on the old memslots>                    |
    ...                                         |
       <action *continues* to occur until next  |
        memslot generation change, which may    |
        be never>                               |
                                                |
    
    By incrementing the generation after synchronizing with kvm->srcu readers,
    we ensure that the generation retrieved in (6) will become invalid soon
    after (8).
    
    Keeping the existing increment is not strictly necessary, but we
    do keep it and just move it for consistency from update_memslots to
    install_new_memslots.  It invalidates old cached MMIOs immediately,
    instead of having to wait for the end of synchronize_srcu_expedited,
    which makes the code more clearly correct in case CPU 1 is preempted
    right after synchronize_srcu() returns.
    
    To avoid halving the generation space in SPTEs, always presume that the
    low bit of the generation is zero when reconstructing a generation number
    out of an SPTE.  This effectively disables MMIO caching in SPTEs during
    the call to synchronize_srcu_expedited.  Using the low bit this way is
    somewhat like a seqcount---where the protected thing is a cache, and
    instead of retrying we can simply punt if we observe the low bit to be 1.
    
    Signed-off-by: David Matlack <dmatlack@google.com>
    Reviewed-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Reviewed-by: David Matlack <dmatlack@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1effd9f19324efb05fccc7421530e11a52db0278
Author: Kirill Tkhai <ktkhai@parallels.com>
Date:   Wed Oct 22 11:17:11 2014 +0400

    sched/numa: Fix unsafe get_task_struct() in task_numa_assign()
    
    Unlocked access to dst_rq->curr in task_numa_compare() is racy.
    If curr task is exiting this may be a reason of use-after-free:
    
    task_numa_compare()                    do_exit()
        ...                                        current->flags |= PF_EXITING;
        ...                                    release_task()
        ...                                        ~~delayed_put_task_struct()~~
        ...                                    schedule()
        rcu_read_lock()                        ...
        cur = ACCESS_ONCE(dst_rq->curr)        ...
            ...                                rq->curr = next;
            ...                                    context_switch()
            ...                                        finish_task_switch()
            ...                                            put_task_struct()
            ...                                                __put_task_struct()
            ...                                                    free_task_struct()
            task_numa_assign()                                     ...
                get_task_struct()                                  ...
    
    As noted by Oleg:
    
      <<The lockless get_task_struct(tsk) is only safe if tsk == current
        and didn't pass exit_notify(), or if this tsk was found on a rcu
        protected list (say, for_each_process() or find_task_by_vpid()).
        IOW, it is only safe if release_task() was not called before we
        take rcu_read_lock(), in this case we can rely on the fact that
        delayed_put_pid() can not drop the (potentially) last reference
        until rcu_read_unlock().
    
        And as Kirill pointed out task_numa_compare()->task_numa_assign()
        path does get_task_struct(dst_rq->curr) and this is not safe. The
        task_struct itself can't go away, but rcu_read_lock() can't save
        us from the final put_task_struct() in finish_task_switch(); this
        reference goes away without rcu gp>>
    
    The patch provides simple check of PF_EXITING flag. If it's not set,
    this guarantees that call_rcu() of delayed_put_task_struct() callback
    hasn't happened yet, so we can safely do get_task_struct() in
    task_numa_assign().
    
    Locked dst_rq->lock protects from concurrency with the last schedule().
    Reusing or unmapping of cur's memory may happen without it.
    
    Suggested-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Kirill Tkhai <ktkhai@parallels.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Link: http://lkml.kernel.org/r/1413962231.19914.130.camel@tkhai
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 048b4e83910547178851bef4c47cf40d015ad9eb
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    [ Upstream commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb ]
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit e9d3d9a67d94617c23e3fbafa3e580741634f6bd
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    [ Upstream commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb ]
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5f3a420dd93a9e4ac8f7b0a05c57f2bf0fd1761c
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    [ Upstream commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb ]
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 696c5d5f340f57bf1085bc7cc95937d2349988cb
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    [ Upstream commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb ]
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9de7922bc709eee2f609cd01d98aaedc4cf5ea74
Author: Daniel Borkmann <dborkman@redhat.com>
Date:   Thu Oct 9 22:55:31 2014 +0200

    net: sctp: fix skb_over_panic when receiving malformed ASCONF chunks
    
    Commit 6f4c618ddb0 ("SCTP : Add paramters validity check for
    ASCONF chunk") added basic verification of ASCONF chunks, however,
    it is still possible to remotely crash a server by sending a
    special crafted ASCONF chunk, even up to pre 2.6.12 kernels:
    
    skb_over_panic: text:ffffffffa01ea1c3 len:31056 put:30768
     head:ffff88011bd81800 data:ffff88011bd81800 tail:0x7950
     end:0x440 dev:<NULL>
     ------------[ cut here ]------------
    kernel BUG at net/core/skbuff.c:129!
    [...]
    Call Trace:
     <IRQ>
     [<ffffffff8144fb1c>] skb_put+0x5c/0x70
     [<ffffffffa01ea1c3>] sctp_addto_chunk+0x63/0xd0 [sctp]
     [<ffffffffa01eadaf>] sctp_process_asconf+0x1af/0x540 [sctp]
     [<ffffffff8152d025>] ? _read_unlock_bh+0x15/0x20
     [<ffffffffa01e0038>] sctp_sf_do_asconf+0x168/0x240 [sctp]
     [<ffffffffa01e3751>] sctp_do_sm+0x71/0x1210 [sctp]
     [<ffffffff8147645d>] ? fib_rules_lookup+0xad/0xf0
     [<ffffffffa01e6b22>] ? sctp_cmp_addr_exact+0x32/0x40 [sctp]
     [<ffffffffa01e8393>] sctp_assoc_bh_rcv+0xd3/0x180 [sctp]
     [<ffffffffa01ee986>] sctp_inq_push+0x56/0x80 [sctp]
     [<ffffffffa01fcc42>] sctp_rcv+0x982/0xa10 [sctp]
     [<ffffffffa01d5123>] ? ipt_local_in_hook+0x23/0x28 [iptable_filter]
     [<ffffffff8148bdc9>] ? nf_iterate+0x69/0xb0
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff8148bf86>] ? nf_hook_slow+0x76/0x120
     [<ffffffff81496d10>] ? ip_local_deliver_finish+0x0/0x2d0
     [<ffffffff81496ded>] ip_local_deliver_finish+0xdd/0x2d0
     [<ffffffff81497078>] ip_local_deliver+0x98/0xa0
     [<ffffffff8149653d>] ip_rcv_finish+0x12d/0x440
     [<ffffffff81496ac5>] ip_rcv+0x275/0x350
     [<ffffffff8145c88b>] __netif_receive_skb+0x4ab/0x750
     [<ffffffff81460588>] netif_receive_skb+0x58/0x60
    
    This can be triggered e.g., through a simple scripted nmap
    connection scan injecting the chunk after the handshake, for
    example, ...
    
      -------------- INIT[ASCONF; ASCONF_ACK] ------------->
      <----------- INIT-ACK[ASCONF; ASCONF_ACK] ------------
      -------------------- COOKIE-ECHO -------------------->
      <-------------------- COOKIE-ACK ---------------------
      ------------------ ASCONF; UNKNOWN ------------------>
    
    ... where ASCONF chunk of length 280 contains 2 parameters ...
    
      1) Add IP address parameter (param length: 16)
      2) Add/del IP address parameter (param length: 255)
    
    ... followed by an UNKNOWN chunk of e.g. 4 bytes. Here, the
    Address Parameter in the ASCONF chunk is even missing, too.
    This is just an example and similarly-crafted ASCONF chunks
    could be used just as well.
    
    The ASCONF chunk passes through sctp_verify_asconf() as all
    parameters passed sanity checks, and after walking, we ended
    up successfully at the chunk end boundary, and thus may invoke
    sctp_process_asconf(). Parameter walking is done with
    WORD_ROUND() to take padding into account.
    
    In sctp_process_asconf()'s TLV processing, we may fail in
    sctp_process_asconf_param() e.g., due to removal of the IP
    address that is also the source address of the packet containing
    the ASCONF chunk, and thus we need to add all TLVs after the
    failure to our ASCONF response to remote via helper function
    sctp_add_asconf_response(), which basically invokes a
    sctp_addto_chunk() adding the error parameters to the given
    skb.
    
    When walking to the next parameter this time, we proceed
    with ...
    
      length = ntohs(asconf_param->param_hdr.length);
      asconf_param = (void *)asconf_param + length;
    
    ... instead of the WORD_ROUND()'ed length, thus resulting here
    in an off-by-one that leads to reading the follow-up garbage
    parameter length of 12336, and thus throwing an skb_over_panic
    for the reply when trying to sctp_addto_chunk() next time,
    which implicitly calls the skb_put() with that length.
    
    Fix it by using sctp_walk_params() [ which is also used in
    INIT parameter processing ] macro in the verification *and*
    in ASCONF processing: it will make sure we don't spill over,
    that we walk parameters WORD_ROUND()'ed. Moreover, we're being
    more defensive and guard against unknown parameter types and
    missized addresses.
    
    Joint work with Vlad Yasevich.
    
    Fixes: b896b82be4ae ("[SCTP] ADDIP: Support for processing incoming ASCONF_ACK chunks.")
    Signed-off-by: Daniel Borkmann <dborkman@redhat.com>
    Signed-off-by: Vlad Yasevich <vyasevich@gmail.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1e203c1a2c104c8f8030245d2afaa337a79b4375
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Thu Oct 2 22:43:09 2014 -0700

    net: sched: suspicious RCU usage in qdisc_watchdog
    
    Suspicious RCU usage in qdisc_watchdog call needs to be done inside
    rcu_read_lock/rcu_read_unlock. And then Qdisc destroy operations
    need to ensure timer is cancelled before removing qdisc structure.
    
    [ 3992.191339] ===============================
    [ 3992.191340] [ INFO: suspicious RCU usage. ]
    [ 3992.191343] 3.17.0-rc6net-next+ #72 Not tainted
    [ 3992.191345] -------------------------------
    [ 3992.191347] include/net/sch_generic.h:272 suspicious rcu_dereference_check() usage!
    [ 3992.191348]
    [ 3992.191348] other info that might help us debug this:
    [ 3992.191348]
    [ 3992.191351]
    [ 3992.191351] rcu_scheduler_active = 1, debug_locks = 1
    [ 3992.191353] no locks held by swapper/1/0.
    [ 3992.191355]
    [ 3992.191355] stack backtrace:
    [ 3992.191358] CPU: 1 PID: 0 Comm: swapper/1 Not tainted 3.17.0-rc6net-next+ #72
    [ 3992.191360] Hardware name:                  /DZ77RE-75K, BIOS GAZ7711H.86A.0060.2012.1115.1750 11/15/2012
    [ 3992.191362]  0000000000000001 ffff880235803e48 ffffffff8178f92c 0000000000000000
    [ 3992.191366]  ffff8802322224a0 ffff880235803e78 ffffffff810c9966 ffff8800a5fe3000
    [ 3992.191370]  ffff880235803f30 ffff8802359cd768 ffff8802359cd6e0 ffff880235803e98
    [ 3992.191374] Call Trace:
    [ 3992.191376]  <IRQ>  [<ffffffff8178f92c>] dump_stack+0x4e/0x68
    [ 3992.191387]  [<ffffffff810c9966>] lockdep_rcu_suspicious+0xe6/0x130
    [ 3992.191392]  [<ffffffff8167213a>] qdisc_watchdog+0x8a/0xb0
    [ 3992.191396]  [<ffffffff810f93f2>] __run_hrtimer+0x72/0x420
    [ 3992.191399]  [<ffffffff810f9bcd>] ? hrtimer_interrupt+0x7d/0x240
    [ 3992.191403]  [<ffffffff816720b0>] ? tc_classify+0xc0/0xc0
    [ 3992.191406]  [<ffffffff810f9c4f>] hrtimer_interrupt+0xff/0x240
    [ 3992.191410]  [<ffffffff8109e4a5>] ? __atomic_notifier_call_chain+0x5/0x140
    [ 3992.191415]  [<ffffffff8103577b>] local_apic_timer_interrupt+0x3b/0x60
    [ 3992.191419]  [<ffffffff8179c2b5>] smp_apic_timer_interrupt+0x45/0x60
    [ 3992.191422]  [<ffffffff8179a6bf>] apic_timer_interrupt+0x6f/0x80
    [ 3992.191424]  <EOI>  [<ffffffff815ed233>] ? cpuidle_enter_state+0x73/0x2e0
    [ 3992.191432]  [<ffffffff815ed22e>] ? cpuidle_enter_state+0x6e/0x2e0
    [ 3992.191437]  [<ffffffff815ed567>] cpuidle_enter+0x17/0x20
    [ 3992.191441]  [<ffffffff810c0741>] cpu_startup_entry+0x3d1/0x4a0
    [ 3992.191445]  [<ffffffff81106fc6>] ? clockevents_config_and_register+0x26/0x30
    [ 3992.191448]  [<ffffffff81033c16>] start_secondary+0x1b6/0x260
    
    Fixes: b26b0d1e8b1 ("net: qdisc: use rcu prefix and silence sparse warnings")
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Cong Wang <cwang@twopensource.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 788a2f69f9b8b77b30ace8d1ef9380fa4ea5c6ec
Author: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Date:   Thu Aug 28 19:35:38 2014 +0100

    vmalloc: use rcu list iterator to reduce vmap_area_lock contention
    
    commit 474750aba88817c53f39424e5567b8e4acc4b39b upstream.
    
    Richard Yao reported a month ago that his system have a trouble with
    vmap_area_lock contention during performance analysis by /proc/meminfo.
    Andrew asked why his analysis checks /proc/meminfo stressfully, but he
    didn't answer it.
    
      https://lkml.org/lkml/2014/4/10/416
    
    Although I'm not sure that this is right usage or not, there is a
    solution reducing vmap_area_lock contention with no side-effect.  That
    is just to use rcu list iterator in get_vmalloc_info().
    
    rcu can be used in this function because all RCU protocol is already
    respected by writers, since Nick Piggin commit db64fe02258f1 ("mm:
    rewrite vmap layer") back in linux-2.6.28
    
    Specifically :
       insertions use list_add_rcu(),
       deletions use list_del_rcu() and kfree_rcu().
    
    Note the rb tree is not used from rcu reader (it would not be safe),
    only the vmap_area_list has full RCU protection.
    
    Note that __purge_vmap_area_lazy() already uses this rcu protection.
    
            rcu_read_lock();
            list_for_each_entry_rcu(va, &vmap_area_list, list) {
                    if (va->flags & VM_LAZY_FREE) {
                            if (va->va_start < *start)
                                    *start = va->va_start;
                            if (va->va_end > *end)
                                    *end = va->va_end;
                            nr += (va->va_end - va->va_start) >> PAGE_SHIFT;
                            list_add_tail(&va->purge_list, &valist);
                            va->flags |= VM_LAZY_FREEING;
                            va->flags &= ~VM_LAZY_FREE;
                    }
            }
            rcu_read_unlock();
    
    Peter:
    
    : While rcu list traversal over the vmap_area_list is safe, this may
    : arrive at different results than the spinlocked version. The rcu list
    : traversal version will not be a 'snapshot' of a single, valid instant
    : of the entire vmap_area_list, but rather a potential amalgam of
    : different list states.
    
    Joonsoo:
    
    : Yes, you are right, but I don't think that we should be strict here.
    : Meminfo is already not a 'snapshot' at specific time.  While we try to get
    : certain stats, the other stats can change.  And, although we may arrive at
    : different results than the spinlocked version, the difference would not be
    : large and would not make serious side-effect.
    
    [edumazet@google.com: add more commit description]
    Signed-off-by: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Reported-by: Richard Yao <ryao@gentoo.org>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Cc: Peter Hurley <peter@hurleysoftware.com>
    Cc: Zhang Yanfei <zhangyanfei.yes@gmail.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Mel Gorman <mgorman@suse.de>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit 952313bd62589cae216a579bb7ebc76f8e290817
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Fri Sep 12 20:06:26 2014 -0700

    net: sched: cls_cgroup use RCU
    
    Make cgroup classifier safe for RCU.
    
    Also drops the calls in the classify routine that were doing a
    rcu_read_lock()/rcu_read_unlock(). If the rcu_read_lock() isn't held
    entering this routine we have issues with deleting the classifier
    chain so remove the unnecessary rcu_read_lock()/rcu_read_unlock()
    pair noting all paths AFAIK hold rcu_read_lock.
    
    If there is a case where classify is called without the rcu read lock
    then an rcu splat will occur and we can correct it.
    
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c7953ef23042b7c4fc2be5ecdd216aacff6df5eb
Author: John Fastabend <john.fastabend@gmail.com>
Date:   Fri Sep 12 20:06:26 2014 -0700

    net: sched: cls_cgroup use RCU
    
    Make cgroup classifier safe for RCU.
    
    Also drops the calls in the classify routine that were doing a
    rcu_read_lock()/rcu_read_unlock(). If the rcu_read_lock() isn't held
    entering this routine we have issues with deleting the classifier
    chain so remove the unnecessary rcu_read_lock()/rcu_read_unlock()
    pair noting all paths AFAIK hold rcu_read_lock.
    
    If there is a case where classify is called without the rcu read lock
    then an rcu splat will occur and we can correct it.
    
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1d082fd061884a587c490c4fc8a2056ce1e47624
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Aug 14 16:01:53 2014 -0700

    rcu: Remove local_irq_disable() in rcu_preempt_note_context_switch()
    
    The rcu_preempt_note_context_switch() function is on a scheduling fast
    path, so it would be good to avoid disabling irqs.  The reason that irqs
    are disabled is to synchronize process-level and irq-handler access to
    the task_struct ->rcu_read_unlock_special bitmask.  This commit therefore
    makes ->rcu_read_unlock_special instead be a union of bools with a short
    allowing single-access checks in RCU's __rcu_read_unlock().  This results
    in the process-level and irq-handler accesses being simple loads and
    stores, so that irqs need no longer be disabled.  This commit therefore
    removes the irq disabling from rcu_preempt_note_context_switch().
    
    Reported-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 3f95aa81d265223fdb13ea2b59883766a05adbdf
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Aug 4 06:10:23 2014 -0700

    rcu: Make TASKS_RCU handle tasks that are almost done exiting
    
    Once a task has passed exit_notify() in the do_exit() code path, it
    is no longer on the task lists, and is therefore no longer visible
    to rcu_tasks_kthread().  This means that an almost-exited task might
    be preempted while within a trampoline, and this task won't be waited
    on by rcu_tasks_kthread().  This commit fixes this bug by adding an
    srcu_struct.  An exiting task does srcu_read_lock() just before calling
    exit_notify(), and does the corresponding srcu_read_unlock() after
    doing the final preempt_disable().  This means that rcu_tasks_kthread()
    can do synchronize_srcu() to wait for all mostly-exited tasks to reach
    their final preempt_disable() region, and then use synchronize_sched()
    to wait for those tasks to finish exiting.
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Suggested-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit eed4d839b0cdf9d84b0a9bc63de90fd5e1e886fb
Author: Guillaume Nault <g.nault@alphalink.fr>
Date:   Wed Sep 3 14:12:55 2014 +0200

    l2tp: fix race while getting PMTU on PPP pseudo-wire
    
    Use dst_entry held by sk_dst_get() to retrieve tunnel's PMTU.
    
    The dst_mtu(__sk_dst_get(tunnel->sock)) call was racy. __sk_dst_get()
    could return NULL if tunnel->sock->sk_dst_cache was reset just before the
    call, thus making dst_mtu() dereference a NULL pointer:
    
    [ 1937.661598] BUG: unable to handle kernel NULL pointer dereference at 0000000000000020
    [ 1937.664005] IP: [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] PGD daf0c067 PUD d9f93067 PMD 0
    [ 1937.664005] Oops: 0000 [#1] SMP
    [ 1937.664005] Modules linked in: l2tp_ppp l2tp_netlink l2tp_core ip6table_filter ip6_tables iptable_filter ip_tables ebtable_nat ebtables x_tables udp_tunnel pppoe pppox ppp_generic slhc deflate ctr twofish_generic twofish_x86_64_3way xts lrw gf128mul glue_helper twofish_x86_64 twofish_common blowfish_generic blowfish_x86_64 blowfish_common des_generic cbc xcbc rmd160 sha512_generic hmac crypto_null af_key xfrm_algo 8021q garp bridge stp llc tun atmtcp clip atm ext3 mbcache jbd iTCO_wdt coretemp kvm_intel iTCO_vendor_support kvm pcspkr evdev ehci_pci lpc_ich mfd_core i5400_edac edac_core i5k_amb shpchp button processor thermal_sys xfs crc32c_generic libcrc32c dm_mod usbhid sg hid sr_mod sd_mod cdrom crc_t10dif crct10dif_common ata_generic ahci ata_piix tg3 libahci libata uhci_hcd ptp ehci_hcd pps_core usbcore scsi_mod libphy usb_common [last unloaded: l2tp_core]
    [ 1937.664005] CPU: 0 PID: 10022 Comm: l2tpstress Tainted: G           O   3.17.0-rc1 #1
    [ 1937.664005] Hardware name: HP ProLiant DL160 G5, BIOS O12 08/22/2008
    [ 1937.664005] task: ffff8800d8fda790 ti: ffff8800c43c4000 task.ti: ffff8800c43c4000
    [ 1937.664005] RIP: 0010:[<ffffffffa049db88>]  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005] RSP: 0018:ffff8800c43c7de8  EFLAGS: 00010282
    [ 1937.664005] RAX: ffff8800da8a7240 RBX: ffff8800d8c64600 RCX: 000001c325a137b5
    [ 1937.664005] RDX: 8c6318c6318c6320 RSI: 000000000000010c RDI: 0000000000000000
    [ 1937.664005] RBP: ffff8800c43c7ea8 R08: 0000000000000000 R09: 0000000000000000
    [ 1937.664005] R10: ffffffffa048e2c0 R11: ffff8800d8c64600 R12: ffff8800ca7a5000
    [ 1937.664005] R13: ffff8800c439bf40 R14: 000000000000000c R15: 0000000000000009
    [ 1937.664005] FS:  00007fd7f610f700(0000) GS:ffff88011a600000(0000) knlGS:0000000000000000
    [ 1937.664005] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    [ 1937.664005] CR2: 0000000000000020 CR3: 00000000d9d75000 CR4: 00000000000027e0
    [ 1937.664005] Stack:
    [ 1937.664005]  ffffffffa049da80 ffff8800d8fda790 000000000000005b ffff880000000009
    [ 1937.664005]  ffff8800daf3f200 0000000000000003 ffff8800c43c7e48 ffffffff81109b57
    [ 1937.664005]  ffffffff81109b0e ffffffff8114c566 0000000000000000 0000000000000000
    [ 1937.664005] Call Trace:
    [ 1937.664005]  [<ffffffffa049da80>] ? pppol2tp_connect+0x235/0x41e [l2tp_ppp]
    [ 1937.664005]  [<ffffffff81109b57>] ? might_fault+0x9e/0xa5
    [ 1937.664005]  [<ffffffff81109b0e>] ? might_fault+0x55/0xa5
    [ 1937.664005]  [<ffffffff8114c566>] ? rcu_read_unlock+0x1c/0x26
    [ 1937.664005]  [<ffffffff81309196>] SYSC_connect+0x87/0xb1
    [ 1937.664005]  [<ffffffff813e56f7>] ? sysret_check+0x1b/0x56
    [ 1937.664005]  [<ffffffff8107590d>] ? trace_hardirqs_on_caller+0x145/0x1a1
    [ 1937.664005]  [<ffffffff81213dee>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 1937.664005]  [<ffffffff8114c262>] ? spin_lock+0x9/0xb
    [ 1937.664005]  [<ffffffff813092b4>] SyS_connect+0x9/0xb
    [ 1937.664005]  [<ffffffff813e56d2>] system_call_fastpath+0x16/0x1b
    [ 1937.664005] Code: 10 2a 84 81 e8 65 76 bd e0 65 ff 0c 25 10 bb 00 00 4d 85 ed 74 37 48 8b 85 60 ff ff ff 48 8b 80 88 01 00 00 48 8b b8 10 02 00 00 <48> 8b 47 20 ff 50 20 85 c0 74 0f 83 e8 28 89 83 10 01 00 00 89
    [ 1937.664005] RIP  [<ffffffffa049db88>] pppol2tp_connect+0x33d/0x41e [l2tp_ppp]
    [ 1937.664005]  RSP <ffff8800c43c7de8>
    [ 1937.664005] CR2: 0000000000000020
    [ 1939.559375] ---[ end trace 82d44500f28f8708 ]---
    
    Fixes: f34c4a35d879 ("l2tp: take PMTU from tunnel UDP socket")
    Signed-off-by: Guillaume Nault <g.nault@alphalink.fr>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ee3d1570b58677885b4552bce8217fda7b226a68
Author: David Matlack <dmatlack@google.com>
Date:   Mon Aug 18 15:46:06 2014 -0700

    kvm: fix potentially corrupt mmio cache
    
    vcpu exits and memslot mutations can run concurrently as long as the
    vcpu does not aquire the slots mutex. Thus it is theoretically possible
    for memslots to change underneath a vcpu that is handling an exit.
    
    If we increment the memslot generation number again after
    synchronize_srcu_expedited(), vcpus can safely cache memslot generation
    without maintaining a single rcu_dereference through an entire vm exit.
    And much of the x86/kvm code does not maintain a single rcu_dereference
    of the current memslots during each exit.
    
    We can prevent the following case:
    
       vcpu (CPU 0)                             | thread (CPU 1)
    --------------------------------------------+--------------------------
    1  vm exit                                  |
    2  srcu_read_unlock(&kvm->srcu)             |
    3  decide to cache something based on       |
         old memslots                           |
    4                                           | change memslots
                                                | (increments generation)
    5                                           | synchronize_srcu(&kvm->srcu);
    6  retrieve generation # from new memslots  |
    7  tag cache with new memslot generation    |
    8  srcu_read_unlock(&kvm->srcu)             |
    ...                                         |
       <action based on cache occurs even       |
        though the caching decision was based   |
        on the old memslots>                    |
    ...                                         |
       <action *continues* to occur until next  |
        memslot generation change, which may    |
        be never>                               |
                                                |
    
    By incrementing the generation after synchronizing with kvm->srcu readers,
    we ensure that the generation retrieved in (6) will become invalid soon
    after (8).
    
    Keeping the existing increment is not strictly necessary, but we
    do keep it and just move it for consistency from update_memslots to
    install_new_memslots.  It invalidates old cached MMIOs immediately,
    instead of having to wait for the end of synchronize_srcu_expedited,
    which makes the code more clearly correct in case CPU 1 is preempted
    right after synchronize_srcu() returns.
    
    To avoid halving the generation space in SPTEs, always presume that the
    low bit of the generation is zero when reconstructing a generation number
    out of an SPTE.  This effectively disables MMIO caching in SPTEs during
    the call to synchronize_srcu_expedited.  Using the low bit this way is
    somewhat like a seqcount---where the protected thing is a cache, and
    instead of retrying we can simply punt if we observe the low bit to be 1.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: David Matlack <dmatlack@google.com>
    Reviewed-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Reviewed-by: David Matlack <dmatlack@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>

commit 474750aba88817c53f39424e5567b8e4acc4b39b
Author: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Date:   Wed Aug 6 16:05:06 2014 -0700

    vmalloc: use rcu list iterator to reduce vmap_area_lock contention
    
    Richard Yao reported a month ago that his system have a trouble with
    vmap_area_lock contention during performance analysis by /proc/meminfo.
    Andrew asked why his analysis checks /proc/meminfo stressfully, but he
    didn't answer it.
    
      https://lkml.org/lkml/2014/4/10/416
    
    Although I'm not sure that this is right usage or not, there is a
    solution reducing vmap_area_lock contention with no side-effect.  That
    is just to use rcu list iterator in get_vmalloc_info().
    
    rcu can be used in this function because all RCU protocol is already
    respected by writers, since Nick Piggin commit db64fe02258f1 ("mm:
    rewrite vmap layer") back in linux-2.6.28
    
    Specifically :
       insertions use list_add_rcu(),
       deletions use list_del_rcu() and kfree_rcu().
    
    Note the rb tree is not used from rcu reader (it would not be safe),
    only the vmap_area_list has full RCU protection.
    
    Note that __purge_vmap_area_lazy() already uses this rcu protection.
    
            rcu_read_lock();
            list_for_each_entry_rcu(va, &vmap_area_list, list) {
                    if (va->flags & VM_LAZY_FREE) {
                            if (va->va_start < *start)
                                    *start = va->va_start;
                            if (va->va_end > *end)
                                    *end = va->va_end;
                            nr += (va->va_end - va->va_start) >> PAGE_SHIFT;
                            list_add_tail(&va->purge_list, &valist);
                            va->flags |= VM_LAZY_FREEING;
                            va->flags &= ~VM_LAZY_FREE;
                    }
            }
            rcu_read_unlock();
    
    Peter:
    
    : While rcu list traversal over the vmap_area_list is safe, this may
    : arrive at different results than the spinlocked version. The rcu list
    : traversal version will not be a 'snapshot' of a single, valid instant
    : of the entire vmap_area_list, but rather a potential amalgam of
    : different list states.
    
    Joonsoo:
    
    : Yes, you are right, but I don't think that we should be strict here.
    : Meminfo is already not a 'snapshot' at specific time.  While we try to get
    : certain stats, the other stats can change.  And, although we may arrive at
    : different results than the spinlocked version, the difference would not be
    : large and would not make serious side-effect.
    
    [edumazet@google.com: add more commit description]
    Signed-off-by: Joonsoo Kim <iamjoonsoo.kim@lge.com>
    Reported-by: Richard Yao <ryao@gentoo.org>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Cc: Peter Hurley <peter@hurleysoftware.com>
    Cc: Zhang Yanfei <zhangyanfei.yes@gmail.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 5bda4f638f36ef4c4e3b1397b02affc3db94356e
Merge: a45c657f28f8 01c9db827146
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Aug 4 15:55:08 2014 -0700

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU changes from Ingo Molar:
     "The main changes:
    
       - torture-test updates
       - callback-offloading changes
       - maintainership changes
       - update RCU documentation
       - miscellaneous fixes"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (32 commits)
      rcu: Allow for NULL tick_nohz_full_mask when nohz_full= missing
      rcu: Fix a sparse warning in rcu_report_unblock_qs_rnp()
      rcu: Fix a sparse warning in rcu_initiate_boost()
      rcu: Fix __rcu_reclaim() to use true/false for bool
      rcu: Remove CONFIG_PROVE_RCU_DELAY
      rcu: Use __this_cpu_read() instead of per_cpu_ptr()
      rcu: Don't use NMIs to dump other CPUs' stacks
      rcu: Bind grace-period kthreads to non-NO_HZ_FULL CPUs
      rcu: Simplify priority boosting by putting rt_mutex in rcu_node
      rcu: Check both root and current rcu_node when setting up future grace period
      rcu: Allow post-unlock reference for rt_mutex
      rcu: Loosen __call_rcu()'s rcu_head alignment constraint
      rcu: Eliminate read-modify-write ACCESS_ONCE() calls
      rcu: Remove redundant ACCESS_ONCE() from tick_do_timer_cpu
      rcu: Make rcu node arrays static const char * const
      signal: Explain local_irq_save() call
      rcu: Handle obsolete references to TINY_PREEMPT_RCU
      rcu: Document deadlock-avoidance information for rcu_read_unlock()
      scripts: Teach get_maintainer.pl about the new "R:" tag
      rcu: Update rcu torture maintainership filename patterns
      ...

commit 70df70927b75eb86f12b14167c398b99dc3a56e4
Author: Lars Ellenberg <lars.ellenberg@linbit.com>
Date:   Fri Dec 20 11:17:02 2013 +0100

    drbd: allow write-ordering policy to be bumped up again
    
    Previously, once you disabled flushes as a means of enforcing
    write-ordering, you'd need to detach/re-attach to enable them again.
    
    Allow drbdsetup disk-options to re-enable previously disabled
    write-ordering policy options at runtime.
    
    While at it fix RCU in drbd_bump_write_ordering()
    max_allowed_wo() uses rcu_dereference, therefore it must
    be called within rcu_read_lock()/rcu_read_unlock()
    
    Signed-off-by: Philipp Reisner <philipp.reisner@linbit.com>
    Signed-off-by: Lars Ellenberg <lars.ellenberg@linbit.com>

commit c41247e1d4864c863ee25e029dd53acdb2abc000
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon May 5 08:18:30 2014 -0700

    signal: Explain local_irq_save() call
    
    The explicit local_irq_save() in __lock_task_sighand() is needed to avoid
    a potential deadlock condition, as noted in a841796f11c90d53 (signal:
    align __lock_task_sighand() irq disabling and RCU).  However, someone
    reading the code might be forgiven for concluding that this separate
    local_irq_save() was completely unnecessary.  This commit therefore adds
    a comment referencing the shiny new block comment on rcu_read_unlock().
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Oleg Nesterov <oleg@redhat.com>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

commit f27bc4873fa8b75cc1eba7b641eda7375dc72ccf
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun May 4 15:38:38 2014 -0700

    rcu: Document deadlock-avoidance information for rcu_read_unlock()
    
    Reported-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

commit ee9a33b2631edb50e3cd2937af7c0f9add5d2e2c
Author: Li RongQing <roy.qing.li@gmail.com>
Date:   Fri Jun 20 17:32:36 2014 +0800

    cxgb4: Not need to hold the adap_rcu_lock lock when read adap_rcu_list
    
    cxgb4_netdev maybe lead to dead lock, since it uses a spin lock, and be called
    in both thread and softirq context, but not disable BH, the lockdep report is
    below; In fact, cxgb4_netdev only reads adap_rcu_list with RCU protection, so
    not need to hold spin lock again.
            =================================
            [ INFO: inconsistent lock state ]
            3.14.7+ #24 Tainted: G         C O
            ---------------------------------
            inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
            radvd/3794 [HC0[0]:SC1[1]:HE1:SE0] takes:
             (adap_rcu_lock){+.?...}, at: [<ffffffffa09989ea>] clip_add+0x2c/0x116 [cxgb4]
            {SOFTIRQ-ON-W} state was registered at:
              [<ffffffff810fca81>] __lock_acquire+0x34a/0xe48
              [<ffffffff810fd98b>] lock_acquire+0x82/0x9d
              [<ffffffff815d6ff8>] _raw_spin_lock+0x34/0x43
              [<ffffffffa09989ea>] clip_add+0x2c/0x116 [cxgb4]
              [<ffffffffa0998beb>] cxgb4_inet6addr_handler+0x117/0x12c [cxgb4]
              [<ffffffff815da98b>] notifier_call_chain+0x32/0x5c
              [<ffffffff815da9f9>] __atomic_notifier_call_chain+0x44/0x6e
              [<ffffffff815daa32>] atomic_notifier_call_chain+0xf/0x11
              [<ffffffff815b1356>] inet6addr_notifier_call_chain+0x16/0x18
              [<ffffffffa01f72e5>] ipv6_add_addr+0x404/0x46e [ipv6]
              [<ffffffffa01f8df0>] addrconf_add_linklocal+0x5f/0x95 [ipv6]
              [<ffffffffa01fc3e9>] addrconf_notify+0x632/0x841 [ipv6]
              [<ffffffff815da98b>] notifier_call_chain+0x32/0x5c
              [<ffffffff810e09a1>] __raw_notifier_call_chain+0x9/0xb
              [<ffffffff810e09b2>] raw_notifier_call_chain+0xf/0x11
              [<ffffffff8151b3b7>] call_netdevice_notifiers_info+0x4e/0x56
              [<ffffffff8151b3d0>] call_netdevice_notifiers+0x11/0x13
              [<ffffffff8151c0a6>] netdev_state_change+0x1f/0x38
              [<ffffffff8152f004>] linkwatch_do_dev+0x3b/0x49
              [<ffffffff8152f184>] __linkwatch_run_queue+0x10b/0x144
              [<ffffffff8152f1dd>] linkwatch_event+0x20/0x27
              [<ffffffff810d7bc0>] process_one_work+0x1cb/0x2ee
              [<ffffffff810d7e3b>] worker_thread+0x12e/0x1fc
              [<ffffffff810dd391>] kthread+0xc4/0xcc
              [<ffffffff815dc48c>] ret_from_fork+0x7c/0xb0
            irq event stamp: 3388
            hardirqs last  enabled at (3388): [<ffffffff810c6c85>]
            __local_bh_enable_ip+0xaa/0xd9
            hardirqs last disabled at (3387): [<ffffffff810c6c2d>]
            __local_bh_enable_ip+0x52/0xd9
            softirqs last  enabled at (3288): [<ffffffffa01f1d5b>]
            rcu_read_unlock_bh+0x0/0x2f [ipv6]
            softirqs last disabled at (3289): [<ffffffff815ddafc>]
            do_softirq_own_stack+0x1c/0x30
    
            other info that might help us debug this:
             Possible unsafe locking scenario:
    
                   CPU0
                   ----
              lock(adap_rcu_lock);
              <Interrupt>
                lock(adap_rcu_lock);
    
             *** DEADLOCK ***
    
            5 locks held by radvd/3794:
             #0:  (sk_lock-AF_INET6){+.+.+.}, at: [<ffffffffa020b85a>]
            rawv6_sendmsg+0x74b/0xa4d [ipv6]
             #1:  (rcu_read_lock){.+.+..}, at: [<ffffffff8151ac6b>]
            rcu_lock_acquire+0x0/0x29
             #2:  (rcu_read_lock){.+.+..}, at: [<ffffffffa01f4cca>]
            rcu_lock_acquire.constprop.16+0x0/0x30 [ipv6]
             #3:  (rcu_read_lock){.+.+..}, at: [<ffffffff810e09b4>]
            rcu_lock_acquire+0x0/0x29
             #4:  (rcu_read_lock){.+.+..}, at: [<ffffffffa0998782>]
            rcu_lock_acquire.constprop.40+0x0/0x30 [cxgb4]
    
            stack backtrace:
            CPU: 7 PID: 3794 Comm: radvd Tainted: G         C O 3.14.7+ #24
            Hardware name: Supermicro X7DBU/X7DBU, BIOS 6.00 12/03/2007
             ffffffff81f15990 ffff88012fdc36a8 ffffffff815d0016 0000000000000006
             ffff8800c80dc2a0 ffff88012fdc3708 ffffffff815cc727 0000000000000001
             0000000000000001 ffff880100000000 ffffffff81015b02 ffff8800c80dcb58
            Call Trace:
             <IRQ>  [<ffffffff815d0016>] dump_stack+0x4e/0x71
             [<ffffffff815cc727>] print_usage_bug+0x1ec/0x1fd
             [<ffffffff81015b02>] ? save_stack_trace+0x27/0x44
             [<ffffffff810fbfaa>] ? check_usage_backwards+0xa0/0xa0
             [<ffffffff810fc640>] mark_lock+0x11b/0x212
             [<ffffffff810fca0b>] __lock_acquire+0x2d4/0xe48
             [<ffffffff810fbfaa>] ? check_usage_backwards+0xa0/0xa0
             [<ffffffff810fbff6>] ? check_usage_forwards+0x4c/0xa6
             [<ffffffff810c6c8a>] ? __local_bh_enable_ip+0xaf/0xd9
             [<ffffffff810fd98b>] lock_acquire+0x82/0x9d
             [<ffffffffa09989ea>] ? clip_add+0x2c/0x116 [cxgb4]
             [<ffffffffa0998782>] ? rcu_read_unlock+0x23/0x23 [cxgb4]
             [<ffffffff815d6ff8>] _raw_spin_lock+0x34/0x43
             [<ffffffffa09989ea>] ? clip_add+0x2c/0x116 [cxgb4]
             [<ffffffffa09987b0>] ? rcu_lock_acquire.constprop.40+0x2e/0x30 [cxgb4]
             [<ffffffffa0998782>] ? rcu_read_unlock+0x23/0x23 [cxgb4]
             [<ffffffffa09989ea>] clip_add+0x2c/0x116 [cxgb4]
             [<ffffffffa0998beb>] cxgb4_inet6addr_handler+0x117/0x12c [cxgb4]
             [<ffffffff810fd99d>] ? lock_acquire+0x94/0x9d
             [<ffffffff810e09b4>] ? raw_notifier_call_chain+0x11/0x11
             [<ffffffff815da98b>] notifier_call_chain+0x32/0x5c
             [<ffffffff815da9f9>] __atomic_notifier_call_chain+0x44/0x6e
             [<ffffffff815daa32>] atomic_notifier_call_chain+0xf/0x11
             [<ffffffff815b1356>] inet6addr_notifier_call_chain+0x16/0x18
             [<ffffffffa01f72e5>] ipv6_add_addr+0x404/0x46e [ipv6]
             [<ffffffff810fde6a>] ? trace_hardirqs_on+0xd/0xf
             [<ffffffffa01fb634>] addrconf_prefix_rcv+0x385/0x6ea [ipv6]
             [<ffffffffa0207950>] ndisc_rcv+0x9d3/0xd76 [ipv6]
             [<ffffffffa020d536>] icmpv6_rcv+0x592/0x67b [ipv6]
             [<ffffffff810c6c85>] ? __local_bh_enable_ip+0xaa/0xd9
             [<ffffffff810c6c85>] ? __local_bh_enable_ip+0xaa/0xd9
             [<ffffffff810fd8dc>] ? lock_release+0x14e/0x17b
             [<ffffffffa020df97>] ? rcu_read_unlock+0x21/0x23 [ipv6]
             [<ffffffff8150df52>] ? rcu_read_unlock+0x23/0x23
             [<ffffffffa01f4ede>] ip6_input_finish+0x1e4/0x2fc [ipv6]
             [<ffffffffa01f540b>] ip6_input+0x33/0x38 [ipv6]
             [<ffffffffa01f5557>] ip6_mc_input+0x147/0x160 [ipv6]
             [<ffffffffa01f4ba3>] ip6_rcv_finish+0x7c/0x81 [ipv6]
             [<ffffffffa01f5397>] ipv6_rcv+0x3a1/0x3e2 [ipv6]
             [<ffffffff8151ef96>] __netif_receive_skb_core+0x4ab/0x511
             [<ffffffff810fdc94>] ? mark_held_locks+0x71/0x99
             [<ffffffff8151f0c0>] ? process_backlog+0x69/0x15e
             [<ffffffff8151f045>] __netif_receive_skb+0x49/0x5b
             [<ffffffff8151f0cf>] process_backlog+0x78/0x15e
             [<ffffffff8151f571>] ? net_rx_action+0x1a2/0x1cc
             [<ffffffff8151f47b>] net_rx_action+0xac/0x1cc
             [<ffffffff810c69b7>] ? __do_softirq+0xad/0x218
             [<ffffffff810c69ff>] __do_softirq+0xf5/0x218
             [<ffffffff815ddafc>] do_softirq_own_stack+0x1c/0x30
             <EOI>  [<ffffffff810c6bb6>] do_softirq+0x38/0x5d
             [<ffffffffa01f1d5b>] ? ip6_copy_metadata+0x156/0x156 [ipv6]
             [<ffffffff810c6c78>] __local_bh_enable_ip+0x9d/0xd9
             [<ffffffffa01f1d88>] rcu_read_unlock_bh+0x2d/0x2f [ipv6]
             [<ffffffffa01f28b4>] ip6_finish_output2+0x381/0x3d8 [ipv6]
             [<ffffffffa01f49ef>] ip6_finish_output+0x6e/0x73 [ipv6]
             [<ffffffffa01f4a70>] ip6_output+0x7c/0xa8 [ipv6]
             [<ffffffff815b1bfa>] dst_output+0x18/0x1c
             [<ffffffff815b1c9e>] ip6_local_out+0x1c/0x21
             [<ffffffffa01f2489>] ip6_push_pending_frames+0x37d/0x427 [ipv6]
             [<ffffffff81558af8>] ? skb_orphan+0x39/0x39
             [<ffffffffa020b85a>] ? rawv6_sendmsg+0x74b/0xa4d [ipv6]
             [<ffffffffa020ba51>] rawv6_sendmsg+0x942/0xa4d [ipv6]
             [<ffffffff81584cd2>] inet_sendmsg+0x3d/0x66
             [<ffffffff81508930>] __sock_sendmsg_nosec+0x25/0x27
             [<ffffffff8150b0d7>] sock_sendmsg+0x5a/0x7b
             [<ffffffff810fd8dc>] ? lock_release+0x14e/0x17b
             [<ffffffff8116d756>] ? might_fault+0x9e/0xa5
             [<ffffffff8116d70d>] ? might_fault+0x55/0xa5
             [<ffffffff81508cb1>] ? copy_from_user+0x2a/0x2c
             [<ffffffff8150b70c>] ___sys_sendmsg+0x226/0x2d9
             [<ffffffff810fcd25>] ? __lock_acquire+0x5ee/0xe48
             [<ffffffff810fde01>] ? trace_hardirqs_on_caller+0x145/0x1a1
             [<ffffffff8118efcb>] ? slab_free_hook.isra.71+0x50/0x59
             [<ffffffff8115c81f>] ? release_pages+0xbc/0x181
             [<ffffffff810fd99d>] ? lock_acquire+0x94/0x9d
             [<ffffffff81115e97>] ? read_seqcount_begin.constprop.25+0x73/0x90
             [<ffffffff8150c408>] __sys_sendmsg+0x3d/0x5b
             [<ffffffff8150c433>] SyS_sendmsg+0xd/0x19
             [<ffffffff815dc53d>] system_call_fastpath+0x1a/0x1f
    
    Reported-by: Ben Greear <greearb@candelatech.com>
    Cc: Casey Leedom <leedom@chelsio.com>
    Cc: Hariprasad Shenai <hariprasad@chelsio.com>
    Signed-off-by: Li RongQing <roy.qing.li@gmail.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Acked-by: Casey Leedom <leedom@chelsio.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 046b961b45f93a92e4c70525a12f3d378bced130
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Thu May 29 08:54:52 2014 -0400

    shrink_dentry_list(): take parent's ->d_lock earlier
    
    The cause of livelocks there is that we are taking ->d_lock on
    dentry and its parent in the wrong order, forcing us to use
    trylock on the parent's one.  d_walk() takes them in the right
    order, and unfortunately it's not hard to create a situation
    when shrink_dentry_list() can't make progress since trylock
    keeps failing, and shrink_dcache_parent() or check_submounts_and_drop()
    keeps calling d_walk() disrupting the very shrink_dentry_list() it's
    waiting for.
    
    Solution is straightforward - if that trylock fails, let's unlock
    the dentry itself and take locks in the right order.  We need to
    stabilize ->d_parent without holding ->d_lock, but that's doable
    using RCU.  And we'd better do that in the very beginning of the
    loop in shrink_dentry_list(), since the checks on refcount, etc.
    would need to be redone anyway.
    
    That deals with a half of the problem - killing dentries on the
    shrink list itself.  Another one (dropping their parents) is
    in the next commit.
    
    locking parent is interesting - it would be easy to do rcu_read_lock(),
    lock whatever we think is a parent, lock dentry itself and check
    if the parent is still the right one.  Except that we need to check
    that *before* locking the dentry, or we are risking taking ->d_lock
    out of order.  Fortunately, once the D1 is locked, we can check if
    D2->d_parent is equal to D1 without the need to lock D2; D2->d_parent
    can start or stop pointing to D1 only under D1->d_lock, so taking
    D1->d_lock is enough.  In other words, the right solution is
    rcu_read_lock/lock what looks like parent right now/check if it's
    still our parent/rcu_read_unlock/lock the child.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 6f3eabcd041aa062cfabd2fc62194a33b507f51c
Author: Phoebe Buckheister <phoebe.buckheister@itwm.fraunhofer.de>
Date:   Tue May 20 13:14:22 2014 +0200

    mac802154: llsec: fix incorrect lock pairing
    
    In encrypt, sec->lock is taken with read_lock_bh, so in the error path,
    we must read_unlock_bh.
    
    Signed-off-by: Phoebe Buckheister <phoebe.buckheister@itwm.fraunhofer.de>
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 8663707a797e6a473c32cf08eb7597543bbdae79
Author: Nicolas Dichtel <nicolas.dichtel@6wind.com>
Date:   Fri Nov 8 11:13:55 2013 +0100

    sctp: unbalanced rcu lock in ip_queue_xmit()
    
    The bug was introduced in 2.6.32.61 by commit b8710128e201 ("inet: add RCU
    protection to inet->opt") (it's a backport of upstream commit f6d8bd051c39).
    
    In SCTP case, packet is already routed, hence we jump to the label
    'packet_routed', but without rcu_read_lock(). After this label,
    rcu_read_unlock() is called unconditionally.
    
    Spotted-by: Guo Fengtian <fengtian.guo@6wind.com>
    Signed-off-by: Nicolas Dichtel <nicolas.dichtel@6wind.com>
    Signed-off-by: Willy Tarreau <w@1wt.eu>

commit 36e9d2ebcc15d029b33f42a36146ab5a5bcfcfe7
Author: Tejun Heo <tj@kernel.org>
Date:   Tue May 13 11:28:30 2014 -0400

    cgroup: fix rcu_read_lock() leak in update_if_frozen()
    
    While updating cgroup_freezer locking, 68fafb77d827 ("cgroup_freezer:
    replace freezer->lock with freezer_mutex") introduced a bug in
    update_if_frozen() where it returns with rcu_read_lock() held.  Fix it
    by adding rcu_read_unlock() before returning.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: kbuild test robot <fengguang.wu@intel.com>

commit bfe4bc71c64a34813a7bde0ad4d28486679ac3fe
Author: Richard Guy Briggs <rgb@redhat.com>
Date:   Tue Apr 22 21:31:53 2014 -0400

    netlink: simplify nfnetlink_bind
    
    Remove duplicity and simplify code flow by moving the rcu_read_unlock() above
    the condition and let the flow control exit naturally at the end of the
    function.
    
    Signed-off-by: Richard Guy Briggs <rgb@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit fc2345d56d07227350981e4528a9dc9ca7f1b570
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Dec 20 15:17:46 2013 +0000

    Btrfs: fix tree mod logging
    
    commit 5de865eebb8330eee19c37b31fb6f315a09d4273 upstream.
    
    While running the test btrfs/004 from xfstests in a loop, it failed
    about 1 time out of 20 runs in my desktop. The failure happened in
    the backref walking part of the test, and the test's error message was
    like this:
    
    #  btrfs/004 93s ... [failed, exit status 1] - output mismatch (see /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad)
    #      --- tests/btrfs/004.out  2013-11-26 18:25:29.263333714 +0000
    #      +++ /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad 2013-12-10 15:25:10.327518516 +0000
    #      @@ -1,3 +1,8 @@
    #       QA output created by 004
    #       *** test backref walking
    #      -*** done
    #      +unexpected output from
    #      +        /home/fdmanana/git/hub/btrfs-progs/btrfs inspect-internal logical-resolve -P 141512704 /home/fdmanana/btrfs-tests/scratch_1
    #      +expected inum: 405, expected address: 454656, file: /home/fdmanana/btrfs-tests/scratch_1/snap1/p0/d6/d3d/d156/fce, got:
    #      +
           ...
           (Run 'diff -u tests/btrfs/004.out /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad' to see the entire diff)
      Ran: btrfs/004
      Failures: btrfs/004
      Failed 1 of 1 tests
    
    But immediately after the test finished, the btrfs inspect-internal command
    returned the expected output:
    
      $ btrfs inspect-internal logical-resolve -P 141512704 /home/fdmanana/btrfs-tests/scratch_1
      inode 405 offset 454656 root 258
      inode 405 offset 454656 root 5
    
    It turned out this was because the btrfs_search_old_slot() calls performed
    during backref walking (backref.c:__resolve_indirect_ref) were not finding
    anything. The reason for this turned out to be that the tree mod logging
    code was not logging some node multi-step operations atomically, therefore
    btrfs_search_old_slot() callers iterated often over an incomplete tree that
    wasn't fully consistent with any tree state from the past. Besides missing
    items, this often (but not always) resulted in -EIO errors during old slot
    searches, reported in dmesg like this:
    
    [ 4299.933936] ------------[ cut here ]------------
    [ 4299.933949] WARNING: CPU: 0 PID: 23190 at fs/btrfs/ctree.c:1343 btrfs_search_old_slot+0x57b/0xab0 [btrfs]()
    [ 4299.933950] Modules linked in: btrfs raid6_pq xor pci_stub vboxpci(O) vboxnetadp(O) vboxnetflt(O) vboxdrv(O) bnep rfcomm bluetooth parport_pc ppdev binfmt_misc joydev snd_hda_codec_h
    [ 4299.933977] CPU: 0 PID: 23190 Comm: btrfs Tainted: G        W  O 3.12.0-fdm-btrfs-next-16+ #70
    [ 4299.933978] Hardware name: To Be Filled By O.E.M. To Be Filled By O.E.M./Z77 Pro4, BIOS P1.50 09/04/2012
    [ 4299.933979]  000000000000053f ffff8806f3fd98f8 ffffffff8176d284 0000000000000007
    [ 4299.933982]  0000000000000000 ffff8806f3fd9938 ffffffff8104a81c ffff880659c64b70
    [ 4299.933984]  ffff880659c643d0 ffff8806599233d8 ffff880701e2e938 0000160000000000
    [ 4299.933987] Call Trace:
    [ 4299.933991]  [<ffffffff8176d284>] dump_stack+0x55/0x76
    [ 4299.933994]  [<ffffffff8104a81c>] warn_slowpath_common+0x8c/0xc0
    [ 4299.933997]  [<ffffffff8104a86a>] warn_slowpath_null+0x1a/0x20
    [ 4299.934003]  [<ffffffffa065d3bb>] btrfs_search_old_slot+0x57b/0xab0 [btrfs]
    [ 4299.934005]  [<ffffffff81775f3b>] ? _raw_read_unlock+0x2b/0x50
    [ 4299.934010]  [<ffffffffa0655001>] ? __tree_mod_log_search+0x81/0xc0 [btrfs]
    [ 4299.934019]  [<ffffffffa06dd9b0>] __resolve_indirect_refs+0x130/0x5f0 [btrfs]
    [ 4299.934027]  [<ffffffffa06a21f1>] ? free_extent_buffer+0x61/0xc0 [btrfs]
    [ 4299.934034]  [<ffffffffa06de39c>] find_parent_nodes+0x1fc/0xe40 [btrfs]
    [ 4299.934042]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934048]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934056]  [<ffffffffa06df980>] iterate_extent_inodes+0xe0/0x250 [btrfs]
    [ 4299.934058]  [<ffffffff817762db>] ? _raw_spin_unlock+0x2b/0x50
    [ 4299.934065]  [<ffffffffa06dfb82>] iterate_inodes_from_logical+0x92/0xb0 [btrfs]
    [ 4299.934071]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934078]  [<ffffffffa06b7015>] btrfs_ioctl+0xf65/0x1f60 [btrfs]
    [ 4299.934080]  [<ffffffff811658b8>] ? handle_mm_fault+0x278/0xb00
    [ 4299.934083]  [<ffffffff81075563>] ? up_read+0x23/0x40
    [ 4299.934085]  [<ffffffff8177a41c>] ? __do_page_fault+0x20c/0x5a0
    [ 4299.934088]  [<ffffffff811b2946>] do_vfs_ioctl+0x96/0x570
    [ 4299.934090]  [<ffffffff81776e23>] ? error_sti+0x5/0x6
    [ 4299.934093]  [<ffffffff810b71e8>] ? trace_hardirqs_off_caller+0x28/0xd0
    [ 4299.934096]  [<ffffffff81776a09>] ? retint_swapgs+0xe/0x13
    [ 4299.934098]  [<ffffffff811b2eb1>] SyS_ioctl+0x91/0xb0
    [ 4299.934100]  [<ffffffff813eecde>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 4299.934102]  [<ffffffff8177ef12>] system_call_fastpath+0x16/0x1b
    [ 4299.934102]  [<ffffffff8177ef12>] system_call_fastpath+0x16/0x1b
    [ 4299.934104] ---[ end trace 48f0cfc902491414 ]---
    [ 4299.934378] btrfs bad fsid on block 0
    
    These tree mod log operations that must be performed atomically, tree_mod_log_free_eb,
    tree_mod_log_eb_copy, tree_mod_log_insert_root and tree_mod_log_insert_move, used to
    be performed atomically before the following commit:
    
      c8cc6341653721b54760480b0d0d9b5f09b46741
      (Btrfs: stop using GFP_ATOMIC for the tree mod log allocations)
    
    That change removed the atomicity of such operations. This patch restores the
    atomicity while still not doing the GFP_ATOMIC allocations of tree_mod_elem
    structures, so it has to do the allocations using GFP_NOFS before acquiring
    the mod log lock.
    
    This issue has been experienced by several users recently, such as for example:
    
      http://www.spinics.net/lists/linux-btrfs/msg28574.html
    
    After running the btrfs/004 test for 679 consecutive iterations with this
    patch applied, I didn't ran into the issue anymore.
    
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1442e7507dd597cc701b224d3cc9bf1f165e928b
Author: Florian Westphal <fw@strlen.de>
Date:   Wed Mar 12 23:49:49 2014 +0100

    netfilter: connlimit: use keyed locks
    
    connlimit currently suffers from spinlock contention, example for
    4-core system with rps enabled:
    
    +  20.84%   ksoftirqd/2  [kernel.kallsyms] [k] _raw_spin_lock_bh
    +  20.76%   ksoftirqd/1  [kernel.kallsyms] [k] _raw_spin_lock_bh
    +  20.42%   ksoftirqd/0  [kernel.kallsyms] [k] _raw_spin_lock_bh
    +   6.07%   ksoftirqd/2  [nf_conntrack]    [k] ____nf_conntrack_find
    +   6.07%   ksoftirqd/1  [nf_conntrack]    [k] ____nf_conntrack_find
    +   5.97%   ksoftirqd/0  [nf_conntrack]    [k] ____nf_conntrack_find
    +   2.47%   ksoftirqd/2  [nf_conntrack]    [k] hash_conntrack_raw
    +   2.45%   ksoftirqd/0  [nf_conntrack]    [k] hash_conntrack_raw
    +   2.44%   ksoftirqd/1  [nf_conntrack]    [k] hash_conntrack_raw
    
    May allow parallel lookup/insert/delete if the entry is hashed to
    another slot.  With patch:
    
    +  20.95%  ksoftirqd/0  [nf_conntrack] [k] ____nf_conntrack_find
    +  20.50%  ksoftirqd/1  [nf_conntrack] [k] ____nf_conntrack_find
    +  20.27%  ksoftirqd/2  [nf_conntrack] [k] ____nf_conntrack_find
    +   5.76%  ksoftirqd/1  [nf_conntrack] [k] hash_conntrack_raw
    +   5.39%  ksoftirqd/2  [nf_conntrack] [k] hash_conntrack_raw
    +   5.35%  ksoftirqd/0  [nf_conntrack] [k] hash_conntrack_raw
    +   2.00%  ksoftirqd/1  [kernel.kallsyms] [k] __rcu_read_unlock
    
    Improved rx processing rate from ~35kpps to ~50 kpps.
    
    Reviewed-by: Jesper Dangaard Brouer <brouer@redhat.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit b7ce40cff0b9f6597f8318fd761accd92727f61f
Author: Tejun Heo <tj@kernel.org>
Date:   Tue Mar 4 15:38:46 2014 -0500

    kernfs: cache atomic_write_len in kernfs_open_file
    
    While implementing atomic_write_len, 4d3773c4bb41 ("kernfs: implement
    kernfs_ops->atomic_write_len") moved data copy from userland inside
    kernfs_get_active() and kernfs_open_file->mutex so that
    kernfs_ops->atomic_write_len can be accessed before copying buffer
    from userland; unfortunately, this could lead to locking order
    inversion involving mmap_sem if copy_from_user() takes a page fault.
    
      ======================================================
      [ INFO: possible circular locking dependency detected ]
      3.14.0-rc4-next-20140228-sasha-00011-g4077c67-dirty #26 Tainted: G        W
      -------------------------------------------------------
      trinity-c236/10658 is trying to acquire lock:
       (&of->mutex#2){+.+.+.}, at: [<fs/kernfs/file.c:487>] kernfs_fop_mmap+0x54/0x120
    
      but task is already holding lock:
       (&mm->mmap_sem){++++++}, at: [<mm/util.c:397>] vm_mmap_pgoff+0x6e/0xe0
    
      which lock already depends on the new lock.
    
      the existing dependency chain (in reverse order) is:
    
     -> #1 (&mm->mmap_sem){++++++}:
             [<kernel/locking/lockdep.c:1945 kernel/locking/lockdep.c:2131>] validate_chain+0x6c5/0x7b0
             [<kernel/locking/lockdep.c:3182>] __lock_acquire+0x4cd/0x5a0
             [<arch/x86/include/asm/current.h:14 kernel/locking/lockdep.c:3602>] lock_acquire+0x182/0x1d0
             [<mm/memory.c:4188>] might_fault+0x7e/0xb0
             [<arch/x86/include/asm/uaccess.h:713 fs/kernfs/file.c:291>] kernfs_fop_write+0xd8/0x190
             [<fs/read_write.c:473>] vfs_write+0xe3/0x1d0
             [<fs/read_write.c:523 fs/read_write.c:515>] SyS_write+0x5d/0xa0
             [<arch/x86/kernel/entry_64.S:749>] tracesys+0xdd/0xe2
    
     -> #0 (&of->mutex#2){+.+.+.}:
             [<kernel/locking/lockdep.c:1840>] check_prev_add+0x13f/0x560
             [<kernel/locking/lockdep.c:1945 kernel/locking/lockdep.c:2131>] validate_chain+0x6c5/0x7b0
             [<kernel/locking/lockdep.c:3182>] __lock_acquire+0x4cd/0x5a0
             [<arch/x86/include/asm/current.h:14 kernel/locking/lockdep.c:3602>] lock_acquire+0x182/0x1d0
             [<kernel/locking/mutex.c:470 kernel/locking/mutex.c:571>] mutex_lock_nested+0x6a/0x510
             [<fs/kernfs/file.c:487>] kernfs_fop_mmap+0x54/0x120
             [<mm/mmap.c:1573>] mmap_region+0x310/0x5c0
             [<mm/mmap.c:1365>] do_mmap_pgoff+0x385/0x430
             [<mm/util.c:399>] vm_mmap_pgoff+0x8f/0xe0
             [<mm/mmap.c:1416 mm/mmap.c:1374>] SyS_mmap_pgoff+0x1b0/0x210
             [<arch/x86/kernel/sys_x86_64.c:72>] SyS_mmap+0x1d/0x20
             [<arch/x86/kernel/entry_64.S:749>] tracesys+0xdd/0xe2
    
      other info that might help us debug this:
    
       Possible unsafe locking scenario:
    
             CPU0                    CPU1
             ----                    ----
        lock(&mm->mmap_sem);
                                     lock(&of->mutex#2);
                                     lock(&mm->mmap_sem);
        lock(&of->mutex#2);
    
       *** DEADLOCK ***
    
      1 lock held by trinity-c236/10658:
       #0:  (&mm->mmap_sem){++++++}, at: [<mm/util.c:397>] vm_mmap_pgoff+0x6e/0xe0
    
      stack backtrace:
      CPU: 2 PID: 10658 Comm: trinity-c236 Tainted: G        W 3.14.0-rc4-next-20140228-sasha-00011-g4077c67-dirty #26
       0000000000000000 ffff88011911fa48 ffffffff8438e945 0000000000000000
       0000000000000000 ffff88011911fa98 ffffffff811a0109 ffff88011911fab8
       ffff88011911fab8 ffff88011911fa98 ffff880119128cc0 ffff880119128cf8
      Call Trace:
       [<lib/dump_stack.c:52>] dump_stack+0x52/0x7f
       [<kernel/locking/lockdep.c:1213>] print_circular_bug+0x129/0x160
       [<kernel/locking/lockdep.c:1840>] check_prev_add+0x13f/0x560
       [<include/linux/spinlock.h:343 mm/slub.c:1933>] ? deactivate_slab+0x511/0x550
       [<kernel/locking/lockdep.c:1945 kernel/locking/lockdep.c:2131>] validate_chain+0x6c5/0x7b0
       [<kernel/locking/lockdep.c:3182>] __lock_acquire+0x4cd/0x5a0
       [<mm/mmap.c:1552>] ? mmap_region+0x24a/0x5c0
       [<arch/x86/include/asm/current.h:14 kernel/locking/lockdep.c:3602>] lock_acquire+0x182/0x1d0
       [<fs/kernfs/file.c:487>] ? kernfs_fop_mmap+0x54/0x120
       [<kernel/locking/mutex.c:470 kernel/locking/mutex.c:571>] mutex_lock_nested+0x6a/0x510
       [<fs/kernfs/file.c:487>] ? kernfs_fop_mmap+0x54/0x120
       [<kernel/sched/core.c:2477>] ? get_parent_ip+0x11/0x50
       [<fs/kernfs/file.c:487>] ? kernfs_fop_mmap+0x54/0x120
       [<fs/kernfs/file.c:487>] kernfs_fop_mmap+0x54/0x120
       [<mm/mmap.c:1573>] mmap_region+0x310/0x5c0
       [<mm/mmap.c:1365>] do_mmap_pgoff+0x385/0x430
       [<mm/util.c:397>] ? vm_mmap_pgoff+0x6e/0xe0
       [<mm/util.c:399>] vm_mmap_pgoff+0x8f/0xe0
       [<kernel/rcu/update.c:97>] ? __rcu_read_unlock+0x44/0xb0
       [<fs/file.c:641>] ? dup_fd+0x3c0/0x3c0
       [<mm/mmap.c:1416 mm/mmap.c:1374>] SyS_mmap_pgoff+0x1b0/0x210
       [<arch/x86/kernel/sys_x86_64.c:72>] SyS_mmap+0x1d/0x20
       [<arch/x86/kernel/entry_64.S:749>] tracesys+0xdd/0xe2
    
    Fix it by caching atomic_write_len in kernfs_open_file during open so
    that it can be determined without accessing kernfs_ops in
    kernfs_fop_write().  This restores the structure of kernfs_fop_write()
    before 4d3773c4bb41 with updated @len determination logic.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reported-by: Sasha Levin <sasha.levin@oracle.com>
    References: http://lkml.kernel.org/g/53113485.2090407@oracle.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3f803abf2e49fe18aaeff9532afc353e68e689c7
Merge: 0c0bd34a1429 27329369c9ec
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Mar 4 08:29:39 2014 -0800

    Merge branch 'akpm' (patches from Andrew Morton)
    
    Merge misc fixes from Andrew Morton.
    
    * emailed patches from Andrew Morton akpm@linux-foundation.org>:
      mm: page_alloc: exempt GFP_THISNODE allocations from zone fairness
      mm: numa: bugfix for LAST_CPUPID_NOT_IN_PAGE_FLAGS
      MAINTAINERS: add and correct types of some "T:" entries
      MAINTAINERS: use tab for separator
      rapidio/tsi721: fix tasklet termination in dma channel release
      hfsplus: fix remount issue
      zram: avoid null access when fail to alloc meta
      sh: prefix sh-specific "CCR" and "CCR2" by "SH_"
      ocfs2: fix quota file corruption
      drivers/rtc/rtc-s3c.c: fix incorrect way of save/restore of S3C2410_TICNT for TYPE_S3C64XX
      kallsyms: fix absolute addresses for kASLR
      scripts/gen_initramfs_list.sh: fix flags for initramfs LZ4 compression
      mm: include VM_MIXEDMAP flag in the VM_SPECIAL list to avoid m(un)locking
      memcg: reparent charges of children before processing parent
      memcg: fix endless loop in __mem_cgroup_iter_next()
      lib/radix-tree.c: swapoff tmpfs radix_tree: remember to rcu_read_unlock
      dma debug: account for cachelines and read-only mappings in overlap tracking
      mm: close PageTail race
      MAINTAINERS: EDAC: add Mauro and Borislav as interim patch collectors

commit 5f30fc94ca985974fd54de454c7a6070388443db
Author: Hugh Dickins <hughd@google.com>
Date:   Mon Mar 3 15:38:23 2014 -0800

    lib/radix-tree.c: swapoff tmpfs radix_tree: remember to rcu_read_unlock
    
    Running fsx on tmpfs with concurrent memhog-swapoff-swapon, lots of
    
      BUG: sleeping function called from invalid context at kernel/fork.c:606
      in_atomic(): 0, irqs_disabled(): 0, pid: 1394, name: swapoff
      1 lock held by swapoff/1394:
       #0:  (rcu_read_lock){.+.+.+}, at: [<ffffffff812520a1>] radix_tree_locate_item+0x1f/0x2b6
    
    followed by
    
      ================================================
      [ BUG: lock held when returning to user space! ]
      3.14.0-rc1 #3 Not tainted
      ------------------------------------------------
      swapoff/1394 is leaving the kernel with locks still held!
      1 lock held by swapoff/1394:
       #0:  (rcu_read_lock){.+.+.+}, at: [<ffffffff812520a1>] radix_tree_locate_item+0x1f/0x2b6
    
    after which the system recovered nicely.
    
    Whoops, I long ago forgot the rcu_read_unlock() on one unlikely branch.
    
    Fixes e504f3fdd63d ("tmpfs radix_tree: locate_item to speed up swapoff")
    
    Signed-off-by: Hugh Dickins <hughd@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 3939448a3adb1a157d4b01ca9082b6a19b6c4a34
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Dec 20 15:17:46 2013 +0000

    Btrfs: fix tree mod logging
    
    commit 5de865eebb8330eee19c37b31fb6f315a09d4273 upstream.
    
    While running the test btrfs/004 from xfstests in a loop, it failed
    about 1 time out of 20 runs in my desktop. The failure happened in
    the backref walking part of the test, and the test's error message was
    like this:
    
      btrfs/004 93s ... [failed, exit status 1] - output mismatch (see /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad)
          --- tests/btrfs/004.out   2013-11-26 18:25:29.263333714 +0000
          +++ /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad  2013-12-10 15:25:10.327518516 +0000
          @@ -1,3 +1,8 @@
           QA output created by 004
           *** test backref walking
          -*** done
          +unexpected output from
          + /home/fdmanana/git/hub/btrfs-progs/btrfs inspect-internal logical-resolve -P 141512704 /home/fdmanana/btrfs-tests/scratch_1
          +expected inum: 405, expected address: 454656, file: /home/fdmanana/btrfs-tests/scratch_1/snap1/p0/d6/d3d/d156/fce, got:
          +
           ...
           (Run 'diff -u tests/btrfs/004.out /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad' to see the entire diff)
      Ran: btrfs/004
      Failures: btrfs/004
      Failed 1 of 1 tests
    
    But immediately after the test finished, the btrfs inspect-internal command
    returned the expected output:
    
      $ btrfs inspect-internal logical-resolve -P 141512704 /home/fdmanana/btrfs-tests/scratch_1
      inode 405 offset 454656 root 258
      inode 405 offset 454656 root 5
    
    It turned out this was because the btrfs_search_old_slot() calls performed
    during backref walking (backref.c:__resolve_indirect_ref) were not finding
    anything. The reason for this turned out to be that the tree mod logging
    code was not logging some node multi-step operations atomically, therefore
    btrfs_search_old_slot() callers iterated often over an incomplete tree that
    wasn't fully consistent with any tree state from the past. Besides missing
    items, this often (but not always) resulted in -EIO errors during old slot
    searches, reported in dmesg like this:
    
    [ 4299.933936] ------------[ cut here ]------------
    [ 4299.933949] WARNING: CPU: 0 PID: 23190 at fs/btrfs/ctree.c:1343 btrfs_search_old_slot+0x57b/0xab0 [btrfs]()
    [ 4299.933950] Modules linked in: btrfs raid6_pq xor pci_stub vboxpci(O) vboxnetadp(O) vboxnetflt(O) vboxdrv(O) bnep rfcomm bluetooth parport_pc ppdev binfmt_misc joydev snd_hda_codec_h
    [ 4299.933977] CPU: 0 PID: 23190 Comm: btrfs Tainted: G        W  O 3.12.0-fdm-btrfs-next-16+ #70
    [ 4299.933978] Hardware name: To Be Filled By O.E.M. To Be Filled By O.E.M./Z77 Pro4, BIOS P1.50 09/04/2012
    [ 4299.933979]  000000000000053f ffff8806f3fd98f8 ffffffff8176d284 0000000000000007
    [ 4299.933982]  0000000000000000 ffff8806f3fd9938 ffffffff8104a81c ffff880659c64b70
    [ 4299.933984]  ffff880659c643d0 ffff8806599233d8 ffff880701e2e938 0000160000000000
    [ 4299.933987] Call Trace:
    [ 4299.933991]  [<ffffffff8176d284>] dump_stack+0x55/0x76
    [ 4299.933994]  [<ffffffff8104a81c>] warn_slowpath_common+0x8c/0xc0
    [ 4299.933997]  [<ffffffff8104a86a>] warn_slowpath_null+0x1a/0x20
    [ 4299.934003]  [<ffffffffa065d3bb>] btrfs_search_old_slot+0x57b/0xab0 [btrfs]
    [ 4299.934005]  [<ffffffff81775f3b>] ? _raw_read_unlock+0x2b/0x50
    [ 4299.934010]  [<ffffffffa0655001>] ? __tree_mod_log_search+0x81/0xc0 [btrfs]
    [ 4299.934019]  [<ffffffffa06dd9b0>] __resolve_indirect_refs+0x130/0x5f0 [btrfs]
    [ 4299.934027]  [<ffffffffa06a21f1>] ? free_extent_buffer+0x61/0xc0 [btrfs]
    [ 4299.934034]  [<ffffffffa06de39c>] find_parent_nodes+0x1fc/0xe40 [btrfs]
    [ 4299.934042]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934048]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934056]  [<ffffffffa06df980>] iterate_extent_inodes+0xe0/0x250 [btrfs]
    [ 4299.934058]  [<ffffffff817762db>] ? _raw_spin_unlock+0x2b/0x50
    [ 4299.934065]  [<ffffffffa06dfb82>] iterate_inodes_from_logical+0x92/0xb0 [btrfs]
    [ 4299.934071]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934078]  [<ffffffffa06b7015>] btrfs_ioctl+0xf65/0x1f60 [btrfs]
    [ 4299.934080]  [<ffffffff811658b8>] ? handle_mm_fault+0x278/0xb00
    [ 4299.934083]  [<ffffffff81075563>] ? up_read+0x23/0x40
    [ 4299.934085]  [<ffffffff8177a41c>] ? __do_page_fault+0x20c/0x5a0
    [ 4299.934088]  [<ffffffff811b2946>] do_vfs_ioctl+0x96/0x570
    [ 4299.934090]  [<ffffffff81776e23>] ? error_sti+0x5/0x6
    [ 4299.934093]  [<ffffffff810b71e8>] ? trace_hardirqs_off_caller+0x28/0xd0
    [ 4299.934096]  [<ffffffff81776a09>] ? retint_swapgs+0xe/0x13
    [ 4299.934098]  [<ffffffff811b2eb1>] SyS_ioctl+0x91/0xb0
    [ 4299.934100]  [<ffffffff813eecde>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 4299.934102]  [<ffffffff8177ef12>] system_call_fastpath+0x16/0x1b
    [ 4299.934102]  [<ffffffff8177ef12>] system_call_fastpath+0x16/0x1b
    [ 4299.934104] ---[ end trace 48f0cfc902491414 ]---
    [ 4299.934378] btrfs bad fsid on block 0
    
    These tree mod log operations that must be performed atomically, tree_mod_log_free_eb,
    tree_mod_log_eb_copy, tree_mod_log_insert_root and tree_mod_log_insert_move, used to
    be performed atomically before the following commit:
    
      c8cc6341653721b54760480b0d0d9b5f09b46741
      (Btrfs: stop using GFP_ATOMIC for the tree mod log allocations)
    
    That change removed the atomicity of such operations. This patch restores the
    atomicity while still not doing the GFP_ATOMIC allocations of tree_mod_elem
    structures, so it has to do the allocations using GFP_NOFS before acquiring
    the mod log lock.
    
    This issue has been experienced by several users recently, such as for example:
    
      http://www.spinics.net/lists/linux-btrfs/msg28574.html
    
    After running the btrfs/004 test for 679 consecutive iterations with this
    patch applied, I didn't ran into the issue anymore.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>

commit b92483d54abb4ff288accc36bf1daef44dea9fbe
Author: Peter Hurley <peter@hurleysoftware.com>
Date:   Sun Feb 9 20:59:15 2014 -0500

    Bluetooth: Fix unsafe RFCOMM device parenting
    
    Accessing the results of hci_conn_hash_lookup_ba() is unsafe without
    holding the hci_dev_lock() during the lookup. For example:
    
    CPU 0                             | CPU 1
    hci_conn_hash_lookup_ba           | hci_conn_del
      rcu_read_lock                   |   hci_conn_hash_del
      list_for_each_entry_rcu         |     list_del_rcu
        if (.....)                    |       synchronize_rcu
          rcu_read_unlock             |
                                      |   hci_conn_del_sysfs
                                      |   hci_dev_put
                                      |   hci_conn_put
                                      |     put_device (last reference)
                                      |       bt_link_release
                                      |         kfree(conn)
          return p  << just freed     |
    
    Even if a hci_conn reference were taken (via hci_conn_get), would
    not guarantee the lifetime of the sysfs device, but only safe
    access to the in-memory structure.
    
    Ensure the hci_conn device stays valid while the rfcomm device
    is reparented; rename rfcomm_get_device() to rfcomm_reparent_device()
    and perform the reparenting within the function while holding the
    hci_dev_lock.
    
    Signed-off-by: Peter Hurley <peter@hurleysoftware.com>
    Tested-By: Alexander Holler <holler@ahsoftware.de>
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>

commit bacb6de62cce0af3be40248c89f980b604b8a54f
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Feb 12 11:54:32 2014 -0800

    staging: Additional item for rtl8188eu TODO list
    
    The rtw_recv_indicatepkt() function in the file named
    drivers/staging/rtl8188eu/os_dep/recv_linux.c has this strange code:
    
            rcu_read_lock();
            rcu_dereference(padapter->pnetdev->rx_handler_data);
            rcu_read_unlock();
    
    This code has no effect.  Normally, you would assign the result of
    rcu_dereference() to some variable, but it is not clear from the
    code what variable that would be.  Therefore, this patch applies to
    the TODO file instead of the code itself.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 16e5a2ed5920f511666a8714f43987bb0e2ad751
Merge: 6792dfe383dd 20e7c4e80dcd
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 11 12:05:55 2014 -0800

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Pull networking updates from David Miller:
    
     1) Fix flexcan build on big endian, from Arnd Bergmann
    
     2) Correctly attach cpsw to GPIO bitbang MDIO drive, from Stefan Roese
    
     3) udp_add_offload has to use GFP_ATOMIC since it can be invoked from
        non-sleepable contexts.  From Or Gerlitz
    
     4) vxlan_gro_receive() does not iterate over all possible flows
        properly, fix also from Or Gerlitz
    
     5) CAN core doesn't use a proper SKB destructor when it hooks up
        sockets to SKBs.  Fix from Oliver Hartkopp
    
     6) ip_tunnel_xmit() can use an uninitialized route pointer, fix from
        Eric Dumazet
    
     7) Fix address family assignment in IPVS, from Michal Kubecek
    
     8) Fix ath9k build on ARM, from Sujith Manoharan
    
     9) Make sure fail_over_mac only applies for the correct bonding modes,
        from Ding Tianhong
    
    10) The udp offload code doesn't use RCU correctly, from Shlomo Pongratz
    
    11) Handle gigabit features properly in generic PHY code, from Florian
        Fainelli
    
    12) Don't blindly invoke link operations in
        rtnl_link_get_slave_info_data_size, they are optional.  Fix from
        Fernando Luis Vazquez Cao
    
    13) Add USB IDs for Netgear Aircard 340U, from Bjrn Mork
    
    14) Handle netlink packet padding properly in openvswitch, from Thomas
        Graf
    
    15) Fix oops when deleting chains in nf_tables, from Patrick McHardy
    
    16) Fix RX stalls in xen-netback driver, from Zoltan Kiss
    
    17) Fix deadlock in mac80211 stack, from Emmanuel Grumbach
    
    18) inet_nlmsg_size() forgets to consider ifa_cacheinfo, fix from Geert
        Uytterhoeven
    
    19) tg3_change_mtu() can deadlock, fix from Nithin Sujir
    
    20) Fix regression in setting SCTP local source addresses on accepted
        sockets, caused by some generic ipv6 socket changes.  Fix from
        Matija Glavinic Pecotic
    
    21) IPPROTO_* must be pure defines, otherwise module aliases don't get
        constructed properly.  Fix from Jan Moskyto
    
    22) IPV6 netconsole setup doesn't work properly unless an explicit
        source address is specified, fix from Sabrina Dubroca
    
    23) Use __GFP_NORETRY for high order skb page allocations in
        sock_alloc_send_pskb and skb_page_frag_refill.  From Eric Dumazet
    
    24) Fix a regression added in netconsole over bridging, from Cong Wang
    
    25) TCP uses an artificial offset of 1ms for SRTT, but this doesn't jive
        well with TCP pacing which needs the SRTT to be accurate.  Fix from
        Eric Dumazet
    
    26) Several cases of missing header file includes from Rashika Kheria
    
    27) Add ZTE MF667 device ID to qmi_wwan driver, from Raymond Wanyoike
    
    28) TCP Small Queues doesn't handle nonagle properly in some corner
        cases, fix from Eric Dumazet
    
    29) Remove extraneous read_unlock in bond_enslave, whoops.  From Ding
        Tianhong
    
    30) Fix 9p trans_virtio handling of vmalloc buffers, from Richard Yao
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net: (136 commits)
      6lowpan: fix lockdep splats
      alx: add missing stats_lock spinlock init
      9p/trans_virtio.c: Fix broken zero-copy on vmalloc() buffers
      bonding: remove unwanted bond lock for enslave processing
      USB2NET : SR9800 : One chip USB2.0 USB2NET SR9800 Device Driver Support
      tcp: tsq: fix nonagle handling
      bridge: Prevent possible race condition in br_fdb_change_mac_address
      bridge: Properly check if local fdb entry can be deleted when deleting vlan
      bridge: Properly check if local fdb entry can be deleted in br_fdb_delete_by_port
      bridge: Properly check if local fdb entry can be deleted in br_fdb_change_mac_address
      bridge: Fix the way to check if a local fdb entry can be deleted
      bridge: Change local fdb entries whenever mac address of bridge device changes
      bridge: Fix the way to find old local fdb entries in br_fdb_change_mac_address
      bridge: Fix the way to insert new local fdb entries in br_fdb_changeaddr
      bridge: Fix the way to find old local fdb entries in br_fdb_changeaddr
      tcp: correct code comment stating 3 min timeout for FIN_WAIT2, we only do 1 min
      net: vxge: Remove unused device pointer
      net: qmi_wwan: add ZTE MF667
      3c59x: Remove unused pointer in vortex_eisa_cleanup()
      net: fix 'ip rule' iif/oif device rename
      ...

commit 6b8790b5006b5ca3ee1c039c3c909833d7958716
Author: dingtianhong <dingtianhong@huawei.com>
Date:   Mon Feb 10 16:33:59 2014 +0800

    bonding: remove unwanted bond lock for enslave processing
    
    The bond enslave processing don't hold bond->lock anymore,
    so release an unlocked rw lock will cause warning message,
    remove the unwanted read_unlock(&bond->lock).
    
    Cc: Jay Vosburgh <fubar@us.ibm.com>
    Cc: Veaceslav Falico <vfalico@redhat.com>
    Cc: Andy Gospodarek <andy@greyhouse.net>
    Signed-off-by: Ding Tianhong <dingtianhong@huawei.com>
    Acked-by: Veaceslav Falico <vfalico@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5de865eebb8330eee19c37b31fb6f315a09d4273
Author: Filipe David Borba Manana <fdmanana@gmail.com>
Date:   Fri Dec 20 15:17:46 2013 +0000

    Btrfs: fix tree mod logging
    
    While running the test btrfs/004 from xfstests in a loop, it failed
    about 1 time out of 20 runs in my desktop. The failure happened in
    the backref walking part of the test, and the test's error message was
    like this:
    
      btrfs/004 93s ... [failed, exit status 1] - output mismatch (see /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad)
          --- tests/btrfs/004.out   2013-11-26 18:25:29.263333714 +0000
          +++ /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad  2013-12-10 15:25:10.327518516 +0000
          @@ -1,3 +1,8 @@
           QA output created by 004
           *** test backref walking
          -*** done
          +unexpected output from
          + /home/fdmanana/git/hub/btrfs-progs/btrfs inspect-internal logical-resolve -P 141512704 /home/fdmanana/btrfs-tests/scratch_1
          +expected inum: 405, expected address: 454656, file: /home/fdmanana/btrfs-tests/scratch_1/snap1/p0/d6/d3d/d156/fce, got:
          +
           ...
           (Run 'diff -u tests/btrfs/004.out /home/fdmanana/git/hub/xfstests_2/results//btrfs/004.out.bad' to see the entire diff)
      Ran: btrfs/004
      Failures: btrfs/004
      Failed 1 of 1 tests
    
    But immediately after the test finished, the btrfs inspect-internal command
    returned the expected output:
    
      $ btrfs inspect-internal logical-resolve -P 141512704 /home/fdmanana/btrfs-tests/scratch_1
      inode 405 offset 454656 root 258
      inode 405 offset 454656 root 5
    
    It turned out this was because the btrfs_search_old_slot() calls performed
    during backref walking (backref.c:__resolve_indirect_ref) were not finding
    anything. The reason for this turned out to be that the tree mod logging
    code was not logging some node multi-step operations atomically, therefore
    btrfs_search_old_slot() callers iterated often over an incomplete tree that
    wasn't fully consistent with any tree state from the past. Besides missing
    items, this often (but not always) resulted in -EIO errors during old slot
    searches, reported in dmesg like this:
    
    [ 4299.933936] ------------[ cut here ]------------
    [ 4299.933949] WARNING: CPU: 0 PID: 23190 at fs/btrfs/ctree.c:1343 btrfs_search_old_slot+0x57b/0xab0 [btrfs]()
    [ 4299.933950] Modules linked in: btrfs raid6_pq xor pci_stub vboxpci(O) vboxnetadp(O) vboxnetflt(O) vboxdrv(O) bnep rfcomm bluetooth parport_pc ppdev binfmt_misc joydev snd_hda_codec_h
    [ 4299.933977] CPU: 0 PID: 23190 Comm: btrfs Tainted: G        W  O 3.12.0-fdm-btrfs-next-16+ #70
    [ 4299.933978] Hardware name: To Be Filled By O.E.M. To Be Filled By O.E.M./Z77 Pro4, BIOS P1.50 09/04/2012
    [ 4299.933979]  000000000000053f ffff8806f3fd98f8 ffffffff8176d284 0000000000000007
    [ 4299.933982]  0000000000000000 ffff8806f3fd9938 ffffffff8104a81c ffff880659c64b70
    [ 4299.933984]  ffff880659c643d0 ffff8806599233d8 ffff880701e2e938 0000160000000000
    [ 4299.933987] Call Trace:
    [ 4299.933991]  [<ffffffff8176d284>] dump_stack+0x55/0x76
    [ 4299.933994]  [<ffffffff8104a81c>] warn_slowpath_common+0x8c/0xc0
    [ 4299.933997]  [<ffffffff8104a86a>] warn_slowpath_null+0x1a/0x20
    [ 4299.934003]  [<ffffffffa065d3bb>] btrfs_search_old_slot+0x57b/0xab0 [btrfs]
    [ 4299.934005]  [<ffffffff81775f3b>] ? _raw_read_unlock+0x2b/0x50
    [ 4299.934010]  [<ffffffffa0655001>] ? __tree_mod_log_search+0x81/0xc0 [btrfs]
    [ 4299.934019]  [<ffffffffa06dd9b0>] __resolve_indirect_refs+0x130/0x5f0 [btrfs]
    [ 4299.934027]  [<ffffffffa06a21f1>] ? free_extent_buffer+0x61/0xc0 [btrfs]
    [ 4299.934034]  [<ffffffffa06de39c>] find_parent_nodes+0x1fc/0xe40 [btrfs]
    [ 4299.934042]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934048]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934056]  [<ffffffffa06df980>] iterate_extent_inodes+0xe0/0x250 [btrfs]
    [ 4299.934058]  [<ffffffff817762db>] ? _raw_spin_unlock+0x2b/0x50
    [ 4299.934065]  [<ffffffffa06dfb82>] iterate_inodes_from_logical+0x92/0xb0 [btrfs]
    [ 4299.934071]  [<ffffffffa06b13e0>] ? defrag_lookup_extent+0xe0/0xe0 [btrfs]
    [ 4299.934078]  [<ffffffffa06b7015>] btrfs_ioctl+0xf65/0x1f60 [btrfs]
    [ 4299.934080]  [<ffffffff811658b8>] ? handle_mm_fault+0x278/0xb00
    [ 4299.934083]  [<ffffffff81075563>] ? up_read+0x23/0x40
    [ 4299.934085]  [<ffffffff8177a41c>] ? __do_page_fault+0x20c/0x5a0
    [ 4299.934088]  [<ffffffff811b2946>] do_vfs_ioctl+0x96/0x570
    [ 4299.934090]  [<ffffffff81776e23>] ? error_sti+0x5/0x6
    [ 4299.934093]  [<ffffffff810b71e8>] ? trace_hardirqs_off_caller+0x28/0xd0
    [ 4299.934096]  [<ffffffff81776a09>] ? retint_swapgs+0xe/0x13
    [ 4299.934098]  [<ffffffff811b2eb1>] SyS_ioctl+0x91/0xb0
    [ 4299.934100]  [<ffffffff813eecde>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [ 4299.934102]  [<ffffffff8177ef12>] system_call_fastpath+0x16/0x1b
    [ 4299.934102]  [<ffffffff8177ef12>] system_call_fastpath+0x16/0x1b
    [ 4299.934104] ---[ end trace 48f0cfc902491414 ]---
    [ 4299.934378] btrfs bad fsid on block 0
    
    These tree mod log operations that must be performed atomically, tree_mod_log_free_eb,
    tree_mod_log_eb_copy, tree_mod_log_insert_root and tree_mod_log_insert_move, used to
    be performed atomically before the following commit:
    
      c8cc6341653721b54760480b0d0d9b5f09b46741
      (Btrfs: stop using GFP_ATOMIC for the tree mod log allocations)
    
    That change removed the atomicity of such operations. This patch restores the
    atomicity while still not doing the GFP_ATOMIC allocations of tree_mod_elem
    structures, so it has to do the allocations using GFP_NOFS before acquiring
    the mod log lock.
    
    This issue has been experienced by several users recently, such as for example:
    
      http://www.spinics.net/lists/linux-btrfs/msg28574.html
    
    After running the btrfs/004 test for 679 consecutive iterations with this
    patch applied, I didn't ran into the issue anymore.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Filipe David Borba Manana <fdmanana@gmail.com>
    Signed-off-by: Josef Bacik <jbacik@fb.com>
    Signed-off-by: Chris Mason <clm@fb.com>

commit 940fe4793a219375c4713a17c61b843720807c9d
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Thu Jan 23 15:55:36 2014 -0800

    proc: fix the potential use-after-free in first_tid()
    
    proc_task_readdir() verifies that the result of get_proc_task() is
    pid_alive() and thus its ->group_leader is fine too.  However this is not
    necessarily true after rcu_read_unlock(), we need to recheck this again
    after first_tid() does rcu_read_lock().  Otherwise
    leader->thread_group.next (used by next_thread()) can be invalid if the
    rcu grace period expires in between.
    
    The race is subtle and unlikely, but still it is possible afaics.  To
    simplify lets ignore the "likely" case when tid != 0, f_version can be
    cleared by proc_task_operations->llseek().
    
    Suppose we have a main thread M and its subthread T.  Suppose that f_pos
    == 3, iow first_tid() should return T.  Now suppose that the following
    happens between rcu_read_unlock() and rcu_read_lock():
    
            1. T execs and becomes the new leader. This removes M from
                ->thread_group but next_thread(M) is still T.
    
            2. T creates another thread X which does exec as well, T
               goes away.
    
            3. X creates another subthread, this increments nr_threads.
    
            4. first_tid() does next_thread(M) and returns the already
               dead T.
    
    Note also that we need 2.  and 3.  only because of get_nr_threads() check,
    and this check was supposed to be optimization only.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: Sameer Nanda <snanda@chromium.org>
    Cc: Sergey Dyasly <dserrg@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit a693c46e14c9fdadbcd68ddfa94a4f72495531a9
Merge: 6ffbe7d1fabd 73a7ac2808fa
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 20 10:25:12 2014 -0800

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     - add RCU torture scripts/tooling
     - static analysis improvements
     - update RCU documentation
     - miscellaneous fixes
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (52 commits)
      rcu: Remove "extern" from function declarations in kernel/rcu/rcu.h
      rcu: Remove "extern" from function declarations in include/linux/*rcu*.h
      rcu/torture: Dynamically allocate SRCU output buffer to avoid overflow
      rcu: Don't activate RCU core on NO_HZ_FULL CPUs
      rcu: Warn on allegedly impossible rcu_read_unlock_special() from irq
      rcu: Add an RCU_INITIALIZER for global RCU-protected pointers
      rcu: Make rcu_assign_pointer's assignment volatile and type-safe
      bonding: Use RCU_INIT_POINTER() for better overhead and for sparse
      rcu: Add comment on evaluate-once properties of rcu_assign_pointer().
      rcu: Provide better diagnostics for blocking in RCU callback functions
      rcu: Improve SRCU's grace-period comments
      rcu: Fix CONFIG_RCU_FANOUT_EXACT for odd fanout/leaf values
      rcu: Fix coccinelle warnings
      rcutorture: Stop tracking FSF's postal address
      rcutorture: Move checkarg to functions.sh
      rcutorture: Flag errors and warnings with color coding
      rcutorture: Record results from repeated runs of the same test scenario
      rcutorture: Test summary at end of run with less chattiness
      rcutorture: Update comment in kvm.sh listing typical RCU trace events
      rcutorture: Add tracing-enabled version of TREE08
      ...

commit d2012975619251bdfeb7a5159faa7727ea9cddd3
Author: Pablo Neira Ayuso <pablo@netfilter.org>
Date:   Fri Dec 27 10:44:23 2013 +0100

    netfilter: nf_tables: fix oops when updating table with user chains
    
    This patch fixes a crash while trying to deactivate a table that
    contains user chains. You can reproduce it via:
    
    % nft add table table1
    % nft add chain table1 chain1
    % nft-table-upd ip table1 dormant
    
    [  253.021026] BUG: unable to handle kernel NULL pointer dereference at 0000000000000030
    [  253.021114] IP: [<ffffffff8134cebd>] nf_register_hook+0x35/0x6f
    [  253.021167] PGD 30fa5067 PUD 30fa2067 PMD 0
    [  253.021208] Oops: 0000 [#1] SMP
    [...]
    [  253.023305] Call Trace:
    [  253.023331]  [<ffffffffa0885020>] nf_tables_newtable+0x11c/0x258 [nf_tables]
    [  253.023385]  [<ffffffffa0878592>] nfnetlink_rcv_msg+0x1f4/0x226 [nfnetlink]
    [  253.023438]  [<ffffffffa0878418>] ? nfnetlink_rcv_msg+0x7a/0x226 [nfnetlink]
    [  253.023491]  [<ffffffffa087839e>] ? nfnetlink_bind+0x45/0x45 [nfnetlink]
    [  253.023542]  [<ffffffff8134b47e>] netlink_rcv_skb+0x3c/0x88
    [  253.023586]  [<ffffffffa0878973>] nfnetlink_rcv+0x3af/0x3e4 [nfnetlink]
    [  253.023638]  [<ffffffff813fb0d4>] ? _raw_read_unlock+0x22/0x34
    [  253.023683]  [<ffffffff8134af17>] netlink_unicast+0xe2/0x161
    [  253.023727]  [<ffffffff8134b29a>] netlink_sendmsg+0x304/0x332
    [  253.023773]  [<ffffffff8130d250>] __sock_sendmsg_nosec+0x25/0x27
    [  253.023820]  [<ffffffff8130fb93>] sock_sendmsg+0x5a/0x7b
    [  253.023861]  [<ffffffff8130d5d5>] ? copy_from_user+0x2a/0x2c
    [  253.023905]  [<ffffffff8131066f>] ? move_addr_to_kernel+0x35/0x60
    [  253.023952]  [<ffffffff813107b3>] SYSC_sendto+0x119/0x15c
    [  253.023995]  [<ffffffff81401107>] ? sysret_check+0x1b/0x56
    [  253.024039]  [<ffffffff8108dc30>] ? trace_hardirqs_on_caller+0x140/0x1db
    [  253.024090]  [<ffffffff8120164e>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    [  253.024141]  [<ffffffff81310caf>] SyS_sendto+0x9/0xb
    [  253.026219]  [<ffffffff814010e2>] system_call_fastpath+0x16/0x1b
    
    Reported-by: Alex Wei <alex.kern.mentor@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit cbe63ac787193844217e30596ce9addf84dafa8e
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Dec 12 17:12:34 2013 -0800

    mm: memcg: fix race condition between memcg teardown and swapin
    
    commit 96f1c58d853497a757463e0b57fed140d6858f3a upstream.
    
    There is a race condition between a memcg being torn down and a swapin
    triggered from a different memcg of a page that was recorded to belong
    to the exiting memcg on swapout (with CONFIG_MEMCG_SWAP extension).  The
    result is unreclaimable pages pointing to dead memcgs, which can lead to
    anything from endless loops in later memcg teardown (the page is charged
    to all hierarchical parents but is not on any LRU list) or crashes from
    following the dangling memcg pointer.
    
    Memcgs with tasks in them can not be torn down and usually charges don't
    show up in memcgs without tasks.  Swapin with the CONFIG_MEMCG_SWAP
    extension is the notable exception because it charges the cgroup that
    was recorded as owner during swapout, which may be empty and in the
    process of being torn down when a task in another memcg triggers the
    swapin:
    
      teardown:                 swapin:
    
                                lookup_swap_cgroup_id()
                                rcu_read_lock()
                                mem_cgroup_lookup()
                                css_tryget()
                                rcu_read_unlock()
      disable css_tryget()
      call_rcu()
        offline_css()
          reparent_charges()
                                res_counter_charge() (hierarchical!)
                                css_put()
                                  css_free()
                                pc->mem_cgroup = dead memcg
                                add page to dead lru
    
    Add a final reparenting step into css_free() to make sure any such raced
    charges are moved out of the memcg before it's finally freed.
    
    In the longer term it would be cleaner to have the css_tryget() and the
    res_counter charge under the same RCU lock section so that the charge
    reparenting is deferred until the last charge whose tryget succeeded is
    visible.  But this will require more invasive changes that will be
    harder to evaluate and backport into stable, so better defer them to a
    separate change set.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 96f1c58d853497a757463e0b57fed140d6858f3a
Author: Johannes Weiner <hannes@cmpxchg.org>
Date:   Thu Dec 12 17:12:34 2013 -0800

    mm: memcg: fix race condition between memcg teardown and swapin
    
    There is a race condition between a memcg being torn down and a swapin
    triggered from a different memcg of a page that was recorded to belong
    to the exiting memcg on swapout (with CONFIG_MEMCG_SWAP extension).  The
    result is unreclaimable pages pointing to dead memcgs, which can lead to
    anything from endless loops in later memcg teardown (the page is charged
    to all hierarchical parents but is not on any LRU list) or crashes from
    following the dangling memcg pointer.
    
    Memcgs with tasks in them can not be torn down and usually charges don't
    show up in memcgs without tasks.  Swapin with the CONFIG_MEMCG_SWAP
    extension is the notable exception because it charges the cgroup that
    was recorded as owner during swapout, which may be empty and in the
    process of being torn down when a task in another memcg triggers the
    swapin:
    
      teardown:                 swapin:
    
                                lookup_swap_cgroup_id()
                                rcu_read_lock()
                                mem_cgroup_lookup()
                                css_tryget()
                                rcu_read_unlock()
      disable css_tryget()
      call_rcu()
        offline_css()
          reparent_charges()
                                res_counter_charge() (hierarchical!)
                                css_put()
                                  css_free()
                                pc->mem_cgroup = dead memcg
                                add page to dead lru
    
    Add a final reparenting step into css_free() to make sure any such raced
    charges are moved out of the memcg before it's finally freed.
    
    In the longer term it would be cleaner to have the css_tryget() and the
    res_counter charge under the same RCU lock section so that the charge
    reparenting is deferred until the last charge whose tryget succeeded is
    visible.  But this will require more invasive changes that will be
    harder to evaluate and backport into stable, so better defer them to a
    separate change set.
    
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: Michal Hocko <mhocko@suse.cz>
    Cc: David Rientjes <rientjes@google.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 79a62f957e0b37c59610a96d018cc341aebb48f4
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Wed Oct 30 04:13:22 2013 -0700

    rcu: Warn on allegedly impossible rcu_read_unlock_special() from irq
    
    After commit #10f39bb1b2c1 (rcu: protect __rcu_read_unlock() against
    scheduler-using irq handlers), it is no longer possible to enter
    the main body of rcu_read_lock_special() from an NMI, interrupt, or
    softirq handler.  In theory, this implies that the check for "in_irq()
    || in_serving_softirq()" must always fail, so that in theory this check
    could be removed entirely.
    
    In practice, this commit wraps this condition with a WARN_ON_ONCE().
    If this warning never triggers, then the condition will be removed
    entirely.
    
    [ paulmck: And one way of triggering the WARN_ON() is if a scheduling
      clock interrupt occurs in an RCU read-side critical section, setting
      RCU_READ_UNLOCK_NEED_QS, which is handled by rcu_read_unlock_special().
      Updated this commit to return if only that bit was set. ]
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit f080480488028bcc25357f85e8ae54ccc3bb7173
Merge: eda670c626a4 e504c9098ed6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Nov 15 13:51:36 2013 +0900

    Merge tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm
    
    Pull KVM changes from Paolo Bonzini:
     "Here are the 3.13 KVM changes.  There was a lot of work on the PPC
      side: the HV and emulation flavors can now coexist in a single kernel
      is probably the most interesting change from a user point of view.
    
      On the x86 side there are nested virtualization improvements and a few
      bugfixes.
    
      ARM got transparent huge page support, improved overcommit, and
      support for big endian guests.
    
      Finally, there is a new interface to connect KVM with VFIO.  This
      helps with devices that use NoSnoop PCI transactions, letting the
      driver in the guest execute WBINVD instructions.  This includes some
      nVidia cards on Windows, that fail to start without these patches and
      the corresponding userspace changes"
    
    * tag 'for-linus' of git://git.kernel.org/pub/scm/virt/kvm/kvm: (146 commits)
      kvm, vmx: Fix lazy FPU on nested guest
      arm/arm64: KVM: PSCI: propagate caller endianness to the incoming vcpu
      arm/arm64: KVM: MMIO support for BE guest
      kvm, cpuid: Fix sparse warning
      kvm: Delete prototype for non-existent function kvm_check_iopl
      kvm: Delete prototype for non-existent function complete_pio
      hung_task: add method to reset detector
      pvclock: detect watchdog reset at pvclock read
      kvm: optimize out smp_mb after srcu_read_unlock
      srcu: API for barrier after srcu read unlock
      KVM: remove vm mmap method
      KVM: IOMMU: hva align mapping page size
      KVM: x86: trace cpuid emulation when called from emulator
      KVM: emulator: cleanup decode_register_operand() a bit
      KVM: emulator: check rex prefix inside decode_register()
      KVM: x86: fix emulation of "movzbl %bpl, %eax"
      kvm_host: typo fix
      KVM: x86: emulate SAHF instruction
      MAINTAINERS: add tree for kvm.git
      Documentation/kvm: add a 00-INDEX file
      ...

commit 5ac68e7c34a4797aa4ca9615e5a6603bda1abe9b
Author: John Stultz <john.stultz@linaro.org>
Date:   Mon Oct 7 15:52:01 2013 -0700

    ipv6: Fix possible ipv6 seqlock deadlock
    
    While enabling lockdep on seqlocks, I ran across the warning below
    caused by the ipv6 stats being updated in both irq and non-irq context.
    
    This patch changes from IP6_INC_STATS_BH to IP6_INC_STATS (suggested
    by Eric Dumazet) to resolve this problem.
    
    [   11.120383] =================================
    [   11.121024] [ INFO: inconsistent lock state ]
    [   11.121663] 3.12.0-rc1+ #68 Not tainted
    [   11.122229] ---------------------------------
    [   11.122867] inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
    [   11.123741] init/4483 [HC0[0]:SC1[3]:HE1:SE0] takes:
    [   11.124505]  (&stats->syncp.seq#6){+.?...}, at: [<c1ab80c2>] ndisc_send_ns+0xe2/0x130
    [   11.125736] {SOFTIRQ-ON-W} state was registered at:
    [   11.126447]   [<c10e0eb7>] __lock_acquire+0x5c7/0x1af0
    [   11.127222]   [<c10e2996>] lock_acquire+0x96/0xd0
    [   11.127925]   [<c1a9a2c3>] write_seqcount_begin+0x33/0x40
    [   11.128766]   [<c1a9aa03>] ip6_dst_lookup_tail+0x3a3/0x460
    [   11.129582]   [<c1a9e0ce>] ip6_dst_lookup_flow+0x2e/0x80
    [   11.130014]   [<c1ad18e0>] ip6_datagram_connect+0x150/0x4e0
    [   11.130014]   [<c1a4d0b5>] inet_dgram_connect+0x25/0x70
    [   11.130014]   [<c198dd61>] SYSC_connect+0xa1/0xc0
    [   11.130014]   [<c198f571>] SyS_connect+0x11/0x20
    [   11.130014]   [<c198fe6b>] SyS_socketcall+0x12b/0x300
    [   11.130014]   [<c1bbf880>] syscall_call+0x7/0xb
    [   11.130014] irq event stamp: 1184
    [   11.130014] hardirqs last  enabled at (1184): [<c1086901>] local_bh_enable+0x71/0x110
    [   11.130014] hardirqs last disabled at (1183): [<c10868cd>] local_bh_enable+0x3d/0x110
    [   11.130014] softirqs last  enabled at (0): [<c108014d>] copy_process.part.42+0x45d/0x11a0
    [   11.130014] softirqs last disabled at (1147): [<c1086e05>] irq_exit+0xa5/0xb0
    [   11.130014]
    [   11.130014] other info that might help us debug this:
    [   11.130014]  Possible unsafe locking scenario:
    [   11.130014]
    [   11.130014]        CPU0
    [   11.130014]        ----
    [   11.130014]   lock(&stats->syncp.seq#6);
    [   11.130014]   <Interrupt>
    [   11.130014]     lock(&stats->syncp.seq#6);
    [   11.130014]
    [   11.130014]  *** DEADLOCK ***
    [   11.130014]
    [   11.130014] 3 locks held by init/4483:
    [   11.130014]  #0:  (rcu_read_lock){.+.+..}, at: [<c109363c>] SyS_setpriority+0x4c/0x620
    [   11.130014]  #1:  (((&ifa->dad_timer))){+.-...}, at: [<c108c1c0>] call_timer_fn+0x0/0xf0
    [   11.130014]  #2:  (rcu_read_lock){.+.+..}, at: [<c1ab6494>] ndisc_send_skb+0x54/0x5d0
    [   11.130014]
    [   11.130014] stack backtrace:
    [   11.130014] CPU: 0 PID: 4483 Comm: init Not tainted 3.12.0-rc1+ #68
    [   11.130014] Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011
    [   11.130014]  00000000 00000000 c55e5c10 c1bb0e71 c57128b0 c55e5c4c c1badf79 c1ec1123
    [   11.130014]  c1ec1484 00001183 00000000 00000000 00000001 00000003 00000001 00000000
    [   11.130014]  c1ec1484 00000004 c5712dcc 00000000 c55e5c84 c10de492 00000004 c10755f2
    [   11.130014] Call Trace:
    [   11.130014]  [<c1bb0e71>] dump_stack+0x4b/0x66
    [   11.130014]  [<c1badf79>] print_usage_bug+0x1d3/0x1dd
    [   11.130014]  [<c10de492>] mark_lock+0x282/0x2f0
    [   11.130014]  [<c10755f2>] ? kvm_clock_read+0x22/0x30
    [   11.130014]  [<c10dd8b0>] ? check_usage_backwards+0x150/0x150
    [   11.130014]  [<c10e0e74>] __lock_acquire+0x584/0x1af0
    [   11.130014]  [<c10b1baf>] ? sched_clock_cpu+0xef/0x190
    [   11.130014]  [<c10de58c>] ? mark_held_locks+0x8c/0xf0
    [   11.130014]  [<c10e2996>] lock_acquire+0x96/0xd0
    [   11.130014]  [<c1ab80c2>] ? ndisc_send_ns+0xe2/0x130
    [   11.130014]  [<c1ab66d3>] ndisc_send_skb+0x293/0x5d0
    [   11.130014]  [<c1ab80c2>] ? ndisc_send_ns+0xe2/0x130
    [   11.130014]  [<c1ab80c2>] ndisc_send_ns+0xe2/0x130
    [   11.130014]  [<c108cc32>] ? mod_timer+0xf2/0x160
    [   11.130014]  [<c1aa706e>] ? addrconf_dad_timer+0xce/0x150
    [   11.130014]  [<c1aa70aa>] addrconf_dad_timer+0x10a/0x150
    [   11.130014]  [<c1aa6fa0>] ? addrconf_dad_completed+0x1c0/0x1c0
    [   11.130014]  [<c108c233>] call_timer_fn+0x73/0xf0
    [   11.130014]  [<c108c1c0>] ? __internal_add_timer+0xb0/0xb0
    [   11.130014]  [<c1aa6fa0>] ? addrconf_dad_completed+0x1c0/0x1c0
    [   11.130014]  [<c108c5b1>] run_timer_softirq+0x141/0x1e0
    [   11.130014]  [<c1086b20>] ? __do_softirq+0x70/0x1b0
    [   11.130014]  [<c1086b70>] __do_softirq+0xc0/0x1b0
    [   11.130014]  [<c1086e05>] irq_exit+0xa5/0xb0
    [   11.130014]  [<c106cfd5>] smp_apic_timer_interrupt+0x35/0x50
    [   11.130014]  [<c1bbfbca>] apic_timer_interrupt+0x32/0x38
    [   11.130014]  [<c10936ed>] ? SyS_setpriority+0xfd/0x620
    [   11.130014]  [<c10e26c9>] ? lock_release+0x9/0x240
    [   11.130014]  [<c10936d7>] ? SyS_setpriority+0xe7/0x620
    [   11.130014]  [<c1bbee6d>] ? _raw_read_unlock+0x1d/0x30
    [   11.130014]  [<c1093701>] SyS_setpriority+0x111/0x620
    [   11.130014]  [<c109363c>] ? SyS_setpriority+0x4c/0x620
    [   11.130014]  [<c1bbf880>] syscall_call+0x7/0xb
    
    Signed-off-by: John Stultz <john.stultz@linaro.org>
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Alexey Kuznetsov <kuznet@ms2.inr.ac.ru>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: Hideaki YOSHIFUJI <yoshfuji@linux-ipv6.org>
    Cc: James Morris <jmorris@namei.org>
    Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
    Cc: Patrick McHardy <kaber@trash.net>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: netdev@vger.kernel.org
    Link: http://lkml.kernel.org/r/1381186321-4906-5-git-send-email-john.stultz@linaro.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 01b71917b55d28c09ade9fb8c683cf0d2aad1858
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Mon Nov 4 22:36:25 2013 +0200

    kvm: optimize out smp_mb after srcu_read_unlock
    
    I noticed that srcu_read_lock/unlock both have a memory barrier,
    so just by moving srcu_read_unlock earlier we can get rid of
    one call to smp_mb() using smp_mb__after_srcu_read_unlock instead.
    
    Unsurprisingly, the gain is small but measureable using the unit test
    microbenchmark:
    before
            vmcall in the ballpark of 1410 cycles
    after
            vmcall in the ballpark of 1360 cycles
    
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: Gleb Natapov <gleb@redhat.com>

commit b5aa3a472b6d13d57a7521a663290dea2fb483a7
Author: Steven Rostedt (Red Hat) <rostedt@goodmis.org>
Date:   Mon Nov 4 18:34:44 2013 -0500

    ftrace: Have control op function callback only trace when RCU is watching
    
    Dave Jones reported that trinity would be able to trigger the following
    back trace:
    
     ===============================
     [ INFO: suspicious RCU usage. ]
     3.10.0-rc2+ #38 Not tainted
     -------------------------------
     include/linux/rcupdate.h:771 rcu_read_lock() used illegally while idle!
     other info that might help us debug this:
    
     RCU used illegally from idle CPU!  rcu_scheduler_active = 1, debug_locks = 0
     RCU used illegally from extended quiescent state!
     1 lock held by trinity-child1/18786:
      #0:  (rcu_read_lock){.+.+..}, at: [<ffffffff8113dd48>] __perf_event_overflow+0x108/0x310
     stack backtrace:
     CPU: 3 PID: 18786 Comm: trinity-child1 Not tainted 3.10.0-rc2+ #38
      0000000000000000 ffff88020767bac8 ffffffff816e2f6b ffff88020767baf8
      ffffffff810b5897 ffff88021de92520 0000000000000000 ffff88020767bbf8
      0000000000000000 ffff88020767bb78 ffffffff8113ded4 ffffffff8113dd48
     Call Trace:
      [<ffffffff816e2f6b>] dump_stack+0x19/0x1b
      [<ffffffff810b5897>] lockdep_rcu_suspicious+0xe7/0x120
      [<ffffffff8113ded4>] __perf_event_overflow+0x294/0x310
      [<ffffffff8113dd48>] ? __perf_event_overflow+0x108/0x310
      [<ffffffff81309289>] ? __const_udelay+0x29/0x30
      [<ffffffff81076054>] ? __rcu_read_unlock+0x54/0xa0
      [<ffffffff816f4000>] ? ftrace_call+0x5/0x2f
      [<ffffffff8113dfa1>] perf_swevent_overflow+0x51/0xe0
      [<ffffffff8113e08f>] perf_swevent_event+0x5f/0x90
      [<ffffffff8113e1c9>] perf_tp_event+0x109/0x4f0
      [<ffffffff8113e36f>] ? perf_tp_event+0x2af/0x4f0
      [<ffffffff81074630>] ? __rcu_read_lock+0x20/0x20
      [<ffffffff8112d79f>] perf_ftrace_function_call+0xbf/0xd0
      [<ffffffff8110e1e1>] ? ftrace_ops_control_func+0x181/0x210
      [<ffffffff81074630>] ? __rcu_read_lock+0x20/0x20
      [<ffffffff81100cae>] ? rcu_eqs_enter_common+0x5e/0x470
      [<ffffffff8110e1e1>] ftrace_ops_control_func+0x181/0x210
      [<ffffffff816f4000>] ftrace_call+0x5/0x2f
      [<ffffffff8110e229>] ? ftrace_ops_control_func+0x1c9/0x210
      [<ffffffff816f4000>] ? ftrace_call+0x5/0x2f
      [<ffffffff81074635>] ? debug_lockdep_rcu_enabled+0x5/0x40
      [<ffffffff81074635>] ? debug_lockdep_rcu_enabled+0x5/0x40
      [<ffffffff81100cae>] ? rcu_eqs_enter_common+0x5e/0x470
      [<ffffffff8110112a>] rcu_eqs_enter+0x6a/0xb0
      [<ffffffff81103673>] rcu_user_enter+0x13/0x20
      [<ffffffff8114541a>] user_enter+0x6a/0xd0
      [<ffffffff8100f6d8>] syscall_trace_leave+0x78/0x140
      [<ffffffff816f46af>] int_check_syscall_exit_work+0x34/0x3d
     ------------[ cut here ]------------
    
    Perf uses rcu_read_lock() but as the function tracer can trace functions
    even when RCU is not currently active, this makes the rcu_read_lock()
    used by perf ineffective.
    
    As perf is currently the only user of the ftrace_ops_control_func() and
    perf is also the only function callback that actively uses rcu_read_lock(),
    the quick fix is to prevent the ftrace_ops_control_func() from calling
    its callbacks if RCU is not active.
    
    With Paul's new "rcu_is_watching()" we can tell if RCU is active or not.
    
    Reported-by: Dave Jones <davej@redhat.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

commit 363090e74f3865c589f4026b40865596b0212f90
Author: Peng Tao <bergwolf@gmail.com>
Date:   Mon Oct 21 23:18:23 2013 +0800

    staging/lustre/llite: fix mkdir endless loop
    
    Running on 3.11-rc4 kernel, I got below endless loop. It turns to be that Lustre
    always saves the first page of a dir inode mapping at index ~0UL.  And after
    commit 5a720394 (mm: teach truncate_inode_pages_range() to handle non page
    aligned ranges), truncate_inode_pages_range() _NO LONGER_ truncates the page
    that is sitting at index ~0UL.
    
    [16768.998006] mkdir           R  running task        0  2717   2716 0x00000080
    [16768.998073]  000000000000000e 0000000000000000 0000000000000000 ffff88000be00460
    [16768.998157]  ffff88000ea65908 ffffffff810fec3e ffff88000ea65968 ffff8800229e7750
    [16768.998241]  ffff88000ea658b8 0000000000000000 0000000000000000 ffff88000ea65958
    [16768.998326] Call Trace:
    [16768.998401]  [<ffffffff810fc6ed>] ? rcu_read_unlock+0x1c/0x2d
    [16768.998473]  [<ffffffff810fec3e>] ? find_get_pages+0xf5/0x11b
    [16768.998530]  [<ffffffff811078f0>] ? pagevec_lookup+0x20/0x2a
    [16768.998586]  [<ffffffff8110920e>] ? truncate_inode_pages_range.part.2+0x161/0x39a
    [16768.998680]  [<ffffffffa02ad5dc>] ? ll_md_blocking_ast+0x338/0x62f [lustre]
    [16768.998744]  [<ffffffff8110947f>] ? truncate_inode_pages_range+0x38/0x3f
    [16768.998805]  [<ffffffff811094f8>] ? truncate_inode_pages+0x12/0x14
    [16768.998871]  [<ffffffffa02ad6e8>] ? ll_md_blocking_ast+0x444/0x62f [lustre]
    [16768.998948]  [<ffffffff810981b5>] ? arch_local_irq_save+0x9/0xc
    [16768.999022]  [<ffffffffa07ee0e8>] ? ldlm_cancel_callback+0x67/0x12a [ptlrpc]
    [16768.999100]  [<ffffffffa07f85b2>] ? ldlm_cli_cancel_local+0xf3/0x2bc [ptlrpc]
    [16768.999176]  [<ffffffffa07f9163>] ? ldlm_cli_cancel_list_local+0x7e/0x1e4 [ptlrpc]
    [16768.999268]  [<ffffffffa07f9473>] ? ldlm_cancel_resource_local+0x1aa/0x1b9 [ptlrpc]
    [16768.999385]  [<ffffffffa0657bad>] ? mdc_resource_get_unused+0xf8/0x115 [mdc]
    [16768.999472]  [<ffffffff8109c887>] ? trace_hardirqs_on+0xd/0xf
    [16768.999533]  [<ffffffffa06583d8>] ? mdc_create+0x11e/0x4db [mdc]
    [16768.999597]  [<ffffffff8152ed84>] ? mutex_unlock+0xe/0x10
    [16768.999654]  [<ffffffffa0350e99>] ? lmv_create+0x355/0x3e9 [lmv]
    [16768.999712]  [<ffffffff811553b7>] ? final_putname+0x35/0x39
    [16768.999775]  [<ffffffffa02ae167>] ? ll_new_node+0x33b/0x3ff [lustre]
    [16768.999841]  [<ffffffffa02ae62c>] ? ll_mkdir+0xf2/0x127 [lustre]
    [16768.999897]  [<ffffffff81156996>] ? vfs_mkdir+0x84/0xc9
    [16768.999961]  [<ffffffff81158cf8>] ? SyS_mkdirat+0x77/0xad
    [16769.000014]  [<ffffffff81158d47>] ? SyS_mkdir+0x19/0x1b
    [16769.000066]  [<ffffffff81538652>] ? system_call_fastpath+0x16/0x1b
    
    Signed-off-by: Peng Tao <bergwolf@gmail.com>
    Signed-off-by: Andreas Dilger <andreas.dilger@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit aa7b08adf6ba9f5e5434c23181fdfee46eab979e
Author: Sasha Levin <levinsasha928@gmail.com>
Date:   Wed Jan 25 22:16:16 2012 -0500

    iscsi: don't hang in endless loop if no targets present
    
    commit 46a7c17d26967922092f3a8291815ffb20f6cabe upstream.
    
    iscsi_if_send_reply() may return -ESRCH if there were no targets to send
    data to. Currently we're ignoring this value and looping in attempt to do it
    over and over, which will usually lead in a hung task like this one:
    
    [ 4920.817298] INFO: task trinity:9074 blocked for more than 120 seconds.
    [ 4920.818527] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 4920.819982] trinity         D 0000000000000000  5504  9074   2756 0x00000004
    [ 4920.825374]  ffff880003961a98 0000000000000086 ffff8800001aa000 ffff8800001aa000
    [ 4920.826791]  00000000001d4340 ffff880003961fd8 ffff880003960000 00000000001d4340
    [ 4920.828241]  00000000001d4340 00000000001d4340 ffff880003961fd8 00000000001d4340
    [ 4920.833231]
    [ 4920.833519] Call Trace:
    [ 4920.834010]  [<ffffffff826363fa>] schedule+0x3a/0x50
    [ 4920.834953]  [<ffffffff82634ac9>] __mutex_lock_common+0x209/0x5b0
    [ 4920.836226]  [<ffffffff81af805d>] ? iscsi_if_rx+0x2d/0x990
    [ 4920.837281]  [<ffffffff81053943>] ? sched_clock+0x13/0x20
    [ 4920.838305]  [<ffffffff81af805d>] ? iscsi_if_rx+0x2d/0x990
    [ 4920.839336]  [<ffffffff82634eb0>] mutex_lock_nested+0x40/0x50
    [ 4920.840423]  [<ffffffff81af805d>] iscsi_if_rx+0x2d/0x990
    [ 4920.841434]  [<ffffffff810dffed>] ? sub_preempt_count+0x9d/0xd0
    [ 4920.842548]  [<ffffffff82637bb0>] ? _raw_read_unlock+0x30/0x60
    [ 4920.843666]  [<ffffffff821f71de>] netlink_unicast+0x1ae/0x1f0
    [ 4920.844751]  [<ffffffff821f7997>] netlink_sendmsg+0x227/0x350
    [ 4920.845850]  [<ffffffff821857bd>] ? sock_update_netprioidx+0xdd/0x1b0
    [ 4920.847060]  [<ffffffff82185732>] ? sock_update_netprioidx+0x52/0x1b0
    [ 4920.848276]  [<ffffffff8217f226>] sock_aio_write+0x166/0x180
    [ 4920.849348]  [<ffffffff810dfe41>] ? get_parent_ip+0x11/0x50
    [ 4920.850428]  [<ffffffff811d0d9a>] do_sync_write+0xda/0x120
    [ 4920.851465]  [<ffffffff810dffed>] ? sub_preempt_count+0x9d/0xd0
    [ 4920.852579]  [<ffffffff810dfe41>] ? get_parent_ip+0x11/0x50
    [ 4920.853608]  [<ffffffff81791887>] ? security_file_permission+0x27/0xb0
    [ 4920.854821]  [<ffffffff811d0f4c>] vfs_write+0x16c/0x180
    [ 4920.855781]  [<ffffffff811d104f>] sys_write+0x4f/0xa0
    [ 4920.856798]  [<ffffffff82638e79>] system_call_fastpath+0x16/0x1b
    [ 4920.877487] 1 lock held by trinity/9074:
    [ 4920.878239]  #0:  (rx_queue_mutex){+.+...}, at: [<ffffffff81af805d>] iscsi_if_rx+0x2d/0x990
    [ 4920.880005] Kernel panic - not syncing: hung_task: blocked tasks
    
    Signed-off-by: Sasha Levin <levinsasha928@gmail.com>
    Acked-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit b917eb155c56bbb766140b406979820e719e3f55
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Oct 18 14:43:55 2013 -0700

    ipv6: gso: remove redundant locking
    
    ipv6_gso_send_check() and ipv6_gso_segment() are called by
    skb_mac_gso_segment() under rcu lock, no need to use
    rcu_read_lock() / rcu_read_unlock()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 47d27aad44169372f358cda88a223883f6760fa5
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Oct 18 13:13:27 2013 -0700

    ipv4: gso: send_check() & segment() cleanups
    
    inet_gso_segment() and inet_gso_send_check() are called by
    skb_mac_gso_segment() under rcu lock, no need to use
    rcu_read_lock() / rcu_read_unlock()
    
    Avoid calling ip_hdr() twice per function.
    
    We can use ip_send_check() helper.
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 29ad23b00474c34e3b5040dda508c78d33a1a3eb
Author: Namhyung Kim <namhyung.kim@lge.com>
Date:   Mon Oct 14 17:24:26 2013 +0900

    ftrace: Add set_graph_notrace filter
    
    The set_graph_notrace filter is analogous to set_ftrace_notrace and
    can be used for eliminating uninteresting part of function graph trace
    output.  It also works with set_graph_function nicely.
    
      # cd /sys/kernel/debug/tracing/
      # echo do_page_fault > set_graph_function
      # perf ftrace live true
       2)               |  do_page_fault() {
       2)               |    __do_page_fault() {
       2)   0.381 us    |      down_read_trylock();
       2)   0.055 us    |      __might_sleep();
       2)   0.696 us    |      find_vma();
       2)               |      handle_mm_fault() {
       2)               |        handle_pte_fault() {
       2)               |          __do_fault() {
       2)               |            filemap_fault() {
       2)               |              find_get_page() {
       2)   0.033 us    |                __rcu_read_lock();
       2)   0.035 us    |                __rcu_read_unlock();
       2)   1.696 us    |              }
       2)   0.031 us    |              __might_sleep();
       2)   2.831 us    |            }
       2)               |            _raw_spin_lock() {
       2)   0.046 us    |              add_preempt_count();
       2)   0.841 us    |            }
       2)   0.033 us    |            page_add_file_rmap();
       2)               |            _raw_spin_unlock() {
       2)   0.057 us    |              sub_preempt_count();
       2)   0.568 us    |            }
       2)               |            unlock_page() {
       2)   0.084 us    |              page_waitqueue();
       2)   0.126 us    |              __wake_up_bit();
       2)   1.117 us    |            }
       2)   7.729 us    |          }
       2)   8.397 us    |        }
       2)   8.956 us    |      }
       2)   0.085 us    |      up_read();
       2) + 12.745 us   |    }
       2) + 13.401 us   |  }
      ...
    
      # echo handle_mm_fault > set_graph_notrace
      # perf ftrace live true
       1)               |  do_page_fault() {
       1)               |    __do_page_fault() {
       1)   0.205 us    |      down_read_trylock();
       1)   0.041 us    |      __might_sleep();
       1)   0.344 us    |      find_vma();
       1)   0.069 us    |      up_read();
       1)   4.692 us    |    }
       1)   5.311 us    |  }
      ...
    
    Link: http://lkml.kernel.org/r/1381739066-7531-5-git-send-email-namhyung@kernel.org
    
    Signed-off-by: Namhyung Kim <namhyung@kernel.org>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

commit 59ec90d76a4bf073b717142c9a08fd7db31b1ee4
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:25 2013 -0700

    ipc,msg: drop msg_unlock
    
    commit 4718787d1f626f45ddb239912bc07266b9880044 upstream.
    
    There is only one user left, drop this function and just call
    ipc_unlock_object() and rcu_read_unlock().
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c143813735d3246637e4ad60bfd4cf042189b83c
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:25 2013 -0700

    ipc,msg: drop msg_unlock
    
    commit 4718787d1f626f45ddb239912bc07266b9880044 upstream.
    
    There is only one user left, drop this function and just call
    ipc_unlock_object() and rcu_read_unlock().
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c00869f1ae6a8fa49802d5e60d843b7051a112ec
Author: Miao Xie <miaox@cn.fujitsu.com>
Date:   Wed Sep 25 21:47:44 2013 +0800

    Btrfs: fix oops caused by the space balance and dead roots
    
    When doing space balance and subvolume destroy at the same time, we met
    the following oops:
    
    kernel BUG at fs/btrfs/relocation.c:2247!
    RIP: 0010: [<ffffffffa04cec16>] prepare_to_merge+0x154/0x1f0 [btrfs]
    Call Trace:
     [<ffffffffa04b5ab7>] relocate_block_group+0x466/0x4e6 [btrfs]
     [<ffffffffa04b5c7a>] btrfs_relocate_block_group+0x143/0x275 [btrfs]
     [<ffffffffa0495c56>] btrfs_relocate_chunk.isra.27+0x5c/0x5a2 [btrfs]
     [<ffffffffa0459871>] ? btrfs_item_key_to_cpu+0x15/0x31 [btrfs]
     [<ffffffffa048b46a>] ? btrfs_get_token_64+0x7e/0xcd [btrfs]
     [<ffffffffa04a3467>] ? btrfs_tree_read_unlock_blocking+0xb2/0xb7 [btrfs]
     [<ffffffffa049907d>] btrfs_balance+0x9c7/0xb6f [btrfs]
     [<ffffffffa049ef84>] btrfs_ioctl_balance+0x234/0x2ac [btrfs]
     [<ffffffffa04a1e8e>] btrfs_ioctl+0xd87/0x1ef9 [btrfs]
     [<ffffffff81122f53>] ? path_openat+0x234/0x4db
     [<ffffffff813c3b78>] ? __do_page_fault+0x31d/0x391
     [<ffffffff810f8ab6>] ? vma_link+0x74/0x94
     [<ffffffff811250f5>] vfs_ioctl+0x1d/0x39
     [<ffffffff811258c8>] do_vfs_ioctl+0x32d/0x3e2
     [<ffffffff811259d4>] SyS_ioctl+0x57/0x83
     [<ffffffff813c3bfa>] ? do_page_fault+0xe/0x10
     [<ffffffff813c73c2>] system_call_fastpath+0x16/0x1b
    
    It is because we returned the error number if the reference of the root was 0
    when doing space relocation. It was not right here, because though the root
    was dead(refs == 0), but the space it held still need be relocated, or we
    could not remove the block group. So in this case, we should return the root
    no matter it is dead or not.
    
    Signed-off-by: Miao Xie <miaox@cn.fujitsu.com>
    Signed-off-by: Josef Bacik <jbacik@fusionio.com>
    Signed-off-by: Chris Mason <chris.mason@fusionio.com>

commit 3a454fd0a92af12ab465b88a25a7089e65eb8420
Author: Sasha Levin <levinsasha928@gmail.com>
Date:   Wed Jan 25 22:16:16 2012 -0500

    SCSI: iscsi: don't hang in endless loop if no targets present
    
    commit 46a7c17d26967922092f3a8291815ffb20f6cabe upstream.
    
    iscsi_if_send_reply() may return -ESRCH if there were no targets to send
    data to. Currently we're ignoring this value and looping in attempt to do it
    over and over, which will usually lead in a hung task like this one:
    
    [ 4920.817298] INFO: task trinity:9074 blocked for more than 120 seconds.
    [ 4920.818527] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 4920.819982] trinity         D 0000000000000000  5504  9074   2756 0x00000004
    [ 4920.825374]  ffff880003961a98 0000000000000086 ffff8800001aa000 ffff8800001aa000
    [ 4920.826791]  00000000001d4340 ffff880003961fd8 ffff880003960000 00000000001d4340
    [ 4920.828241]  00000000001d4340 00000000001d4340 ffff880003961fd8 00000000001d4340
    [ 4920.833231]
    [ 4920.833519] Call Trace:
    [ 4920.834010]  [<ffffffff826363fa>] schedule+0x3a/0x50
    [ 4920.834953]  [<ffffffff82634ac9>] __mutex_lock_common+0x209/0x5b0
    [ 4920.836226]  [<ffffffff81af805d>] ? iscsi_if_rx+0x2d/0x990
    [ 4920.837281]  [<ffffffff81053943>] ? sched_clock+0x13/0x20
    [ 4920.838305]  [<ffffffff81af805d>] ? iscsi_if_rx+0x2d/0x990
    [ 4920.839336]  [<ffffffff82634eb0>] mutex_lock_nested+0x40/0x50
    [ 4920.840423]  [<ffffffff81af805d>] iscsi_if_rx+0x2d/0x990
    [ 4920.841434]  [<ffffffff810dffed>] ? sub_preempt_count+0x9d/0xd0
    [ 4920.842548]  [<ffffffff82637bb0>] ? _raw_read_unlock+0x30/0x60
    [ 4920.843666]  [<ffffffff821f71de>] netlink_unicast+0x1ae/0x1f0
    [ 4920.844751]  [<ffffffff821f7997>] netlink_sendmsg+0x227/0x350
    [ 4920.845850]  [<ffffffff821857bd>] ? sock_update_netprioidx+0xdd/0x1b0
    [ 4920.847060]  [<ffffffff82185732>] ? sock_update_netprioidx+0x52/0x1b0
    [ 4920.848276]  [<ffffffff8217f226>] sock_aio_write+0x166/0x180
    [ 4920.849348]  [<ffffffff810dfe41>] ? get_parent_ip+0x11/0x50
    [ 4920.850428]  [<ffffffff811d0d9a>] do_sync_write+0xda/0x120
    [ 4920.851465]  [<ffffffff810dffed>] ? sub_preempt_count+0x9d/0xd0
    [ 4920.852579]  [<ffffffff810dfe41>] ? get_parent_ip+0x11/0x50
    [ 4920.853608]  [<ffffffff81791887>] ? security_file_permission+0x27/0xb0
    [ 4920.854821]  [<ffffffff811d0f4c>] vfs_write+0x16c/0x180
    [ 4920.855781]  [<ffffffff811d104f>] sys_write+0x4f/0xa0
    [ 4920.856798]  [<ffffffff82638e79>] system_call_fastpath+0x16/0x1b
    [ 4920.877487] 1 lock held by trinity/9074:
    [ 4920.878239]  #0:  (rx_queue_mutex){+.+...}, at: [<ffffffff81af805d>] iscsi_if_rx+0x2d/0x990
    [ 4920.880005] Kernel panic - not syncing: hung_task: blocked tasks
    
    Signed-off-by: Sasha Levin <levinsasha928@gmail.com>
    Acked-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f9ffc31ebd38d2d74dbfe9f0b67274e99ad668f5
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun Sep 8 11:51:06 2013 -0700

    rcu: Change EXPORT_SYMBOL() to EXPORT_SYMBOL_GPL()
    
    Commit e6b80a3b (rcu: Detect illegal rcu dereference in extended
    quiescent state) exported the pre-existing rcu_is_cpu_idle() function
    using EXPORT_SYMBOL().  However, this is inconsistent with the remaining
    exports from RCU, which are all EXPORT_SYMBOL_GPL().  The current state
    of affairs means that a non-GPL module could use rcu_is_cpu_idle(),
    but in a CONFIG_TREE_PREEMPT_RCU=y kernel would be unable to invoke
    rcu_read_lock() and rcu_read_unlock().
    
    This commit therefore makes rcu_is_cpu_idle()'s export be consistent
    with the rest of RCU, namely EXPORT_SYMBOL_GPL().
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit 4718787d1f626f45ddb239912bc07266b9880044
Author: Davidlohr Bueso <davidlohr.bueso@hp.com>
Date:   Wed Sep 11 14:26:25 2013 -0700

    ipc,msg: drop msg_unlock
    
    There is only one user left, drop this function and just call
    ipc_unlock_object() and rcu_read_unlock().
    
    Signed-off-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Tested-by: Sedat Dilek <sedat.dilek@gmail.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Manfred Spraul <manfred@colorfullife.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 6b3c538f5b2cfc53cb6803ec5001bbcf8f18a98e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:46 2013 -0700

    exec: cleanup the error handling in search_binary_handler()
    
    The error hanling and ret-from-loop look confusing and inconsistent.
    
    - "retval >= 0" simply returns
    
    - "!bprm->file" returns too but with read_unlock() because
       binfmt_lock was already re-acquired
    
    - "retval != -ENOEXEC || bprm->mm == NULL" does "break" and
      relies on the same check after the main loop
    
    Consolidate these checks into a single if/return statement.
    
    need_retry still checks "retval == -ENOEXEC", but this and -ENOENT before
    the main loop are not needed.  This is only for pathological and
    impossible list_empty(&formats) case.
    
    It is not clear why do we check "bprm->mm == NULL", probably this
    should be removed.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 92eaa565add62d56b90987f58ea9feafc5a7c183
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:42 2013 -0700

    exec: kill ->load_binary != NULL check in search_binary_handler()
    
    search_binary_handler() checks ->load_binary != NULL for no reason, this
    method should be always defined.  Turn this check into WARN_ON() and move
    it into __register_binfmt().
    
    Also, kill the function pointer.  The current code looks confusing, as if
    ->load_binary can go away after read_unlock(&binfmt_lock).  But we rely on
    module_get(fmt->module), this fmt can't be changed or unregistered,
    otherwise this code is buggy anyway.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 131b2f9f1214f338f0bf7c0d9760019f2b1d0c20
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Wed Sep 11 14:24:39 2013 -0700

    exec: kill "int depth" in search_binary_handler()
    
    Nobody except search_binary_handler() should touch ->recursion_depth, "int
    depth" buys nothing but complicates the code, kill it.
    
    Probably we should also kill "fn" and the !NULL check, ->load_binary
    should be always defined.  And it can not go away after read_unlock() or
    this code is buggy anyway.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Kees Cook <keescook@chromium.org>
    Cc: Al Viro <viro@ZenIV.linux.org.uk>
    Cc: Evgeniy Polyakov <zbr@ioremap.net>
    Cc: Zach Levis <zml@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 48f5ec21d9c67e881ff35343988e290ef5cf933f
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Mon Sep 9 15:22:25 2013 -0400

    split read_seqretry_or_unlock(), convert d_walk() to resulting primitives
    
    Separate "check if we need to retry" from "unlock if we are done and
    had seq_writelock"; that allows to use these guys in d_walk(), where
    we need to recheck every time we ascend back to parent, but do *not*
    want to unlock until the very end.  Lift rcu_read_lock/rcu_read_unlock
    out into callers.
    
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 41154a356f6516ffa266e50ff7d1bf706893dfe3
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jul 12 11:08:33 2013 +0200

    perf: Fix perf_lock_task_context() vs RCU
    
    commit 058ebd0eba3aff16b144eabf4510ed9510e1416e upstream.
    
    Jiri managed to trigger this warning:
    
     [] ======================================================
     [] [ INFO: possible circular locking dependency detected ]
     [] 3.10.0+ #228 Tainted: G        W
     [] -------------------------------------------------------
     [] p/6613 is trying to acquire lock:
     []  (rcu_node_0){..-...}, at: [<ffffffff810ca797>] rcu_read_unlock_special+0xa7/0x250
     []
     [] but task is already holding lock:
     []  (&ctx->lock){-.-...}, at: [<ffffffff810f2879>] perf_lock_task_context+0xd9/0x2c0
     []
     [] which lock already depends on the new lock.
     []
     [] the existing dependency chain (in reverse order) is:
     []
     [] -> #4 (&ctx->lock){-.-...}:
     [] -> #3 (&rq->lock){-.-.-.}:
     [] -> #2 (&p->pi_lock){-.-.-.}:
     [] -> #1 (&rnp->nocb_gp_wq[1]){......}:
     [] -> #0 (rcu_node_0){..-...}:
    
    Paul was quick to explain that due to preemptible RCU we cannot call
    rcu_read_unlock() while holding scheduler (or nested) locks when part
    of the read side critical section was preemptible.
    
    Therefore solve it by making the entire RCU read side non-preemptible.
    
    Also pull out the retry from under the non-preempt to play nice with RT.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Helped-out-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 795c3e68abaa0daa388ff2eb8bc577db955d8f7e
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jul 12 11:08:33 2013 +0200

    perf: Fix perf_lock_task_context() vs RCU
    
    commit 058ebd0eba3aff16b144eabf4510ed9510e1416e upstream.
    
    Jiri managed to trigger this warning:
    
     [] ======================================================
     [] [ INFO: possible circular locking dependency detected ]
     [] 3.10.0+ #228 Tainted: G        W
     [] -------------------------------------------------------
     [] p/6613 is trying to acquire lock:
     []  (rcu_node_0){..-...}, at: [<ffffffff810ca797>] rcu_read_unlock_special+0xa7/0x250
     []
     [] but task is already holding lock:
     []  (&ctx->lock){-.-...}, at: [<ffffffff810f2879>] perf_lock_task_context+0xd9/0x2c0
     []
     [] which lock already depends on the new lock.
     []
     [] the existing dependency chain (in reverse order) is:
     []
     [] -> #4 (&ctx->lock){-.-...}:
     [] -> #3 (&rq->lock){-.-.-.}:
     [] -> #2 (&p->pi_lock){-.-.-.}:
     [] -> #1 (&rnp->nocb_gp_wq[1]){......}:
     [] -> #0 (rcu_node_0){..-...}:
    
    Paul was quick to explain that due to preemptible RCU we cannot call
    rcu_read_unlock() while holding scheduler (or nested) locks when part
    of the read side critical section was preemptible.
    
    Therefore solve it by making the entire RCU read side non-preemptible.
    
    Also pull out the retry from under the non-preempt to play nice with RT.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Helped-out-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dcfe8048de66c3468060c8a2ec2c04ae3725d002
Author: nikolay@redhat.com <nikolay@redhat.com>
Date:   Sat Jul 27 19:10:10 2013 +0200

    bonding: remove bond_resend_igmp_join_requests read_unlock leftover
    
    After commit 4aa5dee4d9 ("net: convert resend IGMP to notifier event") we
    have 1 read_unlock in bond_resend_igmp_join_requests which isn't paired
    with a read_lock because it's removed by that commit.
    
    Signed-off-by: Nikolay Aleksandrov <nikolay@redhat.com>
    Reviewed-by: Jiri Pirko <jiri@resnulli.us>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a7aa204def549434aa80457926bc49300b18b181
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jul 12 11:08:33 2013 +0200

    perf: Fix perf_lock_task_context() vs RCU
    
    commit 058ebd0eba3aff16b144eabf4510ed9510e1416e upstream.
    
    Jiri managed to trigger this warning:
    
     [] ======================================================
     [] [ INFO: possible circular locking dependency detected ]
     [] 3.10.0+ #228 Tainted: G        W
     [] -------------------------------------------------------
     [] p/6613 is trying to acquire lock:
     []  (rcu_node_0){..-...}, at: [<ffffffff810ca797>] rcu_read_unlock_special+0xa7/0x250
     []
     [] but task is already holding lock:
     []  (&ctx->lock){-.-...}, at: [<ffffffff810f2879>] perf_lock_task_context+0xd9/0x2c0
     []
     [] which lock already depends on the new lock.
     []
     [] the existing dependency chain (in reverse order) is:
     []
     [] -> #4 (&ctx->lock){-.-...}:
     [] -> #3 (&rq->lock){-.-.-.}:
     [] -> #2 (&p->pi_lock){-.-.-.}:
     [] -> #1 (&rnp->nocb_gp_wq[1]){......}:
     [] -> #0 (rcu_node_0){..-...}:
    
    Paul was quick to explain that due to preemptible RCU we cannot call
    rcu_read_unlock() while holding scheduler (or nested) locks when part
    of the read side critical section was preemptible.
    
    Therefore solve it by making the entire RCU read side non-preemptible.
    
    Also pull out the retry from under the non-preempt to play nice with RT.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Helped-out-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 65e303d786e20460c3d67d362f989f59944fb744
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jul 12 11:08:33 2013 +0200

    perf: Fix perf_lock_task_context() vs RCU
    
    commit 058ebd0eba3aff16b144eabf4510ed9510e1416e upstream.
    
    Jiri managed to trigger this warning:
    
     [] ======================================================
     [] [ INFO: possible circular locking dependency detected ]
     [] 3.10.0+ #228 Tainted: G        W
     [] -------------------------------------------------------
     [] p/6613 is trying to acquire lock:
     []  (rcu_node_0){..-...}, at: [<ffffffff810ca797>] rcu_read_unlock_special+0xa7/0x250
     []
     [] but task is already holding lock:
     []  (&ctx->lock){-.-...}, at: [<ffffffff810f2879>] perf_lock_task_context+0xd9/0x2c0
     []
     [] which lock already depends on the new lock.
     []
     [] the existing dependency chain (in reverse order) is:
     []
     [] -> #4 (&ctx->lock){-.-...}:
     [] -> #3 (&rq->lock){-.-.-.}:
     [] -> #2 (&p->pi_lock){-.-.-.}:
     [] -> #1 (&rnp->nocb_gp_wq[1]){......}:
     [] -> #0 (rcu_node_0){..-...}:
    
    Paul was quick to explain that due to preemptible RCU we cannot call
    rcu_read_unlock() while holding scheduler (or nested) locks when part
    of the read side critical section was preemptible.
    
    Therefore solve it by making the entire RCU read side non-preemptible.
    
    Also pull out the retry from under the non-preempt to play nice with RT.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Helped-out-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 058ebd0eba3aff16b144eabf4510ed9510e1416e
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jul 12 11:08:33 2013 +0200

    perf: Fix perf_lock_task_context() vs RCU
    
    Jiri managed to trigger this warning:
    
     [] ======================================================
     [] [ INFO: possible circular locking dependency detected ]
     [] 3.10.0+ #228 Tainted: G        W
     [] -------------------------------------------------------
     [] p/6613 is trying to acquire lock:
     []  (rcu_node_0){..-...}, at: [<ffffffff810ca797>] rcu_read_unlock_special+0xa7/0x250
     []
     [] but task is already holding lock:
     []  (&ctx->lock){-.-...}, at: [<ffffffff810f2879>] perf_lock_task_context+0xd9/0x2c0
     []
     [] which lock already depends on the new lock.
     []
     [] the existing dependency chain (in reverse order) is:
     []
     [] -> #4 (&ctx->lock){-.-...}:
     [] -> #3 (&rq->lock){-.-.-.}:
     [] -> #2 (&p->pi_lock){-.-.-.}:
     [] -> #1 (&rnp->nocb_gp_wq[1]){......}:
     [] -> #0 (rcu_node_0){..-...}:
    
    Paul was quick to explain that due to preemptible RCU we cannot call
    rcu_read_unlock() while holding scheduler (or nested) locks when part
    of the read side critical section was preemptible.
    
    Therefore solve it by making the entire RCU read side non-preemptible.
    
    Also pull out the retry from under the non-preempt to play nice with RT.
    
    Reported-by: Jiri Olsa <jolsa@redhat.com>
    Helped-out-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: <stable@kernel.org>
    Signed-off-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit ab3d681e9d41816f90836ea8fe235168d973207f
Merge: 0c46d68d1930 b1fe9987b787
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 2 16:13:29 2013 -0700

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU updates from Ingo Molnar:
     "The major changes:
    
      - Simplify RCU's grace-period and callback processing based on the new
        numbering for callbacks.
    
      - Removal of TINY_PREEMPT_RCU in favor of TREE_PREEMPT_RCU for
        single-CPU low-latency systems.
    
      - SRCU-related changes and fixes.
    
      - Miscellaneous fixes, including converting a few remaining printk()
        calls to pr_*().
    
      - Documentation updates"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (32 commits)
      rcu: Shrink TINY_RCU by reworking CPU-stall ifdefs
      rcu: Shrink TINY_RCU by moving exit_rcu()
      rcu: Remove TINY_PREEMPT_RCU tracing documentation
      rcu: Consolidate rcutiny_plugin.h ifdefs
      rcu: Remove rcu_preempt_note_context_switch()
      rcu: Remove the CONFIG_TINY_RCU ifdefs in rcutiny.h
      rcu: Remove check_cpu_stall_preempt()
      rcu: Simplify RCU_TINY RCU callback invocation
      rcu: Remove rcu_preempt_process_callbacks()
      rcu: Remove rcu_preempt_remove_callbacks()
      rcu: Remove rcu_preempt_check_callbacks()
      rcu: Remove show_tiny_preempt_stats()
      rcu: Remove TINY_PREEMPT_RCU
      powerpc,kvm: fix imbalance srcu_read_[un]lock()
      rcu: Remove srcu_read_lock_raw() and srcu_read_unlock_raw().
      rcu: Apply Dave Jones's NOCB Kconfig help feedback
      rcu: Merge adjacent identical ifdefs
      rcu: Drive quiescent-state-forcing delay from HZ
      rcu: Remove "Experimental" flags
      kthread: Add kworker kthreads to OS-jitter documentation
      ...

commit 3a36515f729458c8efa0c124c7262d5843ad5c37
Author: Pablo Neira <pablo@netfilter.org>
Date:   Fri Jun 28 03:04:23 2013 +0200

    netlink: fix splat in skb_clone with large messages
    
    Since (c05cdb1 netlink: allow large data transfers from user-space),
    netlink splats if it invokes skb_clone on large netlink skbs since:
    
    * skb_shared_info was not correctly initialized.
    * skb->destructor is not set in the cloned skb.
    
    This was spotted by trinity:
    
    [  894.990671] BUG: unable to handle kernel paging request at ffffc9000047b001
    [  894.991034] IP: [<ffffffff81a212c4>] skb_clone+0x24/0xc0
    [...]
    [  894.991034] Call Trace:
    [  894.991034]  [<ffffffff81ad299a>] nl_fib_input+0x6a/0x240
    [  894.991034]  [<ffffffff81c3b7e6>] ? _raw_read_unlock+0x26/0x40
    [  894.991034]  [<ffffffff81a5f189>] netlink_unicast+0x169/0x1e0
    [  894.991034]  [<ffffffff81a601e1>] netlink_sendmsg+0x251/0x3d0
    
    Fix it by:
    
    1) introducing a new netlink_skb_clone function that is used in nl_fib_input,
       that sets our special skb->destructor in the cloned skb. Moreover, handle
       the release of the large cloned skb head area in the destructor path.
    
    2) not allowing large skbuffs in the netlink broadcast path. I cannot find
       any reasonable use of the large data transfer using netlink in that path,
       moreover this helps to skip extra skb_clone handling.
    
    I found two more netlink clients that are cloning the skbs, but they are
    not in the sendmsg path. Therefore, the sole client cloning that I found
    seems to be the fib frontend.
    
    Thanks to Eric Dumazet for helping to address this issue.
    
    Reported-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 99f88919f8fa8a8b01b5306c59c9977b94604df8
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Mar 12 16:54:14 2013 -0700

    rcu: Remove srcu_read_lock_raw() and srcu_read_unlock_raw().
    
    These interfaces never did get used, so this commit removes them,
    their rcutorture tests, and documentation referencing them.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit 016a8d5be6ddcc72ef0432d82d9f6fa34f61b907
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Tue May 28 17:32:53 2013 -0400

    rcu: Don't call wakeup() with rcu_node structure ->lock held
    
    This commit fixes a lockdep-detected deadlock by moving a wake_up()
    call out from a rnp->lock critical section.  Please see below for
    the long version of this story.
    
    On Tue, 2013-05-28 at 16:13 -0400, Dave Jones wrote:
    
    > [12572.705832] ======================================================
    > [12572.750317] [ INFO: possible circular locking dependency detected ]
    > [12572.796978] 3.10.0-rc3+ #39 Not tainted
    > [12572.833381] -------------------------------------------------------
    > [12572.862233] trinity-child17/31341 is trying to acquire lock:
    > [12572.870390]  (rcu_node_0){..-.-.}, at: [<ffffffff811054ff>] rcu_read_unlock_special+0x9f/0x4c0
    > [12572.878859]
    > but task is already holding lock:
    > [12572.894894]  (&ctx->lock){-.-...}, at: [<ffffffff811390ed>] perf_lock_task_context+0x7d/0x2d0
    > [12572.903381]
    > which lock already depends on the new lock.
    >
    > [12572.927541]
    > the existing dependency chain (in reverse order) is:
    > [12572.943736]
    > -> #4 (&ctx->lock){-.-...}:
    > [12572.960032]        [<ffffffff810b9851>] lock_acquire+0x91/0x1f0
    > [12572.968337]        [<ffffffff816ebc90>] _raw_spin_lock+0x40/0x80
    > [12572.976633]        [<ffffffff8113c987>] __perf_event_task_sched_out+0x2e7/0x5e0
    > [12572.984969]        [<ffffffff81088953>] perf_event_task_sched_out+0x93/0xa0
    > [12572.993326]        [<ffffffff816ea0bf>] __schedule+0x2cf/0x9c0
    > [12573.001652]        [<ffffffff816eacfe>] schedule_user+0x2e/0x70
    > [12573.009998]        [<ffffffff816ecd64>] retint_careful+0x12/0x2e
    > [12573.018321]
    > -> #3 (&rq->lock){-.-.-.}:
    > [12573.034628]        [<ffffffff810b9851>] lock_acquire+0x91/0x1f0
    > [12573.042930]        [<ffffffff816ebc90>] _raw_spin_lock+0x40/0x80
    > [12573.051248]        [<ffffffff8108e6a7>] wake_up_new_task+0xb7/0x260
    > [12573.059579]        [<ffffffff810492f5>] do_fork+0x105/0x470
    > [12573.067880]        [<ffffffff81049686>] kernel_thread+0x26/0x30
    > [12573.076202]        [<ffffffff816cee63>] rest_init+0x23/0x140
    > [12573.084508]        [<ffffffff81ed8e1f>] start_kernel+0x3f1/0x3fe
    > [12573.092852]        [<ffffffff81ed856f>] x86_64_start_reservations+0x2a/0x2c
    > [12573.101233]        [<ffffffff81ed863d>] x86_64_start_kernel+0xcc/0xcf
    > [12573.109528]
    > -> #2 (&p->pi_lock){-.-.-.}:
    > [12573.125675]        [<ffffffff810b9851>] lock_acquire+0x91/0x1f0
    > [12573.133829]        [<ffffffff816ebe9b>] _raw_spin_lock_irqsave+0x4b/0x90
    > [12573.141964]        [<ffffffff8108e881>] try_to_wake_up+0x31/0x320
    > [12573.150065]        [<ffffffff8108ebe2>] default_wake_function+0x12/0x20
    > [12573.158151]        [<ffffffff8107bbf8>] autoremove_wake_function+0x18/0x40
    > [12573.166195]        [<ffffffff81085398>] __wake_up_common+0x58/0x90
    > [12573.174215]        [<ffffffff81086909>] __wake_up+0x39/0x50
    > [12573.182146]        [<ffffffff810fc3da>] rcu_start_gp_advanced.isra.11+0x4a/0x50
    > [12573.190119]        [<ffffffff810fdb09>] rcu_start_future_gp+0x1c9/0x1f0
    > [12573.198023]        [<ffffffff810fe2c4>] rcu_nocb_kthread+0x114/0x930
    > [12573.205860]        [<ffffffff8107a91d>] kthread+0xed/0x100
    > [12573.213656]        [<ffffffff816f4b1c>] ret_from_fork+0x7c/0xb0
    > [12573.221379]
    > -> #1 (&rsp->gp_wq){..-.-.}:
    > [12573.236329]        [<ffffffff810b9851>] lock_acquire+0x91/0x1f0
    > [12573.243783]        [<ffffffff816ebe9b>] _raw_spin_lock_irqsave+0x4b/0x90
    > [12573.251178]        [<ffffffff810868f3>] __wake_up+0x23/0x50
    > [12573.258505]        [<ffffffff810fc3da>] rcu_start_gp_advanced.isra.11+0x4a/0x50
    > [12573.265891]        [<ffffffff810fdb09>] rcu_start_future_gp+0x1c9/0x1f0
    > [12573.273248]        [<ffffffff810fe2c4>] rcu_nocb_kthread+0x114/0x930
    > [12573.280564]        [<ffffffff8107a91d>] kthread+0xed/0x100
    > [12573.287807]        [<ffffffff816f4b1c>] ret_from_fork+0x7c/0xb0
    
    Notice the above call chain.
    
    rcu_start_future_gp() is called with the rnp->lock held. Then it calls
    rcu_start_gp_advance, which does a wakeup.
    
    You can't do wakeups while holding the rnp->lock, as that would mean
    that you could not do a rcu_read_unlock() while holding the rq lock, or
    any lock that was taken while holding the rq lock. This is because...
    (See below).
    
    > [12573.295067]
    > -> #0 (rcu_node_0){..-.-.}:
    > [12573.309293]        [<ffffffff810b8d36>] __lock_acquire+0x1786/0x1af0
    > [12573.316568]        [<ffffffff810b9851>] lock_acquire+0x91/0x1f0
    > [12573.323825]        [<ffffffff816ebc90>] _raw_spin_lock+0x40/0x80
    > [12573.331081]        [<ffffffff811054ff>] rcu_read_unlock_special+0x9f/0x4c0
    > [12573.338377]        [<ffffffff810760a6>] __rcu_read_unlock+0x96/0xa0
    > [12573.345648]        [<ffffffff811391b3>] perf_lock_task_context+0x143/0x2d0
    > [12573.352942]        [<ffffffff8113938e>] find_get_context+0x4e/0x1f0
    > [12573.360211]        [<ffffffff811403f4>] SYSC_perf_event_open+0x514/0xbd0
    > [12573.367514]        [<ffffffff81140e49>] SyS_perf_event_open+0x9/0x10
    > [12573.374816]        [<ffffffff816f4dd4>] tracesys+0xdd/0xe2
    
    Notice the above trace.
    
    perf took its own ctx->lock, which can be taken while holding the rq
    lock. While holding this lock, it did a rcu_read_unlock(). The
    perf_lock_task_context() basically looks like:
    
    rcu_read_lock();
    raw_spin_lock(ctx->lock);
    rcu_read_unlock();
    
    Now, what looks to have happened, is that we scheduled after taking that
    first rcu_read_lock() but before taking the spin lock. When we scheduled
    back in and took the ctx->lock, the following rcu_read_unlock()
    triggered the "special" code.
    
    The rcu_read_unlock_special() takes the rnp->lock, which gives us a
    possible deadlock scenario.
    
            CPU0            CPU1            CPU2
            ----            ----            ----
    
                                         rcu_nocb_kthread()
        lock(rq->lock);
                        lock(ctx->lock);
                                         lock(rnp->lock);
    
                                         wake_up();
    
                                         lock(rq->lock);
    
                        rcu_read_unlock();
    
                        rcu_read_unlock_special();
    
                        lock(rnp->lock);
        lock(ctx->lock);
    
    **** DEADLOCK ****
    
    > [12573.382068]
    > other info that might help us debug this:
    >
    > [12573.403229] Chain exists of:
    >   rcu_node_0 --> &rq->lock --> &ctx->lock
    >
    > [12573.424471]  Possible unsafe locking scenario:
    >
    > [12573.438499]        CPU0                    CPU1
    > [12573.445599]        ----                    ----
    > [12573.452691]   lock(&ctx->lock);
    > [12573.459799]                                lock(&rq->lock);
    > [12573.467010]                                lock(&ctx->lock);
    > [12573.474192]   lock(rcu_node_0);
    > [12573.481262]
    >  *** DEADLOCK ***
    >
    > [12573.501931] 1 lock held by trinity-child17/31341:
    > [12573.508990]  #0:  (&ctx->lock){-.-...}, at: [<ffffffff811390ed>] perf_lock_task_context+0x7d/0x2d0
    > [12573.516475]
    > stack backtrace:
    > [12573.530395] CPU: 1 PID: 31341 Comm: trinity-child17 Not tainted 3.10.0-rc3+ #39
    > [12573.545357]  ffffffff825b4f90 ffff880219f1dbc0 ffffffff816e375b ffff880219f1dc00
    > [12573.552868]  ffffffff816dfa5d ffff880219f1dc50 ffff88023ce4d1f8 ffff88023ce4ca40
    > [12573.560353]  0000000000000001 0000000000000001 ffff88023ce4d1f8 ffff880219f1dcc0
    > [12573.567856] Call Trace:
    > [12573.575011]  [<ffffffff816e375b>] dump_stack+0x19/0x1b
    > [12573.582284]  [<ffffffff816dfa5d>] print_circular_bug+0x200/0x20f
    > [12573.589637]  [<ffffffff810b8d36>] __lock_acquire+0x1786/0x1af0
    > [12573.596982]  [<ffffffff810918f5>] ? sched_clock_cpu+0xb5/0x100
    > [12573.604344]  [<ffffffff810b9851>] lock_acquire+0x91/0x1f0
    > [12573.611652]  [<ffffffff811054ff>] ? rcu_read_unlock_special+0x9f/0x4c0
    > [12573.619030]  [<ffffffff816ebc90>] _raw_spin_lock+0x40/0x80
    > [12573.626331]  [<ffffffff811054ff>] ? rcu_read_unlock_special+0x9f/0x4c0
    > [12573.633671]  [<ffffffff811054ff>] rcu_read_unlock_special+0x9f/0x4c0
    > [12573.640992]  [<ffffffff811390ed>] ? perf_lock_task_context+0x7d/0x2d0
    > [12573.648330]  [<ffffffff810b429e>] ? put_lock_stats.isra.29+0xe/0x40
    > [12573.655662]  [<ffffffff813095a0>] ? delay_tsc+0x90/0xe0
    > [12573.662964]  [<ffffffff810760a6>] __rcu_read_unlock+0x96/0xa0
    > [12573.670276]  [<ffffffff811391b3>] perf_lock_task_context+0x143/0x2d0
    > [12573.677622]  [<ffffffff81139070>] ? __perf_event_enable+0x370/0x370
    > [12573.684981]  [<ffffffff8113938e>] find_get_context+0x4e/0x1f0
    > [12573.692358]  [<ffffffff811403f4>] SYSC_perf_event_open+0x514/0xbd0
    > [12573.699753]  [<ffffffff8108cd9d>] ? get_parent_ip+0xd/0x50
    > [12573.707135]  [<ffffffff810b71fd>] ? trace_hardirqs_on_caller+0xfd/0x1c0
    > [12573.714599]  [<ffffffff81140e49>] SyS_perf_event_open+0x9/0x10
    > [12573.721996]  [<ffffffff816f4dd4>] tracesys+0xdd/0xe2
    
    This commit delays the wakeup via irq_work(), which is what
    perf and ftrace use to perform wakeups in critical sections.
    
    Reported-by: Dave Jones <davej@redhat.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 45f2ae9ac0dfef088a0acd577f24bc781690562d
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Fri May 24 15:55:11 2013 -0700

    mm: mmu_notifier: re-fix freed page still mapped in secondary MMU
    
    commit d34883d4e35c0a994e91dd847a82b4c9e0c31d83 upstream.
    
    Commit 751efd8610d3 ("mmu_notifier_unregister NULL Pointer deref and
    multiple ->release()") breaks the fix 3ad3d901bbcf ("mm: mmu_notifier:
    fix freed page still mapped in secondary MMU").
    
    Since hlist_for_each_entry_rcu() is changed now, we can not revert that
    patch directly, so this patch reverts the commit and simply fix the bug
    spotted by that patch
    
    This bug spotted by commit 751efd8610d3 is:
    
        There is a race condition between mmu_notifier_unregister() and
        __mmu_notifier_release().
    
        Assume two tasks, one calling mmu_notifier_unregister() as a result
        of a filp_close() ->flush() callout (task A), and the other calling
        mmu_notifier_release() from an mmput() (task B).
    
                            A                               B
        t1                                            srcu_read_lock()
        t2            if (!hlist_unhashed())
        t3                                            srcu_read_unlock()
        t4            srcu_read_lock()
        t5                                            hlist_del_init_rcu()
        t6                                            synchronize_srcu()
        t7            srcu_read_unlock()
        t8            hlist_del_rcu()  <--- NULL pointer deref.
    
    This can be fixed by using hlist_del_init_rcu instead of hlist_del_rcu.
    
    The another issue spotted in the commit is "multiple ->release()
    callouts", we needn't care it too much because it is really rare (e.g,
    can not happen on kvm since mmu-notify is unregistered after
    exit_mmap()) and the later call of multiple ->release should be fast
    since all the pages have already been released by the first call.
    Anyway, this issue should be fixed in a separate patch.
    
    -stable suggestions: Any version that has commit 751efd8610d3 need to be
    backported.  I find the oldest version has this commit is 3.0-stable.
    
    [akpm@linux-foundation.org: tweak comments]
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Tested-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bfd7610d981cd0fab6d68576c638c8e7550f3e51
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Fri May 24 15:55:11 2013 -0700

    mm: mmu_notifier: re-fix freed page still mapped in secondary MMU
    
    commit d34883d4e35c0a994e91dd847a82b4c9e0c31d83 upstream.
    
    Commit 751efd8610d3 ("mmu_notifier_unregister NULL Pointer deref and
    multiple ->release()") breaks the fix 3ad3d901bbcf ("mm: mmu_notifier:
    fix freed page still mapped in secondary MMU").
    
    Since hlist_for_each_entry_rcu() is changed now, we can not revert that
    patch directly, so this patch reverts the commit and simply fix the bug
    spotted by that patch
    
    This bug spotted by commit 751efd8610d3 is:
    
        There is a race condition between mmu_notifier_unregister() and
        __mmu_notifier_release().
    
        Assume two tasks, one calling mmu_notifier_unregister() as a result
        of a filp_close() ->flush() callout (task A), and the other calling
        mmu_notifier_release() from an mmput() (task B).
    
                            A                               B
        t1                                            srcu_read_lock()
        t2            if (!hlist_unhashed())
        t3                                            srcu_read_unlock()
        t4            srcu_read_lock()
        t5                                            hlist_del_init_rcu()
        t6                                            synchronize_srcu()
        t7            srcu_read_unlock()
        t8            hlist_del_rcu()  <--- NULL pointer deref.
    
    This can be fixed by using hlist_del_init_rcu instead of hlist_del_rcu.
    
    The another issue spotted in the commit is "multiple ->release()
    callouts", we needn't care it too much because it is really rare (e.g,
    can not happen on kvm since mmu-notify is unregistered after
    exit_mmap()) and the later call of multiple ->release should be fast
    since all the pages have already been released by the first call.
    Anyway, this issue should be fixed in a separate patch.
    
    -stable suggestions: Any version that has commit 751efd8610d3 need to be
    backported.  I find the oldest version has this commit is 3.0-stable.
    
    [akpm@linux-foundation.org: tweak comments]
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Tested-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 329d6f2ca0653e8a078637ed42ba259f5414e872
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Fri May 24 15:55:11 2013 -0700

    mm: mmu_notifier: re-fix freed page still mapped in secondary MMU
    
    commit d34883d4e35c0a994e91dd847a82b4c9e0c31d83 upstream.
    
    Commit 751efd8610d3 ("mmu_notifier_unregister NULL Pointer deref and
    multiple ->release()") breaks the fix 3ad3d901bbcf ("mm: mmu_notifier:
    fix freed page still mapped in secondary MMU").
    
    Since hlist_for_each_entry_rcu() is changed now, we can not revert that
    patch directly, so this patch reverts the commit and simply fix the bug
    spotted by that patch
    
    This bug spotted by commit 751efd8610d3 is:
    
        There is a race condition between mmu_notifier_unregister() and
        __mmu_notifier_release().
    
        Assume two tasks, one calling mmu_notifier_unregister() as a result
        of a filp_close() ->flush() callout (task A), and the other calling
        mmu_notifier_release() from an mmput() (task B).
    
                            A                               B
        t1                                            srcu_read_lock()
        t2            if (!hlist_unhashed())
        t3                                            srcu_read_unlock()
        t4            srcu_read_lock()
        t5                                            hlist_del_init_rcu()
        t6                                            synchronize_srcu()
        t7            srcu_read_unlock()
        t8            hlist_del_rcu()  <--- NULL pointer deref.
    
    This can be fixed by using hlist_del_init_rcu instead of hlist_del_rcu.
    
    The another issue spotted in the commit is "multiple ->release()
    callouts", we needn't care it too much because it is really rare (e.g,
    can not happen on kvm since mmu-notify is unregistered after
    exit_mmap()) and the later call of multiple ->release should be fast
    since all the pages have already been released by the first call.
    Anyway, this issue should be fixed in a separate patch.
    
    -stable suggestions: Any version that has commit 751efd8610d3 need to be
    backported.  I find the oldest version has this commit is 3.0-stable.
    
    [akpm@linux-foundation.org: tweak comments]
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Tested-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7cdf9a24694742936fcf78dc6ed8dc31c636141d
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Fri May 24 15:55:11 2013 -0700

    mm: mmu_notifier: re-fix freed page still mapped in secondary MMU
    
    commit d34883d4e35c0a994e91dd847a82b4c9e0c31d83 upstream.
    
    Commit 751efd8610d3 ("mmu_notifier_unregister NULL Pointer deref and
    multiple ->release()") breaks the fix 3ad3d901bbcf ("mm: mmu_notifier:
    fix freed page still mapped in secondary MMU").
    
    Since hlist_for_each_entry_rcu() is changed now, we can not revert that
    patch directly, so this patch reverts the commit and simply fix the bug
    spotted by that patch
    
    This bug spotted by commit 751efd8610d3 is:
    
        There is a race condition between mmu_notifier_unregister() and
        __mmu_notifier_release().
    
        Assume two tasks, one calling mmu_notifier_unregister() as a result
        of a filp_close() ->flush() callout (task A), and the other calling
        mmu_notifier_release() from an mmput() (task B).
    
                            A                               B
        t1                                            srcu_read_lock()
        t2            if (!hlist_unhashed())
        t3                                            srcu_read_unlock()
        t4            srcu_read_lock()
        t5                                            hlist_del_init_rcu()
        t6                                            synchronize_srcu()
        t7            srcu_read_unlock()
        t8            hlist_del_rcu()  <--- NULL pointer deref.
    
    This can be fixed by using hlist_del_init_rcu instead of hlist_del_rcu.
    
    The another issue spotted in the commit is "multiple ->release()
    callouts", we needn't care it too much because it is really rare (e.g,
    can not happen on kvm since mmu-notify is unregistered after
    exit_mmap()) and the later call of multiple ->release should be fast
    since all the pages have already been released by the first call.
    Anyway, this issue should be fixed in a separate patch.
    
    -stable suggestions: Any version that has commit 751efd8610d3 need to be
    backported.  I find the oldest version has this commit is 3.0-stable.
    
    [akpm@linux-foundation.org: tweak comments]
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Tested-by: Robin Holt <holt@sgi.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    [bwh: Backported to 3.2: hlist_for_each_entry_rcu() still requires the
     struct hlist_node pointer]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit d34883d4e35c0a994e91dd847a82b4c9e0c31d83
Author: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
Date:   Fri May 24 15:55:11 2013 -0700

    mm: mmu_notifier: re-fix freed page still mapped in secondary MMU
    
    Commit 751efd8610d3 ("mmu_notifier_unregister NULL Pointer deref and
    multiple ->release()") breaks the fix 3ad3d901bbcf ("mm: mmu_notifier:
    fix freed page still mapped in secondary MMU").
    
    Since hlist_for_each_entry_rcu() is changed now, we can not revert that
    patch directly, so this patch reverts the commit and simply fix the bug
    spotted by that patch
    
    This bug spotted by commit 751efd8610d3 is:
    
        There is a race condition between mmu_notifier_unregister() and
        __mmu_notifier_release().
    
        Assume two tasks, one calling mmu_notifier_unregister() as a result
        of a filp_close() ->flush() callout (task A), and the other calling
        mmu_notifier_release() from an mmput() (task B).
    
                            A                               B
        t1                                            srcu_read_lock()
        t2            if (!hlist_unhashed())
        t3                                            srcu_read_unlock()
        t4            srcu_read_lock()
        t5                                            hlist_del_init_rcu()
        t6                                            synchronize_srcu()
        t7            srcu_read_unlock()
        t8            hlist_del_rcu()  <--- NULL pointer deref.
    
    This can be fixed by using hlist_del_init_rcu instead of hlist_del_rcu.
    
    The another issue spotted in the commit is "multiple ->release()
    callouts", we needn't care it too much because it is really rare (e.g,
    can not happen on kvm since mmu-notify is unregistered after
    exit_mmap()) and the later call of multiple ->release should be fast
    since all the pages have already been released by the first call.
    Anyway, this issue should be fixed in a separate patch.
    
    -stable suggestions: Any version that has commit 751efd8610d3 need to be
    backported.  I find the oldest version has this commit is 3.0-stable.
    
    [akpm@linux-foundation.org: tweak comments]
    Signed-off-by: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Tested-by: Robin Holt <holt@sgi.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit a38e5e230e3f4e7bc9195d3e7a81567c888257ca
Author: Simon Horman <horms@verge.net.au>
Date:   Wed May 22 14:50:32 2013 +0900

    ipvs: use cond_resched_rcu() helper when walking connections
    
    This avoids the situation where walking of a large number of connections
    may prevent scheduling for a long time while also avoiding excessive
    calls to rcu_read_unlock() and rcu_read_lock().
    
    Note that in the case of !CONFIG_PREEMPT_RCU this will
    add a call to cond_resched().
    
    Signed-off-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit f6f3c437d09e2f62533034e67bfb4385191e992c
Author: Simon Horman <horms@verge.net.au>
Date:   Wed May 22 14:50:31 2013 +0900

    sched: add cond_resched_rcu() helper
    
    This is intended for use in loops which read data protected by RCU and may
    have a large number of iterations.  Such an example is dumping the list of
    connections known to IPVS: ip_vs_conn_array() and ip_vs_conn_seq_next().
    
    The benefits are for CONFIG_PREEMPT_RCU=y where we save CPU cycles
    by moving rcu_read_lock and rcu_read_unlock out of large loops
    but still allowing the current task to be preempted after every
    loop iteration for the CONFIG_PREEMPT_RCU=n case.
    
    The call to cond_resched() is not needed when CONFIG_PREEMPT_RCU=y.
    Thanks to Paul E. McKenney for explaining this and for the
    final version that checks the context with CONFIG_DEBUG_ATOMIC_SLEEP=y
    for all possible configurations.
    
    The function can be empty in the CONFIG_PREEMPT_RCU case,
    rcu_read_lock and rcu_read_unlock are not needed in this case
    because the task can be preempted on indication from scheduler.
    Thanks to Peter Zijlstra for catching this and for his help
    in trying a solution that changes __might_sleep.
    
    Initial cond_resched_rcu_lock() function suggested by Eric Dumazet.
    
    Tested-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Julian Anastasov <ja@ssi.bg>
    Signed-off-by: Simon Horman <horms@verge.net.au>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 802d0db827eaa5a34dd655623c71134ec63d8c3f
Merge: 1aaf6d3d3d1e 941b0304a74b
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun May 5 10:13:44 2013 -0700

    Merge branch 'ipc-cleanups'
    
    Merge ipc fixes and cleanups from my IPC branch.
    
    The ipc locking has always been pretty ugly, and the scalability fixes
    to some degree made it even less readable.  We had two cases of double
    unlocks in error paths due to this (one rcu read unlock, one semaphore
    unlock), and this fixes the bugs I found while trying to clean things up
    a bit so that we are less likely to have more.
    
    * ipc-cleanups:
      ipc: simplify rcu_read_lock() in semctl_nolock()
      ipc: simplify semtimedop/semctl_main() common error path handling
      ipc: move sem_obtain_lock() rcu locking into the only caller
      ipc: fix double sem unlock in semctl error path
      ipc: move the rcu_read_lock() from sem_lock_and_putref() into callers
      ipc: sem_putref() does not need the semaphore lock any more
      ipc: move rcu_read_unlock() out of sem_unlock() and into callers

commit c728b9c87b59fb943c4cba0552d38152787a4ab6
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat May 4 11:04:29 2013 -0700

    ipc: simplify semtimedop/semctl_main() common error path handling
    
    With various straight RCU lock/unlock movements, one common exit path
    pattern had become
    
            rcu_read_unlock();
            goto out_wakeup;
    
    and in fact there were no cases where we wanted to exit to out_wakeup
    _without_ releasing the RCU read lock.
    
    So replace that pattern with "goto out_rcu_wakeup", and remove the old
    out_wakeup.
    
    Acked-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 4091fd942e96af5a0b1dfa6aac5f44153ebf7cdb
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sat May 4 10:13:40 2013 -0700

    ipc: move the rcu_read_lock() from sem_lock_and_putref() into callers
    
    This is another ipc semaphore locking cleanup, trying to make the
    locking more straightforward.  We move the rcu read locking into the
    callers of sem_lock_and_putref(), which in general means that we now
    mostly do the rcu_read_lock() and rcu_read_unlock() in the same
    function.
    
    Mostly.  We still have the ipc_addid/newary/freeary mess, and things
    like ipcctl_pre_down_nolock().
    
    Acked-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 6d49dab8ae06c6d35a4d0967364a9ecbe8fdea2c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri May 3 15:04:40 2013 -0700

    ipc: move rcu_read_unlock() out of sem_unlock() and into callers
    
    The IPC locking is a mess, and sem_unlock() unlocks not only the
    semaphore spinlock, it also drops the rcu read lock.  Unlike sem_lock(),
    which just gets the spin-lock, and expects the caller to get the rcu
    read lock.
    
    This all makes things very hard to follow, and it's very confusing when
    you take the rcu read lock in one function, and then release it in
    another.  And it has caused actual bugs: the sem_obtain_lock() function
    ended up dropping the RCU read lock twice in one error path, because it
    first did the sem_unlock(), and then did a rcu_read_unlock() to match
    the rcu_read_lock() it had done.
    
    This is just a totally mindless "remove rcu_read_unlock() from
    sem_unlock() and add it immediately after each caller" (except for the
    aforementioned bug where we did too many rcu_read_unlock(), and in
    find_alloc_undo() where we just got the rcu_read_lock() to correct for
    the fact that sem_unlock would immediately drop it again).
    
    We can (and should) clean things up further, but this fixes the bug with
    the minimal amount of subtlety.
    
    Reviewed-by: Davidlohr Bueso <davidlohr.bueso@hp.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 5f57816197186378449b848e99ca9cf41a0055f1
Author: Michal Hocko <mhocko@suse.cz>
Date:   Mon Apr 29 15:07:17 2013 -0700

    memcg: relax memcg iter caching
    
    Now that the per-node-zone-priority iterator caches memory cgroups
    rather than their css ids we have to be careful and remove them from the
    iterator when they are on the way out otherwise they might live for
    unbounded amount of time even though their group is already gone (until
    the global/targeted reclaim triggers the zone under priority to find out
    the group is dead and let it to find the final rest).
    
    We can fix this issue by relaxing rules for the last_visited memcg.
    Instead of taking a reference to the css before it is stored into
    iter->last_visited we can just store its pointer and track the number of
    removed groups from each memcg's subhierarchy.
    
    This number would be stored into iterator everytime when a memcg is
    cached.  If the iter count doesn't match the curent walker root's one we
    will start from the root again.  The group counter is incremented
    upwards the hierarchy every time a group is removed.
    
    The iter_lock can be dropped because racing iterators cannot leak the
    reference anymore as the reference count is not elevated for
    last_visited when it is cached.
    
    Locking rules got a bit complicated by this change though.  The iterator
    primarily relies on rcu read lock which makes sure that once we see a
    valid last_visited pointer then it will be valid for the whole RCU walk.
    smp_rmb makes sure that dead_count is read before last_visited and
    last_dead_count while smp_wmb makes sure that last_visited is updated
    before last_dead_count so the up-to-date last_dead_count cannot point to
    an outdated last_visited.  css_tryget then makes sure that the
    last_visited is still alive in case the iteration races with the cached
    group removal (css is invalidated before mem_cgroup_css_offline
    increments dead_count).
    
    In short:
    mem_cgroup_iter
     rcu_read_lock()
     dead_count = atomic_read(parent->dead_count)
     smp_rmb()
     if (dead_count != iter->last_dead_count)
            last_visited POSSIBLY INVALID -> last_visited = NULL
     if (!css_tryget(iter->last_visited))
            last_visited DEAD -> last_visited = NULL
     next = find_next(last_visited)
     css_tryget(next)
     css_put(last_visited)  // css would be invalidated and parent->dead_count
                            // incremented if this was the last reference
     iter->last_visited = next
     smp_wmb()
     iter->last_dead_count = dead_count
     rcu_read_unlock()
    
    cgroup_rmdir
     cgroup_destroy_locked
      atomic_add(CSS_DEACT_BIAS, &css->refcnt) // subsequent css_tryget fail
       mem_cgroup_css_offline
        mem_cgroup_invalidate_reclaim_iterators
         while(parent = parent_mem_cgroup)
            atomic_inc(parent->dead_count)
      css_put(css) // last reference held by cgroup core
    
    Spotted by Ying Han.
    
    Original idea from Johannes Weiner.
    
    [akpm@linux-foundation.org: coding-style fixes]
    Signed-off-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
    Acked-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Ying Han <yinghan@google.com>
    Cc: Li Zefan <lizefan@huawei.com>
    Cc: Tejun Heo <htejun@gmail.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 1c3d85dd4e21a405e8de54131a5f759f9a0115b7
Author: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
Date:   Mon Apr 29 00:08:16 2013 +0200

    cpufreq: Revert incorrect commit 5800043
    
    Commit 5800043 (cpufreq: convert cpufreq_driver to using RCU) causes
    the following call trace to be spit on boot:
    
     BUG: sleeping function called from invalid context at /scratch/rafael/work/linux-pm/mm/slab.c:3179
     in_atomic(): 0, irqs_disabled(): 0, pid: 292, name: systemd-udevd
     2 locks held by systemd-udevd/292:
      #0:  (subsys mutex){+.+.+.}, at: [<ffffffff8146851a>] subsys_interface_register+0x4a/0xe0
      #1:  (rcu_read_lock){.+.+.+}, at: [<ffffffff81538210>] cpufreq_add_dev_interface+0x60/0x5e0
     Pid: 292, comm: systemd-udevd Not tainted 3.9.0-rc8+ #323
     Call Trace:
      [<ffffffff81072c90>] __might_sleep+0x140/0x1f0
      [<ffffffff811581c2>] kmem_cache_alloc+0x42/0x2b0
      [<ffffffff811e7179>] sysfs_new_dirent+0x59/0x130
      [<ffffffff811e63cb>] sysfs_add_file_mode+0x6b/0x110
      [<ffffffff81538210>] ? cpufreq_add_dev_interface+0x60/0x5e0
      [<ffffffff810a3254>] ? __lock_is_held+0x54/0x80
      [<ffffffff811e647d>] sysfs_add_file+0xd/0x10
      [<ffffffff811e6541>] sysfs_create_file+0x21/0x30
      [<ffffffff81538280>] cpufreq_add_dev_interface+0xd0/0x5e0
      [<ffffffff81538210>] ? cpufreq_add_dev_interface+0x60/0x5e0
      [<ffffffffa000337f>] ? acpi_processor_get_platform_limit+0x32/0xbb [processor]
      [<ffffffffa022f540>] ? do_drv_write+0x70/0x70 [acpi_cpufreq]
      [<ffffffff810a3254>] ? __lock_is_held+0x54/0x80
      [<ffffffff8106c97e>] ? up_read+0x1e/0x40
      [<ffffffff8106e632>] ? __blocking_notifier_call_chain+0x72/0xc0
      [<ffffffff81538dbd>] cpufreq_add_dev+0x62d/0xae0
      [<ffffffff815389b8>] ? cpufreq_add_dev+0x228/0xae0
      [<ffffffff81468569>] subsys_interface_register+0x99/0xe0
      [<ffffffffa014d000>] ? 0xffffffffa014cfff
      [<ffffffff81535d5d>] cpufreq_register_driver+0x9d/0x200
      [<ffffffffa014d000>] ? 0xffffffffa014cfff
      [<ffffffffa014d0e9>] acpi_cpufreq_init+0xe9/0x1000 [acpi_cpufreq]
      [<ffffffff810002fa>] do_one_initcall+0x11a/0x170
      [<ffffffff810b4b87>] load_module+0x1cf7/0x2920
      [<ffffffff81322580>] ? ddebug_proc_open+0xb0/0xb0
      [<ffffffff816baee0>] ? retint_restore_args+0xe/0xe
      [<ffffffff810b5887>] sys_init_module+0xd7/0x120
      [<ffffffff816bb6d2>] system_call_fastpath+0x16/0x1b
    
    which is quite obvious, because that commit put (multiple instances
    of) sysfs_create_file() under rcu_read_lock()/rcu_read_unlock(),
    although sysfs_create_file() may cause memory to be allocated with
    GFP_KERNEL and that may sleep, which is not permitted in RCU read
    critical section.
    
    Revert the buggy commit altogether along with some changes on top
    of it.
    
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit 09454abba5062d829949a552502220d3666119e1
Author: Robin Holt <holt@sgi.com>
Date:   Fri Feb 22 16:35:34 2013 -0800

    mmu_notifier_unregister NULL Pointer deref and multiple ->release() callouts
    
    commit 751efd8610d3d7d67b7bdf7f62646edea7365dd7 upstream.
    
    There is a race condition between mmu_notifier_unregister() and
    __mmu_notifier_release().
    
    Assume two tasks, one calling mmu_notifier_unregister() as a result of a
    filp_close() ->flush() callout (task A), and the other calling
    mmu_notifier_release() from an mmput() (task B).
    
                    A                               B
    t1                                              srcu_read_lock()
    t2              if (!hlist_unhashed())
    t3                                              srcu_read_unlock()
    t4              srcu_read_lock()
    t5                                              hlist_del_init_rcu()
    t6                                              synchronize_srcu()
    t7              srcu_read_unlock()
    t8              hlist_del_rcu()  <--- NULL pointer deref.
    
    Additionally, the list traversal in __mmu_notifier_release() is not
    protected by the by the mmu_notifier_mm->hlist_lock which can result in
    callouts to the ->release() notifier from both mmu_notifier_unregister()
    and __mmu_notifier_release().
    
    -stable suggestions:
    
    The stable trees prior to 3.7.y need commits 21a92735f660 and
    70400303ce0c cherry-picked in that order prior to cherry-picking this
    commit.  The 3.7.y tree already has those two commits.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.co.il>
    Cc: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 7fecb64cca9a98f60ff4bc794bb353512bd5c665
Author: Robin Holt <holt@sgi.com>
Date:   Fri Feb 22 16:35:34 2013 -0800

    mmu_notifier_unregister NULL Pointer deref and multiple ->release() callouts
    
    commit 751efd8610d3d7d67b7bdf7f62646edea7365dd7 upstream.
    
    There is a race condition between mmu_notifier_unregister() and
    __mmu_notifier_release().
    
    Assume two tasks, one calling mmu_notifier_unregister() as a result of a
    filp_close() ->flush() callout (task A), and the other calling
    mmu_notifier_release() from an mmput() (task B).
    
                    A                               B
    t1                                              srcu_read_lock()
    t2              if (!hlist_unhashed())
    t3                                              srcu_read_unlock()
    t4              srcu_read_lock()
    t5                                              hlist_del_init_rcu()
    t6                                              synchronize_srcu()
    t7              srcu_read_unlock()
    t8              hlist_del_rcu()  <--- NULL pointer deref.
    
    Additionally, the list traversal in __mmu_notifier_release() is not
    protected by the by the mmu_notifier_mm->hlist_lock which can result in
    callouts to the ->release() notifier from both mmu_notifier_unregister()
    and __mmu_notifier_release().
    
    -stable suggestions:
    
    The stable trees prior to 3.7.y need commits 21a92735f660 and
    70400303ce0c cherry-picked in that order prior to cherry-picking this
    commit.  The 3.7.y tree already has those two commits.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.co.il>
    Cc: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8e78002093815336a22ba3e723c1d9d15000d9b5
Author: Robin Holt <holt@sgi.com>
Date:   Fri Feb 22 16:35:34 2013 -0800

    mmu_notifier_unregister NULL Pointer deref and multiple ->release() callouts
    
    commit 751efd8610d3d7d67b7bdf7f62646edea7365dd7 upstream.
    
    There is a race condition between mmu_notifier_unregister() and
    __mmu_notifier_release().
    
    Assume two tasks, one calling mmu_notifier_unregister() as a result of a
    filp_close() ->flush() callout (task A), and the other calling
    mmu_notifier_release() from an mmput() (task B).
    
                    A                               B
    t1                                              srcu_read_lock()
    t2              if (!hlist_unhashed())
    t3                                              srcu_read_unlock()
    t4              srcu_read_lock()
    t5                                              hlist_del_init_rcu()
    t6                                              synchronize_srcu()
    t7              srcu_read_unlock()
    t8              hlist_del_rcu()  <--- NULL pointer deref.
    
    Additionally, the list traversal in __mmu_notifier_release() is not
    protected by the by the mmu_notifier_mm->hlist_lock which can result in
    callouts to the ->release() notifier from both mmu_notifier_unregister()
    and __mmu_notifier_release().
    
    -stable suggestions:
    
    The stable trees prior to 3.7.y need commits 21a92735f660 and
    70400303ce0c cherry-picked in that order prior to cherry-picking this
    commit.  The 3.7.y tree already has those two commits.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.co.il>
    Cc: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6f54cabb268370ccfb66e35a7ba9f0539987a13
Author: Robin Holt <holt@sgi.com>
Date:   Fri Feb 22 16:35:34 2013 -0800

    mmu_notifier_unregister NULL Pointer deref and multiple ->release() callouts
    
    commit 751efd8610d3d7d67b7bdf7f62646edea7365dd7 upstream.
    
    There is a race condition between mmu_notifier_unregister() and
    __mmu_notifier_release().
    
    Assume two tasks, one calling mmu_notifier_unregister() as a result of a
    filp_close() ->flush() callout (task A), and the other calling
    mmu_notifier_release() from an mmput() (task B).
    
                    A                               B
    t1                                              srcu_read_lock()
    t2              if (!hlist_unhashed())
    t3                                              srcu_read_unlock()
    t4              srcu_read_lock()
    t5                                              hlist_del_init_rcu()
    t6                                              synchronize_srcu()
    t7              srcu_read_unlock()
    t8              hlist_del_rcu()  <--- NULL pointer deref.
    
    Additionally, the list traversal in __mmu_notifier_release() is not
    protected by the by the mmu_notifier_mm->hlist_lock which can result in
    callouts to the ->release() notifier from both mmu_notifier_unregister()
    and __mmu_notifier_release().
    
    -stable suggestions:
    
    The stable trees prior to 3.7.y need commits 21a92735f660 and
    70400303ce0c cherry-picked in that order prior to cherry-picking this
    commit.  The 3.7.y tree already has those two commits.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.co.il>
    Cc: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cf63242fbe56cd6ea1cfb7d3536013eb549ed331
Author: Robin Holt <holt@sgi.com>
Date:   Fri Feb 22 16:35:34 2013 -0800

    mmu_notifier_unregister NULL Pointer deref and multiple ->release() callouts
    
    commit 751efd8610d3d7d67b7bdf7f62646edea7365dd7 upstream.
    
    There is a race condition between mmu_notifier_unregister() and
    __mmu_notifier_release().
    
    Assume two tasks, one calling mmu_notifier_unregister() as a result of a
    filp_close() ->flush() callout (task A), and the other calling
    mmu_notifier_release() from an mmput() (task B).
    
                    A                               B
    t1                                              srcu_read_lock()
    t2              if (!hlist_unhashed())
    t3                                              srcu_read_unlock()
    t4              srcu_read_lock()
    t5                                              hlist_del_init_rcu()
    t6                                              synchronize_srcu()
    t7              srcu_read_unlock()
    t8              hlist_del_rcu()  <--- NULL pointer deref.
    
    Additionally, the list traversal in __mmu_notifier_release() is not
    protected by the by the mmu_notifier_mm->hlist_lock which can result in
    callouts to the ->release() notifier from both mmu_notifier_unregister()
    and __mmu_notifier_release().
    
    -stable suggestions:
    
    The stable trees prior to 3.7.y need commits 21a92735f660 and
    70400303ce0c cherry-picked in that order prior to cherry-picking this
    commit.  The 3.7.y tree already has those two commits.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.co.il>
    Cc: Haggai Eran <haggaie@mellanox.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 751efd8610d3d7d67b7bdf7f62646edea7365dd7
Author: Robin Holt <holt@sgi.com>
Date:   Fri Feb 22 16:35:34 2013 -0800

    mmu_notifier_unregister NULL Pointer deref and multiple ->release() callouts
    
    There is a race condition between mmu_notifier_unregister() and
    __mmu_notifier_release().
    
    Assume two tasks, one calling mmu_notifier_unregister() as a result of a
    filp_close() ->flush() callout (task A), and the other calling
    mmu_notifier_release() from an mmput() (task B).
    
                    A                               B
    t1                                              srcu_read_lock()
    t2              if (!hlist_unhashed())
    t3                                              srcu_read_unlock()
    t4              srcu_read_lock()
    t5                                              hlist_del_init_rcu()
    t6                                              synchronize_srcu()
    t7              srcu_read_unlock()
    t8              hlist_del_rcu()  <--- NULL pointer deref.
    
    Additionally, the list traversal in __mmu_notifier_release() is not
    protected by the by the mmu_notifier_mm->hlist_lock which can result in
    callouts to the ->release() notifier from both mmu_notifier_unregister()
    and __mmu_notifier_release().
    
    -stable suggestions:
    
    The stable trees prior to 3.7.y need commits 21a92735f660 and
    70400303ce0c cherry-picked in that order prior to cherry-picking this
    commit.  The 3.7.y tree already has those two commits.
    
    Signed-off-by: Robin Holt <holt@sgi.com>
    Cc: Andrea Arcangeli <aarcange@redhat.com>
    Cc: Wanpeng Li <liwanp@linux.vnet.ibm.com>
    Cc: Xiao Guangrong <xiaoguangrong@linux.vnet.ibm.com>
    Cc: Avi Kivity <avi@redhat.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Sagi Grimberg <sagig@mellanox.co.il>
    Cc: Haggai Eran <haggaie@mellanox.com>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit a3cc86c2f00839453d2dbeb46bfc44e885b073db
Author: Glauber Costa <glommer@parallels.com>
Date:   Thu Feb 21 15:16:41 2013 -0800

    cfq: fix lock imbalance with failed allocations
    
    While stress-running very-small container scenarios with the Kernel Memory
    Controller, I've run into a lockdep-detected lock imbalance in
    cfq-iosched.c.
    
    I'll apologize beforehand for not posting a backlog: I didn't anticipate
    it would be so hard to reproduce, so I didn't save my serial output and
    went directly on debugging.  Turns out that it did not happen again in
    more than 20 runs, making it a quite rare pattern.
    
    But here is my analysis:
    
    When we are in very low-memory situations, we will arrive at
    cfq_find_alloc_queue and may not find a queue, having to resort to the oom
    queue, in an rcu-locked condition:
    
      if (!cfqq || cfqq == &cfqd->oom_cfqq)
          [ ... ]
    
    Next, we will release the rcu lock, and try to allocate a queue, retrying
    if we succeed:
    
      rcu_read_unlock();
      spin_unlock_irq(cfqd->queue->queue_lock);
      new_cfqq = kmem_cache_alloc_node(cfq_pool,
                      gfp_mask | __GFP_ZERO,
                      cfqd->queue->node);
       spin_lock_irq(cfqd->queue->queue_lock);
       if (new_cfqq)
           goto retry;
    
    We are unlocked at this point, but it should be fine, since we will
    reacquire the rcu_read_lock when we retry.
    
    Except of course, that we may not retry: the allocation may very well fail
    and we'll keep on going through the flow:
    
    The next branch is:
    
        if (cfqq) {
            [ ... ]
        } else
            cfqq = &cfqd->oom_cfqq;
    
    And right before exiting, we'll issue rcu_read_unlock().
    
    Being already unlocked, this is the likely source of our imbalance.  Since
    cfqq is either already NULL or made NULL in the first statement of the
    outter branch, the only viable alternative here seems to be to return the
    oom queue right away in case of allocation failure.
    
    Please review the following patch and apply if you agree with my analysis.
    
    Signed-off-by: Glauber Costa <glommer@parallels.com>
    Cc: Jens Axboe <axboe@kernel.dk>
    Cc: Tejun Heo <tj@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit e84cf5d0fd53badf3a93c790e280cc92a69ed999
Merge: 19f949f52599 ac0e32024b8f
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Feb 19 17:45:20 2013 -0800

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Pull RCU changes from Ingo Molnar:
     "SRCU changes:
    
       - These include debugging aids, updates that move towards the goal of
         permitting srcu_read_lock() and srcu_read_unlock() to be used from
         idle and offline CPUs, and a few small fixes.
    
      Changes to rcutorture and to RCU documentation:
    
       - Posted to LKML at https://lkml.org/lkml/2013/1/26/188
    
      Enhancements to uniprocessor handling in tiny RCU:
    
       - Posted to LKML at https://lkml.org/lkml/2013/1/27/2
    
      Tag RCU callbacks with grace-period number to simplify callback
      advancement:
    
       - Posted to LKML at https://lkml.org/lkml/2013/1/26/203
    
      Miscellaneous fixes:
    
       - Posted to LKML at https://lkml.org/lkml/2013/1/26/204"
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (27 commits)
      srcu: use ACCESS_ONCE() to access sp->completed in srcu_read_lock()
      srcu: Update synchronize_srcu_expedited()'s comments
      srcu: Update synchronize_srcu()'s comments
      srcu: Remove checks preventing idle CPUs from calling srcu_read_lock()
      srcu: Remove checks preventing offline CPUs from calling srcu_read_lock()
      srcu: Simple cleanup for cleanup_srcu_struct()
      srcu: Add might_sleep() annotation to synchronize_srcu()
      srcu: Simplify __srcu_read_unlock() via this_cpu_dec()
      rcu: Allow rcutorture to be built at low optimization levels
      rcu: Make rcutorture's shuffler task shuffle recently added tasks
      rcu: Allow TREE_PREEMPT_RCU on UP systems
      rcu: Provide RCU CPU stall warnings for tiny RCU
      context_tracking: Add comments on interface and internals
      rcu: Remove obsolete Kconfig option from comment
      rcu: Remove unused code originally used for context tracking
      rcu: Consolidate debugging Kconfig options
      rcu: Correct 'optimized' to 'optimize' in header comment
      rcu: Trace callback acceleration
      rcu: Tag callback lists with corresponding grace-period number
      rcutorture: Don't compare ptr with 0
      ...

commit ac0e32024b8f40987b3db7d2defdc6b5153ba354
Merge: 0351096eb058 7a6b55e7108b
Author: Ingo Molnar <mingo@kernel.org>
Date:   Wed Feb 13 09:45:59 2013 +0100

    Merge branch 'rcu/srcu' of git://git.kernel.org/pub/scm/linux/kernel/git/paulmck/linux-rcu into core/rcu
    
    Pull SRCU changes from Paul E. McKenney.
    
      " These include debugging aids, updates that move towards the goal
        of permitting srcu_read_lock() and srcu_read_unlock() to be used
        from idle and offline CPUs, and a few small fixes. "
    
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 5a41344a3d83ef2c08e40bfce1efa5795def9b82
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Thu Nov 29 16:46:02 2012 +0800

    srcu: Simplify __srcu_read_unlock() via this_cpu_dec()
    
    This commit replaces disabling of preemption and decrement of a per-CPU
    variable with this_cpu_dec(), which avoids preemption disabling on x86
    and shortens the code on all platforms.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 8fa938acb318378463987b04be083dc2467e0480
Author: Nishanth Menon <nm@ti.com>
Date:   Fri Jan 18 19:52:35 2013 +0000

    PM / devfreq: exynos4_bus: honor RCU lock usage
    
    OPP pointers cannot be expected to be valid beyond the boundary
    of rcu_read_lock and rcu_read_unlock. Unfortunately, the current
    exynos4 busfreq driver does not honor the usage constraint and stores
    the OPP pointer in struct busfreq_data. This could potentially
    become invalid later such as: across devfreq opp change decisions,
    resulting in unpredictable behavior.
    
    To fix this, we introduce a busfreq specific busfreq_opp_info
    structure which is used to handle OPP information. OPP information
    is de-referenced to voltage and frequency pairs as needed into
    busfreq_opp_info structure and used as needed.
    
    Signed-off-by: Nishanth Menon <nm@ti.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit bcb27549f4185ca7d0168e201931613706ef2b83
Author: Nishanth Menon <nm@ti.com>
Date:   Fri Jan 18 19:52:34 2013 +0000

    PM / devfreq: add locking documentation for recommended_opp
    
    OPP pointers are protected by RCU locks, the pointer validity is
    permissible only under the section of rcu_read_lock to rcu_read_unlock
    
    Add documentation to the effect.
    
    Signed-off-by: Nishanth Menon <nm@ti.com>
    Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>

commit b5f0e251211531180989a32ba598968104562c84
Author: Jan Kara <jack@suse.cz>
Date:   Fri Dec 21 00:15:51 2012 -0500

    jbd2: fix assertion failure in jbd2_journal_flush()
    
    commit d7961c7fa4d2e3c3f12be67e21ba8799b5a7238a upstream.
    
    The following race is possible between start_this_handle() and someone
    calling jbd2_journal_flush().
    
    Process A                              Process B
    start_this_handle().
      if (journal->j_barrier_count) # false
      if (!journal->j_running_transaction) { #true
        read_unlock(&journal->j_state_lock);
                                           jbd2_journal_lock_updates()
                                           jbd2_journal_flush()
                                             write_lock(&journal->j_state_lock);
                                             if (journal->j_running_transaction) {
                                               # false
                                             ... wait for committing trans ...
                                             write_unlock(&journal->j_state_lock);
        ...
        write_lock(&journal->j_state_lock);
        if (!journal->j_running_transaction) { # true
          jbd2_get_transaction(journal, new_transaction);
        write_unlock(&journal->j_state_lock);
        goto repeat; # eventually blocks on j_barrier_count > 0
                                             ...
                                             J_ASSERT(!journal->j_running_transaction);
                                               # fails
    
    We fix the race by rechecking j_barrier_count after reacquiring j_state_lock
    in exclusive mode.
    
    Reported-by: yjwsignal@empal.com
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3a06c3ff07f7a00a48edbe264987cc33f409a6d5
Author: Jan Kara <jack@suse.cz>
Date:   Fri Dec 21 00:15:51 2012 -0500

    jbd2: fix assertion failure in jbd2_journal_flush()
    
    commit d7961c7fa4d2e3c3f12be67e21ba8799b5a7238a upstream.
    
    The following race is possible between start_this_handle() and someone
    calling jbd2_journal_flush().
    
    Process A                              Process B
    start_this_handle().
      if (journal->j_barrier_count) # false
      if (!journal->j_running_transaction) { #true
        read_unlock(&journal->j_state_lock);
                                           jbd2_journal_lock_updates()
                                           jbd2_journal_flush()
                                             write_lock(&journal->j_state_lock);
                                             if (journal->j_running_transaction) {
                                               # false
                                             ... wait for committing trans ...
                                             write_unlock(&journal->j_state_lock);
        ...
        write_lock(&journal->j_state_lock);
        if (!journal->j_running_transaction) { # true
          jbd2_get_transaction(journal, new_transaction);
        write_unlock(&journal->j_state_lock);
        goto repeat; # eventually blocks on j_barrier_count > 0
                                             ...
                                             J_ASSERT(!journal->j_running_transaction);
                                               # fails
    
    We fix the race by rechecking j_barrier_count after reacquiring j_state_lock
    in exclusive mode.
    
    Reported-by: yjwsignal@empal.com
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7c558b7eb837ca7bc014af2f5509be143c3c3670
Author: Jan Kara <jack@suse.cz>
Date:   Fri Dec 21 00:15:51 2012 -0500

    jbd2: fix assertion failure in jbd2_journal_flush()
    
    commit d7961c7fa4d2e3c3f12be67e21ba8799b5a7238a upstream.
    
    The following race is possible between start_this_handle() and someone
    calling jbd2_journal_flush().
    
    Process A                              Process B
    start_this_handle().
      if (journal->j_barrier_count) # false
      if (!journal->j_running_transaction) { #true
        read_unlock(&journal->j_state_lock);
                                           jbd2_journal_lock_updates()
                                           jbd2_journal_flush()
                                             write_lock(&journal->j_state_lock);
                                             if (journal->j_running_transaction) {
                                               # false
                                             ... wait for committing trans ...
                                             write_unlock(&journal->j_state_lock);
        ...
        write_lock(&journal->j_state_lock);
        if (!journal->j_running_transaction) { # true
          jbd2_get_transaction(journal, new_transaction);
        write_unlock(&journal->j_state_lock);
        goto repeat; # eventually blocks on j_barrier_count > 0
                                             ...
                                             J_ASSERT(!journal->j_running_transaction);
                                               # fails
    
    We fix the race by rechecking j_barrier_count after reacquiring j_state_lock
    in exclusive mode.
    
    Reported-by: yjwsignal@empal.com
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7a55283222cdd70c1cd7a33df0db1e0c96462ac9
Author: Jan Kara <jack@suse.cz>
Date:   Fri Dec 21 00:15:51 2012 -0500

    jbd2: fix assertion failure in jbd2_journal_flush()
    
    commit d7961c7fa4d2e3c3f12be67e21ba8799b5a7238a upstream.
    
    The following race is possible between start_this_handle() and someone
    calling jbd2_journal_flush().
    
    Process A                              Process B
    start_this_handle().
      if (journal->j_barrier_count) # false
      if (!journal->j_running_transaction) { #true
        read_unlock(&journal->j_state_lock);
                                           jbd2_journal_lock_updates()
                                           jbd2_journal_flush()
                                             write_lock(&journal->j_state_lock);
                                             if (journal->j_running_transaction) {
                                               # false
                                             ... wait for committing trans ...
                                             write_unlock(&journal->j_state_lock);
        ...
        write_lock(&journal->j_state_lock);
        if (!journal->j_running_transaction) { # true
          jbd2_get_transaction(journal, new_transaction);
        write_unlock(&journal->j_state_lock);
        goto repeat; # eventually blocks on j_barrier_count > 0
                                             ...
                                             J_ASSERT(!journal->j_running_transaction);
                                               # fails
    
    We fix the race by rechecking j_barrier_count after reacquiring j_state_lock
    in exclusive mode.
    
    Reported-by: yjwsignal@empal.com
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit d7961c7fa4d2e3c3f12be67e21ba8799b5a7238a
Author: Jan Kara <jack@suse.cz>
Date:   Fri Dec 21 00:15:51 2012 -0500

    jbd2: fix assertion failure in jbd2_journal_flush()
    
    The following race is possible between start_this_handle() and someone
    calling jbd2_journal_flush().
    
    Process A                              Process B
    start_this_handle().
      if (journal->j_barrier_count) # false
      if (!journal->j_running_transaction) { #true
        read_unlock(&journal->j_state_lock);
                                           jbd2_journal_lock_updates()
                                           jbd2_journal_flush()
                                             write_lock(&journal->j_state_lock);
                                             if (journal->j_running_transaction) {
                                               # false
                                             ... wait for committing trans ...
                                             write_unlock(&journal->j_state_lock);
        ...
        write_lock(&journal->j_state_lock);
        if (!journal->j_running_transaction) { # true
          jbd2_get_transaction(journal, new_transaction);
        write_unlock(&journal->j_state_lock);
        goto repeat; # eventually blocks on j_barrier_count > 0
                                             ...
                                             J_ASSERT(!journal->j_running_transaction);
                                               # fails
    
    We fix the race by rechecking j_barrier_count after reacquiring j_state_lock
    in exclusive mode.
    
    Reported-by: yjwsignal@empal.com
    Signed-off-by: Jan Kara <jack@suse.cz>
    Signed-off-by: "Theodore Ts'o" <tytso@mit.edu>
    Cc: stable@vger.kernel.org

commit 499744209b2cbca66c42119226e5470da3bb7040
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Dec 12 19:22:57 2012 +0000

    tuntap: dont use skb after netif_rx_ni(skb)
    
    On Wed, 2012-12-12 at 23:16 -0500, Dave Jones wrote:
    > Since todays net merge, I see this when I start openvpn..
    >
    > general protection fault: 0000 [#1] PREEMPT SMP
    > Modules linked in: ip6t_REJECT nf_conntrack_ipv6 nf_defrag_ipv6 xt_conntrack nf_conntrack ip6table_filter ip6_tables xfs iTCO_wdt iTCO_vendor_support snd_emu10k1 snd_util_mem snd_ac97_codec coretemp ac97_bus microcode snd_hwdep snd_seq pcspkr snd_pcm snd_page_alloc snd_timer lpc_ich i2c_i801 snd_rawmidi mfd_core snd_seq_device snd e1000e soundcore emu10k1_gp gameport i82975x_edac edac_core vhost_net tun macvtap macvlan kvm_intel kvm binfmt_misc nfsd auth_rpcgss nfs_acl lockd sunrpc btrfs libcrc32c zlib_deflate firewire_ohci sata_sil firewire_core crc_itu_t radeon i2c_algo_bit drm_kms_helper ttm drm i2c_core floppy
    > CPU 0
    > Pid: 1381, comm: openvpn Not tainted 3.7.0+ #14                  /D975XBX
    > RIP: 0010:[<ffffffff815b54a4>]  [<ffffffff815b54a4>] skb_flow_dissect+0x314/0x3e0
    > RSP: 0018:ffff88007d0d9c48  EFLAGS: 00010206
    > RAX: 000000000000055d RBX: 6b6b6b6b6b6b6b4b RCX: 1471030a0180040a
    > RDX: 0000000000000005 RSI: 00000000ffffffe0 RDI: ffff8800ba83fa80
    > RBP: ffff88007d0d9cb8 R08: 0000000000000000 R09: 0000000000000000
    > R10: 0000000000000000 R11: 0000000000000101 R12: ffff8800ba83fa80
    > R13: 0000000000000008 R14: ffff88007d0d9cc8 R15: ffff8800ba83fa80
    > FS:  00007f6637104800(0000) GS:ffff8800bf600000(0000) knlGS:0000000000000000
    > CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    > CR2: 00007f563f5b01c4 CR3: 000000007d140000 CR4: 00000000000007f0
    > DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    > DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    > Process openvpn (pid: 1381, threadinfo ffff88007d0d8000, task ffff8800a540cd60)
    > Stack:
    >  ffff8800ba83fa80 0000000000000296 0000000000000000 0000000000000000
    >  ffff88007d0d9cc8 ffffffff815bcff4 ffff88007d0d9ce8 ffffffff815b1831
    >  ffff88007d0d9ca8 00000000703f6364 ffff8800ba83fa80 0000000000000000
    > Call Trace:
    >  [<ffffffff815bcff4>] ? netif_rx+0x114/0x4c0
    >  [<ffffffff815b1831>] ? skb_copy_datagram_from_iovec+0x61/0x290
    >  [<ffffffff815b672a>] __skb_get_rxhash+0x1a/0xd0
    >  [<ffffffffa03b9538>] tun_get_user+0x418/0x810 [tun]
    >  [<ffffffff8135f468>] ? delay_tsc+0x98/0xf0
    >  [<ffffffff8109605c>] ? __rcu_read_unlock+0x5c/0xa0
    >  [<ffffffffa03b9a41>] tun_chr_aio_write+0x81/0xb0 [tun]
    >  [<ffffffff81145011>] ? __buffer_unlock_commit+0x41/0x50
    >  [<ffffffff811db917>] do_sync_write+0xa7/0xe0
    >  [<ffffffff811dc01f>] vfs_write+0xaf/0x190
    >  [<ffffffff811dc375>] sys_write+0x55/0xa0
    >  [<ffffffff81705540>] tracesys+0xdd/0xe2
    > Code: 41 8b 44 24 68 41 2b 44 24 6c 01 de 29 f0 83 f8 03 0f 8e a0 00 00 00 48 63 de 49 03 9c 24 e0 00 00 00 48 85 db 0f 84 72 fe ff ff <8b> 03 41 89 46 08 b8 01 00 00 00 e9 43 fd ff ff 0f 1f 40 00 48
    > RIP  [<ffffffff815b54a4>] skb_flow_dissect+0x314/0x3e0
    >  RSP <ffff88007d0d9c48>
    > ---[ end trace 6d42c834c72c002e ]---
    >
    >
    > Faulting instruction is
    >
    >    0: 8b 03                   mov    (%rbx),%eax
    >
    > rbx is slab poison (-20) so this looks like a use-after-free here...
    >
    >                         flow->ports = *ports;
    >  314:   8b 03                   mov    (%rbx),%eax
    >  316:   41 89 46 08             mov    %eax,0x8(%r14)
    >
    > in the inlined skb_header_pointer in skb_flow_dissect
    >
    >       Dave
    >
    
    commit 96442e4242 (tuntap: choose the txq based on rxq) added
    a use after free.
    
    Cache rxhash in a temp variable before calling netif_rx_ni()
    
    Reported-by: Dave Jones <davej@redhat.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Jason Wang <jasowang@redhat.com>
    Acked-by: Jason Wang <jasowang@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1bf11c53535ab87e3bf14ecdf6747bf46f601c5d
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Oct 22 19:39:16 2012 -0400

    percpu-rw-semaphores: use rcu_read_lock_sched
    
    Use rcu_read_lock_sched / rcu_read_unlock_sched / synchronize_sched
    instead of rcu_read_lock / rcu_read_unlock / synchronize_rcu.
    
    This is an optimization. The RCU-protected region is very small, so
    there will be no latency problems if we disable preempt in this region.
    
    So we use rcu_read_lock_sched / rcu_read_unlock_sched that translates
    to preempt_disable / preempt_disable. It is smaller (and supposedly
    faster) than preemptible rcu_read_lock / rcu_read_unlock.
    
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit d42e3563c6413824d45c1d5023114da585d6e70d
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Feb 24 20:07:29 2012 +0100

    epoll: ep_unregister_pollwait() can use the freed pwq->whead
    
    commit 971316f0503a5c50633d07b83b6db2f15a3a5b00 upstream.
    
    signalfd_cleanup() ensures that ->signalfd_wqh is not used, but
    this is not enough. eppoll_entry->whead still points to the memory
    we are going to free, ep_unregister_pollwait()->remove_wait_queue()
    is obviously unsafe.
    
    Change ep_poll_callback(POLLFREE) to set eppoll_entry->whead = NULL,
    change ep_unregister_pollwait() to check pwq->whead != NULL under
    rcu_read_lock() before remove_wait_queue(). We add the new helper,
    ep_remove_wait_queue(), for this.
    
    This works because sighand_cachep is SLAB_DESTROY_BY_RCU and because
    ->signalfd_wqh is initialized in sighand_ctor(), not in copy_sighand.
    ep_unregister_pollwait()->remove_wait_queue() can play with already
    freed and potentially reused ->sighand, but this is fine. This memory
    must have the valid ->signalfd_wqh until rcu_read_unlock().
    
    Reported-by: Maxime Bizon <mbizon@freebox.fr>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Willy Tarreau <w@1wt.eu>

commit ae4735166ee31e29fbf8615949dac9e56299b1fd
Merge: 2ddc7fe1cd1b 6ee584be3ee3
Author: David S. Miller <davem@davemloft.net>
Date:   Mon Sep 24 15:36:53 2012 -0400

    Merge branch 'master' of git://1984.lsi.us.es/nf-next
    
    Pablo Neira Ayuso says:
    
    ====================
    This patchset contains updates for your net-next tree, they are:
    
    * Mostly fixes for the recently pushed IPv6 NAT support:
    
    - Fix crash while removing nf_nat modules from Patrick McHardy.
    - Fix unbalanced rcu_read_unlock from Ulrich Weber.
    - Merge NETMAP and REDIRECT into one single xt_target module, from
      Jan Engelhardt.
    - Fix Kconfig for IPv6 NAT, which allows inconsistent configurations,
      from myself.
    
    * Updates for ipset, all of the from Jozsef Kadlecsik:
    
    - Add the new "nomatch" option to obtain reverse set matching.
    - Support for /0 CIDR in hash:net,iface set type.
    - One non-critical fix for a rare crash due to pass really
      wrong configuration parameters.
    - Coding style cleanups.
    - Sparse fixes.
    - Add set revision supported via modinfo.i
    
    * One extension for the xt_time match, to support matching during
      the transition between two days with one single rule, from
      Florian Westphal.
    
    * Fix maximum packet length supported by nfnetlink_queue and add
      NFQA_CAP_LEN attribute, from myself.
    
    You can notice that this batch contains a couple of fixes that may
    go to 3.6-rc but I don't consider them critical to push them:
    
    * The ipset fix for the /0 cidr case, which is triggered with one
      inconsistent command line invocation of ipset.
    
    * The nfnetlink_queue maximum packet length supported since it requires
      the new NFQA_CAP_LEN attribute to provide a full workaround for the
      described problem.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b065a85354239cc96295f696eeace67ad3a55e5c
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Wed Aug 1 15:57:54 2012 -0700

    rcu: Fix obsolete rcu_initiate_boost() header comment
    
    Commit 1217ed1b (rcu: permit rcu_read_unlock() to be called while holding
    runqueue locks) made rcu_initiate_boost() restore irq state when releasing
    the rcu_node structure's ->lock, but failed to update the header comment
    accordingly.  This commit therefore brings the header comment up to date.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit e3ebfb96f396731ca2d0b108785d5da31b53ab00
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Mon Jul 2 14:42:01 2012 -0700

    rcu: Add PROVE_RCU_DELAY to provoke difficult races
    
    There have been some recent bugs that were triggered only when
    preemptible RCU's __rcu_read_unlock() was preempted just after setting
    ->rcu_read_lock_nesting to INT_MIN, which is a low-probability event.
    Therefore, reproducing those bugs (to say nothing of gaining confidence
    in alleged fixes) was quite difficult.  This commit therefore creates
    a new debug-only RCU kernel config option that forces a short delay
    in __rcu_read_unlock() to increase the probability of those sorts of
    bugs occurring.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit 136251d02ff283e99f023b0abdeb52b4b3423a56
Author: Ulrich Weber <ulrich.weber@sophos.com>
Date:   Thu Sep 20 03:52:04 2012 +0000

    netfilter: nf_nat: remove obsolete rcu_read_unlock call
    
    hlist walk in find_appropriate_src() is not protected anymore by rcu_read_lock(),
    so rcu_read_unlock() is unnecessary if in_range() matches.
    
    This bug was added in (c7232c9 netfilter: add protocol independent NAT core).
    
    Signed-off-by: Ulrich Weber <ulrich.weber@sophos.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 012dc19a45b2b9cc2ebd14aaa401cf782c2abba4
Author: John Fastabend <john.r.fastabend@intel.com>
Date:   Wed Sep 19 21:35:57 2012 +0000

    ixgbevf: scheduling while atomic in reset hw path
    
    In ixgbevf_reset_hw_vf() msleep is called while holding mbx_lock
    resulting in a schedule while atomic bug with trace below.
    
    This patch uses mdelay instead.
    
    BUG: scheduling while atomic: ip/6539/0x00000002
    2 locks held by ip/6539:
     #0:  (rtnl_mutex){+.+.+.}, at: [<ffffffff81419cc3>] rtnl_lock+0x17/0x19
     #1:  (&(&adapter->mbx_lock)->rlock){+.+...}, at: [<ffffffffa0030855>] ixgbevf_reset+0x30/0xc1 [ixgbevf]
    Modules linked in: ixgbevf ixgbe mdio libfc scsi_transport_fc 8021q scsi_tgt garp stp llc cpufreq_ondemand acpi_cpufreq freq_table mperf ipv6 uinput igb coretemp hwmon crc32c_intel ioatdma i2c_i801 shpchp microcode lpc_ich mfd_core i2c_core joydev dca pcspkr serio_raw pata_acpi ata_generic usb_storage pata_jmicron
    Pid: 6539, comm: ip Not tainted 3.6.0-rc3jk-net-next+ #104
    Call Trace:
     [<ffffffff81072202>] __schedule_bug+0x6a/0x79
     [<ffffffff814bc7e0>] __schedule+0xa2/0x684
     [<ffffffff8108f85f>] ? trace_hardirqs_off+0xd/0xf
     [<ffffffff814bd0c0>] schedule+0x64/0x66
     [<ffffffff814bb5e2>] schedule_timeout+0xa6/0xca
     [<ffffffff810536b9>] ? lock_timer_base+0x52/0x52
     [<ffffffff812629e0>] ? __udelay+0x15/0x17
     [<ffffffff814bb624>] schedule_timeout_uninterruptible+0x1e/0x20
     [<ffffffff810541c0>] msleep+0x1b/0x22
     [<ffffffffa002e723>] ixgbevf_reset_hw_vf+0x90/0xe5 [ixgbevf]
     [<ffffffffa0030860>] ixgbevf_reset+0x3b/0xc1 [ixgbevf]
     [<ffffffffa0032fba>] ixgbevf_open+0x43/0x43e [ixgbevf]
     [<ffffffff81409610>] ? dev_set_rx_mode+0x2e/0x33
     [<ffffffff8140b0f1>] __dev_open+0xa0/0xe5
     [<ffffffff814097ed>] __dev_change_flags+0xbe/0x142
     [<ffffffff8140b01c>] dev_change_flags+0x21/0x56
     [<ffffffff8141a843>] do_setlink+0x2e2/0x7f4
     [<ffffffff81016e36>] ? native_sched_clock+0x37/0x39
     [<ffffffff8141b0ac>] rtnl_newlink+0x277/0x4bb
     [<ffffffff8141aee9>] ? rtnl_newlink+0xb4/0x4bb
     [<ffffffff812217d1>] ? selinux_capable+0x32/0x3a
     [<ffffffff8104fb17>] ? ns_capable+0x4f/0x67
     [<ffffffff81419cc3>] ? rtnl_lock+0x17/0x19
     [<ffffffff81419f28>] rtnetlink_rcv_msg+0x236/0x253
     [<ffffffff81419cf2>] ? rtnetlink_rcv+0x2d/0x2d
     [<ffffffff8142fd42>] netlink_rcv_skb+0x43/0x94
     [<ffffffff81419ceb>] rtnetlink_rcv+0x26/0x2d
     [<ffffffff8142faf1>] netlink_unicast+0xee/0x174
     [<ffffffff81430327>] netlink_sendmsg+0x26a/0x288
     [<ffffffff813fb04f>] ? rcu_read_unlock+0x56/0x67
     [<ffffffff813f5e6d>] __sock_sendmsg_nosec+0x58/0x61
     [<ffffffff813f81b7>] __sock_sendmsg+0x3d/0x48
     [<ffffffff813f8339>] sock_sendmsg+0x6e/0x87
     [<ffffffff81107c9f>] ? might_fault+0xa5/0xac
     [<ffffffff81402a72>] ? copy_from_user+0x2a/0x2c
     [<ffffffff81402e62>] ? verify_iovec+0x54/0xaa
     [<ffffffff813f9834>] __sys_sendmsg+0x206/0x288
     [<ffffffff810694fa>] ? up_read+0x23/0x3d
     [<ffffffff811307e5>] ? fcheck_files+0xac/0xea
     [<ffffffff8113095e>] ? fget_light+0x3a/0xb9
     [<ffffffff813f9a2e>] sys_sendmsg+0x42/0x60
     [<ffffffff814c5ba9>] system_call_fastpath+0x16/0x1b
    
    CC: Eric Dumazet <edumazet@google.com>
    Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
    Tested-By: Robert Garrett <robertx.e.garrett@intel.com>
    Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>

commit 8a8e04df4747661daaee77e98e102d99c9e09b98
Author: Daniel Wagner <daniel.wagner@bmw-carit.de>
Date:   Wed Sep 12 16:12:07 2012 +0200

    cgroup: Assign subsystem IDs during compile time
    
    WARNING: With this change it is impossible to load external built
    controllers anymore.
    
    In case where CONFIG_NETPRIO_CGROUP=m and CONFIG_NET_CLS_CGROUP=m is
    set, corresponding subsys_id should also be a constant. Up to now,
    net_prio_subsys_id and net_cls_subsys_id would be of the type int and
    the value would be assigned during runtime.
    
    By switching the macro definition IS_SUBSYS_ENABLED from IS_BUILTIN
    to IS_ENABLED, all *_subsys_id will have constant value. That means we
    need to remove all the code which assumes a value can be assigned to
    net_prio_subsys_id and net_cls_subsys_id.
    
    A close look is necessary on the RCU part which was introduces by
    following patch:
    
      commit f845172531fb7410c7fb7780b1a6e51ee6df7d52
      Author:       Herbert Xu <herbert@gondor.apana.org.au>  Mon May 24 09:12:34 2010
      Committer:    David S. Miller <davem@davemloft.net>  Mon May 24 09:12:34 2010
    
      cls_cgroup: Store classid in struct sock
    
      Tis code was added to init_cgroup_cls()
    
              /* We can't use rcu_assign_pointer because this is an int. */
              smp_wmb();
              net_cls_subsys_id = net_cls_subsys.subsys_id;
    
      respectively to exit_cgroup_cls()
    
              net_cls_subsys_id = -1;
              synchronize_rcu();
    
      and in module version of task_cls_classid()
    
              rcu_read_lock();
              id = rcu_dereference(net_cls_subsys_id);
              if (id >= 0)
                      classid = container_of(task_subsys_state(p, id),
                                             struct cgroup_cls_state, css)->classid;
              rcu_read_unlock();
    
    Without an explicit explaination why the RCU part is needed. (The
    rcu_deference was fixed by exchanging it to rcu_derefence_index_check()
    in a later commit, but that is a minor detail.)
    
    So here is my pondering why it was introduced and why it safe to
    remove it now. Note that this code was copied over to net_prio the
    reasoning holds for that subsystem too.
    
    The idea behind the RCU use for net_cls_subsys_id is to make sure we
    get a valid pointer back from task_subsys_state(). task_subsys_state()
    is just blindly accessing the subsys array and returning the
    pointer. Obviously, passing in -1 as id into task_subsys_state()
    returns an invalid value (out of lower bound).
    
    So this code makes sure that only after module is loaded and the
    subsystem registered, the id is assigned.
    
    Before unregistering the module all old readers must have left the
    critical section. This is done by assigning -1 to the id and issuing a
    synchronized_rcu(). Any new readers wont call task_subsys_state()
    anymore and therefore it is safe to unregister the subsystem.
    
    The new code relies on the same trick, but it looks at the subsys
    pointer return by task_subsys_state() (remember the id is constant
    and therefore we allways have a valid index into the subsys
    array).
    
    No precautions need to be taken during module loading
    module. Eventually, all CPUs will get a valid pointer back from
    task_subsys_state() because rebind_subsystem() which is called after
    the module init() function will assigned subsys[net_cls_subsys_id] the
    newly loaded module subsystem pointer.
    
    When the subsystem is about to be removed, rebind_subsystem() will
    called before the module exit() function. In this case,
    rebind_subsys() will assign subsys[net_cls_subsys_id] a NULL pointer
    and then it calls synchronize_rcu(). All old readers have left by then
    the critical section. Any new reader wont access the subsystem
    anymore.  At this point we are safe to unregister the subsystem. No
    synchronize_rcu() call is needed.
    
    Signed-off-by: Daniel Wagner <daniel.wagner@bmw-carit.de>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Acked-by: Li Zefan <lizefan@huawei.com>
    Acked-by: Neil Horman <nhorman@tuxdriver.com>
    Cc: "David S. Miller" <davem@davemloft.net>
    Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Eric Dumazet <edumazet@google.com>
    Cc: Gao feng <gaofeng@cn.fujitsu.com>
    Cc: Glauber Costa <glommer@parallels.com>
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: Jamal Hadi Salim <jhs@mojatatu.com>
    Cc: John Fastabend <john.r.fastabend@intel.com>
    Cc: Kamezawa Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: netdev@vger.kernel.org
    Cc: cgroups@vger.kernel.org

commit cca32e4bf999a34ac08d959f351f2b30bcd02460
Author: Eric Dumazet <edumazet@google.com>
Date:   Sun Jul 29 21:06:13 2012 +0000

    net: TCP early demux cleanup
    
    early_demux() handlers should be called in RCU context, and as we
    use skb_dst_set_noref(skb, dst), caller must not exit from RCU context
    before dst use (skb_dst(skb)) or release (skb_drop(dst))
    
    Therefore, rcu_read_lock()/rcu_read_unlock() pairs around
    ->early_demux() are confusing and not needed :
    
    Protocol handlers are already in an RCU read lock section.
    (__netif_receive_skb() does the rcu_read_lock() )
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5672874889a8e9f3049eefb57e0eb41dd6fa83a7
Merge: dab058fd5ff8 2e1706f234f8
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Tue Jul 3 18:01:54 2012 -0700

    Merge git://git.kernel.org/pub/scm/linux/kernel/git/davem/net
    
    Pull networking update from David Miller:
    
     1) Fix RX sequence number handling in mwifiex, from Stone Piao.
    
     2) Netfilter ipset mis-compares device names, fix from Florian
        Westphal.
    
     3) Fix route leak in ipv6 IPVS, from Eric Dumazet.
    
     4) NFS fixes.  Several buffer overflows in NCI layer from Dan
        Rosenberg, and release sock OOPS'er fix from Eric Dumazet.
    
     5) Fix WEP handling ath9k, we started using a bit the chip provides to
        indicate undecrypted packets but that bit turns out to be unreliable
        in certain configurations.  Fix from Felix Fietkau.
    
     6) Fix Kconfig dependency bug in wlcore, from Randy Dunlap.
    
     7) New USB IDs for rtlwifi driver from Larry Finger.
    
     8) Fix crashes in qmi_wwan usbnet driver when disconnecting, from Bjrn
        Mork.
    
     9) Gianfar driver programs coalescing settings properly in single queue
        mode, but does not do so in multi-queue mode.  Fix from Claudiu
        Manoil.
    
    10) Missing module.h include in davinci_cpdma.c, from Daniel Mack.
    
    11) Need dummy handler for IPSET_CMD_NONE otherwise we crash in ipset if
        we get this via nfnetlink, fix from Tomasz Bursztyka.
    
    12) Missing RCU unlock in nfnetlink error path, also from Tomasz.
    
    13) Fix divide by zero in igbvf when the user tries to set an RX
        coalescing value of 0 usecs, from Mitch A Williams.
    
    14) We can process SCTP sacks for the wrong transport, oops.  Fix from
        Neil Horman.
    
    15) Remove hw IP payload checksumming from e1000e driver.  This has zery
        value in our stack, and turning it on creates a very unintuitive
        restriction for users when using jumbo MTUs.
    
        Specifically, when IP payload checksums are on you cannot use both
        receive hashing offload and jumbo MTU.  Fix from Bruce Allan.
    
    * git://git.kernel.org/pub/scm/linux/kernel/git/davem/net: (27 commits)
      e1000e: remove use of IP payload checksum
      sctp: be more restrictive in transport selection on bundled sacks
      igbvf: fix divide by zero
      netfilter: nfnetlink: fix missing rcu_read_unlock in nfnetlink_rcv_msg
      netfilter: ipset: fix crash if IPSET_CMD_NONE command is sent
      davinci_cpdma: include linux/module.h
      gianfar: Fix RXICr/TXICr programming for multi-queue mode
      net: Downgrade CAP_SYS_MODULE deprecated message from error to warning.
      net: qmi_wwan: fix Oops while disconnecting
      mwifiex: fix memory leak associated with IE manamgement
      ath9k: fix panic caused by returning a descriptor we have queued for reuse
      mac80211: correct behaviour on unrecognised action frames
      ath9k: enable serialize_regmode for non-PCIE AR9287
      rtlwifi: rtl8192cu: New USB IDs
      NFC: Return from rawsock_release when sk is NULL
      iwlwifi: fix activating inactive stations
      wlcore: drop INET dependency
      ath9k: fix dynamic WEP related regression
      NFC: Prevent multiple buffer overflows in NCI
      netfilter: update location of my trees
      ...

commit 2a3fa843b555d202e682bf08c65ee1a4a93c79cf
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Mon May 21 11:58:36 2012 -0700

    rcu: Consolidate tree/tiny __rcu_read_{,un}lock() implementations
    
    The CONFIG_TREE_PREEMPT_RCU and CONFIG_TINY_PREEMPT_RCU versions of
    __rcu_read_lock() and __rcu_read_unlock() are identical, so this commit
    consolidates them into kernel/rcupdate.h.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit 0c12d91b7064e16e96939243187b12fbd99caac7
Merge: 76fbc247b9ae 4009e18851ea
Author: David S. Miller <davem@davemloft.net>
Date:   Fri Jun 29 16:35:53 2012 -0700

    Merge branch 'master' of git://1984.lsi.us.es/nf
    
    Pablo Neira Ayuso says:
    
    ====================
    The following are 4 fixes and the update of the MAINTAINERS file
    to point to my Netfilter trees.
    
    They are:
    
    * One refcount leak fix in IPVS IPv6 support from Eric Dumazet.
    
    * One fix for interface comparison in ipset hash-netiface sets
      from Florian Westphal.
    
    * One fix for a missing rcu_read_unlock in nfnetlink from
      Tomasz Bursztyka.
    
    * One fix for a kernel crash if IPSET_CMD_NONE is set to ipset via
      nfnetlink, again from Tomasz Bursztyka.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4009e18851ea555959c6017d848983b3d60bf667
Author: Tomasz Bursztyka <tomasz.bursztyka@linux.intel.com>
Date:   Thu Jun 28 02:57:49 2012 +0000

    netfilter: nfnetlink: fix missing rcu_read_unlock in nfnetlink_rcv_msg
    
    Bug added in commit 6b75e3e8d664a9a (netfilter: nfnetlink: add RCU in
    nfnetlink_rcv_msg())
    
    Signed-off-by: Tomasz Bursztyka <tomasz.bursztyka@linux.intel.com>
    Acked-by: Eric Dumazet <edumazet@google.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 0450243096de90ff51c3a6c605410c5e28d79f8d
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Jun 13 05:30:07 2012 +0000

    bonding: drop_monitor aware
    
    When packets are dropped in TX path, its better to use kfree_skb()
    instead of dev_kfree_skb() to give proper drop_monitor events.
    
    Also move the kfree_skb() call after read_unlock() in bond_alb_xmit()
    and bond_xmit_activebackup()
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Jay Vosburgh <fubar@us.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 778b032d96909690c19d84f8d17c13be65ed6f8e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Tue May 29 21:30:08 2012 +0200

    uprobes: Kill uprobes_srcu/uprobe_srcu_id
    
    Kill the no longer needed uprobes_srcu/uprobe_srcu_id code.
    
    It doesn't really work anyway. synchronize_srcu() can only
    synchronize with the code "inside" the
    srcu_read_lock/srcu_read_unlock section, while
    uprobe_pre_sstep_notifier() does srcu_read_lock() _after_ we
    already hit the breakpoint.
    
    I guess this probably works "in practice". synchronize_srcu() is
    slow and it implies synchronize_sched(), and the probed task
    enters the non- preemptible section at the start of exception
    handler. Still this is not right at least in theory, and
    task->uprobe_srcu_id blows task_struct.
    
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
    Cc: Anton Arapov <anton@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: http://lkml.kernel.org/r/20120529193008.GG8057@redhat.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit cb79295e20a8088a2fd6a9b3cb5f2d889ec36b4d
Author: Anton Vorontsov <anton.vorontsov@linaro.org>
Date:   Thu May 31 16:26:22 2012 -0700

    cpu: introduce clear_tasks_mm_cpumask() helper
    
    Many architectures clear tasks' mm_cpumask like this:
    
            read_lock(&tasklist_lock);
            for_each_process(p) {
                    if (p->mm)
                            cpumask_clear_cpu(cpu, mm_cpumask(p->mm));
            }
            read_unlock(&tasklist_lock);
    
    Depending on the context, the code above may have several problems,
    such as:
    
    1. Working with task->mm w/o getting mm or grabing the task lock is
       dangerous as ->mm might disappear (exit_mm() assigns NULL under
       task_lock(), so tasklist lock is not enough).
    
    2. Checking for process->mm is not enough because process' main
       thread may exit or detach its mm via use_mm(), but other threads
       may still have a valid mm.
    
    This patch implements a small helper function that does things
    correctly, i.e.:
    
    1. We take the task's lock while whe handle its mm (we can't use
       get_task_mm()/mmput() pair as mmput() might sleep);
    
    2. To catch exited main thread case, we use find_lock_task_mm(),
       which walks up all threads and returns an appropriate task
       (with task lock held).
    
    Also, Per Peter Zijlstra's idea, now we don't grab tasklist_lock in
    the new helper, instead we take the rcu read lock. We can do this
    because the function is called after the cpu is taken down and marked
    offline, so no new tasks will get this cpu set in their mm mask.
    
    Signed-off-by: Anton Vorontsov <anton.vorontsov@linaro.org>
    Cc: Richard Weinberger <richard@nod.at>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Russell King <rmk@arm.linux.org.uk>
    Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Cc: Mike Frysinger <vapier@gentoo.org>
    Cc: Paul Mundt <lethal@linux-sh.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit f05ed3f1abefd37c08fbf08c766d2abd40607777
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Thu May 31 16:26:18 2012 -0700

    proc: don't do dummy rcu_read_lock/rcu_read_unlock on error path
    
    rcu_read_lock()/rcu_read_unlock() is nop for TINY_RCU, but is not a nop
    for, say, PREEMPT_RCU.
    
    proc_fill_cache() is called without RCU lock, there is no need to
    lock/unlock on error path, simply jump out of the loop.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 440253c17fc4ed41d778492a7fb44dc0d756eccc
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Wed Feb 22 13:29:06 2012 -0800

    rcu: Increment upper bit only for srcu_read_lock()
    
    The purpose of the upper bit of SRCU's per-CPU counters is to guarantee
    that no reasonable series of srcu_read_lock() and srcu_read_unlock()
    operations can return the value of the counter to its original value.
    This guarantee is require only after the index has been switched to
    the other set of counters, so at most one srcu_read_lock() can affect
    a given CPU's counter.  The number of srcu_read_unlock() operations
    on a given counter is limited to the number of tasks in the system,
    which given the Linux kernel's current structure is limited to far less
    than 2^30 on 32-bit systems and far less than 2^62 on 64-bit systems.
    (Something about a limited number of bytes in the kernel's address space.)
    
    Therefore, if srcu_read_lock() increments the upper bits, then
    srcu_read_unlock() need not do so.  In this case, an srcu_read_lock() and
    an srcu_read_unlock() will flip the lower bit of the upper field of the
    counter.  An unreasonably large additional number of srcu_read_unlock()
    operations would be required to return the counter to its initial value,
    thus preserving the guarantee.
    
    This commit takes this approach, which further allows it to shrink
    the size of the upper field to one bit, making the number of
    srcu_read_unlock() operations required to return the counter to its
    initial value even more unreasonable than before.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit cef50120b61c2af4ce34bc165e19cad66296f93d
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Sun Feb 5 07:42:44 2012 -0800

    rcu: Direct algorithmic SRCU implementation
    
    The current implementation of synchronize_srcu_expedited() can cause
    severe OS jitter due to its use of synchronize_sched(), which in turn
    invokes try_stop_cpus(), which causes each CPU to be sent an IPI.
    This can result in severe performance degradation for real-time workloads
    and especially for short-interation-length HPC workloads.  Furthermore,
    because only one instance of try_stop_cpus() can be making forward progress
    at a given time, only one instance of synchronize_srcu_expedited() can
    make forward progress at a time, even if they are all operating on
    distinct srcu_struct structures.
    
    This commit, inspired by an earlier implementation by Peter Zijlstra
    (https://lkml.org/lkml/2012/1/31/211) and by further offline discussions,
    takes a strictly algorithmic bits-in-memory approach.  This has the
    disadvantage of requiring one explicit memory-barrier instruction in
    each of srcu_read_lock() and srcu_read_unlock(), but on the other hand
    completely dispenses with OS jitter and furthermore allows SRCU to be
    used freely by CPUs that RCU believes to be idle or offline.
    
    The update-side implementation handles the single read-side memory
    barrier by rechecking the per-CPU counters after summing them and
    by running through the update-side state machine twice.
    
    This implementation has passed moderate rcutorture testing on both
    x86 and Power.  Also updated to use this_cpu_ptr() instead of per_cpu_ptr(),
    as suggested by Peter Zijlstra.
    
    Reported-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Reviewed-by: Lai Jiangshan <laijs@cn.fujitsu.com>

commit 1cbfac52d7ccb45e3a3ea1941ed626997143456c
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Mar 28 23:29:45 2012 +0200

    firmware_class: Rework usermodehelper check
    
    commit fe2e39d8782d885755139304d8dba0b3e5bfa878 upstream.
    
    Instead of two functions, read_lock_usermodehelper() and
    usermodehelper_is_disabled(), used in combination, introduce
    usermodehelper_read_trylock() that will only return with umhelper_sem
    held if usermodehelper_disabled is unset (and will return -EAGAIN
    otherwise) and make _request_firmware() use it.
    
    Rename read_unlock_usermodehelper() to
    usermodehelper_read_unlock() to follow the naming convention of the
    new function.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 16223d0d61330c85276e84e0ce8e26addcbf00d7
Author: Dave Chinner <dchinner@redhat.com>
Date:   Wed Mar 7 04:50:25 2012 +0000

    xfs: fix inode lookup race
    
    commit f30d500f809eca67a21704347ab14bb35877b5ee upstream.
    
    When we get concurrent lookups of the same inode that is not in the
    per-AG inode cache, there is a race condition that triggers warnings
    in unlock_new_inode() indicating that we are initialising an inode
    that isn't in a the correct state for a new inode.
    
    When we do an inode lookup via a file handle or a bulkstat, we don't
    serialise lookups at a higher level through the dentry cache (i.e.
    pathless lookup), and so we can get concurrent lookups of the same
    inode.
    
    The race condition is between the insertion of the inode into the
    cache in the case of a cache miss and a concurrently lookup:
    
    Thread 1                        Thread 2
    xfs_iget()
      xfs_iget_cache_miss()
        xfs_iread()
        lock radix tree
        radix_tree_insert()
                                    rcu_read_lock
                                    radix_tree_lookup
                                    lock inode flags
                                    XFS_INEW not set
                                    igrab()
                                    unlock inode flags
                                    rcu_read_unlock
                                    use uninitialised inode
                                    .....
        lock inode flags
        set XFS_INEW
        unlock inode flags
        unlock radix tree
      xfs_setup_inode()
        inode flags = I_NEW
        unlock_new_inode()
          WARNING as inode flags != I_NEW
    
    This can lead to inode corruption, inode list corruption, etc, and
    is generally a bad thing to occur.
    
    Fix this by setting XFS_INEW before inserting the inode into the
    radix tree. This will ensure any concurrent lookup will find the new
    inode with XFS_INEW set and that forces the lookup to wait until the
    XFS_INEW flag is removed before allowing the lookup to succeed.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ben Myers <bpm@sgi.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cebef762efaa200ad00134a14c88374c6faaac6d
Author: Dave Chinner <dchinner@redhat.com>
Date:   Wed Mar 7 04:50:25 2012 +0000

    xfs: fix inode lookup race
    
    commit f30d500f809eca67a21704347ab14bb35877b5ee upstream.
    
    When we get concurrent lookups of the same inode that is not in the
    per-AG inode cache, there is a race condition that triggers warnings
    in unlock_new_inode() indicating that we are initialising an inode
    that isn't in a the correct state for a new inode.
    
    When we do an inode lookup via a file handle or a bulkstat, we don't
    serialise lookups at a higher level through the dentry cache (i.e.
    pathless lookup), and so we can get concurrent lookups of the same
    inode.
    
    The race condition is between the insertion of the inode into the
    cache in the case of a cache miss and a concurrently lookup:
    
    Thread 1                        Thread 2
    xfs_iget()
      xfs_iget_cache_miss()
        xfs_iread()
        lock radix tree
        radix_tree_insert()
                                    rcu_read_lock
                                    radix_tree_lookup
                                    lock inode flags
                                    XFS_INEW not set
                                    igrab()
                                    unlock inode flags
                                    rcu_read_unlock
                                    use uninitialised inode
                                    .....
        lock inode flags
        set XFS_INEW
        unlock inode flags
        unlock radix tree
      xfs_setup_inode()
        inode flags = I_NEW
        unlock_new_inode()
          WARNING as inode flags != I_NEW
    
    This can lead to inode corruption, inode list corruption, etc, and
    is generally a bad thing to occur.
    
    Fix this by setting XFS_INEW before inserting the inode into the
    radix tree. This will ensure any concurrent lookup will find the new
    inode with XFS_INEW set and that forces the lookup to wait until the
    XFS_INEW flag is removed before allowing the lookup to succeed.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ben Myers <bpm@sgi.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c5ee1ac24b6f878e63fd208984b3cfe3ccf7b9a8
Author: Dave Chinner <dchinner@redhat.com>
Date:   Wed Mar 7 04:50:25 2012 +0000

    xfs: fix inode lookup race
    
    commit f30d500f809eca67a21704347ab14bb35877b5ee upstream.
    
    When we get concurrent lookups of the same inode that is not in the
    per-AG inode cache, there is a race condition that triggers warnings
    in unlock_new_inode() indicating that we are initialising an inode
    that isn't in a the correct state for a new inode.
    
    When we do an inode lookup via a file handle or a bulkstat, we don't
    serialise lookups at a higher level through the dentry cache (i.e.
    pathless lookup), and so we can get concurrent lookups of the same
    inode.
    
    The race condition is between the insertion of the inode into the
    cache in the case of a cache miss and a concurrently lookup:
    
    Thread 1                        Thread 2
    xfs_iget()
      xfs_iget_cache_miss()
        xfs_iread()
        lock radix tree
        radix_tree_insert()
                                    rcu_read_lock
                                    radix_tree_lookup
                                    lock inode flags
                                    XFS_INEW not set
                                    igrab()
                                    unlock inode flags
                                    rcu_read_unlock
                                    use uninitialised inode
                                    .....
        lock inode flags
        set XFS_INEW
        unlock inode flags
        unlock radix tree
      xfs_setup_inode()
        inode flags = I_NEW
        unlock_new_inode()
          WARNING as inode flags != I_NEW
    
    This can lead to inode corruption, inode list corruption, etc, and
    is generally a bad thing to occur.
    
    Fix this by setting XFS_INEW before inserting the inode into the
    radix tree. This will ensure any concurrent lookup will find the new
    inode with XFS_INEW set and that forces the lookup to wait until the
    XFS_INEW flag is removed before allowing the lookup to succeed.
    
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ben Myers <bpm@sgi.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fe2e39d8782d885755139304d8dba0b3e5bfa878
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Wed Mar 28 23:29:45 2012 +0200

    firmware_class: Rework usermodehelper check
    
    Instead of two functions, read_lock_usermodehelper() and
    usermodehelper_is_disabled(), used in combination, introduce
    usermodehelper_read_trylock() that will only return with umhelper_sem
    held if usermodehelper_disabled is unset (and will return -EAGAIN
    otherwise) and make _request_firmware() use it.
    
    Rename read_unlock_usermodehelper() to
    usermodehelper_read_unlock() to follow the naming convention of the
    new function.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Acked-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: stable@vger.kernel.org

commit eaddcd76903c28e84bb452a35835babb0800a2c4
Author: Andy Gospodarek <andy@greyhouse.net>
Date:   Thu Mar 22 16:14:29 2012 +0000

    bonding: remove entries for master_ip and vlan_ip and query devices instead
    
    The following patch aimed to resolve an issue where secondary, tertiary,
    etc. addresses added to bond interfaces could overwrite the
    bond->master_ip and vlan_ip values.
    
            commit 917fbdb32f37e9a93b00bb12ee83532982982df3
            Author: Henrik Saavedra Persson <henrik.e.persson@ericsson.com>
            Date:   Wed Nov 23 23:37:15 2011 +0000
    
                bonding: only use primary address for ARP
    
    That patch was good because it prevented bonds using ARP monitoring from
    sending frames with an invalid source IP address.  Unfortunately, it
    didn't always work as expected.
    
    When using an ioctl (like ifconfig does) to set the IP address and
    netmask, 2 separate ioctls are actually called to set the IP and netmask
    if the mask chosen doesn't match the standard mask for that class of
    address.  The first ioctl did not have a mask that matched the one in
    the primary address and would still cause the device address to be
    overwritten.  The second ioctl that was called to set the mask would
    then detect as secondary and ignored, but the damage was already done.
    
    This was not an issue when using an application that used netlink
    sockets as the setting of IP and netmask came down at once.  The
    inconsistent behavior between those two interfaces was something that
    needed to be resolved.
    
    While I was thinking about how I wanted to resolve this, Ralf Zeidler
    came with a patch that resolved this on a RHEL kernel by keeping a full
    shadow of the entries in dev->ifa_list for the bonding device and vlan
    devices in the bonding driver.  I didn't like the duplication of the
    list as I want to see the 'bonding' struct and code shrink rather than
    grow, but liked the general idea.
    
    As the Subject indicates this patch drops the master_ip and vlan_ip
    elements from the 'bonding' and 'vlan_entry' structs, respectively.
    This can be done because a device's address-list is now traversed to
    determine the optimal source IP address for ARP requests and for checks
    to see if the bonding device has a particular IP address.  This code
    could have all be contained inside the bonding driver, but it made more
    sense to me to EXPORT and call inet_confirm_addr since it did exactly
    what was needed.
    
    I tested this and a backported patch and everything works as expected.
    Ralf also helped with verification of the backported patch.
    
    Thanks to Ralf for all his help on this.
    
    v2: Whitespace and organizational changes based on suggestions from Jay
    Vosburgh and Dave Miller.
    
    v3: Fixup incorrect usage of rcu_read_unlock based on Dave Miller's
    suggestion.
    
    Signed-off-by: Andy Gospodarek <andy@greyhouse.net>
    CC: Ralf Zeidler <ralf.zeidler@nsn.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 619d094b5872a5af153f1af77a8b7f7326faf0d0
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Wed Mar 21 16:34:23 2012 -0700

    memcg: simplify move_account() check
    
    In memcg, for avoiding take-lock-irq-off at accessing page_cgroup, a
    logic, flag + rcu_read_lock(), is used.  This works as following
    
         CPU-A                     CPU-B
                                 rcu_read_lock()
        set flag
                                 if(flag is set)
                                       take heavy lock
                                 do job.
        synchronize_rcu()        rcu_read_unlock()
        take heavy lock.
    
    In recent discussion, it's argued that using per-cpu value for this flag
    just complicates the code because 'set flag' is very rare.
    
    This patch changes 'flag' implementation from percpu to atomic_t.  This
    will be much simpler.
    
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Greg Thelen <gthelen@google.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Michal Hocko <mhocko@suse.cz>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: Ying Han <yinghan@google.com>
    Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
    Acked-by: Johannes Weiner <hannes@cmpxchg.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 3268c63eded4612a3d07b56d1e02ce7731e6608e
Author: Christoph Lameter <cl@linux.com>
Date:   Wed Mar 21 16:34:06 2012 -0700

    mm: fix move/migrate_pages() race on task struct
    
    Migration functions perform the rcu_read_unlock too early.  As a result
    the task pointed to may change from under us.  This can result in an oops,
    as reported by Dave Hansen in https://lkml.org/lkml/2012/2/23/302.
    
    The following patch extend the period of the rcu_read_lock until after the
    permissions checks are done.  We also take a refcount so that the task
    reference is stable when calling security check functions and performing
    cpuset node validation (which takes a mutex).
    
    The refcount is dropped before actual page migration occurs so there is no
    change to the refcounts held during page migration.
    
    Also move the determination of the mm of the task struct to immediately
    before the do_migrate*() calls so that it is clear that we switch from
    handling the task during permission checks to the mm for the actual
    migration.  Since the determination is only done once and we then no
    longer use the task_struct we can be sure that we operate on a specific
    address space that will not change from under us.
    
    [akpm@linux-foundation.org: checkpatch fixes]
    Signed-off-by: Christoph Lameter <cl@linux.com>
    Cc: "Eric W. Biederman" <ebiederm@xmission.com>
    Reported-by: Dave Hansen <dave@linux.vnet.ibm.com>
    Cc: Mel Gorman <mel@csn.ul.ie>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Cc: Hugh Dickins <hughd@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit f30d500f809eca67a21704347ab14bb35877b5ee
Author: Dave Chinner <dchinner@redhat.com>
Date:   Wed Mar 7 04:50:25 2012 +0000

    xfs: fix inode lookup race
    
    When we get concurrent lookups of the same inode that is not in the
    per-AG inode cache, there is a race condition that triggers warnings
    in unlock_new_inode() indicating that we are initialising an inode
    that isn't in a the correct state for a new inode.
    
    When we do an inode lookup via a file handle or a bulkstat, we don't
    serialise lookups at a higher level through the dentry cache (i.e.
    pathless lookup), and so we can get concurrent lookups of the same
    inode.
    
    The race condition is between the insertion of the inode into the
    cache in the case of a cache miss and a concurrently lookup:
    
    Thread 1                        Thread 2
    xfs_iget()
      xfs_iget_cache_miss()
        xfs_iread()
        lock radix tree
        radix_tree_insert()
                                    rcu_read_lock
                                    radix_tree_lookup
                                    lock inode flags
                                    XFS_INEW not set
                                    igrab()
                                    unlock inode flags
                                    rcu_read_unlock
                                    use uninitialised inode
                                    .....
        lock inode flags
        set XFS_INEW
        unlock inode flags
        unlock radix tree
      xfs_setup_inode()
        inode flags = I_NEW
        unlock_new_inode()
          WARNING as inode flags != I_NEW
    
    This can lead to inode corruption, inode list corruption, etc, and
    is generally a bad thing to occur.
    
    Fix this by setting XFS_INEW before inserting the inode into the
    radix tree. This will ensure any concurrent lookup will find the new
    inode with XFS_INEW set and that forces the lookup to wait until the
    XFS_INEW flag is removed before allowing the lookup to succeed.
    
    cc: <stable@vger.kernel.org> # for 3.0.x, 3.2.x
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Ben Myers <bpm@sgi.com>

commit 4175e9d6c44519cd60f4a9efbf031cfa37e42be2
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Mar 7 19:09:39 2012 +0000

    dm flakey: fix crash on read when corrupt_bio_byte not set
    
    commit 1212268fd9816e3b8801e57b896fceaec71969ad upstream.
    
    The following BUG is hit on the first read that is submitted to a dm
    flakey test device while the device is "down" if the corrupt_bio_byte
    feature wasn't requested when the device's table was loaded.
    
    Example DM table that will hit this BUG:
    0 2097152 flakey 8:0 2048 0 30
    
    This bug was introduced by commit a3998799fb4df0b0af8271a7d50c4269032397aa
    (dm flakey: add corrupt_bio_byte feature) in v3.1-rc1.
    
    BUG: unable to handle kernel paging request at ffff8801cfce3fff
    IP: [<ffffffffa008c233>] corrupt_bio_data+0x6e/0xae [dm_flakey]
    PGD 1606063 PUD 0
    Oops: 0002 [#1] SMP
    ...
    Call Trace:
     <IRQ>
     [<ffffffffa008c2b5>] flakey_end_io+0x42/0x48 [dm_flakey]
     [<ffffffffa00dca98>] clone_endio+0x54/0xb6 [dm_mod]
     [<ffffffff81130587>] bio_endio+0x2d/0x2f
     [<ffffffff811c819a>] req_bio_endio+0x96/0x9f
     [<ffffffff811c94b9>] blk_update_request+0x1dc/0x3a9
     [<ffffffff812f5ee2>] ? rcu_read_unlock+0x21/0x23
     [<ffffffff811c96a6>] blk_update_bidi_request+0x20/0x6e
     [<ffffffff811c9713>] blk_end_bidi_request+0x1f/0x5d
     [<ffffffff811c978d>] blk_end_request+0x10/0x12
     [<ffffffff8128f450>] scsi_io_completion+0x1e5/0x4b1
     [<ffffffff812882a9>] scsi_finish_command+0xec/0xf5
     [<ffffffff8128f830>] scsi_softirq_done+0xff/0x108
     [<ffffffff811ce284>] blk_done_softirq+0x84/0x98
     [<ffffffff81048d19>] __do_softirq+0xe3/0x1d5
     [<ffffffff8138f83f>] ? _raw_spin_lock+0x62/0x69
     [<ffffffff810997cf>] ? handle_irq_event+0x4c/0x61
     [<ffffffff8139833c>] call_softirq+0x1c/0x30
     [<ffffffff81003b37>] do_softirq+0x4b/0xa3
     [<ffffffff81048a39>] irq_exit+0x53/0xca
     [<ffffffff81398acd>] do_IRQ+0x9d/0xb4
     [<ffffffff81390333>] common_interrupt+0x73/0x73
    ...
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1212268fd9816e3b8801e57b896fceaec71969ad
Author: Mike Snitzer <snitzer@redhat.com>
Date:   Wed Mar 7 19:09:39 2012 +0000

    dm flakey: fix crash on read when corrupt_bio_byte not set
    
    The following BUG is hit on the first read that is submitted to a dm
    flakey test device while the device is "down" if the corrupt_bio_byte
    feature wasn't requested when the device's table was loaded.
    
    Example DM table that will hit this BUG:
    0 2097152 flakey 8:0 2048 0 30
    
    This bug was introduced by commit a3998799fb4df0b0af8271a7d50c4269032397aa
    (dm flakey: add corrupt_bio_byte feature) in v3.1-rc1.
    
    BUG: unable to handle kernel paging request at ffff8801cfce3fff
    IP: [<ffffffffa008c233>] corrupt_bio_data+0x6e/0xae [dm_flakey]
    PGD 1606063 PUD 0
    Oops: 0002 [#1] SMP
    ...
    Call Trace:
     <IRQ>
     [<ffffffffa008c2b5>] flakey_end_io+0x42/0x48 [dm_flakey]
     [<ffffffffa00dca98>] clone_endio+0x54/0xb6 [dm_mod]
     [<ffffffff81130587>] bio_endio+0x2d/0x2f
     [<ffffffff811c819a>] req_bio_endio+0x96/0x9f
     [<ffffffff811c94b9>] blk_update_request+0x1dc/0x3a9
     [<ffffffff812f5ee2>] ? rcu_read_unlock+0x21/0x23
     [<ffffffff811c96a6>] blk_update_bidi_request+0x20/0x6e
     [<ffffffff811c9713>] blk_end_bidi_request+0x1f/0x5d
     [<ffffffff811c978d>] blk_end_request+0x10/0x12
     [<ffffffff8128f450>] scsi_io_completion+0x1e5/0x4b1
     [<ffffffff812882a9>] scsi_finish_command+0xec/0xf5
     [<ffffffff8128f830>] scsi_softirq_done+0xff/0x108
     [<ffffffff811ce284>] blk_done_softirq+0x84/0x98
     [<ffffffff81048d19>] __do_softirq+0xe3/0x1d5
     [<ffffffff8138f83f>] ? _raw_spin_lock+0x62/0x69
     [<ffffffff810997cf>] ? handle_irq_event+0x4c/0x61
     [<ffffffff8139833c>] call_softirq+0x1c/0x30
     [<ffffffff81003b37>] do_softirq+0x4b/0xa3
     [<ffffffff81048a39>] irq_exit+0x53/0xca
     [<ffffffff81398acd>] do_IRQ+0x9d/0xb4
     [<ffffffff81390333>] common_interrupt+0x73/0x73
    ...
    
    Signed-off-by: Mike Snitzer <snitzer@redhat.com>
    Cc: stable@vger.kernel.org # 3.1+
    Signed-off-by: Alasdair G Kergon <agk@redhat.com>

commit bf698b519721739568a34f7b301c2c7c51683d8e
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Wed Feb 29 12:24:56 2012 +0530

    PM / Sleep: Fix read_unlock_usermodehelper() call.
    
    [ Upstream commit e4c89a508f4385a0cd8681c2749a2cd2fa476e40 ]
    
    Commit b298d289
     "PM / Sleep: Fix freezer failures due to racy usermodehelper_is_disabled()"
    added read_unlock_usermodehelper() but read_unlock_usermodehelper() is called
    without read_lock_usermodehelper() when kmalloc() failed.
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Acked-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>
    Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d10e3b2952f0df0f23896e32ed54a5a6c916058e
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Feb 24 20:07:29 2012 +0100

    epoll: ep_unregister_pollwait() can use the freed pwq->whead
    
    commit 971316f0503a5c50633d07b83b6db2f15a3a5b00 upstream.
    
    signalfd_cleanup() ensures that ->signalfd_wqh is not used, but
    this is not enough. eppoll_entry->whead still points to the memory
    we are going to free, ep_unregister_pollwait()->remove_wait_queue()
    is obviously unsafe.
    
    Change ep_poll_callback(POLLFREE) to set eppoll_entry->whead = NULL,
    change ep_unregister_pollwait() to check pwq->whead != NULL under
    rcu_read_lock() before remove_wait_queue(). We add the new helper,
    ep_remove_wait_queue(), for this.
    
    This works because sighand_cachep is SLAB_DESTROY_BY_RCU and because
    ->signalfd_wqh is initialized in sighand_ctor(), not in copy_sighand.
    ep_unregister_pollwait()->remove_wait_queue() can play with already
    freed and potentially reused ->sighand, but this is fine. This memory
    must have the valid ->signalfd_wqh until rcu_read_unlock().
    
    Reported-by: Maxime Bizon <mbizon@freebox.fr>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e6aa5c0ba6e2383b2952a9f340e58a990bf15111
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Feb 24 20:07:29 2012 +0100

    epoll: ep_unregister_pollwait() can use the freed pwq->whead
    
    commit 971316f0503a5c50633d07b83b6db2f15a3a5b00 upstream.
    
    signalfd_cleanup() ensures that ->signalfd_wqh is not used, but
    this is not enough. eppoll_entry->whead still points to the memory
    we are going to free, ep_unregister_pollwait()->remove_wait_queue()
    is obviously unsafe.
    
    Change ep_poll_callback(POLLFREE) to set eppoll_entry->whead = NULL,
    change ep_unregister_pollwait() to check pwq->whead != NULL under
    rcu_read_lock() before remove_wait_queue(). We add the new helper,
    ep_remove_wait_queue(), for this.
    
    This works because sighand_cachep is SLAB_DESTROY_BY_RCU and because
    ->signalfd_wqh is initialized in sighand_ctor(), not in copy_sighand.
    ep_unregister_pollwait()->remove_wait_queue() can play with already
    freed and potentially reused ->sighand, but this is fine. This memory
    must have the valid ->signalfd_wqh until rcu_read_unlock().
    
    Reported-by: Maxime Bizon <mbizon@freebox.fr>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 971316f0503a5c50633d07b83b6db2f15a3a5b00
Author: Oleg Nesterov <oleg@redhat.com>
Date:   Fri Feb 24 20:07:29 2012 +0100

    epoll: ep_unregister_pollwait() can use the freed pwq->whead
    
    signalfd_cleanup() ensures that ->signalfd_wqh is not used, but
    this is not enough. eppoll_entry->whead still points to the memory
    we are going to free, ep_unregister_pollwait()->remove_wait_queue()
    is obviously unsafe.
    
    Change ep_poll_callback(POLLFREE) to set eppoll_entry->whead = NULL,
    change ep_unregister_pollwait() to check pwq->whead != NULL under
    rcu_read_lock() before remove_wait_queue(). We add the new helper,
    ep_remove_wait_queue(), for this.
    
    This works because sighand_cachep is SLAB_DESTROY_BY_RCU and because
    ->signalfd_wqh is initialized in sighand_ctor(), not in copy_sighand.
    ep_unregister_pollwait()->remove_wait_queue() can play with already
    freed and potentially reused ->sighand, but this is fine. This memory
    must have the valid ->signalfd_wqh until rcu_read_unlock().
    
    Reported-by: Maxime Bizon <mbizon@freebox.fr>
    Cc: <stable@kernel.org>
    Signed-off-by: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 3ce3230a0cff484e5130153f244d4fb8a56b3a8b
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Feb 8 03:37:27 2012 +0100

    cgroup: Walk task list under tasklist_lock in cgroup_enable_task_cg_list
    
    Walking through the tasklist in cgroup_enable_task_cg_list() inside
    an RCU read side critical section is not enough because:
    
    - RCU is not (yet) safe against while_each_thread()
    
    - If we use only RCU, a forking task that has passed cgroup_post_fork()
      without seeing use_task_css_set_links == 1 is not guaranteed to have
      its child immediately visible in the tasklist if we walk through it
      remotely with RCU. In this case it will be missing in its css_set's
      task list.
    
    Thus we need to traverse the list (unfortunately) under the
    tasklist_lock. It makes us safe against while_each_thread() and also
    make sure we see all forked task that have been added to the tasklist.
    
    As a secondary effect, reading and writing use_task_css_set_links are
    now well ordered against tasklist traversing and modification. The new
    layout is:
    
    CPU 0                                      CPU 1
    
    use_task_css_set_links = 1                write_lock(tasklist_lock)
    read_lock(tasklist_lock)                  add task to tasklist
    do_each_thread() {                        write_unlock(tasklist_lock)
            add thread to css set links       if (use_task_css_set_links)
    } while_each_thread()                         add thread to css set links
    read_unlock(tasklist_lock)
    
    If CPU 0 traverse the list after the task has been added to the tasklist
    then it is correctly added to the css set links. OTOH if CPU 0 traverse
    the tasklist before the new task had the opportunity to be added to the
    tasklist because it was too early in the fork process, then CPU 1
    catches up and add the task to the css set links after it added the task
    to the tasklist. The right value of use_task_css_set_links is guaranteed
    to be visible from CPU 1 due to the LOCK/UNLOCK implicit barrier properties:
    the read_unlock on CPU 0 makes the write on use_task_css_set_links happening
    and the write_lock on CPU 1 make the read of use_task_css_set_links that comes
    afterward to return the correct value.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Cc: Mandeep Singh Baines <msb@chromium.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 1aa03f1188f7b0b85df2de602b33ee7b6fab8e00
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Wed Jan 11 17:25:17 2012 -0800

    rcu: Simplify unboosting checks
    
    This is a port of commit #82e78d80 from TREE_PREEMPT_RCU to
    TINY_PREEMPT_RCU.
    
    This commit uses the fact that current->rcu_boost_mutex is set
    any time that the RCU_READ_UNLOCK_BOOSTED flag is set in the
    current->rcu_read_unlock_special bitmask.  This allows tests of
    the bit to be changed to tests of the pointer, which in turn allows
    the RCU_READ_UNLOCK_BOOSTED flag to be eliminated.
    
    Please note that the check of current->rcu_read_unlock_special need not
    change because any time that RCU_READ_UNLOCK_BOOSTED was set, so was
    RCU_READ_UNLOCK_BLOCKED.  Therefore, __rcu_read_unlock() can continue
    testing current->rcu_read_unlock_special for non-zero, as before.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 8762705ad4ac860bb78434409df463d02ac8f027
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Wed Jan 11 16:59:01 2012 -0800

    rcu: Inform RCU of irq_exit() activity
    
    This is a port to TINY_RCU of Peter Zijlstra's commit #ec433f0c5
    
    The rcu_read_unlock_special() function relies on in_irq() to exclude
    scheduler activity from interrupt level.  This fails because exit_irq()
    can invoke the scheduler after clearing the preempt_count() bits that
    in_irq() uses to determine that it is at interrupt level.  This situation
    can result in failures as follows:
    
         $task                      IRQ             SoftIRQ
    
         rcu_read_lock()
    
         /* do stuff */
    
         <preempt> |= UNLOCK_BLOCKED
    
         rcu_read_unlock()
           --t->rcu_read_lock_nesting
    
                            irq_enter();
                            /* do stuff, don't use RCU */
                            irq_exit();
                              sub_preempt_count(IRQ_EXIT_OFFSET);
                              invoke_softirq()
    
                                            ttwu();
                                              spin_lock_irq(&pi->lock)
                                              rcu_read_lock();
                                              /* do stuff */
                                              rcu_read_unlock();
                                                rcu_read_unlock_special()
                                                  rcu_report_exp_rnp()
                                                    ttwu()
                                                      spin_lock_irq(&pi->lock) /* deadlock */
    
           rcu_read_unlock_special(t);
    
    This can be triggered 'easily' because invoke_softirq() immediately does
    a ttwu() of ksoftirqd/# instead of doing the in-place softirq stuff first,
    but even without that the above happens.
    
    Cure this by also excluding softirqs from the rcu_read_unlock_special()
    handler and ensuring the force_irqthreads ksoftirqd/# wakeup is done
    from full softirq context.
    
    It is also necessary to delay the ->rcu_read_lock_nesting decrement until
    after rcu_read_unlock_special().  This delay is handled by the commit
    "Protect __rcu_read_unlock() against scheduler-using irq handlers".
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit afef20540f7cd1ea91bc1ac20be238389eee4003
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Jan 11 15:30:36 2012 -0800

    rcu: Streamline code produced by __rcu_read_unlock()
    
    This is a port of commit #be0e1e21 to TINY_PREEMPT_RCU.  This uses
    noinline to prevent rcu_read_unlock_special() from being inlined into
    __rcu_read_unlock().
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 26861faf896a4cfdc4243281e5c305755f4bad52
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Wed Jan 11 14:40:20 2012 -0800

    rcu: Protect __rcu_read_unlock() against scheduler-using irq handlers
    
    This commit ports commit #10f39bb1b2 (rcu: protect __rcu_read_unlock()
    against scheduler-using irq handlers) from TREE_PREEMPT_RCU to
    TINY_PREEMPT_RCU.  The following is a corresponding port of that
    commit message.
    
    The addition of RCU read-side critical sections within runqueue and
    priority-inheritance critical sections introduced some deadlocks,
    for example, involving interrupts from __rcu_read_unlock() where the
    interrupt handlers call wake_up().  This situation can cause the
    instance of __rcu_read_unlock() invoked from interrupt to do some
    of the processing that would otherwise have been carried out by the
    task-level instance of __rcu_read_unlock().  When the interrupt-level
    instance of __rcu_read_unlock() is called with a scheduler lock held from
    interrupt-entry/exit situations where in_irq() returns false, deadlock can
    result.  Of course, in a UP kernel, there are not really any deadlocks,
    but the upper-level critical section can still be be fatally confused
    by the lower-level critical section changing things out from under it.
    
    This commit resolves these deadlocks by using negative values of the
    per-task ->rcu_read_lock_nesting counter to indicate that an instance of
    __rcu_read_unlock() is in flight, which in turn prevents instances from
    interrupt handlers from doing any special processing.  Note that nested
    rcu_read_lock()/rcu_read_unlock() pairs are still permitted, but they will
    never see ->rcu_read_lock_nesting go to zero, and will therefore never
    invoke rcu_read_unlock_special(), thus preventing them from seeing the
    RCU_READ_UNLOCK_BLOCKED bit should it be set in ->rcu_read_unlock_special.
    This patch also adds a check for ->rcu_read_unlock_special being negative
    in rcu_check_callbacks(), thus preventing the RCU_READ_UNLOCK_NEED_QS
    bit from being set should a scheduling-clock interrupt occur while
    __rcu_read_unlock() is exiting from an outermost RCU read-side critical
    section.
    
    Of course, __rcu_read_unlock() can be preempted during the time that
    ->rcu_read_lock_nesting is negative.  This could result in the setting
    of the RCU_READ_UNLOCK_BLOCKED bit after __rcu_read_unlock() checks it,
    and would also result it this task being queued on the corresponding
    rcu_node structure's blkd_tasks list.  Therefore, some later RCU read-side
    critical section would enter rcu_read_unlock_special() to clean up --
    which could result in deadlock (OK, OK, fatal confusion) if that RCU
    read-side critical section happened to be in the scheduler where the
    runqueue or priority-inheritance locks were held.
    
    To prevent the possibility of fatal confusion that might result from
    preemption during the time that ->rcu_read_lock_nesting is negative,
    this commit also makes rcu_preempt_note_context_switch() check for
    negative ->rcu_read_lock_nesting, thus refraining from queuing the task
    (and from setting RCU_READ_UNLOCK_BLOCKED) if we are already exiting
    from the outermost RCU read-side critical section (in other words,
    we really are no longer actually in that RCU read-side critical
    section).  In addition, rcu_preempt_note_context_switch() invokes
    rcu_read_unlock_special() to carry out the cleanup in this case, which
    clears out the ->rcu_read_unlock_special bits and dequeues the task
    (if necessary), in turn avoiding needless delay of the current RCU grace
    period and needless RCU priority boosting.
    
    It is still illegal to call rcu_read_unlock() while holding a scheduler
    lock if the prior RCU read-side critical section has ever had both
    preemption and irqs enabled.  However, the common use case is legal,
    namely where then entire RCU read-side critical section executes with
    irqs disabled, for example, when the scheduler lock is held across the
    entire lifetime of the RCU read-side critical section.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 46a7c17d26967922092f3a8291815ffb20f6cabe
Author: Sasha Levin <levinsasha928@gmail.com>
Date:   Wed Jan 25 22:16:16 2012 -0500

    [SCSI] iscsi: don't hang in endless loop if no targets present
    
    iscsi_if_send_reply() may return -ESRCH if there were no targets to send
    data to. Currently we're ignoring this value and looping in attempt to do it
    over and over, which will usually lead in a hung task like this one:
    
    [ 4920.817298] INFO: task trinity:9074 blocked for more than 120 seconds.
    [ 4920.818527] "echo 0 > /proc/sys/kernel/hung_task_timeout_secs" disables this message.
    [ 4920.819982] trinity         D 0000000000000000  5504  9074   2756 0x00000004
    [ 4920.825374]  ffff880003961a98 0000000000000086 ffff8800001aa000 ffff8800001aa000
    [ 4920.826791]  00000000001d4340 ffff880003961fd8 ffff880003960000 00000000001d4340
    [ 4920.828241]  00000000001d4340 00000000001d4340 ffff880003961fd8 00000000001d4340
    [ 4920.833231]
    [ 4920.833519] Call Trace:
    [ 4920.834010]  [<ffffffff826363fa>] schedule+0x3a/0x50
    [ 4920.834953]  [<ffffffff82634ac9>] __mutex_lock_common+0x209/0x5b0
    [ 4920.836226]  [<ffffffff81af805d>] ? iscsi_if_rx+0x2d/0x990
    [ 4920.837281]  [<ffffffff81053943>] ? sched_clock+0x13/0x20
    [ 4920.838305]  [<ffffffff81af805d>] ? iscsi_if_rx+0x2d/0x990
    [ 4920.839336]  [<ffffffff82634eb0>] mutex_lock_nested+0x40/0x50
    [ 4920.840423]  [<ffffffff81af805d>] iscsi_if_rx+0x2d/0x990
    [ 4920.841434]  [<ffffffff810dffed>] ? sub_preempt_count+0x9d/0xd0
    [ 4920.842548]  [<ffffffff82637bb0>] ? _raw_read_unlock+0x30/0x60
    [ 4920.843666]  [<ffffffff821f71de>] netlink_unicast+0x1ae/0x1f0
    [ 4920.844751]  [<ffffffff821f7997>] netlink_sendmsg+0x227/0x350
    [ 4920.845850]  [<ffffffff821857bd>] ? sock_update_netprioidx+0xdd/0x1b0
    [ 4920.847060]  [<ffffffff82185732>] ? sock_update_netprioidx+0x52/0x1b0
    [ 4920.848276]  [<ffffffff8217f226>] sock_aio_write+0x166/0x180
    [ 4920.849348]  [<ffffffff810dfe41>] ? get_parent_ip+0x11/0x50
    [ 4920.850428]  [<ffffffff811d0d9a>] do_sync_write+0xda/0x120
    [ 4920.851465]  [<ffffffff810dffed>] ? sub_preempt_count+0x9d/0xd0
    [ 4920.852579]  [<ffffffff810dfe41>] ? get_parent_ip+0x11/0x50
    [ 4920.853608]  [<ffffffff81791887>] ? security_file_permission+0x27/0xb0
    [ 4920.854821]  [<ffffffff811d0f4c>] vfs_write+0x16c/0x180
    [ 4920.855781]  [<ffffffff811d104f>] sys_write+0x4f/0xa0
    [ 4920.856798]  [<ffffffff82638e79>] system_call_fastpath+0x16/0x1b
    [ 4920.877487] 1 lock held by trinity/9074:
    [ 4920.878239]  #0:  (rx_queue_mutex){+.+...}, at: [<ffffffff81af805d>] iscsi_if_rx+0x2d/0x990
    [ 4920.880005] Kernel panic - not syncing: hung_task: blocked tasks
    
    Signed-off-by: Sasha Levin <levinsasha928@gmail.com>
    Acked-by: Mike Christie <michaelc@cs.wisc.edu>
    Signed-off-by: James Bottomley <JBottomley@Parallels.com>

commit 18d3e0d7507949d776e50667d0a4e44b13d3e1ac
Merge: 6d08f2c71397 f36ae342388e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Feb 1 15:18:39 2012 -0800

    Merge tag 'rdma-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband
    
    InfiniBand/RDMA fixes for 3.3:
    
     - Fix a crash due to a regression (uninitialized refcnt) introduced in
       3.2 with XRC support.
     - Close race in how ucma reports events when connect fails.
     - Process vendor-specific MADs in mlx4 so that eg FDR-10 data rate works.
     - Fix regression in qib caused by over-aggressive PCIe tuning.
     - Other small fixes for hardware drivers (ipath, nes, qib).
    
    * tag 'rdma-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/roland/infiniband:
      RDMA/nes: Copyright update
      IB/mlx4: pass SMP vendor-specific attribute MADs to firmware
      RDMA/nes: Fix fast memory registration opcode
      RDMA/nes: Fix fast memory registration length
      RDMA/ucma: Discard all events for new connections until accepted
      IB/qib: Roll back PCIe tuning change
      IB/qib: Use GFP_ATOMIC when locks are held
      RDMA/nes: Add missing rcu_read_unlock() in nes_addr_resolve_neigh()
      RDMA/nes: Fix for sending MPA reject frame
      IB/ipath: Calling PTR_ERR() on right variable in create_file()
      RDMA/core: Fix kernel panic by always initializing qp->usecnt

commit 7525c85be0e6d18596390e7e2b17a206cd9777f6
Author: Roland Dreier <roland@purestorage.com>
Date:   Fri Jan 27 09:54:30 2012 -0800

    RDMA/nes: Add missing rcu_read_unlock() in nes_addr_resolve_neigh()
    
    Make sure all exit paths from this function unlock everything.
    
    Reported-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Roland Dreier <roland@purestorage.com>

commit ac1e3d4f5c1097422c6e72aeae322033e9a8c803
Merge: eaed435a7b87 e4c89a508f43
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Jan 23 15:11:27 2012 -0800

    Merge tag 'pm-fixes-for-3.3' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm
    
    Power management fixes for 3.3
    
    Two fixes for regressions introduced during the merge window, one fix for
    a long-standing obscure issue in the computation of hibernate image size
    and two small PM documentation fixes.
    
    * tag 'pm-fixes-for-3.3' of git://git.kernel.org/pub/scm/linux/kernel/git/rafael/linux-pm:
      PM / Sleep: Fix read_unlock_usermodehelper() call.
      PM / Hibernate: Rewrite unlock_system_sleep() to fix s2disk regression
      PM / Hibernate: Correct additional pages number calculation
      PM / Documentation: Fix minor issue in freezing_of_tasks.txt
      PM / Documentation: Fix spelling mistake in basic-pm-debugging.txt

commit e4c89a508f4385a0cd8681c2749a2cd2fa476e40
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Mon Jan 23 21:59:08 2012 +0100

    PM / Sleep: Fix read_unlock_usermodehelper() call.
    
    Commit b298d289
     "PM / Sleep: Fix freezer failures due to racy usermodehelper_is_disabled()"
    added read_unlock_usermodehelper() but read_unlock_usermodehelper() is called
    without read_lock_usermodehelper() when kmalloc() failed.
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Acked-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

commit 6ac6172a935d1faf7ef259802267657bc0007a62
Author: Mimi Zohar <zohar@linux.vnet.ibm.com>
Date:   Tue Jan 17 20:40:02 2012 +0000

    encrypted-keys: fix rcu and sparse messages
    
    Enabling CONFIG_PROVE_RCU and CONFIG_SPARSE_RCU_POINTER resulted in
    "suspicious rcu_dereference_check() usage!" and "incompatible types
    in comparison expression (different address spaces)" messages.
    
    Access the masterkey directly when holding the rwsem.
    
    Changelog v1:
    - Use either rcu_read_lock()/rcu_derefence_key()/rcu_read_unlock()
    or remove the unnecessary rcu_derefence() - David Howells
    
    Reported-by: Dmitry Kasatkin <dmitry.kasatkin@intel.com>
    Signed-off-by: Mimi Zohar <zohar@us.ibm.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: James Morris <jmorris@namei.org>

commit 257058ae2b971646b96ab3a15605ac69186e562a
Author: Tejun Heo <tj@kernel.org>
Date:   Mon Dec 12 18:12:21 2011 -0800

    threadgroup: rename signal->threadgroup_fork_lock to ->group_rwsem
    
    Make the following renames to prepare for extension of threadgroup
    locking.
    
    * s/signal->threadgroup_fork_lock/signal->group_rwsem/
    * s/threadgroup_fork_read_lock()/threadgroup_change_begin()/
    * s/threadgroup_fork_read_unlock()/threadgroup_change_end()/
    * s/threadgroup_fork_write_lock()/threadgroup_lock()/
    * s/threadgroup_fork_write_unlock()/threadgroup_unlock()/
    
    This patch doesn't cause any behavior change.
    
    -v2: Rename threadgroup_change_done() to threadgroup_change_end() per
         KAMEZAWA's suggestion.
    
    Signed-off-by: Tejun Heo <tj@kernel.org>
    Reviewed-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Paul Menage <paul@paulmenage.org>

commit 101db7b41d8d6c070278bca1f7bce814ecbf781d
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Dec 5 15:36:31 2011 -0800

    rcu: Add rcutorture tests for srcu_read_lock_raw()
    
    This commit adds simple rcutorture tests for srcu_read_lock_raw() and
    srcu_read_unlock_raw().  It does not test doing srcu_read_lock_raw()
    in an exception handler and releasing it in the corresponding process
    context.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 3842a0832a1d6eb0b31421f8810a813135967512
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Nov 28 10:42:42 2011 -0800

    rcu: Document same-context read-side constraints
    
    The intent is that a given RCU read-side critical section be confined
    to a single context.  For example, it is illegal to invoke rcu_read_lock()
    in an exception handler and then invoke rcu_read_unlock() from the
    context of the task that received the exception.
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 9ceae0e248fb553c702d51d5275167d462f4efd2
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Nov 3 13:43:24 2011 -0700

    rcu: Add documentation for raw SRCU read-side primitives
    
    Update various files in Documentation/RCU to reflect srcu_read_lock_raw()
    and srcu_read_unlock_raw().  Credit to Peter Zijlstra for suggesting
    use of the existing _raw suffix instead of the earlier bulkref names.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 389abd48efe1ceacb141b2fd151263b1bc432dbc
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Wed Sep 21 14:41:37 2011 -0700

    rcu: Avoid RCU-preempt expedited grace-period botch
    
    Because rcu_read_unlock_special() samples rcu_preempted_readers_exp(rnp)
    after dropping rnp->lock, the following sequence of events is possible:
    
    1.      Task A exits its RCU read-side critical section, and removes
            itself from the ->blkd_tasks list, releases rnp->lock, and is
            then preempted.  Task B remains on the ->blkd_tasks list, and
            blocks the current expedited grace period.
    
    2.      Task B exits from its RCU read-side critical section and removes
            itself from the ->blkd_tasks list.  Because it is the last task
            blocking the current expedited grace period, it ends that
            expedited grace period.
    
    3.      Task A resumes, and samples rcu_preempted_readers_exp(rnp) which
            of course indicates that nothing is blocking the nonexistent
            expedited grace period. Task A is again preempted.
    
    4.      Some other CPU starts an expedited grace period.  There are several
            tasks blocking this expedited grace period queued on the
            same rcu_node structure that Task A was using in step 1 above.
    
    5.      Task A examines its state and incorrectly concludes that it was
            the last task blocking the expedited grace period on the current
            rcu_node structure.  It therefore reports completion up the
            rcu_node tree.
    
    6.      The expedited grace period can then incorrectly complete before
            the tasks blocked on this same rcu_node structure exit their
            RCU read-side critical sections.  Arbitrarily bad things happen.
    
    This commit therefore takes a snapshot of rcu_preempted_readers_exp(rnp)
    prior to dropping the lock, so that only the last task thinks that it is
    the last task, thus avoiding the failure scenario laid out above.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit f667de2e66ea9b8f99353ff01221bb355faf3f3c
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Nov 29 20:05:55 2011 +0000

    ipv4: fix lockdep splat in rt_cache_seq_show
    
    [ Upstream commit 218fa90f072e4aeff9003d57e390857f4f35513e ]
    
    After commit f2c31e32b378 (fix NULL dereferences in check_peer_redir()),
    dst_get_neighbour() should be guarded by rcu_read_lock() /
    rcu_read_unlock() section.
    
    Reported-by: Miles Lane <miles.lane@gmail.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 218fa90f072e4aeff9003d57e390857f4f35513e
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Nov 29 20:05:55 2011 +0000

    ipv4: fix lockdep splat in rt_cache_seq_show
    
    After commit f2c31e32b378 (fix NULL dereferences in check_peer_redir()),
    dst_get_neighbour() should be guarded by rcu_read_lock() /
    rcu_read_unlock() section.
    
    Reported-by: Miles Lane <miles.lane@gmail.com>
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ff7ee93f47151e23601856e7eb5510babf956571
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Wed Nov 2 13:38:11 2011 -0700

    cgroup/kmemleak: Annotate alloc_page() for cgroup allocations
    
    When the cgroup base was allocated with kmalloc, it was necessary to
    annotate the variable with kmemleak_not_leak().  But because it has
    recently been changed to be allocated with alloc_page() (which skips
    kmemleak checks) causes a warning on boot up.
    
    I was triggering this output:
    
     allocated 8388608 bytes of page_cgroup
     please try 'cgroup_disable=memory' option if you don't want memory cgroups
     kmemleak: Trying to color unknown object at 0xf5840000 as Grey
     Pid: 0, comm: swapper Not tainted 3.0.0-test #12
     Call Trace:
      [<c17e34e6>] ? printk+0x1d/0x1f^M
      [<c10e2941>] paint_ptr+0x4f/0x78
      [<c178ab57>] kmemleak_not_leak+0x58/0x7d
      [<c108ae9f>] ? __rcu_read_unlock+0x9/0x7d
      [<c1cdb462>] kmemleak_init+0x19d/0x1e9
      [<c1cbf771>] start_kernel+0x346/0x3ec
      [<c1cbf1b4>] ? loglevel+0x18/0x18
      [<c1cbf0aa>] i386_start_kernel+0xaa/0xb0
    
    After a bit of debugging I tracked the object 0xf840000 (and others) down
    to the cgroup code.  The change from allocating base with kmalloc to
    alloc_page() has the base not calling kmemleak_alloc() which adds the
    pointer to the object_tree_root, but kmemleak_not_leak() adds it to the
    crt_early_log[] table.  On kmemleak_init(), the entry is found in the
    early_log[] but not the object_tree_root, and this error message is
    displayed.
    
    If alloc_page() fails then it defaults back to vmalloc() which still uses
    the kmemleak_alloc() which makes us still need the kmemleak_not_leak()
    call.  The solution is to call the kmemleak_alloc() directly if the
    alloc_page() succeeds.
    
    Reviewed-by: Michal Hocko <mhocko@suse.cz>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Acked-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Jonathan Nieder <jrnieder@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 19b4a8d520a6e0176dd52aaa429261ad4fcaa545
Merge: 3cfef9524677 048b71802903
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 26 16:26:53 2011 +0200

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (45 commits)
      rcu: Move propagation of ->completed from rcu_start_gp() to rcu_report_qs_rsp()
      rcu: Remove rcu_needs_cpu_flush() to avoid false quiescent states
      rcu: Wire up RCU_BOOST_PRIO for rcutree
      rcu: Make rcu_torture_boost() exit loops at end of test
      rcu: Make rcu_torture_fqs() exit loops at end of test
      rcu: Permit rt_mutex_unlock() with irqs disabled
      rcu: Avoid having just-onlined CPU resched itself when RCU is idle
      rcu: Suppress NMI backtraces when stall ends before dump
      rcu: Prohibit grace periods during early boot
      rcu: Simplify unboosting checks
      rcu: Prevent early boot set_need_resched() from __rcu_pending()
      rcu: Dump local stack if cannot dump all CPUs' stacks
      rcu: Move __rcu_read_unlock()'s barrier() within if-statement
      rcu: Improve rcu_assign_pointer() and RCU_INIT_POINTER() documentation
      rcu: Make rcu_assign_pointer() unconditionally insert a memory barrier
      rcu: Make rcu_implicit_dynticks_qs() locals be correct size
      rcu: Eliminate in_irq() checks in rcu_enter_nohz()
      nohz: Remove nohz_cpu_mask
      rcu: Document interpretation of RCU-lockdep splats
      rcu: Allow rcutorture's stat_interval parameter to be changed at runtime
      ...

commit 3cfef9524677a4ecb392d6fbffe6ebce6302f1d4
Merge: 982653009b88 68cc3990a545
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Oct 26 16:17:32 2011 +0200

    Merge branch 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'core-locking-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip: (27 commits)
      rtmutex: Add missing rcu_read_unlock() in debug_rt_mutex_print_deadlock()
      lockdep: Comment all warnings
      lib: atomic64: Change the type of local lock to raw_spinlock_t
      locking, lib/atomic64: Annotate atomic64_lock::lock as raw
      locking, x86, iommu: Annotate qi->q_lock as raw
      locking, x86, iommu: Annotate irq_2_ir_lock as raw
      locking, x86, iommu: Annotate iommu->register_lock as raw
      locking, dma, ipu: Annotate bank_lock as raw
      locking, ARM: Annotate low level hw locks as raw
      locking, drivers/dca: Annotate dca_lock as raw
      locking, powerpc: Annotate uic->lock as raw
      locking, x86: mce: Annotate cmci_discover_lock as raw
      locking, ACPI: Annotate c3_lock as raw
      locking, oprofile: Annotate oprofilefs lock as raw
      locking, video: Annotate vga console lock as raw
      locking, latencytop: Annotate latency_lock as raw
      locking, timer_stats: Annotate table_lock as raw
      locking, rwsem: Annotate inner lock as raw
      locking, semaphores: Annotate inner lock as raw
      locking, sched: Annotate thread_group_cputimer as raw
      ...
    
    Fix up conflicts in kernel/posix-cpu-timers.c manually: making
    cputimer->cputime a raw lock conflicted with the ABBA fix in commit
    bcd5cff7216f ("cputimer: Cure lock inversion").

commit 1f1503ba096d3a394d1454dac77467092ca996e6
Author: Daniel De Graaf <dgdegra@tycho.nsa.gov>
Date:   Tue Oct 11 15:16:06 2011 -0400

    xen/gntdev: Fix sleep-inside-spinlock
    
    BUG: sleeping function called from invalid context at /local/scratch/dariof/linux/kernel/mutex.c:271
    in_atomic(): 1, irqs_disabled(): 0, pid: 3256, name: qemu-dm
    1 lock held by qemu-dm/3256:
     #0:  (&(&priv->lock)->rlock){......}, at: [<ffffffff813223da>] gntdev_ioctl+0x2bd/0x4d5
    Pid: 3256, comm: qemu-dm Tainted: G        W   3.1.0-rc8+ #5
    Call Trace:
     [<ffffffff81054594>] __might_sleep+0x131/0x135
     [<ffffffff816bd64f>] mutex_lock_nested+0x25/0x45
     [<ffffffff8131c7c8>] free_xenballooned_pages+0x20/0xb1
     [<ffffffff8132194d>] gntdev_put_map+0xa8/0xdb
     [<ffffffff816be546>] ? _raw_spin_lock+0x71/0x7a
     [<ffffffff813223da>] ? gntdev_ioctl+0x2bd/0x4d5
     [<ffffffff8132243c>] gntdev_ioctl+0x31f/0x4d5
     [<ffffffff81007d62>] ? check_events+0x12/0x20
     [<ffffffff811433bc>] do_vfs_ioctl+0x488/0x4d7
     [<ffffffff81007d4f>] ? xen_restore_fl_direct_reloc+0x4/0x4
     [<ffffffff8109168b>] ? lock_release+0x21c/0x229
     [<ffffffff81135cdd>] ? rcu_read_unlock+0x21/0x32
     [<ffffffff81143452>] sys_ioctl+0x47/0x6a
     [<ffffffff816bfd82>] system_call_fastpath+0x16/0x1b
    
    gntdev_put_map tries to acquire a mutex when freeing pages back to the
    xenballoon pool, so it cannot be called with a spinlock held. In
    gntdev_release, the spinlock is not needed as we are freeing the
    structure later; in the ioctl, only the list manipulation needs to be
    under the lock.
    
    Reported-and-Tested-By: Dario Faggioli <dario.faggioli@citrix.com>
    Signed-off-by: Daniel De Graaf <dgdegra@tycho.nsa.gov>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

commit 68cc3990a545dc0da221b4844dd8b9c06623a6c5
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Wed Oct 5 13:20:24 2011 +0200

    rtmutex: Add missing rcu_read_unlock() in debug_rt_mutex_print_deadlock()
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 82e78d80fc392ac7e98326bc8beeb8a679913ffd
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Thu Aug 4 07:55:34 2011 -0700

    rcu: Simplify unboosting checks
    
    Commit 7765be (Fix RCU_BOOST race handling current->rcu_read_unlock_special)
    introduced a new ->rcu_boosted field in the task structure.  This is
    redundant because the existing ->rcu_boost_mutex will be non-NULL at
    any time that ->rcu_boosted is nonzero.  Therefore, this commit removes
    ->rcu_boosted and tests ->rcu_boost_mutex instead.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 6206ab9bab620fc0fbbed30ce20d145b0b3d1840
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Mon Aug 1 06:22:11 2011 -0700

    rcu: Move __rcu_read_unlock()'s barrier() within if-statement
    
    We only need to constrain the compiler if we are actually exiting
    the top-level RCU read-side critical section.  This commit therefore
    moves the first barrier() cal in __rcu_read_unlock() to inside the
    "if" statement, thus avoiding needless register flushes for inner
    rcu_read_unlock() calls.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit cf6ace16a3cd8b728fb0afa68368fd40bbeae19f
Merge: acc11eab7059 d1e9ae47a028
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Jul 20 15:56:25 2011 -0700

    Merge branch 'core-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      signal: align __lock_task_sighand() irq disabling and RCU
      softirq,rcu: Inform RCU of irq_exit() activity
      sched: Add irq_{enter,exit}() to scheduler_ipi()
      rcu: protect __rcu_read_unlock() against scheduler-using irq handlers
      rcu: Streamline code produced by __rcu_read_unlock()
      rcu: Fix RCU_BOOST race handling current->rcu_read_unlock_special
      rcu: decrease rcu_report_exp_rnp coupling with scheduler

commit a841796f11c90d53dbac773be56b04fbee8af272
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Tue Jul 19 03:25:36 2011 -0700

    signal: align __lock_task_sighand() irq disabling and RCU
    
    The __lock_task_sighand() function calls rcu_read_lock() with interrupts
    and preemption enabled, but later calls rcu_read_unlock() with interrupts
    disabled.  It is therefore possible that this RCU read-side critical
    section will be preempted and later RCU priority boosted, which means that
    rcu_read_unlock() will call rt_mutex_unlock() in order to deboost itself, but
    with interrupts disabled. This results in lockdep splats, so this commit
    nests the RCU read-side critical section within the interrupt-disabled
    region of code.  This prevents the RCU read-side critical section from
    being preempted, and thus prevents the attempt to deboost with interrupts
    disabled.
    
    It is quite possible that a better long-term fix is to make rt_mutex_unlock()
    disable irqs when acquiring the rt_mutex structure's ->wait_lock.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit ec433f0c51527426989ea8a38a856d810d739414
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Tue Jul 19 15:32:00 2011 -0700

    softirq,rcu: Inform RCU of irq_exit() activity
    
    The rcu_read_unlock_special() function relies on in_irq() to exclude
    scheduler activity from interrupt level.  This fails because exit_irq()
    can invoke the scheduler after clearing the preempt_count() bits that
    in_irq() uses to determine that it is at interrupt level.  This situation
    can result in failures as follows:
    
     $task                  IRQ             SoftIRQ
    
     rcu_read_lock()
    
     /* do stuff */
    
     <preempt> |= UNLOCK_BLOCKED
    
     rcu_read_unlock()
       --t->rcu_read_lock_nesting
    
                            irq_enter();
                            /* do stuff, don't use RCU */
                            irq_exit();
                              sub_preempt_count(IRQ_EXIT_OFFSET);
                              invoke_softirq()
    
                                            ttwu();
                                              spin_lock_irq(&pi->lock)
                                              rcu_read_lock();
                                              /* do stuff */
                                              rcu_read_unlock();
                                                rcu_read_unlock_special()
                                                  rcu_report_exp_rnp()
                                                    ttwu()
                                                      spin_lock_irq(&pi->lock) /* deadlock */
    
       rcu_read_unlock_special(t);
    
    Ed can simply trigger this 'easy' because invoke_softirq() immediately
    does a ttwu() of ksoftirqd/# instead of doing the in-place softirq stuff
    first, but even without that the above happens.
    
    Cure this by also excluding softirqs from the
    rcu_read_unlock_special() handler and ensuring the force_irqthreads
    ksoftirqd/# wakeup is done from full softirq context.
    
    [ Alternatively, delaying the ->rcu_read_lock_nesting decrement
      until after the special handling would make the thing more robust
      in the face of interrupts as well.  And there is a separate patch
      for that. ]
    
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Reported-and-tested-by: Ed Tomlinson <edt@aei.ca>
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 10f39bb1b2c1923ca73e70cb13aeee0e9b822d8f
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Sun Jul 17 21:14:35 2011 -0700

    rcu: protect __rcu_read_unlock() against scheduler-using irq handlers
    
    The addition of RCU read-side critical sections within runqueue and
    priority-inheritance lock critical sections introduced some deadlock
    cycles, for example, involving interrupts from __rcu_read_unlock()
    where the interrupt handlers call wake_up().  This situation can cause
    the instance of __rcu_read_unlock() invoked from interrupt to do some
    of the processing that would otherwise have been carried out by the
    task-level instance of __rcu_read_unlock().  When the interrupt-level
    instance of __rcu_read_unlock() is called with a scheduler lock held
    from interrupt-entry/exit situations where in_irq() returns false,
    deadlock can result.
    
    This commit resolves these deadlocks by using negative values of
    the per-task ->rcu_read_lock_nesting counter to indicate that an
    instance of __rcu_read_unlock() is in flight, which in turn prevents
    instances from interrupt handlers from doing any special processing.
    This patch is inspired by Steven Rostedt's earlier patch that similarly
    made __rcu_read_unlock() guard against interrupt-mediated recursion
    (see https://lkml.org/lkml/2011/7/15/326), but this commit refines
    Steven's approach to avoid the need for preemption disabling on the
    __rcu_read_unlock() fastpath and to also avoid the need for manipulating
    a separate per-CPU variable.
    
    This patch avoids need for preempt_disable() by instead using negative
    values of the per-task ->rcu_read_lock_nesting counter.  Note that nested
    rcu_read_lock()/rcu_read_unlock() pairs are still permitted, but they will
    never see ->rcu_read_lock_nesting go to zero, and will therefore never
    invoke rcu_read_unlock_special(), thus preventing them from seeing the
    RCU_READ_UNLOCK_BLOCKED bit should it be set in ->rcu_read_unlock_special.
    This patch also adds a check for ->rcu_read_unlock_special being negative
    in rcu_check_callbacks(), thus preventing the RCU_READ_UNLOCK_NEED_QS
    bit from being set should a scheduling-clock interrupt occur while
    __rcu_read_unlock() is exiting from an outermost RCU read-side critical
    section.
    
    Of course, __rcu_read_unlock() can be preempted during the time that
    ->rcu_read_lock_nesting is negative.  This could result in the setting
    of the RCU_READ_UNLOCK_BLOCKED bit after __rcu_read_unlock() checks it,
    and would also result it this task being queued on the corresponding
    rcu_node structure's blkd_tasks list.  Therefore, some later RCU read-side
    critical section would enter rcu_read_unlock_special() to clean up --
    which could result in deadlock if that critical section happened to be in
    the scheduler where the runqueue or priority-inheritance locks were held.
    
    This situation is dealt with by making rcu_preempt_note_context_switch()
    check for negative ->rcu_read_lock_nesting, thus refraining from
    queuing the task (and from setting RCU_READ_UNLOCK_BLOCKED) if we are
    already exiting from the outermost RCU read-side critical section (in
    other words, we really are no longer actually in that RCU read-side
    critical section).  In addition, rcu_preempt_note_context_switch()
    invokes rcu_read_unlock_special() to carry out the cleanup in this case,
    which clears out the ->rcu_read_unlock_special bits and dequeues the task
    (if necessary), in turn avoiding needless delay of the current RCU grace
    period and needless RCU priority boosting.
    
    It is still illegal to call rcu_read_unlock() while holding a scheduler
    lock if the prior RCU read-side critical section has ever had either
    preemption or irqs enabled.  However, the common use case is legal,
    namely where then entire RCU read-side critical section executes with
    irqs disabled, for example, when the scheduler lock is held across the
    entire lifetime of the RCU read-side critical section.
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit be0e1e21ef707be4d16ea6a96ac9997463e4b8d2
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sat May 21 05:57:18 2011 -0700

    rcu: Streamline code produced by __rcu_read_unlock()
    
    Given some common flag combinations, particularly -Os, gcc will inline
    rcu_read_unlock_special() despite its being in an unlikely() clause.
    Use noinline to prohibit this misoptimization.
    
    In addition, move the second barrier() in __rcu_read_unlock() so that
    it is not on the common-case code path.  This will allow the compiler to
    generate better code for the common-case path through __rcu_read_unlock().
    
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>

commit 7765be2fec0f476fcd61812d5f9406b04c765020
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Thu Jul 14 12:24:11 2011 -0700

    rcu: Fix RCU_BOOST race handling current->rcu_read_unlock_special
    
    The RCU_BOOST commits for TREE_PREEMPT_RCU introduced an other-task
    write to a new RCU_READ_UNLOCK_BOOSTED bit in the task_struct structure's
    ->rcu_read_unlock_special field, but, as noted by Steven Rostedt, without
    correctly synchronizing all accesses to ->rcu_read_unlock_special.
    This could result in bits in ->rcu_read_unlock_special being spuriously
    set and cleared due to conflicting accesses, which in turn could result
    in deadlocks between the rcu_node structure's ->lock and the scheduler's
    rq and pi locks.  These deadlocks would result from RCU incorrectly
    believing that the just-ended RCU read-side critical section had been
    preempted and/or boosted.  If that RCU read-side critical section was
    executed with either rq or pi locks held, RCU's ensuing (incorrect)
    calls to the scheduler would cause the scheduler to attempt to once
    again acquire the rq and pi locks, resulting in deadlock.  More complex
    deadlock cycles are also possible, involving multiple rq and pi locks
    as well as locks from multiple rcu_node structures.
    
    This commit fixes synchronization by creating ->rcu_boosted field in
    task_struct that is accessed and modified only when holding the ->lock
    in the rcu_node structure on which the task is queued (on that rcu_node
    structure's ->blkd_tasks list).  This results in tasks accessing only
    their own current->rcu_read_unlock_special fields, making unsynchronized
    access once again legal, and keeping the rcu_read_unlock() fastpath free
    of atomic instructions and memory barriers.
    
    The reason that the rcu_read_unlock() fastpath does not need to access
    the new current->rcu_boosted field is that this new field cannot
    be non-zero unless the RCU_READ_UNLOCK_BLOCKED bit is set in the
    current->rcu_read_unlock_special field.  Therefore, rcu_read_unlock()
    need only test current->rcu_read_unlock_special: if that is zero, then
    current->rcu_boosted must also be zero.
    
    This bug does not affect TINY_PREEMPT_RCU because this implementation
    of RCU accesses current->rcu_read_unlock_special with irqs disabled,
    thus preventing races on the !SMP systems that TINY_PREEMPT_RCU runs on.
    
    Maybe-reported-by: Dave Jones <davej@redhat.com>
    Maybe-reported-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Reported-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Steven Rostedt <rostedt@goodmis.org>

commit 8aded7110a5625bc00aef05e94dd4b1a9cf3605f
Author: Andre Guedes <andre.guedes@openbossa.org>
Date:   Thu Jul 7 10:30:35 2011 -0300

    Bluetooth: Fix potential deadlock in hci_core
    
    Since hdev->lock may be acquired by threads runnning in interrupt
    context, all threads running in process context should disable
    local bottom halve before locking hdev->lock. This can be done by
    using hci_dev_lock_bh macro.
    
    This way, we avoid potencial deadlocks like this one reported by
    CONFIG_PROVE_LOCKING=y.
    
    [  304.788780] =================================
    [  304.789686] [ INFO: inconsistent lock state ]
    [  304.789686] 2.6.39+ #1
    [  304.789686] ---------------------------------
    [  304.789686] inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
    [  304.789686] ksoftirqd/0/3 [HC0[0]:SC1[1]:HE1:SE0] takes:
    [  304.789686]  (&(&hdev->lock)->rlock){+.?...}, at: [<ffffffffa000bbfe>] hci_conn_check_pending+0x38/0x76 [bluetooth]
    [  304.789686] {SOFTIRQ-ON-W} state was registered at:
    [  304.789686]   [<ffffffff8105188b>] __lock_acquire+0x347/0xd52
    [  304.789686]   [<ffffffff810526ac>] lock_acquire+0x8a/0xa7
    [  304.789686]   [<ffffffff812b3758>] _raw_spin_lock+0x2c/0x3b
    [  304.789686]   [<ffffffffa0009cf0>] hci_blacklist_del+0x1f/0x8a [bluetooth]
    [  304.789686]   [<ffffffffa00139fd>] hci_sock_ioctl+0x2d9/0x314 [bluetooth]
    [  304.789686]   [<ffffffff812197d8>] sock_ioctl+0x1f2/0x214
    [  304.789686]   [<ffffffff810b0fd6>] do_vfs_ioctl+0x46c/0x4ad
    [  304.789686]   [<ffffffff810b1059>] sys_ioctl+0x42/0x65
    [  304.789686]   [<ffffffff812b4892>] system_call_fastpath+0x16/0x1b
    [  304.789686] irq event stamp: 9768
    [  304.789686] hardirqs last  enabled at (9768): [<ffffffff812b40d4>] restore_args+0x0/0x30
    [  304.789686] hardirqs last disabled at (9767): [<ffffffff812b3f6a>] save_args+0x6a/0x70
    [  304.789686] softirqs last  enabled at (9726): [<ffffffff8102fa9b>] __do_softirq+0x129/0x13f
    [  304.789686] softirqs last disabled at (9739): [<ffffffff8102fb33>] run_ksoftirqd+0x82/0x133
    [  304.789686]
    [  304.789686] other info that might help us debug this:
    [  304.789686]  Possible unsafe locking scenario:
    [  304.789686]
    [  304.789686]        CPU0
    [  304.789686]        ----
    [  304.789686]   lock(&(&hdev->lock)->rlock);
    [  304.789686]   <Interrupt>
    [  304.789686]     lock(&(&hdev->lock)->rlock);
    [  304.789686]
    [  304.789686]  *** DEADLOCK ***
    [  304.789686]
    [  304.789686] 1 lock held by ksoftirqd/0/3:
    [  304.789686]  #0:  (hci_task_lock){++.-..}, at: [<ffffffffa0008353>] hci_rx_task+0x49/0x2f3 [bluetooth]
    [  304.789686]
    [  304.789686] stack backtrace:
    [  304.789686] Pid: 3, comm: ksoftirqd/0 Not tainted 2.6.39+ #1
    [  304.789686] Call Trace:
    [  304.789686]  [<ffffffff812ae901>] print_usage_bug+0x1e7/0x1f8
    [  304.789686]  [<ffffffff8100a796>] ? save_stack_trace+0x27/0x44
    [  304.789686]  [<ffffffff8104fc3f>] ? print_irq_inversion_bug.part.26+0x19a/0x19a
    [  304.789686]  [<ffffffff810504bb>] mark_lock+0x106/0x258
    [  304.789686]  [<ffffffff812b40d4>] ? retint_restore_args+0x13/0x13
    [  304.789686]  [<ffffffff81051817>] __lock_acquire+0x2d3/0xd52
    [  304.789686]  [<ffffffff8102be73>] ? vprintk+0x3ab/0x3d7
    [  304.789686]  [<ffffffff812ae126>] ? printk+0x3c/0x3e
    [  304.789686]  [<ffffffff810526ac>] lock_acquire+0x8a/0xa7
    [  304.789686]  [<ffffffffa000bbfe>] ? hci_conn_check_pending+0x38/0x76 [bluetooth]
    [  304.789686]  [<ffffffff811601c6>] ? __dynamic_pr_debug+0x10c/0x11a
    [  304.789686]  [<ffffffff812b3758>] _raw_spin_lock+0x2c/0x3b
    [  304.789686]  [<ffffffffa000bbfe>] ? hci_conn_check_pending+0x38/0x76 [bluetooth]
    [  304.789686]  [<ffffffffa000bbfe>] hci_conn_check_pending+0x38/0x76 [bluetooth]
    [  304.789686]  [<ffffffffa000c561>] hci_event_packet+0x38e/0x3e12 [bluetooth]
    [  304.789686]  [<ffffffff81052615>] ? lock_release+0x16c/0x179
    [  304.789686]  [<ffffffff812b3b41>] ? _raw_read_unlock+0x23/0x27
    [  304.789686]  [<ffffffffa0013e7f>] ? hci_send_to_sock+0x179/0x188 [bluetooth]
    [  304.789686]  [<ffffffffa00083d2>] hci_rx_task+0xc8/0x2f3 [bluetooth]
    [  304.789686]  [<ffffffff8102f5a9>] tasklet_action+0x87/0xe6
    [  304.789686]  [<ffffffff8102fa11>] __do_softirq+0x9f/0x13f
    [  304.789686]  [<ffffffff8102fb33>] run_ksoftirqd+0x82/0x133
    [  304.789686]  [<ffffffff8102fab1>] ? __do_softirq+0x13f/0x13f
    [  304.789686]  [<ffffffff81040f0a>] kthread+0x7f/0x87
    [  304.789686]  [<ffffffff812b55c4>] kernel_thread_helper+0x4/0x10
    [  304.789686]  [<ffffffff812b40d4>] ? retint_restore_args+0x13/0x13
    [  304.789686]  [<ffffffff81040e8b>] ? __init_kthread_worker+0x53/0x53
    [  304.789686]  [<ffffffff812b55c0>] ? gs_change+0x13/0x13
    
    Signed-off-by: Andre Guedes <andre.guedes@openbossa.org>
    Signed-off-by: Gustavo F. Padovan <padovan@profusion.mobi>

commit 803caa34f9b51f4f0e513bc9a216f738af7bb488
Author: David Howells <dhowells@redhat.com>
Date:   Thu Jul 29 12:45:49 2010 +0100

    CRED: Fix get_task_cred() and task_state() to not resurrect dead credentials
    
    commit de09a9771a5346029f4d11e4ac886be7f9bfdd75 upstream.
    
    It's possible for get_task_cred() as it currently stands to 'corrupt' a set of
    credentials by incrementing their usage count after their replacement by the
    task being accessed.
    
    What happens is that get_task_cred() can race with commit_creds():
    
            TASK_1                  TASK_2                  RCU_CLEANER
            -->get_task_cred(TASK_2)
            rcu_read_lock()
            __cred = __task_cred(TASK_2)
                                    -->commit_creds()
                                    old_cred = TASK_2->real_cred
                                    TASK_2->real_cred = ...
                                    put_cred(old_cred)
                                      call_rcu(old_cred)
                    [__cred->usage == 0]
            get_cred(__cred)
                    [__cred->usage == 1]
            rcu_read_unlock()
                                                            -->put_cred_rcu()
                                                            [__cred->usage == 1]
                                                            panic()
    
    However, since a tasks credentials are generally not changed very often, we can
    reasonably make use of a loop involving reading the creds pointer and using
    atomic_inc_not_zero() to attempt to increment it if it hasn't already hit zero.
    
    If successful, we can safely return the credentials in the knowledge that, even
    if the task we're accessing has released them, they haven't gone to the RCU
    cleanup code.
    
    We then change task_state() in procfs to use get_task_cred() rather than
    calling get_cred() on the result of __task_cred(), as that suffers from the
    same problem.
    
    Without this change, a BUG_ON in __put_cred() or in put_cred_rcu() can be
    tripped when it is noticed that the usage count is not zero as it ought to be,
    for example:
    
    kernel BUG at kernel/cred.c:168!
    invalid opcode: 0000 [#1] SMP
    last sysfs file: /sys/kernel/mm/ksm/run
    CPU 0
    Pid: 2436, comm: master Not tainted 2.6.33.3-85.fc13.x86_64 #1 0HR330/OptiPlex
    745
    RIP: 0010:[<ffffffff81069881>]  [<ffffffff81069881>] __put_cred+0xc/0x45
    RSP: 0018:ffff88019e7e9eb8  EFLAGS: 00010202
    RAX: 0000000000000001 RBX: ffff880161514480 RCX: 00000000ffffffff
    RDX: 00000000ffffffff RSI: ffff880140c690c0 RDI: ffff880140c690c0
    RBP: ffff88019e7e9eb8 R08: 00000000000000d0 R09: 0000000000000000
    R10: 0000000000000001 R11: 0000000000000040 R12: ffff880140c690c0
    R13: ffff88019e77aea0 R14: 00007fff336b0a5c R15: 0000000000000001
    FS:  00007f12f50d97c0(0000) GS:ffff880007400000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f8f461bc000 CR3: 00000001b26ce000 CR4: 00000000000006f0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process master (pid: 2436, threadinfo ffff88019e7e8000, task ffff88019e77aea0)
    Stack:
     ffff88019e7e9ec8 ffffffff810698cd ffff88019e7e9ef8 ffffffff81069b45
    <0> ffff880161514180 ffff880161514480 ffff880161514180 0000000000000000
    <0> ffff88019e7e9f28 ffffffff8106aace 0000000000000001 0000000000000246
    Call Trace:
     [<ffffffff810698cd>] put_cred+0x13/0x15
     [<ffffffff81069b45>] commit_creds+0x16b/0x175
     [<ffffffff8106aace>] set_current_groups+0x47/0x4e
     [<ffffffff8106ac89>] sys_setgroups+0xf6/0x105
     [<ffffffff81009b02>] system_call_fastpath+0x16/0x1b
    Code: 48 8d 71 ff e8 7e 4e 15 00 85 c0 78 0b 8b 75 ec 48 89 df e8 ef 4a 15 00
    48 83 c4 18 5b c9 c3 55 8b 07 8b 07 48 89 e5 85 c0 74 04 <0f> 0b eb fe 65 48 8b
    04 25 00 cc 00 00 48 3b b8 58 04 00 00 75
    RIP  [<ffffffff81069881>] __put_cred+0xc/0x45
     RSP <ffff88019e7e9eb8>
    ---[ end trace df391256a100ebdd ]---
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

commit 199abfab40389963b397c2982222e68ea782b2cf
Author: Jiri Olsa <jolsa@redhat.com>
Date:   Fri Jun 3 16:58:50 2011 +0200

    tracing, function_graph: Remove lock-depth from latency trace
    
    The lock_depth was removed in commit
    e6e1e25 tracing: Remove lock_depth from event entry
    
    Removing the lock_depth info from function_graph latency header.
    
    With following commands:
            # echo function_graph > ./current_tracer
            # echo 1 > options/latency-format
            # cat trace
    
    This is what it looked like before:
    # tracer: function_graph
    #
    # function_graph latency trace v1.1.5 on 3.0.0-rc1-tip+
    # --------------------------------------------------------------------
    # latency: 0 us, #59756/311298, CPU#0 | (M:preempt VP:0, KP:0, SP:0 HP:0 #P:2)
    #    -----------------
    #    | task: -0 (uid:0 nice:0 policy:0 rt_prio:0)
    #    -----------------
    #
    #      _-----=> irqs-off
    #     / _----=> need-resched
    #    | / _---=> hardirq/softirq
    #    || / _--=> preempt-depth
    #    ||| / _-=> lock-depth
    #    |||| /
    # CPU|||||  DURATION                  FUNCTION CALLS
    # |  |||||   |   |                     |   |   |   |
     0)  ....  0.068 us    |    } /* __rcu_read_unlock */
    ...
    
    This is what it looks like now:
    # tracer: function_graph
    #
    # function_graph latency trace v1.1.5 on 3.0.0-rc1-tip+
    # --------------------------------------------------------------------
    # latency: 0 us, #59747/1744610, CPU#0 | (M:preempt VP:0, KP:0, SP:0 HP:0 #P:2)
    #    -----------------
    #    | task: -0 (uid:0 nice:0 policy:0 rt_prio:0)
    #    -----------------
    #
    #      _-----=> irqs-off
    #     / _----=> need-resched
    #    | / _---=> hardirq/softirq
    #    || / _--=> preempt-depth
    #    ||| /
    # CPU||||  DURATION                  FUNCTION CALLS
    # |  ||||   |   |                     |   |   |   |
     0)  ..s.  1.641 us    |  } /* __rcu_process_callbacks */
    ...
    
    Signed-off-by: Jiri Olsa <jolsa@redhat.com>
    Link: http://lkml.kernel.org/r/1307113131-10045-5-git-send-email-jolsa@redhat.com
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

commit a7567b2059020bf3fa96c389ec25eed8e28ad4ba
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Wed Jun 1 08:29:54 2011 +0200

    bluetooth l2cap: fix locking in l2cap_global_chan_by_psm
    
    read_lock() ... read_unlock_bh() is clearly bogus.
    This was broken by
    
    commit 23691d75cdc69c3b285211b4d77746aa20a17d18
    Author: Gustavo F. Padovan <padovan@profusion.mobi>
    Date:   Wed Apr 27 18:26:32 2011 -0300
    
        Bluetooth: Remove l2cap_sk_list
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 8826f3b0397562eee6f8785d548be9dfdb169100
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Wed May 11 05:41:41 2011 -0700

    rcu: Avoid acquiring rcu_node locks in timer functions
    
    This commit switches manipulations of the rcu_node ->wakemask field
    to atomic operations, which allows rcu_cpu_kthread_timer() to avoid
    acquiring the rcu_node lock.  This should avoid the following lockdep
    splat reported by Valdis Kletnieks:
    
    [   12.872150] usb 1-4: new high speed USB device number 3 using ehci_hcd
    [   12.986667] usb 1-4: New USB device found, idVendor=413c, idProduct=2513
    [   12.986679] usb 1-4: New USB device strings: Mfr=0, Product=0, SerialNumber=0
    [   12.987691] hub 1-4:1.0: USB hub found
    [   12.987877] hub 1-4:1.0: 3 ports detected
    [   12.996372] input: PS/2 Generic Mouse as /devices/platform/i8042/serio1/input/input10
    [   13.071471] udevadm used greatest stack depth: 3984 bytes left
    [   13.172129]
    [   13.172130] =======================================================
    [   13.172425] [ INFO: possible circular locking dependency detected ]
    [   13.172650] 2.6.39-rc6-mmotm0506 #1
    [   13.172773] -------------------------------------------------------
    [   13.172997] blkid/267 is trying to acquire lock:
    [   13.173009]  (&p->pi_lock){-.-.-.}, at: [<ffffffff81032d8f>] try_to_wake_up+0x29/0x1aa
    [   13.173009]
    [   13.173009] but task is already holding lock:
    [   13.173009]  (rcu_node_level_0){..-...}, at: [<ffffffff810901cc>] rcu_cpu_kthread_timer+0x27/0x58
    [   13.173009]
    [   13.173009] which lock already depends on the new lock.
    [   13.173009]
    [   13.173009]
    [   13.173009] the existing dependency chain (in reverse order) is:
    [   13.173009]
    [   13.173009] -> #2 (rcu_node_level_0){..-...}:
    [   13.173009]        [<ffffffff810679b9>] check_prevs_add+0x8b/0x104
    [   13.173009]        [<ffffffff81067da1>] validate_chain+0x36f/0x3ab
    [   13.173009]        [<ffffffff8106846b>] __lock_acquire+0x369/0x3e2
    [   13.173009]        [<ffffffff81068a0f>] lock_acquire+0xfc/0x14c
    [   13.173009]        [<ffffffff815697f1>] _raw_spin_lock+0x36/0x45
    [   13.173009]        [<ffffffff81090794>] rcu_read_unlock_special+0x8c/0x1d5
    [   13.173009]        [<ffffffff8109092c>] __rcu_read_unlock+0x4f/0xd7
    [   13.173009]        [<ffffffff81027bd3>] rcu_read_unlock+0x21/0x23
    [   13.173009]        [<ffffffff8102cc34>] cpuacct_charge+0x6c/0x75
    [   13.173009]        [<ffffffff81030cc6>] update_curr+0x101/0x12e
    [   13.173009]        [<ffffffff810311d0>] check_preempt_wakeup+0xf7/0x23b
    [   13.173009]        [<ffffffff8102acb3>] check_preempt_curr+0x2b/0x68
    [   13.173009]        [<ffffffff81031d40>] ttwu_do_wakeup+0x76/0x128
    [   13.173009]        [<ffffffff81031e49>] ttwu_do_activate.constprop.63+0x57/0x5c
    [   13.173009]        [<ffffffff81031e96>] scheduler_ipi+0x48/0x5d
    [   13.173009]        [<ffffffff810177d5>] smp_reschedule_interrupt+0x16/0x18
    [   13.173009]        [<ffffffff815710f3>] reschedule_interrupt+0x13/0x20
    [   13.173009]        [<ffffffff810b66d1>] rcu_read_unlock+0x21/0x23
    [   13.173009]        [<ffffffff810b739c>] find_get_page+0xa9/0xb9
    [   13.173009]        [<ffffffff810b8b48>] filemap_fault+0x6a/0x34d
    [   13.173009]        [<ffffffff810d1a25>] __do_fault+0x54/0x3e6
    [   13.173009]        [<ffffffff810d447a>] handle_pte_fault+0x12c/0x1ed
    [   13.173009]        [<ffffffff810d48f7>] handle_mm_fault+0x1cd/0x1e0
    [   13.173009]        [<ffffffff8156cfee>] do_page_fault+0x42d/0x5de
    [   13.173009]        [<ffffffff8156a75f>] page_fault+0x1f/0x30
    [   13.173009]
    [   13.173009] -> #1 (&rq->lock){-.-.-.}:
    [   13.173009]        [<ffffffff810679b9>] check_prevs_add+0x8b/0x104
    [   13.173009]        [<ffffffff81067da1>] validate_chain+0x36f/0x3ab
    [   13.173009]        [<ffffffff8106846b>] __lock_acquire+0x369/0x3e2
    [   13.173009]        [<ffffffff81068a0f>] lock_acquire+0xfc/0x14c
    [   13.173009]        [<ffffffff815697f1>] _raw_spin_lock+0x36/0x45
    [   13.173009]        [<ffffffff81027e19>] __task_rq_lock+0x8b/0xd3
    [   13.173009]        [<ffffffff81032f7f>] wake_up_new_task+0x41/0x108
    [   13.173009]        [<ffffffff810376c3>] do_fork+0x265/0x33f
    [   13.173009]        [<ffffffff81007d02>] kernel_thread+0x6b/0x6d
    [   13.173009]        [<ffffffff8153a9dd>] rest_init+0x21/0xd2
    [   13.173009]        [<ffffffff81b1db4f>] start_kernel+0x3bb/0x3c6
    [   13.173009]        [<ffffffff81b1d29f>] x86_64_start_reservations+0xaf/0xb3
    [   13.173009]        [<ffffffff81b1d393>] x86_64_start_kernel+0xf0/0xf7
    [   13.173009]
    [   13.173009] -> #0 (&p->pi_lock){-.-.-.}:
    [   13.173009]        [<ffffffff81067788>] check_prev_add+0x68/0x20e
    [   13.173009]        [<ffffffff810679b9>] check_prevs_add+0x8b/0x104
    [   13.173009]        [<ffffffff81067da1>] validate_chain+0x36f/0x3ab
    [   13.173009]        [<ffffffff8106846b>] __lock_acquire+0x369/0x3e2
    [   13.173009]        [<ffffffff81068a0f>] lock_acquire+0xfc/0x14c
    [   13.173009]        [<ffffffff815698ea>] _raw_spin_lock_irqsave+0x44/0x57
    [   13.173009]        [<ffffffff81032d8f>] try_to_wake_up+0x29/0x1aa
    [   13.173009]        [<ffffffff81032f3c>] wake_up_process+0x10/0x12
    [   13.173009]        [<ffffffff810901e9>] rcu_cpu_kthread_timer+0x44/0x58
    [   13.173009]        [<ffffffff81045286>] call_timer_fn+0xac/0x1e9
    [   13.173009]        [<ffffffff8104556d>] run_timer_softirq+0x1aa/0x1f2
    [   13.173009]        [<ffffffff8103e487>] __do_softirq+0x109/0x26a
    [   13.173009]        [<ffffffff8157144c>] call_softirq+0x1c/0x30
    [   13.173009]        [<ffffffff81003207>] do_softirq+0x44/0xf1
    [   13.173009]        [<ffffffff8103e8b9>] irq_exit+0x58/0xc8
    [   13.173009]        [<ffffffff81017f5a>] smp_apic_timer_interrupt+0x79/0x87
    [   13.173009]        [<ffffffff81570fd3>] apic_timer_interrupt+0x13/0x20
    [   13.173009]        [<ffffffff810bd51a>] get_page_from_freelist+0x2aa/0x310
    [   13.173009]        [<ffffffff810bdf03>] __alloc_pages_nodemask+0x178/0x243
    [   13.173009]        [<ffffffff8101fe2f>] pte_alloc_one+0x1e/0x3a
    [   13.173009]        [<ffffffff810d27fe>] __pte_alloc+0x22/0x14b
    [   13.173009]        [<ffffffff810d48a8>] handle_mm_fault+0x17e/0x1e0
    [   13.173009]        [<ffffffff8156cfee>] do_page_fault+0x42d/0x5de
    [   13.173009]        [<ffffffff8156a75f>] page_fault+0x1f/0x30
    [   13.173009]
    [   13.173009] other info that might help us debug this:
    [   13.173009]
    [   13.173009] Chain exists of:
    [   13.173009]   &p->pi_lock --> &rq->lock --> rcu_node_level_0
    [   13.173009]
    [   13.173009]  Possible unsafe locking scenario:
    [   13.173009]
    [   13.173009]        CPU0                    CPU1
    [   13.173009]        ----                    ----
    [   13.173009]   lock(rcu_node_level_0);
    [   13.173009]                                lock(&rq->lock);
    [   13.173009]                                lock(rcu_node_level_0);
    [   13.173009]   lock(&p->pi_lock);
    [   13.173009]
    [   13.173009]  *** DEADLOCK ***
    [   13.173009]
    [   13.173009] 3 locks held by blkid/267:
    [   13.173009]  #0:  (&mm->mmap_sem){++++++}, at: [<ffffffff8156cdb4>] do_page_fault+0x1f3/0x5de
    [   13.173009]  #1:  (&yield_timer){+.-...}, at: [<ffffffff810451da>] call_timer_fn+0x0/0x1e9
    [   13.173009]  #2:  (rcu_node_level_0){..-...}, at: [<ffffffff810901cc>] rcu_cpu_kthread_timer+0x27/0x58
    [   13.173009]
    [   13.173009] stack backtrace:
    [   13.173009] Pid: 267, comm: blkid Not tainted 2.6.39-rc6-mmotm0506 #1
    [   13.173009] Call Trace:
    [   13.173009]  <IRQ>  [<ffffffff8154a529>] print_circular_bug+0xc8/0xd9
    [   13.173009]  [<ffffffff81067788>] check_prev_add+0x68/0x20e
    [   13.173009]  [<ffffffff8100c861>] ? save_stack_trace+0x28/0x46
    [   13.173009]  [<ffffffff810679b9>] check_prevs_add+0x8b/0x104
    [   13.173009]  [<ffffffff81067da1>] validate_chain+0x36f/0x3ab
    [   13.173009]  [<ffffffff8106846b>] __lock_acquire+0x369/0x3e2
    [   13.173009]  [<ffffffff81032d8f>] ? try_to_wake_up+0x29/0x1aa
    [   13.173009]  [<ffffffff81068a0f>] lock_acquire+0xfc/0x14c
    [   13.173009]  [<ffffffff81032d8f>] ? try_to_wake_up+0x29/0x1aa
    [   13.173009]  [<ffffffff810901a5>] ? rcu_check_quiescent_state+0x82/0x82
    [   13.173009]  [<ffffffff815698ea>] _raw_spin_lock_irqsave+0x44/0x57
    [   13.173009]  [<ffffffff81032d8f>] ? try_to_wake_up+0x29/0x1aa
    [   13.173009]  [<ffffffff81032d8f>] try_to_wake_up+0x29/0x1aa
    [   13.173009]  [<ffffffff810901a5>] ? rcu_check_quiescent_state+0x82/0x82
    [   13.173009]  [<ffffffff81032f3c>] wake_up_process+0x10/0x12
    [   13.173009]  [<ffffffff810901e9>] rcu_cpu_kthread_timer+0x44/0x58
    [   13.173009]  [<ffffffff810901a5>] ? rcu_check_quiescent_state+0x82/0x82
    [   13.173009]  [<ffffffff81045286>] call_timer_fn+0xac/0x1e9
    [   13.173009]  [<ffffffff810451da>] ? del_timer+0x75/0x75
    [   13.173009]  [<ffffffff810901a5>] ? rcu_check_quiescent_state+0x82/0x82
    [   13.173009]  [<ffffffff8104556d>] run_timer_softirq+0x1aa/0x1f2
    [   13.173009]  [<ffffffff8103e487>] __do_softirq+0x109/0x26a
    [   13.173009]  [<ffffffff8106365f>] ? tick_dev_program_event+0x37/0xf6
    [   13.173009]  [<ffffffff810a0e4a>] ? time_hardirqs_off+0x1b/0x2f
    [   13.173009]  [<ffffffff8157144c>] call_softirq+0x1c/0x30
    [   13.173009]  [<ffffffff81003207>] do_softirq+0x44/0xf1
    [   13.173009]  [<ffffffff8103e8b9>] irq_exit+0x58/0xc8
    [   13.173009]  [<ffffffff81017f5a>] smp_apic_timer_interrupt+0x79/0x87
    [   13.173009]  [<ffffffff81570fd3>] apic_timer_interrupt+0x13/0x20
    [   13.173009]  <EOI>  [<ffffffff810bd384>] ? get_page_from_freelist+0x114/0x310
    [   13.173009]  [<ffffffff810bd51a>] ? get_page_from_freelist+0x2aa/0x310
    [   13.173009]  [<ffffffff812220e7>] ? clear_page_c+0x7/0x10
    [   13.173009]  [<ffffffff810bd1ef>] ? prep_new_page+0x14c/0x1cd
    [   13.173009]  [<ffffffff810bd51a>] get_page_from_freelist+0x2aa/0x310
    [   13.173009]  [<ffffffff810bdf03>] __alloc_pages_nodemask+0x178/0x243
    [   13.173009]  [<ffffffff810d46b9>] ? __pmd_alloc+0x87/0x99
    [   13.173009]  [<ffffffff8101fe2f>] pte_alloc_one+0x1e/0x3a
    [   13.173009]  [<ffffffff810d46b9>] ? __pmd_alloc+0x87/0x99
    [   13.173009]  [<ffffffff810d27fe>] __pte_alloc+0x22/0x14b
    [   13.173009]  [<ffffffff810d48a8>] handle_mm_fault+0x17e/0x1e0
    [   13.173009]  [<ffffffff8156cfee>] do_page_fault+0x42d/0x5de
    [   13.173009]  [<ffffffff810d915f>] ? sys_brk+0x32/0x10c
    [   13.173009]  [<ffffffff810a0e4a>] ? time_hardirqs_off+0x1b/0x2f
    [   13.173009]  [<ffffffff81065c4f>] ? trace_hardirqs_off_caller+0x3f/0x9c
    [   13.173009]  [<ffffffff812235dd>] ? trace_hardirqs_off_thunk+0x3a/0x3c
    [   13.173009]  [<ffffffff8156a75f>] page_fault+0x1f/0x30
    [   14.010075] usb 5-1: new full speed USB device number 2 using uhci_hcd
    
    Reported-by: Valdis Kletnieks <Valdis.Kletnieks@vt.edu>
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 2907c35ff64708065e5a7fd54e8ded8263eb3074
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Wed May 25 07:34:04 2011 +0000

    net: hold rtnl again in dump callbacks
    
    Commit e67f88dd12f6 (dont hold rtnl mutex during netlink dump callbacks)
    missed fact that rtnl_fill_ifinfo() must be called with rtnl held.
    
    Because of possible deadlocks between two mutexes (cb_mutex and rtnl),
    its not easy to solve this problem, so revert this part of the patch.
    
    It also forgot one rcu_read_unlock() in FIB dump_rules()
    
    Add one ASSERT_RTNL() in rtnl_fill_ifinfo() to remind us the rule.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    CC: Patrick McHardy <kaber@trash.net>
    CC: Stephen Hemminger <shemminger@vyatta.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit e3aa52d665ec1a962d1cf025a2e5ee84b3b33406
Merge: d2f62766d577 29ce83100008
Author: Avi Kivity <avi@redhat.com>
Date:   Wed May 11 05:56:53 2011 -0400

    Merge commit '29ce831000081dd757d3116bf774aafffc4b6b20' into next
    
    * commit '29ce831000081dd757d3116bf774aafffc4b6b20': (34 commits)
      rcu: provide rcu_virt_note_context_switch() function.
      rcu: get rid of signed overflow in check_cpu_stall()
      rcu: optimize rcutiny
      rcu: prevent call_rcu() from diving into rcu core if irqs disabled
      rcu: further lower priority in rcu_yield()
      rcu: introduce kfree_rcu()
      rcu: fix spelling
      rcu: call __rcu_read_unlock() in exit_rcu for tree RCU
      rcu: Converge TINY_RCU expedited and normal boosting
      rcu: remove useless ->boosted_this_gp field
      rcu: code cleanups in TINY_RCU priority boosting.
      rcu: Switch to this_cpu() primitives
      rcu: Use WARN_ON_ONCE for DEBUG_OBJECTS_RCU_HEAD warnings
      rcu: mark rcutorture boosting callback as being on-stack
      rcu: add DEBUG_OBJECTS_RCU_HEAD check for alignment
      rcu: Enable DEBUG_OBJECTS_RCU_HEAD from !PREEMPT
      rcu: Add forward-progress diagnostic for per-CPU kthreads
      rcu: add grace-period age and more kthread state to tracing
      rcu: fix tracing bug thinko on boost-balk attribution
      rcu: update tracing documentation for new rcutorture and rcuboost
      ...
    
    Pulling in rcu_virt_note_context_switch().
    
    Signed-off-by: Avi Kivity <avi@redhat.com>
    
    * commit '29ce831000081dd757d3116bf774aafffc4b6b20': (34 commits)
      rcu: provide rcu_virt_note_context_switch() function.
      rcu: get rid of signed overflow in check_cpu_stall()
      rcu: optimize rcutiny
      rcu: prevent call_rcu() from diving into rcu core if irqs disabled
      rcu: further lower priority in rcu_yield()
      rcu: introduce kfree_rcu()
      rcu: fix spelling
      rcu: call __rcu_read_unlock() in exit_rcu for tree RCU
      rcu: Converge TINY_RCU expedited and normal boosting
      rcu: remove useless ->boosted_this_gp field
      rcu: code cleanups in TINY_RCU priority boosting.
      rcu: Switch to this_cpu() primitives
      rcu: Use WARN_ON_ONCE for DEBUG_OBJECTS_RCU_HEAD warnings
      rcu: mark rcutorture boosting callback as being on-stack
      rcu: add DEBUG_OBJECTS_RCU_HEAD check for alignment
      rcu: Enable DEBUG_OBJECTS_RCU_HEAD from !PREEMPT
      rcu: Add forward-progress diagnostic for per-CPU kthreads
      rcu: add grace-period age and more kthread state to tracing
      rcu: fix tracing bug thinko on boost-balk attribution
      rcu: update tracing documentation for new rcutorture and rcuboost
      ...

commit 1928ecab620907a0953f811316d05f367f3f4dba
Author: Johannes Berg <johannes.berg@intel.com>
Date:   Sat May 14 11:00:52 2011 +0200

    mac80211: fix and simplify mesh locking
    
    The locking in mesh_{mpath,mpp}_table_grow not only
    has an rcu_read_unlock() missing, it's also racy
    (though really only technically since it's invoked
    from a single function only) since it obtains the
    new size of the table without any locking, so two
    invocations of the function could attempt the same
    resize.
    
    Additionally, it uses synchronize_rcu() which is
    rather expensive and can be avoided trivially here.
    
    Modify the functions to only use the table lock
    and use call_rcu() instead of synchronize_rcu().
    
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 1217ed1ba5c67393293dfb0f03c353b118dadeb4
Author: Paul E. McKenney <paul.mckenney@linaro.org>
Date:   Wed May 4 21:43:49 2011 -0700

    rcu: permit rcu_read_unlock() to be called while holding runqueue locks
    
    Avoid calling into the scheduler while holding core RCU locks.  This
    allows rcu_read_unlock() to be called while holding the runqueue locks,
    but only as long as there was no chance of the RCU read-side critical
    section having been preempted.  (Otherwise, if RCU priority boosting
    is enabled, rcu_read_unlock() might call into the scheduler in order to
    unboost itself, which might allows self-deadlock on the runqueue locks
    within the scheduler.)
    
    Signed-off-by: Paul E. McKenney <paul.mckenney@linaro.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 13491a0ee1ef862b6c842132b6eb9c5e721af5ad
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Fri Feb 25 11:37:59 2011 -0800

    rcu: call __rcu_read_unlock() in exit_rcu for tree RCU
    
    Using __rcu_read_lock() in place of rcu_read_lock() leaves any debug
    state as it really should be, namely with the lock still held.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Reviewed-by: Josh Triplett <josh@joshtriplett.org>

commit b5a6f69c5ca024bea43496d517c3b7ccfdb084a6
Author: Antonio Quartulli <ordex@autistici.org>
Date:   Sat Apr 16 11:30:57 2011 +0200

    batman-adv: orig_hash_find() manages rcu_lock/unlock internally
    
    orig_hash_find() manages rcu_lock/unlock internally and doesn't need to
    be surrounded by rcu_read_lock() / rcu_read_unlock() anymore
    
    Signed-off-by: Antonio Quartulli <ordex@autistici.org>
    Acked-by: Marek Lindner <lindner_marek@yahoo.de>
    Signed-off-by: Sven Eckelmann <sven@narfation.org>

commit 527a95060a52006117803e36ac63911540fe0cf3
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 31 17:00:18 2010 -0700

    pid: make setpgid() system call use RCU read-side critical section
    
    commit 950eaaca681c44aab87a46225c9e44f902c080aa upstream.
    
    [   23.584719]
    [   23.584720] ===================================================
    [   23.585059] [ INFO: suspicious rcu_dereference_check() usage. ]
    [   23.585176] ---------------------------------------------------
    [   23.585176] kernel/pid.c:419 invoked rcu_dereference_check() without protection!
    [   23.585176]
    [   23.585176] other info that might help us debug this:
    [   23.585176]
    [   23.585176]
    [   23.585176] rcu_scheduler_active = 1, debug_locks = 1
    [   23.585176] 1 lock held by rc.sysinit/728:
    [   23.585176]  #0:  (tasklist_lock){.+.+..}, at: [<ffffffff8104771f>] sys_setpgid+0x5f/0x193
    [   23.585176]
    [   23.585176] stack backtrace:
    [   23.585176] Pid: 728, comm: rc.sysinit Not tainted 2.6.36-rc2 #2
    [   23.585176] Call Trace:
    [   23.585176]  [<ffffffff8105b436>] lockdep_rcu_dereference+0x99/0xa2
    [   23.585176]  [<ffffffff8104c324>] find_task_by_pid_ns+0x50/0x6a
    [   23.585176]  [<ffffffff8104c35b>] find_task_by_vpid+0x1d/0x1f
    [   23.585176]  [<ffffffff81047727>] sys_setpgid+0x67/0x193
    [   23.585176]  [<ffffffff810029eb>] system_call_fastpath+0x16/0x1b
    [   24.959669] type=1400 audit(1282938522.956:4): avc:  denied  { module_request } for  pid=766 comm="hwclock" kmod="char-major-10-135" scontext=system_u:system_r:hwclock_t:s0 tcontext=system_u:system_r:kernel_t:s0 tclas
    
    It turns out that the setpgid() system call fails to enter an RCU
    read-side critical section before doing a PID-to-task_struct translation.
    This commit therefore does rcu_read_lock() before the translation, and
    also does rcu_read_unlock() after the last use of the returned pointer.
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 006c514c67d28b1242e29fa89061cb4201f776eb
Author: David Howells <dhowells@redhat.com>
Date:   Thu Jul 29 12:45:49 2010 +0100

    CRED: Fix get_task_cred() and task_state() to not resurrect dead credentials
    
    commit de09a9771a5346029f4d11e4ac886be7f9bfdd75 upstream.
    
    It's possible for get_task_cred() as it currently stands to 'corrupt' a set of
    credentials by incrementing their usage count after their replacement by the
    task being accessed.
    
    What happens is that get_task_cred() can race with commit_creds():
    
            TASK_1                  TASK_2                  RCU_CLEANER
            -->get_task_cred(TASK_2)
            rcu_read_lock()
            __cred = __task_cred(TASK_2)
                                    -->commit_creds()
                                    old_cred = TASK_2->real_cred
                                    TASK_2->real_cred = ...
                                    put_cred(old_cred)
                                      call_rcu(old_cred)
                    [__cred->usage == 0]
            get_cred(__cred)
                    [__cred->usage == 1]
            rcu_read_unlock()
                                                            -->put_cred_rcu()
                                                            [__cred->usage == 1]
                                                            panic()
    
    However, since a tasks credentials are generally not changed very often, we can
    reasonably make use of a loop involving reading the creds pointer and using
    atomic_inc_not_zero() to attempt to increment it if it hasn't already hit zero.
    
    If successful, we can safely return the credentials in the knowledge that, even
    if the task we're accessing has released them, they haven't gone to the RCU
    cleanup code.
    
    We then change task_state() in procfs to use get_task_cred() rather than
    calling get_cred() on the result of __task_cred(), as that suffers from the
    same problem.
    
    Without this change, a BUG_ON in __put_cred() or in put_cred_rcu() can be
    tripped when it is noticed that the usage count is not zero as it ought to be,
    for example:
    
    kernel BUG at kernel/cred.c:168!
    invalid opcode: 0000 [#1] SMP
    last sysfs file: /sys/kernel/mm/ksm/run
    CPU 0
    Pid: 2436, comm: master Not tainted 2.6.33.3-85.fc13.x86_64 #1 0HR330/OptiPlex
    745
    RIP: 0010:[<ffffffff81069881>]  [<ffffffff81069881>] __put_cred+0xc/0x45
    RSP: 0018:ffff88019e7e9eb8  EFLAGS: 00010202
    RAX: 0000000000000001 RBX: ffff880161514480 RCX: 00000000ffffffff
    RDX: 00000000ffffffff RSI: ffff880140c690c0 RDI: ffff880140c690c0
    RBP: ffff88019e7e9eb8 R08: 00000000000000d0 R09: 0000000000000000
    R10: 0000000000000001 R11: 0000000000000040 R12: ffff880140c690c0
    R13: ffff88019e77aea0 R14: 00007fff336b0a5c R15: 0000000000000001
    FS:  00007f12f50d97c0(0000) GS:ffff880007400000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f8f461bc000 CR3: 00000001b26ce000 CR4: 00000000000006f0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process master (pid: 2436, threadinfo ffff88019e7e8000, task ffff88019e77aea0)
    Stack:
     ffff88019e7e9ec8 ffffffff810698cd ffff88019e7e9ef8 ffffffff81069b45
    <0> ffff880161514180 ffff880161514480 ffff880161514180 0000000000000000
    <0> ffff88019e7e9f28 ffffffff8106aace 0000000000000001 0000000000000246
    Call Trace:
     [<ffffffff810698cd>] put_cred+0x13/0x15
     [<ffffffff81069b45>] commit_creds+0x16b/0x175
     [<ffffffff8106aace>] set_current_groups+0x47/0x4e
     [<ffffffff8106ac89>] sys_setgroups+0xf6/0x105
     [<ffffffff81009b02>] system_call_fastpath+0x16/0x1b
    Code: 48 8d 71 ff e8 7e 4e 15 00 85 c0 78 0b 8b 75 ec 48 89 df e8 ef 4a 15 00
    48 83 c4 18 5b c9 c3 55 8b 07 8b 07 48 89 e5 85 c0 74 04 <0f> 0b eb fe 65 48 8b
    04 25 00 cc 00 00 48 3b b8 58 04 00 00 75
    RIP  [<ffffffff81069881>] __put_cred+0xc/0x45
     RSP <ffff88019e7e9eb8>
    ---[ end trace df391256a100ebdd ]---
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 016aa2ed1cc9cf704cf76d8df07751b6daa9750f
Merge: 34d211a2d5df 241e6663b515
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Wed Mar 16 08:10:07 2011 -0700

    Merge branch 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-rcu-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      smp: Document transitivity for memory barriers.
      rcu: add comment saying why DEBUG_OBJECTS_RCU_HEAD depends on PREEMPT.
      rcupdate: remove dead code
      rcu: add documentation saying which RCU flavor to choose
      rcutorture: Get rid of duplicate sched.h include
      rcu: call __rcu_read_unlock() in exit_rcu for tiny RCU

commit ba74f4d7e5125d04d453b4af69c53c533e6feb80
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Sun Jan 9 18:09:51 2011 -0800

    rcu: call __rcu_read_unlock() in exit_rcu for tiny RCU
    
    Using __rcu_read_lock() in place of rcu_read_lock() leaves any debug
    state as it really should be, namely with the lock still held.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit c8fd44092f8f4ddcaac39f898769f64580a5a244
Author: David Howells <dhowells@redhat.com>
Date:   Thu Jul 29 12:45:49 2010 +0100

    CRED: Fix get_task_cred() and task_state() to not resurrect dead credentials
    
    commit de09a9771a5346029f4d11e4ac886be7f9bfdd75 upstream.
    
    It's possible for get_task_cred() as it currently stands to 'corrupt' a set of
    credentials by incrementing their usage count after their replacement by the
    task being accessed.
    
    What happens is that get_task_cred() can race with commit_creds():
    
            TASK_1                  TASK_2                  RCU_CLEANER
            -->get_task_cred(TASK_2)
            rcu_read_lock()
            __cred = __task_cred(TASK_2)
                                    -->commit_creds()
                                    old_cred = TASK_2->real_cred
                                    TASK_2->real_cred = ...
                                    put_cred(old_cred)
                                      call_rcu(old_cred)
                    [__cred->usage == 0]
            get_cred(__cred)
                    [__cred->usage == 1]
            rcu_read_unlock()
                                                            -->put_cred_rcu()
                                                            [__cred->usage == 1]
                                                            panic()
    
    However, since a tasks credentials are generally not changed very often, we can
    reasonably make use of a loop involving reading the creds pointer and using
    atomic_inc_not_zero() to attempt to increment it if it hasn't already hit zero.
    
    If successful, we can safely return the credentials in the knowledge that, even
    if the task we're accessing has released them, they haven't gone to the RCU
    cleanup code.
    
    We then change task_state() in procfs to use get_task_cred() rather than
    calling get_cred() on the result of __task_cred(), as that suffers from the
    same problem.
    
    Without this change, a BUG_ON in __put_cred() or in put_cred_rcu() can be
    tripped when it is noticed that the usage count is not zero as it ought to be,
    for example:
    
    kernel BUG at kernel/cred.c:168!
    invalid opcode: 0000 [#1] SMP
    last sysfs file: /sys/kernel/mm/ksm/run
    CPU 0
    Pid: 2436, comm: master Not tainted 2.6.33.3-85.fc13.x86_64 #1 0HR330/OptiPlex
    745
    RIP: 0010:[<ffffffff81069881>]  [<ffffffff81069881>] __put_cred+0xc/0x45
    RSP: 0018:ffff88019e7e9eb8  EFLAGS: 00010202
    RAX: 0000000000000001 RBX: ffff880161514480 RCX: 00000000ffffffff
    RDX: 00000000ffffffff RSI: ffff880140c690c0 RDI: ffff880140c690c0
    RBP: ffff88019e7e9eb8 R08: 00000000000000d0 R09: 0000000000000000
    R10: 0000000000000001 R11: 0000000000000040 R12: ffff880140c690c0
    R13: ffff88019e77aea0 R14: 00007fff336b0a5c R15: 0000000000000001
    FS:  00007f12f50d97c0(0000) GS:ffff880007400000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f8f461bc000 CR3: 00000001b26ce000 CR4: 00000000000006f0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process master (pid: 2436, threadinfo ffff88019e7e8000, task ffff88019e77aea0)
    Stack:
     ffff88019e7e9ec8 ffffffff810698cd ffff88019e7e9ef8 ffffffff81069b45
    <0> ffff880161514180 ffff880161514480 ffff880161514180 0000000000000000
    <0> ffff88019e7e9f28 ffffffff8106aace 0000000000000001 0000000000000246
    Call Trace:
     [<ffffffff810698cd>] put_cred+0x13/0x15
     [<ffffffff81069b45>] commit_creds+0x16b/0x175
     [<ffffffff8106aace>] set_current_groups+0x47/0x4e
     [<ffffffff8106ac89>] sys_setgroups+0xf6/0x105
     [<ffffffff81009b02>] system_call_fastpath+0x16/0x1b
    Code: 48 8d 71 ff e8 7e 4e 15 00 85 c0 78 0b 8b 75 ec 48 89 df e8 ef 4a 15 00
    48 83 c4 18 5b c9 c3 55 8b 07 8b 07 48 89 e5 85 c0 74 04 <0f> 0b eb fe 65 48 8b
    04 25 00 cc 00 00 48 3b b8 58 04 00 00 75
    RIP  [<ffffffff81069881>] __put_cred+0xc/0x45
     RSP <ffff88019e7e9eb8>
    ---[ end trace df391256a100ebdd ]---
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 88fabbfcc6d347555f9be04e3fe89e7a9c9a2a2d
Author: Adrian Knoth <adi@drcomp.erfurt.thur.de>
Date:   Wed Feb 23 11:43:10 2011 +0100

    ALSA: hdspm - Restrict channel count on RME AES/AES32
    
    Without calling an appropriate rule, AES/AES32 cards would announce a
    theoretical channel count of 64 (HDSPM_MAX_CHANNELS), leading to the
    already known bug:
    
    [37422.640481] ------------[ cut here ]------------
    [37422.640487] WARNING: at sound/pci/rme9652/hdspm.c:5449
    snd_hdspm_ioctl+0x18f/0x202 [snd_hdspm]()
    [37422.640489] Hardware name: PRIMERGY RX100 S6
    [37422.640490] BUG? (info->channel >= hdspm->max_channels_in)
    [37422.640492] Modules linked in: snd_hdspm snd_seq_midi ipmi_watchdog
    ipmi_poweroff ipmi_si ipmi_devintf ipmi_msghandler i2c_i801 e1000e
    snd_rawmidi power_meter [last unloaded: snd_hdspm]
    [37422.640501] Pid: 22231, comm: jackd Tainted: G      D W
    2.6.36-gentoo-r5 #5
    [37422.640502] Call Trace:
    [37422.640508]  [<ffffffff8103db3a>] warn_slowpath_common+0x80/0x98
    [37422.640511]  [<ffffffff8103dbe6>] warn_slowpath_fmt+0x41/0x43
    [37422.640514]  [<ffffffff81034306>] ? get_parent_ip+0x11/0x42
    [37422.640518]  [<ffffffffa0055763>] snd_hdspm_ioctl+0x18f/0x202
    [snd_hdspm]
    [37422.640522]  [<ffffffff813fd626>] snd_pcm_channel_info+0x73/0x7c
    [37422.640525]  [<ffffffff814001e9>] snd_pcm_common_ioctl1+0x326/0xb01
    [37422.640527]  [<ffffffff81034306>] ? get_parent_ip+0x11/0x42
    [37422.640531]  [<ffffffff8105be6c>] ? __srcu_read_unlock+0x3b/0x59
    [37422.640533]  [<ffffffff81400bce>] snd_pcm_capture_ioctl1+0x20a/0x227
    [37422.640537]  [<ffffffff811e599c>] ? file_has_perm+0x90/0x9e
    [37422.640540]  [<ffffffff81400c15>] snd_pcm_capture_ioctl+0x2a/0x2e
    [37422.640543]  [<ffffffff810f2c69>] do_vfs_ioctl+0x404/0x453
    [37422.640546]  [<ffffffff810f2d09>] sys_ioctl+0x51/0x74
    [37422.640549]  [<ffffffff81002aab>] system_call_fastpath+0x16/0x1b
    [37422.640552] ---[ end trace 0cd919cd68118082 ]---
    
    We already have all the right values in place, we simply have to inform
    the upper layers about this restriction.
    
    Note that snd_hdspm_hw_rule_rate_out_channels and
    snd_hdspm_hw_rule_rate_in_channels must not be called on AES32, because
    the channel count is always 16, no matter of the samplerate in use.
    
    Signed-off-by: Adrian Knoth <adi@drcomp.erfurt.thur.de>
    Signed-off-by: Takashi Iwai <tiwai@suse.de>

commit 31d409373cca3517a30540b51f55dcb1f5af0d49
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Mon Feb 14 11:23:04 2011 -0800

    ipv4: fix rcu lock imbalance in fib_select_default()
    
    Commit 0c838ff1ade7 (ipv4: Consolidate all default route selection
    implementations.) forgot to remove one rcu_read_unlock() from
    fib_select_default().
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 884b821fa27a5e3714d4871976d3e7c3abfa0d1b
Author: Rafael J. Wysocki <rjw@sisk.pl>
Date:   Tue Feb 8 23:37:16 2011 +0100

    ACPI: Fix acpi_os_read_memory() and acpi_os_write_memory() (v2)
    
    The functions acpi_os_read_memory() and acpi_os_write_memory() do
    two wrong things.  First, they shouldn't call rcu_read_unlock()
    before the looked up address is actually used for I/O, because in
    that case the iomap it belongs to may be removed before the I/O
    is done.  Second, if they have to create a new mapping, they should
    check the returned virtual address and tell the caller that the
    operation failed if it is NULL (in fact, I think they even should not
    attempt to map an address that's not present in one of the existing
    ACPI iomaps, because that may cause problems to happen when they are
    called from nonpreemptible context and their callers ought to know
    what they are doing and map the requisite memory regions beforehand).
    
    Make these functions call rcu_read_unlock() when the I/O is complete
    (or if it's necessary to map the given address "on the fly") and
    return an error code if the requested physical address is not present
    in the existing ACPI iomaps and cannot be mapped.
    
    Signed-off-by: Rafael J. Wysocki <rjw@sisk.pl>

commit 29562d83a2d8d0bbe5ffb0d976c6c73d5a269853
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 31 17:00:18 2010 -0700

    pid: make setpgid() system call use RCU read-side critical section
    
    commit 950eaaca681c44aab87a46225c9e44f902c080aa upstream.
    
    [   23.584719]
    [   23.584720] ===================================================
    [   23.585059] [ INFO: suspicious rcu_dereference_check() usage. ]
    [   23.585176] ---------------------------------------------------
    [   23.585176] kernel/pid.c:419 invoked rcu_dereference_check() without protection!
    [   23.585176]
    [   23.585176] other info that might help us debug this:
    [   23.585176]
    [   23.585176]
    [   23.585176] rcu_scheduler_active = 1, debug_locks = 1
    [   23.585176] 1 lock held by rc.sysinit/728:
    [   23.585176]  #0:  (tasklist_lock){.+.+..}, at: [<ffffffff8104771f>] sys_setpgid+0x5f/0x193
    [   23.585176]
    [   23.585176] stack backtrace:
    [   23.585176] Pid: 728, comm: rc.sysinit Not tainted 2.6.36-rc2 #2
    [   23.585176] Call Trace:
    [   23.585176]  [<ffffffff8105b436>] lockdep_rcu_dereference+0x99/0xa2
    [   23.585176]  [<ffffffff8104c324>] find_task_by_pid_ns+0x50/0x6a
    [   23.585176]  [<ffffffff8104c35b>] find_task_by_vpid+0x1d/0x1f
    [   23.585176]  [<ffffffff81047727>] sys_setpgid+0x67/0x193
    [   23.585176]  [<ffffffff810029eb>] system_call_fastpath+0x16/0x1b
    [   24.959669] type=1400 audit(1282938522.956:4): avc:  denied  { module_request } for  pid=766 comm="hwclock" kmod="char-major-10-135" scontext=system_u:system_r:hwclock_t:s0 tcontext=system_u:system_r:kernel_t:s0 tclas
    
    It turns out that the setpgid() system call fails to enter an RCU
    read-side critical section before doing a PID-to-task_struct translation.
    This commit therefore does rcu_read_lock() before the translation, and
    also does rcu_read_unlock() after the last use of the returned pointer.
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

commit 1447399b3e34af016c368b4178db7ef0e04e15b0
Author: Daniel J Blueman <daniel.blueman@gmail.com>
Date:   Tue Nov 9 21:33:02 2010 +0100

    ioprio: fix RCU locking around task dereference
    
    With 2.6.37-rc1, I observe sys_ioprio_set not taking the RCU lock [1]
    across access to the task credentials.
    
    Inspecting the code in fs/ioprio.c, the tasklist_lock is held for read
    across the __task_cred call, which is presumably sufficient to prevent
    the task credentials becoming stale.
    
    ===================================================
    
    [ INFO: suspicious rcu_dereference_check() usage. ]
    
    ---------------------------------------------------
    
    kernel/pid.c:419 invoked rcu_dereference_check() without protection!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 1, debug_locks = 1
    
    1 lock held by start-stop-daem/2246:
    
     #0:  (tasklist_lock){.?.?..}, at: [<ffffffff811a2dfa>]
    sys_ioprio_set+0x8a/0x400
    
    stack backtrace:
    
    Pid: 2246, comm: start-stop-daem Not tainted 2.6.37-rc1-330cd+ #2
    
    Call Trace:
    
     [<ffffffff8109f5f4>] lockdep_rcu_dereference+0xa4/0xc0
    
     [<ffffffff81085651>] find_task_by_pid_ns+0x81/0x90
    
     [<ffffffff8108567d>] find_task_by_vpid+0x1d/0x20
    
     [<ffffffff811a3160>] sys_ioprio_set+0x3f0/0x400
    
     [<ffffffff816efa79>] ? trace_hardirqs_on_thunk+0x3a/0x3f
    
     [<ffffffff81003482>] system_call_fastpath+0x16/0x1b
    
    Take the RCU lock for read across acquiring the pointer to the task
    credentials and dereferencing it.
    
    Signed-off-by: Daniel J Blueman <daniel.blueman@gmail.com>
    
    Fixed up by Jens to fix missing rcu_read_unlock() on mismatches.
    
    Signed-off-by: Jens Axboe <jaxboe@fusionio.com>

commit c0deae8c9587419ab13874b74425ce2eb2e18508
Author: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
Date:   Wed Nov 3 18:52:56 2010 +0200

    posix-cpu-timers: Rcu_read_lock/unlock protect find_task_by_vpid call
    
    Commit 4221a9918e38b7494cee341dda7b7b4bb8c04bde "Add RCU check for
    find_task_by_vpid()" introduced rcu_lockdep_assert to find_task_by_pid_ns.
    Add rcu_read_lock/rcu_read_unlock to call find_task_by_vpid.
    
    Tetsuo Handa wrote:
    | Quoting from one of posts in that thead
    | http://kerneltrap.org/mailarchive/linux-kernel/2010/2/8/4536388
    |
    || Usually tasklist gives enough protection, but if copy_process() fails
    || it calls free_pid() lockless and does call_rcu(delayed_put_pid().
    || This means, without rcu lock find_pid_ns() can't scan the hash table
    || safely.
    
    Thomas Gleixner wrote:
    | We can remove the tasklist_lock while at it. rcu_read_lock is enough.
    
    Patch also replaces thread_group_leader with has_group_leader_pid
    in accordance to comment by Oleg Nesterov:
    
    | ... thread_group_leader() check is not relaible without
    | tasklist. If we race with de_thread() find_task_by_vpid() can find
    | the new leader before it updates its ->group_leader.
    |
    | perhaps it makes sense to change posix_cpu_timer_create() to use
    | has_group_leader_pid() instead, just to make this code not look racy
    | and avoid adding new problems.
    
    
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Stanislaw Gruszka <sgruszka@redhat.com>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    LKML-Reference: <20101103165256.GD30053@swordfish.minsk.epam.com>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit dafeac387d7f10d12d4fa9cc626af43c805540f7
Author: Christian Lamparter <chunkeey@googlemail.com>
Date:   Sat Oct 23 15:02:02 2010 +0200

    carl9170: fix scheduling while atomic
    
    This patch fixes the following mishap:
    
    BUG: scheduling while atomic: wpa_supplicant/4164/0x00000002
    Modules linked in: carl9170 mac80211 [...]
    Pid: 4164, comm: wpa_supplicant Not tainted 2.6.36-wl+ #119
    Call Trace:
     [<c13779a9>] ? schedule+0x349/0x4c0
     [<c13780d6>] ? schedule_timeout+0x106/0x1e0
     [<c1037f50>] ? process_timeout+0x0/0x10
     [<c1377e8d>] ? wait_for_common+0x9d/0x140
     [<c1029110>] ? default_wake_function+0x0/0x10
     [<f80c6080>] ? carl9170_exec_cmd+0xf0/0x250 [carl9170]
     [<f80c695e>] ? carl9170_set_mac_reg+0x5e/0x70 [carl9170]
     [<f80c3f76>] ? carl9170_op_add_interface+0x176/0x310 [carl9170]
     [...]
    
    rcu_read_unlock() call was erroneously placed after the
    sync. function carl9170_mod_virtual_mac.
    
    Signed-off-by: Christian Lamparter <chunkeey@googlemail.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 8391d07b80e8da957cd888870e23f8e218438622
Author: Dimitris Michailidis <dm@chelsio.com>
Date:   Thu Oct 7 14:48:38 2010 +0000

    ipv4: Remove leftover rcu_read_unlock calls from __mkroute_output()
    
    Commit "fib: RCU conversion of fib_lookup()" removed rcu_read_lock() from
    __mkroute_output but left a couple of calls to rcu_read_unlock() in there.
    This causes lockdep to complain that the rcu_read_unlock() call in
    __ip_route_output_key causes a lock inbalance and quickly crashes the
    kernel. The below fixes this for me.
    
    Signed-off-by: Dimitris Michailidis <dm@chelsio.com>
    Acked-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 767e97e1e0db0d0f3152cd2f3bd3403596aedbad
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Wed Oct 6 17:49:21 2010 -0700

    neigh: RCU conversion of struct neighbour
    
    This is the second step for neighbour RCU conversion.
    
    (first was commit d6bf7817 : RCU conversion of neigh hash table)
    
    neigh_lookup() becomes lockless, but still take a reference on found
    neighbour. (no more read_lock()/read_unlock() on tbl->lock)
    
    struct neighbour gets an additional rcu_head field and is freed after an
    RCU grace period.
    
    Future work would need to eventually not take a reference on neighbour
    for temporary dst (DST_NOCACHE), but this would need dst->_neighbour to
    use a noref bit like we did for skb->_dst.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ebc0ffae5dfb4447e0a431ffe7fe1d467c48bbb9
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Oct 5 10:41:36 2010 +0000

    fib: RCU conversion of fib_lookup()
    
    fib_lookup() converted to be called in RCU protected context, no
    reference taken and released on a contended cache line (fib_clntref)
    
    fib_table_lookup() and fib_semantic_match() get an additional parameter.
    
    struct fib_info gets an rcu_head field, and is freed after an rcu grace
    period.
    
    Stress test :
    (Sending 160.000.000 UDP frames on same neighbour,
    IP route cache disabled, dual E5540 @2.53GHz,
    32bit kernel, FIB_HASH) (about same results for FIB_TRIE)
    
    Before patch :
    
    real    1m31.199s
    user    0m13.761s
    sys     23m24.780s
    
    After patch:
    
    real    1m5.375s
    user    0m14.997s
    sys     15m50.115s
    
    Before patch Profile :
    
    13044.00 15.4% __ip_route_output_key vmlinux
     8438.00 10.0% dst_destroy           vmlinux
     5983.00  7.1% fib_semantic_match    vmlinux
     5410.00  6.4% fib_rules_lookup      vmlinux
     4803.00  5.7% neigh_lookup          vmlinux
     4420.00  5.2% _raw_spin_lock        vmlinux
     3883.00  4.6% rt_set_nexthop        vmlinux
     3261.00  3.9% _raw_read_lock        vmlinux
     2794.00  3.3% fib_table_lookup      vmlinux
     2374.00  2.8% neigh_resolve_output  vmlinux
     2153.00  2.5% dst_alloc             vmlinux
     1502.00  1.8% _raw_read_lock_bh     vmlinux
     1484.00  1.8% kmem_cache_alloc      vmlinux
     1407.00  1.7% eth_header            vmlinux
     1406.00  1.7% ipv4_dst_destroy      vmlinux
     1298.00  1.5% __copy_from_user_ll   vmlinux
     1174.00  1.4% dev_queue_xmit        vmlinux
     1000.00  1.2% ip_output             vmlinux
    
    After patch Profile :
    
    13712.00 15.8% dst_destroy             vmlinux
     8548.00  9.9% __ip_route_output_key   vmlinux
     7017.00  8.1% neigh_lookup            vmlinux
     4554.00  5.3% fib_semantic_match      vmlinux
     4067.00  4.7% _raw_read_lock          vmlinux
     3491.00  4.0% dst_alloc               vmlinux
     3186.00  3.7% neigh_resolve_output    vmlinux
     3103.00  3.6% fib_table_lookup        vmlinux
     2098.00  2.4% _raw_read_lock_bh       vmlinux
     2081.00  2.4% kmem_cache_alloc        vmlinux
     2013.00  2.3% _raw_spin_lock          vmlinux
     1763.00  2.0% __copy_from_user_ll     vmlinux
     1763.00  2.0% ip_output               vmlinux
     1761.00  2.0% ipv4_dst_destroy        vmlinux
     1631.00  1.9% eth_header              vmlinux
     1440.00  1.7% _raw_read_unlock_bh     vmlinux
    
    Reference results, if IP route cache is enabled :
    
    real    0m29.718s
    user    0m10.845s
    sys     7m37.341s
    
    25213.00 29.5% __ip_route_output_key   vmlinux
     9011.00 10.5% dst_release             vmlinux
     4817.00  5.6% ip_push_pending_frames  vmlinux
     4232.00  5.0% ip_finish_output        vmlinux
     3940.00  4.6% udp_sendmsg             vmlinux
     3730.00  4.4% __copy_from_user_ll     vmlinux
     3716.00  4.4% ip_route_output_flow    vmlinux
     2451.00  2.9% __xfrm_lookup           vmlinux
     2221.00  2.6% ip_append_data          vmlinux
     1718.00  2.0% _raw_spin_lock_bh       vmlinux
     1655.00  1.9% __alloc_skb             vmlinux
     1572.00  1.8% sock_wfree              vmlinux
     1345.00  1.6% kfree                   vmlinux
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6b7b329a3112648aa31e2d05db61f9bfd4a9b0b6
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 31 17:00:18 2010 -0700

    pid: make setpgid() system call use RCU read-side critical section
    
    commit 950eaaca681c44aab87a46225c9e44f902c080aa upstream.
    
    [   23.584719]
    [   23.584720] ===================================================
    [   23.585059] [ INFO: suspicious rcu_dereference_check() usage. ]
    [   23.585176] ---------------------------------------------------
    [   23.585176] kernel/pid.c:419 invoked rcu_dereference_check() without protection!
    [   23.585176]
    [   23.585176] other info that might help us debug this:
    [   23.585176]
    [   23.585176]
    [   23.585176] rcu_scheduler_active = 1, debug_locks = 1
    [   23.585176] 1 lock held by rc.sysinit/728:
    [   23.585176]  #0:  (tasklist_lock){.+.+..}, at: [<ffffffff8104771f>] sys_setpgid+0x5f/0x193
    [   23.585176]
    [   23.585176] stack backtrace:
    [   23.585176] Pid: 728, comm: rc.sysinit Not tainted 2.6.36-rc2 #2
    [   23.585176] Call Trace:
    [   23.585176]  [<ffffffff8105b436>] lockdep_rcu_dereference+0x99/0xa2
    [   23.585176]  [<ffffffff8104c324>] find_task_by_pid_ns+0x50/0x6a
    [   23.585176]  [<ffffffff8104c35b>] find_task_by_vpid+0x1d/0x1f
    [   23.585176]  [<ffffffff81047727>] sys_setpgid+0x67/0x193
    [   23.585176]  [<ffffffff810029eb>] system_call_fastpath+0x16/0x1b
    [   24.959669] type=1400 audit(1282938522.956:4): avc:  denied  { module_request } for  pid=766 comm="hwclock" kmod="char-major-10-135" scontext=system_u:system_r:hwclock_t:s0 tcontext=system_u:system_r:kernel_t:s0 tclas
    
    It turns out that the setpgid() system call fails to enter an RCU
    read-side critical section before doing a PID-to-task_struct translation.
    This commit therefore does rcu_read_lock() before the translation, and
    also does rcu_read_unlock() after the last use of the returned pointer.
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 7495973bc945e7f4962f676ad631492b2ba4c061
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 31 17:00:18 2010 -0700

    pid: make setpgid() system call use RCU read-side critical section
    
    commit 950eaaca681c44aab87a46225c9e44f902c080aa upstream.
    
    [   23.584719]
    [   23.584720] ===================================================
    [   23.585059] [ INFO: suspicious rcu_dereference_check() usage. ]
    [   23.585176] ---------------------------------------------------
    [   23.585176] kernel/pid.c:419 invoked rcu_dereference_check() without protection!
    [   23.585176]
    [   23.585176] other info that might help us debug this:
    [   23.585176]
    [   23.585176]
    [   23.585176] rcu_scheduler_active = 1, debug_locks = 1
    [   23.585176] 1 lock held by rc.sysinit/728:
    [   23.585176]  #0:  (tasklist_lock){.+.+..}, at: [<ffffffff8104771f>] sys_setpgid+0x5f/0x193
    [   23.585176]
    [   23.585176] stack backtrace:
    [   23.585176] Pid: 728, comm: rc.sysinit Not tainted 2.6.36-rc2 #2
    [   23.585176] Call Trace:
    [   23.585176]  [<ffffffff8105b436>] lockdep_rcu_dereference+0x99/0xa2
    [   23.585176]  [<ffffffff8104c324>] find_task_by_pid_ns+0x50/0x6a
    [   23.585176]  [<ffffffff8104c35b>] find_task_by_vpid+0x1d/0x1f
    [   23.585176]  [<ffffffff81047727>] sys_setpgid+0x67/0x193
    [   23.585176]  [<ffffffff810029eb>] system_call_fastpath+0x16/0x1b
    [   24.959669] type=1400 audit(1282938522.956:4): avc:  denied  { module_request } for  pid=766 comm="hwclock" kmod="char-major-10-135" scontext=system_u:system_r:hwclock_t:s0 tcontext=system_u:system_r:kernel_t:s0 tclas
    
    It turns out that the setpgid() system call fails to enter an RCU
    read-side critical section before doing a PID-to-task_struct translation.
    This commit therefore does rcu_read_lock() before the translation, and
    also does rcu_read_unlock() after the last use of the returned pointer.
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: David Howells <dhowells@redhat.com>
    Cc: Jiri Slaby <jslaby@suse.cz>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 15cdeadaa5d76009e20c7792aed69f5a73808f97
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Sep 21 21:17:32 2010 +0000

    netfilter: fix a race in nf_ct_ext_create()
    
    As soon as rcu_read_unlock() is called, there is no guarantee current
    thread can safely derefence t pointer, rcu protected.
    
    Fix is to copy t->alloc_size in a temporary variable.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 399fb5b445370ddcc93221e339d02736f55b9bb8
Author: Sven Eckelmann <sven.eckelmann@gmx.de>
Date:   Sat Sep 18 21:01:20 2010 +0200

    Staging: batman-adv: count batman_if list queries as reference
    
    The return of get_batman_if_by_netdev and get_active_batman_if leaks a
    pointer from the rcu protected list of interfaces. We must protect it to
    prevent a too early release of the memory. Those functions must increase
    the reference counter before rcu_read_unlock or it may be to late to
    prevent a free.
    
    hardif_add_interface must also increase the reference count for the
    returned batman_if to make the behaviour consistent.
    
    Reported-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Sven Eckelmann <sven.eckelmann@gmx.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 47f621dddc0b5ce3be4592a58e5f73707a83ad41
Author: Sven Eckelmann <sven.eckelmann@gmx.de>
Date:   Sat Sep 18 21:01:19 2010 +0200

    Staging: batman-adv: Use refcnt to track usage count of batman_if
    
    get_batman_if_by_netdev and get_active_batman_if may leak data from the
    rcu protected list of interfaces. The rcu protected list of all gateway
    nodes leaks the actual data outside the read-side critical area. This is
    not valid as we may free the data using a call_rcu created callback
    after we unlock using rcu_read_unlock. A workaround is to provide a
    reference count to be sure that the memory isn't freed to early.
    
    It is currently only to implement the already existing functionality and
    doesn't provide the full tracking of all usage cases.
    
    Additionally, we must hardif_hold inside the
    rcu_read_lock()..rcu_read_unlock() before we attach to the structure
    which "leaks" it. When another function now removed it from its usage
    context (primary_if, usage on stack, ...) then we must hardif_put it. If
    it is decremented to zero then we can issue the call_rcu to the freeing
    function. So "put" is not allowed inside an rcu_read_lock.
    
    Signed-off-by: Sven Eckelmann <sven.eckelmann@gmx.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 950eaaca681c44aab87a46225c9e44f902c080aa
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Aug 31 17:00:18 2010 -0700

    pid: make setpgid() system call use RCU read-side critical section
    
    [   23.584719]
    [   23.584720] ===================================================
    [   23.585059] [ INFO: suspicious rcu_dereference_check() usage. ]
    [   23.585176] ---------------------------------------------------
    [   23.585176] kernel/pid.c:419 invoked rcu_dereference_check() without protection!
    [   23.585176]
    [   23.585176] other info that might help us debug this:
    [   23.585176]
    [   23.585176]
    [   23.585176] rcu_scheduler_active = 1, debug_locks = 1
    [   23.585176] 1 lock held by rc.sysinit/728:
    [   23.585176]  #0:  (tasklist_lock){.+.+..}, at: [<ffffffff8104771f>] sys_setpgid+0x5f/0x193
    [   23.585176]
    [   23.585176] stack backtrace:
    [   23.585176] Pid: 728, comm: rc.sysinit Not tainted 2.6.36-rc2 #2
    [   23.585176] Call Trace:
    [   23.585176]  [<ffffffff8105b436>] lockdep_rcu_dereference+0x99/0xa2
    [   23.585176]  [<ffffffff8104c324>] find_task_by_pid_ns+0x50/0x6a
    [   23.585176]  [<ffffffff8104c35b>] find_task_by_vpid+0x1d/0x1f
    [   23.585176]  [<ffffffff81047727>] sys_setpgid+0x67/0x193
    [   23.585176]  [<ffffffff810029eb>] system_call_fastpath+0x16/0x1b
    [   24.959669] type=1400 audit(1282938522.956:4): avc:  denied  { module_request } for  pid=766 comm="hwclock" kmod="char-major-10-135" scontext=system_u:system_r:hwclock_t:s0 tcontext=system_u:system_r:kernel_t:s0 tclas
    
    It turns out that the setpgid() system call fails to enter an RCU
    read-side critical section before doing a PID-to-task_struct translation.
    This commit therefore does rcu_read_lock() before the translation, and
    also does rcu_read_unlock() after the last use of the returned pointer.
    
    Reported-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Acked-by: David Howells <dhowells@redhat.com>

commit dd7c4d89730a1be2c1d361a8ae1f0fe9465ccf9c
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Aug 27 10:51:17 2010 -0700

    rcu: performance fixes to TINY_PREEMPT_RCU callback checking
    
    This commit tightens up checks in rcu_preempt_check_callbacks() to avoid
    unnecessary special handling at rcu_read_unlock() time.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 80dcf60e6b97c7363971e7a0a788d8484d35f8a6
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Aug 19 16:57:45 2010 -0700

    rcu: apply TINY_PREEMPT_RCU read-side speedup to TREE_PREEMPT_RCU
    
    Replace one of the ACCESS_ONCE() calls in each of __rcu_read_lock()
    and __rcu_read_unlock() with barrier() as suggested by Steve Rostedt in
    order to avoid the potential compiler-optimization-induced bug noted by
    Mathieu Desnoyers.
    
    Located-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Suggested-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit a57eb940d130477a799dfb24a570ee04979c0f7f
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Tue Jun 29 16:49:16 2010 -0700

    rcu: Add a TINY_PREEMPT_RCU
    
    Implement a small-memory-footprint uniprocessor-only implementation of
    preemptible RCU.  This implementation uses but a single blocked-tasks
    list rather than the combinatorial number used per leaf rcu_node by
    TREE_PREEMPT_RCU, which reduces memory consumption and greatly simplifies
    processing.  This version also takes advantage of uniprocessor execution
    to accelerate grace periods in the case where there are no readers.
    
    The general design is otherwise broadly similar to that of TREE_PREEMPT_RCU.
    
    This implementation is a step towards having RCU implementation driven
    off of the SMP and PREEMPT kernel configuration variables, which can
    happen once this implementation has accumulated sufficient experience.
    
    Removed ACCESS_ONCE() from __rcu_read_unlock() and added barrier() as
    suggested by Steve Rostedt in order to avoid the compiler-reordering
    issue noted by Mathieu Desnoyers (http://lkml.org/lkml/2010/8/16/183).
    
    As can be seen below, CONFIG_TINY_PREEMPT_RCU represents almost 5Kbyte
    savings compared to CONFIG_TREE_PREEMPT_RCU.  Of course, for non-real-time
    workloads, CONFIG_TINY_RCU is even better.
    
            CONFIG_TREE_PREEMPT_RCU
    
               text    data     bss     dec    filename
                 13       0       0      13    kernel/rcupdate.o
               6170     825      28    7023    kernel/rcutree.o
                                       ----
                                       7026    Total
    
            CONFIG_TINY_PREEMPT_RCU
    
               text    data     bss     dec    filename
                 13       0       0      13    kernel/rcupdate.o
               2081      81       8    2170    kernel/rcutiny.o
                                       ----
                                       2183    Total
    
            CONFIG_TINY_RCU (non-preemptible)
    
               text    data     bss     dec    filename
                 13       0       0      13    kernel/rcupdate.o
                719      25       0     744    kernel/rcutiny.o
                                        ---
                                        757    Total
    
    Requested-by: Loc Minier <loic.minier@canonical.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>

commit 71cd03b0044183843318bfac0b6ce5868a96ef34
Author: Julia Lawall <julia@diku.dk>
Date:   Mon Aug 2 16:04:21 2010 -0700

    arch/sparc/mm: Use GFP_KERNEL
    
    GFP_ATOMIC is not needed here, as evidenced by the other two uses of
    GFP_KERNEL in the same function.
    
    The semantic match that finds this problem is as follows:
    (http://coccinelle.lip6.fr/)
    
    // <smpl>
    @@ identifier f; @@
    
    *f(...,GFP_ATOMIC,...)
    ... when != spin_unlock(...)
        when != read_unlock(...)
        when != write_unlock(...)
        when != read_unlock_irq(...)
        when != write_unlock_irq(...)
        when != read_unlock_irqrestore(...)
        when != write_unlock_irqrestore(...)
        when != spin_unlock_irq(...)
        when != spin_unlock_irqrestore(...)
    *f(...,GFP_KERNEL,...)
    // </smpl>
    
    Signed-off-by: Julia Lawall <julia@diku.dk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit e2e0c7c9ddbe6b79fe647aca5eea3a405d38ada4
Author: Julia Lawall <julia@diku.dk>
Date:   Fri Jul 30 23:56:39 2010 +0000

    net/rose: Use GFP_ATOMIC
    
    The other calls to kmalloc in the same function use GFP_ATOMIC, and indeed
    two locks are held within the body of the function.
    
    The semantic match that finds this problem is as follows:
    (http://coccinelle.lip6.fr/)
    
    // <smpl>
    @@ identifier f; @@
    
    *f(...,GFP_ATOMIC,...)
    ... when != spin_unlock(...)
        when != read_unlock(...)
        when != write_unlock(...)
        when != read_unlock_irq(...)
        when != write_unlock_irq(...)
        when != read_unlock_irqrestore(...)
        when != write_unlock_irqrestore(...)
        when != spin_unlock_irq(...)
        when != spin_unlock_irqrestore(...)
    *f(...,GFP_KERNEL,...)
    // </smpl>
    
    Signed-off-by: Julia Lawall <julia@diku.dk>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit de09a9771a5346029f4d11e4ac886be7f9bfdd75
Author: David Howells <dhowells@redhat.com>
Date:   Thu Jul 29 12:45:49 2010 +0100

    CRED: Fix get_task_cred() and task_state() to not resurrect dead credentials
    
    It's possible for get_task_cred() as it currently stands to 'corrupt' a set of
    credentials by incrementing their usage count after their replacement by the
    task being accessed.
    
    What happens is that get_task_cred() can race with commit_creds():
    
            TASK_1                  TASK_2                  RCU_CLEANER
            -->get_task_cred(TASK_2)
            rcu_read_lock()
            __cred = __task_cred(TASK_2)
                                    -->commit_creds()
                                    old_cred = TASK_2->real_cred
                                    TASK_2->real_cred = ...
                                    put_cred(old_cred)
                                      call_rcu(old_cred)
                    [__cred->usage == 0]
            get_cred(__cred)
                    [__cred->usage == 1]
            rcu_read_unlock()
                                                            -->put_cred_rcu()
                                                            [__cred->usage == 1]
                                                            panic()
    
    However, since a tasks credentials are generally not changed very often, we can
    reasonably make use of a loop involving reading the creds pointer and using
    atomic_inc_not_zero() to attempt to increment it if it hasn't already hit zero.
    
    If successful, we can safely return the credentials in the knowledge that, even
    if the task we're accessing has released them, they haven't gone to the RCU
    cleanup code.
    
    We then change task_state() in procfs to use get_task_cred() rather than
    calling get_cred() on the result of __task_cred(), as that suffers from the
    same problem.
    
    Without this change, a BUG_ON in __put_cred() or in put_cred_rcu() can be
    tripped when it is noticed that the usage count is not zero as it ought to be,
    for example:
    
    kernel BUG at kernel/cred.c:168!
    invalid opcode: 0000 [#1] SMP
    last sysfs file: /sys/kernel/mm/ksm/run
    CPU 0
    Pid: 2436, comm: master Not tainted 2.6.33.3-85.fc13.x86_64 #1 0HR330/OptiPlex
    745
    RIP: 0010:[<ffffffff81069881>]  [<ffffffff81069881>] __put_cred+0xc/0x45
    RSP: 0018:ffff88019e7e9eb8  EFLAGS: 00010202
    RAX: 0000000000000001 RBX: ffff880161514480 RCX: 00000000ffffffff
    RDX: 00000000ffffffff RSI: ffff880140c690c0 RDI: ffff880140c690c0
    RBP: ffff88019e7e9eb8 R08: 00000000000000d0 R09: 0000000000000000
    R10: 0000000000000001 R11: 0000000000000040 R12: ffff880140c690c0
    R13: ffff88019e77aea0 R14: 00007fff336b0a5c R15: 0000000000000001
    FS:  00007f12f50d97c0(0000) GS:ffff880007400000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f8f461bc000 CR3: 00000001b26ce000 CR4: 00000000000006f0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Process master (pid: 2436, threadinfo ffff88019e7e8000, task ffff88019e77aea0)
    Stack:
     ffff88019e7e9ec8 ffffffff810698cd ffff88019e7e9ef8 ffffffff81069b45
    <0> ffff880161514180 ffff880161514480 ffff880161514180 0000000000000000
    <0> ffff88019e7e9f28 ffffffff8106aace 0000000000000001 0000000000000246
    Call Trace:
     [<ffffffff810698cd>] put_cred+0x13/0x15
     [<ffffffff81069b45>] commit_creds+0x16b/0x175
     [<ffffffff8106aace>] set_current_groups+0x47/0x4e
     [<ffffffff8106ac89>] sys_setgroups+0xf6/0x105
     [<ffffffff81009b02>] system_call_fastpath+0x16/0x1b
    Code: 48 8d 71 ff e8 7e 4e 15 00 85 c0 78 0b 8b 75 ec 48 89 df e8 ef 4a 15 00
    48 83 c4 18 5b c9 c3 55 8b 07 8b 07 48 89 e5 85 c0 74 04 <0f> 0b eb fe 65 48 8b
    04 25 00 cc 00 00 48 3b b8 58 04 00 00 75
    RIP  [<ffffffff81069881>] __put_cred+0xc/0x45
     RSP <ffff88019e7e9eb8>
    ---[ end trace df391256a100ebdd ]---
    
    Signed-off-by: David Howells <dhowells@redhat.com>
    Acked-by: Jiri Olsa <jolsa@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit d8b6569a31e9dfa66fc85afe79dc9b3aed48a1c7
Author: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
Date:   Fri Apr 30 14:32:13 2010 +0100

    KEYS: find_keyring_by_name() can gain access to a freed keyring
    
    commit cea7daa3589d6b550546a8c8963599f7c1a3ae5c upstream.
    
    find_keyring_by_name() can gain access to a keyring that has had its reference
    count reduced to zero, and is thus ready to be freed.  This then allows the
    dead keyring to be brought back into use whilst it is being destroyed.
    
    The following timeline illustrates the process:
    
    |(cleaner)                           (user)
    |
    | free_user(user)                    sys_keyctl()
    |  |                                  |
    |  key_put(user->session_keyring)     keyctl_get_keyring_ID()
    |  ||   //=> keyring->usage = 0        |
    |  |schedule_work(&key_cleanup_task)   lookup_user_key()
    |  ||                                   |
    |  kmem_cache_free(,user)               |
    |  .                                    |[KEY_SPEC_USER_KEYRING]
    |  .                                    install_user_keyrings()
    |  .                                    ||
    | key_cleanup() [<= worker_thread()]    ||
    |  |                                    ||
    |  [spin_lock(&key_serial_lock)]        |[mutex_lock(&key_user_keyr..mutex)]
    |  |                                    ||
    |  atomic_read() == 0                   ||
    |  |{ rb_ease(&key->serial_node,) }     ||
    |  |                                    ||
    |  [spin_unlock(&key_serial_lock)]      |find_keyring_by_name()
    |  |                                    |||
    |  keyring_destroy(keyring)             ||[read_lock(&keyring_name_lock)]
    |  ||                                   |||
    |  |[write_lock(&keyring_name_lock)]    ||atomic_inc(&keyring->usage)
    |  |.                                   ||| *** GET freeing keyring ***
    |  |.                                   ||[read_unlock(&keyring_name_lock)]
    |  ||                                   ||
    |  |list_del()                          |[mutex_unlock(&key_user_k..mutex)]
    |  ||                                   |
    |  |[write_unlock(&keyring_name_lock)]  ** INVALID keyring is returned **
    |  |                                    .
    |  kmem_cache_free(,keyring)            .
    |                                       .
    |                                       atomic_dec(&keyring->usage)
    v                                         *** DESTROYED ***
    TIME
    
    If CONFIG_SLUB_DEBUG=y then we may see the following message generated:
    
            =============================================================================
            BUG key_jar: Poison overwritten
            -----------------------------------------------------------------------------
    
            INFO: 0xffff880197a7e200-0xffff880197a7e200. First byte 0x6a instead of 0x6b
            INFO: Allocated in key_alloc+0x10b/0x35f age=25 cpu=1 pid=5086
            INFO: Freed in key_cleanup+0xd0/0xd5 age=12 cpu=1 pid=10
            INFO: Slab 0xffffea000592cb90 objects=16 used=2 fp=0xffff880197a7e200 flags=0x200000000000c3
            INFO: Object 0xffff880197a7e200 @offset=512 fp=0xffff880197a7e300
    
            Bytes b4 0xffff880197a7e1f0:  5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a ZZZZZZZZZZZZZZZZ
              Object 0xffff880197a7e200:  6a 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b jkkkkkkkkkkkkkkk
    
    Alternatively, we may see a system panic happen, such as:
    
            BUG: unable to handle kernel NULL pointer dereference at 0000000000000001
            IP: [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            PGD 6b2b4067 PUD 6a80d067 PMD 0
            Oops: 0000 [#1] SMP
            last sysfs file: /sys/kernel/kexec_crash_loaded
            CPU 1
            ...
            Pid: 31245, comm: su Not tainted 2.6.34-rc5-nofixed-nodebug #2 D2089/PRIMERGY
            RIP: 0010:[<ffffffff810e61a3>]  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            RSP: 0018:ffff88006af3bd98  EFLAGS: 00010002
            RAX: 0000000000000000 RBX: 0000000000000001 RCX: ffff88007d19900b
            RDX: 0000000100000000 RSI: 00000000000080d0 RDI: ffffffff81828430
            RBP: ffffffff81828430 R08: ffff88000a293750 R09: 0000000000000000
            R10: 0000000000000001 R11: 0000000000100000 R12: 00000000000080d0
            R13: 00000000000080d0 R14: 0000000000000296 R15: ffffffff810f20ce
            FS:  00007f97116bc700(0000) GS:ffff88000a280000(0000) knlGS:0000000000000000
            CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
            CR2: 0000000000000001 CR3: 000000006a91c000 CR4: 00000000000006e0
            DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
            DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
            Process su (pid: 31245, threadinfo ffff88006af3a000, task ffff8800374414c0)
            Stack:
             0000000512e0958e 0000000000008000 ffff880037f8d180 0000000000000001
             0000000000000000 0000000000008001 ffff88007d199000 ffffffff810f20ce
             0000000000008000 ffff88006af3be48 0000000000000024 ffffffff810face3
            Call Trace:
             [<ffffffff810f20ce>] ? get_empty_filp+0x70/0x12f
             [<ffffffff810face3>] ? do_filp_open+0x145/0x590
             [<ffffffff810ce208>] ? tlb_finish_mmu+0x2a/0x33
             [<ffffffff810ce43c>] ? unmap_region+0xd3/0xe2
             [<ffffffff810e4393>] ? virt_to_head_page+0x9/0x2d
             [<ffffffff81103916>] ? alloc_fd+0x69/0x10e
             [<ffffffff810ef4ed>] ? do_sys_open+0x56/0xfc
             [<ffffffff81008a02>] ? system_call_fastpath+0x16/0x1b
            Code: 0f 1f 44 00 00 49 89 c6 fa 66 0f 1f 44 00 00 65 4c 8b 04 25 60 e8 00 00 48 8b 45 00 49 01 c0 49 8b 18 48 85 db 74 0d 48 63 45 18 <48> 8b 04 03 49 89 00 eb 14 4c 89 f9 83 ca ff 44 89 e6 48 89 ef
            RIP  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
    
    This problem is that find_keyring_by_name does not confirm that the keyring is
    valid before accepting it.
    
    Skipping keyrings that have been reduced to a zero count seems the way to go.
    To this end, use atomic_inc_not_zero() to increment the usage count and skip
    the candidate keyring if that returns false.
    
    The following script _may_ cause the bug to happen, but there's no guarantee
    as the window of opportunity is small:
    
            #!/bin/sh
            LOOP=100000
            USER=dummy_user
            /bin/su -c "exit;" $USER || { /usr/sbin/adduser -m $USER; add=1; }
            for ((i=0; i<LOOP; i++))
            do
                    /bin/su -c "echo '$i' > /dev/null" $USER
            done
            (( add == 1 )) && /usr/sbin/userdel -r $USER
            exit
    
    Note that the nominated user must not be in use.
    
    An alternative way of testing this may be:
    
            for ((i=0; i<100000; i++))
            do
                    keyctl session foo /bin/true || break
            done >&/dev/null
    
    as that uses a keyring named "foo" rather than relying on the user and
    user-session named keyrings.
    
    Reported-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Chuck Ebbert <cebbert@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 48b97a01ba4d411047dad9abce933301699cdf25
Author: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
Date:   Fri Apr 30 14:32:13 2010 +0100

    KEYS: find_keyring_by_name() can gain access to a freed keyring
    
    commit cea7daa3589d6b550546a8c8963599f7c1a3ae5c upstream.
    
    find_keyring_by_name() can gain access to a keyring that has had its reference
    count reduced to zero, and is thus ready to be freed.  This then allows the
    dead keyring to be brought back into use whilst it is being destroyed.
    
    The following timeline illustrates the process:
    
    |(cleaner)                           (user)
    |
    | free_user(user)                    sys_keyctl()
    |  |                                  |
    |  key_put(user->session_keyring)     keyctl_get_keyring_ID()
    |  ||   //=> keyring->usage = 0        |
    |  |schedule_work(&key_cleanup_task)   lookup_user_key()
    |  ||                                   |
    |  kmem_cache_free(,user)               |
    |  .                                    |[KEY_SPEC_USER_KEYRING]
    |  .                                    install_user_keyrings()
    |  .                                    ||
    | key_cleanup() [<= worker_thread()]    ||
    |  |                                    ||
    |  [spin_lock(&key_serial_lock)]        |[mutex_lock(&key_user_keyr..mutex)]
    |  |                                    ||
    |  atomic_read() == 0                   ||
    |  |{ rb_ease(&key->serial_node,) }     ||
    |  |                                    ||
    |  [spin_unlock(&key_serial_lock)]      |find_keyring_by_name()
    |  |                                    |||
    |  keyring_destroy(keyring)             ||[read_lock(&keyring_name_lock)]
    |  ||                                   |||
    |  |[write_lock(&keyring_name_lock)]    ||atomic_inc(&keyring->usage)
    |  |.                                   ||| *** GET freeing keyring ***
    |  |.                                   ||[read_unlock(&keyring_name_lock)]
    |  ||                                   ||
    |  |list_del()                          |[mutex_unlock(&key_user_k..mutex)]
    |  ||                                   |
    |  |[write_unlock(&keyring_name_lock)]  ** INVALID keyring is returned **
    |  |                                    .
    |  kmem_cache_free(,keyring)            .
    |                                       .
    |                                       atomic_dec(&keyring->usage)
    v                                         *** DESTROYED ***
    TIME
    
    If CONFIG_SLUB_DEBUG=y then we may see the following message generated:
    
            =============================================================================
            BUG key_jar: Poison overwritten
            -----------------------------------------------------------------------------
    
            INFO: 0xffff880197a7e200-0xffff880197a7e200. First byte 0x6a instead of 0x6b
            INFO: Allocated in key_alloc+0x10b/0x35f age=25 cpu=1 pid=5086
            INFO: Freed in key_cleanup+0xd0/0xd5 age=12 cpu=1 pid=10
            INFO: Slab 0xffffea000592cb90 objects=16 used=2 fp=0xffff880197a7e200 flags=0x200000000000c3
            INFO: Object 0xffff880197a7e200 @offset=512 fp=0xffff880197a7e300
    
            Bytes b4 0xffff880197a7e1f0:  5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a ZZZZZZZZZZZZZZZZ
              Object 0xffff880197a7e200:  6a 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b jkkkkkkkkkkkkkkk
    
    Alternatively, we may see a system panic happen, such as:
    
            BUG: unable to handle kernel NULL pointer dereference at 0000000000000001
            IP: [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            PGD 6b2b4067 PUD 6a80d067 PMD 0
            Oops: 0000 [#1] SMP
            last sysfs file: /sys/kernel/kexec_crash_loaded
            CPU 1
            ...
            Pid: 31245, comm: su Not tainted 2.6.34-rc5-nofixed-nodebug #2 D2089/PRIMERGY
            RIP: 0010:[<ffffffff810e61a3>]  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            RSP: 0018:ffff88006af3bd98  EFLAGS: 00010002
            RAX: 0000000000000000 RBX: 0000000000000001 RCX: ffff88007d19900b
            RDX: 0000000100000000 RSI: 00000000000080d0 RDI: ffffffff81828430
            RBP: ffffffff81828430 R08: ffff88000a293750 R09: 0000000000000000
            R10: 0000000000000001 R11: 0000000000100000 R12: 00000000000080d0
            R13: 00000000000080d0 R14: 0000000000000296 R15: ffffffff810f20ce
            FS:  00007f97116bc700(0000) GS:ffff88000a280000(0000) knlGS:0000000000000000
            CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
            CR2: 0000000000000001 CR3: 000000006a91c000 CR4: 00000000000006e0
            DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
            DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
            Process su (pid: 31245, threadinfo ffff88006af3a000, task ffff8800374414c0)
            Stack:
             0000000512e0958e 0000000000008000 ffff880037f8d180 0000000000000001
             0000000000000000 0000000000008001 ffff88007d199000 ffffffff810f20ce
             0000000000008000 ffff88006af3be48 0000000000000024 ffffffff810face3
            Call Trace:
             [<ffffffff810f20ce>] ? get_empty_filp+0x70/0x12f
             [<ffffffff810face3>] ? do_filp_open+0x145/0x590
             [<ffffffff810ce208>] ? tlb_finish_mmu+0x2a/0x33
             [<ffffffff810ce43c>] ? unmap_region+0xd3/0xe2
             [<ffffffff810e4393>] ? virt_to_head_page+0x9/0x2d
             [<ffffffff81103916>] ? alloc_fd+0x69/0x10e
             [<ffffffff810ef4ed>] ? do_sys_open+0x56/0xfc
             [<ffffffff81008a02>] ? system_call_fastpath+0x16/0x1b
            Code: 0f 1f 44 00 00 49 89 c6 fa 66 0f 1f 44 00 00 65 4c 8b 04 25 60 e8 00 00 48 8b 45 00 49 01 c0 49 8b 18 48 85 db 74 0d 48 63 45 18 <48> 8b 04 03 49 89 00 eb 14 4c 89 f9 83 ca ff 44 89 e6 48 89 ef
            RIP  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
    
    This problem is that find_keyring_by_name does not confirm that the keyring is
    valid before accepting it.
    
    Skipping keyrings that have been reduced to a zero count seems the way to go.
    To this end, use atomic_inc_not_zero() to increment the usage count and skip
    the candidate keyring if that returns false.
    
    The following script _may_ cause the bug to happen, but there's no guarantee
    as the window of opportunity is small:
    
            #!/bin/sh
            LOOP=100000
            USER=dummy_user
            /bin/su -c "exit;" $USER || { /usr/sbin/adduser -m $USER; add=1; }
            for ((i=0; i<LOOP; i++))
            do
                    /bin/su -c "echo '$i' > /dev/null" $USER
            done
            (( add == 1 )) && /usr/sbin/userdel -r $USER
            exit
    
    Note that the nominated user must not be in use.
    
    An alternative way of testing this may be:
    
            for ((i=0; i<100000; i++))
            do
                    keyctl session foo /bin/true || break
            done >&/dev/null
    
    as that uses a keyring named "foo" rather than relying on the user and
    user-session named keyrings.
    
    Reported-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Chuck Ebbert <cebbert@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 8e3c5b14d0aa33e347569e53f42f874a83f426c5
Author: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
Date:   Fri Apr 30 14:32:13 2010 +0100

    KEYS: find_keyring_by_name() can gain access to a freed keyring
    
    commit cea7daa3589d6b550546a8c8963599f7c1a3ae5c upstream.
    
    find_keyring_by_name() can gain access to a keyring that has had its reference
    count reduced to zero, and is thus ready to be freed.  This then allows the
    dead keyring to be brought back into use whilst it is being destroyed.
    
    The following timeline illustrates the process:
    
    |(cleaner)                           (user)
    |
    | free_user(user)                    sys_keyctl()
    |  |                                  |
    |  key_put(user->session_keyring)     keyctl_get_keyring_ID()
    |  ||   //=> keyring->usage = 0        |
    |  |schedule_work(&key_cleanup_task)   lookup_user_key()
    |  ||                                   |
    |  kmem_cache_free(,user)               |
    |  .                                    |[KEY_SPEC_USER_KEYRING]
    |  .                                    install_user_keyrings()
    |  .                                    ||
    | key_cleanup() [<= worker_thread()]    ||
    |  |                                    ||
    |  [spin_lock(&key_serial_lock)]        |[mutex_lock(&key_user_keyr..mutex)]
    |  |                                    ||
    |  atomic_read() == 0                   ||
    |  |{ rb_ease(&key->serial_node,) }     ||
    |  |                                    ||
    |  [spin_unlock(&key_serial_lock)]      |find_keyring_by_name()
    |  |                                    |||
    |  keyring_destroy(keyring)             ||[read_lock(&keyring_name_lock)]
    |  ||                                   |||
    |  |[write_lock(&keyring_name_lock)]    ||atomic_inc(&keyring->usage)
    |  |.                                   ||| *** GET freeing keyring ***
    |  |.                                   ||[read_unlock(&keyring_name_lock)]
    |  ||                                   ||
    |  |list_del()                          |[mutex_unlock(&key_user_k..mutex)]
    |  ||                                   |
    |  |[write_unlock(&keyring_name_lock)]  ** INVALID keyring is returned **
    |  |                                    .
    |  kmem_cache_free(,keyring)            .
    |                                       .
    |                                       atomic_dec(&keyring->usage)
    v                                         *** DESTROYED ***
    TIME
    
    If CONFIG_SLUB_DEBUG=y then we may see the following message generated:
    
            =============================================================================
            BUG key_jar: Poison overwritten
            -----------------------------------------------------------------------------
    
            INFO: 0xffff880197a7e200-0xffff880197a7e200. First byte 0x6a instead of 0x6b
            INFO: Allocated in key_alloc+0x10b/0x35f age=25 cpu=1 pid=5086
            INFO: Freed in key_cleanup+0xd0/0xd5 age=12 cpu=1 pid=10
            INFO: Slab 0xffffea000592cb90 objects=16 used=2 fp=0xffff880197a7e200 flags=0x200000000000c3
            INFO: Object 0xffff880197a7e200 @offset=512 fp=0xffff880197a7e300
    
            Bytes b4 0xffff880197a7e1f0:  5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a ZZZZZZZZZZZZZZZZ
              Object 0xffff880197a7e200:  6a 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b jkkkkkkkkkkkkkkk
    
    Alternatively, we may see a system panic happen, such as:
    
            BUG: unable to handle kernel NULL pointer dereference at 0000000000000001
            IP: [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            PGD 6b2b4067 PUD 6a80d067 PMD 0
            Oops: 0000 [#1] SMP
            last sysfs file: /sys/kernel/kexec_crash_loaded
            CPU 1
            ...
            Pid: 31245, comm: su Not tainted 2.6.34-rc5-nofixed-nodebug #2 D2089/PRIMERGY
            RIP: 0010:[<ffffffff810e61a3>]  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            RSP: 0018:ffff88006af3bd98  EFLAGS: 00010002
            RAX: 0000000000000000 RBX: 0000000000000001 RCX: ffff88007d19900b
            RDX: 0000000100000000 RSI: 00000000000080d0 RDI: ffffffff81828430
            RBP: ffffffff81828430 R08: ffff88000a293750 R09: 0000000000000000
            R10: 0000000000000001 R11: 0000000000100000 R12: 00000000000080d0
            R13: 00000000000080d0 R14: 0000000000000296 R15: ffffffff810f20ce
            FS:  00007f97116bc700(0000) GS:ffff88000a280000(0000) knlGS:0000000000000000
            CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
            CR2: 0000000000000001 CR3: 000000006a91c000 CR4: 00000000000006e0
            DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
            DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
            Process su (pid: 31245, threadinfo ffff88006af3a000, task ffff8800374414c0)
            Stack:
             0000000512e0958e 0000000000008000 ffff880037f8d180 0000000000000001
             0000000000000000 0000000000008001 ffff88007d199000 ffffffff810f20ce
             0000000000008000 ffff88006af3be48 0000000000000024 ffffffff810face3
            Call Trace:
             [<ffffffff810f20ce>] ? get_empty_filp+0x70/0x12f
             [<ffffffff810face3>] ? do_filp_open+0x145/0x590
             [<ffffffff810ce208>] ? tlb_finish_mmu+0x2a/0x33
             [<ffffffff810ce43c>] ? unmap_region+0xd3/0xe2
             [<ffffffff810e4393>] ? virt_to_head_page+0x9/0x2d
             [<ffffffff81103916>] ? alloc_fd+0x69/0x10e
             [<ffffffff810ef4ed>] ? do_sys_open+0x56/0xfc
             [<ffffffff81008a02>] ? system_call_fastpath+0x16/0x1b
            Code: 0f 1f 44 00 00 49 89 c6 fa 66 0f 1f 44 00 00 65 4c 8b 04 25 60 e8 00 00 48 8b 45 00 49 01 c0 49 8b 18 48 85 db 74 0d 48 63 45 18 <48> 8b 04 03 49 89 00 eb 14 4c 89 f9 83 ca ff 44 89 e6 48 89 ef
            RIP  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
    
    This problem is that find_keyring_by_name does not confirm that the keyring is
    valid before accepting it.
    
    Skipping keyrings that have been reduced to a zero count seems the way to go.
    To this end, use atomic_inc_not_zero() to increment the usage count and skip
    the candidate keyring if that returns false.
    
    The following script _may_ cause the bug to happen, but there's no guarantee
    as the window of opportunity is small:
    
            #!/bin/sh
            LOOP=100000
            USER=dummy_user
            /bin/su -c "exit;" $USER || { /usr/sbin/adduser -m $USER; add=1; }
            for ((i=0; i<LOOP; i++))
            do
                    /bin/su -c "echo '$i' > /dev/null" $USER
            done
            (( add == 1 )) && /usr/sbin/userdel -r $USER
            exit
    
    Note that the nominated user must not be in use.
    
    An alternative way of testing this may be:
    
            for ((i=0; i<100000; i++))
            do
                    keyctl session foo /bin/true || break
            done >&/dev/null
    
    as that uses a keyring named "foo" rather than relying on the user and
    user-session named keyrings.
    
    Reported-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>
    Cc: Ben Hutchings <ben@decadent.org.uk>
    Cc: Chuck Ebbert <cebbert@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 0e6f989ba83e6fa64e979d3488f01670b8be7959
Author: Julia Lawall <julia@diku.dk>
Date:   Sun Jun 20 11:24:54 2010 +0000

    arch/sh/mm: Eliminate a double lock
    
    The function begins and ends with a read_lock.  The latter is changed to a
    read_unlock.
    
    A simplified version of the semantic match that finds this problem is as
    follows: (http://coccinelle.lip6.fr/)
    
    // <smpl>
    @locked@
    expression E1;
    position p;
    @@
    
    read_lock(E1@p,...);
    
    @r exists@
    expression x <= locked.E1;
    expression locked.E1;
    expression E2;
    identifier lock;
    position locked.p,p1,p2;
    @@
    
    *lock@p1 (E1@p,...);
    ... when != E1
        when != \(x = E2\|&x\)
    *lock@p2 (E1,...);
    // </smpl>
    
    Signed-off-by: Julia Lawall <julia@diku.dk>
    Acked-by: Matt Fleming <matt@console-pimps.org>
    Signed-off-by: Paul Mundt <lethal@linux-sh.org>

commit c6d409cfd0fd41e7a0847875e4338ad648c9b96b
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Jun 3 20:03:40 2010 -0700

    From abbffa2aa9bd6f8df16d0d0a102af677510d8b9a Mon Sep 17 00:00:00 2001
    From: Eric Dumazet <eric.dumazet@gmail.com>
    Date: Thu, 3 Jun 2010 04:29:41 +0000
    Subject: [PATCH 2/3] net: net/socket.c and net/compat.c cleanups
    
    cleanup patch, to match modern coding style.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    ---
     net/compat.c |   47 ++++++++---------
     net/socket.c |  165 ++++++++++++++++++++++++++++------------------------------
     2 files changed, 102 insertions(+), 110 deletions(-)
    
    diff --git a/net/compat.c b/net/compat.c
    index 1cf7590..63d260e 100644
    --- a/net/compat.c
    +++ b/net/compat.c
    @@ -81,7 +81,7 @@ int verify_compat_iovec(struct msghdr *kern_msg, struct iovec *kern_iov,
            int tot_len;
    
            if (kern_msg->msg_namelen) {
    -               if (mode==VERIFY_READ) {
    +               if (mode == VERIFY_READ) {
                            int err = move_addr_to_kernel(kern_msg->msg_name,
                                                          kern_msg->msg_namelen,
                                                          kern_address);
    @@ -354,7 +354,7 @@ static int do_set_attach_filter(struct socket *sock, int level, int optname,
     static int do_set_sock_timeout(struct socket *sock, int level,
                    int optname, char __user *optval, unsigned int optlen)
     {
    -       struct compat_timeval __user *up = (struct compat_timeval __user *) optval;
    +       struct compat_timeval __user *up = (struct compat_timeval __user *)optval;
            struct timeval ktime;
            mm_segment_t old_fs;
            int err;
    @@ -367,7 +367,7 @@ static int do_set_sock_timeout(struct socket *sock, int level,
                    return -EFAULT;
            old_fs = get_fs();
            set_fs(KERNEL_DS);
    -       err = sock_setsockopt(sock, level, optname, (char *) &ktime, sizeof(ktime));
    +       err = sock_setsockopt(sock, level, optname, (char *)&ktime, sizeof(ktime));
            set_fs(old_fs);
    
            return err;
    @@ -389,11 +389,10 @@ asmlinkage long compat_sys_setsockopt(int fd, int level, int optname,
                                    char __user *optval, unsigned int optlen)
     {
            int err;
    -       struct socket *sock;
    +       struct socket *sock = sockfd_lookup(fd, &err);
    
    -       if ((sock = sockfd_lookup(fd, &err))!=NULL)
    -       {
    -               err = security_socket_setsockopt(sock,level,optname);
    +       if (sock) {
    +               err = security_socket_setsockopt(sock, level, optname);
                    if (err) {
                            sockfd_put(sock);
                            return err;
    @@ -453,7 +452,7 @@ static int compat_sock_getsockopt(struct socket *sock, int level, int optname,
     int compat_sock_get_timestamp(struct sock *sk, struct timeval __user *userstamp)
     {
            struct compat_timeval __user *ctv =
    -                       (struct compat_timeval __user*) userstamp;
    +                       (struct compat_timeval __user *) userstamp;
            int err = -ENOENT;
            struct timeval tv;
    
    @@ -477,7 +476,7 @@ EXPORT_SYMBOL(compat_sock_get_timestamp);
     int compat_sock_get_timestampns(struct sock *sk, struct timespec __user *userstamp)
     {
            struct compat_timespec __user *ctv =
    -                       (struct compat_timespec __user*) userstamp;
    +                       (struct compat_timespec __user *) userstamp;
            int err = -ENOENT;
            struct timespec ts;
    
    @@ -502,12 +501,10 @@ asmlinkage long compat_sys_getsockopt(int fd, int level, int optname,
                                    char __user *optval, int __user *optlen)
     {
            int err;
    -       struct socket *sock;
    +       struct socket *sock = sockfd_lookup(fd, &err);
    
    -       if ((sock = sockfd_lookup(fd, &err))!=NULL)
    -       {
    -               err = security_socket_getsockopt(sock, level,
    -                                                          optname);
    +       if (sock) {
    +               err = security_socket_getsockopt(sock, level, optname);
                    if (err) {
                            sockfd_put(sock);
                            return err;
    @@ -557,7 +554,7 @@ struct compat_group_filter {
    
     int compat_mc_setsockopt(struct sock *sock, int level, int optname,
            char __user *optval, unsigned int optlen,
    -       int (*setsockopt)(struct sock *,int,int,char __user *,unsigned int))
    +       int (*setsockopt)(struct sock *, int, int, char __user *, unsigned int))
     {
            char __user     *koptval = optval;
            int             koptlen = optlen;
    @@ -640,12 +637,11 @@ int compat_mc_setsockopt(struct sock *sock, int level, int optname,
            }
            return setsockopt(sock, level, optname, koptval, koptlen);
     }
    -
     EXPORT_SYMBOL(compat_mc_setsockopt);
    
     int compat_mc_getsockopt(struct sock *sock, int level, int optname,
            char __user *optval, int __user *optlen,
    -       int (*getsockopt)(struct sock *,int,int,char __user *,int __user *))
    +       int (*getsockopt)(struct sock *, int, int, char __user *, int __user *))
     {
            struct compat_group_filter __user *gf32 = (void *)optval;
            struct group_filter __user *kgf;
    @@ -681,7 +677,7 @@ int compat_mc_getsockopt(struct sock *sock, int level, int optname,
                __put_user(interface, &kgf->gf_interface) ||
                __put_user(fmode, &kgf->gf_fmode) ||
                __put_user(numsrc, &kgf->gf_numsrc) ||
    -           copy_in_user(&kgf->gf_group,&gf32->gf_group,sizeof(kgf->gf_group)))
    +           copy_in_user(&kgf->gf_group, &gf32->gf_group, sizeof(kgf->gf_group)))
                    return -EFAULT;
    
            err = getsockopt(sock, level, optname, (char __user *)kgf, koptlen);
    @@ -714,21 +710,22 @@ int compat_mc_getsockopt(struct sock *sock, int level, int optname,
                    copylen = numsrc * sizeof(gf32->gf_slist[0]);
                    if (copylen > klen)
                            copylen = klen;
    -               if (copy_in_user(gf32->gf_slist, kgf->gf_slist, copylen))
    +               if (copy_in_user(gf32->gf_slist, kgf->gf_slist, copylen))
                            return -EFAULT;
            }
            return err;
     }
    -
     EXPORT_SYMBOL(compat_mc_getsockopt);
    
     /* Argument list sizes for compat_sys_socketcall */
     #define AL(x) ((x) * sizeof(u32))
    -static unsigned char nas[20]={AL(0),AL(3),AL(3),AL(3),AL(2),AL(3),
    -                               AL(3),AL(3),AL(4),AL(4),AL(4),AL(6),
    -                               AL(6),AL(2),AL(5),AL(5),AL(3),AL(3),
    -                               AL(4),AL(5)};
    +static unsigned char nas[20] = {
    +       AL(0), AL(3), AL(3), AL(3), AL(2), AL(3),
    +       AL(3), AL(3), AL(4), AL(4), AL(4), AL(6),
    +       AL(6), AL(2), AL(5), AL(5), AL(3), AL(3),
    +       AL(4), AL(5)
    +};
     #undef AL
    
     asmlinkage long compat_sys_sendmsg(int fd, struct compat_msghdr __user *msg, unsigned flags)
    @@ -827,7 +824,7 @@ asmlinkage long compat_sys_socketcall(int call, u32 __user *args)
                                              compat_ptr(a[4]), compat_ptr(a[5]));
                    break;
            case SYS_SHUTDOWN:
    -               ret = sys_shutdown(a0,a1);
    +               ret = sys_shutdown(a0, a1);
                    break;
            case SYS_SETSOCKOPT:
                    ret = compat_sys_setsockopt(a0, a1, a[2],
    diff --git a/net/socket.c b/net/socket.c
    index 367d547..b63c051 100644
    --- a/net/socket.c
    +++ b/net/socket.c
    @@ -124,7 +124,7 @@ static int sock_fasync(int fd, struct file *filp, int on);
     static ssize_t sock_sendpage(struct file *file, struct page *page,
                                 int offset, size_t size, loff_t *ppos, int more);
     static ssize_t sock_splice_read(struct file *file, loff_t *ppos,
    -                               struct pipe_inode_info *pipe, size_t len,
    +                               struct pipe_inode_info *pipe, size_t len,
                                    unsigned int flags);
    
     /*
    @@ -162,7 +162,7 @@ static const struct net_proto_family *net_families[NPROTO] __read_mostly;
      *     Statistics counters of the socket lists
      */
    
    -static DEFINE_PER_CPU(int, sockets_in_use) = 0;
    +static DEFINE_PER_CPU(int, sockets_in_use);
    
     /*
      * Support routines.
    @@ -309,9 +309,9 @@ static int init_inodecache(void)
     }
    
     static const struct super_operations sockfs_ops = {
    -       .alloc_inode =  sock_alloc_inode,
    -       .destroy_inode =sock_destroy_inode,
    -       .statfs =       simple_statfs,
    +       .alloc_inode    = sock_alloc_inode,
    +       .destroy_inode  = sock_destroy_inode,
    +       .statfs         = simple_statfs,
     };
    
     static int sockfs_get_sb(struct file_system_type *fs_type,
    @@ -411,6 +411,7 @@ int sock_map_fd(struct socket *sock, int flags)
    
            return fd;
     }
    +EXPORT_SYMBOL(sock_map_fd);
    
     static struct socket *sock_from_file(struct file *file, int *err)
     {
    @@ -422,7 +423,7 @@ static struct socket *sock_from_file(struct file *file, int *err)
     }
    
     /**
    - *     sockfd_lookup   -       Go from a file number to its socket slot
    + *     sockfd_lookup - Go from a file number to its socket slot
      *     @fd: file handle
      *     @err: pointer to an error code return
      *
    @@ -450,6 +451,7 @@ struct socket *sockfd_lookup(int fd, int *err)
                    fput(file);
            return sock;
     }
    +EXPORT_SYMBOL(sockfd_lookup);
    
     static struct socket *sockfd_lookup_light(int fd, int *err, int *fput_needed)
     {
    @@ -540,6 +542,7 @@ void sock_release(struct socket *sock)
            }
            sock->file = NULL;
     }
    +EXPORT_SYMBOL(sock_release);
    
     int sock_tx_timestamp(struct msghdr *msg, struct sock *sk,
                          union skb_shared_tx *shtx)
    @@ -586,6 +589,7 @@ int sock_sendmsg(struct socket *sock, struct msghdr *msg, size_t size)
                    ret = wait_on_sync_kiocb(&iocb);
            return ret;
     }
    +EXPORT_SYMBOL(sock_sendmsg);
    
     int kernel_sendmsg(struct socket *sock, struct msghdr *msg,
                       struct kvec *vec, size_t num, size_t size)
    @@ -604,6 +608,7 @@ int kernel_sendmsg(struct socket *sock, struct msghdr *msg,
            set_fs(oldfs);
            return result;
     }
    +EXPORT_SYMBOL(kernel_sendmsg);
    
     static int ktime2ts(ktime_t kt, struct timespec *ts)
     {
    @@ -664,7 +669,6 @@ void __sock_recv_timestamp(struct msghdr *msg, struct sock *sk,
                    put_cmsg(msg, SOL_SOCKET,
                             SCM_TIMESTAMPING, sizeof(ts), &ts);
     }
    -
     EXPORT_SYMBOL_GPL(__sock_recv_timestamp);
    
     inline void sock_recv_drops(struct msghdr *msg, struct sock *sk, struct sk_buff *skb)
    @@ -720,6 +724,7 @@ int sock_recvmsg(struct socket *sock, struct msghdr *msg,
                    ret = wait_on_sync_kiocb(&iocb);
            return ret;
     }
    +EXPORT_SYMBOL(sock_recvmsg);
    
     static int sock_recvmsg_nosec(struct socket *sock, struct msghdr *msg,
                                  size_t size, int flags)
    @@ -752,6 +757,7 @@ int kernel_recvmsg(struct socket *sock, struct msghdr *msg,
            set_fs(oldfs);
            return result;
     }
    +EXPORT_SYMBOL(kernel_recvmsg);
    
     static void sock_aio_dtor(struct kiocb *iocb)
     {
    @@ -774,7 +780,7 @@ static ssize_t sock_sendpage(struct file *file, struct page *page,
     }
    
     static ssize_t sock_splice_read(struct file *file, loff_t *ppos,
    -                               struct pipe_inode_info *pipe, size_t len,
    +                               struct pipe_inode_info *pipe, size_t len,
                                    unsigned int flags)
     {
            struct socket *sock = file->private_data;
    @@ -887,7 +893,7 @@ static ssize_t sock_aio_write(struct kiocb *iocb, const struct iovec *iov,
      */
    
     static DEFINE_MUTEX(br_ioctl_mutex);
    -static int (*br_ioctl_hook) (struct net *, unsigned int cmd, void __user *arg) = NULL;
    +static int (*br_ioctl_hook) (struct net *, unsigned int cmd, void __user *arg);
    
     void brioctl_set(int (*hook) (struct net *, unsigned int, void __user *))
     {
    @@ -895,7 +901,6 @@ void brioctl_set(int (*hook) (struct net *, unsigned int, void __user *))
            br_ioctl_hook = hook;
            mutex_unlock(&br_ioctl_mutex);
     }
    -
     EXPORT_SYMBOL(brioctl_set);
    
     static DEFINE_MUTEX(vlan_ioctl_mutex);
    @@ -907,7 +912,6 @@ void vlan_ioctl_set(int (*hook) (struct net *, void __user *))
            vlan_ioctl_hook = hook;
            mutex_unlock(&vlan_ioctl_mutex);
     }
    -
     EXPORT_SYMBOL(vlan_ioctl_set);
    
     static DEFINE_MUTEX(dlci_ioctl_mutex);
    @@ -919,7 +923,6 @@ void dlci_ioctl_set(int (*hook) (unsigned int, void __user *))
            dlci_ioctl_hook = hook;
            mutex_unlock(&dlci_ioctl_mutex);
     }
    -
     EXPORT_SYMBOL(dlci_ioctl_set);
    
     static long sock_do_ioctl(struct net *net, struct socket *sock,
    @@ -1047,6 +1050,7 @@ out_release:
            sock = NULL;
            goto out;
     }
    +EXPORT_SYMBOL(sock_create_lite);
    
     /* No kernel lock held - perfect */
     static unsigned int sock_poll(struct file *file, poll_table *wait)
    @@ -1147,6 +1151,7 @@ call_kill:
            rcu_read_unlock();
            return 0;
     }
    +EXPORT_SYMBOL(sock_wake_async);
    
     static int __sock_create(struct net *net, int family, int type, int protocol,
                             struct socket **res, int kern)
    @@ -1265,11 +1270,13 @@ int sock_create(int family, int type, int protocol, struct socket **res)
     {
            return __sock_create(current->nsproxy->net_ns, family, type, protocol, res, 0);
     }
    +EXPORT_SYMBOL(sock_create);
    
     int sock_create_kern(int family, int type, int protocol, struct socket **res)
     {
            return __sock_create(&init_net, family, type, protocol, res, 1);
     }
    +EXPORT_SYMBOL(sock_create_kern);
    
     SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol)
     {
    @@ -1474,7 +1481,8 @@ SYSCALL_DEFINE4(accept4, int, fd, struct sockaddr __user *, upeer_sockaddr,
                    goto out;
    
            err = -ENFILE;
    -       if (!(newsock = sock_alloc()))
    +       newsock = sock_alloc();
    +       if (!newsock)
                    goto out_put;
    
            newsock->type = sock->type;
    @@ -1861,8 +1869,7 @@ SYSCALL_DEFINE3(sendmsg, int, fd, struct msghdr __user *, msg, unsigned, flags)
            if (MSG_CMSG_COMPAT & flags) {
                    if (get_compat_msghdr(&msg_sys, msg_compat))
                            return -EFAULT;
    -       }
    -       else if (copy_from_user(&msg_sys, msg, sizeof(struct msghdr)))
    +       } else if (copy_from_user(&msg_sys, msg, sizeof(struct msghdr)))
                    return -EFAULT;
    
            sock = sockfd_lookup_light(fd, &err, &fput_needed);
    @@ -1964,8 +1971,7 @@ static int __sys_recvmsg(struct socket *sock, struct msghdr __user *msg,
            if (MSG_CMSG_COMPAT & flags) {
                    if (get_compat_msghdr(msg_sys, msg_compat))
                            return -EFAULT;
    -       }
    -       else if (copy_from_user(msg_sys, msg, sizeof(struct msghdr)))
    +       } else if (copy_from_user(msg_sys, msg, sizeof(struct msghdr)))
                    return -EFAULT;
    
            err = -EMSGSIZE;
    @@ -2191,10 +2197,10 @@ SYSCALL_DEFINE5(recvmmsg, int, fd, struct mmsghdr __user *, mmsg,
     /* Argument list sizes for sys_socketcall */
     #define AL(x) ((x) * sizeof(unsigned long))
     static const unsigned char nargs[20] = {
    -       AL(0),AL(3),AL(3),AL(3),AL(2),AL(3),
    -       AL(3),AL(3),AL(4),AL(4),AL(4),AL(6),
    -       AL(6),AL(2),AL(5),AL(5),AL(3),AL(3),
    -       AL(4),AL(5)
    +       AL(0), AL(3), AL(3), AL(3), AL(2), AL(3),
    +       AL(3), AL(3), AL(4), AL(4), AL(4), AL(6),
    +       AL(6), AL(2), AL(5), AL(5), AL(3), AL(3),
    +       AL(4), AL(5)
     };
    
     #undef AL
    @@ -2340,6 +2346,7 @@ int sock_register(const struct net_proto_family *ops)
            printk(KERN_INFO "NET: Registered protocol family %d\n", ops->family);
            return err;
     }
    +EXPORT_SYMBOL(sock_register);
    
     /**
      *     sock_unregister - remove a protocol handler
    @@ -2366,6 +2373,7 @@ void sock_unregister(int family)
    
            printk(KERN_INFO "NET: Unregistered protocol family %d\n", family);
     }
    +EXPORT_SYMBOL(sock_unregister);
    
     static int __init sock_init(void)
     {
    @@ -2490,13 +2498,13 @@ static int dev_ifconf(struct net *net, struct compat_ifconf __user *uifc32)
                    ifc.ifc_req = NULL;
                    uifc = compat_alloc_user_space(sizeof(struct ifconf));
            } else {
    -               size_t len =((ifc32.ifc_len / sizeof (struct compat_ifreq)) + 1) *
    -                       sizeof (struct ifreq);
    +               size_t len = ((ifc32.ifc_len / sizeof(struct compat_ifreq)) + 1) *
    +                       sizeof(struct ifreq);
                    uifc = compat_alloc_user_space(sizeof(struct ifconf) + len);
                    ifc.ifc_len = len;
                    ifr = ifc.ifc_req = (void __user *)(uifc + 1);
                    ifr32 = compat_ptr(ifc32.ifcbuf);
    -               for (i = 0; i < ifc32.ifc_len; i += sizeof (struct compat_ifreq)) {
    +               for (i = 0; i < ifc32.ifc_len; i += sizeof(struct compat_ifreq)) {
                            if (copy_in_user(ifr, ifr32, sizeof(struct compat_ifreq)))
                                    return -EFAULT;
                            ifr++;
    @@ -2516,9 +2524,9 @@ static int dev_ifconf(struct net *net, struct compat_ifconf __user *uifc32)
            ifr = ifc.ifc_req;
            ifr32 = compat_ptr(ifc32.ifcbuf);
            for (i = 0, j = 0;
    -             i + sizeof (struct compat_ifreq) <= ifc32.ifc_len && j < ifc.ifc_len;
    -            i += sizeof (struct compat_ifreq), j += sizeof (struct ifreq)) {
    -               if (copy_in_user(ifr32, ifr, sizeof (struct compat_ifreq)))
    +            i + sizeof(struct compat_ifreq) <= ifc32.ifc_len && j < ifc.ifc_len;
    +            i += sizeof(struct compat_ifreq), j += sizeof(struct ifreq)) {
    +               if (copy_in_user(ifr32, ifr, sizeof(struct compat_ifreq)))
                            return -EFAULT;
                    ifr32++;
                    ifr++;
    @@ -2567,7 +2575,7 @@ static int compat_siocwandev(struct net *net, struct compat_ifreq __user *uifr32
            compat_uptr_t uptr32;
            struct ifreq __user *uifr;
    
    -       uifr = compat_alloc_user_space(sizeof (*uifr));
    +       uifr = compat_alloc_user_space(sizeof(*uifr));
            if (copy_in_user(uifr, uifr32, sizeof(struct compat_ifreq)))
                    return -EFAULT;
    
    @@ -2601,9 +2609,9 @@ static int bond_ioctl(struct net *net, unsigned int cmd,
                            return -EFAULT;
    
                    old_fs = get_fs();
    -               set_fs (KERNEL_DS);
    +               set_fs(KERNEL_DS);
                    err = dev_ioctl(net, cmd, &kifr);
    -               set_fs (old_fs);
    +               set_fs(old_fs);
    
                    return err;
            case SIOCBONDSLAVEINFOQUERY:
    @@ -2710,9 +2718,9 @@ static int compat_sioc_ifmap(struct net *net, unsigned int cmd,
                    return -EFAULT;
    
            old_fs = get_fs();
    -       set_fs (KERNEL_DS);
    +       set_fs(KERNEL_DS);
            err = dev_ioctl(net, cmd, (void __user *)&ifr);
    -       set_fs (old_fs);
    +       set_fs(old_fs);
    
            if (cmd == SIOCGIFMAP && !err) {
                    err = copy_to_user(uifr32, &ifr, sizeof(ifr.ifr_name));
    @@ -2734,7 +2742,7 @@ static int compat_siocshwtstamp(struct net *net, struct compat_ifreq __user *uif
            compat_uptr_t uptr32;
            struct ifreq __user *uifr;
    
    -       uifr = compat_alloc_user_space(sizeof (*uifr));
    +       uifr = compat_alloc_user_space(sizeof(*uifr));
            if (copy_in_user(uifr, uifr32, sizeof(struct compat_ifreq)))
                    return -EFAULT;
    
    @@ -2750,20 +2758,20 @@ static int compat_siocshwtstamp(struct net *net, struct compat_ifreq __user *uif
     }
    
     struct rtentry32 {
    -       u32             rt_pad1;
    +       u32             rt_pad1;
            struct sockaddr rt_dst;         /* target address               */
            struct sockaddr rt_gateway;     /* gateway addr (RTF_GATEWAY)   */
            struct sockaddr rt_genmask;     /* target network mask (IP)     */
    -       unsigned short  rt_flags;
    -       short           rt_pad2;
    -       u32             rt_pad3;
    -       unsigned char   rt_tos;
    -       unsigned char   rt_class;
    -       short           rt_pad4;
    -       short           rt_metric;      /* +1 for binary compatibility! */
    +       unsigned short  rt_flags;
    +       short           rt_pad2;
    +       u32             rt_pad3;
    +       unsigned char   rt_tos;
    +       unsigned char   rt_class;
    +       short           rt_pad4;
    +       short           rt_metric;      /* +1 for binary compatibility! */
            /* char * */ u32 rt_dev;        /* forcing the device at add    */
    -       u32             rt_mtu;         /* per route MTU/Window         */
    -       u32             rt_window;      /* Window clamping              */
    +       u32             rt_mtu;         /* per route MTU/Window         */
    +       u32             rt_window;      /* Window clamping              */
            unsigned short  rt_irtt;        /* Initial RTT                  */
     };
    
    @@ -2793,29 +2801,29 @@ static int routing_ioctl(struct net *net, struct socket *sock,
    
            if (sock && sock->sk && sock->sk->sk_family == AF_INET6) { /* ipv6 */
                    struct in6_rtmsg32 __user *ur6 = argp;
    -               ret = copy_from_user (&r6.rtmsg_dst, &(ur6->rtmsg_dst),
    +               ret = copy_from_user(&r6.rtmsg_dst, &(ur6->rtmsg_dst),
                            3 * sizeof(struct in6_addr));
    -               ret |= __get_user (r6.rtmsg_type, &(ur6->rtmsg_type));
    -               ret |= __get_user (r6.rtmsg_dst_len, &(ur6->rtmsg_dst_len));
    -               ret |= __get_user (r6.rtmsg_src_len, &(ur6->rtmsg_src_len));
    -               ret |= __get_user (r6.rtmsg_metric, &(ur6->rtmsg_metric));
    -               ret |= __get_user (r6.rtmsg_info, &(ur6->rtmsg_info));
    -               ret |= __get_user (r6.rtmsg_flags, &(ur6->rtmsg_flags));
    -               ret |= __get_user (r6.rtmsg_ifindex, &(ur6->rtmsg_ifindex));
    +               ret |= __get_user(r6.rtmsg_type, &(ur6->rtmsg_type));
    +               ret |= __get_user(r6.rtmsg_dst_len, &(ur6->rtmsg_dst_len));
    +               ret |= __get_user(r6.rtmsg_src_len, &(ur6->rtmsg_src_len));
    +               ret |= __get_user(r6.rtmsg_metric, &(ur6->rtmsg_metric));
    +               ret |= __get_user(r6.rtmsg_info, &(ur6->rtmsg_info));
    +               ret |= __get_user(r6.rtmsg_flags, &(ur6->rtmsg_flags));
    +               ret |= __get_user(r6.rtmsg_ifindex, &(ur6->rtmsg_ifindex));
    
                    r = (void *) &r6;
            } else { /* ipv4 */
                    struct rtentry32 __user *ur4 = argp;
    -               ret = copy_from_user (&r4.rt_dst, &(ur4->rt_dst),
    +               ret = copy_from_user(&r4.rt_dst, &(ur4->rt_dst),
                                            3 * sizeof(struct sockaddr));
    -               ret |= __get_user (r4.rt_flags, &(ur4->rt_flags));
    -               ret |= __get_user (r4.rt_metric, &(ur4->rt_metric));
    -               ret |= __get_user (r4.rt_mtu, &(ur4->rt_mtu));
    -               ret |= __get_user (r4.rt_window, &(ur4->rt_window));
    -               ret |= __get_user (r4.rt_irtt, &(ur4->rt_irtt));
    -               ret |= __get_user (rtdev, &(ur4->rt_dev));
    +               ret |= __get_user(r4.rt_flags, &(ur4->rt_flags));
    +               ret |= __get_user(r4.rt_metric, &(ur4->rt_metric));
    +               ret |= __get_user(r4.rt_mtu, &(ur4->rt_mtu));
    +               ret |= __get_user(r4.rt_window, &(ur4->rt_window));
    +               ret |= __get_user(r4.rt_irtt, &(ur4->rt_irtt));
    +               ret |= __get_user(rtdev, &(ur4->rt_dev));
                    if (rtdev) {
    -                       ret |= copy_from_user (devname, compat_ptr(rtdev), 15);
    +                       ret |= copy_from_user(devname, compat_ptr(rtdev), 15);
                            r4.rt_dev = devname; devname[15] = 0;
                    } else
                            r4.rt_dev = NULL;
    @@ -2828,9 +2836,9 @@ static int routing_ioctl(struct net *net, struct socket *sock,
                    goto out;
            }
    
    -       set_fs (KERNEL_DS);
    +       set_fs(KERNEL_DS);
            ret = sock_do_ioctl(net, sock, cmd, (unsigned long) r);
    -       set_fs (old_fs);
    +       set_fs(old_fs);
    
     out:
            return ret;
    @@ -2993,11 +3001,13 @@ int kernel_bind(struct socket *sock, struct sockaddr *addr, int addrlen)
     {
            return sock->ops->bind(sock, addr, addrlen);
     }
    +EXPORT_SYMBOL(kernel_bind);
    
     int kernel_listen(struct socket *sock, int backlog)
     {
            return sock->ops->listen(sock, backlog);
     }
    +EXPORT_SYMBOL(kernel_listen);
    
     int kernel_accept(struct socket *sock, struct socket **newsock, int flags)
     {
    @@ -3022,24 +3032,28 @@ int kernel_accept(struct socket *sock, struct socket **newsock, int flags)
     done:
            return err;
     }
    +EXPORT_SYMBOL(kernel_accept);
    
     int kernel_connect(struct socket *sock, struct sockaddr *addr, int addrlen,
                       int flags)
     {
            return sock->ops->connect(sock, addr, addrlen, flags);
     }
    +EXPORT_SYMBOL(kernel_connect);
    
     int kernel_getsockname(struct socket *sock, struct sockaddr *addr,
                             int *addrlen)
     {
            return sock->ops->getname(sock, addr, addrlen, 0);
     }
    +EXPORT_SYMBOL(kernel_getsockname);
    
     int kernel_getpeername(struct socket *sock, struct sockaddr *addr,
                             int *addrlen)
     {
            return sock->ops->getname(sock, addr, addrlen, 1);
     }
    +EXPORT_SYMBOL(kernel_getpeername);
    
     int kernel_getsockopt(struct socket *sock, int level, int optname,
                            char *optval, int *optlen)
    @@ -3056,6 +3070,7 @@ int kernel_getsockopt(struct socket *sock, int level, int optname,
            set_fs(oldfs);
            return err;
     }
    +EXPORT_SYMBOL(kernel_getsockopt);
    
     int kernel_setsockopt(struct socket *sock, int level, int optname,
                            char *optval, unsigned int optlen)
    @@ -3072,6 +3087,7 @@ int kernel_setsockopt(struct socket *sock, int level, int optname,
            set_fs(oldfs);
            return err;
     }
    +EXPORT_SYMBOL(kernel_setsockopt);
    
     int kernel_sendpage(struct socket *sock, struct page *page, int offset,
                        size_t size, int flags)
    @@ -3083,6 +3099,7 @@ int kernel_sendpage(struct socket *sock, struct page *page, int offset,
    
            return sock_no_sendpage(sock, page, offset, size, flags);
     }
    +EXPORT_SYMBOL(kernel_sendpage);
    
     int kernel_sock_ioctl(struct socket *sock, int cmd, unsigned long arg)
     {
    @@ -3095,33 +3112,11 @@ int kernel_sock_ioctl(struct socket *sock, int cmd, unsigned long arg)
    
            return err;
     }
    +EXPORT_SYMBOL(kernel_sock_ioctl);
    
     int kernel_sock_shutdown(struct socket *sock, enum sock_shutdown_cmd how)
     {
            return sock->ops->shutdown(sock, how);
     }
    -
    -EXPORT_SYMBOL(sock_create);
    -EXPORT_SYMBOL(sock_create_kern);
    -EXPORT_SYMBOL(sock_create_lite);
    -EXPORT_SYMBOL(sock_map_fd);
    -EXPORT_SYMBOL(sock_recvmsg);
    -EXPORT_SYMBOL(sock_register);
    -EXPORT_SYMBOL(sock_release);
    -EXPORT_SYMBOL(sock_sendmsg);
    -EXPORT_SYMBOL(sock_unregister);
    -EXPORT_SYMBOL(sock_wake_async);
    -EXPORT_SYMBOL(sockfd_lookup);
    -EXPORT_SYMBOL(kernel_sendmsg);
    -EXPORT_SYMBOL(kernel_recvmsg);
    -EXPORT_SYMBOL(kernel_bind);
    -EXPORT_SYMBOL(kernel_listen);
    -EXPORT_SYMBOL(kernel_accept);
    -EXPORT_SYMBOL(kernel_connect);
    -EXPORT_SYMBOL(kernel_getsockname);
    -EXPORT_SYMBOL(kernel_getpeername);
    -EXPORT_SYMBOL(kernel_getsockopt);
    -EXPORT_SYMBOL(kernel_setsockopt);
    -EXPORT_SYMBOL(kernel_sendpage);
    -EXPORT_SYMBOL(kernel_sock_ioctl);
     EXPORT_SYMBOL(kernel_sock_shutdown);
    +
    --
    1.7.0.4

commit 25502a6c13745f4650cc59322bd198194f55e796
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Thu Apr 1 17:37:01 2010 -0700

    rcu: refactor RCU's context-switch handling
    
    The addition of preemptible RCU to treercu resulted in a bit of
    confusion and inefficiency surrounding the handling of context switches
    for RCU-sched and for RCU-preempt.  For RCU-sched, a context switch
    is a quiescent state, pure and simple, just like it always has been.
    For RCU-preempt, a context switch is in no way a quiescent state, but
    special handling is required when a task blocks in an RCU read-side
    critical section.
    
    However, the callout from the scheduler and the outer loop in ksoftirqd
    still calls something named rcu_sched_qs(), whose name is no longer
    accurate.  Furthermore, when rcu_check_callbacks() notes an RCU-sched
    quiescent state, it ends up unnecessarily (though harmlessly, aside
    from the performance hit) enqueuing the current task if it happens to
    be running in an RCU-preempt read-side critical section.  This not only
    increases the maximum latency of scheduler_tick(), it also needlessly
    increases the overhead of the next outermost rcu_read_unlock() invocation.
    
    This patch addresses this situation by separating the notion of RCU's
    context-switch handling from that of RCU-sched's quiescent states.
    The context-switch handling is covered by rcu_note_context_switch() in
    general and by rcu_preempt_note_context_switch() for preemptible RCU.
    This permits rcu_sched_qs() to handle quiescent states and only quiescent
    states.  It also reduces the maximum latency of scheduler_tick(), though
    probably by much less than a microsecond.  Finally, it means that tasks
    within preemptible-RCU read-side critical sections avoid incurring the
    overhead of queuing unless there really is a context switch.
    
    Suggested-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Acked-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>

commit cea7daa3589d6b550546a8c8963599f7c1a3ae5c
Author: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
Date:   Fri Apr 30 14:32:13 2010 +0100

    KEYS: find_keyring_by_name() can gain access to a freed keyring
    
    find_keyring_by_name() can gain access to a keyring that has had its reference
    count reduced to zero, and is thus ready to be freed.  This then allows the
    dead keyring to be brought back into use whilst it is being destroyed.
    
    The following timeline illustrates the process:
    
    |(cleaner)                           (user)
    |
    | free_user(user)                    sys_keyctl()
    |  |                                  |
    |  key_put(user->session_keyring)     keyctl_get_keyring_ID()
    |  ||   //=> keyring->usage = 0        |
    |  |schedule_work(&key_cleanup_task)   lookup_user_key()
    |  ||                                   |
    |  kmem_cache_free(,user)               |
    |  .                                    |[KEY_SPEC_USER_KEYRING]
    |  .                                    install_user_keyrings()
    |  .                                    ||
    | key_cleanup() [<= worker_thread()]    ||
    |  |                                    ||
    |  [spin_lock(&key_serial_lock)]        |[mutex_lock(&key_user_keyr..mutex)]
    |  |                                    ||
    |  atomic_read() == 0                   ||
    |  |{ rb_ease(&key->serial_node,) }     ||
    |  |                                    ||
    |  [spin_unlock(&key_serial_lock)]      |find_keyring_by_name()
    |  |                                    |||
    |  keyring_destroy(keyring)             ||[read_lock(&keyring_name_lock)]
    |  ||                                   |||
    |  |[write_lock(&keyring_name_lock)]    ||atomic_inc(&keyring->usage)
    |  |.                                   ||| *** GET freeing keyring ***
    |  |.                                   ||[read_unlock(&keyring_name_lock)]
    |  ||                                   ||
    |  |list_del()                          |[mutex_unlock(&key_user_k..mutex)]
    |  ||                                   |
    |  |[write_unlock(&keyring_name_lock)]  ** INVALID keyring is returned **
    |  |                                    .
    |  kmem_cache_free(,keyring)            .
    |                                       .
    |                                       atomic_dec(&keyring->usage)
    v                                         *** DESTROYED ***
    TIME
    
    If CONFIG_SLUB_DEBUG=y then we may see the following message generated:
    
            =============================================================================
            BUG key_jar: Poison overwritten
            -----------------------------------------------------------------------------
    
            INFO: 0xffff880197a7e200-0xffff880197a7e200. First byte 0x6a instead of 0x6b
            INFO: Allocated in key_alloc+0x10b/0x35f age=25 cpu=1 pid=5086
            INFO: Freed in key_cleanup+0xd0/0xd5 age=12 cpu=1 pid=10
            INFO: Slab 0xffffea000592cb90 objects=16 used=2 fp=0xffff880197a7e200 flags=0x200000000000c3
            INFO: Object 0xffff880197a7e200 @offset=512 fp=0xffff880197a7e300
    
            Bytes b4 0xffff880197a7e1f0:  5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a 5a ZZZZZZZZZZZZZZZZ
              Object 0xffff880197a7e200:  6a 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b 6b jkkkkkkkkkkkkkkk
    
    Alternatively, we may see a system panic happen, such as:
    
            BUG: unable to handle kernel NULL pointer dereference at 0000000000000001
            IP: [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            PGD 6b2b4067 PUD 6a80d067 PMD 0
            Oops: 0000 [#1] SMP
            last sysfs file: /sys/kernel/kexec_crash_loaded
            CPU 1
            ...
            Pid: 31245, comm: su Not tainted 2.6.34-rc5-nofixed-nodebug #2 D2089/PRIMERGY
            RIP: 0010:[<ffffffff810e61a3>]  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
            RSP: 0018:ffff88006af3bd98  EFLAGS: 00010002
            RAX: 0000000000000000 RBX: 0000000000000001 RCX: ffff88007d19900b
            RDX: 0000000100000000 RSI: 00000000000080d0 RDI: ffffffff81828430
            RBP: ffffffff81828430 R08: ffff88000a293750 R09: 0000000000000000
            R10: 0000000000000001 R11: 0000000000100000 R12: 00000000000080d0
            R13: 00000000000080d0 R14: 0000000000000296 R15: ffffffff810f20ce
            FS:  00007f97116bc700(0000) GS:ffff88000a280000(0000) knlGS:0000000000000000
            CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
            CR2: 0000000000000001 CR3: 000000006a91c000 CR4: 00000000000006e0
            DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
            DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
            Process su (pid: 31245, threadinfo ffff88006af3a000, task ffff8800374414c0)
            Stack:
             0000000512e0958e 0000000000008000 ffff880037f8d180 0000000000000001
             0000000000000000 0000000000008001 ffff88007d199000 ffffffff810f20ce
             0000000000008000 ffff88006af3be48 0000000000000024 ffffffff810face3
            Call Trace:
             [<ffffffff810f20ce>] ? get_empty_filp+0x70/0x12f
             [<ffffffff810face3>] ? do_filp_open+0x145/0x590
             [<ffffffff810ce208>] ? tlb_finish_mmu+0x2a/0x33
             [<ffffffff810ce43c>] ? unmap_region+0xd3/0xe2
             [<ffffffff810e4393>] ? virt_to_head_page+0x9/0x2d
             [<ffffffff81103916>] ? alloc_fd+0x69/0x10e
             [<ffffffff810ef4ed>] ? do_sys_open+0x56/0xfc
             [<ffffffff81008a02>] ? system_call_fastpath+0x16/0x1b
            Code: 0f 1f 44 00 00 49 89 c6 fa 66 0f 1f 44 00 00 65 4c 8b 04 25 60 e8 00 00 48 8b 45 00 49 01 c0 49 8b 18 48 85 db 74 0d 48 63 45 18 <48> 8b 04 03 49 89 00 eb 14 4c 89 f9 83 ca ff 44 89 e6 48 89 ef
            RIP  [<ffffffff810e61a3>] kmem_cache_alloc+0x5b/0xe9
    
    This problem is that find_keyring_by_name does not confirm that the keyring is
    valid before accepting it.
    
    Skipping keyrings that have been reduced to a zero count seems the way to go.
    To this end, use atomic_inc_not_zero() to increment the usage count and skip
    the candidate keyring if that returns false.
    
    The following script _may_ cause the bug to happen, but there's no guarantee
    as the window of opportunity is small:
    
            #!/bin/sh
            LOOP=100000
            USER=dummy_user
            /bin/su -c "exit;" $USER || { /usr/sbin/adduser -m $USER; add=1; }
            for ((i=0; i<LOOP; i++))
            do
                    /bin/su -c "echo '$i' > /dev/null" $USER
            done
            (( add == 1 )) && /usr/sbin/userdel -r $USER
            exit
    
    Note that the nominated user must not be in use.
    
    An alternative way of testing this may be:
    
            for ((i=0; i<100000; i++))
            do
                    keyctl session foo /bin/true || break
            done >&/dev/null
    
    as that uses a keyring named "foo" rather than relying on the user and
    user-session named keyrings.
    
    Reported-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    Tested-by: Toshiyuki Okajima <toshi.okajima@jp.fujitsu.com>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

commit 43815482370c510c569fd18edb57afcb0fa8cab6
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Apr 29 11:01:49 2010 +0000

    net: sock_def_readable() and friends RCU conversion
    
    sk_callback_lock rwlock actually protects sk->sk_sleep pointer, so we
    need two atomic operations (and associated dirtying) per incoming
    packet.
    
    RCU conversion is pretty much needed :
    
    1) Add a new structure, called "struct socket_wq" to hold all fields
    that will need rcu_read_lock() protection (currently: a
    wait_queue_head_t and a struct fasync_struct pointer).
    
    [Future patch will add a list anchor for wakeup coalescing]
    
    2) Attach one of such structure to each "struct socket" created in
    sock_alloc_inode().
    
    3) Respect RCU grace period when freeing a "struct socket_wq"
    
    4) Change sk_sleep pointer in "struct sock" by sk_wq, pointer to "struct
    socket_wq"
    
    5) Change sk_sleep() function to use new sk->sk_wq instead of
    sk->sk_sleep
    
    6) Change sk_has_sleeper() to wq_has_sleeper() that must be used inside
    a rcu_read_lock() section.
    
    7) Change all sk_has_sleeper() callers to :
      - Use rcu_read_lock() instead of read_lock(&sk->sk_callback_lock)
      - Use wq_has_sleeper() to eventually wakeup tasks.
      - Use rcu_read_unlock() instead of read_unlock(&sk->sk_callback_lock)
    
    8) sock_wake_async() is modified to use rcu protection as well.
    
    9) Exceptions :
      macvtap, drivers/net/tun.c, af_unix use integrated "struct socket_wq"
    instead of dynamically allocated ones. They dont need rcu freeing.
    
    Some cleanups or followups are probably needed, (possible
    sk_callback_lock conversion to a spinlock for example...).
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a94b3267924327acf606ba22f4a5fb480e354da6
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Mar 12 20:03:30 2010 -0500

    tracing: Do not record user stack trace from NMI context
    
    commit b6345879ccbd9b92864fbd7eb8ac48acdb4d6b15 upstream.
    
    A bug was found with Li Zefan's ftrace_stress_test that caused applications
    to segfault during the test.
    
    Placing a tracing_off() in the segfault code, and examining several
    traces, I found that the following was always the case. The lock tracer
    was enabled (lockdep being required) and userstack was enabled. Testing
    this out, I just enabled the two, but that was not good enough. I needed
    to run something else that could trigger it. Running a load like hackbench
    did not work, but executing a new program would. The following would
    trigger the segfault within seconds:
    
      # echo 1 > /debug/tracing/options/userstacktrace
      # echo 1 > /debug/tracing/events/lock/enable
      # while :; do ls > /dev/null ; done
    
    Enabling the function graph tracer and looking at what was happening
    I finally noticed that all cashes happened just after an NMI.
    
     1)               |    copy_user_handle_tail() {
     1)               |      bad_area_nosemaphore() {
     1)               |        __bad_area_nosemaphore() {
     1)               |          no_context() {
     1)               |            fixup_exception() {
     1)   0.319 us    |              search_exception_tables();
     1)   0.873 us    |            }
    [...]
     1)   0.314 us    |  __rcu_read_unlock();
     1)   0.325 us    |    native_apic_mem_write();
     1)   0.943 us    |  }
     1)   0.304 us    |  rcu_nmi_exit();
    [...]
     1)   0.479 us    |  find_vma();
     1)               |  bad_area() {
     1)               |    __bad_area() {
    
    After capturing several traces of failures, all of them happened
    after an NMI. Curious about this, I added a trace_printk() to the NMI
    handler to read the regs->ip to see where the NMI happened. In which I
    found out it was here:
    
    ffffffff8135b660 <page_fault>:
    ffffffff8135b660:       48 83 ec 78             sub    $0x78,%rsp
    ffffffff8135b664:       e8 97 01 00 00          callq  ffffffff8135b800 <error_entry>
    
    What was happening is that the NMI would happen at the place that a page
    fault occurred. It would call rcu_read_lock() which was traced by
    the lock events, and the user_stack_trace would run. This would trigger
    a page fault inside the NMI. I do not see where the CR2 register is
    saved or restored in NMI handling. This means that it would corrupt
    the page fault handling that the NMI interrupted.
    
    The reason the while loop of ls helped trigger the bug, was that
    each execution of ls would cause lots of pages to be faulted in, and
    increase the chances of the race happening.
    
    The simple solution is to not allow user stack traces in NMI context.
    After this patch, I ran the above "ls" test for a couple of hours
    without any issues. Without this patch, the bug would trigger in less
    than a minute.
    
    Reported-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 80736c50f92cc545fe190d5ca47ca04fd3eca860
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Mar 12 20:03:30 2010 -0500

    tracing: Do not record user stack trace from NMI context
    
    commit b6345879ccbd9b92864fbd7eb8ac48acdb4d6b15 upstream.
    
    A bug was found with Li Zefan's ftrace_stress_test that caused applications
    to segfault during the test.
    
    Placing a tracing_off() in the segfault code, and examining several
    traces, I found that the following was always the case. The lock tracer
    was enabled (lockdep being required) and userstack was enabled. Testing
    this out, I just enabled the two, but that was not good enough. I needed
    to run something else that could trigger it. Running a load like hackbench
    did not work, but executing a new program would. The following would
    trigger the segfault within seconds:
    
      # echo 1 > /debug/tracing/options/userstacktrace
      # echo 1 > /debug/tracing/events/lock/enable
      # while :; do ls > /dev/null ; done
    
    Enabling the function graph tracer and looking at what was happening
    I finally noticed that all cashes happened just after an NMI.
    
     1)               |    copy_user_handle_tail() {
     1)               |      bad_area_nosemaphore() {
     1)               |        __bad_area_nosemaphore() {
     1)               |          no_context() {
     1)               |            fixup_exception() {
     1)   0.319 us    |              search_exception_tables();
     1)   0.873 us    |            }
    [...]
     1)   0.314 us    |  __rcu_read_unlock();
     1)   0.325 us    |    native_apic_mem_write();
     1)   0.943 us    |  }
     1)   0.304 us    |  rcu_nmi_exit();
    [...]
     1)   0.479 us    |  find_vma();
     1)               |  bad_area() {
     1)               |    __bad_area() {
    
    After capturing several traces of failures, all of them happened
    after an NMI. Curious about this, I added a trace_printk() to the NMI
    handler to read the regs->ip to see where the NMI happened. In which I
    found out it was here:
    
    ffffffff8135b660 <page_fault>:
    ffffffff8135b660:       48 83 ec 78             sub    $0x78,%rsp
    ffffffff8135b664:       e8 97 01 00 00          callq  ffffffff8135b800 <error_entry>
    
    What was happening is that the NMI would happen at the place that a page
    fault occurred. It would call rcu_read_lock() which was traced by
    the lock events, and the user_stack_trace would run. This would trigger
    a page fault inside the NMI. I do not see where the CR2 register is
    saved or restored in NMI handling. This means that it would corrupt
    the page fault handling that the NMI interrupted.
    
    The reason the while loop of ls helped trigger the bug, was that
    each execution of ls would cause lots of pages to be faulted in, and
    increase the chances of the race happening.
    
    The simple solution is to not allow user stack traces in NMI context.
    After this patch, I ran the above "ls" test for a couple of hours
    without any issues. Without this patch, the bug would trigger in less
    than a minute.
    
    Reported-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 2fb3573dfbca0bd853ddc1e47617eb446fa3deae
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Tue Mar 9 20:03:38 2010 +0000

    net: remove rcu locking from fib_rules_event()
    
    We hold RTNL at this point and dont use RCU variants of list traversals,
    we dont need rcu_read_lock()/rcu_read_unlock()
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b6345879ccbd9b92864fbd7eb8ac48acdb4d6b15
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Fri Mar 12 20:03:30 2010 -0500

    tracing: Do not record user stack trace from NMI context
    
    A bug was found with Li Zefan's ftrace_stress_test that caused applications
    to segfault during the test.
    
    Placing a tracing_off() in the segfault code, and examining several
    traces, I found that the following was always the case. The lock tracer
    was enabled (lockdep being required) and userstack was enabled. Testing
    this out, I just enabled the two, but that was not good enough. I needed
    to run something else that could trigger it. Running a load like hackbench
    did not work, but executing a new program would. The following would
    trigger the segfault within seconds:
    
      # echo 1 > /debug/tracing/options/userstacktrace
      # echo 1 > /debug/tracing/events/lock/enable
      # while :; do ls > /dev/null ; done
    
    Enabling the function graph tracer and looking at what was happening
    I finally noticed that all cashes happened just after an NMI.
    
     1)               |    copy_user_handle_tail() {
     1)               |      bad_area_nosemaphore() {
     1)               |        __bad_area_nosemaphore() {
     1)               |          no_context() {
     1)               |            fixup_exception() {
     1)   0.319 us    |              search_exception_tables();
     1)   0.873 us    |            }
    [...]
     1)   0.314 us    |  __rcu_read_unlock();
     1)   0.325 us    |    native_apic_mem_write();
     1)   0.943 us    |  }
     1)   0.304 us    |  rcu_nmi_exit();
    [...]
     1)   0.479 us    |  find_vma();
     1)               |  bad_area() {
     1)               |    __bad_area() {
    
    After capturing several traces of failures, all of them happened
    after an NMI. Curious about this, I added a trace_printk() to the NMI
    handler to read the regs->ip to see where the NMI happened. In which I
    found out it was here:
    
    ffffffff8135b660 <page_fault>:
    ffffffff8135b660:       48 83 ec 78             sub    $0x78,%rsp
    ffffffff8135b664:       e8 97 01 00 00          callq  ffffffff8135b800 <error_entry>
    
    What was happening is that the NMI would happen at the place that a page
    fault occurred. It would call rcu_read_lock() which was traced by
    the lock events, and the user_stack_trace would run. This would trigger
    a page fault inside the NMI. I do not see where the CR2 register is
    saved or restored in NMI handling. This means that it would corrupt
    the page fault handling that the NMI interrupted.
    
    The reason the while loop of ls helped trigger the bug, was that
    each execution of ls would cause lots of pages to be faulted in, and
    increase the chances of the race happening.
    
    The simple solution is to not allow user stack traces in NMI context.
    After this patch, I ran the above "ls" test for a couple of hours
    without any issues. Without this patch, the bug would trigger in less
    than a minute.
    
    Cc: stable@kernel.org
    Reported-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Steven Rostedt <rostedt@goodmis.org>

commit db2c4c7791cd04512093d05afc693c3511a65fd7
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Tue Feb 2 23:34:40 2010 +0100

    lockdep: Move lock events under lockdep recursion protection
    
    There are rcu locked read side areas in the path where we submit
    a trace event. And these rcu_read_(un)lock() trigger lock events,
    which create recursive events.
    
    One pair in do_perf_sw_event:
    
    __lock_acquire
          |
          |--96.11%-- lock_acquire
          |          |
          |          |--27.21%-- do_perf_sw_event
          |          |          perf_tp_event
          |          |          |
          |          |          |--49.62%-- ftrace_profile_lock_release
          |          |          |          lock_release
          |          |          |          |
          |          |          |          |--33.85%-- _raw_spin_unlock
    
    Another pair in perf_output_begin/end:
    
    __lock_acquire
          |--23.40%-- perf_output_begin
          |          |          __perf_event_overflow
          |          |          perf_swevent_overflow
          |          |          perf_swevent_add
          |          |          perf_swevent_ctx_event
          |          |          do_perf_sw_event
          |          |          perf_tp_event
          |          |          |
          |          |          |--55.37%-- ftrace_profile_lock_acquire
          |          |          |          lock_acquire
          |          |          |          |
          |          |          |          |--37.31%-- _raw_spin_lock
    
    The problem is not that much the trace recursion itself, as we have a
    recursion protection already (though it's always wasteful to recurse).
    But the trace events are outside the lockdep recursion protection, then
    each lockdep event triggers a lock trace, which will trigger two
    other lockdep events. Here the recursive lock trace event won't
    be taken because of the trace recursion, so the recursion stops there
    but lockdep will still analyse these new events:
    
    To sum up, for each lockdep events we have:
    
            lock_*()
                 |
                 trace lock_acquire
                      |
                      ----- rcu_read_lock()
                      |          |
                      |          lock_acquire()
                      |          |
                      |          trace_lock_acquire() (stopped)
                      |          |
                      |          lockdep analyze
                      |
                      ----- rcu_read_unlock()
                                 |
                                 lock_release
                                 |
                                 trace_lock_release() (stopped)
                                 |
                                 lockdep analyze
    
    And you can repeat the above two times as we have two rcu read side
    sections when we submit an event.
    
    This is fixed in this patch by moving the lock trace event under
    the lockdep recursion protection.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Hitoshi Mitake <mitake@dcl.info.waseda.ac.jp>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Jens Axboe <jens.axboe@oracle.com>

commit d1c9ae6d1e7b95cedc8e39e8949e795379a0669e
Author: Patrick McHardy <kaber@trash.net>
Date:   Tue Feb 2 11:46:50 2010 -0800

    ipv4: ip_fragment: fix unbalanced rcu_read_unlock()
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 3a4d5c94e959359ece6d6b55045c3f046677f55c
Author: Michael S. Tsirkin <mst@redhat.com>
Date:   Thu Jan 14 06:17:27 2010 +0000

    vhost_net: a kernel-level virtio server
    
    What it is: vhost net is a character device that can be used to reduce
    the number of system calls involved in virtio networking.
    Existing virtio net code is used in the guest without modification.
    
    There's similarity with vringfd, with some differences and reduced scope
    - uses eventfd for signalling
    - structures can be moved around in memory at any time (good for
      migration, bug work-arounds in userspace)
    - write logging is supported (good for migration)
    - support memory table and not just an offset (needed for kvm)
    
    common virtio related code has been put in a separate file vhost.c and
    can be made into a separate module if/when more backends appear.  I used
    Rusty's lguest.c as the source for developing this part : this supplied
    me with witty comments I wouldn't be able to write myself.
    
    What it is not: vhost net is not a bus, and not a generic new system
    call. No assumptions are made on how guest performs hypercalls.
    Userspace hypervisors are supported as well as kvm.
    
    How it works: Basically, we connect virtio frontend (configured by
    userspace) to a backend. The backend could be a network device, or a tap
    device.  Backend is also configured by userspace, including vlan/mac
    etc.
    
    Status: This works for me, and I haven't see any crashes.
    Compared to userspace, people reported improved latency (as I save up to
    4 system calls per packet), as well as better bandwidth and CPU
    utilization.
    
    Features that I plan to look at in the future:
    - mergeable buffers
    - zero copy
    - scalability tuning: figure out the best threading model to use
    
    Note on RCU usage (this is also documented in vhost.h, near
    private_pointer which is the value protected by this variant of RCU):
    what is happening is that the rcu_dereference() is being used in a
    workqueue item.  The role of rcu_read_lock() is taken on by the start of
    execution of the workqueue item, of rcu_read_unlock() by the end of
    execution of the workqueue item, and of synchronize_rcu() by
    flush_workqueue()/flush_work(). In the future we might need to apply
    some gcc attribute or sparse annotation to the function passed to
    INIT_WORK(). Paul's ack below is for this RCU usage.
    
    (Includes fixes by Alan Cox <alan@linux.intel.com>,
    David L Stevens <dlstevens@us.ibm.com>,
    Chris Wright <chrisw@redhat.com>)
    
    Acked-by: Rusty Russell <rusty@rustcorp.com.au>
    Acked-by: Arnd Bergmann <arnd@arndb.de>
    Acked-by: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit cba8244a0f1c277b6b1e48ed6504fa434119e24d
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Jan 4 16:04:01 2010 -0800

    rcu: Add debug check for too many rcu_read_unlock()
    
    TREE_PREEMPT_RCU maintains an rcu_read_lock_nesting counter in
    the task structure, which happens to be a signed int.  So this
    patch adds a check for this counter being negative at the end of
    __rcu_read_unlock(). This check is under CONFIG_PROVE_LOCKING,
    so can be thought of as being part of lockdep.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    LKML-Reference: <12626498423064-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 846f99749ab68bbc7f75c74fec305de675b1a1bf
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Sat Jan 2 13:37:12 2010 -0800

    sysfs: Add lockdep annotations for the sysfs active reference
    
    Holding locks over device_del -> kobject_del -> sysfs_deactivate can
    cause deadlocks if those same locks are grabbed in sysfs show or store
    methods.
    
    The I model s_active count + completion as a sleeping read/write lock.
    I describe to lockdep sysfs_get_active as a read_trylock,
    sysfs_put_active as a read_unlock, and sysfs_deactivate as a
    write_lock and write_unlock pair.  This seems to capture the essence
    for purposes of finding deadlocks, and in my testing gives finds real
    issues and ignores non-issues.
    
    This brings us back to holding locks over kobject_del is a problem
    that ideally we should find a way of addressing, but at least lockdep
    can tell us about the problems instead of requiring developers to debug
    rare strange system deadlocks, that happen when sysfs files are removed
    while being written to.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit fdb8ebb729bbb640e64028a4f579a02ebc405727
Author: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
Date:   Tue Dec 8 09:34:43 2009 +0900

    TOMOYO: Use RCU primitives for list operation
    
    Replace list operation with RCU primitives and replace
    down_read()/up_read() with srcu_read_lock()/srcu_read_unlock().
    
    Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
    Acked-by: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: James Morris <jmorris@namei.org>

commit 415cc7b7fe6fd663139da295d7bd2cde556345f0
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Oct 14 16:58:03 2009 +1100

    perf_event: Adjust frequency and unthrottle for non-group-leader events
    
    commit 03541f8b69c058162e4cf9675ec9181e6a204d55 upstream.
    
    The loop in perf_ctx_adjust_freq checks the frequency of sampling
    event counters, and adjusts the event interval and unthrottles the
    event if required, and resets the interrupt count for the event.
    However, at present it only looks at group leaders.
    
    This means that a sampling event that is not a group leader will
    eventually get throttled, once its interrupt count reaches
    sysctl_perf_event_sample_rate/HZ --- and that is guaranteed to
    happen, if the event is active for long enough, since the interrupt
    count never gets reset.  Once it is throttled it never gets
    unthrottled, so it basically just stops working at that point.
    
    This fixes it by making perf_ctx_adjust_freq use ctx->event_list
    rather than ctx->group_list.  The existing spin_lock/spin_unlock
    around the loop makes it unnecessary to put rcu_read_lock/
    rcu_read_unlock around the list_for_each_entry_rcu().
    
    Reported-by: Mark W. Krentel <krentel@cs.rice.edu>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <19157.26731.855609.165622@cargo.ozlabs.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 7f33f9c5cc3c99aeaf4d266a7ed502b828115a53
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sat Dec 5 12:01:17 2009 +0100

    x86/perf: Exclude the debug stack from the callchains
    
    Dumping the callchains from breakpoint events with perf gives strange
    results:
    
    3.75%             perf  [kernel]           [k] _raw_read_unlock
                           |
                           --- _raw_read_unlock
                               perf_callchain
                               perf_prepare_sample
                               __perf_event_overflow
                               perf_swevent_overflow
                               perf_swevent_add
                               perf_bp_event
                               hw_breakpoint_exceptions_notify
                               notifier_call_chain
                               __atomic_notifier_call_chain
                               atomic_notifier_call_chain
                               notify_die
                               do_debug
                               debug
                               munmap
    
    We are infected with all the debug stack. Like the nmi stack, the debug
    stack is undesired as it is part of the profiling path, not helpful for
    the user.
    
    Ignore it.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: "K. Prasad" <prasad@linux.vnet.ibm.com>

commit 3305443c968b98902199bea0abbd9443c6a2bb8d
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Fri Nov 20 10:09:14 2009 +0100

    mac80211: fix rcu locking
    
    Add a missing rcu_read_unlock() before jumping out
    of the ieee80211_change_station() function in the
    error case.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 1b290d670ffa883b7e062177463a8efd00eaa2c1
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Mon Nov 23 15:42:35 2009 +0100

    perf tools: Add support for breakpoint events in perf tools
    
    Add the breakpoint events support with this new sysnopsis:
    
      mem:addr[:access]
    
    Where addr is a raw addr value in the kernel and access can be
    either [r][w][x]
    
    Example to profile tasklist_lock:
    
            $ grep tasklist_lock /proc/kallsyms
            ffffffff8189c000 D tasklist_lock
    
            $ perf record -e mem:0xffffffff8189c000:rw -a -f -c 1
            $ perf report
    
            # Samples: 62
            #
            # Overhead          Command  Shared Object  Symbol
            # ........  ...............  .............  ......
            #
                29.03%          swapper  [kernel]       [k] _raw_read_trylock
                29.03%          swapper  [kernel]       [k] _raw_read_unlock
                19.35%             init  [kernel]       [k] _raw_read_trylock
                19.35%             init  [kernel]       [k] _raw_read_unlock
                 1.61%         events/0  [kernel]       [k] _raw_read_trylock
                 1.61%         events/0  [kernel]       [k] _raw_read_unlock
    
    Coming soon:
    
     - Support for symbols in the event definition.
    
     - Default period to 1 for breakpoint events because these are
       not high frequency events. The same thing is needed for trace
       events.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Prasad <prasad@linux.vnet.ibm.com>
    LKML-Reference: <1258987355-8751-4-git-send-email-fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Prasad <prasad@linux.vnet.ibm.com>

commit b668c9cf3e58739dac54a1d6f42f2b4bdd980b3e
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun Nov 22 08:53:48 2009 -0800

    rcu: Fix grace-period-stall bug on large systems with CPU hotplug
    
    When the last CPU of a given leaf rcu_node structure goes
    offline, all of the tasks queued on that leaf rcu_node structure
    (due to having blocked in their current RCU read-side critical
    sections) are requeued onto the root rcu_node structure.  This
    requeuing is carried out by rcu_preempt_offline_tasks().
    However, it is possible that these queued tasks are the only
    thing preventing the leaf rcu_node structure from reporting a
    quiescent state up the rcu_node hierarchy.  Unfortunately, the
    old code would fail to do this reporting, resulting in a
    grace-period stall given the following sequence of events:
    
    1.      Kernel built for more than 32 CPUs on 32-bit systems or for more
            than 64 CPUs on 64-bit systems, so that there is more than one
            rcu_node structure.  (Or CONFIG_RCU_FANOUT is artificially set
            to a number smaller than CONFIG_NR_CPUS.)
    
    2.      The kernel is built with CONFIG_TREE_PREEMPT_RCU.
    
    3.      A task running on a CPU associated with a given leaf rcu_node
            structure blocks while in an RCU read-side critical section
            -and- that CPU has not yet passed through a quiescent state
            for the current RCU grace period.  This will cause the task
            to be queued on the leaf rcu_node's blocked_tasks[] array, in
            particular, on the element of this array corresponding to the
            current grace period.
    
    4.      Each of the remaining CPUs corresponding to this same leaf rcu_node
            structure pass through a quiescent state.  However, the task is
            still in its RCU read-side critical section, so these quiescent
            states cannot be reported further up the rcu_node hierarchy.
            Nevertheless, all bits in the leaf rcu_node structure's ->qsmask
            field are now zero.
    
    5.      Each of the remaining CPUs go offline.  (The events in step
            #4 and #5 can happen in any order as long as each CPU passes
            through a quiescent state before going offline.)
    
    6.      When the last CPU goes offline, __rcu_offline_cpu() will invoke
            rcu_preempt_offline_tasks(), which will move the task to the
            root rcu_node structure, but without reporting a quiescent state
            up the rcu_node hierarchy (and this failure to report a quiescent
            state is the bug).
    
            But because this leaf rcu_node structure's ->qsmask field is
            already zero and its ->block_tasks[] entries are all empty,
            force_quiescent_state() will skip this rcu_node structure.
    
            Therefore, grace periods are now hung.
    
    This patch abstracts some code out of rcu_read_unlock_special(),
    calling the result task_quiet() by analogy with cpu_quiet(), and
    invokes task_quiet() from both rcu_read_lock_special() and
    __rcu_offline_cpu().  Invoking task_quiet() from
    __rcu_offline_cpu() reports the quiescent state up the rcu_node
    hierarchy, fixing the bug.  This ends up requiring a separate
    lock_class_key per level of the rcu_node hierarchy, which this
    patch also provides.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    LKML-Reference: <12589088301770-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 444a2a3bcd6d5bed5c823136f68fcc93c0fe283f
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Fri Nov 6 04:13:05 2009 +0100

    tracing, perf_events: Protect the buffer from recursion in perf
    
    While tracing using events with perf, if one enables the
    lockdep:lock_acquire event, it will infect every other perf
    trace events.
    
    Basically, you can enable whatever set of trace events through
    perf but if this event is part of the set, the only result we
    can get is a long list of lock_acquire events of rcu read lock,
    and only that.
    
    This is because of a recursion inside perf.
    
    1) When a trace event is triggered, it will fill a per cpu
       buffer and submit it to perf.
    
    2) Perf will commit this event but will also protect some data
       using rcu_read_lock
    
    3) A recursion appears: rcu_read_lock triggers a lock_acquire
       event that will fill the per cpu event and then submit the
       buffer to perf.
    
    4) Perf detects a recursion and ignores it
    
    5) Perf continues its work on the previous event, but its buffer
       has been overwritten by the lock_acquire event, it has then
       been turned into a lock_acquire event of rcu read lock
    
    Such scenario also happens with lock_release with
    rcu_read_unlock().
    
    We could turn the rcu_read_lock() into __rcu_read_lock() to drop
    the lock debugging from perf fast path, but that would make us
    lose the rcu debugging and that doesn't prevent from other
    possible kind of recursion from perf in the future.
    
    This patch adds a recursion protection based on a counter on the
    perf trace per cpu buffers to solve the problem.
    
    -v2: Fixed lost whitespace, added reviewed-by tag
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Reviewed-by: Masami Hiramatsu <mhiramat@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Jason Baron <jbaron@redhat.com>
    LKML-Reference: <1257477185-7838-1-git-send-email-fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit c6d14c84566d6b70ad9dc1618db0dec87cca9300
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Wed Nov 4 05:43:23 2009 -0800

    net: Introduce for_each_netdev_rcu() iterator
    
    Adds RCU management to the list of netdevices.
    
    Convert some for_each_netdev() users to RCU version, if
    it can avoid read_lock-ing dev_base_lock
    
    Ie:
            read_lock(&dev_base_loack);
            for_each_netdev(net, dev)
                    some_action();
            read_unlock(&dev_base_lock);
    
    becomes :
    
            rcu_read_lock();
            for_each_netdev_rcu(net, dev)
                    some_action();
            rcu_read_unlock();
    
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 45054dc1bf2367ccb0e7c0486037907cd9395f8b
Author: Dave Young <hidave.darkstar@gmail.com>
Date:   Sun Oct 18 20:28:30 2009 +0000

    bluetooth: static lock key fix
    
    When shutdown ppp connection, lockdep waring about non-static key
    will happen, it is caused by the lock is not initialized properly
    at that time.
    
    Fix with tuning the lock/skb_queue_head init order
    
    [   94.339261] INFO: trying to register non-static key.
    [   94.342509] the code is fine but needs lockdep annotation.
    [   94.342509] turning off the locking correctness validator.
    [   94.342509] Pid: 0, comm: swapper Not tainted 2.6.31-mm1 #2
    [   94.342509] Call Trace:
    [   94.342509]  [<c0248fbe>] register_lock_class+0x58/0x241
    [   94.342509]  [<c024b5df>] ? __lock_acquire+0xb57/0xb73
    [   94.342509]  [<c024ab34>] __lock_acquire+0xac/0xb73
    [   94.342509]  [<c024b7fa>] ? lock_release_non_nested+0x17b/0x1de
    [   94.342509]  [<c024b662>] lock_acquire+0x67/0x84
    [   94.342509]  [<c04cd1eb>] ? skb_dequeue+0x15/0x41
    [   94.342509]  [<c054a857>] _spin_lock_irqsave+0x2f/0x3f
    [   94.342509]  [<c04cd1eb>] ? skb_dequeue+0x15/0x41
    [   94.342509]  [<c04cd1eb>] skb_dequeue+0x15/0x41
    [   94.342509]  [<c054a648>] ? _read_unlock+0x1d/0x20
    [   94.342509]  [<c04cd641>] skb_queue_purge+0x14/0x1b
    [   94.342509]  [<fab94fdc>] l2cap_recv_frame+0xea1/0x115a [l2cap]
    [   94.342509]  [<c024b5df>] ? __lock_acquire+0xb57/0xb73
    [   94.342509]  [<c0249c04>] ? mark_lock+0x1e/0x1c7
    [   94.342509]  [<f8364963>] ? hci_rx_task+0xd2/0x1bc [bluetooth]
    [   94.342509]  [<fab95346>] l2cap_recv_acldata+0xb1/0x1c6 [l2cap]
    [   94.342509]  [<f8364997>] hci_rx_task+0x106/0x1bc [bluetooth]
    [   94.342509]  [<fab95295>] ? l2cap_recv_acldata+0x0/0x1c6 [l2cap]
    [   94.342509]  [<c02302c4>] tasklet_action+0x69/0xc1
    [   94.342509]  [<c022fbef>] __do_softirq+0x94/0x11e
    [   94.342509]  [<c022fcaf>] do_softirq+0x36/0x5a
    [   94.342509]  [<c022fe14>] irq_exit+0x35/0x68
    [   94.342509]  [<c0204ced>] do_IRQ+0x72/0x89
    [   94.342509]  [<c02038ee>] common_interrupt+0x2e/0x34
    [   94.342509]  [<c024007b>] ? pm_qos_add_requirement+0x63/0x9d
    [   94.342509]  [<c038e8a5>] ? acpi_idle_enter_bm+0x209/0x238
    [   94.342509]  [<c049d238>] cpuidle_idle_call+0x5c/0x94
    [   94.342509]  [<c02023f8>] cpu_idle+0x4e/0x6f
    [   94.342509]  [<c0534153>] rest_init+0x53/0x55
    [   94.342509]  [<c0781894>] start_kernel+0x2f0/0x2f5
    [   94.342509]  [<c0781091>] i386_start_kernel+0x91/0x96
    
    Reported-by: Oliver Hartkopp <oliver@hartkopp.net>
    Signed-off-by: Dave Young <hidave.darkstar@gmail.com>
    Tested-by: Oliver Hartkopp <oliver@hartkopp.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 03541f8b69c058162e4cf9675ec9181e6a204d55
Author: Paul Mackerras <paulus@samba.org>
Date:   Wed Oct 14 16:58:03 2009 +1100

    perf_event: Adjust frequency and unthrottle for non-group-leader events
    
    The loop in perf_ctx_adjust_freq checks the frequency of sampling
    event counters, and adjusts the event interval and unthrottles the
    event if required, and resets the interrupt count for the event.
    However, at present it only looks at group leaders.
    
    This means that a sampling event that is not a group leader will
    eventually get throttled, once its interrupt count reaches
    sysctl_perf_event_sample_rate/HZ --- and that is guaranteed to
    happen, if the event is active for long enough, since the interrupt
    count never gets reset.  Once it is throttled it never gets
    unthrottled, so it basically just stops working at that point.
    
    This fixes it by making perf_ctx_adjust_freq use ctx->event_list
    rather than ctx->group_list.  The existing spin_lock/spin_unlock
    around the loop makes it unnecessary to put rcu_read_lock/
    rcu_read_unlock around the list_for_each_entry_rcu().
    
    Reported-by: Mark W. Krentel <krentel@cs.rice.edu>
    Signed-off-by: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <19157.26731.855609.165622@cargo.ozlabs.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 3d76c082907e8f83c5d5c4572f38d53ad8f00c4b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Sep 28 07:46:32 2009 -0700

    rcu: Clean up code based on review feedback from Josh Triplett, part 3
    
    Whitespace fixes, updated comments, and trivial code movement.
    
    o       Fix whitespace error in RCU_HEAD_INIT()
    
    o       Move "So where is rcu_write_lock()" comment so that it does
            not come between the rcu_read_unlock() header comment and
            the rcu_read_unlock() definition.
    
    o       Move the module_param statements for blimit, qhimark, and
            qlowmark to immediately follow the corresponding
            definitions.
    
    o       In __rcu_offline_cpu(), move the assignment to rdp_me
            inside the "if" statement, given that rdp_me is not used
            outside of that "if" statement.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: akpm@linux-foundation.org
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    LKML-Reference: <12541491931164-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit b3a5b6cc7cab89dcc3301add750f88019d910a2b
Author: Eric Dumazet <eric.dumazet@gmail.com>
Date:   Thu Sep 24 12:16:51 2009 +0000

    icmp: No need to call sk_write_space()
    
    We can make icmp messages tx completion callback a litle bit faster.
    
    Setting SOCK_USE_WRITE_QUEUE sk flag tells sock_wfree() to
    not call sk_write_space() on a socket we know no thread is posssibly
    waiting for write space. (on per cpu kernel internal icmp sockets only)
    
    This avoids the sock_def_write_space() call and
    read_lock(&sk->sk_callback_lock)/read_unlock(&sk->sk_callback_lock) calls
    as well.
    
    We avoid three atomic ops.
    
    Signed-off-by: Eric Dumazet <eric.dumazet@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ee305acef5c7841dc25cc32e84bb94f744e1e9b9
Author: NeilBrown <neilb@suse.de>
Date:   Wed Sep 23 18:06:44 2009 +1000

    md: remove sparse warnings about lock context.
    
    There was a real error here on a failure path where we
    incorrectly call rcu_read_unlock.
    
    
    Signed-off-by: NeilBrown <neilb@suse.de>

commit b8c7f1dc5ca4e0d10709182233cdab932cef593d
Merge: f4eccb6d979e a71fca58b7f4
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Sep 21 09:06:52 2009 -0700

    Merge branch 'core-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'core-fixes-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip:
      rcu: Fix whitespace inconsistencies
      rcu: Fix thinko, actually initialize full tree
      rcu: Apply results of code inspection of kernel/rcutree_plugin.h
      rcu: Add WARN_ON_ONCE() consistency checks covering state transitions
      rcu: Fix synchronize_rcu() for TREE_PREEMPT_RCU
      rcu: Simplify rcu_read_unlock_special() quiescent-state accounting
      rcu: Add debug checks to TREE_PREEMPT_RCU for premature grace periods
      rcu: Kconfig help needs to say that TREE_PREEMPT_RCU scales down
      rcutorture: Occasionally delay readers enough to make RCU force_quiescent_state
      rcu: Initialize multi-level RCU grace periods holding locks
      rcu: Need to update rnp->gpnum if preemptable RCU is to be reliable

commit e7d8842ed34a7fe19d1ed90f84c211fb056ac523
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Fri Sep 18 09:50:18 2009 -0700

    rcu: Apply results of code inspection of kernel/rcutree_plugin.h
    
    o Drop the calls to cpu_quiet() from the online/offline code.
      These are unnecessary, since force_quiescent_state() will
      clean up, and removing them simplifies the code a bit.
    
    o Add a warning to check that we don't enqueue the same blocked
      task twice onto the ->blocked_tasks[] lists.
    
    o Rework the phase computation in rcu_preempt_note_context_switch()
      to be more readable, as suggested by Josh Triplett.
    
    o Disable irqs to close a race between the scheduling clock
      interrupt and rcu_preempt_note_context_switch() WRT the
      ->rcu_read_unlock_special field.
    
    o Add comments to rnp->lock acquisition and release within
      rcu_read_unlock_special() noting that irqs are already
      disabled.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: akpm@linux-foundation.org
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    LKML-Reference: <12532926201851-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit c3422bea5f09b0e85704f51f2b01271630b8940b
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Sun Sep 13 09:15:10 2009 -0700

    rcu: Simplify rcu_read_unlock_special() quiescent-state accounting
    
    The earlier approach required two scheduling-clock ticks to note an
    preemptable-RCU quiescent state in the situation in which the
    scheduling-clock interrupt is unlucky enough to always interrupt an
    RCU read-side critical section.
    
    With this change, the quiescent state is instead noted by the
    outermost rcu_read_unlock() immediately following the first
    scheduling-clock tick, or, alternatively, by the first subsequent
    context switch.  Therefore, this change also speeds up grace
    periods.
    
    Suggested-by: Josh Triplett <josh@joshtriplett.org>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: akpm@linux-foundation.org
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    LKML-Reference: <12528585111945-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 7c614d6461399acca5c0ba444f5db49cb332fc08
Author: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
Date:   Mon Aug 24 09:42:00 2009 -0700

    rcu: Add "notrace" to RCU function headers used by ftrace
    
    Both rcu_read_lock_sched_notrace() and
    rcu_read_unlock_sched_notrace() are used by ftrace, and thus
    need to be marked "notrace".
    
    Unfortunately, my naive assumption that gcc would see the inner
    "notrace" does not hold.
    
    Kudos to Lai Jiangshan for noting this.
    
    Reported-by: Ingo Molnar <mingo@elte.hu>
    Bug-spotted-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: akpm@linux-foundation.org
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josht@linux.vnet.ibm.com
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    LKML-Reference: <12511321213243-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 59615b5f9d1323898ca94e88e595b5b04115076a
Author: Andrey Yurovsky <andrey@cozybit.com>
Date:   Thu Jun 25 16:07:42 2009 -0700

    mac80211: fix allocation in mesh_queue_preq
    
    We allocate a PREQ queue node in mesh_queue_preq, however the allocation
    may cause us to sleep.  Use GFP_ATOMIC to prevent this.
    
    [ 1869.126498] BUG: scheduling while atomic: ping/1859/0x10000100
    [ 1869.127164] Modules linked in: ath5k mac80211 ath
    [ 1869.128310] Pid: 1859, comm: ping Not tainted 2.6.30-wl #1
    [ 1869.128754] Call Trace:
    [ 1869.129293]  [<c1023a2b>] __schedule_bug+0x48/0x4d
    [ 1869.129866]  [<c13b5533>] __schedule+0x77/0x67a
    [ 1869.130544]  [<c1026f2e>] ? release_console_sem+0x17d/0x185
    [ 1869.131568]  [<c807cf47>] ? mesh_queue_preq+0x2b/0x165 [mac80211]
    [ 1869.132318]  [<c13b5b3e>] schedule+0x8/0x1f
    [ 1869.132807]  [<c1023c12>] __cond_resched+0x16/0x2f
    [ 1869.133478]  [<c13b5bf0>] _cond_resched+0x27/0x32
    [ 1869.134191]  [<c108a370>] kmem_cache_alloc+0x1c/0xcf
    [ 1869.134714]  [<c10273ae>] ? printk+0x15/0x17
    [ 1869.135670]  [<c807cf47>] mesh_queue_preq+0x2b/0x165 [mac80211]
    [ 1869.136731]  [<c807d1f8>] mesh_nexthop_lookup+0xee/0x12d [mac80211]
    [ 1869.138130]  [<c807417e>] ieee80211_xmit+0xe6/0x2b2 [mac80211]
    [ 1869.138935]  [<c80be46d>] ? ath5k_hw_setup_rx_desc+0x0/0x66 [ath5k]
    [ 1869.139831]  [<c80c97bc>] ? ath5k_tasklet_rx+0xba/0x506 [ath5k]
    [ 1869.140863]  [<c8075191>] ieee80211_subif_start_xmit+0x6c9/0x6e4
    [mac80211]
    [ 1869.141665]  [<c105cf1c>] ? handle_level_irq+0x78/0x9d
    [ 1869.142390]  [<c12e3f93>] dev_hard_start_xmit+0x168/0x1c7
    [ 1869.143092]  [<c12f1f17>] __qdisc_run+0xe1/0x1b7
    [ 1869.143612]  [<c12e25ff>] qdisc_run+0x18/0x1a
    [ 1869.144248]  [<c12e62f4>] dev_queue_xmit+0x16a/0x25a
    [ 1869.144785]  [<c13b6dcc>] ? _read_unlock_bh+0xe/0x10
    [ 1869.145465]  [<c12eacdb>] neigh_resolve_output+0x19c/0x1c7
    [ 1869.146182]  [<c130e2da>] ? ip_finish_output+0x0/0x51
    [ 1869.146697]  [<c130e2a0>] ip_finish_output2+0x182/0x1bc
    [ 1869.147358]  [<c130e327>] ip_finish_output+0x4d/0x51
    [ 1869.147863]  [<c130e9d5>] ip_output+0x80/0x85
    [ 1869.148515]  [<c130cc49>] dst_output+0x9/0xb
    [ 1869.149141]  [<c130dec6>] ip_local_out+0x17/0x1a
    [ 1869.149632]  [<c130e0bc>] ip_push_pending_frames+0x1f3/0x255
    [ 1869.150343]  [<c13247ff>] raw_sendmsg+0x5e6/0x667
    [ 1869.150883]  [<c1033c55>] ? insert_work+0x6a/0x73
    [ 1869.151834]  [<c8071e00>] ?
    ieee80211_invoke_rx_handlers+0x17da/0x1ae8 [mac80211]
    [ 1869.152630]  [<c132bd68>] inet_sendmsg+0x3b/0x48
    [ 1869.153232]  [<c12d7deb>] __sock_sendmsg+0x45/0x4e
    [ 1869.153740]  [<c12d8537>] sock_sendmsg+0xb8/0xce
    [ 1869.154519]  [<c80be46d>] ? ath5k_hw_setup_rx_desc+0x0/0x66 [ath5k]
    [ 1869.155289]  [<c1036b25>] ? autoremove_wake_function+0x0/0x30
    [ 1869.155859]  [<c115992b>] ? __copy_from_user_ll+0x11/0xce
    [ 1869.156573]  [<c1159d99>] ? copy_from_user+0x31/0x54
    [ 1869.157235]  [<c12df646>] ? verify_iovec+0x40/0x6e
    [ 1869.157778]  [<c12d869a>] sys_sendmsg+0x14d/0x1a5
    [ 1869.158714]  [<c8072c40>] ? __ieee80211_rx+0x49e/0x4ee [mac80211]
    [ 1869.159641]  [<c80c83fe>] ? ath5k_rxbuf_setup+0x6d/0x8d [ath5k]
    [ 1869.160543]  [<c80be46d>] ? ath5k_hw_setup_rx_desc+0x0/0x66 [ath5k]
    [ 1869.161434]  [<c80beba4>] ? ath5k_hw_get_rxdp+0xe/0x10 [ath5k]
    [ 1869.162319]  [<c80c97bc>] ? ath5k_tasklet_rx+0xba/0x506 [ath5k]
    [ 1869.163063]  [<c1005627>] ? enable_8259A_irq+0x40/0x43
    [ 1869.163594]  [<c101edb8>] ? __dequeue_entity+0x23/0x27
    [ 1869.164793]  [<c100187a>] ? __switch_to+0x2b/0x105
    [ 1869.165442]  [<c1021d5f>] ? finish_task_switch+0x5b/0x74
    [ 1869.166129]  [<c12d963a>] sys_socketcall+0x14b/0x17b
    [ 1869.166612]  [<c1002b95>] syscall_call+0x7/0xb
    
    Signed-off-by: Andrey Yurovsky <andrey@cozybit.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 815e777f913ed54ddb449d2854015c65b4ecbfe3
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue May 26 19:46:14 2009 -0300

    perf report: Show the IP only in --verbose mode
    
    perf: report should show the IP only in --verbose mode
    
    [acme@emilia ~]$ perf report | head
     4.95          find [k] _spin_lock
     2.19          find [k] ext3fs_dirhash  [ext3]
     1.87          find [k] __rcu_read_lock
     1.86          find [k] _atomic_dec_and_lock
     1.86          find [.] /lib64/libc-2.5.so: __GI_strlen
     1.85          find [k] __kmalloc
     1.62          find [.] /lib64/libc-2.5.so: vfprintf
     1.59          find [k] __rcu_read_unlock
     1.55          find [k] __d_lookup
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: John Kacur <jkacur@redhat.com>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    LKML-Reference: <20090526224614.GK4424@ghostprotocols.net>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 3a4b8cc70b7473a0b9f26f5b4ddc6579b5e214be
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue May 26 16:19:04 2009 -0300

    perf report: Sort output by symbol usage
    
    [acme@emilia ~]$ perf record find / > /dev/null 2>&1
    [acme@emilia ~]$ perf stat perf report | head -20
     4.95          find [k] 0xffffffff81393d65 _spin_lock
     3.89          find [.] 0x000000000000af89 /usr/bin/find: <unknown>
     2.19          find [k] 0xffffffffa00518e0 ext3fs_dirhash
     1.87          find [k] 0xffffffff810a6cea __rcu_read_lock
     1.86          find [k] 0xffffffff811c7312 _atomic_dec_and_lock
     1.86          find [.] 0x00000000000782ab /lib64/libc-2.5.so: __GI_strlen
     1.85          find [k] 0xffffffff810fedfb __kmalloc
     1.62          find [.] 0x00000000000430ff /lib64/libc-2.5.so: vfprintf
     1.59          find [k] 0xffffffff810a6d6d __rcu_read_unlock
     1.55          find [k] 0xffffffff81119395 __d_lookup
     1.39          find [.] 0x0000000000071b40 /lib64/libc-2.5.so: _int_malloc
     1.30          find [k] 0xffffffffa031c4fc nfs_do_filldir
     1.21          find [k] 0xffffffff811876a5 avc_has_perm_noaudit
     1.15          find [k] 0xffffffff810fef62 kmem_cache_alloc
     1.07          find [k] 0xffffffff811d03fb copy_user_generic_string
     1.03          find [k] 0xffffffffa0043882 ext3_htree_store_dirent
     0.99          find [k] 0xffffffff81393ebb _spin_lock_bh
     0.98          find [k] 0xffffffffa03319a2 nfs3_decode_dirent
     0.97          find [k] 0xffffffff8100bf20 system_call
     0.92          find [k] 0xffffffff8139437e _spin_unlock
    
     Performance counter stats for 'perf':
    
         244.278972  task clock ticks     (msecs)
                  8  context switches     (events)
                  9  CPU migrations       (events)
               2104  pagefaults           (events)
           35329669  CPU cycles           (events)  (scaled from 75.40%)
           13740366  instructions         (events)  (scaled from 75.49%)
              59073  cache references     (events)  (scaled from 24.60%)
                196  cache misses         (events)  (scaled from 24.51%)
    
     Wall-clock time elapsed:   246.060717 msecs
    
    [acme@emilia ~]$
    [acme@emilia ~]$ grep "model name" /proc/cpuinfo | head -1
    model name      : Intel(R) Xeon(R) CPU           E5405  @ 2.00GHz
    [acme@emilia ~]$ grep "model name" /proc/cpuinfo | wc -l
    8
    [acme@emilia ~]$
    
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    LKML-Reference: <20090526191904.GH4424@ghostprotocols.net>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 457ca7bb6bdf39d0832d3f88c65fa367a3b20de6
Author: Marcel Holtmann <marcel@holtmann.org>
Date:   Tue May 5 13:09:01 2009 -0700

    Bluetooth: Move dev_set_name() to a context that can sleep
    
    Setting the name of a sysfs device has to be done in a context that can
    actually sleep. It allocates its memory with GFP_KERNEL. Previously it
    was a static (size limited) string and that got changed to accommodate
    longer device names. So move the dev_set_name() just before calling
    device_add() which is executed in a work queue.
    
    This fixes the following error:
    
    [  110.012125] BUG: sleeping function called from invalid context at mm/slub.c:1595
    [  110.012135] in_atomic(): 1, irqs_disabled(): 0, pid: 0, name: swapper
    [  110.012141] 2 locks held by swapper/0:
    [  110.012145]  #0:  (hci_task_lock){++.-.+}, at: [<ffffffffa01f822f>] hci_rx_task+0x2f/0x2d0 [bluetooth]
    [  110.012173]  #1:  (&hdev->lock){+.-.+.}, at: [<ffffffffa01fb9e2>] hci_event_packet+0x72/0x25c0 [bluetooth]
    [  110.012198] Pid: 0, comm: swapper Tainted: G        W 2.6.30-rc4-g953cdaa #1
    [  110.012203] Call Trace:
    [  110.012207]  <IRQ>  [<ffffffff8023eabd>] __might_sleep+0x14d/0x170
    [  110.012228]  [<ffffffff802cfbe1>] __kmalloc+0x111/0x170
    [  110.012239]  [<ffffffff803c2094>] kvasprintf+0x64/0xb0
    [  110.012248]  [<ffffffff803b7a5b>] kobject_set_name_vargs+0x3b/0xa0
    [  110.012257]  [<ffffffff80465326>] dev_set_name+0x76/0xa0
    [  110.012273]  [<ffffffffa01fb9e2>] ? hci_event_packet+0x72/0x25c0 [bluetooth]
    [  110.012289]  [<ffffffffa01ffc1d>] hci_conn_add_sysfs+0x3d/0x70 [bluetooth]
    [  110.012303]  [<ffffffffa01fba2c>] hci_event_packet+0xbc/0x25c0 [bluetooth]
    [  110.012312]  [<ffffffff80516eb0>] ? sock_def_readable+0x80/0xa0
    [  110.012328]  [<ffffffffa01fee0c>] ? hci_send_to_sock+0xfc/0x1c0 [bluetooth]
    [  110.012343]  [<ffffffff80516eb0>] ? sock_def_readable+0x80/0xa0
    [  110.012347]  [<ffffffff805e88c5>] ? _read_unlock+0x75/0x80
    [  110.012354]  [<ffffffffa01fee0c>] ? hci_send_to_sock+0xfc/0x1c0 [bluetooth]
    [  110.012360]  [<ffffffffa01f8403>] hci_rx_task+0x203/0x2d0 [bluetooth]
    [  110.012365]  [<ffffffff80250ab5>] tasklet_action+0xb5/0x160
    [  110.012369]  [<ffffffff8025116c>] __do_softirq+0x9c/0x150
    [  110.012372]  [<ffffffff805e850f>] ? _spin_unlock+0x3f/0x80
    [  110.012376]  [<ffffffff8020cbbc>] call_softirq+0x1c/0x30
    [  110.012380]  [<ffffffff8020f01d>] do_softirq+0x8d/0xe0
    [  110.012383]  [<ffffffff80250df5>] irq_exit+0xc5/0xe0
    [  110.012386]  [<ffffffff8020e71d>] do_IRQ+0x9d/0x120
    [  110.012389]  [<ffffffff8020c3d3>] ret_from_intr+0x0/0xf
    [  110.012391]  <EOI>  [<ffffffff80431832>] ? acpi_idle_enter_bm+0x264/0x2a6
    [  110.012399]  [<ffffffff80431828>] ? acpi_idle_enter_bm+0x25a/0x2a6
    [  110.012403]  [<ffffffff804f50d5>] ? cpuidle_idle_call+0xc5/0x130
    [  110.012407]  [<ffffffff8020a4b4>] ? cpu_idle+0xc4/0x130
    [  110.012411]  [<ffffffff805d2268>] ? rest_init+0x88/0xb0
    [  110.012416]  [<ffffffff807e2fbd>] ? start_kernel+0x3b5/0x412
    [  110.012420]  [<ffffffff807e2281>] ? x86_64_start_reservations+0x91/0xb5
    [  110.012424]  [<ffffffff807e2394>] ? x86_64_start_kernel+0xef/0x11b
    
    Based on a report by Davide Pesavento <davidepesa@gmail.com>
    
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>
    Tested-by: Hugo Mildenberger <hugo.mildenberger@namir.de>
    Tested-by: Bing Zhao <bzhao@marvell.com>

commit 358c4bcd8b00452f7e38550cee5ee4fddbca2dfb
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Mon Mar 23 16:07:24 2009 +0100

    fix ptrace slowness
    
    commit 53da1d9456fe7f87a920a78fdbdcf1225d197cb7 upstream.
    
    This patch fixes bug #12208:
    
      Bug-Entry       : http://bugzilla.kernel.org/show_bug.cgi?id=12208
      Subject         : uml is very slow on 2.6.28 host
    
    This turned out to be not a scheduler regression, but an already
    existing problem in ptrace being triggered by subtle scheduler
    changes.
    
    The problem is this:
    
     - task A is ptracing task B
     - task B stops on a trace event
     - task A is woken up and preempts task B
     - task A calls ptrace on task B, which does ptrace_check_attach()
     - this calls wait_task_inactive(), which sees that task B is still on the runq
     - task A goes to sleep for a jiffy
     - ...
    
    Since UML does lots of the above sequences, those jiffies quickly add
    up to make it slow as hell.
    
    This patch solves this by not rescheduling in read_unlock() after
    ptrace_stop() has woken up the tracer.
    
    Thanks to Oleg Nesterov and Ingo Molnar for the feedback.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    CC: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 147ef5ab74fb71f9bc088962e1a09213096edeb6
Author: Jesper Nilsson <jesper.nilsson@axis.com>
Date:   Fri Mar 27 00:17:45 2009 -0700

    ipv6: Plug sk_buff leak in ipv6_rcv (net/ipv6/ip6_input.c)
    
    [ Upstream commit 71f6f6dfdf7c7a67462386d9ea05c1095a89c555 ]
    
    Commit 778d80be52699596bf70e0eb0761cf5e1e46088d
    (ipv6: Add disable_ipv6 sysctl to disable IPv6 operaion on specific interface)
    seems to have introduced a leak of sk_buff's for ipv6 traffic,
    at least in some configurations where idev is NULL, or when ipv6
    is disabled via sysctl.
    
    The problem is that if the first condition of the if-statement
    returns non-NULL, it returns an skb with only one reference,
    and when the other conditions apply, execution jumps to the "out"
    label, which does not call kfree_skb for it.
    
    To plug this leak, change to use the "drop" label instead.
    (this relies on it being ok to call kfree_skb on NULL)
    This also allows us to avoid calling rcu_read_unlock here,
    and removes the only user of the "out" label.
    
    Signed-off-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 953e45c45cf3daa1037fac03246e2fabc088ba0b
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Mon Mar 23 16:07:24 2009 +0100

    fix ptrace slowness
    
    commit 53da1d9456fe7f87a920a78fdbdcf1225d197cb7 upstream.
    
    This patch fixes bug #12208:
    
      Bug-Entry       : http://bugzilla.kernel.org/show_bug.cgi?id=12208
      Subject         : uml is very slow on 2.6.28 host
    
    This turned out to be not a scheduler regression, but an already
    existing problem in ptrace being triggered by subtle scheduler
    changes.
    
    The problem is this:
    
     - task A is ptracing task B
     - task B stops on a trace event
     - task A is woken up and preempts task B
     - task A calls ptrace on task B, which does ptrace_check_attach()
     - this calls wait_task_inactive(), which sees that task B is still on the runq
     - task A goes to sleep for a jiffy
     - ...
    
    Since UML does lots of the above sequences, those jiffies quickly add
    up to make it slow as hell.
    
    This patch solves this by not rescheduling in read_unlock() after
    ptrace_stop() has woken up the tracer.
    
    Thanks to Oleg Nesterov and Ingo Molnar for the feedback.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    CC: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit d1a2496e6da4dc33279e9037b58c397cb5d19436
Author: Jesper Nilsson <jesper.nilsson@axis.com>
Date:   Fri Mar 27 00:17:45 2009 -0700

    ipv6: Plug sk_buff leak in ipv6_rcv (net/ipv6/ip6_input.c)
    
    [ Upstream commit 71f6f6dfdf7c7a67462386d9ea05c1095a89c555 ]
    
    Commit 778d80be52699596bf70e0eb0761cf5e1e46088d
    (ipv6: Add disable_ipv6 sysctl to disable IPv6 operaion on specific interface)
    seems to have introduced a leak of sk_buff's for ipv6 traffic,
    at least in some configurations where idev is NULL, or when ipv6
    is disabled via sysctl.
    
    The problem is that if the first condition of the if-statement
    returns non-NULL, it returns an skb with only one reference,
    and when the other conditions apply, execution jumps to the "out"
    label, which does not call kfree_skb for it.
    
    To plug this leak, change to use the "drop" label instead.
    (this relies on it being ok to call kfree_skb on NULL)
    This also allows us to avoid calling rcu_read_unlock here,
    and removes the only user of the "out" label.
    
    Signed-off-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit f3b9aae16219aaeca2dd5a9ca69f7a10faa063df
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Sun Apr 19 23:39:33 2009 +0200

    tracing/ring-buffer: Add unlock recursion protection on discard
    
    The pair of helpers trace_recursive_lock() and trace_recursive_unlock()
    have been introduced recently to provide generic tracing recursion
    protection.
    
    They are used in a symetric way:
    
     - trace_recursive_lock() on buffer reserve
     - trace_recursive_unlock() on buffer commit
    
    However sometimes, we don't commit but discard on entry
    to the buffer, ie: in case of filter checking.
    
    Then we must also unlock the recursion protection on discard time,
    otherwise the tracing gets definitely deactivated and a warning
    is raised spuriously, such as:
    
    111.119821] ------------[ cut here ]------------
    [  111.119829] WARNING: at kernel/trace/ring_buffer.c:1498 ring_buffer_lock_reserve+0x1b7/0x1d0()
    [  111.119835] Hardware name: AMILO Li 2727
    [  111.119839] Modules linked in:
    [  111.119846] Pid: 5731, comm: Xorg Tainted: G        W  2.6.30-rc1 #69
    [  111.119851] Call Trace:
    [  111.119863]  [<ffffffff8025ce68>] warn_slowpath+0xd8/0x130
    [  111.119873]  [<ffffffff8028a30f>] ? __lock_acquire+0x19f/0x1ae0
    [  111.119882]  [<ffffffff8028a30f>] ? __lock_acquire+0x19f/0x1ae0
    [  111.119891]  [<ffffffff802199b0>] ? native_sched_clock+0x20/0x70
    [  111.119899]  [<ffffffff80286dee>] ? put_lock_stats+0xe/0x30
    [  111.119906]  [<ffffffff80286eb8>] ? lock_release_holdtime+0xa8/0x150
    [  111.119913]  [<ffffffff802c8ae7>] ring_buffer_lock_reserve+0x1b7/0x1d0
    [  111.119921]  [<ffffffff802cd110>] trace_buffer_lock_reserve+0x30/0x70
    [  111.119930]  [<ffffffff802ce000>] trace_current_buffer_lock_reserve+0x20/0x30
    [  111.119939]  [<ffffffff802474e8>] ftrace_raw_event_sched_switch+0x58/0x100
    [  111.119948]  [<ffffffff808103b7>] __schedule+0x3a7/0x4cd
    [  111.119957]  [<ffffffff80211b56>] ? ftrace_call+0x5/0x2b
    [  111.119964]  [<ffffffff80211b56>] ? ftrace_call+0x5/0x2b
    [  111.119971]  [<ffffffff80810c08>] schedule+0x18/0x40
    [  111.119977]  [<ffffffff80810e09>] preempt_schedule+0x39/0x60
    [  111.119985]  [<ffffffff80813bd3>] _read_unlock+0x53/0x60
    [  111.119993]  [<ffffffff807259d2>] sock_def_readable+0x72/0x80
    [  111.120002]  [<ffffffff807ad5ed>] unix_stream_sendmsg+0x24d/0x3d0
    [  111.120011]  [<ffffffff807219a3>] sock_aio_write+0x143/0x160
    [  111.120019]  [<ffffffff80211b56>] ? ftrace_call+0x5/0x2b
    [  111.120026]  [<ffffffff80721860>] ? sock_aio_write+0x0/0x160
    [  111.120033]  [<ffffffff80721860>] ? sock_aio_write+0x0/0x160
    [  111.120042]  [<ffffffff8031c283>] do_sync_readv_writev+0xf3/0x140
    [  111.120049]  [<ffffffff80211b56>] ? ftrace_call+0x5/0x2b
    [  111.120057]  [<ffffffff80276ff0>] ? autoremove_wake_function+0x0/0x40
    [  111.120067]  [<ffffffff8045d489>] ? cap_file_permission+0x9/0x10
    [  111.120074]  [<ffffffff8045c1e6>] ? security_file_permission+0x16/0x20
    [  111.120082]  [<ffffffff8031cab4>] do_readv_writev+0xd4/0x1f0
    [  111.120089]  [<ffffffff80211b56>] ? ftrace_call+0x5/0x2b
    [  111.120097]  [<ffffffff80211b56>] ? ftrace_call+0x5/0x2b
    [  111.120105]  [<ffffffff8031cc18>] vfs_writev+0x48/0x70
    [  111.120111]  [<ffffffff8031cd65>] sys_writev+0x55/0xc0
    [  111.120119]  [<ffffffff80211e32>] system_call_fastpath+0x16/0x1b
    [  111.120125] ---[ end trace 15605f4e98d5ccb5 ]---
    
    [ Impact: fix spurious warning triggering tracing shutdown ]
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

commit 38460b48d06440de46b34cb778bd6c4855030754
Author: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
Date:   Thu Apr 2 16:57:25 2009 -0700

    cgroup: CSS ID support
    
    Patch for Per-CSS(Cgroup Subsys State) ID and private hierarchy code.
    
    This patch attaches unique ID to each css and provides following.
    
     - css_lookup(subsys, id)
       returns pointer to struct cgroup_subysys_state of id.
     - css_get_next(subsys, id, rootid, depth, foundid)
       returns the next css under "root" by scanning
    
    When cgroup_subsys->use_id is set, an id for css is maintained.
    
    The cgroup framework only parepares
            - css_id of root css for subsys
            - id is automatically attached at creation of css.
            - id is *not* freed automatically. Because the cgroup framework
              don't know lifetime of cgroup_subsys_state.
              free_css_id() function is provided. This must be called by subsys.
    
    There are several reasons to develop this.
            - Saving space .... For example, memcg's swap_cgroup is array of
              pointers to cgroup. But it is not necessary to be very fast.
              By replacing pointers(8bytes per ent) to ID (2byes per ent), we can
              reduce much amount of memory usage.
    
            - Scanning without lock.
              CSS_ID provides "scan id under this ROOT" function. By this, scanning
              css under root can be written without locks.
              ex)
              do {
                    rcu_read_lock();
                    next = cgroup_get_next(subsys, id, root, &found);
                    /* check sanity of next here */
                    css_tryget();
                    rcu_read_unlock();
                    id = found + 1
             } while(...)
    
    Characteristics:
            - Each css has unique ID under subsys.
            - Lifetime of ID is controlled by subsys.
            - css ID contains "ID" and "Depth in hierarchy" and stack of hierarchy
            - Allowed ID is 1-65535, ID 0 is UNUSED ID.
    
    Design Choices:
            - scan-by-ID v.s. scan-by-tree-walk.
              As /proc's pid scan does, scan-by-ID is robust when scanning is done
              by following kind of routine.
              scan -> rest a while(release a lock) -> conitunue from interrupted
              memcg's hierarchical reclaim does this.
    
            - When subsys->use_id is set, # of css in the system is limited to
              65535.
    
    [bharata@linux.vnet.ibm.com: remove rcu_read_lock() from css_get_next()]
    Signed-off-by: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Acked-by: Paul Menage <menage@google.com>
    Cc: Li Zefan <lizf@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: Daisuke Nishimura <nishimura@mxp.nes.nec.co.jp>
    Signed-off-by: Bharata B Rao <bharata@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit c8289b1f3fb7ab89146a29e280c8f64d4f51f53a
Author: Jesper Nilsson <jesper.nilsson@axis.com>
Date:   Fri Mar 27 00:17:45 2009 -0700

    ipv6: Plug sk_buff leak in ipv6_rcv (net/ipv6/ip6_input.c)
    
    [ Upstream commit 71f6f6dfdf7c7a67462386d9ea05c1095a89c555 ]
    
    Commit 778d80be52699596bf70e0eb0761cf5e1e46088d
    (ipv6: Add disable_ipv6 sysctl to disable IPv6 operaion on specific interface)
    seems to have introduced a leak of sk_buff's for ipv6 traffic,
    at least in some configurations where idev is NULL, or when ipv6
    is disabled via sysctl.
    
    The problem is that if the first condition of the if-statement
    returns non-NULL, it returns an skb with only one reference,
    and when the other conditions apply, execution jumps to the "out"
    label, which does not call kfree_skb for it.
    
    To plug this leak, change to use the "drop" label instead.
    (this relies on it being ok to call kfree_skb on NULL)
    This also allows us to avoid calling rcu_read_unlock here,
    and removes the only user of the "out" label.
    
    Signed-off-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Chris Wright <chrisw@sous-sol.org>

commit 71f6f6dfdf7c7a67462386d9ea05c1095a89c555
Author: Jesper Nilsson <jesper.nilsson@axis.com>
Date:   Fri Mar 27 00:17:45 2009 -0700

    ipv6: Plug sk_buff leak in ipv6_rcv (net/ipv6/ip6_input.c)
    
    Commit 778d80be52699596bf70e0eb0761cf5e1e46088d
    (ipv6: Add disable_ipv6 sysctl to disable IPv6 operaion on specific interface)
    seems to have introduced a leak of sk_buff's for ipv6 traffic,
    at least in some configurations where idev is NULL, or when ipv6
    is disabled via sysctl.
    
    The problem is that if the first condition of the if-statement
    returns non-NULL, it returns an skb with only one reference,
    and when the other conditions apply, execution jumps to the "out"
    label, which does not call kfree_skb for it.
    
    To plug this leak, change to use the "drop" label instead.
    (this relies on it being ok to call kfree_skb on NULL)
    This also allows us to avoid calling rcu_read_unlock here,
    and removes the only user of the "out" label.
    
    Signed-off-by: Jesper Nilsson <jesper.nilsson@axis.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 53da1d9456fe7f87a920a78fdbdcf1225d197cb7
Author: Miklos Szeredi <mszeredi@suse.cz>
Date:   Mon Mar 23 16:07:24 2009 +0100

    fix ptrace slowness
    
    This patch fixes bug #12208:
    
      Bug-Entry       : http://bugzilla.kernel.org/show_bug.cgi?id=12208
      Subject         : uml is very slow on 2.6.28 host
    
    This turned out to be not a scheduler regression, but an already
    existing problem in ptrace being triggered by subtle scheduler
    changes.
    
    The problem is this:
    
     - task A is ptracing task B
     - task B stops on a trace event
     - task A is woken up and preempts task B
     - task A calls ptrace on task B, which does ptrace_check_attach()
     - this calls wait_task_inactive(), which sees that task B is still on the runq
     - task A goes to sleep for a jiffy
     - ...
    
    Since UML does lots of the above sequences, those jiffies quickly add
    up to make it slow as hell.
    
    This patch solves this by not rescheduling in read_unlock() after
    ptrace_stop() has woken up the tracer.
    
    Thanks to Oleg Nesterov and Ingo Molnar for the feedback.
    
    Signed-off-by: Miklos Szeredi <mszeredi@suse.cz>
    CC: stable@kernel.org
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 2ae9a6be5f476f3512839a4d11a8f432bfd2914c
Author: Dave Young <hidave.darkstar@gmail.com>
Date:   Sat Feb 21 16:13:34 2009 +0800

    Bluetooth: Move hci_conn_del_sysfs() back to avoid device destruct too early
    
    The following commit introduce a regression:
    
            commit 7d0db0a373195385a2e0b19d1f5e4b186fdcffac
            Author: Marcel Holtmann <marcel@holtmann.org>
            Date:   Mon Jul 14 20:13:51 2008 +0200
    
                    [Bluetooth] Use a more unique bus name for connections
    
    I get panic as following (by netconsole):
    
    [ 2709.344034] usb 5-1: new full speed USB device using uhci_hcd and address 4
    [ 2709.505776] usb 5-1: configuration #1 chosen from 1 choice
    [ 2709.569207] Bluetooth: Generic Bluetooth USB driver ver 0.4
    [ 2709.570169] usbcore: registered new interface driver btusb
    [ 2845.742781] BUG: unable to handle kernel paging request at 6b6b6c2f
    [ 2845.742958] IP: [<c015515c>] __lock_acquire+0x6c/0xa80
    [ 2845.743087] *pde = 00000000
    [ 2845.743206] Oops: 0002 [#1] SMP
    [ 2845.743377] last sysfs file: /sys/class/bluetooth/hci0/hci0:6/type
    [ 2845.743742] Modules linked in: btusb netconsole snd_seq_dummy snd_seq_oss snd_seq_midi_event snd_seq snd_seq_device snd_pcm_oss snd_mixer_oss rfcomm l2cap bluetooth vfat fuse snd_hda_codec_idt snd_hda_intel snd_hda_codec snd_hwdep snd_pcm pl2303 snd_timer psmouse usbserial snd 3c59x e100 serio_raw soundcore i2c_i801 intel_agp mii agpgart snd_page_alloc rtc_cmos rtc_core thermal processor rtc_lib button thermal_sys sg evdev
    [ 2845.743742]
    [ 2845.743742] Pid: 0, comm: swapper Not tainted (2.6.29-rc5-smp #54) Dell DM051
    [ 2845.743742] EIP: 0060:[<c015515c>] EFLAGS: 00010002 CPU: 0
    [ 2845.743742] EIP is at __lock_acquire+0x6c/0xa80
    [ 2845.743742] EAX: 00000046 EBX: 00000046 ECX: 6b6b6b6b EDX: 00000002
    [ 2845.743742] ESI: 6b6b6b6b EDI: 00000000 EBP: c064fd14 ESP: c064fcc8
    [ 2845.743742]  DS: 007b ES: 007b FS: 00d8 GS: 0000 SS: 0068
    [ 2845.743742] Process swapper (pid: 0, ti=c064e000 task=c05d1400 task.ti=c064e000)
    [ 2845.743742] Stack:
    [ 2845.743742]  c05d1400 00000002 c05d1400 00000001 00000002 00000000 f65388dc c05d1400
    [ 2845.743742]  6b6b6b6b 00000292 c064fd0c c0153732 00000000 00000000 00000001 f700fa50
    [ 2845.743742]  00000046 00000000 00000000 c064fd40 c0155be6 00000000 00000002 00000001
    [ 2845.743742] Call Trace:
    [ 2845.743742]  [<c0153732>] ? trace_hardirqs_on_caller+0x72/0x1c0
    [ 2845.743742]  [<c0155be6>] ? lock_acquire+0x76/0xa0
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c046c885>] ? _spin_lock_irqsave+0x45/0x80
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c03e1f94>] ? skb_queue_purge+0x14/0x20
    [ 2845.743742]  [<f8171f5a>] ? hci_conn_del+0x10a/0x1c0 [bluetooth]
    [ 2845.743742]  [<f81399c9>] ? l2cap_disconn_ind+0x59/0xb0 [l2cap]
    [ 2845.743742]  [<f81795ce>] ? hci_conn_del_sysfs+0x8e/0xd0 [bluetooth]
    [ 2845.743742]  [<f8175758>] ? hci_event_packet+0x5f8/0x31c0 [bluetooth]
    [ 2845.743742]  [<c03dfe19>] ? sock_def_readable+0x59/0x80
    [ 2845.743742]  [<c046c14d>] ? _read_unlock+0x1d/0x20
    [ 2845.743742]  [<f8178aa9>] ? hci_send_to_sock+0xe9/0x1d0 [bluetooth]
    [ 2845.743742]  [<c015388b>] ? trace_hardirqs_on+0xb/0x10
    [ 2845.743742]  [<f816fa6a>] ? hci_rx_task+0x2ba/0x490 [bluetooth]
    [ 2845.743742]  [<c0133661>] ? tasklet_action+0x31/0xc0
    [ 2845.743742]  [<c013367c>] ? tasklet_action+0x4c/0xc0
    [ 2845.743742]  [<c0132eb7>] ? __do_softirq+0xa7/0x170
    [ 2845.743742]  [<c0116dec>] ? ack_apic_level+0x5c/0x1c0
    [ 2845.743742]  [<c0132fd7>] ? do_softirq+0x57/0x60
    [ 2845.743742]  [<c01333dc>] ? irq_exit+0x7c/0x90
    [ 2845.743742]  [<c01055bb>] ? do_IRQ+0x4b/0x90
    [ 2845.743742]  [<c01333d5>] ? irq_exit+0x75/0x90
    [ 2845.743742]  [<c010392c>] ? common_interrupt+0x2c/0x34
    [ 2845.743742]  [<c010a14f>] ? mwait_idle+0x4f/0x70
    [ 2845.743742]  [<c0101c05>] ? cpu_idle+0x65/0xb0
    [ 2845.743742]  [<c045731e>] ? rest_init+0x4e/0x60
    [ 2845.743742] Code: 0f 84 69 02 00 00 83 ff 07 0f 87 1e 06 00 00 85 ff 0f 85 08 05 00 00 8b 4d cc 8b 49 04 85 c9 89 4d d4 0f 84 f7 04 00 00 8b 75 d4 <f0> ff 86 c4 00 00 00 89 f0 e8 56 a9 ff ff 85 c0 0f 85 6e 03 00
    [ 2845.743742] EIP: [<c015515c>] __lock_acquire+0x6c/0xa80 SS:ESP 0068:c064fcc8
    [ 2845.743742] ---[ end trace 4c985b38f022279f ]---
    [ 2845.743742] Kernel panic - not syncing: Fatal exception in interrupt
    [ 2845.743742] ------------[ cut here ]------------
    [ 2845.743742] WARNING: at kernel/smp.c:329 smp_call_function_many+0x151/0x200()
    [ 2845.743742] Hardware name: Dell DM051
    [ 2845.743742] Modules linked in: btusb netconsole snd_seq_dummy snd_seq_oss snd_seq_midi_event snd_seq snd_seq_device snd_pcm_oss snd_mixer_oss rfcomm l2cap bluetooth vfat fuse snd_hda_codec_idt snd_hda_intel snd_hda_codec snd_hwdep snd_pcm pl2303 snd_timer psmouse usbserial snd 3c59x e100 serio_raw soundcore i2c_i801 intel_agp mii agpgart snd_page_alloc rtc_cmos rtc_core thermal processor rtc_lib button thermal_sys sg evdev
    [ 2845.743742] Pid: 0, comm: swapper Tainted: G      D    2.6.29-rc5-smp #54
    [ 2845.743742] Call Trace:
    [ 2845.743742]  [<c012e076>] warn_slowpath+0x86/0xa0
    [ 2845.743742]  [<c015041b>] ? trace_hardirqs_off+0xb/0x10
    [ 2845.743742]  [<c0146384>] ? up+0x14/0x40
    [ 2845.743742]  [<c012e661>] ? release_console_sem+0x31/0x1e0
    [ 2845.743742]  [<c046c8ab>] ? _spin_lock_irqsave+0x6b/0x80
    [ 2845.743742]  [<c015041b>] ? trace_hardirqs_off+0xb/0x10
    [ 2845.743742]  [<c046c900>] ? _read_lock_irqsave+0x40/0x80
    [ 2845.743742]  [<c012e7f2>] ? release_console_sem+0x1c2/0x1e0
    [ 2845.743742]  [<c0146384>] ? up+0x14/0x40
    [ 2845.743742]  [<c015041b>] ? trace_hardirqs_off+0xb/0x10
    [ 2845.743742]  [<c046a3d7>] ? __mutex_unlock_slowpath+0x97/0x160
    [ 2845.743742]  [<c046a563>] ? mutex_trylock+0xb3/0x180
    [ 2845.743742]  [<c046a4a8>] ? mutex_unlock+0x8/0x10
    [ 2845.743742]  [<c015b991>] smp_call_function_many+0x151/0x200
    [ 2845.743742]  [<c010a1a0>] ? stop_this_cpu+0x0/0x40
    [ 2845.743742]  [<c015ba61>] smp_call_function+0x21/0x30
    [ 2845.743742]  [<c01137ae>] native_smp_send_stop+0x1e/0x50
    [ 2845.743742]  [<c012e0f5>] panic+0x55/0x110
    [ 2845.743742]  [<c01065a8>] oops_end+0xb8/0xc0
    [ 2845.743742]  [<c010668f>] die+0x4f/0x70
    [ 2845.743742]  [<c011a8c9>] do_page_fault+0x269/0x610
    [ 2845.743742]  [<c011a660>] ? do_page_fault+0x0/0x610
    [ 2845.743742]  [<c046cbaf>] error_code+0x77/0x7c
    [ 2845.743742]  [<c015515c>] ? __lock_acquire+0x6c/0xa80
    [ 2845.743742]  [<c0153732>] ? trace_hardirqs_on_caller+0x72/0x1c0
    [ 2845.743742]  [<c0155be6>] lock_acquire+0x76/0xa0
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c046c885>] _spin_lock_irqsave+0x45/0x80
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c03e1aad>] skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c03e1f94>] skb_queue_purge+0x14/0x20
    [ 2845.743742]  [<f8171f5a>] hci_conn_del+0x10a/0x1c0 [bluetooth]
    [ 2845.743742]  [<f81399c9>] ? l2cap_disconn_ind+0x59/0xb0 [l2cap]
    [ 2845.743742]  [<f81795ce>] ? hci_conn_del_sysfs+0x8e/0xd0 [bluetooth]
    [ 2845.743742]  [<f8175758>] hci_event_packet+0x5f8/0x31c0 [bluetooth]
    [ 2845.743742]  [<c03dfe19>] ? sock_def_readable+0x59/0x80
    [ 2845.743742]  [<c046c14d>] ? _read_unlock+0x1d/0x20
    [ 2845.743742]  [<f8178aa9>] ? hci_send_to_sock+0xe9/0x1d0 [bluetooth]
    [ 2845.743742]  [<c015388b>] ? trace_hardirqs_on+0xb/0x10
    [ 2845.743742]  [<f816fa6a>] hci_rx_task+0x2ba/0x490 [bluetooth]
    [ 2845.743742]  [<c0133661>] ? tasklet_action+0x31/0xc0
    [ 2845.743742]  [<c013367c>] tasklet_action+0x4c/0xc0
    [ 2845.743742]  [<c0132eb7>] __do_softirq+0xa7/0x170
    [ 2845.743742]  [<c0116dec>] ? ack_apic_level+0x5c/0x1c0
    [ 2845.743742]  [<c0132fd7>] do_softirq+0x57/0x60
    [ 2845.743742]  [<c01333dc>] irq_exit+0x7c/0x90
    [ 2845.743742]  [<c01055bb>] do_IRQ+0x4b/0x90
    [ 2845.743742]  [<c01333d5>] ? irq_exit+0x75/0x90
    [ 2845.743742]  [<c010392c>] common_interrupt+0x2c/0x34
    [ 2845.743742]  [<c010a14f>] ? mwait_idle+0x4f/0x70
    [ 2845.743742]  [<c0101c05>] cpu_idle+0x65/0xb0
    [ 2845.743742]  [<c045731e>] rest_init+0x4e/0x60
    [ 2845.743742] ---[ end trace 4c985b38f02227a0 ]---
    [ 2845.743742] ------------[ cut here ]------------
    [ 2845.743742] WARNING: at kernel/smp.c:226 smp_call_function_single+0x8e/0x110()
    [ 2845.743742] Hardware name: Dell DM051
    [ 2845.743742] Modules linked in: btusb netconsole snd_seq_dummy snd_seq_oss snd_seq_midi_event snd_seq snd_seq_device snd_pcm_oss snd_mixer_oss rfcomm l2cap bluetooth vfat fuse snd_hda_codec_idt snd_hda_intel snd_hda_codec snd_hwdep snd_pcm pl2303 snd_timer psmouse usbserial snd 3c59x e100 serio_raw soundcore i2c_i801 intel_agp mii agpgart snd_page_alloc rtc_cmos rtc_core thermal processor rtc_lib button thermal_sys sg evdev
    [ 2845.743742] Pid: 0, comm: swapper Tainted: G      D W  2.6.29-rc5-smp #54
    [ 2845.743742] Call Trace:
    [ 2845.743742]  [<c012e076>] warn_slowpath+0x86/0xa0
    [ 2845.743742]  [<c012e000>] ? warn_slowpath+0x10/0xa0
    [ 2845.743742]  [<c015041b>] ? trace_hardirqs_off+0xb/0x10
    [ 2845.743742]  [<c0146384>] ? up+0x14/0x40
    [ 2845.743742]  [<c012e661>] ? release_console_sem+0x31/0x1e0
    [ 2845.743742]  [<c046c8ab>] ? _spin_lock_irqsave+0x6b/0x80
    [ 2845.743742]  [<c015041b>] ? trace_hardirqs_off+0xb/0x10
    [ 2845.743742]  [<c046c900>] ? _read_lock_irqsave+0x40/0x80
    [ 2845.743742]  [<c012e7f2>] ? release_console_sem+0x1c2/0x1e0
    [ 2845.743742]  [<c0146384>] ? up+0x14/0x40
    [ 2845.743742]  [<c015b7be>] smp_call_function_single+0x8e/0x110
    [ 2845.743742]  [<c010a1a0>] ? stop_this_cpu+0x0/0x40
    [ 2845.743742]  [<c026d23f>] ? cpumask_next_and+0x1f/0x40
    [ 2845.743742]  [<c015b95a>] smp_call_function_many+0x11a/0x200
    [ 2845.743742]  [<c010a1a0>] ? stop_this_cpu+0x0/0x40
    [ 2845.743742]  [<c015ba61>] smp_call_function+0x21/0x30
    [ 2845.743742]  [<c01137ae>] native_smp_send_stop+0x1e/0x50
    [ 2845.743742]  [<c012e0f5>] panic+0x55/0x110
    [ 2845.743742]  [<c01065a8>] oops_end+0xb8/0xc0
    [ 2845.743742]  [<c010668f>] die+0x4f/0x70
    [ 2845.743742]  [<c011a8c9>] do_page_fault+0x269/0x610
    [ 2845.743742]  [<c011a660>] ? do_page_fault+0x0/0x610
    [ 2845.743742]  [<c046cbaf>] error_code+0x77/0x7c
    [ 2845.743742]  [<c015515c>] ? __lock_acquire+0x6c/0xa80
    [ 2845.743742]  [<c0153732>] ? trace_hardirqs_on_caller+0x72/0x1c0
    [ 2845.743742]  [<c0155be6>] lock_acquire+0x76/0xa0
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c046c885>] _spin_lock_irqsave+0x45/0x80
    [ 2845.743742]  [<c03e1aad>] ? skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c03e1aad>] skb_dequeue+0x1d/0x70
    [ 2845.743742]  [<c03e1f94>] skb_queue_purge+0x14/0x20
    [ 2845.743742]  [<f8171f5a>] hci_conn_del+0x10a/0x1c0 [bluetooth]
    [ 2845.743742]  [<f81399c9>] ? l2cap_disconn_ind+0x59/0xb0 [l2cap]
    [ 2845.743742]  [<f81795ce>] ? hci_conn_del_sysfs+0x8e/0xd0 [bluetooth]
    [ 2845.743742]  [<f8175758>] hci_event_packet+0x5f8/0x31c0 [bluetooth]
    [ 2845.743742]  [<c03dfe19>] ? sock_def_readable+0x59/0x80
    [ 2845.743742]  [<c046c14d>] ? _read_unlock+0x1d/0x20
    [ 2845.743742]  [<f8178aa9>] ? hci_send_to_sock+0xe9/0x1d0 [bluetooth]
    [ 2845.743742]  [<c015388b>] ? trace_hardirqs_on+0xb/0x10
    [ 2845.743742]  [<f816fa6a>] hci_rx_task+0x2ba/0x490 [bluetooth]
    [ 2845.743742]  [<c0133661>] ? tasklet_action+0x31/0xc0
    [ 2845.743742]  [<c013367c>] tasklet_action+0x4c/0xc0
    [ 2845.743742]  [<c0132eb7>] __do_softirq+0xa7/0x170
    [ 2845.743742]  [<c0116dec>] ? ack_apic_level+0x5c/0x1c0
    [ 2845.743742]  [<c0132fd7>] do_softirq+0x57/0x60
    [ 2845.743742]  [<c01333dc>] irq_exit+0x7c/0x90
    [ 2845.743742]  [<c01055bb>] do_IRQ+0x4b/0x90
    [ 2845.743742]  [<c01333d5>] ? irq_exit+0x75/0x90
    [ 2845.743742]  [<c010392c>] common_interrupt+0x2c/0x34
    [ 2845.743742]  [<c010a14f>] ? mwait_idle+0x4f/0x70
    [ 2845.743742]  [<c0101c05>] cpu_idle+0x65/0xb0
    [ 2845.743742]  [<c045731e>] rest_init+0x4e/0x60
    [ 2845.743742] ---[ end trace 4c985b38f02227a1 ]---
    [ 2845.743742] Rebooting in 3 seconds..
    
    My logitec bluetooth mouse trying connect to pc, but
    pc side reject the connection again and again. then panic happens.
    
    The reason is due to hci_conn_del_sysfs now called in hci_event_packet,
    the del work is done in a workqueue, so it's possible done before
    skb_queue_purge called.
    
    I move the hci_conn_del_sysfs after skb_queue_purge just as that before
    marcel's commit.
    
    Remove the hci_conn_del_sysfs in hci_conn_hash_flush as well due to
    hci_conn_del will deal with the work.
    
    Signed-off-by: Dave Young <hidave.darkstar@gmail.com>
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>

commit d1f9cbd78841f1a797c77e9117e4882f932c2ef6
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Feb 18 04:25:25 2009 +0100

    tracing/function-graph-tracer: fix traces weirdness while absolute time printing
    
    Impact: trace output cleanup/reordering
    
    When an interrupt occurs and and the abstime option is selected:
    
      echo funcgraph-abstime > /debug/tracing/trace_options
    
    then we observe broken traces:
    
    30581.025422 |   0)   Xorg-4291    |   0.503 us    |      idle_cpu();
    30581.025424 |   0)   Xorg-4291    |   2.576 us    |    }
    30581.025424 |   0)   Xorg-4291    | + 75.771 us   |  }
     0)   Xorg-4291    |   <========== |
    30581.025425 |   0)   Xorg-4291    |               |  schedule() {
    30581.025426 |   0)   Xorg-4291    |               |    __schedule() {
    30581.025426 |   0)   Xorg-4291    |   0.705 us    |      _spin_lock_irq();
    
    With this patch, the interrupts output better adapts
    to absolute time printing:
    
      414.856543 |   1)   Xorg-4279    |   8.816 us    |                        }
      414.856544 |   1)   Xorg-4279    |   0.525 us    |                        rcu_irq_exit();
      414.856545 |   1)   Xorg-4279    |   0.526 us    |                        idle_cpu();
      414.856546 |   1)   Xorg-4279    | + 12.157 us   |                      }
      414.856549 |   1)   Xorg-4279    | ! 104.114 us  |                    }
      414.856549 |   1)   Xorg-4279    |   <========== |
      414.856549 |   1)   Xorg-4279    | ! 107.944 us  |                  }
      414.856550 |   1)   Xorg-4279    | ! 137.010 us  |                }
      414.856551 |   1)   Xorg-4279    |   0.624 us    |                _read_unlock();
      414.856552 |   1)   Xorg-4279    | ! 140.930 us  |              }
      414.856552 |   1)   Xorg-4279    | ! 166.159 us  |            }
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 9005f3ebebfcfe9ccd731d16c468907a35ac1f9a
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Jan 22 17:04:53 2009 -0800

    tracing/function-graph-tracer: various fixes and features
    
    This patch brings various bugfixes:
    
    - Drop the first irrelevant task switch on the very beginning of a trace.
    
    - Drop the OVERHEAD word from the headers, the DURATION word is sufficient
      and will not overlap other columns.
    
    - Make the headers fit well their respective columns whatever the
      selected options.
    
    Ie, default options:
    
     # tracer: function_graph
     #
     # CPU  DURATION                  FUNCTION CALLS
     # |     |   |                     |   |   |   |
    
      1)   0.646 us    |                    }
      1)               |                    mem_cgroup_del_lru_list() {
      1)   0.624 us    |                      lookup_page_cgroup();
      1)   1.970 us    |                    }
    
     echo funcgraph-proc > trace_options
    
     # tracer: function_graph
     #
     # CPU  TASK/PID        DURATION                  FUNCTION CALLS
     # |    |    |           |   |                     |   |   |   |
    
      0)   bash-2937    |   0.895 us    |                }
      0)   bash-2937    |   0.888 us    |                __rcu_read_unlock();
      0)   bash-2937    |   0.864 us    |                conv_uni_to_pc();
      0)   bash-2937    |   1.015 us    |                __rcu_read_lock();
    
     echo nofuncgraph-cpu > trace_options
     echo nofuncgraph-proc > trace_options
    
     # tracer: function_graph
     #
     #   DURATION                  FUNCTION CALLS
     #    |   |                     |   |   |   |
    
       3.752 us    |                  native_pud_val();
       0.616 us    |                  native_pud_val();
       0.624 us    |                  native_pmd_val();
    
    About features, one can now disable the duration (this will hide the
    overhead too for convenient reasons and because on  doesn't need
    overhead if it hasn't the duration):
    
     echo nofuncgraph-duration > trace_options
    
     # tracer: function_graph
     #
     #                FUNCTION CALLS
     #                |   |   |   |
    
               cap_vm_enough_memory() {
                 __vm_enough_memory() {
                   vm_acct_memory();
                 }
               }
             }
    
    And at last, an option to print the absolute time:
    
     //Restart from default options
     echo funcgraph-abstime > trace_options
    
     # tracer: function_graph
     #
     #      TIME       CPU  DURATION                  FUNCTION CALLS
     #       |         |     |   |                     |   |   |   |
    
       261.339774 |   1) + 42.823 us   |    }
       261.339775 |   1)   1.045 us    |    _spin_lock_irq();
       261.339777 |   1)   0.940 us    |    _spin_lock_irqsave();
       261.339778 |   1)   0.752 us    |    _spin_unlock_irqrestore();
       261.339780 |   1)   0.857 us    |    _spin_unlock_irq();
       261.339782 |   1)               |    flush_to_ldisc() {
       261.339783 |   1)               |      tty_ldisc_ref() {
       261.339783 |   1)               |        tty_ldisc_try() {
       261.339784 |   1)   1.075 us    |          _spin_lock_irqsave();
       261.339786 |   1)   0.842 us    |          _spin_unlock_irqrestore();
       261.339788 |   1)   4.211 us    |        }
       261.339788 |   1)   5.662 us    |      }
    
    The format is seconds.usecs.
    
    I guess no one needs the nanosec precision here, the main goal is to have
    an overview about the general timings of events, and to see the place when
    the trace switches from one cpu to another.
    
    ie:
    
       274.874760 |   1)   0.676 us    |      _spin_unlock();
       274.874762 |   1)   0.609 us    |      native_load_sp0();
       274.874763 |   1)   0.602 us    |      native_load_tls();
       274.878739 |   0)   0.722 us    |                  }
       274.878740 |   0)   0.714 us    |                  native_pmd_val();
       274.878741 |   0)   0.730 us    |                  native_pmd_val();
    
    Here there is a 4000 usecs difference when we switch the cpu.
    
    Changes in V2:
    
    - Completely fix the first pointless task switch.
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 5766b842b23c6b40935a5f3bd435b2bcdaff2143
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jan 20 09:13:15 2009 +0100

    x86, cpumask: fix tlb flush race
    
    Impact: fix bootup crash
    
    The cpumask is now passed in as a reference to mm->cpu_vm_mask, not on
    the stack - hence it is not constant anymore during the TLB flush.
    
    That way it could race and some static sanity checks would trigger:
    
    [  238.154287] ------------[ cut here ]------------
    [  238.156039] kernel BUG at arch/x86/kernel/tlb_32.c:130!
    [  238.156039] invalid opcode: 0000 [#1] SMP
    [  238.156039] last sysfs file: /sys/class/net/eth2/address
    [  238.156039] Modules linked in:
    [  238.156039]
    [  238.156039] Pid: 6493, comm: ifup-eth Not tainted (2.6.29-rc2-tip #1) P4DC6
    [  238.156039] EIP: 0060:[<c0118f87>] EFLAGS: 00010202 CPU: 2
    [  238.156039] EIP is at native_flush_tlb_others+0x35/0x158
    [  238.156039] EAX: c0ef972c EBX: f6143301 ECX: 00000000 EDX: 00000000
    [  238.156039] ESI: f61433a8 EDI: f6143200 EBP: f34f3e00 ESP: f34f3df0
    [  238.156039]  DS: 007b ES: 007b FS: 00d8 GS: 0000 SS: 0068
    [  238.156039] Process ifup-eth (pid: 6493, ti=f34f2000 task=f399ab00 task.ti=f34f2000)
    [  238.156039] Stack:
    [  238.156039]  ffffffff f61433a8 ffffffff f6143200 f34f3e18 c0118e9c 00000000 f6143200
    [  238.156039]  f61433a8 f5bec738 f34f3e28 c0119435 c2b5b830 f6143200 f34f3e34 c01c2dc3
    [  238.156039]  bffd9000 f34f3e60 c01c3051 00000000 ffffffff f34f3e4c 00000000 00000071
    [  238.156039] Call Trace:
    [  238.156039]  [<c0118e9c>] ? flush_tlb_others+0x52/0x5b
    [  238.156039]  [<c0119435>] ? flush_tlb_mm+0x7f/0x8b
    [  238.156039]  [<c01c2dc3>] ? tlb_finish_mmu+0x2d/0x55
    [  238.156039]  [<c01c3051>] ? exit_mmap+0x124/0x170
    [  238.156039]  [<c013e965>] ? mmput+0x40/0xf5
    [  238.156039]  [<c01e4788>] ? flush_old_exec+0x640/0x94b
    [  238.156039]  [<c01ddb4e>] ? fsnotify_access+0x37/0x39
    [  238.156039]  [<c01e3435>] ? kernel_read+0x39/0x4b
    [  238.156039]  [<c021bc8a>] ? load_elf_binary+0x4a1/0x11bb
    [  238.156039]  [<c01c0af9>] ? might_fault+0x51/0x9c
    [  238.156039]  [<c010a2cc>] ? paravirt_read_tsc+0x20/0x4f
    [  238.156039]  [<c010a406>] ? native_sched_clock+0x5d/0x60
    [  238.156039]  [<c01e2fda>] ? search_binary_handler+0xab/0x2c4
    [  238.156039]  [<c021b7e9>] ? load_elf_binary+0x0/0x11bb
    [  238.156039]  [<c04ae9a5>] ? _raw_read_unlock+0x21/0x46
    [  238.156039]  [<c021b7e9>] ? load_elf_binary+0x0/0x11bb
    [  238.156039]  [<c01e2fe1>] ? search_binary_handler+0xb2/0x2c4
    [  238.156039]  [<c01e4076>] ? do_execve+0x21c/0x2ee
    [  238.156039]  [<c01029b7>] ? sys_execve+0x51/0x8c
    [  238.156039]  [<c0103eaf>] ? sysenter_do_call+0x12/0x43
    
    Fix it by not assuming that the cpumask is constant.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit ea4e2bc4d9f7370e57a343ccb5e7c0ad3222ec3c
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Wed Dec 3 15:36:57 2008 -0500

    ftrace: graph of a single function
    
    This patch adds the file:
    
       /debugfs/tracing/set_graph_function
    
    which can be used along with the function graph tracer.
    
    When this file is empty, the function graph tracer will act as
    usual. When the file has a function in it, the function graph
    tracer will only trace that function.
    
    For example:
    
     # echo blk_unplug > /debugfs/tracing/set_graph_function
     # cat /debugfs/tracing/trace
     [...]
     ------------------------------------------
     | 2)  make-19003  =>  kjournald-2219
     ------------------------------------------
    
     2)               |  blk_unplug() {
     2)               |    dm_unplug_all() {
     2)               |      dm_get_table() {
     2)      1.381 us |        _read_lock();
     2)      0.911 us |        dm_table_get();
     2)      1. 76 us |        _read_unlock();
     2) +   12.912 us |      }
     2)               |      dm_table_unplug_all() {
     2)               |        blk_unplug() {
     2)      0.778 us |          generic_unplug_device();
     2)      2.409 us |        }
     2)      5.992 us |      }
     2)      0.813 us |      dm_table_put();
     2) +   29. 90 us |    }
     2) +   34.532 us |  }
    
    You can add up to 32 functions into this file. Currently we limit it
    to 32, but this may change with later improvements.
    
    To add another function, use the append '>>':
    
      # echo sys_read >> /debugfs/tracing/set_graph_function
      # cat /debugfs/tracing/set_graph_function
      blk_unplug
      sys_read
    
    Using the '>' will clear out the function and write anew:
    
      # echo sys_write > /debug/tracing/set_graph_function
      # cat /debug/tracing/set_graph_function
      sys_write
    
    Note, if you have function graph running while doing this, the small
    time between clearing it and updating it will cause the graph to
    record all functions. This should not be an issue because after
    it sets the filter, only those functions will be recorded from then on.
    If you need to only record a particular function then set this
    file first before starting the function graph tracer. In the future
    this side effect may be corrected.
    
    The set_graph_function file is similar to the set_ftrace_filter but
    it does not take wild cards nor does it allow for more than one
    function to be set with a single write. There is no technical reason why
    this is the case, I just do not have the time yet to implement that.
    
    Note, dynamic ftrace must be enabled for this to appear because it
    uses the dynamic ftrace records to match the name to the mcount
    call sites.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 3ab5aee7fe840b5b1b35a8d1ac11c3de5281e611
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Sun Nov 16 19:40:17 2008 -0800

    net: Convert TCP & DCCP hash tables to use RCU / hlist_nulls
    
    RCU was added to UDP lookups, using a fast infrastructure :
    - sockets kmem_cache use SLAB_DESTROY_BY_RCU and dont pay the
      price of call_rcu() at freeing time.
    - hlist_nulls permits to use few memory barriers.
    
    This patch uses same infrastructure for TCP/DCCP established
    and timewait sockets.
    
    Thanks to SLAB_DESTROY_BY_RCU, no slowdown for applications
    using short lived TCP connections. A followup patch, converting
    rwlocks to spinlocks will even speedup this case.
    
    __inet_lookup_established() is pretty fast now we dont have to
    dirty a contended cache line (read_lock/read_unlock)
    
    Only established and timewait hashtable are converted to RCU
    (bind table and listen table are still using traditional locking)
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit bbaffaca4810de1a25e32ecaf836eeaacc7a3d11
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Sun Nov 16 19:37:55 2008 -0800

    rcu: Introduce hlist_nulls variant of hlist
    
    hlist uses NULL value to finish a chain.
    
    hlist_nulls variant use the low order bit set to 1 to signal an end-of-list marker.
    
    This allows to store many different end markers, so that some RCU lockless
    algos (used in TCP/UDP stack for example) can save some memory barriers in
    fast paths.
    
    Two new files are added :
    
    include/linux/list_nulls.h
      - mimics hlist part of include/linux/list.h, derived to hlist_nulls variant
    
    include/linux/rculist_nulls.h
      - mimics hlist part of include/linux/rculist.h, derived to hlist_nulls variant
    
       Only four helpers are declared for the moment :
    
         hlist_nulls_del_init_rcu(), hlist_nulls_del_rcu(),
         hlist_nulls_add_head_rcu() and hlist_nulls_for_each_entry_rcu()
    
    prefetches() were removed, since an end of list is not anymore NULL value.
    prefetches() could trigger useless (and possibly dangerous) memory transactions.
    
    Example of use (extracted from __udp4_lib_lookup())
    
            struct sock *sk, *result;
            struct hlist_nulls_node *node;
            unsigned short hnum = ntohs(dport);
            unsigned int hash = udp_hashfn(net, hnum);
            struct udp_hslot *hslot = &udptable->hash[hash];
            int score, badness;
    
            rcu_read_lock();
    begin:
            result = NULL;
            badness = -1;
            sk_nulls_for_each_rcu(sk, node, &hslot->head) {
                    score = compute_score(sk, net, saddr, hnum, sport,
                                          daddr, dport, dif);
                    if (score > badness) {
                            result = sk;
                            badness = score;
                    }
            }
            /*
             * if the nulls value we got at the end of this lookup is
             * not the expected one, we must restart lookup.
             * We probably met an item that was moved to another chain.
             */
            if (get_nulls_value(node) != hash)
                    goto begin;
    
            if (result) {
                    if (unlikely(!atomic_inc_not_zero(&result->sk_refcnt)))
                            result = NULL;
                    else if (unlikely(compute_score(result, net, saddr, hnum, sport,
                                      daddr, dport, dif) < badness)) {
                            sock_put(result);
                            goto begin;
                    }
            }
            rcu_read_unlock();
            return result;
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 271b72c7fa82c2c7a795bc16896149933110672d
Author: Eric Dumazet <dada1@cosmosbay.com>
Date:   Wed Oct 29 02:11:14 2008 -0700

    udp: RCU handling for Unicast packets.
    
    Goals are :
    
    1) Optimizing handling of incoming Unicast UDP frames, so that no memory
     writes should happen in the fast path.
    
     Note: Multicasts and broadcasts still will need to take a lock,
     because doing a full lockless lookup in this case is difficult.
    
    2) No expensive operations in the socket bind/unhash phases :
      - No expensive synchronize_rcu() calls.
    
      - No added rcu_head in socket structure, increasing memory needs,
      but more important, forcing us to use call_rcu() calls,
      that have the bad property of making sockets structure cold.
      (rcu grace period between socket freeing and its potential reuse
       make this socket being cold in CPU cache).
      David did a previous patch using call_rcu() and noticed a 20%
      impact on TCP connection rates.
      Quoting Cristopher Lameter :
       "Right. That results in cacheline cooldown. You'd want to recycle
        the object as they are cache hot on a per cpu basis. That is screwed
        up by the delayed regular rcu processing. We have seen multiple
        regressions due to cacheline cooldown.
        The only choice in cacheline hot sensitive areas is to deal with the
        complexity that comes with SLAB_DESTROY_BY_RCU or give up on RCU."
    
      - Because udp sockets are allocated from dedicated kmem_cache,
      use of SLAB_DESTROY_BY_RCU can help here.
    
    Theory of operation :
    ---------------------
    
    As the lookup is lockfree (using rcu_read_lock()/rcu_read_unlock()),
    special attention must be taken by readers and writers.
    
    Use of SLAB_DESTROY_BY_RCU is tricky too, because a socket can be freed,
    reused, inserted in a different chain or in worst case in the same chain
    while readers could do lookups in the same time.
    
    In order to avoid loops, a reader must check each socket found in a chain
    really belongs to the chain the reader was traversing. If it finds a
    mismatch, lookup must start again at the begining. This *restart* loop
    is the reason we had to use rdlock for the multicast case, because
    we dont want to send same message several times to the same socket.
    
    We use RCU only for fast path.
    Thus, /proc/net/udp still takes spinlocks.
    
    Signed-off-by: Eric Dumazet <dada1@cosmosbay.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5f86515158ca86182c1dbecd546f1848121ba135
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Fri Oct 17 14:40:30 2008 +0800

    rcupdate: fix bug of rcu_barrier*()
    
    current rcu_barrier_bh() is like this:
    
    void rcu_barrier_bh(void)
    {
            BUG_ON(in_interrupt());
            /* Take cpucontrol mutex to protect against CPU hotplug */
            mutex_lock(&rcu_barrier_mutex);
            init_completion(&rcu_barrier_completion);
            atomic_set(&rcu_barrier_cpu_count, 0);
            /*
             * The queueing of callbacks in all CPUs must be atomic with
             * respect to RCU, otherwise one CPU may queue a callback,
             * wait for a grace period, decrement barrier count and call
             * complete(), while other CPUs have not yet queued anything.
             * So, we need to make sure that grace periods cannot complete
             * until all the callbacks are queued.
             */
            rcu_read_lock();
            on_each_cpu(rcu_barrier_func, (void *)RCU_BARRIER_BH, 1);
            rcu_read_unlock();
            wait_for_completion(&rcu_barrier_completion);
            mutex_unlock(&rcu_barrier_mutex);
    }
    
    The inconsistency of the code and the comments show a bug here.
    rcu_read_lock() cannot make sure that "grace periods for RCU_BH
    cannot complete until all the callbacks are queued".
    it only make sure that race periods for RCU cannot complete
    until all the callbacks are queued.
    
    so we must use rcu_read_lock_bh() for rcu_barrier_bh().
    like this:
    
    void rcu_barrier_bh(void)
    {
            ......
            rcu_read_lock_bh();
            on_each_cpu(rcu_barrier_func, (void *)RCU_BARRIER_BH, 1);
            rcu_read_unlock_bh();
            ......
    }
    
    and also rcu_barrier() rcu_barrier_sched() are implemented like this.
    it will bring a lot of duplicate code. My patch uses another way to
    fix this bug, please see the comment of my patch.
    Thank Paul E. McKenney for he rewrote the comment.
    
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Reviewed-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 146aa1bd0511f88ddb4e92fafa2b8aad4f2f65f3
Author: Lai Jiangshan <laijs@cn.fujitsu.com>
Date:   Sat Oct 18 20:28:03 2008 -0700

    cgroups: fix probable race with put_css_set[_taskexit] and find_css_set
    
    put_css_set_taskexit may be called when find_css_set is called on other
    cpu.  And the race will occur:
    
    put_css_set_taskexit side                    find_css_set side
    
                                            |
    atomic_dec_and_test(&kref->refcount)    |
        /* kref->refcount = 0 */            |
    ....................................................................
                                            |  read_lock(&css_set_lock)
                                            |  find_existing_css_set
                                            |  get_css_set
                                            |  read_unlock(&css_set_lock);
    ....................................................................
    __release_css_set                       |
    ....................................................................
                                            | /* use a released css_set */
                                            |
    
    [put_css_set is the same. But in the current code, all put_css_set are
    put into cgroup mutex critical region as the same as find_css_set.]
    
    [akpm@linux-foundation.org: repair comments]
    [menage@google.com: eliminate race in css_set refcounting]
    Signed-off-by: Lai Jiangshan <laijs@cn.fujitsu.com>
    Cc: Balbir Singh <balbir@in.ibm.com>
    Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
    Signed-off-by: Paul Menage <menage@google.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit b922df7383749a1c0b7ea64c50fa839263d3816b
Merge: c54dcd8ec9f0 cdbb92b31d3c
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 10 13:10:51 2008 -0700

    Merge branch 'rcu-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip
    
    * 'rcu-v28-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/linux-2.6-tip: (21 commits)
      rcu: RCU-based detection of stalled CPUs for Classic RCU, fix
      rcu: RCU-based detection of stalled CPUs for Classic RCU
      rcu: add rcu_read_lock_sched() / rcu_read_unlock_sched()
      rcu: fix sparse shadowed variable warning
      doc/RCU: fix pseudocode in rcuref.txt
      rcuclassic: fix compiler warning
      rcu: use irq-safe locks
      rcuclassic: fix compilation NG
      rcu: fix locking cleanup fallout
      rcu: remove redundant ACCESS_ONCE definition from rcupreempt.c
      rcu: fix classic RCU locking cleanup lockdep problem
      rcu: trace fix possible mem-leak
      rcu: just rename call_rcu_bh instead of making it a macro
      rcu: remove list_for_each_rcu()
      rcu: fixes to include/linux/rcupreempt.h
      rcu: classic RCU locking and memory-barrier cleanups
      rcu: prevent console flood when one CPU sees another AWOL via RCU
      rcu, debug: detect stalled grace periods, cleanups
      rcu, debug: detect stalled grace periods
      rcu classic: new algorithm for callbacks-processing(v2)
      ...

commit 1c50b728c3e734150b8a4a8310ce3e01bc5c70be
Author: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
Date:   Mon Sep 29 11:06:46 2008 -0400

    rcu: add rcu_read_lock_sched() / rcu_read_unlock_sched()
    
    Add rcu_read_lock_sched() and rcu_read_unlock_sched() to rcupdate.h to match the
    recently added write-side call_rcu_sched() and rcu_barrier_sched(). They also
    match the no-so-recently-added synchronize_sched().
    
    It will help following matching use of the update/read lock primitives. Those
    new read lock will replace preempt_disable()/enable() used in pair with
    RCU-classic synchronization.
    
    Signed-off-by: Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 15160716eea5591eb31f40fd4dba56d83bea4209
Author: Ingo Molnar <mingo@elte.hu>
Date:   Fri Sep 26 11:40:53 2008 +0200

    x86, pci-hotplug, calgary / rio: fix EBDA ioremap()
    
    IO resource and ioremap debugging uncovered this ioremap() done
    by drivers/pci/hotplug/ibmphp_ebda.c:
    
    initcall pci_hotplug_init+0x0/0x41 returned 0 after 3 msecs
    calling  ibmphp_init+0x0/0x360 @ 1
    ibmphpd: IBM Hot Plug PCI Controller Driver version: 0.6
    resource map sanity check conflict: 0x9f800 0xaf5e7 0x9f800 0x9ffff reserved
    ------------[ cut here ]------------
    WARNING: at arch/x86/mm/ioremap.c:175 __ioremap_caller+0x5c/0x226()
    Pid: 1, comm: swapper Not tainted 2.6.27-rc7-tip-00914-g347b10f-dirty #36038
     [<c013a72d>] warn_on_slowpath+0x41/0x68
     [<c0156f00>] ? __lock_acquire+0x9ba/0xa7f
     [<c012158c>] ? do_flush_tlb_all+0x0/0x59
     [<c015ac31>] ? smp_call_function_mask+0x74/0x17d
     [<c012158c>] ? do_flush_tlb_all+0x0/0x59
     [<c013b228>] ? printk+0x1a/0x1c
     [<c013f302>] ? iomem_map_sanity_check+0x82/0x8c
     [<c0a773e8>] ? _read_unlock+0x22/0x25
     [<c013f302>] ? iomem_map_sanity_check+0x82/0x8c
     [<c0154e17>] ? trace_hardirqs_off+0xb/0xd
     [<c0127731>] __ioremap_caller+0x5c/0x226
     [<c0156158>] ? trace_hardirqs_on+0xb/0xd
     [<c012767d>] ? iounmap+0x9d/0xa5
     [<c01279dd>] ioremap_nocache+0x15/0x17
     [<c0403c42>] ? ioremap+0xd/0xf
     [<c0403c42>] ioremap+0xd/0xf
     [<c0f1928f>] ibmphp_access_ebda+0x60/0xa0e
     [<c0f17f64>] ibmphp_init+0xb5/0x360
     [<c0101057>] do_one_initcall+0x57/0x138
     [<c0f17eaf>] ? ibmphp_init+0x0/0x360
     [<c0156158>] ? trace_hardirqs_on+0xb/0xd
     [<c0148d75>] ? __queue_work+0x2b/0x30
     [<c0f17eaf>] ? ibmphp_init+0x0/0x360
     [<c0f015a0>] kernel_init+0x17b/0x1e2
     [<c0f01425>] ? kernel_init+0x0/0x1e2
     [<c01178b3>] kernel_thread_helper+0x7/0x10
     =======================
    ---[ end trace a7919e7f17c0a725 ]---
    initcall ibmphp_init+0x0/0x360 returned -19 after 144 msecs
    calling  zt5550_init+0x0/0x6a @ 1
    
    the problem is this code:
    
            io_mem = ioremap (ebda_seg<<4, 65000);
    
    it assumes that the EBDA is 65000 bytes. But BIOS EBDA pointers are
    at most 1K large.
    
    _if_ the Rio code truly extends upon the customary EBDA size it needs
    to iounmap() this memory and ioremap() it larger, once it knows it from
    the generic descriptors that a Rio system is around.
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 52fd8ca6ad4124c15952ded35cfcf6adbd7ae8d4
Author: Vegard Nossum <vegard.nossum@gmail.com>
Date:   Wed Jul 30 09:29:06 2008 -0700

    IB/ipath: Use unsigned long for irq flags
    
    A few functions in the ipath driver incorrectly use unsigned int to
    hold irq flags for spin_lock_irqsave().
    
    This patch was generated using the Coccinelle framework with the
    following semantic patch:
    
    The semantic patch I used was this:
    
    @@
    expression lock;
    identifier flags;
    expression subclass;
    @@
    
    - unsigned int flags;
    + unsigned long flags;
    
    ...
    
    <+...
    
    (
     spin_lock_irqsave(lock, flags)
    |
     _spin_lock_irqsave(lock)
    |
     spin_unlock_irqrestore(lock, flags)
    |
     _spin_unlock_irqrestore(lock, flags)
    |
     read_lock_irqsave(lock, flags)
    |
     _read_lock_irqsave(lock)
    |
     read_unlock_irqrestore(lock, flags)
    |
     _read_unlock_irqrestore(lock, flags)
    |
     write_lock_irqsave(lock, flags)
    |
     _write_lock_irqsave(lock)
    |
     write_unlock_irqrestore(lock, flags)
    |
     _write_unlock_irqrestore(lock, flags)
    |
     spin_lock_irqsave_nested(lock, flags, subclass)
    |
     _spin_lock_irqsave_nested(lock, subclass)
    |
     spin_unlock_irqrestore(lock, flags)
    |
     _spin_unlock_irqrestore(lock, flags)
    |
     _raw_spin_lock_flags(lock, flags)
    |
     __raw_spin_lock_flags(lock, flags)
    )
    
    ...+>
    
    Cc: Ralph Campbell <ralph.campbell@qlogic.com>
    Cc: Julia Lawall <julia@diku.dk>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Vegard Nossum <vegard.nossum@gmail.com>
    Signed-off-by: Roland Dreier <rolandd@cisco.com>

commit 77bbadd5ea893f364a0d1879723037678a03725c
Author: Vegard Nossum <vegard.nossum@gmail.com>
Date:   Tue Jul 29 13:31:47 2008 +0200

    PS3: gelic: use unsigned long for irqflags
    
    The semantic patch I used was this:
    
    @@
    expression lock;
    identifier flags;
    expression subclass;
    @@
    
    - unsigned int flags;
    + unsigned long flags;
    
    ...
    
    <+...
    
    (
     spin_lock_irqsave(lock, flags)
    |
     _spin_lock_irqsave(lock)
    |
     spin_unlock_irqrestore(lock, flags)
    |
     _spin_unlock_irqrestore(lock, flags)
    |
     read_lock_irqsave(lock, flags)
    |
     _read_lock_irqsave(lock)
    |
     read_unlock_irqrestore(lock, flags)
    |
     _read_unlock_irqrestore(lock, flags)
    |
     write_lock_irqsave(lock, flags)
    |
     _write_lock_irqsave(lock)
    |
     write_unlock_irqrestore(lock, flags)
    |
     _write_unlock_irqrestore(lock, flags)
    |
     spin_lock_irqsave_nested(lock, flags, subclass)
    |
     _spin_lock_irqsave_nested(lock, subclass)
    |
     spin_unlock_irqrestore(lock, flags)
    |
     _spin_unlock_irqrestore(lock, flags)
    |
     _raw_spin_lock_flags(lock, flags)
    |
     __raw_spin_lock_flags(lock, flags)
    )
    
    ...+>
    
    This patch was generated using the Coccinelle framework.
    
    Cc: Masakazu Mokuno <mokuno@sm.sony.co.jp>
    Cc: Julia Lawall <julia@diku.dk>
    Cc: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Vegard Nossum <vegard.nossum@gmail.com>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 23add7455c42eef63f8719bd268328047d4aed69
Author: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>
Date:   Mon Jun 16 13:35:23 2008 +0300

    UBI: fix LEB locking
    
    leb_read_unlock() may be called simultaniously by several tasks.
    The would race at the following code:
    
     up_read(&le->mutex);
     if (free)
             kfree(le);
    
    And it is possible that one task frees 'le' before the other tasks
    do 'up_read()'. Fix this by doing up_read and free inside the
    'ubi->ltree' lock. Below it the oops we had because of this:
    
    BUG: spinlock bad magic on CPU#0, integck/7504
    BUG: unable to handle kernel paging request at 6b6b6c4f
    IP: [<c0211221>] spin_bug+0x5c/0xdb
    *pde = 00000000 Oops: 0000 [#1] PREEMPT SMP Modules linked in: ubifs ubi nandsim nand nand_ids nand_ecc video output
    
    Pid: 7504, comm: integck Not tainted (2.6.26-rc3ubifs26 #8)
    EIP: 0060:[<c0211221>] EFLAGS: 00010002 CPU: 0
    EIP is at spin_bug+0x5c/0xdb
    EAX: 00000032 EBX: 6b6b6b6b ECX: 6b6b6b6b EDX: f7f7ce30
    ESI: f76491dc EDI: c044f51f EBP: e8a736cc ESP: e8a736a8
    DS: 007b ES: 007b FS: 00d8 GS: 0033 SS: 0068
    Process integck (pid: 7504, ti=e8a72000 task=f7f7ce30 task.ti=e8a72000)
    Stack: c044f754 c044f51f 00000000 f7f7d024 00001d50 00000001 f76491dc 00000296       f6df50e0 e8a736d8 c02112f0 f76491dc e8a736e8 c039157a f7d9e830 f76491d8       e8a7370c c020b975 f76491dc 00000296 f76491f8 00000000 f76491d8 00000000 Call Trace:
    [<c02112f0>] ? _raw_spin_unlock+0x50/0x7c
    [<c039157a>] ? _spin_unlock_irqrestore+0x20/0x58
    [<c020b975>] ? rwsem_wake+0x4b/0x122
    [<c0390e0a>] ? call_rwsem_wake+0xa/0xc
    [<c0139ee7>] ? up_read+0x28/0x31
    [<f8873b3c>] ? leb_read_unlock+0x73/0x7b [ubi]
    [<f88742a3>] ? ubi_eba_read_leb+0x195/0x2b0 [ubi]
    [<f8872a04>] ? ubi_leb_read+0xaf/0xf8 [ubi]
    
    Signed-off-by: Artem Bityutskiy <Artem.Bityutskiy@nokia.com>

commit 65450cebc6a2efde80ed45514f727e6e4dc1eafd
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Wed Apr 30 00:54:25 2008 -0700

    pids: de_thread: don't clear session/pgrp pids for the old leader
    
    Based on Eric W. Biederman's idea.
    
    Unless task == current, without tasklist_lock held task_session()/task_pgrp()
    can return NULL if the caller races with de_thread() which switches the group
    leader.
    
    Change transfer_pid() to not clear old->pids[type].pid for the old leader.
    This means that its .pid can point to "nowhere", but this is already true for
    sub-threads, and the old leader is not group_leader() any longer.  IOW, with
    or without this change we can't trust task's special pids unless it is the
    group leader.
    
    With this change the following code
    
            rcu_read_lock();
            task = find_task_by_xxx();
            do_something(task_pgrp(task), task_session(task));
            rcu_read_unlock();
    
    can't race with exec and hit the NULL pid.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc:  "Eric W. Biederman" <ebiederm@xmission.com>
    Cc: Pavel Emelyanov <xemul@openvz.org>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 047f7617eba3653ff3bcfbe902986903fff2ed3b
Author: Bernard Pidoux <f6bvp@amsat.org>
Date:   Sun Apr 20 15:58:07 2008 -0700

    [ROSE]: Fix soft lockup wrt. rose_node_list_lock
    
    [ INFO: possible recursive locking detected ]
    2.6.25 #3
    ---------------------------------------------
    ax25ipd/3811 is trying to acquire lock:
      (rose_node_list_lock){-+..}, at: [<f8d31f1a>] rose_get_neigh+0x1a/0xa0
    [rose]
    
    but task is already holding lock:
      (rose_node_list_lock){-+..}, at: [<f8d31fed>]
    rose_route_frame+0x4d/0x620 [rose]
    
    other info that might help us debug this:
    6 locks held by ax25ipd/3811:
      #0:  (&tty->atomic_write_lock){--..}, at: [<c0259a1c>]
    tty_write_lock+0x1c/0x50
      #1:  (rcu_read_lock){..--}, at: [<c02aea36>] net_rx_action+0x96/0x230
      #2:  (rcu_read_lock){..--}, at: [<c02ac5c0>] netif_receive_skb+0x100/0x2f0
      #3:  (rose_node_list_lock){-+..}, at: [<f8d31fed>]
    rose_route_frame+0x4d/0x620 [rose]
      #4:  (rose_neigh_list_lock){-+..}, at: [<f8d31ff7>]
    rose_route_frame+0x57/0x620 [rose]
      #5:  (rose_route_list_lock){-+..}, at: [<f8d32001>]
    rose_route_frame+0x61/0x620 [rose]
    
    stack backtrace:
    Pid: 3811, comm: ax25ipd Not tainted 2.6.25 #3
      [<c0147e27>] print_deadlock_bug+0xc7/0xd0
      [<c0147eca>] check_deadlock+0x9a/0xb0
      [<c0149cd2>] validate_chain+0x1e2/0x310
      [<c0149b95>] ? validate_chain+0xa5/0x310
      [<c010a7d8>] ? native_sched_clock+0x88/0xc0
      [<c0149fa1>] __lock_acquire+0x1a1/0x750
      [<c014a5d1>] lock_acquire+0x81/0xa0
      [<f8d31f1a>] ? rose_get_neigh+0x1a/0xa0 [rose]
      [<c03201a3>] _spin_lock_bh+0x33/0x60
      [<f8d31f1a>] ? rose_get_neigh+0x1a/0xa0 [rose]
      [<f8d31f1a>] rose_get_neigh+0x1a/0xa0 [rose]
      [<f8d32404>] rose_route_frame+0x464/0x620 [rose]
      [<c031ffdd>] ? _read_unlock+0x1d/0x20
      [<f8d31fa0>] ? rose_route_frame+0x0/0x620 [rose]
      [<f8d1c396>] ax25_rx_iframe+0x66/0x3b0 [ax25]
      [<f8d1f42f>] ? ax25_start_t3timer+0x1f/0x40 [ax25]
      [<f8d1e65b>] ax25_std_frame_in+0x7fb/0x890 [ax25]
      [<c0320005>] ? _spin_unlock_bh+0x25/0x30
      [<f8d1bdf6>] ax25_kiss_rcv+0x2c6/0x800 [ax25]
      [<c02a4769>] ? sock_def_readable+0x59/0x80
      [<c014a8a7>] ? __lock_release+0x47/0x70
      [<c02a4769>] ? sock_def_readable+0x59/0x80
      [<c031ffdd>] ? _read_unlock+0x1d/0x20
      [<c02a4769>] ? sock_def_readable+0x59/0x80
      [<c02a4d3a>] ? sock_queue_rcv_skb+0x13a/0x1d0
      [<c02a4c45>] ? sock_queue_rcv_skb+0x45/0x1d0
      [<f8d1bb30>] ? ax25_kiss_rcv+0x0/0x800 [ax25]
      [<c02ac715>] netif_receive_skb+0x255/0x2f0
      [<c02ac5c0>] ? netif_receive_skb+0x100/0x2f0
      [<c02af05c>] process_backlog+0x7c/0xf0
      [<c02aeb0c>] net_rx_action+0x16c/0x230
      [<c02aea36>] ? net_rx_action+0x96/0x230
      [<c012bd53>] __do_softirq+0x93/0x120
      [<f8d2a68a>] ? mkiss_receive_buf+0x33a/0x3f0 [mkiss]
      [<c012be37>] do_softirq+0x57/0x60
      [<c012c265>] local_bh_enable_ip+0xa5/0xe0
      [<c0320005>] _spin_unlock_bh+0x25/0x30
      [<f8d2a68a>] mkiss_receive_buf+0x33a/0x3f0 [mkiss]
      [<c025ea37>] pty_write+0x47/0x60
      [<c025c620>] write_chan+0x1b0/0x220
      [<c0259a1c>] ? tty_write_lock+0x1c/0x50
      [<c011fec0>] ? default_wake_function+0x0/0x10
      [<c0259bea>] tty_write+0x12a/0x1c0
      [<c025c470>] ? write_chan+0x0/0x220
      [<c018bbc6>] vfs_write+0x96/0x130
      [<c0259ac0>] ? tty_write+0x0/0x1c0
      [<c018c24d>] sys_write+0x3d/0x70
      [<c0104d1e>] sysenter_past_esp+0x5f/0xa5
      =======================
    BUG: soft lockup - CPU#0 stuck for 61s! [ax25ipd:3811]
    
    Pid: 3811, comm: ax25ipd Not tainted (2.6.25 #3)
    EIP: 0060:[<c010a9db>] EFLAGS: 00000246 CPU: 0
    EIP is at native_read_tsc+0xb/0x20
    EAX: b404aa2c EBX: b404a9c9 ECX: 017f1000 EDX: 0000076b
    ESI: 00000001 EDI: 00000000 EBP: ecc83afc ESP: ecc83afc
      DS: 007b ES: 007b FS: 00d8 GS: 0033 SS: 0068
    CR0: 8005003b CR2: b7f5f000 CR3: 2cd8e000 CR4: 000006f0
    DR0: 00000000 DR1: 00000000 DR2: 00000000 DR3: 00000000
    DR6: ffff0ff0 DR7: 00000400
      [<c0204937>] delay_tsc+0x17/0x30
      [<c02048e9>] __delay+0x9/0x10
      [<c02127f6>] __spin_lock_debug+0x76/0xf0
      [<c0212618>] ? spin_bug+0x18/0x100
      [<c0147923>] ? __lock_contended+0xa3/0x110
      [<c0212998>] _raw_spin_lock+0x68/0x90
      [<c03201bf>] _spin_lock_bh+0x4f/0x60
      [<f8d31f1a>] ? rose_get_neigh+0x1a/0xa0 [rose]
      [<f8d31f1a>] rose_get_neigh+0x1a/0xa0 [rose]
      [<f8d32404>] rose_route_frame+0x464/0x620 [rose]
      [<c031ffdd>] ? _read_unlock+0x1d/0x20
      [<f8d31fa0>] ? rose_route_frame+0x0/0x620 [rose]
      [<f8d1c396>] ax25_rx_iframe+0x66/0x3b0 [ax25]
      [<f8d1f42f>] ? ax25_start_t3timer+0x1f/0x40 [ax25]
      [<f8d1e65b>] ax25_std_frame_in+0x7fb/0x890 [ax25]
      [<c0320005>] ? _spin_unlock_bh+0x25/0x30
      [<f8d1bdf6>] ax25_kiss_rcv+0x2c6/0x800 [ax25]
      [<c02a4769>] ? sock_def_readable+0x59/0x80
      [<c014a8a7>] ? __lock_release+0x47/0x70
      [<c02a4769>] ? sock_def_readable+0x59/0x80
      [<c031ffdd>] ? _read_unlock+0x1d/0x20
      [<c02a4769>] ? sock_def_readable+0x59/0x80
      [<c02a4d3a>] ? sock_queue_rcv_skb+0x13a/0x1d0
      [<c02a4c45>] ? sock_queue_rcv_skb+0x45/0x1d0
      [<f8d1bb30>] ? ax25_kiss_rcv+0x0/0x800 [ax25]
      [<c02ac715>] netif_receive_skb+0x255/0x2f0
      [<c02ac5c0>] ? netif_receive_skb+0x100/0x2f0
      [<c02af05c>] process_backlog+0x7c/0xf0
      [<c02aeb0c>] net_rx_action+0x16c/0x230
      [<c02aea36>] ? net_rx_action+0x96/0x230
      [<c012bd53>] __do_softirq+0x93/0x120
      [<f8d2a68a>] ? mkiss_receive_buf+0x33a/0x3f0 [mkiss]
      [<c012be37>] do_softirq+0x57/0x60
      [<c012c265>] local_bh_enable_ip+0xa5/0xe0
      [<c0320005>] _spin_unlock_bh+0x25/0x30
      [<f8d2a68a>] mkiss_receive_buf+0x33a/0x3f0 [mkiss]
      [<c025ea37>] pty_write+0x47/0x60
      [<c025c620>] write_chan+0x1b0/0x220
      [<c0259a1c>] ? tty_write_lock+0x1c/0x50
      [<c011fec0>] ? default_wake_function+0x0/0x10
      [<c0259bea>] tty_write+0x12a/0x1c0
      [<c025c470>] ? write_chan+0x0/0x220
      [<c018bbc6>] vfs_write+0x96/0x130
      [<c0259ac0>] ? tty_write+0x0/0x1c0
      [<c018c24d>] sys_write+0x3d/0x70
      [<c0104d1e>] sysenter_past_esp+0x5f/0xa5
      =======================
    
    Since rose_route_frame() does not use rose_node_list we can safely
    remove rose_node_list_lock spin lock here and let it be free for
    rose_get_neigh().
    
    Signed-off-by: Bernard Pidoux <f6bvp@amsat.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4dee959723e2bf3a0f9343a46841cd2f0029d424
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Mon Apr 14 00:44:52 2008 -0700

    [NETFILTER]: ipt_CLUSTERIP: fix race between clusterip_config_find_get and _entry_put
    
    Consider we are putting a clusterip_config entry with the "entries"
    count == 1, and on the other CPU there's a clusterip_config_find_get
    in progress:
    
    CPU1:                                                   CPU2:
    clusterip_config_entry_put:                             clusterip_config_find_get:
    if (atomic_dec_and_test(&c->entries)) {
            /* true */
                                                            read_lock_bh(&clusterip_lock);
                                                            c = __clusterip_config_find(clusterip);
                                                            /* found - it's still in list */
                                                            ...
                                                            atomic_inc(&c->entries);
                                                            read_unlock_bh(&clusterip_lock);
    
            write_lock_bh(&clusterip_lock);
            list_del(&c->list);
            write_unlock_bh(&clusterip_lock);
            ...
            dev_put(c->dev);
    
    Oops! We have an entry returned by the clusterip_config_find_get,
    which is a) not in list b) has a stale dev pointer.
    
    The problems will happen when the CPU2 will release the entry - it
    will remove it from the list for the 2nd time, thus spoiling it, and
    will put a stale dev pointer.
    
    The fix is to make atomic_dec_and_test under the clusterip_lock.
    
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Patrick McHardy <kaber@trash.net>

commit f99b751fca5b16bea53c0d6724935e1949350052
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Wed Jan 16 21:47:40 2008 +0100

    mac80211: fix RCU locking in __ieee80211_rx_handle_packet
    
    Commit c7a51bda ("mac80211: restructure __ieee80211_rx") extracted
    __ieee80211_rx_handle_packet out of __ieee80211_rx and hence changed
    the locking rules for __ieee80211_rx_handle_packet(), it is now
    invoked under RCU lock. There is, however, one instance left where
    it contains an rcu_read_unlock() in an error path, which is a bug.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit ab63a633cf072c719f885e46fa4814624312f672
Author: Peter Zijlstra <a.p.zijlstra@chello.nl>
Date:   Thu Oct 25 14:02:45 2007 +0200

    sched: fix unconditional irq lock
    
    Lockdep noticed that this lock can also be taken from hardirq context, and can
    thus not unconditionally disable/enable irqs.
    
     WARNING: at kernel/lockdep.c:2033 trace_hardirqs_on()
      [show_trace_log_lvl+26/48] show_trace_log_lvl+0x1a/0x30
      [show_trace+18/32] show_trace+0x12/0x20
      [dump_stack+22/32] dump_stack+0x16/0x20
      [trace_hardirqs_on+405/416] trace_hardirqs_on+0x195/0x1a0
      [_read_unlock_irq+34/48] _read_unlock_irq+0x22/0x30
      [sched_debug_show+2615/4224] sched_debug_show+0xa37/0x1080
      [show_state_filter+326/368] show_state_filter+0x146/0x170
      [sysrq_handle_showstate+10/16] sysrq_handle_showstate+0xa/0x10
      [__handle_sysrq+123/288] __handle_sysrq+0x7b/0x120
      [handle_sysrq+40/64] handle_sysrq+0x28/0x40
      [kbd_event+1045/1680] kbd_event+0x415/0x690
      [input_pass_event+206/208] input_pass_event+0xce/0xd0
      [input_handle_event+170/928] input_handle_event+0xaa/0x3a0
      [input_event+95/112] input_event+0x5f/0x70
      [atkbd_interrupt+434/1456] atkbd_interrupt+0x1b2/0x5b0
      [serio_interrupt+59/128] serio_interrupt+0x3b/0x80
      [i8042_interrupt+263/576] i8042_interrupt+0x107/0x240
      [handle_IRQ_event+40/96] handle_IRQ_event+0x28/0x60
      [handle_edge_irq+175/320] handle_edge_irq+0xaf/0x140
      [do_IRQ+64/128] do_IRQ+0x40/0x80
      [common_interrupt+46/52] common_interrupt+0x2e/0x34
    
    Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit cf7b708c8d1d7a27736771bcf4c457b332b0f818
Author: Pavel Emelyanov <xemul@openvz.org>
Date:   Thu Oct 18 23:39:54 2007 -0700

    Make access to task's nsproxy lighter
    
    When someone wants to deal with some other taks's namespaces it has to lock
    the task and then to get the desired namespace if the one exists.  This is
    slow on read-only paths and may be impossible in some cases.
    
    E.g.  Oleg recently noticed a race between unshare() and the (sent for
    review in cgroups) pid namespaces - when the task notifies the parent it
    has to know the parent's namespace, but taking the task_lock() is
    impossible there - the code is under write locked tasklist lock.
    
    On the other hand switching the namespace on task (daemonize) and releasing
    the namespace (after the last task exit) is rather rare operation and we
    can sacrifice its speed to solve the issues above.
    
    The access to other task namespaces is proposed to be performed
    like this:
    
         rcu_read_lock();
         nsproxy = task_nsproxy(tsk);
         if (nsproxy != NULL) {
                 / *
                   * work with the namespaces here
                   * e.g. get the reference on one of them
                   * /
         } / *
             * NULL task_nsproxy() means that this task is
             * almost dead (zombie)
             * /
         rcu_read_unlock();
    
    This patch has passed the review by Eric and Oleg :) and,
    of course, tested.
    
    [clg@fr.ibm.com: fix unshare()]
    [ebiederm@xmission.com: Update get_net_ns_by_pid]
    Signed-off-by: Pavel Emelyanov <xemul@openvz.org>
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Cc: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Serge Hallyn <serue@us.ibm.com>
    Signed-off-by: Cedric Le Goater <clg@fr.ibm.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 9b013e05e0289c190a53d78ca029e2f21c0e4485
Author: Olof Johansson <olof@lixom.net>
Date:   Thu Oct 18 21:48:39 2007 -0700

    [NET]: Fix bug in sk_filter race cures.
    
    Looks like this might be causing problems, at least for me on ppc. This
    happened during a normal boot, right around first interface config/dhcp
    run..
    
    cpu 0x0: Vector: 300 (Data Access) at [c00000000147b820]
        pc: c000000000435e5c: .sk_filter_delayed_uncharge+0x1c/0x60
        lr: c0000000004360d0: .sk_attach_filter+0x170/0x180
        sp: c00000000147baa0
       msr: 9000000000009032
       dar: 4
     dsisr: 40000000
      current = 0xc000000004780fa0
      paca    = 0xc000000000650480
        pid   = 1295, comm = dhclient3
    0:mon> t
    [c00000000147bb20] c0000000004360d0 .sk_attach_filter+0x170/0x180
    [c00000000147bbd0] c000000000418988 .sock_setsockopt+0x788/0x7f0
    [c00000000147bcb0] c000000000438a74 .compat_sys_setsockopt+0x4e4/0x5a0
    [c00000000147bd90] c00000000043955c .compat_sys_socketcall+0x25c/0x2b0
    [c00000000147be30] c000000000007508 syscall_exit+0x0/0x40
    --- Exception: c01 (System Call) at 000000000ff618d8
    SP (fffdf040) is in userspace
    0:mon>
    
    I.e. null pointer deref at sk_filter_delayed_uncharge+0x1c:
    
    0:mon> di $.sk_filter_delayed_uncharge
    c000000000435e40  7c0802a6      mflr    r0
    c000000000435e44  fbc1fff0      std     r30,-16(r1)
    c000000000435e48  7c8b2378      mr      r11,r4
    c000000000435e4c  ebc2cdd0      ld      r30,-12848(r2)
    c000000000435e50  f8010010      std     r0,16(r1)
    c000000000435e54  f821ff81      stdu    r1,-128(r1)
    c000000000435e58  380300a4      addi    r0,r3,164
    c000000000435e5c  81240004      lwz     r9,4(r4)
    
    That's the deref of fp:
    
    static void sk_filter_delayed_uncharge(struct sock *sk, struct sk_filter *fp)
    {
            unsigned int size = sk_filter_len(fp);
    ...
    
    That is called from sk_attach_filter():
    
    ...
            rcu_read_lock_bh();
            old_fp = rcu_dereference(sk->sk_filter);
            rcu_assign_pointer(sk->sk_filter, fp);
            rcu_read_unlock_bh();
    
            sk_filter_delayed_uncharge(sk, old_fp);
            return 0;
    ...
    
    So, looks like rcu_dereference() returned NULL. I don't know the
    filter code at all, but it seems like it might be a valid case?
    sk_detach_filter() seems to handle a NULL sk_filter, at least.
    
    So, this needs review by someone who knows the filter, but it fixes the
    problem for me:
    
    Signed-off-by: Olof Johansson <olof@lixom.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 10b726e7cd765ef571109e386882cd2e2d77b9af
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Aug 21 21:09:15 2007 -0700

    [PATCH] NET: Fix missing rcu unlock in __sock_create()
    
    [NET]: Fix unbalanced rcu_read_unlock in __sock_create
    
    The recent RCU work created an unbalanced rcu_read_unlock
    in __sock_create.  This patch fixes that.  Reported by
    oleg 123.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 2f4e6e2a814eb1305a873a045401708d73f870bc
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Tue Oct 16 23:26:58 2007 -0700

    wait_task_zombie: fix 2/3 races vs forget_original_parent()
    
    Two threads, T1 and T2.  T2 ptraces P, and P is not a child of ptracer's
    thread group.  P exits and goes to TASK_ZOMBIE.
    
    T1 does wait_task_zombie(P):
    
            P->exit_state = TASK_DEAD;
            ...
            read_unlock(&tasklist_lock);
    
                                            T2 does exit(), takes tasklist,
                                            forget_original_parent() does
                                            __ptrace_unlink(P) but doesn't
                                            call do_notify_parent(P) because
                                            p->exit_state == EXIT_DEAD.
    
    Now, P is not visible to our process: __ptrace_unlink() removed it from
    ->children. We should send notification to P->parent and release P if and
    only if SIGCHLD is ignored.
    
    And we have 3 bugs:
    
    1. P->parent does do_wait() and gets -ECHILD (P is on ->parent->children,
       but its state is TASK_DEAD).
    
    2. // wait_task_zombie() continues
    
            if (put_user(...)) {
                    // TODO: is this safe?
                    p->exit_state = EXIT_ZOMBIE;
                    return;
            }
    
       we return without notification/release, task_struct leaked.
    
       Solution: ignore -EFAULT and proceed. It is an application's bug if
       we can't fill infop/stat_addr (in case of VM_FAULT_OOM we have much
       more problems).
    
    3. // wait_task_zombie() continues
    
            if (p->real_parent != p->parent) {
                    // Not taken, it was untraced'ed
                    ...
            }
    
            release_task(p);
    
       we released the task which we shouldn't.
    
       Solution: check ->real_parent != ->parent before, under tasklist_lock,
       but use ptrace_unlink() instead of __ptrace_unlink() to check ->ptrace.
    
    This patch hopefully solves 2 and 3, the 1st bug will be fixed later, we need
    some cleanups in forget_original_parent/reparent_thread.
    
    However, the first race is very unlikely and not critical, so I hope it makes
    sense to fix 1 and 2 for now.
    
    4. Small cleanup: don't "restore" EXIT_ZOMBIE unless we know we are not going
       to realease the child.
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Roland McGrath <roland@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 87400c04753674f546c7779abf536d2a3b5e0b7e
Author: Alexey Dobriyan <adobriyan@gmail.com>
Date:   Tue Oct 16 23:26:19 2007 -0700

    fs/proc/mmu.c: headers butchery
    
    fs/proc/mmu.c consists of only one function which uses only:
    1) struct vmalloc_info *
    2) struct vm_struct *
    3) struct vmalloc_info
    4) vmlist
    5) VMALLOC_TOTAL, VMALLOC_START, VMALLOC_END
    6) read_lock, read_unlock
    7) vmlist_lock
    8) struct vm_struct
    
    This gives us linux/spinlock.h, asm/pgtable.h, "internal.h", linux/vmalloc.h.
    asm/pgtable.h uses PKMAP_BASE on i386, for which asm/highmem.h is needed.
    But, linux/highmem.h is actually used to make it compile everywhere.
    I'll deal later with this particular i386 surprise.
    
    Cross-compile tested on many archs and configs.
    
    Signed-off-by: Alexey Dobriyan <adobriyan@gmail.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 82ba56c273911f7eda79849cfa0fc2d2e5a3b75b
Author: Dmitry Torokhov <dmitry.torokhov@gmail.com>
Date:   Sat Oct 13 15:46:55 2007 -0400

    Input: use full RCU API
    
    RT guys alerted me to the fact that in their tree spinlocks
    are preemptible and it is better to use full RCU API
    (rcu_read_lock()/rcu_read_unlock()) to be safe.
    
    Signed-off-by: Dmitry Torokhov <dtor@mail.ru>

commit d4e46a3d9869563c6210b01bb651c40cbe65da80
Author: Johannes Berg <johannes@sipsolutions.net>
Date:   Fri Sep 14 11:10:24 2007 -0400

    [MAC80211]: fix race conditions with keys
    
    During receive processing, we select the key long before using it and
    because there's no locking it is possible that we kfree() the key
    after having selected it but before using it for crypto operations.
    Obviously, this is bad.
    
    Secondly, during transmit processing, there are two possible races: We
    have a similar race between select_key() and using it for encryption,
    but we also have a race here between select_key() and hardware
    encryption (both when a key is removed.)
    
    This patch solves these issues by using RCU: when a key is to be freed,
    we first remove the pointer from the appropriate places (sdata->keys,
    sdata->default_key, sta->key) using rcu_assign_pointer() and then
    synchronize_rcu(). Then, we can safely kfree() the key and remove it
    from the hardware. There's a window here where the hardware may still
    be using it for decryption, but we can't work around that without having
    two hardware callbacks, one to disable the key for RX and one to disable
    it for TX; but the worst thing that will happen is that we receive a
    packet decrypted that we don't find a key for any more and then drop it.
    
    When we add a key, we first need to upload it to the hardware and then,
    using rcu_assign_pointer() again, link it into our structures.
    
    In the code using keys (TX/RX paths) we use rcu_dereference() to get the
    key and enclose the whole tx/rx section in a rcu_read_lock() ...
    rcu_read_unlock() block. Because we've uploaded the key to hardware
    before linking it into internal structures, we can guarantee that it is
    valid once get to into tx().
    
    One possible race condition remains, however: when we have hardware
    acceleration enabled and the driver shuts down the queues, we end up
    queueing the frame. If now somebody removes the key, the key will be
    removed from hwaccel and then then driver will be asked to encrypt the
    frame with a key index that has been removed. Hence, drivers will need
    to be aware that the hw_key_index they are passed might not be under
    all circumstances. Most drivers will, however, simply ignore that
    condition and encrypt the frame with the selected key anyway, this
    only results in a frame being encrypted with a wrong key or dropped
    (rightfully) because the key was not valid. There isn't much we can
    do about it unless we want to walk the pending frame queue every time
    a key is removed and remove all frames that used it.
    
    This race condition, however, will most likely be solved once we add
    multiqueue support to mac80211 because then frames will be queued
    further up the stack instead of after being processed.
    
    Signed-off-by: Johannes Berg <johannes@sipsolutions.net>
    Acked-by: Michael Wu <flamingice@sourmilk.net>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b13778e09272469203cb8d100defd8047a2117df
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Tue Aug 21 21:09:15 2007 -0700

    NET: Fix missing rcu unlock in __sock_create()
    
    [NET]: Fix unbalanced rcu_read_unlock in __sock_create
    
    The recent RCU work created an unbalanced rcu_read_unlock
    in __sock_create.  This patch fixes that.  Reported by
    oleg 123.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 605a494e4df0b2dabdebcdfee99536b0f6a22adc
Merge: 585eb6daa4b6 660adc6e60bc
Author: Linus Torvalds <torvalds@woody.linux-foundation.org>
Date:   Sat Aug 18 09:34:09 2007 -0700

    Merge branch 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6
    
    * 'master' of master.kernel.org:/pub/scm/linux/kernel/git/davem/net-2.6:
      [IPv6]: Invalid semicolon after if statement
      [NET]: Fix unbalanced rcu_read_unlock in __sock_create
      [VLAN] net/8021q/vlanproc.c: fix check-after-use
      [NET]: Unexport dev_ethtool
      [IOAT]: Remove redundant struct member to avoid descriptor cache miss
      [ECONET]: remove econet_packet_type on unload
      [AX25]: don't free pointers to statically allocated data
      [PATCH] mac80211: probe for hidden SSIDs in pre-auth scan
      [PATCH] mac80211: fix tx status frame code
      [BRIDGE]: Fix typo in net/bridge/br_stp_if.c
      [BRIDGE]: sysfs locking fix.
      [NETFILTER]: nf_nat_sip: don't drop short packets
      [NETFILTER]: nf_conntrack_sip: fix SIP-URI parsing
      [NETFILTER]: nf_conntrack_sip: check sname != NULL before calling strncmp
      [NETFILTER]: netfilter: xt_u32 bug correction

commit 3b1855255098e1f78fa74c0f3378c0391e9a7a2b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Wed Aug 15 14:46:02 2007 -0700

    [NET]: Fix unbalanced rcu_read_unlock in __sock_create
    
    The recent RCU work created an unbalanced rcu_read_unlock
    in __sock_create.  This patch fixes that.  Reported by
    oleg 123.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a7ab4b501f9b8a9dc4d5cee542db67b6ccd1088b
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Sun Jun 10 17:33:08 2007 -0700

    [TCPv4]: Improve BH latency in /proc/net/tcp
    
    Currently the code for /proc/net/tcp disable BH while iterating
    over the entire established hash table.  Even though we call
    cond_resched_softirq for each entry, we still won't process
    softirq's as regularly as we would otherwise do which results
    in poor performance when the system is loaded near capacity.
    
    This anomaly comes from the 2.4 code where this was all in a
    single function and the local_bh_disable might have made sense
    as a small optimisation.
    
    The cost of each local_bh_disable is so small when compared
    against the increased latency in keeping it disabled over a
    large but mostly empty TCP established hash table that we
    should just move it to the individual read_lock/read_unlock
    calls as we do in inet_diag.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit b19cbe2a1695c09c74f83646c4b82b51123b3690
Author: Patrick McHardy <kaber@trash.net>
Date:   Thu Mar 22 12:25:20 2007 -0700

    [BRIDGE]: Fix fdb RCU race
    
    br_fdb_get use atomic_inc to increase the refcount of an element found
    on a RCU protected list, which can lead to the following race:
    
    CPU0                                    CPU1
    
                                            br_fdb_get:   rcu_read_lock
                                            __br_fdb_get: find element
    fdb_delete:   hlist_del_rcu
                  br_fdb_put
    br_fdb_put:   atomic_dec_and_test
                  call_rcu(fdb_rcu_free)    br_fdb_get:   atomic_inc
                                                          rcu_read_unlock
    fdb_rcu_free: kmem_cache_free
    
    Use atomic_inc_not_zero instead.
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 923f4902fefdf4e89b0fb32c4e069d4f57d704f5
Author: Patrick McHardy <kaber@trash.net>
Date:   Mon Feb 12 11:12:57 2007 -0800

    [NETFILTER]: nf_conntrack: properly use RCU API for nf_ct_protos/nf_ct_l3protos arrays
    
    Replace preempt_{enable,disable} based RCU by proper use of the
    RCU API and add missing rcu_read_lock/rcu_read_unlock calls in
    all paths not obviously only used within packet process context
    (nfnetlink_conntrack).
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 642d628b2c92e5283bbd3c849c7099c64ab68856
Author: Patrick McHardy <kaber@trash.net>
Date:   Mon Feb 12 11:12:40 2007 -0800

    [NETFILTER]: ip_conntrack: properly use RCU API for ip_ct_protos array
    
    Replace preempt_{enable,disable} based RCU by proper use of the
    RCU API and add missing rcu_read_lock/rcu_read_unlock calls in
    all paths not obviously only used within packet process context
    (nfnetlink_conntrack).
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit e22a05486913ccb959281cd6370593bd8e197fa9
Author: Patrick McHardy <kaber@trash.net>
Date:   Mon Feb 12 11:12:26 2007 -0800

    [NETFILTER]: nf_nat: properly use RCU API for nf_nat_protos array
    
    Replace preempt_{enable,disable} based RCU by proper use of the
    RCU API and add missing rcu_read_lock/rcu_read_unlock calls in
    paths used outside of packet processing context (nfnetlink_conntrack).
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a441dfdbb2e54217b8d26a6c129650728d401bf7
Author: Patrick McHardy <kaber@trash.net>
Date:   Mon Feb 12 11:12:09 2007 -0800

    [NETFILTER]: ip_nat: properly use RCU API for ip_nat_protos array
    
    Replace preempt_{enable,disable} based RCU by proper use of the
    RCU API and add missing rcu_read_lock/rcu_read_unlock calls in
    paths used outside of packet processing context (nfnetlink_conntrack).
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 012d3ca8d85bf3ae5278ba897dd1ca3999247107
Author: Josh Triplett <josh@joshtriplett.org>
Date:   Wed Dec 6 20:40:19 2006 -0800

    [PATCH] Add Sparse annotations to SRCU wrapper functions in rcutorture
    
    The SRCU wrapper functions srcu_torture_read_lock and
    srcu_torture_read_unlock in rcutorture intentionally change the SRCU
    context; annotate them accordingly, to avoid a warning.
    
    Signed-off-by: Josh Triplett <josh@freedesktop.org>
    Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 621934ee7ed5b073c7fd638b347e632c53572761
Author: Paul E. McKenney <paulmck@us.ibm.com>
Date:   Wed Oct 4 02:17:02 2006 -0700

    [PATCH] srcu-3: RCU variant permitting read-side blocking
    
    Updated patch adding a variant of RCU that permits sleeping in read-side
    critical sections.  SRCU is as follows:
    
    o       Each use of SRCU creates its own srcu_struct, and each
            srcu_struct has its own set of grace periods.  This is
            critical, as it prevents one subsystem with a blocking
            reader from holding up SRCU grace periods for other
            subsystems.
    
    o       The SRCU primitives (srcu_read_lock(), srcu_read_unlock(),
            and synchronize_srcu()) all take a pointer to a srcu_struct.
    
    o       The SRCU primitives must be called from process context.
    
    o       srcu_read_lock() returns an int that must be passed to
            the matching srcu_read_unlock().  Realtime RCU avoids the
            need for this by storing the state in the task struct,
            but SRCU needs to allow a given code path to pass through
            multiple SRCU domains -- storing state in the task struct
            would therefore require either arbitrary space in the
            task struct or arbitrary limits on SRCU nesting.  So I
            kicked the state-storage problem up to the caller.
    
            Of course, it is not permitted to call synchronize_srcu()
            while in an SRCU read-side critical section.
    
    o       There is no call_srcu().  It would not be hard to implement
            one, but it seems like too easy a way to OOM the system.
            (Hey, we have enough trouble with call_rcu(), which does
            -not- permit readers to sleep!!!)  So, if you want it,
            please tell me why...
    
    [josht@us.ibm.com: sparse notation]
    Signed-off-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Josh Triplett <josh@freedesktop.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit a49a4af759c0193d42aeaeefb4df7de8973dd713
Author: Josh Triplett <josh@joshtriplett.org>
Date:   Fri Sep 29 01:59:30 2006 -0700

    [PATCH] rcu: add lock annotations to rcu{,_bh}_torture_read_{lock,unlock}
    
    rcu_torture_read_lock and rcu_bh_torture_read_lock acquire locks without
    releasing them, and the matching functions rcu_torture_read_unlock and
    rcu_bh_torture_read_unlock get called with the corresponding locks held and
    release them.  Add lock annotations to these four functions so that sparse
    can check callers for lock pairing, and so that sparse will not complain
    about these functions since they intentionally use locks in this manner.
    
    Signed-off-by: Josh Triplett <josh@freedesktop.org>
    Acked-by: Paul McKenney <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 7f04ac062e92a37bb0fa3313405597244b4702c1
Author: Josh Triplett <josh@joshtriplett.org>
Date:   Fri Jun 30 01:56:05 2006 -0700

    [PATCH] rcu: Add lock annotations to RCU locking primitives
    
    Add __acquire annotations to rcu_read_lock and rcu_read_lock_bh, and add
    __release annotations to rcu_read_unlock and rcu_read_unlock_bh.  This
    allows sparse to detect improperly paired calls to these functions.
    
    Signed-off-by: Josh Triplett <josh@freedesktop.org>
    Acked-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 1bc1731133140dccdd08899a59bbc06d975d0a15
Author: Josh Triplett <josh@joshtriplett.org>
Date:   Thu Jun 29 17:02:31 2006 -0700

    [IrDA]: Fix RCU lock pairing on error path
    
    irlan_client_discovery_indication calls rcu_read_lock and rcu_read_unlock, but
    returns without unlocking in an error case.  Fix that by replacing the return
    with a goto so that the rcu_read_unlock always gets executed.
    
    Signed-off-by: Josh Triplett <josh@freedesktop.org>
    Acked-by: Paul E. McKenney <paulmck@us.ibm.com>
    Signed-off-by: Samuel Ortiz samuel@sortiz.org <>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 8c7904a00b06d2ee51149794b619e07369fcf9d4
Author: Eric W. Biederman <ebiederm@xmission.com>
Date:   Fri Mar 31 02:31:37 2006 -0800

    [PATCH] task: RCU protect task->usage
    
    A big problem with rcu protected data structures that are also reference
    counted is that you must jump through several hoops to increase the reference
    count.  I think someone finally implemented atomic_inc_not_zero(&count) to
    automate the common case.  Unfortunately this means you must special case the
    rcu access case.
    
    When data structures are only visible via rcu in a manner that is not
    determined by the reference count on the object (i.e.  tasks are visible until
    their zombies are reaped) there is a much simpler technique we can employ.
    Simply delaying the decrement of the reference count until the rcu interval is
    over.
    
    What that means is that the proc code that looks up a task and later
    wants to sleep can now do:
    
    rcu_read_lock();
    task = find_task_by_pid(some_pid);
    if (task) {
            get_task_struct(task);
    }
    rcu_read_unlock();
    
    The effect on the rest of the kernel is that put_task_struct becomes cheaper
    and immediate, and in the case where the task has been reaped it frees the
    task immediate instead of unnecessarily waiting an until the rcu interval is
    over.
    
    Cleanup of task_struct does not happen when its reference count drops to
    zero, instead cleanup happens when release_task is called.  Tasks can only
    be looked up via rcu before release_task is called.  All rcu protected
    members of task_struct are freed by release_task.
    
    Therefore we can move call_rcu from put_task_struct into release_task.  And
    we can modify release_task to not immediately release the reference count
    but instead have it call put_task_struct from the function it gives to
    call_rcu.
    
    The end result:
    
    - get_task_struct is safe in an rcu context where we have just looked
      up the task.
    
    - put_task_struct() simplifies into its old pre rcu self.
    
    This reorganization also makes put_task_struct uncallable from modules as
    it is not exported but it does not appear to be called from any modules so
    this should not be an issue, and is trivially fixed.
    
    Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 6146e6a43b3584c0c67b0ac94e3f14fdc618bd30
Author: Luiz Capitulino <lcapitulino@mandriva.com.br>
Date:   Mon Mar 20 22:24:45 2006 -0800

    [PKTGEN]: Removes thread_{un,}lock() macros.
    
    As suggested by Arnaldo, this patch replaces the
    thread_lock()/thread_unlock() by directly calls to
    mutex_lock()/mutex_unlock().
    
    This change makes the code a bit more readable, and the direct calls
    are used everywhere in the kernel.
    
    Signed-off-by: Luiz Capitulino <lcapitulino@mandriva.com.br>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 140ffcec4def3ee3af7565b2cf1d3b2580f7e180
Author: Andrew Morton <akpm@osdl.org>
Date:   Thu Mar 2 02:54:28 2006 -0800

    [PATCH] out_of_memory() locking fix
    
    I seem to have lost this read_unlock().
    
    While we're there, let's turn that interruptible sleep unto uninterruptible,
    so we don't get a busywait if signal_pending().  (Again.  We seem to have a
    habit of doing this).
    
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 144b9c135b963bcb7f242c7b83bff930620d3161
Author: Anton Blanchard <anton@samba.org>
Date:   Fri Jan 13 15:37:17 2006 +1100

    [PATCH] powerpc: use lwsync in atomics, bitops, lock functions
    
    eieio is only a store - store ordering. When used to order an unlock
    operation loads may leak out of the critical region. This is potentially
    buggy, one example is if a user wants to atomically read a couple of
    values.
    
    We can solve this with an lwsync which orders everything except store - load.
    
    I removed the (now unused) EIEIO_ON_SMP macros and the c versions
    isync_on_smp and eieio_on_smp now we dont use them. I also removed some
    old comments that were used to identify inline spinlocks in assembly,
    they dont make sense now our locks are out of line.
    
    Another interesting thing was that read_unlock was using an eieio even
    though the rest of the spinlock code had already been converted to
    use lwsync.
    
    Signed-off-by: Anton Blanchard <anton@samba.org>
    Signed-off-by: Paul Mackerras <paulus@samba.org>

commit b72c1d0c14634506a2ff740033ab1bda3c3d5d7f
Author: Patrick McHardy <kaber@trash.net>
Date:   Tue Dec 13 12:26:07 2005 +0100

    [PATCH] Fix unbalanced read_unlock_bh in ctnetlink
    
    NFA_NEST calls NFA_PUT which jumps to nfattr_failure if the skb has no
    room left. We call read_unlock_bh at nfattr_failure for the NFA_PUT
    inside the locked section, so move NFA_NEST inside the locked section
    too.
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Krzysztof Piotr Oledzki <ole@ans.pl>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 266c8543480e2202ab63d1d604a5ca049f350cd8
Author: Patrick McHardy <kaber@trash.net>
Date:   Mon Dec 5 13:37:33 2005 -0800

    [NETFILTER]: Fix unbalanced read_unlock_bh in ctnetlink
    
    NFA_NEST calls NFA_PUT which jumps to nfattr_failure if the skb has no
    room left. We call read_unlock_bh at nfattr_failure for the NFA_PUT inside
    the locked section, so move NFA_NEST inside the locked section too.
    
    Signed-off-by: Patrick McHardy <kaber@trash.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 91f4ab056d85d23fa6955927fdeb1558673e8cd1
Author: Hirokazu Takata <takata@linux-m32r.org>
Date:   Mon Nov 28 13:43:58 2005 -0800

    [PATCH] m32r: Fix sys_tas() syscall
    
    This patch fixes a deadlock problem of the m32r SMP kernel.
    
    In the m32r kernel, sys_tas() system call is provided as a test-and-set
    function for userspace, for backward compatibility.
    
    In some multi-threading application program, deadlocks were rarely caused
    at sys_tas() funcion.  Such a deadlock was caused due to a collision of
    __pthread_lock() and __pthread_unlock() operations.
    
    The "tas" syscall is repeatedly called by pthread_mutex_lock() to get a
    lock, while a lock variable's value is not 0.  On the other hand,
    pthead_mutex_unlock() sets the lock variable to 0 for unlocking.
    
    In the previous implementation of sys_tas() routine, there was a
    possibility that a unlock operation was ignored in the following case:
    
    - Assume a lock variable (*addr) was equal to 1 before sys_tas() execution.
    - __pthread_unlock() operation is executed by the other processor
      and the lock variable (*addr) is set to 0, between a read operation
      ("oldval = *addr;") and the following write operation ("*addr = 1;")
      during a execution of sys_tas().
    
    In this case, the following write operation ("*addr = 1;") overwrites the
    __pthread_unlock() result, and sys_tas() fails to get a lock in the next
    turn and after that.
    
    According to the attatched patch, sys_tas() returns 0 value in the next
    turn and deadlocks never happen.
    
    Signed-off-by: Hitoshi Yamamoto <Yamamoto.Hitoshi@ap.MitsubishiElectric.co.jp>
    Signed-off-by: Hirokazu Takata <takata@linux-m32r.org>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit a69ac4a78d8bd9e1ec478bd7297d4f047fcd44a8
Author: Oleg Nesterov <oleg@tv-sign.ru>
Date:   Mon Oct 24 18:29:58 2005 +0400

    [PATCH] posix-timers: fix posix_cpu_timer_set() vs run_posix_cpu_timers() race
    
    This might be harmless, but looks like a race from code inspection (I
    was unable to trigger it).  I must admit, I don't understand why we
    can't return TIMER_RETRY after 'spin_unlock(&p->sighand->siglock)'
    without doing bump_cpu_timer(), but this is what original code does.
    
    posix_cpu_timer_set:
    
            read_lock(&tasklist_lock);
    
            spin_lock(&p->sighand->siglock);
            list_del_init(&timer->it.cpu.entry);
            spin_unlock(&p->sighand->siglock);
    
    We are probaly deleting the timer from run_posix_cpu_timers's 'firing'
    local list_head while run_posix_cpu_timers() does list_for_each_safe.
    
    Various bad things can happen, for example we can just delete this timer
    so that list_for_each() will not notice it and run_posix_cpu_timers()
    will not reset '->firing' flag. In that case,
    
            ....
    
            if (timer->it.cpu.firing) {
                    read_unlock(&tasklist_lock);
                    timer->it.cpu.firing = -1;
                    return TIMER_RETRY;
            }
    
    sys_timer_settime() goes to 'retry:', calls posix_cpu_timer_set() again,
    it returns TIMER_RETRY ...
    
    Signed-off-by: Oleg Nesterov <oleg@tv-sign.ru>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit b835996f628eadb55c5fb222ba46fe9395bf73c7
Author: Dipankar Sarma <dipankar@in.ibm.com>
Date:   Fri Sep 9 13:04:14 2005 -0700

    [PATCH] files: lock-free fd look-up
    
    With the use of RCU in files structure, the look-up of files using fds can now
    be lock-free.  The lookup is protected by rcu_read_lock()/rcu_read_unlock().
    This patch changes the readers to use lock-free lookup.
    
    Signed-off-by: Maneesh Soni <maneesh@in.ibm.com>
    Signed-off-by: Ravikiran Thirumalai <kiran_th@gmail.com>
    Signed-off-by: Dipankar Sarma <dipankar@in.ibm.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>
