commit 9b83ec63d0de7b1f379daa1571e128bc7b9570f8
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    commit 96398560f26aa07e8f2969d73c8197e6a6d10407 upstream.
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0195d5ad539382a83e1bfaab51b93b8685f0b7c7
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    commit 96398560f26aa07e8f2969d73c8197e6a6d10407 upstream.
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4574e32cbf652d7efcaa6076558752f770b01757
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    commit 96398560f26aa07e8f2969d73c8197e6a6d10407 upstream.
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3a415d59c1dbec9d772dbfab2d2520d98360caae
Author: Eric Dumazet <edumazet@google.com>
Date:   Fri Jan 13 16:48:49 2023 +0000

    net/sched: sch_taprio: fix possible use-after-free
    
    syzbot reported a nasty crash [1] in net_tx_action() which
    made little sense until we got a repro.
    
    This repro installs a taprio qdisc, but providing an
    invalid TCA_RATE attribute.
    
    qdisc_create() has to destroy the just initialized
    taprio qdisc, and taprio_destroy() is called.
    
    However, the hrtimer used by taprio had already fired,
    therefore advance_sched() called __netif_schedule().
    
    Then net_tx_action was trying to use a destroyed qdisc.
    
    We can not undo the __netif_schedule(), so we must wait
    until one cpu serviced the qdisc before we can proceed.
    
    Many thanks to Alexander Potapenko for his help.
    
    [1]
    BUG: KMSAN: uninit-value in queued_spin_trylock include/asm-generic/qspinlock.h:94 [inline]
    BUG: KMSAN: uninit-value in do_raw_spin_trylock include/linux/spinlock.h:191 [inline]
    BUG: KMSAN: uninit-value in __raw_spin_trylock include/linux/spinlock_api_smp.h:89 [inline]
    BUG: KMSAN: uninit-value in _raw_spin_trylock+0x92/0xa0 kernel/locking/spinlock.c:138
     queued_spin_trylock include/asm-generic/qspinlock.h:94 [inline]
     do_raw_spin_trylock include/linux/spinlock.h:191 [inline]
     __raw_spin_trylock include/linux/spinlock_api_smp.h:89 [inline]
     _raw_spin_trylock+0x92/0xa0 kernel/locking/spinlock.c:138
     spin_trylock include/linux/spinlock.h:359 [inline]
     qdisc_run_begin include/net/sch_generic.h:187 [inline]
     qdisc_run+0xee/0x540 include/net/pkt_sched.h:125
     net_tx_action+0x77c/0x9a0 net/core/dev.c:5086
     __do_softirq+0x1cc/0x7fb kernel/softirq.c:571
     run_ksoftirqd+0x2c/0x50 kernel/softirq.c:934
     smpboot_thread_fn+0x554/0x9f0 kernel/smpboot.c:164
     kthread+0x31b/0x430 kernel/kthread.c:376
     ret_from_fork+0x1f/0x30
    
    Uninit was created at:
     slab_post_alloc_hook mm/slab.h:732 [inline]
     slab_alloc_node mm/slub.c:3258 [inline]
     __kmalloc_node_track_caller+0x814/0x1250 mm/slub.c:4970
     kmalloc_reserve net/core/skbuff.c:358 [inline]
     __alloc_skb+0x346/0xcf0 net/core/skbuff.c:430
     alloc_skb include/linux/skbuff.h:1257 [inline]
     nlmsg_new include/net/netlink.h:953 [inline]
     netlink_ack+0x5f3/0x12b0 net/netlink/af_netlink.c:2436
     netlink_rcv_skb+0x55d/0x6c0 net/netlink/af_netlink.c:2507
     rtnetlink_rcv+0x30/0x40 net/core/rtnetlink.c:6108
     netlink_unicast_kernel net/netlink/af_netlink.c:1319 [inline]
     netlink_unicast+0xf3b/0x1270 net/netlink/af_netlink.c:1345
     netlink_sendmsg+0x1288/0x1440 net/netlink/af_netlink.c:1921
     sock_sendmsg_nosec net/socket.c:714 [inline]
     sock_sendmsg net/socket.c:734 [inline]
     ____sys_sendmsg+0xabc/0xe90 net/socket.c:2482
     ___sys_sendmsg+0x2a1/0x3f0 net/socket.c:2536
     __sys_sendmsg net/socket.c:2565 [inline]
     __do_sys_sendmsg net/socket.c:2574 [inline]
     __se_sys_sendmsg net/socket.c:2572 [inline]
     __x64_sys_sendmsg+0x367/0x540 net/socket.c:2572
     do_syscall_x64 arch/x86/entry/common.c:50 [inline]
     do_syscall_64+0x3d/0xb0 arch/x86/entry/common.c:80
     entry_SYSCALL_64_after_hwframe+0x63/0xcd
    
    CPU: 0 PID: 13 Comm: ksoftirqd/0 Not tainted 6.0.0-rc2-syzkaller-47461-gac3859c02d7f #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 07/22/2022
    
    Fixes: 5a781ccbd19e ("tc: Add support for configuring the taprio scheduler")
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Alexander Potapenko <glider@google.com>
    Cc: Vinicius Costa Gomes <vinicius.gomes@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit e8988e878af693ac13b0fa80ba2e72d22d68f2dd
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    commit 96398560f26aa07e8f2969d73c8197e6a6d10407 upstream.
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 04941c1d5bb59d64165e09813de2947bdf6f4f28
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    commit 96398560f26aa07e8f2969d73c8197e6a6d10407 upstream.
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9f7bc28a6b8afc2274e25650511555e93f45470f
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    commit 96398560f26aa07e8f2969d73c8197e6a6d10407 upstream.
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 96398560f26aa07e8f2969d73c8197e6a6d10407
Author: Frederick Lawler <fred@cloudflare.com>
Date:   Mon Jan 9 10:39:06 2023 -0600

    net: sched: disallow noqueue for qdisc classes
    
    While experimenting with applying noqueue to a classful queue discipline,
    we discovered a NULL pointer dereference in the __dev_queue_xmit()
    path that generates a kernel OOPS:
    
        # dev=enp0s5
        # tc qdisc replace dev $dev root handle 1: htb default 1
        # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit
        # tc qdisc add dev $dev parent 1:1 handle 10: noqueue
        # ping -I $dev -w 1 -c 1 1.1.1.1
    
    [    2.172856] BUG: kernel NULL pointer dereference, address: 0000000000000000
    [    2.173217] #PF: supervisor instruction fetch in kernel mode
    ...
    [    2.178451] Call Trace:
    [    2.178577]  <TASK>
    [    2.178686]  htb_enqueue+0x1c8/0x370
    [    2.178880]  dev_qdisc_enqueue+0x15/0x90
    [    2.179093]  __dev_queue_xmit+0x798/0xd00
    [    2.179305]  ? _raw_write_lock_bh+0xe/0x30
    [    2.179522]  ? __local_bh_enable_ip+0x32/0x70
    [    2.179759]  ? ___neigh_create+0x610/0x840
    [    2.179968]  ? eth_header+0x21/0xc0
    [    2.180144]  ip_finish_output2+0x15e/0x4f0
    [    2.180348]  ? dst_output+0x30/0x30
    [    2.180525]  ip_push_pending_frames+0x9d/0xb0
    [    2.180739]  raw_sendmsg+0x601/0xcb0
    [    2.180916]  ? _raw_spin_trylock+0xe/0x50
    [    2.181112]  ? _raw_spin_unlock_irqrestore+0x16/0x30
    [    2.181354]  ? get_page_from_freelist+0xcd6/0xdf0
    [    2.181594]  ? sock_sendmsg+0x56/0x60
    [    2.181781]  sock_sendmsg+0x56/0x60
    [    2.181958]  __sys_sendto+0xf7/0x160
    [    2.182139]  ? handle_mm_fault+0x6e/0x1d0
    [    2.182366]  ? do_user_addr_fault+0x1e1/0x660
    [    2.182627]  __x64_sys_sendto+0x1b/0x30
    [    2.182881]  do_syscall_64+0x38/0x90
    [    2.183085]  entry_SYSCALL_64_after_hwframe+0x63/0xcd
    ...
    [    2.187402]  </TASK>
    
    Previously in commit d66d6c3152e8 ("net: sched: register noqueue
    qdisc"), NULL was set for the noqueue discipline on noqueue init
    so that __dev_queue_xmit() falls through for the noqueue case. This
    also sets a bypass of the enqueue NULL check in the
    register_qdisc() function for the struct noqueue_disc_ops.
    
    Classful queue disciplines make it past the NULL check in
    __dev_queue_xmit() because the discipline is set to htb (in this case),
    and then in the call to __dev_xmit_skb(), it calls into htb_enqueue()
    which grabs a leaf node for a class and then calls qdisc_enqueue() by
    passing in a queue discipline which assumes ->enqueue() is not set to NULL.
    
    Fix this by not allowing classes to be assigned to the noqueue
    discipline. Linux TC Notes states that classes cannot be set to
    the noqueue discipline. [1] Let's enforce that here.
    
    Links:
    1. https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt
    
    Fixes: d66d6c3152e8 ("net: sched: register noqueue qdisc")
    Cc: stable@vger.kernel.org
    Signed-off-by: Frederick Lawler <fred@cloudflare.com>
    Reviewed-by: Jakub Sitnicki <jakub@cloudflare.com>
    Link: https://lore.kernel.org/r/20230109163906.706000-1-fred@cloudflare.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit 6aa42f883c438ea132a28801bef3f86f3883d14c
Author: Nicholas Piggin <npiggin@gmail.com>
Date:   Sat Nov 26 19:59:19 2022 +1000

    powerpc/qspinlock: allow new waiters to steal the lock before queueing
    
    Allow new waiters to "steal" the lock before queueing. That is, to
    acquire it while other CPUs have queued.
    
    This particularly helps paravirt performance when physical CPUs are
    oversubscribed, by keeping the lock from becoming a strict FIFO and
    vCPU preemption causing queue train wrecks.
    
    The new __queued_spin_trylock_steal() function is put in qspinlock.h
    to save having to move it, because it will be used there by a later
    change.
    
    Signed-off-by: Nicholas Piggin <npiggin@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20221126095932.1234527-5-npiggin@gmail.com

commit 5749077415994eb02d660b2559b9d8278521e73d
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Nov 18 10:17:14 2022 +0000

    mm/page_alloc: leave IRQs enabled for per-cpu page allocations
    
    The pcp_spin_lock_irqsave protecting the PCP lists is IRQ-safe as a task
    allocating from the PCP must not re-enter the allocator from IRQ context.
    In each instance where IRQ-reentrancy is possible, the lock is acquired
    using pcp_spin_trylock_irqsave() even though IRQs are disabled and
    re-entrancy is impossible.
    
    Demote the lock to pcp_spin_lock avoids an IRQ disable/enable in the
    common case at the cost of some IRQ allocations taking a slower path.  If
    the PCP lists need to be refilled, the zone lock still needs to disable
    IRQs but that will only happen on PCP refill and drain.  If an IRQ is
    raised when a PCP allocation is in progress, the trylock will fail and
    fallback to using the buddy lists directly.  Note that this may not be a
    universal win if an interrupt-intensive workload also allocates heavily
    from interrupt context and contends heavily on the zone->lock as a result.
    
    [mgorman@techsingularity.net: migratetype might be wrong if a PCP was locked]
      Link: https://lkml.kernel.org/r/20221122131229.5263-2-mgorman@techsingularity.net
    [yuzhao@google.com: reported lockdep issue on IO completion from softirq]
    [hughd@google.com: fix list corruption, lock improvements, micro-optimsations]
    Link: https://lkml.kernel.org/r/20221118101714.19590-3-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Reviewed-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

commit 1aa262c1d056551dd1246115af8b7e351184deae
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Mon Aug 22 15:07:03 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    commit f7b12a62f008a3041f42f2426983e59a6a0a3c59 upstream
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 096e8eb9639b342bc35f9b741cf05e26d0106e92
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Sat Jul 9 08:18:40 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    [ Upstream commit f7b12a62f008a3041f42f2426983e59a6a0a3c59 ]
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6cb4b96df97082a54634ba02196516919cda228c
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Sat Jul 9 08:18:40 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    [ Upstream commit f7b12a62f008a3041f42f2426983e59a6a0a3c59 ]
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f7b12a62f008a3041f42f2426983e59a6a0a3c59
Author: Naohiro Aota <naohiro.aota@wdc.com>
Date:   Sat Jul 9 08:18:40 2022 +0900

    btrfs: replace BTRFS_MAX_EXTENT_SIZE with fs_info->max_extent_size
    
    On zoned filesystem, data write out is limited by max_zone_append_size,
    and a large ordered extent is split according the size of a bio. OTOH,
    the number of extents to be written is calculated using
    BTRFS_MAX_EXTENT_SIZE, and that estimated number is used to reserve the
    metadata bytes to update and/or create the metadata items.
    
    The metadata reservation is done at e.g, btrfs_buffered_write() and then
    released according to the estimation changes. Thus, if the number of extent
    increases massively, the reserved metadata can run out.
    
    The increase of the number of extents easily occurs on zoned filesystem
    if BTRFS_MAX_EXTENT_SIZE > max_zone_append_size. And, it causes the
    following warning on a small RAM environment with disabling metadata
    over-commit (in the following patch).
    
    [75721.498492] ------------[ cut here ]------------
    [75721.505624] BTRFS: block rsv 1 returned -28
    [75721.512230] WARNING: CPU: 24 PID: 2327559 at fs/btrfs/block-rsv.c:537 btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.581854] CPU: 24 PID: 2327559 Comm: kworker/u64:10 Kdump: loaded Tainted: G        W         5.18.0-rc2-BTRFS-ZNS+ #109
    [75721.597200] Hardware name: Supermicro Super Server/H12SSL-NT, BIOS 2.0 02/22/2021
    [75721.607310] Workqueue: btrfs-endio-write btrfs_work_helper [btrfs]
    [75721.616209] RIP: 0010:btrfs_use_block_rsv+0x560/0x760 [btrfs]
    [75721.646649] RSP: 0018:ffffc9000fbdf3e0 EFLAGS: 00010286
    [75721.654126] RAX: 0000000000000000 RBX: 0000000000004000 RCX: 0000000000000000
    [75721.663524] RDX: 0000000000000004 RSI: 0000000000000008 RDI: fffff52001f7be6e
    [75721.672921] RBP: ffffc9000fbdf420 R08: 0000000000000001 R09: ffff889f8d1fc6c7
    [75721.682493] R10: ffffed13f1a3f8d8 R11: 0000000000000001 R12: ffff88980a3c0e28
    [75721.692284] R13: ffff889b66590000 R14: ffff88980a3c0e40 R15: ffff88980a3c0e8a
    [75721.701878] FS:  0000000000000000(0000) GS:ffff889f8d000000(0000) knlGS:0000000000000000
    [75721.712601] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [75721.720726] CR2: 000055d12e05c018 CR3: 0000800193594000 CR4: 0000000000350ee0
    [75721.730499] Call Trace:
    [75721.735166]  <TASK>
    [75721.739886]  btrfs_alloc_tree_block+0x1e1/0x1100 [btrfs]
    [75721.747545]  ? btrfs_alloc_logged_file_extent+0x550/0x550 [btrfs]
    [75721.756145]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.762852]  ? btrfs_get_32+0xea/0x2d0 [btrfs]
    [75721.769520]  ? push_leaf_left+0x420/0x620 [btrfs]
    [75721.776431]  ? memcpy+0x4e/0x60
    [75721.781931]  split_leaf+0x433/0x12d0 [btrfs]
    [75721.788392]  ? btrfs_get_token_32+0x580/0x580 [btrfs]
    [75721.795636]  ? push_for_double_split.isra.0+0x420/0x420 [btrfs]
    [75721.803759]  ? leaf_space_used+0x15d/0x1a0 [btrfs]
    [75721.811156]  btrfs_search_slot+0x1bc3/0x2790 [btrfs]
    [75721.818300]  ? lock_downgrade+0x7c0/0x7c0
    [75721.824411]  ? free_extent_buffer.part.0+0x107/0x200 [btrfs]
    [75721.832456]  ? split_leaf+0x12d0/0x12d0 [btrfs]
    [75721.839149]  ? free_extent_buffer.part.0+0x14f/0x200 [btrfs]
    [75721.846945]  ? free_extent_buffer+0x13/0x20 [btrfs]
    [75721.853960]  ? btrfs_release_path+0x4b/0x190 [btrfs]
    [75721.861429]  btrfs_csum_file_blocks+0x85c/0x1500 [btrfs]
    [75721.869313]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.876085]  ? lock_release+0x552/0xf80
    [75721.881957]  ? btrfs_del_csums+0x8c0/0x8c0 [btrfs]
    [75721.888886]  ? __kasan_check_write+0x14/0x20
    [75721.895152]  ? do_raw_read_unlock+0x44/0x80
    [75721.901323]  ? _raw_write_lock_irq+0x60/0x80
    [75721.907983]  ? btrfs_global_root+0xb9/0xe0 [btrfs]
    [75721.915166]  ? btrfs_csum_root+0x12b/0x180 [btrfs]
    [75721.921918]  ? btrfs_get_global_root+0x820/0x820 [btrfs]
    [75721.929166]  ? _raw_write_unlock+0x23/0x40
    [75721.935116]  ? unpin_extent_cache+0x1e3/0x390 [btrfs]
    [75721.942041]  btrfs_finish_ordered_io.isra.0+0xa0c/0x1dc0 [btrfs]
    [75721.949906]  ? try_to_wake_up+0x30/0x14a0
    [75721.955700]  ? btrfs_unlink_subvol+0xda0/0xda0 [btrfs]
    [75721.962661]  ? rcu_read_lock_sched_held+0x16/0x80
    [75721.969111]  ? lock_acquire+0x41b/0x4c0
    [75721.974982]  finish_ordered_fn+0x15/0x20 [btrfs]
    [75721.981639]  btrfs_work_helper+0x1af/0xa80 [btrfs]
    [75721.988184]  ? _raw_spin_unlock_irq+0x28/0x50
    [75721.994643]  process_one_work+0x815/0x1460
    [75722.000444]  ? pwq_dec_nr_in_flight+0x250/0x250
    [75722.006643]  ? do_raw_spin_trylock+0xbb/0x190
    [75722.013086]  worker_thread+0x59a/0xeb0
    [75722.018511]  kthread+0x2ac/0x360
    [75722.023428]  ? process_one_work+0x1460/0x1460
    [75722.029431]  ? kthread_complete_and_exit+0x30/0x30
    [75722.036044]  ret_from_fork+0x22/0x30
    [75722.041255]  </TASK>
    [75722.045047] irq event stamp: 0
    [75722.049703] hardirqs last  enabled at (0): [<0000000000000000>] 0x0
    [75722.057610] hardirqs last disabled at (0): [<ffffffff8118a94a>] copy_process+0x1c1a/0x66b0
    [75722.067533] softirqs last  enabled at (0): [<ffffffff8118a989>] copy_process+0x1c59/0x66b0
    [75722.077423] softirqs last disabled at (0): [<0000000000000000>] 0x0
    [75722.085335] ---[ end trace 0000000000000000 ]---
    
    To fix the estimation, we need to introduce fs_info->max_extent_size to
    replace BTRFS_MAX_EXTENT_SIZE, which allow setting the different size for
    regular vs zoned filesystem.
    
    Set fs_info->max_extent_size to BTRFS_MAX_EXTENT_SIZE by default. On zoned
    filesystem, it is set to fs_info->max_zone_append_size.
    
    CC: stable@vger.kernel.org # 5.12+
    Fixes: d8e3fb106f39 ("btrfs: zoned: use ZONE_APPEND write for zoned mode")
    Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
    Signed-off-by: Naohiro Aota <naohiro.aota@wdc.com>
    Signed-off-by: David Sterba <dsterba@suse.com>

commit 01b44456a7aa7c3b24fa9db7d1714b208b8ef3d8
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Jun 24 13:54:23 2022 +0100

    mm/page_alloc: replace local_lock with normal spinlock
    
    struct per_cpu_pages is no longer strictly local as PCP lists can be
    drained remotely using a lock for protection.  While the use of local_lock
    works, it goes against the intent of local_lock which is for "pure CPU
    local concurrency control mechanisms and not suited for inter-CPU
    concurrency control" (Documentation/locking/locktypes.rst)
    
    local_lock protects against migration between when the percpu pointer is
    accessed and the pcp->lock acquired.  The lock acquisition is a preemption
    point so in the worst case, a task could migrate to another NUMA node and
    accidentally allocate remote memory.  The main requirement is to pin the
    task to a CPU that is suitable for PREEMPT_RT and !PREEMPT_RT.
    
    Replace local_lock with helpers that pin a task to a CPU, lookup the
    per-cpu structure and acquire the embedded lock.  It's similar to
    local_lock without breaking the intent behind the API.  It is not a
    complete API as only the parts needed for PCP-alloc are implemented but in
    theory, the generic helpers could be promoted to a general API if there
    was demand for an embedded lock within a per-cpu struct with a guarantee
    that the per-cpu structure locked matches the running CPU and cannot use
    get_cpu_var due to RT concerns.  PCP requires these semantics to avoid
    accidentally allocating remote memory.
    
    [mgorman@techsingularity.net: use pcp_spin_trylock_irqsave instead of pcpu_spin_trylock_irqsave]
      Link: https://lkml.kernel.org/r/20220627084645.GA27531@techsingularity.net
    Link: https://lkml.kernel.org/r/20220624125423.6126-8-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Tested-by: Yu Zhao <yuzhao@google.com>
    Reviewed-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Tested-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Tested-by: Yu Zhao <yuzhao@google.com>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

commit 4b23a68f953628eb4e4b7fe1294ebf93d4b8ceee
Author: Mel Gorman <mgorman@techsingularity.net>
Date:   Fri Jun 24 13:54:21 2022 +0100

    mm/page_alloc: protect PCP lists with a spinlock
    
    Currently the PCP lists are protected by using local_lock_irqsave to
    prevent migration and IRQ reentrancy but this is inconvenient.  Remote
    draining of the lists is impossible and a workqueue is required and every
    task allocation/free must disable then enable interrupts which is
    expensive.
    
    As preparation for dealing with both of those problems, protect the
    lists with a spinlock.  The IRQ-unsafe version of the lock is used
    because IRQs are already disabled by local_lock_irqsave.  spin_trylock
    is used in combination with local_lock_irqsave() but later will be
    replaced with a spin_trylock_irqsave when the local_lock is removed.
    
    The per_cpu_pages still fits within the same number of cache lines after
    this patch relative to before the series.
    
    struct per_cpu_pages {
            spinlock_t                 lock;                 /*     0     4 */
            int                        count;                /*     4     4 */
            int                        high;                 /*     8     4 */
            int                        batch;                /*    12     4 */
            short int                  free_factor;          /*    16     2 */
            short int                  expire;               /*    18     2 */
    
            /* XXX 4 bytes hole, try to pack */
    
            struct list_head           lists[13];            /*    24   208 */
    
            /* size: 256, cachelines: 4, members: 7 */
            /* sum members: 228, holes: 1, sum holes: 4 */
            /* padding: 24 */
    } __attribute__((__aligned__(64)));
    
    There is overhead in the fast path due to acquiring the spinlock even
    though the spinlock is per-cpu and uncontended in the common case.  Page
    Fault Test (PFT) running on a 1-socket reported the following results on a
    1 socket machine.
    
                                         5.19.0-rc3               5.19.0-rc3
                                            vanilla      mm-pcpspinirq-v5r16
    Hmean     faults/sec-1   869275.7381 (   0.00%)   874597.5167 *   0.61%*
    Hmean     faults/sec-3  2370266.6681 (   0.00%)  2379802.0362 *   0.40%*
    Hmean     faults/sec-5  2701099.7019 (   0.00%)  2664889.7003 *  -1.34%*
    Hmean     faults/sec-7  3517170.9157 (   0.00%)  3491122.8242 *  -0.74%*
    Hmean     faults/sec-8  3965729.6187 (   0.00%)  3939727.0243 *  -0.66%*
    
    There is a small hit in the number of faults per second but given that the
    results are more stable, it's borderline noise.
    
    [akpm@linux-foundation.org: add missing local_unlock_irqrestore() on contention path]
    Link: https://lkml.kernel.org/r/20220624125423.6126-6-mgorman@techsingularity.net
    Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
    Tested-by: Yu Zhao <yuzhao@google.com>
    Reviewed-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Tested-by: Nicolas Saenz Julienne <nsaenzju@redhat.com>
    Acked-by: Vlastimil Babka <vbabka@suse.cz>
    Cc: Hugh Dickins <hughd@google.com>
    Cc: Marcelo Tosatti <mtosatti@redhat.com>
    Cc: Marek Szyprowski <m.szyprowski@samsung.com>
    Cc: Michal Hocko <mhocko@kernel.org>
    Cc: Minchan Kim <minchan@kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

commit 4a557a5d1a6145ea586dc9b17a9b4e5190c9c017
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Thu Jun 30 09:34:10 2022 -0700

    sparse: introduce conditional lock acquire function attribute
    
    The kernel tends to try to avoid conditional locking semantics because
    it makes it harder to think about and statically check locking rules,
    but we do have a few fundamental locking primitives that take locks
    conditionally - most obviously the 'trylock' functions.
    
    That has always been a problem for 'sparse' checking for locking
    imbalance, and we've had a special '__cond_lock()' macro that we've used
    to let sparse know how the locking works:
    
        # define __cond_lock(x,c)        ((c) ? ({ __acquire(x); 1; }) : 0)
    
    so that you can then use this to tell sparse that (for example) the
    spinlock trylock macro ends up acquiring the lock when it succeeds, but
    not when it fails:
    
        #define raw_spin_trylock(lock)  __cond_lock(lock, _raw_spin_trylock(lock))
    
    and then sparse can follow along the locking rules when you have code like
    
            if (!spin_trylock(&dentry->d_lock))
                    return LRU_SKIP;
            .. sparse sees that the lock is held here..
            spin_unlock(&dentry->d_lock);
    
    and sparse ends up happy about the lock contexts.
    
    However, this '__cond_lock()' use does result in very ugly header files,
    and requires you to basically wrap the real function with that macro
    that uses '__cond_lock'.  Which has made PeterZ NAK things that try to
    fix sparse warnings over the years [1].
    
    To solve this, there is now a very experimental patch to sparse that
    basically does the exact same thing as '__cond_lock()' did, but using a
    function attribute instead.  That seems to make PeterZ happy [2].
    
    Note that this does not replace existing use of '__cond_lock()', but
    only exposes the new proposed attribute and uses it for the previously
    unannotated 'refcount_dec_and_lock()' family of functions.
    
    For existing sparse installations, this will make no difference (a
    negative output context was ignored), but if you have the experimental
    sparse patch it will make sparse now understand code that uses those
    functions, the same way '__cond_lock()' makes sparse understand the very
    similar 'atomic_dec_and_lock()' uses that have the old '__cond_lock()'
    annotations.
    
    Note that in some cases this will silence existing context imbalance
    warnings.  But in other cases it may end up exposing new sparse warnings
    for code that sparse just didn't see the locking for at all before.
    
    This is a trial, in other words.  I'd expect that if it ends up being
    successful, and new sparse releases end up having this new attribute,
    we'll migrate the old-style '__cond_lock()' users to use the new-style
    '__cond_acquires' function attribute.
    
    The actual experimental sparse patch was posted in [3].
    
    Link: https://lore.kernel.org/all/20130930134434.GC12926@twins.programming.kicks-ass.net/ [1]
    Link: https://lore.kernel.org/all/Yr60tWxN4P568x3W@worktop.programming.kicks-ass.net/ [2]
    Link: https://lore.kernel.org/all/CAHk-=wjZfO9hGqJ2_hGQG3U_XzSh9_XaXze=HgPdvJbgrvASfA@mail.gmail.com/ [3]
    Acked-by: Peter Zijlstra <peterz@infradead.org>
    Cc: Alexander Aring <aahringo@redhat.com>
    Cc: Luc Van Oostenryck <luc.vanoostenryck@gmail.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 4e659b396823de142624e0e172079e1dcc185454
Author: Guoju Fang <gjfang@linux.alibaba.com>
Date:   Sat May 28 18:16:28 2022 +0800

    net: sched: add barrier to fix packet stuck problem for lockless qdisc
    
    [ Upstream commit 2e8728c955ce0624b958eee6e030a37aca3a5d86 ]
    
    In qdisc_run_end(), the spin_unlock() only has store-release semantic,
    which guarantees all earlier memory access are visible before it. But
    the subsequent test_bit() has no barrier semantics so may be reordered
    ahead of the spin_unlock(). The store-load reordering may cause a packet
    stuck problem.
    
    The concurrent operations can be described as below,
             CPU 0                      |          CPU 1
       qdisc_run_end()                  |     qdisc_run_begin()
              .                         |           .
     ----> /* may be reorderd here */   |           .
    |         .                         |           .
    |     spin_unlock()                 |         set_bit()
    |         .                         |         smp_mb__after_atomic()
     ---- test_bit()                    |         spin_trylock()
              .                         |          .
    
    Consider the following sequence of events:
        CPU 0 reorder test_bit() ahead and see MISSED = 0
        CPU 1 calls set_bit()
        CPU 1 calls spin_trylock() and return fail
        CPU 0 executes spin_unlock()
    
    At the end of the sequence, CPU 0 calls spin_unlock() and does nothing
    because it see MISSED = 0. The skb on CPU 1 has beed enqueued but no one
    take it, until the next cpu pushing to the qdisc (if ever ...) will
    notice and dequeue it.
    
    This patch fix this by adding one explicit barrier. As spin_unlock() and
    test_bit() ordering is a store-load ordering, a full memory barrier
    smp_mb() is needed here.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Guoju Fang <gjfang@linux.alibaba.com>
    Link: https://lore.kernel.org/r/20220528101628.120193-1-gjfang@linux.alibaba.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 7ce6a502eb967b9ca532a8b1d0f1db2fcef55c2c
Author: Vincent Ray <vray@kalrayinc.com>
Date:   Wed May 25 17:17:46 2022 -0700

    net: sched: fixed barrier to prevent skbuff sticking in qdisc backlog
    
    [ Upstream commit a54ce3703613e41fe1d98060b62ec09a3984dc28 ]
    
    In qdisc_run_begin(), smp_mb__before_atomic() used before test_bit()
    does not provide any ordering guarantee as test_bit() is not an atomic
    operation. This, added to the fact that the spin_trylock() call at
    the beginning of qdisc_run_begin() does not guarantee acquire
    semantics if it does not grab the lock, makes it possible for the
    following statement :
    
    if (test_bit(__QDISC_STATE_MISSED, &qdisc->state))
    
    to be executed before an enqueue operation called before
    qdisc_run_begin().
    
    As a result the following race can happen :
    
               CPU 1                             CPU 2
    
          qdisc_run_begin()               qdisc_run_begin() /* true */
            set(MISSED)                            .
          /* returns false */                      .
              .                            /* sees MISSED = 1 */
              .                            /* so qdisc not empty */
              .                            __qdisc_run()
              .                                    .
              .                              pfifo_fast_dequeue()
     ----> /* may be done here */                  .
    |         .                                clear(MISSED)
    |         .                                    .
    |         .                                smp_mb __after_atomic();
    |         .                                    .
    |         .                                /* recheck the queue */
    |         .                                /* nothing => exit   */
    |   enqueue(skb1)
    |         .
    |   qdisc_run_begin()
    |         .
    |     spin_trylock() /* fail */
    |         .
    |     smp_mb__before_atomic() /* not enough */
    |         .
     ---- if (test_bit(MISSED))
            return false;   /* exit */
    
    In the above scenario, CPU 1 and CPU 2 both try to grab the
    qdisc->seqlock at the same time. Only CPU 2 succeeds and enters the
    bypass code path, where it emits its skb then calls __qdisc_run().
    
    CPU1 fails, sets MISSED and goes down the traditionnal enqueue() +
    dequeue() code path. But when executing qdisc_run_begin() for the
    second time, after enqueuing its skbuff, it sees the MISSED bit still
    set (by itself) and consequently chooses to exit early without setting
    it again nor trying to grab the spinlock again.
    
    Meanwhile CPU2 has seen MISSED = 1, cleared it, checked the queue
    and found it empty, so it returned.
    
    At the end of the sequence, we end up with skb1 enqueued in the
    backlog, both CPUs out of __dev_xmit_skb(), the MISSED bit not set,
    and no __netif_schedule() called made. skb1 will now linger in the
    qdisc until somebody later performs a full __qdisc_run(). Associated
    to the bypass capacity of the qdisc, and the ability of the TCP layer
    to avoid resending packets which it knows are still in the qdisc, this
    can lead to serious traffic "holes" in a TCP connection.
    
    We fix this by replacing the smp_mb__before_atomic() / test_bit() /
    set_bit() / smp_mb__after_atomic() sequence inside qdisc_run_begin()
    by a single test_and_set_bit() call, which is more concise and
    enforces the needed memory barriers.
    
    Fixes: 89837eb4b246 ("net: sched: add barrier to ensure correct ordering for lockless qdisc")
    Signed-off-by: Vincent Ray <vray@kalrayinc.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Link: https://lore.kernel.org/r/20220526001746.2437669-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d3119910a6b3c154e2f87f9e174e08ec8b1ba774
Author: Guoju Fang <gjfang@linux.alibaba.com>
Date:   Sat May 28 18:16:28 2022 +0800

    net: sched: add barrier to fix packet stuck problem for lockless qdisc
    
    [ Upstream commit 2e8728c955ce0624b958eee6e030a37aca3a5d86 ]
    
    In qdisc_run_end(), the spin_unlock() only has store-release semantic,
    which guarantees all earlier memory access are visible before it. But
    the subsequent test_bit() has no barrier semantics so may be reordered
    ahead of the spin_unlock(). The store-load reordering may cause a packet
    stuck problem.
    
    The concurrent operations can be described as below,
             CPU 0                      |          CPU 1
       qdisc_run_end()                  |     qdisc_run_begin()
              .                         |           .
     ----> /* may be reorderd here */   |           .
    |         .                         |           .
    |     spin_unlock()                 |         set_bit()
    |         .                         |         smp_mb__after_atomic()
     ---- test_bit()                    |         spin_trylock()
              .                         |          .
    
    Consider the following sequence of events:
        CPU 0 reorder test_bit() ahead and see MISSED = 0
        CPU 1 calls set_bit()
        CPU 1 calls spin_trylock() and return fail
        CPU 0 executes spin_unlock()
    
    At the end of the sequence, CPU 0 calls spin_unlock() and does nothing
    because it see MISSED = 0. The skb on CPU 1 has beed enqueued but no one
    take it, until the next cpu pushing to the qdisc (if ever ...) will
    notice and dequeue it.
    
    This patch fix this by adding one explicit barrier. As spin_unlock() and
    test_bit() ordering is a store-load ordering, a full memory barrier
    smp_mb() is needed here.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Guoju Fang <gjfang@linux.alibaba.com>
    Link: https://lore.kernel.org/r/20220528101628.120193-1-gjfang@linux.alibaba.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 0db2dcc639cff0955ad64330c86752b8efb3bc72
Author: Vincent Ray <vray@kalrayinc.com>
Date:   Wed May 25 17:17:46 2022 -0700

    net: sched: fixed barrier to prevent skbuff sticking in qdisc backlog
    
    [ Upstream commit a54ce3703613e41fe1d98060b62ec09a3984dc28 ]
    
    In qdisc_run_begin(), smp_mb__before_atomic() used before test_bit()
    does not provide any ordering guarantee as test_bit() is not an atomic
    operation. This, added to the fact that the spin_trylock() call at
    the beginning of qdisc_run_begin() does not guarantee acquire
    semantics if it does not grab the lock, makes it possible for the
    following statement :
    
    if (test_bit(__QDISC_STATE_MISSED, &qdisc->state))
    
    to be executed before an enqueue operation called before
    qdisc_run_begin().
    
    As a result the following race can happen :
    
               CPU 1                             CPU 2
    
          qdisc_run_begin()               qdisc_run_begin() /* true */
            set(MISSED)                            .
          /* returns false */                      .
              .                            /* sees MISSED = 1 */
              .                            /* so qdisc not empty */
              .                            __qdisc_run()
              .                                    .
              .                              pfifo_fast_dequeue()
     ----> /* may be done here */                  .
    |         .                                clear(MISSED)
    |         .                                    .
    |         .                                smp_mb __after_atomic();
    |         .                                    .
    |         .                                /* recheck the queue */
    |         .                                /* nothing => exit   */
    |   enqueue(skb1)
    |         .
    |   qdisc_run_begin()
    |         .
    |     spin_trylock() /* fail */
    |         .
    |     smp_mb__before_atomic() /* not enough */
    |         .
     ---- if (test_bit(MISSED))
            return false;   /* exit */
    
    In the above scenario, CPU 1 and CPU 2 both try to grab the
    qdisc->seqlock at the same time. Only CPU 2 succeeds and enters the
    bypass code path, where it emits its skb then calls __qdisc_run().
    
    CPU1 fails, sets MISSED and goes down the traditionnal enqueue() +
    dequeue() code path. But when executing qdisc_run_begin() for the
    second time, after enqueuing its skbuff, it sees the MISSED bit still
    set (by itself) and consequently chooses to exit early without setting
    it again nor trying to grab the spinlock again.
    
    Meanwhile CPU2 has seen MISSED = 1, cleared it, checked the queue
    and found it empty, so it returned.
    
    At the end of the sequence, we end up with skb1 enqueued in the
    backlog, both CPUs out of __dev_xmit_skb(), the MISSED bit not set,
    and no __netif_schedule() called made. skb1 will now linger in the
    qdisc until somebody later performs a full __qdisc_run(). Associated
    to the bypass capacity of the qdisc, and the ability of the TCP layer
    to avoid resending packets which it knows are still in the qdisc, this
    can lead to serious traffic "holes" in a TCP connection.
    
    We fix this by replacing the smp_mb__before_atomic() / test_bit() /
    set_bit() / smp_mb__after_atomic() sequence inside qdisc_run_begin()
    by a single test_and_set_bit() call, which is more concise and
    enforces the needed memory barriers.
    
    Fixes: 89837eb4b246 ("net: sched: add barrier to ensure correct ordering for lockless qdisc")
    Signed-off-by: Vincent Ray <vray@kalrayinc.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Link: https://lore.kernel.org/r/20220526001746.2437669-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f7ca1989fd218c88c0d219c2ae8007d82750fbfb
Author: Guoju Fang <gjfang@linux.alibaba.com>
Date:   Sat May 28 18:16:28 2022 +0800

    net: sched: add barrier to fix packet stuck problem for lockless qdisc
    
    [ Upstream commit 2e8728c955ce0624b958eee6e030a37aca3a5d86 ]
    
    In qdisc_run_end(), the spin_unlock() only has store-release semantic,
    which guarantees all earlier memory access are visible before it. But
    the subsequent test_bit() has no barrier semantics so may be reordered
    ahead of the spin_unlock(). The store-load reordering may cause a packet
    stuck problem.
    
    The concurrent operations can be described as below,
             CPU 0                      |          CPU 1
       qdisc_run_end()                  |     qdisc_run_begin()
              .                         |           .
     ----> /* may be reorderd here */   |           .
    |         .                         |           .
    |     spin_unlock()                 |         set_bit()
    |         .                         |         smp_mb__after_atomic()
     ---- test_bit()                    |         spin_trylock()
              .                         |          .
    
    Consider the following sequence of events:
        CPU 0 reorder test_bit() ahead and see MISSED = 0
        CPU 1 calls set_bit()
        CPU 1 calls spin_trylock() and return fail
        CPU 0 executes spin_unlock()
    
    At the end of the sequence, CPU 0 calls spin_unlock() and does nothing
    because it see MISSED = 0. The skb on CPU 1 has beed enqueued but no one
    take it, until the next cpu pushing to the qdisc (if ever ...) will
    notice and dequeue it.
    
    This patch fix this by adding one explicit barrier. As spin_unlock() and
    test_bit() ordering is a store-load ordering, a full memory barrier
    smp_mb() is needed here.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Guoju Fang <gjfang@linux.alibaba.com>
    Link: https://lore.kernel.org/r/20220528101628.120193-1-gjfang@linux.alibaba.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1e853f235a012c33b9e6f08db11639f82daa3b42
Author: Vincent Ray <vray@kalrayinc.com>
Date:   Wed May 25 17:17:46 2022 -0700

    net: sched: fixed barrier to prevent skbuff sticking in qdisc backlog
    
    [ Upstream commit a54ce3703613e41fe1d98060b62ec09a3984dc28 ]
    
    In qdisc_run_begin(), smp_mb__before_atomic() used before test_bit()
    does not provide any ordering guarantee as test_bit() is not an atomic
    operation. This, added to the fact that the spin_trylock() call at
    the beginning of qdisc_run_begin() does not guarantee acquire
    semantics if it does not grab the lock, makes it possible for the
    following statement :
    
    if (test_bit(__QDISC_STATE_MISSED, &qdisc->state))
    
    to be executed before an enqueue operation called before
    qdisc_run_begin().
    
    As a result the following race can happen :
    
               CPU 1                             CPU 2
    
          qdisc_run_begin()               qdisc_run_begin() /* true */
            set(MISSED)                            .
          /* returns false */                      .
              .                            /* sees MISSED = 1 */
              .                            /* so qdisc not empty */
              .                            __qdisc_run()
              .                                    .
              .                              pfifo_fast_dequeue()
     ----> /* may be done here */                  .
    |         .                                clear(MISSED)
    |         .                                    .
    |         .                                smp_mb __after_atomic();
    |         .                                    .
    |         .                                /* recheck the queue */
    |         .                                /* nothing => exit   */
    |   enqueue(skb1)
    |         .
    |   qdisc_run_begin()
    |         .
    |     spin_trylock() /* fail */
    |         .
    |     smp_mb__before_atomic() /* not enough */
    |         .
     ---- if (test_bit(MISSED))
            return false;   /* exit */
    
    In the above scenario, CPU 1 and CPU 2 both try to grab the
    qdisc->seqlock at the same time. Only CPU 2 succeeds and enters the
    bypass code path, where it emits its skb then calls __qdisc_run().
    
    CPU1 fails, sets MISSED and goes down the traditionnal enqueue() +
    dequeue() code path. But when executing qdisc_run_begin() for the
    second time, after enqueuing its skbuff, it sees the MISSED bit still
    set (by itself) and consequently chooses to exit early without setting
    it again nor trying to grab the spinlock again.
    
    Meanwhile CPU2 has seen MISSED = 1, cleared it, checked the queue
    and found it empty, so it returned.
    
    At the end of the sequence, we end up with skb1 enqueued in the
    backlog, both CPUs out of __dev_xmit_skb(), the MISSED bit not set,
    and no __netif_schedule() called made. skb1 will now linger in the
    qdisc until somebody later performs a full __qdisc_run(). Associated
    to the bypass capacity of the qdisc, and the ability of the TCP layer
    to avoid resending packets which it knows are still in the qdisc, this
    can lead to serious traffic "holes" in a TCP connection.
    
    We fix this by replacing the smp_mb__before_atomic() / test_bit() /
    set_bit() / smp_mb__after_atomic() sequence inside qdisc_run_begin()
    by a single test_and_set_bit() call, which is more concise and
    enforces the needed memory barriers.
    
    Fixes: 89837eb4b246 ("net: sched: add barrier to ensure correct ordering for lockless qdisc")
    Signed-off-by: Vincent Ray <vray@kalrayinc.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Link: https://lore.kernel.org/r/20220526001746.2437669-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e05dd93826e1a0f9dedb6bcf8f99ba17462ae08f
Author: Guoju Fang <gjfang@linux.alibaba.com>
Date:   Sat May 28 18:16:28 2022 +0800

    net: sched: add barrier to fix packet stuck problem for lockless qdisc
    
    [ Upstream commit 2e8728c955ce0624b958eee6e030a37aca3a5d86 ]
    
    In qdisc_run_end(), the spin_unlock() only has store-release semantic,
    which guarantees all earlier memory access are visible before it. But
    the subsequent test_bit() has no barrier semantics so may be reordered
    ahead of the spin_unlock(). The store-load reordering may cause a packet
    stuck problem.
    
    The concurrent operations can be described as below,
             CPU 0                      |          CPU 1
       qdisc_run_end()                  |     qdisc_run_begin()
              .                         |           .
     ----> /* may be reorderd here */   |           .
    |         .                         |           .
    |     spin_unlock()                 |         set_bit()
    |         .                         |         smp_mb__after_atomic()
     ---- test_bit()                    |         spin_trylock()
              .                         |          .
    
    Consider the following sequence of events:
        CPU 0 reorder test_bit() ahead and see MISSED = 0
        CPU 1 calls set_bit()
        CPU 1 calls spin_trylock() and return fail
        CPU 0 executes spin_unlock()
    
    At the end of the sequence, CPU 0 calls spin_unlock() and does nothing
    because it see MISSED = 0. The skb on CPU 1 has beed enqueued but no one
    take it, until the next cpu pushing to the qdisc (if ever ...) will
    notice and dequeue it.
    
    This patch fix this by adding one explicit barrier. As spin_unlock() and
    test_bit() ordering is a store-load ordering, a full memory barrier
    smp_mb() is needed here.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Guoju Fang <gjfang@linux.alibaba.com>
    Link: https://lore.kernel.org/r/20220528101628.120193-1-gjfang@linux.alibaba.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 503a3fd6466d517c489c1f5fa000929852e2815b
Author: Vincent Ray <vray@kalrayinc.com>
Date:   Wed May 25 17:17:46 2022 -0700

    net: sched: fixed barrier to prevent skbuff sticking in qdisc backlog
    
    [ Upstream commit a54ce3703613e41fe1d98060b62ec09a3984dc28 ]
    
    In qdisc_run_begin(), smp_mb__before_atomic() used before test_bit()
    does not provide any ordering guarantee as test_bit() is not an atomic
    operation. This, added to the fact that the spin_trylock() call at
    the beginning of qdisc_run_begin() does not guarantee acquire
    semantics if it does not grab the lock, makes it possible for the
    following statement :
    
    if (test_bit(__QDISC_STATE_MISSED, &qdisc->state))
    
    to be executed before an enqueue operation called before
    qdisc_run_begin().
    
    As a result the following race can happen :
    
               CPU 1                             CPU 2
    
          qdisc_run_begin()               qdisc_run_begin() /* true */
            set(MISSED)                            .
          /* returns false */                      .
              .                            /* sees MISSED = 1 */
              .                            /* so qdisc not empty */
              .                            __qdisc_run()
              .                                    .
              .                              pfifo_fast_dequeue()
     ----> /* may be done here */                  .
    |         .                                clear(MISSED)
    |         .                                    .
    |         .                                smp_mb __after_atomic();
    |         .                                    .
    |         .                                /* recheck the queue */
    |         .                                /* nothing => exit   */
    |   enqueue(skb1)
    |         .
    |   qdisc_run_begin()
    |         .
    |     spin_trylock() /* fail */
    |         .
    |     smp_mb__before_atomic() /* not enough */
    |         .
     ---- if (test_bit(MISSED))
            return false;   /* exit */
    
    In the above scenario, CPU 1 and CPU 2 both try to grab the
    qdisc->seqlock at the same time. Only CPU 2 succeeds and enters the
    bypass code path, where it emits its skb then calls __qdisc_run().
    
    CPU1 fails, sets MISSED and goes down the traditionnal enqueue() +
    dequeue() code path. But when executing qdisc_run_begin() for the
    second time, after enqueuing its skbuff, it sees the MISSED bit still
    set (by itself) and consequently chooses to exit early without setting
    it again nor trying to grab the spinlock again.
    
    Meanwhile CPU2 has seen MISSED = 1, cleared it, checked the queue
    and found it empty, so it returned.
    
    At the end of the sequence, we end up with skb1 enqueued in the
    backlog, both CPUs out of __dev_xmit_skb(), the MISSED bit not set,
    and no __netif_schedule() called made. skb1 will now linger in the
    qdisc until somebody later performs a full __qdisc_run(). Associated
    to the bypass capacity of the qdisc, and the ability of the TCP layer
    to avoid resending packets which it knows are still in the qdisc, this
    can lead to serious traffic "holes" in a TCP connection.
    
    We fix this by replacing the smp_mb__before_atomic() / test_bit() /
    set_bit() / smp_mb__after_atomic() sequence inside qdisc_run_begin()
    by a single test_and_set_bit() call, which is more concise and
    enforces the needed memory barriers.
    
    Fixes: 89837eb4b246 ("net: sched: add barrier to ensure correct ordering for lockless qdisc")
    Signed-off-by: Vincent Ray <vray@kalrayinc.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Link: https://lore.kernel.org/r/20220526001746.2437669-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1bd2f7f38bace42895d2989b4baa202361ac06c5
Author: Guoju Fang <gjfang@linux.alibaba.com>
Date:   Sat May 28 18:16:28 2022 +0800

    net: sched: add barrier to fix packet stuck problem for lockless qdisc
    
    [ Upstream commit 2e8728c955ce0624b958eee6e030a37aca3a5d86 ]
    
    In qdisc_run_end(), the spin_unlock() only has store-release semantic,
    which guarantees all earlier memory access are visible before it. But
    the subsequent test_bit() has no barrier semantics so may be reordered
    ahead of the spin_unlock(). The store-load reordering may cause a packet
    stuck problem.
    
    The concurrent operations can be described as below,
             CPU 0                      |          CPU 1
       qdisc_run_end()                  |     qdisc_run_begin()
              .                         |           .
     ----> /* may be reorderd here */   |           .
    |         .                         |           .
    |     spin_unlock()                 |         set_bit()
    |         .                         |         smp_mb__after_atomic()
     ---- test_bit()                    |         spin_trylock()
              .                         |          .
    
    Consider the following sequence of events:
        CPU 0 reorder test_bit() ahead and see MISSED = 0
        CPU 1 calls set_bit()
        CPU 1 calls spin_trylock() and return fail
        CPU 0 executes spin_unlock()
    
    At the end of the sequence, CPU 0 calls spin_unlock() and does nothing
    because it see MISSED = 0. The skb on CPU 1 has beed enqueued but no one
    take it, until the next cpu pushing to the qdisc (if ever ...) will
    notice and dequeue it.
    
    This patch fix this by adding one explicit barrier. As spin_unlock() and
    test_bit() ordering is a store-load ordering, a full memory barrier
    smp_mb() is needed here.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Guoju Fang <gjfang@linux.alibaba.com>
    Link: https://lore.kernel.org/r/20220528101628.120193-1-gjfang@linux.alibaba.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit be73e3bf68620db7dba698c92e33b45bf8bff79f
Author: Vincent Ray <vray@kalrayinc.com>
Date:   Wed May 25 17:17:46 2022 -0700

    net: sched: fixed barrier to prevent skbuff sticking in qdisc backlog
    
    [ Upstream commit a54ce3703613e41fe1d98060b62ec09a3984dc28 ]
    
    In qdisc_run_begin(), smp_mb__before_atomic() used before test_bit()
    does not provide any ordering guarantee as test_bit() is not an atomic
    operation. This, added to the fact that the spin_trylock() call at
    the beginning of qdisc_run_begin() does not guarantee acquire
    semantics if it does not grab the lock, makes it possible for the
    following statement :
    
    if (test_bit(__QDISC_STATE_MISSED, &qdisc->state))
    
    to be executed before an enqueue operation called before
    qdisc_run_begin().
    
    As a result the following race can happen :
    
               CPU 1                             CPU 2
    
          qdisc_run_begin()               qdisc_run_begin() /* true */
            set(MISSED)                            .
          /* returns false */                      .
              .                            /* sees MISSED = 1 */
              .                            /* so qdisc not empty */
              .                            __qdisc_run()
              .                                    .
              .                              pfifo_fast_dequeue()
     ----> /* may be done here */                  .
    |         .                                clear(MISSED)
    |         .                                    .
    |         .                                smp_mb __after_atomic();
    |         .                                    .
    |         .                                /* recheck the queue */
    |         .                                /* nothing => exit   */
    |   enqueue(skb1)
    |         .
    |   qdisc_run_begin()
    |         .
    |     spin_trylock() /* fail */
    |         .
    |     smp_mb__before_atomic() /* not enough */
    |         .
     ---- if (test_bit(MISSED))
            return false;   /* exit */
    
    In the above scenario, CPU 1 and CPU 2 both try to grab the
    qdisc->seqlock at the same time. Only CPU 2 succeeds and enters the
    bypass code path, where it emits its skb then calls __qdisc_run().
    
    CPU1 fails, sets MISSED and goes down the traditionnal enqueue() +
    dequeue() code path. But when executing qdisc_run_begin() for the
    second time, after enqueuing its skbuff, it sees the MISSED bit still
    set (by itself) and consequently chooses to exit early without setting
    it again nor trying to grab the spinlock again.
    
    Meanwhile CPU2 has seen MISSED = 1, cleared it, checked the queue
    and found it empty, so it returned.
    
    At the end of the sequence, we end up with skb1 enqueued in the
    backlog, both CPUs out of __dev_xmit_skb(), the MISSED bit not set,
    and no __netif_schedule() called made. skb1 will now linger in the
    qdisc until somebody later performs a full __qdisc_run(). Associated
    to the bypass capacity of the qdisc, and the ability of the TCP layer
    to avoid resending packets which it knows are still in the qdisc, this
    can lead to serious traffic "holes" in a TCP connection.
    
    We fix this by replacing the smp_mb__before_atomic() / test_bit() /
    set_bit() / smp_mb__after_atomic() sequence inside qdisc_run_begin()
    by a single test_and_set_bit() call, which is more concise and
    enforces the needed memory barriers.
    
    Fixes: 89837eb4b246 ("net: sched: add barrier to ensure correct ordering for lockless qdisc")
    Signed-off-by: Vincent Ray <vray@kalrayinc.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Link: https://lore.kernel.org/r/20220526001746.2437669-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1fa37b00dc55a061a3eb82e378849862b4aeca9d
Author: Yunfei Dong <yunfei.dong@mediatek.com>
Date:   Thu May 12 04:19:50 2022 +0200

    media: mediatek: vcodec: prevent kernel crash when rmmod mtk-vcodec-dec.ko
    
    [ Upstream commit c10c0086db688c95bb4e0e378e523818dff1551d ]
    
    If the driver support subdev mode, the parameter "dev->pm.dev" will be
    NULL in mtk_vcodec_dec_remove. Kernel will crash when try to rmmod
    mtk-vcodec-dec.ko.
    
    [ 4380.702726] pc : do_raw_spin_trylock+0x4/0x80
    [ 4380.707075] lr : _raw_spin_lock_irq+0x90/0x14c
    [ 4380.711509] sp : ffff80000819bc10
    [ 4380.714811] x29: ffff80000819bc10 x28: ffff3600c03e4000 x27: 0000000000000000
    [ 4380.721934] x26: 0000000000000000 x25: 0000000000000000 x24: 0000000000000000
    [ 4380.729057] x23: ffff3600c0f34930 x22: ffffd5e923549000 x21: 0000000000000220
    [ 4380.736179] x20: 0000000000000208 x19: ffffd5e9213e8ebc x18: 0000000000000020
    [ 4380.743298] x17: 0000002000000000 x16: ffffd5e9213e8e90 x15: 696c346f65646976
    [ 4380.750420] x14: 0000000000000000 x13: 0000000000000001 x12: 0000000000000040
    [ 4380.757542] x11: 0000000000000000 x10: 0000000000000000 x9 : 0000000000000000
    [ 4380.764664] x8 : 0000000000000000 x7 : ffff3600c7273ae8 x6 : ffffd5e9213e8ebc
    [ 4380.771786] x5 : 0000000000000000 x4 : 0000000000000001 x3 : 0000000000000000
    [ 4380.778908] x2 : 0000000000000000 x1 : ffff3600c03e4000 x0 : 0000000000000208
    [ 4380.786031] Call trace:
    [ 4380.788465]  do_raw_spin_trylock+0x4/0x80
    [ 4380.792462]  __pm_runtime_disable+0x2c/0x1b0
    [ 4380.796723]  mtk_vcodec_dec_remove+0x5c/0xa0 [mtk_vcodec_dec]
    [ 4380.802466]  platform_remove+0x2c/0x60
    [ 4380.806204]  __device_release_driver+0x194/0x250
    [ 4380.810810]  driver_detach+0xc8/0x15c
    [ 4380.814462]  bus_remove_driver+0x5c/0xb0
    [ 4380.818375]  driver_unregister+0x34/0x64
    [ 4380.822288]  platform_driver_unregister+0x18/0x24
    [ 4380.826979]  mtk_vcodec_dec_driver_exit+0x1c/0x888 [mtk_vcodec_dec]
    [ 4380.833240]  __arm64_sys_delete_module+0x190/0x224
    [ 4380.838020]  invoke_syscall+0x48/0x114
    [ 4380.841760]  el0_svc_common.constprop.0+0x60/0x11c
    [ 4380.846540]  do_el0_svc+0x28/0x90
    [ 4380.849844]  el0_svc+0x4c/0x100
    [ 4380.852975]  el0t_64_sync_handler+0xec/0xf0
    [ 4380.857148]  el0t_64_sync+0x190/0x194
    [ 4380.860801] Code: 94431515 17ffffca d503201f d503245f (b9400004)
    
    Signed-off-by: Yunfei Dong <yunfei.dong@mediatek.com>
    Tested-by: Ncolas F. R. A. Prado <nfraprado@collabora.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2e8728c955ce0624b958eee6e030a37aca3a5d86
Author: Guoju Fang <gjfang@linux.alibaba.com>
Date:   Sat May 28 18:16:28 2022 +0800

    net: sched: add barrier to fix packet stuck problem for lockless qdisc
    
    In qdisc_run_end(), the spin_unlock() only has store-release semantic,
    which guarantees all earlier memory access are visible before it. But
    the subsequent test_bit() has no barrier semantics so may be reordered
    ahead of the spin_unlock(). The store-load reordering may cause a packet
    stuck problem.
    
    The concurrent operations can be described as below,
             CPU 0                      |          CPU 1
       qdisc_run_end()                  |     qdisc_run_begin()
              .                         |           .
     ----> /* may be reorderd here */   |           .
    |         .                         |           .
    |     spin_unlock()                 |         set_bit()
    |         .                         |         smp_mb__after_atomic()
     ---- test_bit()                    |         spin_trylock()
              .                         |          .
    
    Consider the following sequence of events:
        CPU 0 reorder test_bit() ahead and see MISSED = 0
        CPU 1 calls set_bit()
        CPU 1 calls spin_trylock() and return fail
        CPU 0 executes spin_unlock()
    
    At the end of the sequence, CPU 0 calls spin_unlock() and does nothing
    because it see MISSED = 0. The skb on CPU 1 has beed enqueued but no one
    take it, until the next cpu pushing to the qdisc (if ever ...) will
    notice and dequeue it.
    
    This patch fix this by adding one explicit barrier. As spin_unlock() and
    test_bit() ordering is a store-load ordering, a full memory barrier
    smp_mb() is needed here.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Guoju Fang <gjfang@linux.alibaba.com>
    Link: https://lore.kernel.org/r/20220528101628.120193-1-gjfang@linux.alibaba.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit a54ce3703613e41fe1d98060b62ec09a3984dc28
Author: Vincent Ray <vray@kalrayinc.com>
Date:   Wed May 25 17:17:46 2022 -0700

    net: sched: fixed barrier to prevent skbuff sticking in qdisc backlog
    
    In qdisc_run_begin(), smp_mb__before_atomic() used before test_bit()
    does not provide any ordering guarantee as test_bit() is not an atomic
    operation. This, added to the fact that the spin_trylock() call at
    the beginning of qdisc_run_begin() does not guarantee acquire
    semantics if it does not grab the lock, makes it possible for the
    following statement :
    
    if (test_bit(__QDISC_STATE_MISSED, &qdisc->state))
    
    to be executed before an enqueue operation called before
    qdisc_run_begin().
    
    As a result the following race can happen :
    
               CPU 1                             CPU 2
    
          qdisc_run_begin()               qdisc_run_begin() /* true */
            set(MISSED)                            .
          /* returns false */                      .
              .                            /* sees MISSED = 1 */
              .                            /* so qdisc not empty */
              .                            __qdisc_run()
              .                                    .
              .                              pfifo_fast_dequeue()
     ----> /* may be done here */                  .
    |         .                                clear(MISSED)
    |         .                                    .
    |         .                                smp_mb __after_atomic();
    |         .                                    .
    |         .                                /* recheck the queue */
    |         .                                /* nothing => exit   */
    |   enqueue(skb1)
    |         .
    |   qdisc_run_begin()
    |         .
    |     spin_trylock() /* fail */
    |         .
    |     smp_mb__before_atomic() /* not enough */
    |         .
     ---- if (test_bit(MISSED))
            return false;   /* exit */
    
    In the above scenario, CPU 1 and CPU 2 both try to grab the
    qdisc->seqlock at the same time. Only CPU 2 succeeds and enters the
    bypass code path, where it emits its skb then calls __qdisc_run().
    
    CPU1 fails, sets MISSED and goes down the traditionnal enqueue() +
    dequeue() code path. But when executing qdisc_run_begin() for the
    second time, after enqueuing its skbuff, it sees the MISSED bit still
    set (by itself) and consequently chooses to exit early without setting
    it again nor trying to grab the spinlock again.
    
    Meanwhile CPU2 has seen MISSED = 1, cleared it, checked the queue
    and found it empty, so it returned.
    
    At the end of the sequence, we end up with skb1 enqueued in the
    backlog, both CPUs out of __dev_xmit_skb(), the MISSED bit not set,
    and no __netif_schedule() called made. skb1 will now linger in the
    qdisc until somebody later performs a full __qdisc_run(). Associated
    to the bypass capacity of the qdisc, and the ability of the TCP layer
    to avoid resending packets which it knows are still in the qdisc, this
    can lead to serious traffic "holes" in a TCP connection.
    
    We fix this by replacing the smp_mb__before_atomic() / test_bit() /
    set_bit() / smp_mb__after_atomic() sequence inside qdisc_run_begin()
    by a single test_and_set_bit() call, which is more concise and
    enforces the needed memory barriers.
    
    Fixes: 89837eb4b246 ("net: sched: add barrier to ensure correct ordering for lockless qdisc")
    Signed-off-by: Vincent Ray <vray@kalrayinc.com>
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Link: https://lore.kernel.org/r/20220526001746.2437669-1-eric.dumazet@gmail.com
    Signed-off-by: Jakub Kicinski <kuba@kernel.org>

commit c10c0086db688c95bb4e0e378e523818dff1551d
Author: Yunfei Dong <yunfei.dong@mediatek.com>
Date:   Thu May 12 04:19:50 2022 +0200

    media: mediatek: vcodec: prevent kernel crash when rmmod mtk-vcodec-dec.ko
    
    If the driver support subdev mode, the parameter "dev->pm.dev" will be
    NULL in mtk_vcodec_dec_remove. Kernel will crash when try to rmmod
    mtk-vcodec-dec.ko.
    
    [ 4380.702726] pc : do_raw_spin_trylock+0x4/0x80
    [ 4380.707075] lr : _raw_spin_lock_irq+0x90/0x14c
    [ 4380.711509] sp : ffff80000819bc10
    [ 4380.714811] x29: ffff80000819bc10 x28: ffff3600c03e4000 x27: 0000000000000000
    [ 4380.721934] x26: 0000000000000000 x25: 0000000000000000 x24: 0000000000000000
    [ 4380.729057] x23: ffff3600c0f34930 x22: ffffd5e923549000 x21: 0000000000000220
    [ 4380.736179] x20: 0000000000000208 x19: ffffd5e9213e8ebc x18: 0000000000000020
    [ 4380.743298] x17: 0000002000000000 x16: ffffd5e9213e8e90 x15: 696c346f65646976
    [ 4380.750420] x14: 0000000000000000 x13: 0000000000000001 x12: 0000000000000040
    [ 4380.757542] x11: 0000000000000000 x10: 0000000000000000 x9 : 0000000000000000
    [ 4380.764664] x8 : 0000000000000000 x7 : ffff3600c7273ae8 x6 : ffffd5e9213e8ebc
    [ 4380.771786] x5 : 0000000000000000 x4 : 0000000000000001 x3 : 0000000000000000
    [ 4380.778908] x2 : 0000000000000000 x1 : ffff3600c03e4000 x0 : 0000000000000208
    [ 4380.786031] Call trace:
    [ 4380.788465]  do_raw_spin_trylock+0x4/0x80
    [ 4380.792462]  __pm_runtime_disable+0x2c/0x1b0
    [ 4380.796723]  mtk_vcodec_dec_remove+0x5c/0xa0 [mtk_vcodec_dec]
    [ 4380.802466]  platform_remove+0x2c/0x60
    [ 4380.806204]  __device_release_driver+0x194/0x250
    [ 4380.810810]  driver_detach+0xc8/0x15c
    [ 4380.814462]  bus_remove_driver+0x5c/0xb0
    [ 4380.818375]  driver_unregister+0x34/0x64
    [ 4380.822288]  platform_driver_unregister+0x18/0x24
    [ 4380.826979]  mtk_vcodec_dec_driver_exit+0x1c/0x888 [mtk_vcodec_dec]
    [ 4380.833240]  __arm64_sys_delete_module+0x190/0x224
    [ 4380.838020]  invoke_syscall+0x48/0x114
    [ 4380.841760]  el0_svc_common.constprop.0+0x60/0x11c
    [ 4380.846540]  do_el0_svc+0x28/0x90
    [ 4380.849844]  el0_svc+0x4c/0x100
    [ 4380.852975]  el0t_64_sync_handler+0xec/0xf0
    [ 4380.857148]  el0t_64_sync+0x190/0x194
    [ 4380.860801] Code: 94431515 17ffffca d503201f d503245f (b9400004)
    
    Signed-off-by: Yunfei Dong <yunfei.dong@mediatek.com>
    Tested-by: Ncolas F. R. A. Prado <nfraprado@collabora.com>
    Signed-off-by: Hans Verkuil <hverkuil-cisco@xs4all.nl>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@kernel.org>

commit 6ab6bf31432f38dfd13da0ac3528e4a4be2cf28c
Author: Marek Vasut <marex@denx.de>
Date:   Thu Apr 21 16:08:27 2022 +0200

    pinctrl: stm32: Keep pinctrl block clock enabled when LEVEL IRQ requested
    
    [ Upstream commit 05d8af449d93e04547b4c6b328e39c890bc803f4 ]
    
    The current EOI handler for LEVEL triggered interrupts calls clk_enable(),
    register IO, clk_disable(). The clock manipulation requires locking which
    happens with IRQs disabled in clk_enable_lock(). Instead of turning the
    clock on and off all the time, enable the clock in case LEVEL interrupt is
    requested and keep the clock enabled until all LEVEL interrupts are freed.
    The LEVEL interrupts are an exception on this platform and seldom used, so
    this does not affect the common case.
    
    This simplifies the LEVEL interrupt handling considerably and also fixes
    the following splat found when using preempt-rt:
     ------------[ cut here ]------------
     WARNING: CPU: 0 PID: 0 at kernel/locking/rtmutex.c:2040 __rt_mutex_trylock+0x37/0x62
     Modules linked in:
     CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.10.109-rt65-stable-standard-00068-g6a5afc4b1217 #85
     Hardware name: STM32 (Device Tree Support)
     [<c010a45d>] (unwind_backtrace) from [<c010766f>] (show_stack+0xb/0xc)
     [<c010766f>] (show_stack) from [<c06353ab>] (dump_stack+0x6f/0x84)
     [<c06353ab>] (dump_stack) from [<c01145e3>] (__warn+0x7f/0xa4)
     [<c01145e3>] (__warn) from [<c063386f>] (warn_slowpath_fmt+0x3b/0x74)
     [<c063386f>] (warn_slowpath_fmt) from [<c063b43d>] (__rt_mutex_trylock+0x37/0x62)
     [<c063b43d>] (__rt_mutex_trylock) from [<c063c053>] (rt_spin_trylock+0x7/0x16)
     [<c063c053>] (rt_spin_trylock) from [<c036a2f3>] (clk_enable_lock+0xb/0x80)
     [<c036a2f3>] (clk_enable_lock) from [<c036ba69>] (clk_core_enable_lock+0x9/0x18)
     [<c036ba69>] (clk_core_enable_lock) from [<c034e9f3>] (stm32_gpio_get+0x11/0x24)
     [<c034e9f3>] (stm32_gpio_get) from [<c034ef43>] (stm32_gpio_irq_trigger+0x1f/0x48)
     [<c034ef43>] (stm32_gpio_irq_trigger) from [<c014aa53>] (handle_fasteoi_irq+0x71/0xa8)
     [<c014aa53>] (handle_fasteoi_irq) from [<c0147111>] (generic_handle_irq+0x19/0x22)
     [<c0147111>] (generic_handle_irq) from [<c014752d>] (__handle_domain_irq+0x55/0x64)
     [<c014752d>] (__handle_domain_irq) from [<c0346f13>] (gic_handle_irq+0x53/0x64)
     [<c0346f13>] (gic_handle_irq) from [<c0100ba5>] (__irq_svc+0x65/0xc0)
     Exception stack(0xc0e01f18 to 0xc0e01f60)
     1f00:                                                       0000300c 00000000
     1f20: 0000300c c010ff01 00000000 00000000 c0e00000 c0e07714 00000001 c0e01f78
     1f40: c0e07758 00000000 ef7cd0ff c0e01f68 c010554b c0105542 40000033 ffffffff
     [<c0100ba5>] (__irq_svc) from [<c0105542>] (arch_cpu_idle+0xc/0x1e)
     [<c0105542>] (arch_cpu_idle) from [<c063be95>] (default_idle_call+0x21/0x3c)
     [<c063be95>] (default_idle_call) from [<c01324f7>] (do_idle+0xe3/0x1e4)
     [<c01324f7>] (do_idle) from [<c01327b3>] (cpu_startup_entry+0x13/0x14)
     [<c01327b3>] (cpu_startup_entry) from [<c0a00c13>] (start_kernel+0x397/0x3d4)
     [<c0a00c13>] (start_kernel) from [<00000000>] (0x0)
     ---[ end trace 0000000000000002 ]---
    
    Power consumption measured on STM32MP157C DHCOM SoM is not increased or
    is below noise threshold.
    
    Fixes: 47beed513a85b ("pinctrl: stm32: Add level interrupt support to gpio irq chip")
    Signed-off-by: Marek Vasut <marex@denx.de>
    Cc: Alexandre Torgue <alexandre.torgue@foss.st.com>
    Cc: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: linux-stm32@st-md-mailman.stormreply.com
    Cc: linux-arm-kernel@lists.infradead.org
    To: linux-gpio@vger.kernel.org
    Reviewed-by: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Link: https://lore.kernel.org/r/20220421140827.214088-1-marex@denx.de
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e9b1a51c32972a2e7956d7abda90296ba7f8db1b
Author: Marek Vasut <marex@denx.de>
Date:   Thu Apr 21 16:08:27 2022 +0200

    pinctrl: stm32: Keep pinctrl block clock enabled when LEVEL IRQ requested
    
    [ Upstream commit 05d8af449d93e04547b4c6b328e39c890bc803f4 ]
    
    The current EOI handler for LEVEL triggered interrupts calls clk_enable(),
    register IO, clk_disable(). The clock manipulation requires locking which
    happens with IRQs disabled in clk_enable_lock(). Instead of turning the
    clock on and off all the time, enable the clock in case LEVEL interrupt is
    requested and keep the clock enabled until all LEVEL interrupts are freed.
    The LEVEL interrupts are an exception on this platform and seldom used, so
    this does not affect the common case.
    
    This simplifies the LEVEL interrupt handling considerably and also fixes
    the following splat found when using preempt-rt:
     ------------[ cut here ]------------
     WARNING: CPU: 0 PID: 0 at kernel/locking/rtmutex.c:2040 __rt_mutex_trylock+0x37/0x62
     Modules linked in:
     CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.10.109-rt65-stable-standard-00068-g6a5afc4b1217 #85
     Hardware name: STM32 (Device Tree Support)
     [<c010a45d>] (unwind_backtrace) from [<c010766f>] (show_stack+0xb/0xc)
     [<c010766f>] (show_stack) from [<c06353ab>] (dump_stack+0x6f/0x84)
     [<c06353ab>] (dump_stack) from [<c01145e3>] (__warn+0x7f/0xa4)
     [<c01145e3>] (__warn) from [<c063386f>] (warn_slowpath_fmt+0x3b/0x74)
     [<c063386f>] (warn_slowpath_fmt) from [<c063b43d>] (__rt_mutex_trylock+0x37/0x62)
     [<c063b43d>] (__rt_mutex_trylock) from [<c063c053>] (rt_spin_trylock+0x7/0x16)
     [<c063c053>] (rt_spin_trylock) from [<c036a2f3>] (clk_enable_lock+0xb/0x80)
     [<c036a2f3>] (clk_enable_lock) from [<c036ba69>] (clk_core_enable_lock+0x9/0x18)
     [<c036ba69>] (clk_core_enable_lock) from [<c034e9f3>] (stm32_gpio_get+0x11/0x24)
     [<c034e9f3>] (stm32_gpio_get) from [<c034ef43>] (stm32_gpio_irq_trigger+0x1f/0x48)
     [<c034ef43>] (stm32_gpio_irq_trigger) from [<c014aa53>] (handle_fasteoi_irq+0x71/0xa8)
     [<c014aa53>] (handle_fasteoi_irq) from [<c0147111>] (generic_handle_irq+0x19/0x22)
     [<c0147111>] (generic_handle_irq) from [<c014752d>] (__handle_domain_irq+0x55/0x64)
     [<c014752d>] (__handle_domain_irq) from [<c0346f13>] (gic_handle_irq+0x53/0x64)
     [<c0346f13>] (gic_handle_irq) from [<c0100ba5>] (__irq_svc+0x65/0xc0)
     Exception stack(0xc0e01f18 to 0xc0e01f60)
     1f00:                                                       0000300c 00000000
     1f20: 0000300c c010ff01 00000000 00000000 c0e00000 c0e07714 00000001 c0e01f78
     1f40: c0e07758 00000000 ef7cd0ff c0e01f68 c010554b c0105542 40000033 ffffffff
     [<c0100ba5>] (__irq_svc) from [<c0105542>] (arch_cpu_idle+0xc/0x1e)
     [<c0105542>] (arch_cpu_idle) from [<c063be95>] (default_idle_call+0x21/0x3c)
     [<c063be95>] (default_idle_call) from [<c01324f7>] (do_idle+0xe3/0x1e4)
     [<c01324f7>] (do_idle) from [<c01327b3>] (cpu_startup_entry+0x13/0x14)
     [<c01327b3>] (cpu_startup_entry) from [<c0a00c13>] (start_kernel+0x397/0x3d4)
     [<c0a00c13>] (start_kernel) from [<00000000>] (0x0)
     ---[ end trace 0000000000000002 ]---
    
    Power consumption measured on STM32MP157C DHCOM SoM is not increased or
    is below noise threshold.
    
    Fixes: 47beed513a85b ("pinctrl: stm32: Add level interrupt support to gpio irq chip")
    Signed-off-by: Marek Vasut <marex@denx.de>
    Cc: Alexandre Torgue <alexandre.torgue@foss.st.com>
    Cc: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: linux-stm32@st-md-mailman.stormreply.com
    Cc: linux-arm-kernel@lists.infradead.org
    To: linux-gpio@vger.kernel.org
    Reviewed-by: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Link: https://lore.kernel.org/r/20220421140827.214088-1-marex@denx.de
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ce4c3f70878704e52d117f2b3d305d2e7c5d1439
Author: Marek Vasut <marex@denx.de>
Date:   Thu Apr 21 16:08:27 2022 +0200

    pinctrl: stm32: Keep pinctrl block clock enabled when LEVEL IRQ requested
    
    [ Upstream commit 05d8af449d93e04547b4c6b328e39c890bc803f4 ]
    
    The current EOI handler for LEVEL triggered interrupts calls clk_enable(),
    register IO, clk_disable(). The clock manipulation requires locking which
    happens with IRQs disabled in clk_enable_lock(). Instead of turning the
    clock on and off all the time, enable the clock in case LEVEL interrupt is
    requested and keep the clock enabled until all LEVEL interrupts are freed.
    The LEVEL interrupts are an exception on this platform and seldom used, so
    this does not affect the common case.
    
    This simplifies the LEVEL interrupt handling considerably and also fixes
    the following splat found when using preempt-rt:
     ------------[ cut here ]------------
     WARNING: CPU: 0 PID: 0 at kernel/locking/rtmutex.c:2040 __rt_mutex_trylock+0x37/0x62
     Modules linked in:
     CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.10.109-rt65-stable-standard-00068-g6a5afc4b1217 #85
     Hardware name: STM32 (Device Tree Support)
     [<c010a45d>] (unwind_backtrace) from [<c010766f>] (show_stack+0xb/0xc)
     [<c010766f>] (show_stack) from [<c06353ab>] (dump_stack+0x6f/0x84)
     [<c06353ab>] (dump_stack) from [<c01145e3>] (__warn+0x7f/0xa4)
     [<c01145e3>] (__warn) from [<c063386f>] (warn_slowpath_fmt+0x3b/0x74)
     [<c063386f>] (warn_slowpath_fmt) from [<c063b43d>] (__rt_mutex_trylock+0x37/0x62)
     [<c063b43d>] (__rt_mutex_trylock) from [<c063c053>] (rt_spin_trylock+0x7/0x16)
     [<c063c053>] (rt_spin_trylock) from [<c036a2f3>] (clk_enable_lock+0xb/0x80)
     [<c036a2f3>] (clk_enable_lock) from [<c036ba69>] (clk_core_enable_lock+0x9/0x18)
     [<c036ba69>] (clk_core_enable_lock) from [<c034e9f3>] (stm32_gpio_get+0x11/0x24)
     [<c034e9f3>] (stm32_gpio_get) from [<c034ef43>] (stm32_gpio_irq_trigger+0x1f/0x48)
     [<c034ef43>] (stm32_gpio_irq_trigger) from [<c014aa53>] (handle_fasteoi_irq+0x71/0xa8)
     [<c014aa53>] (handle_fasteoi_irq) from [<c0147111>] (generic_handle_irq+0x19/0x22)
     [<c0147111>] (generic_handle_irq) from [<c014752d>] (__handle_domain_irq+0x55/0x64)
     [<c014752d>] (__handle_domain_irq) from [<c0346f13>] (gic_handle_irq+0x53/0x64)
     [<c0346f13>] (gic_handle_irq) from [<c0100ba5>] (__irq_svc+0x65/0xc0)
     Exception stack(0xc0e01f18 to 0xc0e01f60)
     1f00:                                                       0000300c 00000000
     1f20: 0000300c c010ff01 00000000 00000000 c0e00000 c0e07714 00000001 c0e01f78
     1f40: c0e07758 00000000 ef7cd0ff c0e01f68 c010554b c0105542 40000033 ffffffff
     [<c0100ba5>] (__irq_svc) from [<c0105542>] (arch_cpu_idle+0xc/0x1e)
     [<c0105542>] (arch_cpu_idle) from [<c063be95>] (default_idle_call+0x21/0x3c)
     [<c063be95>] (default_idle_call) from [<c01324f7>] (do_idle+0xe3/0x1e4)
     [<c01324f7>] (do_idle) from [<c01327b3>] (cpu_startup_entry+0x13/0x14)
     [<c01327b3>] (cpu_startup_entry) from [<c0a00c13>] (start_kernel+0x397/0x3d4)
     [<c0a00c13>] (start_kernel) from [<00000000>] (0x0)
     ---[ end trace 0000000000000002 ]---
    
    Power consumption measured on STM32MP157C DHCOM SoM is not increased or
    is below noise threshold.
    
    Fixes: 47beed513a85b ("pinctrl: stm32: Add level interrupt support to gpio irq chip")
    Signed-off-by: Marek Vasut <marex@denx.de>
    Cc: Alexandre Torgue <alexandre.torgue@foss.st.com>
    Cc: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: linux-stm32@st-md-mailman.stormreply.com
    Cc: linux-arm-kernel@lists.infradead.org
    To: linux-gpio@vger.kernel.org
    Reviewed-by: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Link: https://lore.kernel.org/r/20220421140827.214088-1-marex@denx.de
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 05d8af449d93e04547b4c6b328e39c890bc803f4
Author: Marek Vasut <marex@denx.de>
Date:   Thu Apr 21 16:08:27 2022 +0200

    pinctrl: stm32: Keep pinctrl block clock enabled when LEVEL IRQ requested
    
    The current EOI handler for LEVEL triggered interrupts calls clk_enable(),
    register IO, clk_disable(). The clock manipulation requires locking which
    happens with IRQs disabled in clk_enable_lock(). Instead of turning the
    clock on and off all the time, enable the clock in case LEVEL interrupt is
    requested and keep the clock enabled until all LEVEL interrupts are freed.
    The LEVEL interrupts are an exception on this platform and seldom used, so
    this does not affect the common case.
    
    This simplifies the LEVEL interrupt handling considerably and also fixes
    the following splat found when using preempt-rt:
     ------------[ cut here ]------------
     WARNING: CPU: 0 PID: 0 at kernel/locking/rtmutex.c:2040 __rt_mutex_trylock+0x37/0x62
     Modules linked in:
     CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.10.109-rt65-stable-standard-00068-g6a5afc4b1217 #85
     Hardware name: STM32 (Device Tree Support)
     [<c010a45d>] (unwind_backtrace) from [<c010766f>] (show_stack+0xb/0xc)
     [<c010766f>] (show_stack) from [<c06353ab>] (dump_stack+0x6f/0x84)
     [<c06353ab>] (dump_stack) from [<c01145e3>] (__warn+0x7f/0xa4)
     [<c01145e3>] (__warn) from [<c063386f>] (warn_slowpath_fmt+0x3b/0x74)
     [<c063386f>] (warn_slowpath_fmt) from [<c063b43d>] (__rt_mutex_trylock+0x37/0x62)
     [<c063b43d>] (__rt_mutex_trylock) from [<c063c053>] (rt_spin_trylock+0x7/0x16)
     [<c063c053>] (rt_spin_trylock) from [<c036a2f3>] (clk_enable_lock+0xb/0x80)
     [<c036a2f3>] (clk_enable_lock) from [<c036ba69>] (clk_core_enable_lock+0x9/0x18)
     [<c036ba69>] (clk_core_enable_lock) from [<c034e9f3>] (stm32_gpio_get+0x11/0x24)
     [<c034e9f3>] (stm32_gpio_get) from [<c034ef43>] (stm32_gpio_irq_trigger+0x1f/0x48)
     [<c034ef43>] (stm32_gpio_irq_trigger) from [<c014aa53>] (handle_fasteoi_irq+0x71/0xa8)
     [<c014aa53>] (handle_fasteoi_irq) from [<c0147111>] (generic_handle_irq+0x19/0x22)
     [<c0147111>] (generic_handle_irq) from [<c014752d>] (__handle_domain_irq+0x55/0x64)
     [<c014752d>] (__handle_domain_irq) from [<c0346f13>] (gic_handle_irq+0x53/0x64)
     [<c0346f13>] (gic_handle_irq) from [<c0100ba5>] (__irq_svc+0x65/0xc0)
     Exception stack(0xc0e01f18 to 0xc0e01f60)
     1f00:                                                       0000300c 00000000
     1f20: 0000300c c010ff01 00000000 00000000 c0e00000 c0e07714 00000001 c0e01f78
     1f40: c0e07758 00000000 ef7cd0ff c0e01f68 c010554b c0105542 40000033 ffffffff
     [<c0100ba5>] (__irq_svc) from [<c0105542>] (arch_cpu_idle+0xc/0x1e)
     [<c0105542>] (arch_cpu_idle) from [<c063be95>] (default_idle_call+0x21/0x3c)
     [<c063be95>] (default_idle_call) from [<c01324f7>] (do_idle+0xe3/0x1e4)
     [<c01324f7>] (do_idle) from [<c01327b3>] (cpu_startup_entry+0x13/0x14)
     [<c01327b3>] (cpu_startup_entry) from [<c0a00c13>] (start_kernel+0x397/0x3d4)
     [<c0a00c13>] (start_kernel) from [<00000000>] (0x0)
     ---[ end trace 0000000000000002 ]---
    
    Power consumption measured on STM32MP157C DHCOM SoM is not increased or
    is below noise threshold.
    
    Fixes: 47beed513a85b ("pinctrl: stm32: Add level interrupt support to gpio irq chip")
    Signed-off-by: Marek Vasut <marex@denx.de>
    Cc: Alexandre Torgue <alexandre.torgue@foss.st.com>
    Cc: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Cc: Linus Walleij <linus.walleij@linaro.org>
    Cc: Marc Zyngier <maz@kernel.org>
    Cc: linux-stm32@st-md-mailman.stormreply.com
    Cc: linux-arm-kernel@lists.infradead.org
    To: linux-gpio@vger.kernel.org
    Reviewed-by: Fabien Dessenne <fabien.dessenne@foss.st.com>
    Link: https://lore.kernel.org/r/20220421140827.214088-1-marex@denx.de
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>

commit 2d24336c7214b281b51860e54783dfc65f1248df
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2f5a1ac68bdf2899ce822ab845081922ea8c588e
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec4334152dae175dbd8fd5bde1d2139bbe7b42d0
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 53e4f71763c61a557283eb43301efd671922d1e8
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 003bcee66a8f0e76157eb3af369c173151901d97
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 471085571f926a1fe6b1bed095638994dbf23990
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3a345198a7c2d1db2526dc60b77052f75de019d3
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3 upstream.
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 936bd03405fc83ba039d42bc93ffd4b88418f1d3
Author: John Meneghini <jmeneghi@redhat.com>
Date:   Mon Jan 24 09:51:10 2022 -0500

    scsi: bnx2fc: Make bnx2fc_recv_frame() mp safe
    
    Running tests with a debug kernel shows that bnx2fc_recv_frame() is
    modifying the per_cpu lport stats counters in a non-mpsafe way.  Just boot
    a debug kernel and run the bnx2fc driver with the hardware enabled.
    
    [ 1391.699147] BUG: using smp_processor_id() in preemptible [00000000] code: bnx2fc_
    [ 1391.699160] caller is bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699174] CPU: 2 PID: 4355 Comm: bnx2fc_l2_threa Kdump: loaded Tainted: G    B
    [ 1391.699180] Hardware name: HP ProLiant DL120 G7, BIOS J01 07/01/2013
    [ 1391.699183] Call Trace:
    [ 1391.699188]  dump_stack_lvl+0x57/0x7d
    [ 1391.699198]  check_preemption_disabled+0xc8/0xd0
    [ 1391.699205]  bnx2fc_recv_frame+0xbf9/0x1760 [bnx2fc]
    [ 1391.699215]  ? do_raw_spin_trylock+0xb5/0x180
    [ 1391.699221]  ? bnx2fc_npiv_create_vports.isra.0+0x4e0/0x4e0 [bnx2fc]
    [ 1391.699229]  ? bnx2fc_l2_rcv_thread+0xb7/0x3a0 [bnx2fc]
    [ 1391.699240]  bnx2fc_l2_rcv_thread+0x1af/0x3a0 [bnx2fc]
    [ 1391.699250]  ? bnx2fc_ulp_init+0xc0/0xc0 [bnx2fc]
    [ 1391.699258]  kthread+0x364/0x420
    [ 1391.699263]  ? _raw_spin_unlock_irq+0x24/0x50
    [ 1391.699268]  ? set_kthread_struct+0x100/0x100
    [ 1391.699273]  ret_from_fork+0x22/0x30
    
    Restore the old get_cpu/put_cpu code with some modifications to reduce the
    size of the critical section.
    
    Link: https://lore.kernel.org/r/20220124145110.442335-1-jmeneghi@redhat.com
    Fixes: d576a5e80cd0 ("bnx2fc: Improve stats update mechanism")
    Tested-by: Guangwu Zhang <guazhang@redhat.com>
    Acked-by: Saurav Kashyap <skashyap@marvell.com>
    Signed-off-by: John Meneghini <jmeneghi@redhat.com>
    Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>

commit 1081a9ac20c1721c080a582bce6307c4fe6e42e1
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit bd2b5268910cdd77a6b4376c4eee390d89f8e246
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Fri Oct 29 16:19:23 2021 -0400

    rsi: Fix out-of-bounds read in rsi_read_pkt()
    
    [ Upstream commit f1cb3476e48b60c450ec3a1d7da0805bffc6e43a ]
    
    rsi_get_* functions rely on an offset variable from usb
    input. The size of usb input is RSI_MAX_RX_USB_PKT_SIZE(3000),
    while 2-byte offset can be up to 0xFFFF. Thus a large offset
    can cause out-of-bounds read.
    
    The patch adds a bound checking condition when rcv_pkt_len is 0,
    indicating it's USB. It's unclear whether this is triggerable
    from other type of bus. The following check might help in that case.
    offset > rcv_pkt_len - FRAME_DESC_SZ
    
    The bug is trigerrable with conpromised/malfunctioning USB devices.
    I tested the patch with the crashing input and got no more bug report.
    
    Attached is the KASAN report from fuzzing.
    
    BUG: KASAN: slab-out-of-bounds in rsi_read_pkt+0x42e/0x500 [rsi_91x]
    Read of size 2 at addr ffff888019439fdb by task RX-Thread/227
    
    CPU: 0 PID: 227 Comm: RX-Thread Not tainted 5.6.0 #66
    Call Trace:
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     __kasan_report.cold+0x37/0x7c
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     kasan_report+0xe/0x20
     rsi_read_pkt+0x42e/0x500 [rsi_91x]
     rsi_usb_rx_thread+0x1b1/0x2fc [rsi_usb]
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __wake_up_common+0x10b/0x520
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     kthread+0x2b5/0x3b0
     ? kthread_create_on_node+0xd0/0xd0
     ret_from_fork+0x22/0x40
    
    Reported-by: Brendan Dolan-Gavitt <brendandg@nyu.edu>
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXxXS4wgu2OsmlVv@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c91e7952bce2d5293503a0466777b44682017ebc
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 38d8d8a882745f87c6a0f54549734241a5818d37
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit dbba81756c1b7a8e7a6df443f863d8da11c2054b
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Fri Oct 29 16:19:23 2021 -0400

    rsi: Fix out-of-bounds read in rsi_read_pkt()
    
    [ Upstream commit f1cb3476e48b60c450ec3a1d7da0805bffc6e43a ]
    
    rsi_get_* functions rely on an offset variable from usb
    input. The size of usb input is RSI_MAX_RX_USB_PKT_SIZE(3000),
    while 2-byte offset can be up to 0xFFFF. Thus a large offset
    can cause out-of-bounds read.
    
    The patch adds a bound checking condition when rcv_pkt_len is 0,
    indicating it's USB. It's unclear whether this is triggerable
    from other type of bus. The following check might help in that case.
    offset > rcv_pkt_len - FRAME_DESC_SZ
    
    The bug is trigerrable with conpromised/malfunctioning USB devices.
    I tested the patch with the crashing input and got no more bug report.
    
    Attached is the KASAN report from fuzzing.
    
    BUG: KASAN: slab-out-of-bounds in rsi_read_pkt+0x42e/0x500 [rsi_91x]
    Read of size 2 at addr ffff888019439fdb by task RX-Thread/227
    
    CPU: 0 PID: 227 Comm: RX-Thread Not tainted 5.6.0 #66
    Call Trace:
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     __kasan_report.cold+0x37/0x7c
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     kasan_report+0xe/0x20
     rsi_read_pkt+0x42e/0x500 [rsi_91x]
     rsi_usb_rx_thread+0x1b1/0x2fc [rsi_usb]
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __wake_up_common+0x10b/0x520
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     kthread+0x2b5/0x3b0
     ? kthread_create_on_node+0xd0/0xd0
     ret_from_fork+0x22/0x40
    
    Reported-by: Brendan Dolan-Gavitt <brendandg@nyu.edu>
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXxXS4wgu2OsmlVv@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit fbcd1e9f8a4306cea72195292658ab51f7722b98
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3ef25f3122c07d143732e27235edb4eaecabb3da
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ab523ea096ef289da0f4431a4395f0ceb1e4ede9
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Fri Oct 29 16:19:23 2021 -0400

    rsi: Fix out-of-bounds read in rsi_read_pkt()
    
    [ Upstream commit f1cb3476e48b60c450ec3a1d7da0805bffc6e43a ]
    
    rsi_get_* functions rely on an offset variable from usb
    input. The size of usb input is RSI_MAX_RX_USB_PKT_SIZE(3000),
    while 2-byte offset can be up to 0xFFFF. Thus a large offset
    can cause out-of-bounds read.
    
    The patch adds a bound checking condition when rcv_pkt_len is 0,
    indicating it's USB. It's unclear whether this is triggerable
    from other type of bus. The following check might help in that case.
    offset > rcv_pkt_len - FRAME_DESC_SZ
    
    The bug is trigerrable with conpromised/malfunctioning USB devices.
    I tested the patch with the crashing input and got no more bug report.
    
    Attached is the KASAN report from fuzzing.
    
    BUG: KASAN: slab-out-of-bounds in rsi_read_pkt+0x42e/0x500 [rsi_91x]
    Read of size 2 at addr ffff888019439fdb by task RX-Thread/227
    
    CPU: 0 PID: 227 Comm: RX-Thread Not tainted 5.6.0 #66
    Call Trace:
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     __kasan_report.cold+0x37/0x7c
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     kasan_report+0xe/0x20
     rsi_read_pkt+0x42e/0x500 [rsi_91x]
     rsi_usb_rx_thread+0x1b1/0x2fc [rsi_usb]
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __wake_up_common+0x10b/0x520
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     kthread+0x2b5/0x3b0
     ? kthread_create_on_node+0xd0/0xd0
     ret_from_fork+0x22/0x40
    
    Reported-by: Brendan Dolan-Gavitt <brendandg@nyu.edu>
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXxXS4wgu2OsmlVv@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 2f13f10fddf4689fbc06204fe75ad595dbe93091
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c8fe499c456528a8a946058e33a52f1762c41c89
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit c27a52321190a45d37c09234c507dcbb1d763d69
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Fri Oct 29 16:19:23 2021 -0400

    rsi: Fix out-of-bounds read in rsi_read_pkt()
    
    [ Upstream commit f1cb3476e48b60c450ec3a1d7da0805bffc6e43a ]
    
    rsi_get_* functions rely on an offset variable from usb
    input. The size of usb input is RSI_MAX_RX_USB_PKT_SIZE(3000),
    while 2-byte offset can be up to 0xFFFF. Thus a large offset
    can cause out-of-bounds read.
    
    The patch adds a bound checking condition when rcv_pkt_len is 0,
    indicating it's USB. It's unclear whether this is triggerable
    from other type of bus. The following check might help in that case.
    offset > rcv_pkt_len - FRAME_DESC_SZ
    
    The bug is trigerrable with conpromised/malfunctioning USB devices.
    I tested the patch with the crashing input and got no more bug report.
    
    Attached is the KASAN report from fuzzing.
    
    BUG: KASAN: slab-out-of-bounds in rsi_read_pkt+0x42e/0x500 [rsi_91x]
    Read of size 2 at addr ffff888019439fdb by task RX-Thread/227
    
    CPU: 0 PID: 227 Comm: RX-Thread Not tainted 5.6.0 #66
    Call Trace:
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     __kasan_report.cold+0x37/0x7c
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     kasan_report+0xe/0x20
     rsi_read_pkt+0x42e/0x500 [rsi_91x]
     rsi_usb_rx_thread+0x1b1/0x2fc [rsi_usb]
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __wake_up_common+0x10b/0x520
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     kthread+0x2b5/0x3b0
     ? kthread_create_on_node+0xd0/0xd0
     ret_from_fork+0x22/0x40
    
    Reported-by: Brendan Dolan-Gavitt <brendandg@nyu.edu>
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXxXS4wgu2OsmlVv@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 3642493839af4b18bf2d88f5889f3997957f2f89
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 8fcc23dce6a1355d6e71bc8b35272390e11cd42f
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit b61836cd323c94942402c3191169518607db8bfd
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Fri Oct 29 16:19:23 2021 -0400

    rsi: Fix out-of-bounds read in rsi_read_pkt()
    
    [ Upstream commit f1cb3476e48b60c450ec3a1d7da0805bffc6e43a ]
    
    rsi_get_* functions rely on an offset variable from usb
    input. The size of usb input is RSI_MAX_RX_USB_PKT_SIZE(3000),
    while 2-byte offset can be up to 0xFFFF. Thus a large offset
    can cause out-of-bounds read.
    
    The patch adds a bound checking condition when rcv_pkt_len is 0,
    indicating it's USB. It's unclear whether this is triggerable
    from other type of bus. The following check might help in that case.
    offset > rcv_pkt_len - FRAME_DESC_SZ
    
    The bug is trigerrable with conpromised/malfunctioning USB devices.
    I tested the patch with the crashing input and got no more bug report.
    
    Attached is the KASAN report from fuzzing.
    
    BUG: KASAN: slab-out-of-bounds in rsi_read_pkt+0x42e/0x500 [rsi_91x]
    Read of size 2 at addr ffff888019439fdb by task RX-Thread/227
    
    CPU: 0 PID: 227 Comm: RX-Thread Not tainted 5.6.0 #66
    Call Trace:
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     __kasan_report.cold+0x37/0x7c
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     kasan_report+0xe/0x20
     rsi_read_pkt+0x42e/0x500 [rsi_91x]
     rsi_usb_rx_thread+0x1b1/0x2fc [rsi_usb]
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __wake_up_common+0x10b/0x520
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     kthread+0x2b5/0x3b0
     ? kthread_create_on_node+0xd0/0xd0
     ret_from_fork+0x22/0x40
    
    Reported-by: Brendan Dolan-Gavitt <brendandg@nyu.edu>
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXxXS4wgu2OsmlVv@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 52a20b60421be926cfa72f578bae869b26d77b99
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1d153d82e55f1cd2f32f5de72859a2608f05a0dc
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 105f110a3632c89cf19b2227dfb4f70cd10c9799
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ee29701dfeef15bc770a4c92e512efe6a3760e4d
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 729674532ddac2cb6866d0da60d8f3dd0c603096
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 36371eb1ffa10fec85edc074cfb9475a957f9012
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    [ Upstream commit 6ce708f54cc8d73beca213cec66ede5ce100a781 ]
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a5f1c71982623bbcda9ee21818b7f693e1536f05
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    [ Upstream commit ae80b6033834342601e99f74f6a62ff5092b1cee ]
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6ce708f54cc8d73beca213cec66ede5ce100a781
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:21:42 2021 -0400

    ath9k: Fix out-of-bound memcpy in ath9k_hif_usb_rx_stream
    
    Large pkt_len can lead to out-out-bound memcpy. Current
    ath9k_hif_usb_rx_stream allows combining the content of two urb
    inputs to one pkt. The first input can indicate the size of the
    pkt. Any remaining size is saved in hif_dev->rx_remain_len.
    While processing the next input, memcpy is used with rx_remain_len.
    
    4-byte pkt_len can go up to 0xffff, while a single input is 0x4000
    maximum in size (MAX_RX_BUF_SIZE). Thus, the patch adds a check for
    pkt_len which must not exceed 2 * MAX_RX_BUG_SIZE.
    
    BUG: KASAN: slab-out-of-bounds in ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
    Read of size 46393 at addr ffff888018798000 by task kworker/0:1/23
    
    CPU: 0 PID: 23 Comm: kworker/0:1 Not tainted 5.6.0 #63
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
    BIOS rel-1.10.2-0-g5f4c7b1-prebuilt.qemu-project.org 04/01/2014
    Workqueue: events request_firmware_work_func
    Call Trace:
     <IRQ>
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     __kasan_report.cold+0x37/0x7c
     ? ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     kasan_report+0xe/0x20
     check_memory_region+0x15a/0x1d0
     memcpy+0x20/0x50
     ath9k_hif_usb_rx_cb+0x490/0xed7 [ath9k_htc]
     ? hif_usb_mgmt_cb+0x2d9/0x2d9 [ath9k_htc]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __usb_unanchor_urb+0x12f/0x210
     __usb_hcd_giveback_urb+0x1e4/0x380
     usb_giveback_urb_bh+0x241/0x4f0
     ? __hrtimer_run_queues+0x316/0x740
     ? __usb_hcd_giveback_urb+0x380/0x380
     tasklet_action_common.isra.0+0x135/0x330
     __do_softirq+0x18c/0x634
     irq_exit+0x114/0x140
     smp_apic_timer_interrupt+0xde/0x380
     apic_timer_interrupt+0xf/0x20
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the value of pkt_tag to ATH_USB_RX_STREAM_MODE_TAG in QEMU
    emulation, I found the KASAN report. The bug is triggerable whenever
    pkt_len is above two MAX_RX_BUG_SIZE. I used the same input that crashes
    to test the driver works when applying the patch.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <quic_kvalo@quicinc.com>
    Link: https://lore.kernel.org/r/YXsidrRuK6zBJicZ@10-18-43-117.dynapool.wireless.nyu.edu

commit f1cb3476e48b60c450ec3a1d7da0805bffc6e43a
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Fri Oct 29 16:19:23 2021 -0400

    rsi: Fix out-of-bounds read in rsi_read_pkt()
    
    rsi_get_* functions rely on an offset variable from usb
    input. The size of usb input is RSI_MAX_RX_USB_PKT_SIZE(3000),
    while 2-byte offset can be up to 0xFFFF. Thus a large offset
    can cause out-of-bounds read.
    
    The patch adds a bound checking condition when rcv_pkt_len is 0,
    indicating it's USB. It's unclear whether this is triggerable
    from other type of bus. The following check might help in that case.
    offset > rcv_pkt_len - FRAME_DESC_SZ
    
    The bug is trigerrable with conpromised/malfunctioning USB devices.
    I tested the patch with the crashing input and got no more bug report.
    
    Attached is the KASAN report from fuzzing.
    
    BUG: KASAN: slab-out-of-bounds in rsi_read_pkt+0x42e/0x500 [rsi_91x]
    Read of size 2 at addr ffff888019439fdb by task RX-Thread/227
    
    CPU: 0 PID: 227 Comm: RX-Thread Not tainted 5.6.0 #66
    Call Trace:
     dump_stack+0x76/0xa0
     print_address_description.constprop.0+0x16/0x200
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     __kasan_report.cold+0x37/0x7c
     ? rsi_read_pkt+0x42e/0x500 [rsi_91x]
     kasan_report+0xe/0x20
     rsi_read_pkt+0x42e/0x500 [rsi_91x]
     rsi_usb_rx_thread+0x1b1/0x2fc [rsi_usb]
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     ? _raw_spin_lock_irqsave+0x7b/0xd0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? __wake_up_common+0x10b/0x520
     ? rsi_probe+0x16a0/0x16a0 [rsi_usb]
     kthread+0x2b5/0x3b0
     ? kthread_create_on_node+0xd0/0xd0
     ret_from_fork+0x22/0x40
    
    Reported-by: Brendan Dolan-Gavitt <brendandg@nyu.edu>
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXxXS4wgu2OsmlVv@10-18-43-117.dynapool.wireless.nyu.edu

commit ae80b6033834342601e99f74f6a62ff5092b1cee
Author: Zekun Shen <bruceshenzk@gmail.com>
Date:   Thu Oct 28 18:37:49 2021 -0400

    ar5523: Fix null-ptr-deref with unexpected WDCMSG_TARGET_START reply
    
    Unexpected WDCMSG_TARGET_START replay can lead to null-ptr-deref
    when ar->tx_cmd->odata is NULL. The patch adds a null check to
    prevent such case.
    
    KASAN: null-ptr-deref in range [0x0000000000000000-0x0000000000000007]
     ar5523_cmd+0x46a/0x581 [ar5523]
     ar5523_probe.cold+0x1b7/0x18da [ar5523]
     ? ar5523_cmd_rx_cb+0x7a0/0x7a0 [ar5523]
     ? __pm_runtime_set_status+0x54a/0x8f0
     ? _raw_spin_trylock_bh+0x120/0x120
     ? pm_runtime_barrier+0x220/0x220
     ? __pm_runtime_resume+0xb1/0xf0
     usb_probe_interface+0x25b/0x710
     really_probe+0x209/0x5d0
     driver_probe_device+0xc6/0x1b0
     device_driver_attach+0xe2/0x120
    
    I found the bug using a custome USBFuzz port. It's a research work
    to fuzz USB stack/drivers. I modified it to fuzz ath9k driver only,
    providing hand-crafted usb descriptors to QEMU.
    
    After fixing the code (fourth byte in usb packet) to WDCMSG_TARGET_START,
    I got the null-ptr-deref bug. I believe the bug is triggerable whenever
    cmd->odata is NULL. After patching, I tested with the same input and no
    longer see the KASAN report.
    
    This was NOT tested on a real device.
    
    Signed-off-by: Zekun Shen <bruceshenzk@gmail.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/YXsmPQ3awHFLuAj2@10-18-43-117.dynapool.wireless.nyu.edu

commit 61616be899975404df44c20ab902464b60882cd7
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Mon Oct 11 13:48:06 2021 -0700

    ice: fix locking for Tx timestamp tracking flush
    
    commit 4d4a223a86afe658cd878800f09458e8bb54415d upstream.
    
    Commit 4dd0d5c33c3e ("ice: add lock around Tx timestamp tracker flush")
    added a lock around the Tx timestamp tracker flow which is used to
    cleanup any left over SKBs and prepare for device removal.
    
    This lock is problematic because it is being held around a call to
    ice_clear_phy_tstamp. The clear function takes a mutex to send a PHY
    write command to firmware. This could lead to a deadlock if the mutex
    actually sleeps, and causes the following warning on a kernel with
    preemption debugging enabled:
    
    [  715.419426] BUG: sleeping function called from invalid context at kernel/locking/mutex.c:573
    [  715.427900] in_atomic(): 1, irqs_disabled(): 0, non_block: 0, pid: 3100, name: rmmod
    [  715.435652] INFO: lockdep is turned off.
    [  715.439591] Preemption disabled at:
    [  715.439594] [<0000000000000000>] 0x0
    [  715.446678] CPU: 52 PID: 3100 Comm: rmmod Tainted: G        W  OE     5.15.0-rc4+ #42 bdd7ec3018e725f159ca0d372ce8c2c0e784891c
    [  715.458058] Hardware name: Intel Corporation S2600STQ/S2600STQ, BIOS SE5C620.86B.02.01.0010.010620200716 01/06/2020
    [  715.468483] Call Trace:
    [  715.470940]  dump_stack_lvl+0x6a/0x9a
    [  715.474613]  ___might_sleep.cold+0x224/0x26a
    [  715.478895]  __mutex_lock+0xb3/0x1440
    [  715.482569]  ? stack_depot_save+0x378/0x500
    [  715.486763]  ? ice_sq_send_cmd+0x78/0x14c0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.494979]  ? kfree+0xc1/0x520
    [  715.498128]  ? mutex_lock_io_nested+0x12a0/0x12a0
    [  715.502837]  ? kasan_set_free_info+0x20/0x30
    [  715.507110]  ? __kasan_slab_free+0x10b/0x140
    [  715.511385]  ? slab_free_freelist_hook+0xc7/0x220
    [  715.516092]  ? kfree+0xc1/0x520
    [  715.519235]  ? ice_deinit_lag+0x16c/0x220 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.527359]  ? ice_remove+0x1cf/0x6a0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.535133]  ? pci_device_remove+0xab/0x1d0
    [  715.539318]  ? __device_release_driver+0x35b/0x690
    [  715.544110]  ? driver_detach+0x214/0x2f0
    [  715.548035]  ? bus_remove_driver+0x11d/0x2f0
    [  715.552309]  ? pci_unregister_driver+0x26/0x250
    [  715.556840]  ? ice_module_exit+0xc/0x2f [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.564799]  ? __do_sys_delete_module.constprop.0+0x2d8/0x4e0
    [  715.570554]  ? do_syscall_64+0x3b/0x90
    [  715.574303]  ? entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  715.579529]  ? start_flush_work+0x542/0x8f0
    [  715.583719]  ? ice_sq_send_cmd+0x78/0x14c0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.591923]  ice_sq_send_cmd+0x78/0x14c0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.599960]  ? wait_for_completion_io+0x250/0x250
    [  715.604662]  ? lock_acquire+0x196/0x200
    [  715.608504]  ? do_raw_spin_trylock+0xa5/0x160
    [  715.612864]  ice_sbq_rw_reg+0x1e6/0x2f0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.620813]  ? ice_reset+0x130/0x130 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.628497]  ? __debug_check_no_obj_freed+0x1e8/0x3c0
    [  715.633550]  ? trace_hardirqs_on+0x1c/0x130
    [  715.637748]  ice_write_phy_reg_e810+0x70/0xf0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.646220]  ? do_raw_spin_trylock+0xa5/0x160
    [  715.650581]  ? ice_ptp_release+0x910/0x910 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.658797]  ? ice_ptp_release+0x255/0x910 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.667013]  ice_clear_phy_tstamp+0x2c/0x110 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.675403]  ice_ptp_release+0x408/0x910 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.683440]  ice_remove+0x560/0x6a0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.691037]  ? _raw_spin_unlock_irqrestore+0x46/0x73
    [  715.696005]  pci_device_remove+0xab/0x1d0
    [  715.700018]  __device_release_driver+0x35b/0x690
    [  715.704637]  driver_detach+0x214/0x2f0
    [  715.708389]  bus_remove_driver+0x11d/0x2f0
    [  715.712489]  pci_unregister_driver+0x26/0x250
    [  715.716857]  ice_module_exit+0xc/0x2f [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.724637]  __do_sys_delete_module.constprop.0+0x2d8/0x4e0
    [  715.730210]  ? free_module+0x6d0/0x6d0
    [  715.733963]  ? task_work_run+0xe1/0x170
    [  715.737803]  ? exit_to_user_mode_loop+0x17f/0x1d0
    [  715.742509]  ? rcu_read_lock_sched_held+0x12/0x80
    [  715.747215]  ? trace_hardirqs_on+0x1c/0x130
    [  715.751401]  do_syscall_64+0x3b/0x90
    [  715.754981]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  715.760033] RIP: 0033:0x7f4dfe59000b
    [  715.763612] Code: 73 01 c3 48 8b 0d 6d 1e 0c 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 90 f3 0f 1e fa b8 b0 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 3d 1e 0c 00 f7 d8 64 89 01 48
    [  715.782357] RSP: 002b:00007ffe8c891708 EFLAGS: 00000206 ORIG_RAX: 00000000000000b0
    [  715.789923] RAX: ffffffffffffffda RBX: 00005558a20468b0 RCX: 00007f4dfe59000b
    [  715.797054] RDX: 000000000000000a RSI: 0000000000000800 RDI: 00005558a2046918
    [  715.804189] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
    [  715.811319] R10: 00007f4dfe603ac0 R11: 0000000000000206 R12: 00007ffe8c891940
    [  715.818455] R13: 00007ffe8c8920a3 R14: 00005558a20462a0 R15: 00005558a20468b0
    
    Notice that this is the only case where we use the lock in this way. In
    the cleanup kthread and work kthread the lock is only taken around the
    bit accesses. This was done intentionally to avoid this kind of issue.
    The way the lock is used, we only protect ordering of bit sets vs bit
    clears. The Tx writers in the hot path don't need to be protected
    against the entire kthread loop. The Tx queues threads only need to
    ensure that they do not re-use an index that is currently in use. The
    cleanup loop does not need to block all new set bits, since it will
    re-queue itself if new timestamps are present.
    
    Fix the tracker flow so that it uses the same flow as the standard
    cleanup thread. In addition, ensure the in_use bitmap actually gets
    cleared properly.
    
    This fixes the warning and also avoids the potential deadlock that might
    have occurred otherwise.
    
    Fixes: 4dd0d5c33c3e ("ice: add lock around Tx timestamp tracker flush")
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4d4a223a86afe658cd878800f09458e8bb54415d
Author: Jacob Keller <jacob.e.keller@intel.com>
Date:   Mon Oct 11 13:48:06 2021 -0700

    ice: fix locking for Tx timestamp tracking flush
    
    Commit 4dd0d5c33c3e ("ice: add lock around Tx timestamp tracker flush")
    added a lock around the Tx timestamp tracker flow which is used to
    cleanup any left over SKBs and prepare for device removal.
    
    This lock is problematic because it is being held around a call to
    ice_clear_phy_tstamp. The clear function takes a mutex to send a PHY
    write command to firmware. This could lead to a deadlock if the mutex
    actually sleeps, and causes the following warning on a kernel with
    preemption debugging enabled:
    
    [  715.419426] BUG: sleeping function called from invalid context at kernel/locking/mutex.c:573
    [  715.427900] in_atomic(): 1, irqs_disabled(): 0, non_block: 0, pid: 3100, name: rmmod
    [  715.435652] INFO: lockdep is turned off.
    [  715.439591] Preemption disabled at:
    [  715.439594] [<0000000000000000>] 0x0
    [  715.446678] CPU: 52 PID: 3100 Comm: rmmod Tainted: G        W  OE     5.15.0-rc4+ #42 bdd7ec3018e725f159ca0d372ce8c2c0e784891c
    [  715.458058] Hardware name: Intel Corporation S2600STQ/S2600STQ, BIOS SE5C620.86B.02.01.0010.010620200716 01/06/2020
    [  715.468483] Call Trace:
    [  715.470940]  dump_stack_lvl+0x6a/0x9a
    [  715.474613]  ___might_sleep.cold+0x224/0x26a
    [  715.478895]  __mutex_lock+0xb3/0x1440
    [  715.482569]  ? stack_depot_save+0x378/0x500
    [  715.486763]  ? ice_sq_send_cmd+0x78/0x14c0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.494979]  ? kfree+0xc1/0x520
    [  715.498128]  ? mutex_lock_io_nested+0x12a0/0x12a0
    [  715.502837]  ? kasan_set_free_info+0x20/0x30
    [  715.507110]  ? __kasan_slab_free+0x10b/0x140
    [  715.511385]  ? slab_free_freelist_hook+0xc7/0x220
    [  715.516092]  ? kfree+0xc1/0x520
    [  715.519235]  ? ice_deinit_lag+0x16c/0x220 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.527359]  ? ice_remove+0x1cf/0x6a0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.535133]  ? pci_device_remove+0xab/0x1d0
    [  715.539318]  ? __device_release_driver+0x35b/0x690
    [  715.544110]  ? driver_detach+0x214/0x2f0
    [  715.548035]  ? bus_remove_driver+0x11d/0x2f0
    [  715.552309]  ? pci_unregister_driver+0x26/0x250
    [  715.556840]  ? ice_module_exit+0xc/0x2f [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.564799]  ? __do_sys_delete_module.constprop.0+0x2d8/0x4e0
    [  715.570554]  ? do_syscall_64+0x3b/0x90
    [  715.574303]  ? entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  715.579529]  ? start_flush_work+0x542/0x8f0
    [  715.583719]  ? ice_sq_send_cmd+0x78/0x14c0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.591923]  ice_sq_send_cmd+0x78/0x14c0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.599960]  ? wait_for_completion_io+0x250/0x250
    [  715.604662]  ? lock_acquire+0x196/0x200
    [  715.608504]  ? do_raw_spin_trylock+0xa5/0x160
    [  715.612864]  ice_sbq_rw_reg+0x1e6/0x2f0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.620813]  ? ice_reset+0x130/0x130 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.628497]  ? __debug_check_no_obj_freed+0x1e8/0x3c0
    [  715.633550]  ? trace_hardirqs_on+0x1c/0x130
    [  715.637748]  ice_write_phy_reg_e810+0x70/0xf0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.646220]  ? do_raw_spin_trylock+0xa5/0x160
    [  715.650581]  ? ice_ptp_release+0x910/0x910 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.658797]  ? ice_ptp_release+0x255/0x910 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.667013]  ice_clear_phy_tstamp+0x2c/0x110 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.675403]  ice_ptp_release+0x408/0x910 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.683440]  ice_remove+0x560/0x6a0 [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.691037]  ? _raw_spin_unlock_irqrestore+0x46/0x73
    [  715.696005]  pci_device_remove+0xab/0x1d0
    [  715.700018]  __device_release_driver+0x35b/0x690
    [  715.704637]  driver_detach+0x214/0x2f0
    [  715.708389]  bus_remove_driver+0x11d/0x2f0
    [  715.712489]  pci_unregister_driver+0x26/0x250
    [  715.716857]  ice_module_exit+0xc/0x2f [ice 9a7e1ec00971c89ecd3fe0d4dc7da2b3786a421d]
    [  715.724637]  __do_sys_delete_module.constprop.0+0x2d8/0x4e0
    [  715.730210]  ? free_module+0x6d0/0x6d0
    [  715.733963]  ? task_work_run+0xe1/0x170
    [  715.737803]  ? exit_to_user_mode_loop+0x17f/0x1d0
    [  715.742509]  ? rcu_read_lock_sched_held+0x12/0x80
    [  715.747215]  ? trace_hardirqs_on+0x1c/0x130
    [  715.751401]  do_syscall_64+0x3b/0x90
    [  715.754981]  entry_SYSCALL_64_after_hwframe+0x44/0xae
    [  715.760033] RIP: 0033:0x7f4dfe59000b
    [  715.763612] Code: 73 01 c3 48 8b 0d 6d 1e 0c 00 f7 d8 64 89 01 48 83 c8 ff c3 66 2e 0f 1f 84 00 00 00 00 00 90 f3 0f 1e fa b8 b0 00 00 00 0f 05 <48> 3d 01 f0 ff ff 73 01 c3 48 8b 0d 3d 1e 0c 00 f7 d8 64 89 01 48
    [  715.782357] RSP: 002b:00007ffe8c891708 EFLAGS: 00000206 ORIG_RAX: 00000000000000b0
    [  715.789923] RAX: ffffffffffffffda RBX: 00005558a20468b0 RCX: 00007f4dfe59000b
    [  715.797054] RDX: 000000000000000a RSI: 0000000000000800 RDI: 00005558a2046918
    [  715.804189] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000000
    [  715.811319] R10: 00007f4dfe603ac0 R11: 0000000000000206 R12: 00007ffe8c891940
    [  715.818455] R13: 00007ffe8c8920a3 R14: 00005558a20462a0 R15: 00005558a20468b0
    
    Notice that this is the only case where we use the lock in this way. In
    the cleanup kthread and work kthread the lock is only taken around the
    bit accesses. This was done intentionally to avoid this kind of issue.
    The way the lock is used, we only protect ordering of bit sets vs bit
    clears. The Tx writers in the hot path don't need to be protected
    against the entire kthread loop. The Tx queues threads only need to
    ensure that they do not re-use an index that is currently in use. The
    cleanup loop does not need to block all new set bits, since it will
    re-queue itself if new timestamps are present.
    
    Fix the tracker flow so that it uses the same flow as the standard
    cleanup thread. In addition, ensure the in_use bitmap actually gets
    cleared properly.
    
    This fixes the warning and also avoids the potential deadlock that might
    have occurred otherwise.
    
    Fixes: 4dd0d5c33c3e ("ice: add lock around Tx timestamp tracker flush")
    Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
    Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 99b0c836b3d88e43b8aad90db3d4d761a33c0348
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Thu Jun 17 09:04:14 2021 +0800

    net: sched: add barrier to ensure correct ordering for lockless qdisc
    
    [ Upstream commit 89837eb4b2463c556a123437f242d6c2bc62ce81 ]
    
    The spin_trylock() was assumed to contain the implicit
    barrier needed to ensure the correct ordering between
    STATE_MISSED setting/clearing and STATE_MISSED checking
    in commit a90c57f2cedd ("net: sched: fix packet stuck
    problem for lockless qdisc").
    
    But it turns out that spin_trylock() only has load-acquire
    semantic, for strongly-ordered system(like x86), the compiler
    barrier implicitly contained in spin_trylock() seems enough
    to ensure the correct ordering. But for weakly-orderly system
    (like arm64), the store-release semantic is needed to ensure
    the correct ordering as clear_bit() and test_bit() is store
    operation, see queued_spin_lock().
    
    So add the explicit barrier to ensure the correct ordering
    for the above case.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 108bfc008437a895671ad0663687fed23f707549
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Thu Jun 17 09:04:14 2021 +0800

    net: sched: add barrier to ensure correct ordering for lockless qdisc
    
    [ Upstream commit 89837eb4b2463c556a123437f242d6c2bc62ce81 ]
    
    The spin_trylock() was assumed to contain the implicit
    barrier needed to ensure the correct ordering between
    STATE_MISSED setting/clearing and STATE_MISSED checking
    in commit a90c57f2cedd ("net: sched: fix packet stuck
    problem for lockless qdisc").
    
    But it turns out that spin_trylock() only has load-acquire
    semantic, for strongly-ordered system(like x86), the compiler
    barrier implicitly contained in spin_trylock() seems enough
    to ensure the correct ordering. But for weakly-orderly system
    (like arm64), the store-release semantic is needed to ensure
    the correct ordering as clear_bit() and test_bit() is store
    operation, see queued_spin_lock().
    
    So add the explicit barrier to ensure the correct ordering
    for the above case.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e7c3ae47978f97f528d95b0c86de51896e78d9f0
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Thu Jun 17 09:04:14 2021 +0800

    net: sched: add barrier to ensure correct ordering for lockless qdisc
    
    [ Upstream commit 89837eb4b2463c556a123437f242d6c2bc62ce81 ]
    
    The spin_trylock() was assumed to contain the implicit
    barrier needed to ensure the correct ordering between
    STATE_MISSED setting/clearing and STATE_MISSED checking
    in commit a90c57f2cedd ("net: sched: fix packet stuck
    problem for lockless qdisc").
    
    But it turns out that spin_trylock() only has load-acquire
    semantic, for strongly-ordered system(like x86), the compiler
    barrier implicitly contained in spin_trylock() seems enough
    to ensure the correct ordering. But for weakly-orderly system
    (like arm64), the store-release semantic is needed to ensure
    the correct ordering as clear_bit() and test_bit() is store
    operation, see queued_spin_lock().
    
    So add the explicit barrier to ensure the correct ordering
    for the above case.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6fea1a58c914d69f0573e39ea1b2b9239b841b26
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Thu Jun 17 09:04:14 2021 +0800

    net: sched: add barrier to ensure correct ordering for lockless qdisc
    
    [ Upstream commit 89837eb4b2463c556a123437f242d6c2bc62ce81 ]
    
    The spin_trylock() was assumed to contain the implicit
    barrier needed to ensure the correct ordering between
    STATE_MISSED setting/clearing and STATE_MISSED checking
    in commit a90c57f2cedd ("net: sched: fix packet stuck
    problem for lockless qdisc").
    
    But it turns out that spin_trylock() only has load-acquire
    semantic, for strongly-ordered system(like x86), the compiler
    barrier implicitly contained in spin_trylock() seems enough
    to ensure the correct ordering. But for weakly-orderly system
    (like arm64), the store-release semantic is needed to ensure
    the correct ordering as clear_bit() and test_bit() is store
    operation, see queued_spin_lock().
    
    So add the explicit barrier to ensure the correct ordering
    for the above case.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit e940eb3c1ba8202a73004e6af62508cb9fbb9a0b
Merge: 38f75922a690 d3e0f57501bd
Author: David S. Miller <davem@davemloft.net>
Date:   Wed Jun 23 12:17:35 2021 -0700

    Merge branch 'lockless-qdisc-opts'
    
    Yunsheng Lin says:
    
    ====================
    Some optimization for lockless qdisc
    
    Patch 1: remove unnecessary seqcount operation.
    Patch 2: implement TCQ_F_CAN_BYPASS.
    Patch 3: remove qdisc->empty.
    
    Performance data for pktgen in queue_xmit mode + dummy netdev
    with pfifo_fast:
    
     threads    unpatched           patched             delta
        1       2.60Mpps            3.21Mpps             +23%
        2       3.84Mpps            5.56Mpps             +44%
        4       5.52Mpps            5.58Mpps             +1%
        8       2.77Mpps            2.76Mpps             -0.3%
       16       2.24Mpps            2.23Mpps             -0.4%
    
    Performance for IP forward testing: 1.05Mpps increases to
    1.16Mpps, about 10% improvement.
    
    V3: Add 'Acked-by' from Jakub and 'Tested-by' from Vladimir,
        and resend based on latest net-next.
    V2: Adjust the comment and commit log according to discussion
        in V1.
    V1: Drop RFC tag, add nolock_qdisc_is_empty() and do the qdisc
        empty checking without the protection of qdisc->seqlock to
        aviod doing unnecessary spin_trylock() for contention case.
    RFC v4: Use STATE_MISSED and STATE_DRAINING to indicate non-empty
            qdisc, and add patch 1 and 3.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c4fef01ba4793a85b2d38a472bddd1e3b56d9585
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Tue Jun 22 14:49:56 2021 +0800

    net: sched: implement TCQ_F_CAN_BYPASS for lockless qdisc
    
    Currently pfifo_fast has both TCQ_F_CAN_BYPASS and TCQ_F_NOLOCK
    flag set, but queue discipline by-pass does not work for lockless
    qdisc because skb is always enqueued to qdisc even when the qdisc
    is empty, see __dev_xmit_skb().
    
    This patch calls sch_direct_xmit() to transmit the skb directly
    to the driver for empty lockless qdisc, which aviod enqueuing
    and dequeuing operation.
    
    As qdisc->empty is not reliable to indicate a empty qdisc because
    there is a time window between enqueuing and setting qdisc->empty.
    So we use the MISSED state added in commit a90c57f2cedd ("net:
    sched: fix packet stuck problem for lockless qdisc"), which
    indicate there is lock contention, suggesting that it is better
    not to do the qdisc bypass in order to avoid packet out of order
    problem.
    
    In order to make MISSED state reliable to indicate a empty qdisc,
    we need to ensure that testing and clearing of MISSED state is
    within the protection of qdisc->seqlock, only setting MISSED state
    can be done without the protection of qdisc->seqlock. A MISSED
    state testing is added without the protection of qdisc->seqlock to
    aviod doing unnecessary spin_trylock() for contention case.
    
    As the enqueuing is not within the protection of qdisc->seqlock,
    there is still a potential data race as mentioned by Jakub [1]:
    
          thread1               thread2             thread3
    qdisc_run_begin() # true
                            qdisc_run_begin(q)
                                 set(MISSED)
    pfifo_fast_dequeue
      clear(MISSED)
      # recheck the queue
    qdisc_run_end()
                                enqueue skb1
                                                 qdisc empty # true
                                              qdisc_run_begin() # true
                                              sch_direct_xmit() # skb2
                             qdisc_run_begin()
                                set(MISSED)
    
    When above happens, skb1 enqueued by thread2 is transmited after
    skb2 is transmited by thread3 because MISSED state setting and
    enqueuing is not under the qdisc->seqlock. If qdisc bypass is
    disabled, skb1 has better chance to be transmited quicker than
    skb2.
    
    This patch does not take care of the above data race, because we
    view this as similar as below:
    Even at the same time CPU1 and CPU2 write the skb to two socket
    which both heading to the same qdisc, there is no guarantee that
    which skb will hit the qdisc first, because there is a lot of
    factor like interrupt/softirq/cache miss/scheduling afffecting
    that.
    
    There are below cases that need special handling:
    1. When MISSED state is cleared before another round of dequeuing
       in pfifo_fast_dequeue(), and __qdisc_run() might not be able to
       dequeue all skb in one round and call __netif_schedule(), which
       might result in a non-empty qdisc without MISSED set. In order
       to avoid this, the MISSED state is set for lockless qdisc and
       __netif_schedule() will be called at the end of qdisc_run_end.
    
    2. The MISSED state also need to be set for lockless qdisc instead
       of calling __netif_schedule() directly when requeuing a skb for
       a similar reason.
    
    3. For netdev queue stopped case, the MISSED case need clearing
       while the netdev queue is stopped, otherwise there may be
       unnecessary __netif_schedule() calling. So a new DRAINING state
       is added to indicate this case, which also indicate a non-empty
       qdisc.
    
    4. As there is already netif_xmit_frozen_or_stopped() checking in
       dequeue_skb() and sch_direct_xmit(), which are both within the
       protection of qdisc->seqlock, but the same checking in
       __dev_xmit_skb() is without the protection, which might cause
       empty indication of a lockless qdisc to be not reliable. So
       remove the checking in __dev_xmit_skb(), and the checking in
       the protection of qdisc->seqlock seems enough to avoid the cpu
       consumption problem for netdev queue stopped case.
    
    1. https://lkml.org/lkml/2021/5/29/215
    
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Tested-by: Vladimir Oltean <vladimir.oltean@nxp.com> # flexcan
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 89837eb4b2463c556a123437f242d6c2bc62ce81
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Thu Jun 17 09:04:14 2021 +0800

    net: sched: add barrier to ensure correct ordering for lockless qdisc
    
    The spin_trylock() was assumed to contain the implicit
    barrier needed to ensure the correct ordering between
    STATE_MISSED setting/clearing and STATE_MISSED checking
    in commit a90c57f2cedd ("net: sched: fix packet stuck
    problem for lockless qdisc").
    
    But it turns out that spin_trylock() only has load-acquire
    semantic, for strongly-ordered system(like x86), the compiler
    barrier implicitly contained in spin_trylock() seems enough
    to ensure the correct ordering. But for weakly-orderly system
    (like arm64), the store-release semantic is needed to ensure
    the correct ordering as clear_bit() and test_bit() is store
    operation, see queued_spin_lock().
    
    So add the explicit barrier to ensure the correct ordering
    for the above case.
    
    Fixes: a90c57f2cedd ("net: sched: fix packet stuck problem for lockless qdisc")
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ae746b6f4ce619cf4032fd798a232b010907a397
Author: Pawel Laszczak <pawell@cadence.com>
Date:   Wed May 26 08:05:27 2021 +0200

    usb: cdnsp: Fix deadlock issue in cdnsp_thread_irq_handler
    
    commit a9aecef198faae3240921b707bc09b602e966fce upstream.
    
    Patch fixes the following critical issue caused by deadlock which has been
    detected during testing NCM class:
    
    smp: csd: Detected non-responsive CSD lock (#1) on CPU#0
    smp:     csd: CSD lock (#1) unresponsive.
    ....
    RIP: 0010:native_queued_spin_lock_slowpath+0x61/0x1d0
    RSP: 0018:ffffbc494011cde0 EFLAGS: 00000002
    RAX: 0000000000000101 RBX: ffff9ee8116b4a68 RCX: 0000000000000000
    RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff9ee8116b4658
    RBP: ffffbc494011cde0 R08: 0000000000000001 R09: 0000000000000000
    R10: ffff9ee8116b4670 R11: 0000000000000000 R12: ffff9ee8116b4658
    R13: ffff9ee8116b4670 R14: 0000000000000246 R15: ffff9ee8116b4658
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f7bcc41a830 CR3: 000000007a612003 CR4: 00000000001706e0
    Call Trace:
     <IRQ>
     do_raw_spin_lock+0xc0/0xd0
     _raw_spin_lock_irqsave+0x95/0xa0
     cdnsp_gadget_ep_queue.cold+0x88/0x107 [cdnsp_udc_pci]
     usb_ep_queue+0x35/0x110
     eth_start_xmit+0x220/0x3d0 [u_ether]
     ncm_tx_timeout+0x34/0x40 [usb_f_ncm]
     ? ncm_free_inst+0x50/0x50 [usb_f_ncm]
     __hrtimer_run_queues+0xac/0x440
     hrtimer_run_softirq+0x8c/0xb0
     __do_softirq+0xcf/0x428
     asm_call_irq_on_stack+0x12/0x20
     </IRQ>
     do_softirq_own_stack+0x61/0x70
     irq_exit_rcu+0xc1/0xd0
     sysvec_apic_timer_interrupt+0x52/0xb0
     asm_sysvec_apic_timer_interrupt+0x12/0x20
    RIP: 0010:do_raw_spin_trylock+0x18/0x40
    RSP: 0018:ffffbc494138bda8 EFLAGS: 00000246
    RAX: 0000000000000000 RBX: ffff9ee8116b4658 RCX: 0000000000000000
    RDX: 0000000000000001 RSI: 0000000000000000 RDI: ffff9ee8116b4658
    RBP: ffffbc494138bda8 R08: 0000000000000001 R09: 0000000000000000
    R10: ffff9ee8116b4670 R11: 0000000000000000 R12: ffff9ee8116b4658
    R13: ffff9ee8116b4670 R14: ffff9ee7b5c73d80 R15: ffff9ee8116b4000
     _raw_spin_lock+0x3d/0x70
     ? cdnsp_thread_irq_handler.cold+0x32/0x112c [cdnsp_udc_pci]
     cdnsp_thread_irq_handler.cold+0x32/0x112c [cdnsp_udc_pci]
     ? cdnsp_remove_request+0x1f0/0x1f0 [cdnsp_udc_pci]
     ? cdnsp_thread_irq_handler+0x5/0xa0 [cdnsp_udc_pci]
     ? irq_thread+0xa0/0x1c0
     irq_thread_fn+0x28/0x60
     irq_thread+0x105/0x1c0
     ? __kthread_parkme+0x42/0x90
     ? irq_forced_thread_fn+0x90/0x90
     ? wake_threads_waitq+0x30/0x30
     ? irq_thread_check_affinity+0xe0/0xe0
     kthread+0x12a/0x160
     ? kthread_park+0x90/0x90
     ret_from_fork+0x22/0x30
    
    The root cause of issue is spin_lock/spin_unlock instruction instead
    spin_lock_irqsave/spin_lock_irqrestore in cdnsp_thread_irq_handler
    function.
    
    Cc: stable@vger.kernel.org
    Fixes: 3d82904559f4 ("usb: cdnsp: cdns3 Add main part of Cadence USBSSP DRD Driver")
    Signed-off-by: Pawel Laszczak <pawell@cadence.com>
    Link: https://lore.kernel.org/r/20210526060527.7197-1-pawell@gli-login.cadence.com
    Signed-off-by: Peter Chen <peter.chen@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dbc50efd5625bfb2daaa946a61cc778d66d57d36
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Fri May 14 11:16:59 2021 +0800

    net: sched: fix packet stuck problem for lockless qdisc
    
    [ Upstream commit a90c57f2cedd52a511f739fb55e6244e22e1a2fb ]
    
    Lockless qdisc has below concurrent problem:
        cpu0                 cpu1
         .                     .
    q->enqueue                 .
         .                     .
    qdisc_run_begin()          .
         .                     .
    dequeue_skb()              .
         .                     .
    sch_direct_xmit()          .
         .                     .
         .                q->enqueue
         .             qdisc_run_begin()
         .            return and do nothing
         .                     .
    qdisc_run_end()            .
    
    cpu1 enqueue a skb without calling __qdisc_run() because cpu0
    has not released the lock yet and spin_trylock() return false
    for cpu1 in qdisc_run_begin(), and cpu0 do not see the skb
    enqueued by cpu1 when calling dequeue_skb() because cpu1 may
    enqueue the skb after cpu0 calling dequeue_skb() and before
    cpu0 calling qdisc_run_end().
    
    Lockless qdisc has below another concurrent problem when
    tx_action is involved:
    
    cpu0(serving tx_action)     cpu1             cpu2
              .                   .                .
              .              q->enqueue            .
              .            qdisc_run_begin()       .
              .              dequeue_skb()         .
              .                   .            q->enqueue
              .                   .                .
              .             sch_direct_xmit()      .
              .                   .         qdisc_run_begin()
              .                   .       return and do nothing
              .                   .                .
     clear __QDISC_STATE_SCHED    .                .
     qdisc_run_begin()            .                .
     return and do nothing        .                .
              .                   .                .
              .            qdisc_run_end()         .
    
    This patch fixes the above data race by:
    1. If the first spin_trylock() return false and STATE_MISSED is
       not set, set STATE_MISSED and retry another spin_trylock() in
       case other CPU may not see STATE_MISSED after it releases the
       lock.
    2. reschedule if STATE_MISSED is set after the lock is released
       at the end of qdisc_run_end().
    
    For tx_action case, STATE_MISSED is also set when cpu1 is at the
    end if qdisc_run_end(), so tx_action will be rescheduled again
    to dequeue the skb enqueued by cpu2.
    
    Clear STATE_MISSED before retrying a dequeuing when dequeuing
    returns NULL in order to reduce the overhead of the second
    spin_trylock() and __netif_schedule() calling.
    
    Also clear the STATE_MISSED before calling __netif_schedule()
    at the end of qdisc_run_end() to avoid doing another round of
    dequeuing in the pfifo_fast_dequeue().
    
    The performance impact of this patch, tested using pktgen and
    dummy netdev with pfifo_fast qdisc attached:
    
     threads  without+this_patch   with+this_patch      delta
        1        2.61Mpps            2.60Mpps           -0.3%
        2        3.97Mpps            3.82Mpps           -3.7%
        4        5.62Mpps            5.59Mpps           -0.5%
        8        2.78Mpps            2.77Mpps           -0.3%
       16        2.22Mpps            2.22Mpps           -0.0%
    
    Fixes: 6b3ba9146fe6 ("net: sched: allow qdiscs to handle locking")
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Tested-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 21c71510925308a1d81513e1519165c063d1b57c
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Fri May 14 11:16:59 2021 +0800

    net: sched: fix packet stuck problem for lockless qdisc
    
    [ Upstream commit a90c57f2cedd52a511f739fb55e6244e22e1a2fb ]
    
    Lockless qdisc has below concurrent problem:
        cpu0                 cpu1
         .                     .
    q->enqueue                 .
         .                     .
    qdisc_run_begin()          .
         .                     .
    dequeue_skb()              .
         .                     .
    sch_direct_xmit()          .
         .                     .
         .                q->enqueue
         .             qdisc_run_begin()
         .            return and do nothing
         .                     .
    qdisc_run_end()            .
    
    cpu1 enqueue a skb without calling __qdisc_run() because cpu0
    has not released the lock yet and spin_trylock() return false
    for cpu1 in qdisc_run_begin(), and cpu0 do not see the skb
    enqueued by cpu1 when calling dequeue_skb() because cpu1 may
    enqueue the skb after cpu0 calling dequeue_skb() and before
    cpu0 calling qdisc_run_end().
    
    Lockless qdisc has below another concurrent problem when
    tx_action is involved:
    
    cpu0(serving tx_action)     cpu1             cpu2
              .                   .                .
              .              q->enqueue            .
              .            qdisc_run_begin()       .
              .              dequeue_skb()         .
              .                   .            q->enqueue
              .                   .                .
              .             sch_direct_xmit()      .
              .                   .         qdisc_run_begin()
              .                   .       return and do nothing
              .                   .                .
     clear __QDISC_STATE_SCHED    .                .
     qdisc_run_begin()            .                .
     return and do nothing        .                .
              .                   .                .
              .            qdisc_run_end()         .
    
    This patch fixes the above data race by:
    1. If the first spin_trylock() return false and STATE_MISSED is
       not set, set STATE_MISSED and retry another spin_trylock() in
       case other CPU may not see STATE_MISSED after it releases the
       lock.
    2. reschedule if STATE_MISSED is set after the lock is released
       at the end of qdisc_run_end().
    
    For tx_action case, STATE_MISSED is also set when cpu1 is at the
    end if qdisc_run_end(), so tx_action will be rescheduled again
    to dequeue the skb enqueued by cpu2.
    
    Clear STATE_MISSED before retrying a dequeuing when dequeuing
    returns NULL in order to reduce the overhead of the second
    spin_trylock() and __netif_schedule() calling.
    
    Also clear the STATE_MISSED before calling __netif_schedule()
    at the end of qdisc_run_end() to avoid doing another round of
    dequeuing in the pfifo_fast_dequeue().
    
    The performance impact of this patch, tested using pktgen and
    dummy netdev with pfifo_fast qdisc attached:
    
     threads  without+this_patch   with+this_patch      delta
        1        2.61Mpps            2.60Mpps           -0.3%
        2        3.97Mpps            3.82Mpps           -3.7%
        4        5.62Mpps            5.59Mpps           -0.5%
        8        2.78Mpps            2.77Mpps           -0.3%
       16        2.22Mpps            2.22Mpps           -0.0%
    
    Fixes: 6b3ba9146fe6 ("net: sched: allow qdiscs to handle locking")
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Tested-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 1c25c7621fb78887b4d28f86a19719c024e3665a
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Fri May 14 11:16:59 2021 +0800

    net: sched: fix packet stuck problem for lockless qdisc
    
    [ Upstream commit a90c57f2cedd52a511f739fb55e6244e22e1a2fb ]
    
    Lockless qdisc has below concurrent problem:
        cpu0                 cpu1
         .                     .
    q->enqueue                 .
         .                     .
    qdisc_run_begin()          .
         .                     .
    dequeue_skb()              .
         .                     .
    sch_direct_xmit()          .
         .                     .
         .                q->enqueue
         .             qdisc_run_begin()
         .            return and do nothing
         .                     .
    qdisc_run_end()            .
    
    cpu1 enqueue a skb without calling __qdisc_run() because cpu0
    has not released the lock yet and spin_trylock() return false
    for cpu1 in qdisc_run_begin(), and cpu0 do not see the skb
    enqueued by cpu1 when calling dequeue_skb() because cpu1 may
    enqueue the skb after cpu0 calling dequeue_skb() and before
    cpu0 calling qdisc_run_end().
    
    Lockless qdisc has below another concurrent problem when
    tx_action is involved:
    
    cpu0(serving tx_action)     cpu1             cpu2
              .                   .                .
              .              q->enqueue            .
              .            qdisc_run_begin()       .
              .              dequeue_skb()         .
              .                   .            q->enqueue
              .                   .                .
              .             sch_direct_xmit()      .
              .                   .         qdisc_run_begin()
              .                   .       return and do nothing
              .                   .                .
     clear __QDISC_STATE_SCHED    .                .
     qdisc_run_begin()            .                .
     return and do nothing        .                .
              .                   .                .
              .            qdisc_run_end()         .
    
    This patch fixes the above data race by:
    1. If the first spin_trylock() return false and STATE_MISSED is
       not set, set STATE_MISSED and retry another spin_trylock() in
       case other CPU may not see STATE_MISSED after it releases the
       lock.
    2. reschedule if STATE_MISSED is set after the lock is released
       at the end of qdisc_run_end().
    
    For tx_action case, STATE_MISSED is also set when cpu1 is at the
    end if qdisc_run_end(), so tx_action will be rescheduled again
    to dequeue the skb enqueued by cpu2.
    
    Clear STATE_MISSED before retrying a dequeuing when dequeuing
    returns NULL in order to reduce the overhead of the second
    spin_trylock() and __netif_schedule() calling.
    
    Also clear the STATE_MISSED before calling __netif_schedule()
    at the end of qdisc_run_end() to avoid doing another round of
    dequeuing in the pfifo_fast_dequeue().
    
    The performance impact of this patch, tested using pktgen and
    dummy netdev with pfifo_fast qdisc attached:
    
     threads  without+this_patch   with+this_patch      delta
        1        2.61Mpps            2.60Mpps           -0.3%
        2        3.97Mpps            3.82Mpps           -3.7%
        4        5.62Mpps            5.59Mpps           -0.5%
        8        2.78Mpps            2.77Mpps           -0.3%
       16        2.22Mpps            2.22Mpps           -0.0%
    
    Fixes: 6b3ba9146fe6 ("net: sched: allow qdiscs to handle locking")
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Tested-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit a9aecef198faae3240921b707bc09b602e966fce
Author: Pawel Laszczak <pawell@cadence.com>
Date:   Wed May 26 08:05:27 2021 +0200

    usb: cdnsp: Fix deadlock issue in cdnsp_thread_irq_handler
    
    Patch fixes the following critical issue caused by deadlock which has been
    detected during testing NCM class:
    
    smp: csd: Detected non-responsive CSD lock (#1) on CPU#0
    smp:     csd: CSD lock (#1) unresponsive.
    ....
    RIP: 0010:native_queued_spin_lock_slowpath+0x61/0x1d0
    RSP: 0018:ffffbc494011cde0 EFLAGS: 00000002
    RAX: 0000000000000101 RBX: ffff9ee8116b4a68 RCX: 0000000000000000
    RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff9ee8116b4658
    RBP: ffffbc494011cde0 R08: 0000000000000001 R09: 0000000000000000
    R10: ffff9ee8116b4670 R11: 0000000000000000 R12: ffff9ee8116b4658
    R13: ffff9ee8116b4670 R14: 0000000000000246 R15: ffff9ee8116b4658
    CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    CR2: 00007f7bcc41a830 CR3: 000000007a612003 CR4: 00000000001706e0
    Call Trace:
     <IRQ>
     do_raw_spin_lock+0xc0/0xd0
     _raw_spin_lock_irqsave+0x95/0xa0
     cdnsp_gadget_ep_queue.cold+0x88/0x107 [cdnsp_udc_pci]
     usb_ep_queue+0x35/0x110
     eth_start_xmit+0x220/0x3d0 [u_ether]
     ncm_tx_timeout+0x34/0x40 [usb_f_ncm]
     ? ncm_free_inst+0x50/0x50 [usb_f_ncm]
     __hrtimer_run_queues+0xac/0x440
     hrtimer_run_softirq+0x8c/0xb0
     __do_softirq+0xcf/0x428
     asm_call_irq_on_stack+0x12/0x20
     </IRQ>
     do_softirq_own_stack+0x61/0x70
     irq_exit_rcu+0xc1/0xd0
     sysvec_apic_timer_interrupt+0x52/0xb0
     asm_sysvec_apic_timer_interrupt+0x12/0x20
    RIP: 0010:do_raw_spin_trylock+0x18/0x40
    RSP: 0018:ffffbc494138bda8 EFLAGS: 00000246
    RAX: 0000000000000000 RBX: ffff9ee8116b4658 RCX: 0000000000000000
    RDX: 0000000000000001 RSI: 0000000000000000 RDI: ffff9ee8116b4658
    RBP: ffffbc494138bda8 R08: 0000000000000001 R09: 0000000000000000
    R10: ffff9ee8116b4670 R11: 0000000000000000 R12: ffff9ee8116b4658
    R13: ffff9ee8116b4670 R14: ffff9ee7b5c73d80 R15: ffff9ee8116b4000
     _raw_spin_lock+0x3d/0x70
     ? cdnsp_thread_irq_handler.cold+0x32/0x112c [cdnsp_udc_pci]
     cdnsp_thread_irq_handler.cold+0x32/0x112c [cdnsp_udc_pci]
     ? cdnsp_remove_request+0x1f0/0x1f0 [cdnsp_udc_pci]
     ? cdnsp_thread_irq_handler+0x5/0xa0 [cdnsp_udc_pci]
     ? irq_thread+0xa0/0x1c0
     irq_thread_fn+0x28/0x60
     irq_thread+0x105/0x1c0
     ? __kthread_parkme+0x42/0x90
     ? irq_forced_thread_fn+0x90/0x90
     ? wake_threads_waitq+0x30/0x30
     ? irq_thread_check_affinity+0xe0/0xe0
     kthread+0x12a/0x160
     ? kthread_park+0x90/0x90
     ret_from_fork+0x22/0x30
    
    The root cause of issue is spin_lock/spin_unlock instruction instead
    spin_lock_irqsave/spin_lock_irqrestore in cdnsp_thread_irq_handler
    function.
    
    Cc: stable@vger.kernel.org
    Fixes: 3d82904559f4 ("usb: cdnsp: cdns3 Add main part of Cadence USBSSP DRD Driver")
    Signed-off-by: Pawel Laszczak <pawell@cadence.com>
    
    Link: https://lore.kernel.org/r/20210526060527.7197-1-pawell@gli-login.cadence.com
    Signed-off-by: Peter Chen <peter.chen@kernel.org>

commit a90c57f2cedd52a511f739fb55e6244e22e1a2fb
Author: Yunsheng Lin <linyunsheng@huawei.com>
Date:   Fri May 14 11:16:59 2021 +0800

    net: sched: fix packet stuck problem for lockless qdisc
    
    Lockless qdisc has below concurrent problem:
        cpu0                 cpu1
         .                     .
    q->enqueue                 .
         .                     .
    qdisc_run_begin()          .
         .                     .
    dequeue_skb()              .
         .                     .
    sch_direct_xmit()          .
         .                     .
         .                q->enqueue
         .             qdisc_run_begin()
         .            return and do nothing
         .                     .
    qdisc_run_end()            .
    
    cpu1 enqueue a skb without calling __qdisc_run() because cpu0
    has not released the lock yet and spin_trylock() return false
    for cpu1 in qdisc_run_begin(), and cpu0 do not see the skb
    enqueued by cpu1 when calling dequeue_skb() because cpu1 may
    enqueue the skb after cpu0 calling dequeue_skb() and before
    cpu0 calling qdisc_run_end().
    
    Lockless qdisc has below another concurrent problem when
    tx_action is involved:
    
    cpu0(serving tx_action)     cpu1             cpu2
              .                   .                .
              .              q->enqueue            .
              .            qdisc_run_begin()       .
              .              dequeue_skb()         .
              .                   .            q->enqueue
              .                   .                .
              .             sch_direct_xmit()      .
              .                   .         qdisc_run_begin()
              .                   .       return and do nothing
              .                   .                .
     clear __QDISC_STATE_SCHED    .                .
     qdisc_run_begin()            .                .
     return and do nothing        .                .
              .                   .                .
              .            qdisc_run_end()         .
    
    This patch fixes the above data race by:
    1. If the first spin_trylock() return false and STATE_MISSED is
       not set, set STATE_MISSED and retry another spin_trylock() in
       case other CPU may not see STATE_MISSED after it releases the
       lock.
    2. reschedule if STATE_MISSED is set after the lock is released
       at the end of qdisc_run_end().
    
    For tx_action case, STATE_MISSED is also set when cpu1 is at the
    end if qdisc_run_end(), so tx_action will be rescheduled again
    to dequeue the skb enqueued by cpu2.
    
    Clear STATE_MISSED before retrying a dequeuing when dequeuing
    returns NULL in order to reduce the overhead of the second
    spin_trylock() and __netif_schedule() calling.
    
    Also clear the STATE_MISSED before calling __netif_schedule()
    at the end of qdisc_run_end() to avoid doing another round of
    dequeuing in the pfifo_fast_dequeue().
    
    The performance impact of this patch, tested using pktgen and
    dummy netdev with pfifo_fast qdisc attached:
    
     threads  without+this_patch   with+this_patch      delta
        1        2.61Mpps            2.60Mpps           -0.3%
        2        3.97Mpps            3.82Mpps           -3.7%
        4        5.62Mpps            5.59Mpps           -0.5%
        8        2.78Mpps            2.77Mpps           -0.3%
       16        2.22Mpps            2.22Mpps           -0.0%
    
    Fixes: 6b3ba9146fe6 ("net: sched: allow qdiscs to handle locking")
    Acked-by: Jakub Kicinski <kuba@kernel.org>
    Tested-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Yunsheng Lin <linyunsheng@huawei.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5697df7322fe0a95e56393f63ca8e0f256be92f9
Author: Michael Walle <michael@walle.cc>
Date:   Wed May 12 16:12:50 2021 +0200

    serial: fsl_lpuart: split sysrq handling
    
    Instead of uart_handle_sysrq_char() use uart_prepare_sysrq_char() and
    uart_unlock_and_check_sysrq(). This will call handle_sysrq() without
    holding the port lock, which in turn let us drop the spin_trylock hack.
    
    Suggested-by: Johan Hovold <johan@kernel.org>
    Signed-off-by: Michael Walle <michael@walle.cc>
    Link: https://lore.kernel.org/r/20210512141255.18277-5-michael@walle.cc
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3799cc62513a58f314ebdde8efe2c9fbfedfd4ff
Author: Song Liu <songliubraving@fb.com>
Date:   Mon Oct 5 09:58:38 2020 -0700

    bpf: Use raw_spin_trylock() for pcpu_freelist_push/pop in NMI
    
    [ Upstream commit 39d8f0d1026a990604770a658708f5845f7dbec0 ]
    
    Recent improvements in LOCKDEP highlighted a potential A-A deadlock with
    pcpu_freelist in NMI:
    
    ./tools/testing/selftests/bpf/test_progs -t stacktrace_build_id_nmi
    
    [   18.984807] ================================
    [   18.984807] WARNING: inconsistent lock state
    [   18.984808] 5.9.0-rc6-01771-g1466de1330e1 #2967 Not tainted
    [   18.984809] --------------------------------
    [   18.984809] inconsistent {INITIAL USE} -> {IN-NMI} usage.
    [   18.984810] test_progs/1990 [HC2[2]:SC0[0]:HE0:SE1] takes:
    [   18.984810] ffffe8ffffc219c0 (&head->lock){....}-{2:2}, at: __pcpu_freelist_pop+0xe3/0x180
    [   18.984813] {INITIAL USE} state was registered at:
    [   18.984814]   lock_acquire+0x175/0x7c0
    [   18.984814]   _raw_spin_lock+0x2c/0x40
    [   18.984815]   __pcpu_freelist_pop+0xe3/0x180
    [   18.984815]   pcpu_freelist_pop+0x31/0x40
    [   18.984816]   htab_map_alloc+0xbbf/0xf40
    [   18.984816]   __do_sys_bpf+0x5aa/0x3ed0
    [   18.984817]   do_syscall_64+0x2d/0x40
    [   18.984818]   entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   18.984818] irq event stamp: 12
    [...]
    [   18.984822] other info that might help us debug this:
    [   18.984823]  Possible unsafe locking scenario:
    [   18.984823]
    [   18.984824]        CPU0
    [   18.984824]        ----
    [   18.984824]   lock(&head->lock);
    [   18.984826]   <Interrupt>
    [   18.984826]     lock(&head->lock);
    [   18.984827]
    [   18.984828]  *** DEADLOCK ***
    [   18.984828]
    [   18.984829] 2 locks held by test_progs/1990:
    [...]
    [   18.984838]  <NMI>
    [   18.984838]  dump_stack+0x9a/0xd0
    [   18.984839]  lock_acquire+0x5c9/0x7c0
    [   18.984839]  ? lock_release+0x6f0/0x6f0
    [   18.984840]  ? __pcpu_freelist_pop+0xe3/0x180
    [   18.984840]  _raw_spin_lock+0x2c/0x40
    [   18.984841]  ? __pcpu_freelist_pop+0xe3/0x180
    [   18.984841]  __pcpu_freelist_pop+0xe3/0x180
    [   18.984842]  pcpu_freelist_pop+0x17/0x40
    [   18.984842]  ? lock_release+0x6f0/0x6f0
    [   18.984843]  __bpf_get_stackid+0x534/0xaf0
    [   18.984843]  bpf_prog_1fd9e30e1438d3c5_oncpu+0x73/0x350
    [   18.984844]  bpf_overflow_handler+0x12f/0x3f0
    
    This is because pcpu_freelist_head.lock is accessed in both NMI and
    non-NMI context. Fix this issue by using raw_spin_trylock() in NMI.
    
    Since NMI interrupts non-NMI context, when NMI context tries to lock the
    raw_spinlock, non-NMI context of the same CPU may already have locked a
    lock and is blocked from unlocking the lock. For a system with N CPUs,
    there could be N NMIs at the same time, and they may block N non-NMI
    raw_spinlocks. This is tricky for pcpu_freelist_push(), where unlike
    _pop(), failing _push() means leaking memory. This issue is more likely to
    trigger in non-SMP system.
    
    Fix this issue with an extra list, pcpu_freelist.extralist. The extralist
    is primarily used to take _push() when raw_spin_trylock() failed on all
    the per CPU lists. It should be empty most of the time. The following
    table summarizes the behavior of pcpu_freelist in NMI and non-NMI:
    
    non-NMI pop():  use _lock(); check per CPU lists first;
                    if all per CPU lists are empty, check extralist;
                    if extralist is empty, return NULL.
    
    non-NMI push(): use _lock(); only push to per CPU lists.
    
    NMI pop():    use _trylock(); check per CPU lists first;
                  if all per CPU lists are locked or empty, check extralist;
                  if extralist is locked or empty, return NULL.
    
    NMI push():   use _trylock(); check per CPU lists first;
                  if all per CPU lists are locked; try push to extralist;
                  if extralist is also locked, keep trying on per CPU lists.
    
    Reported-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20201005165838.3735218-1-songliubraving@fb.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 6cc0a248bcfa9b9f9511f2a55c4a1f64b1aff87d
Author: Song Liu <songliubraving@fb.com>
Date:   Mon Oct 5 09:58:38 2020 -0700

    bpf: Use raw_spin_trylock() for pcpu_freelist_push/pop in NMI
    
    [ Upstream commit 39d8f0d1026a990604770a658708f5845f7dbec0 ]
    
    Recent improvements in LOCKDEP highlighted a potential A-A deadlock with
    pcpu_freelist in NMI:
    
    ./tools/testing/selftests/bpf/test_progs -t stacktrace_build_id_nmi
    
    [   18.984807] ================================
    [   18.984807] WARNING: inconsistent lock state
    [   18.984808] 5.9.0-rc6-01771-g1466de1330e1 #2967 Not tainted
    [   18.984809] --------------------------------
    [   18.984809] inconsistent {INITIAL USE} -> {IN-NMI} usage.
    [   18.984810] test_progs/1990 [HC2[2]:SC0[0]:HE0:SE1] takes:
    [   18.984810] ffffe8ffffc219c0 (&head->lock){....}-{2:2}, at: __pcpu_freelist_pop+0xe3/0x180
    [   18.984813] {INITIAL USE} state was registered at:
    [   18.984814]   lock_acquire+0x175/0x7c0
    [   18.984814]   _raw_spin_lock+0x2c/0x40
    [   18.984815]   __pcpu_freelist_pop+0xe3/0x180
    [   18.984815]   pcpu_freelist_pop+0x31/0x40
    [   18.984816]   htab_map_alloc+0xbbf/0xf40
    [   18.984816]   __do_sys_bpf+0x5aa/0x3ed0
    [   18.984817]   do_syscall_64+0x2d/0x40
    [   18.984818]   entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   18.984818] irq event stamp: 12
    [...]
    [   18.984822] other info that might help us debug this:
    [   18.984823]  Possible unsafe locking scenario:
    [   18.984823]
    [   18.984824]        CPU0
    [   18.984824]        ----
    [   18.984824]   lock(&head->lock);
    [   18.984826]   <Interrupt>
    [   18.984826]     lock(&head->lock);
    [   18.984827]
    [   18.984828]  *** DEADLOCK ***
    [   18.984828]
    [   18.984829] 2 locks held by test_progs/1990:
    [...]
    [   18.984838]  <NMI>
    [   18.984838]  dump_stack+0x9a/0xd0
    [   18.984839]  lock_acquire+0x5c9/0x7c0
    [   18.984839]  ? lock_release+0x6f0/0x6f0
    [   18.984840]  ? __pcpu_freelist_pop+0xe3/0x180
    [   18.984840]  _raw_spin_lock+0x2c/0x40
    [   18.984841]  ? __pcpu_freelist_pop+0xe3/0x180
    [   18.984841]  __pcpu_freelist_pop+0xe3/0x180
    [   18.984842]  pcpu_freelist_pop+0x17/0x40
    [   18.984842]  ? lock_release+0x6f0/0x6f0
    [   18.984843]  __bpf_get_stackid+0x534/0xaf0
    [   18.984843]  bpf_prog_1fd9e30e1438d3c5_oncpu+0x73/0x350
    [   18.984844]  bpf_overflow_handler+0x12f/0x3f0
    
    This is because pcpu_freelist_head.lock is accessed in both NMI and
    non-NMI context. Fix this issue by using raw_spin_trylock() in NMI.
    
    Since NMI interrupts non-NMI context, when NMI context tries to lock the
    raw_spinlock, non-NMI context of the same CPU may already have locked a
    lock and is blocked from unlocking the lock. For a system with N CPUs,
    there could be N NMIs at the same time, and they may block N non-NMI
    raw_spinlocks. This is tricky for pcpu_freelist_push(), where unlike
    _pop(), failing _push() means leaking memory. This issue is more likely to
    trigger in non-SMP system.
    
    Fix this issue with an extra list, pcpu_freelist.extralist. The extralist
    is primarily used to take _push() when raw_spin_trylock() failed on all
    the per CPU lists. It should be empty most of the time. The following
    table summarizes the behavior of pcpu_freelist in NMI and non-NMI:
    
    non-NMI pop():  use _lock(); check per CPU lists first;
                    if all per CPU lists are empty, check extralist;
                    if extralist is empty, return NULL.
    
    non-NMI push(): use _lock(); only push to per CPU lists.
    
    NMI pop():    use _trylock(); check per CPU lists first;
                  if all per CPU lists are locked or empty, check extralist;
                  if extralist is locked or empty, return NULL.
    
    NMI push():   use _trylock(); check per CPU lists first;
                  if all per CPU lists are locked; try push to extralist;
                  if extralist is also locked, keep trying on per CPU lists.
    
    Reported-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20201005165838.3735218-1-songliubraving@fb.com
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 39d8f0d1026a990604770a658708f5845f7dbec0
Author: Song Liu <songliubraving@fb.com>
Date:   Mon Oct 5 09:58:38 2020 -0700

    bpf: Use raw_spin_trylock() for pcpu_freelist_push/pop in NMI
    
    Recent improvements in LOCKDEP highlighted a potential A-A deadlock with
    pcpu_freelist in NMI:
    
    ./tools/testing/selftests/bpf/test_progs -t stacktrace_build_id_nmi
    
    [   18.984807] ================================
    [   18.984807] WARNING: inconsistent lock state
    [   18.984808] 5.9.0-rc6-01771-g1466de1330e1 #2967 Not tainted
    [   18.984809] --------------------------------
    [   18.984809] inconsistent {INITIAL USE} -> {IN-NMI} usage.
    [   18.984810] test_progs/1990 [HC2[2]:SC0[0]:HE0:SE1] takes:
    [   18.984810] ffffe8ffffc219c0 (&head->lock){....}-{2:2}, at: __pcpu_freelist_pop+0xe3/0x180
    [   18.984813] {INITIAL USE} state was registered at:
    [   18.984814]   lock_acquire+0x175/0x7c0
    [   18.984814]   _raw_spin_lock+0x2c/0x40
    [   18.984815]   __pcpu_freelist_pop+0xe3/0x180
    [   18.984815]   pcpu_freelist_pop+0x31/0x40
    [   18.984816]   htab_map_alloc+0xbbf/0xf40
    [   18.984816]   __do_sys_bpf+0x5aa/0x3ed0
    [   18.984817]   do_syscall_64+0x2d/0x40
    [   18.984818]   entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [   18.984818] irq event stamp: 12
    [...]
    [   18.984822] other info that might help us debug this:
    [   18.984823]  Possible unsafe locking scenario:
    [   18.984823]
    [   18.984824]        CPU0
    [   18.984824]        ----
    [   18.984824]   lock(&head->lock);
    [   18.984826]   <Interrupt>
    [   18.984826]     lock(&head->lock);
    [   18.984827]
    [   18.984828]  *** DEADLOCK ***
    [   18.984828]
    [   18.984829] 2 locks held by test_progs/1990:
    [...]
    [   18.984838]  <NMI>
    [   18.984838]  dump_stack+0x9a/0xd0
    [   18.984839]  lock_acquire+0x5c9/0x7c0
    [   18.984839]  ? lock_release+0x6f0/0x6f0
    [   18.984840]  ? __pcpu_freelist_pop+0xe3/0x180
    [   18.984840]  _raw_spin_lock+0x2c/0x40
    [   18.984841]  ? __pcpu_freelist_pop+0xe3/0x180
    [   18.984841]  __pcpu_freelist_pop+0xe3/0x180
    [   18.984842]  pcpu_freelist_pop+0x17/0x40
    [   18.984842]  ? lock_release+0x6f0/0x6f0
    [   18.984843]  __bpf_get_stackid+0x534/0xaf0
    [   18.984843]  bpf_prog_1fd9e30e1438d3c5_oncpu+0x73/0x350
    [   18.984844]  bpf_overflow_handler+0x12f/0x3f0
    
    This is because pcpu_freelist_head.lock is accessed in both NMI and
    non-NMI context. Fix this issue by using raw_spin_trylock() in NMI.
    
    Since NMI interrupts non-NMI context, when NMI context tries to lock the
    raw_spinlock, non-NMI context of the same CPU may already have locked a
    lock and is blocked from unlocking the lock. For a system with N CPUs,
    there could be N NMIs at the same time, and they may block N non-NMI
    raw_spinlocks. This is tricky for pcpu_freelist_push(), where unlike
    _pop(), failing _push() means leaking memory. This issue is more likely to
    trigger in non-SMP system.
    
    Fix this issue with an extra list, pcpu_freelist.extralist. The extralist
    is primarily used to take _push() when raw_spin_trylock() failed on all
    the per CPU lists. It should be empty most of the time. The following
    table summarizes the behavior of pcpu_freelist in NMI and non-NMI:
    
    non-NMI pop():  use _lock(); check per CPU lists first;
                    if all per CPU lists are empty, check extralist;
                    if extralist is empty, return NULL.
    
    non-NMI push(): use _lock(); only push to per CPU lists.
    
    NMI pop():    use _trylock(); check per CPU lists first;
                  if all per CPU lists are locked or empty, check extralist;
                  if extralist is locked or empty, return NULL.
    
    NMI push():   use _trylock(); check per CPU lists first;
                  if all per CPU lists are locked; try push to extralist;
                  if extralist is also locked, keep trying on per CPU lists.
    
    Reported-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Song Liu <songliubraving@fb.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Martin KaFai Lau <kafai@fb.com>
    Link: https://lore.kernel.org/bpf/20201005165838.3735218-1-songliubraving@fb.com

commit 176b2e5140afa957095c84fade39f6fa87a07b0c
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 8 01:20:23 2020 -0700

    ipv6: avoid lockdep issue in fib6_del()
    
    [ Upstream commit 843d926b003ea692468c8cc5bea1f9f58dfa8c75 ]
    
    syzbot reported twice a lockdep issue in fib6_del() [1]
    which I think is caused by net->ipv6.fib6_null_entry
    having a NULL fib6_table pointer.
    
    fib6_del() already checks for fib6_null_entry special
    case, we only need to return earlier.
    
    Bug seems to occur very rarely, I have thus chosen
    a 'bug origin' that makes backports not too complex.
    
    [1]
    WARNING: suspicious RCU usage
    5.9.0-rc4-syzkaller #0 Not tainted
    -----------------------------
    net/ipv6/ip6_fib.c:1996 suspicious rcu_dereference_protected() usage!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    4 locks held by syz-executor.5/8095:
     #0: ffffffff8a7ea708 (rtnl_mutex){+.+.}-{3:3}, at: ppp_release+0x178/0x240 drivers/net/ppp/ppp_generic.c:401
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: spin_trylock_bh include/linux/spinlock.h:414 [inline]
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: fib6_run_gc+0x21b/0x2d0 net/ipv6/ip6_fib.c:2312
     #2: ffffffff89bd6a40 (rcu_read_lock){....}-{1:2}, at: __fib6_clean_all+0x0/0x290 net/ipv6/ip6_fib.c:2613
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: spin_lock_bh include/linux/spinlock.h:359 [inline]
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: __fib6_clean_all+0x107/0x290 net/ipv6/ip6_fib.c:2245
    
    stack backtrace:
    CPU: 1 PID: 8095 Comm: syz-executor.5 Not tainted 5.9.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x198/0x1fd lib/dump_stack.c:118
     fib6_del+0x12b4/0x1630 net/ipv6/ip6_fib.c:1996
     fib6_clean_node+0x39b/0x570 net/ipv6/ip6_fib.c:2180
     fib6_walk_continue+0x4aa/0x8e0 net/ipv6/ip6_fib.c:2102
     fib6_walk+0x182/0x370 net/ipv6/ip6_fib.c:2150
     fib6_clean_tree+0xdb/0x120 net/ipv6/ip6_fib.c:2230
     __fib6_clean_all+0x120/0x290 net/ipv6/ip6_fib.c:2246
     fib6_clean_all net/ipv6/ip6_fib.c:2257 [inline]
     fib6_run_gc+0x113/0x2d0 net/ipv6/ip6_fib.c:2320
     ndisc_netdev_event+0x217/0x350 net/ipv6/ndisc.c:1805
     notifier_call_chain+0xb5/0x200 kernel/notifier.c:83
     call_netdevice_notifiers_info+0xb5/0x130 net/core/dev.c:2033
     call_netdevice_notifiers_extack net/core/dev.c:2045 [inline]
     call_netdevice_notifiers net/core/dev.c:2059 [inline]
     dev_close_many+0x30b/0x650 net/core/dev.c:1634
     rollback_registered_many+0x3a8/0x1210 net/core/dev.c:9261
     rollback_registered net/core/dev.c:9329 [inline]
     unregister_netdevice_queue+0x2dd/0x570 net/core/dev.c:10410
     unregister_netdevice include/linux/netdevice.h:2774 [inline]
     ppp_release+0x216/0x240 drivers/net/ppp/ppp_generic.c:403
     __fput+0x285/0x920 fs/file_table.c:281
     task_work_run+0xdd/0x190 kernel/task_work.c:141
     tracehook_notify_resume include/linux/tracehook.h:188 [inline]
     exit_to_user_mode_loop kernel/entry/common.c:163 [inline]
     exit_to_user_mode_prepare+0x1e1/0x200 kernel/entry/common.c:190
     syscall_exit_to_user_mode+0x7e/0x2e0 kernel/entry/common.c:265
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 421842edeaf6 ("net/ipv6: Add fib6_null_entry")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: David Ahern <dsahern@gmail.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d0b05f019f843c64dda1347fc3e6459e0e7b7f8f
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 8 01:20:23 2020 -0700

    ipv6: avoid lockdep issue in fib6_del()
    
    [ Upstream commit 843d926b003ea692468c8cc5bea1f9f58dfa8c75 ]
    
    syzbot reported twice a lockdep issue in fib6_del() [1]
    which I think is caused by net->ipv6.fib6_null_entry
    having a NULL fib6_table pointer.
    
    fib6_del() already checks for fib6_null_entry special
    case, we only need to return earlier.
    
    Bug seems to occur very rarely, I have thus chosen
    a 'bug origin' that makes backports not too complex.
    
    [1]
    WARNING: suspicious RCU usage
    5.9.0-rc4-syzkaller #0 Not tainted
    -----------------------------
    net/ipv6/ip6_fib.c:1996 suspicious rcu_dereference_protected() usage!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    4 locks held by syz-executor.5/8095:
     #0: ffffffff8a7ea708 (rtnl_mutex){+.+.}-{3:3}, at: ppp_release+0x178/0x240 drivers/net/ppp/ppp_generic.c:401
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: spin_trylock_bh include/linux/spinlock.h:414 [inline]
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: fib6_run_gc+0x21b/0x2d0 net/ipv6/ip6_fib.c:2312
     #2: ffffffff89bd6a40 (rcu_read_lock){....}-{1:2}, at: __fib6_clean_all+0x0/0x290 net/ipv6/ip6_fib.c:2613
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: spin_lock_bh include/linux/spinlock.h:359 [inline]
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: __fib6_clean_all+0x107/0x290 net/ipv6/ip6_fib.c:2245
    
    stack backtrace:
    CPU: 1 PID: 8095 Comm: syz-executor.5 Not tainted 5.9.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x198/0x1fd lib/dump_stack.c:118
     fib6_del+0x12b4/0x1630 net/ipv6/ip6_fib.c:1996
     fib6_clean_node+0x39b/0x570 net/ipv6/ip6_fib.c:2180
     fib6_walk_continue+0x4aa/0x8e0 net/ipv6/ip6_fib.c:2102
     fib6_walk+0x182/0x370 net/ipv6/ip6_fib.c:2150
     fib6_clean_tree+0xdb/0x120 net/ipv6/ip6_fib.c:2230
     __fib6_clean_all+0x120/0x290 net/ipv6/ip6_fib.c:2246
     fib6_clean_all net/ipv6/ip6_fib.c:2257 [inline]
     fib6_run_gc+0x113/0x2d0 net/ipv6/ip6_fib.c:2320
     ndisc_netdev_event+0x217/0x350 net/ipv6/ndisc.c:1805
     notifier_call_chain+0xb5/0x200 kernel/notifier.c:83
     call_netdevice_notifiers_info+0xb5/0x130 net/core/dev.c:2033
     call_netdevice_notifiers_extack net/core/dev.c:2045 [inline]
     call_netdevice_notifiers net/core/dev.c:2059 [inline]
     dev_close_many+0x30b/0x650 net/core/dev.c:1634
     rollback_registered_many+0x3a8/0x1210 net/core/dev.c:9261
     rollback_registered net/core/dev.c:9329 [inline]
     unregister_netdevice_queue+0x2dd/0x570 net/core/dev.c:10410
     unregister_netdevice include/linux/netdevice.h:2774 [inline]
     ppp_release+0x216/0x240 drivers/net/ppp/ppp_generic.c:403
     __fput+0x285/0x920 fs/file_table.c:281
     task_work_run+0xdd/0x190 kernel/task_work.c:141
     tracehook_notify_resume include/linux/tracehook.h:188 [inline]
     exit_to_user_mode_loop kernel/entry/common.c:163 [inline]
     exit_to_user_mode_prepare+0x1e1/0x200 kernel/entry/common.c:190
     syscall_exit_to_user_mode+0x7e/0x2e0 kernel/entry/common.c:265
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 421842edeaf6 ("net/ipv6: Add fib6_null_entry")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: David Ahern <dsahern@gmail.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f2e5359dd3bffa434cba0f62179b1e72065183af
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 8 01:20:23 2020 -0700

    ipv6: avoid lockdep issue in fib6_del()
    
    [ Upstream commit 843d926b003ea692468c8cc5bea1f9f58dfa8c75 ]
    
    syzbot reported twice a lockdep issue in fib6_del() [1]
    which I think is caused by net->ipv6.fib6_null_entry
    having a NULL fib6_table pointer.
    
    fib6_del() already checks for fib6_null_entry special
    case, we only need to return earlier.
    
    Bug seems to occur very rarely, I have thus chosen
    a 'bug origin' that makes backports not too complex.
    
    [1]
    WARNING: suspicious RCU usage
    5.9.0-rc4-syzkaller #0 Not tainted
    -----------------------------
    net/ipv6/ip6_fib.c:1996 suspicious rcu_dereference_protected() usage!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    4 locks held by syz-executor.5/8095:
     #0: ffffffff8a7ea708 (rtnl_mutex){+.+.}-{3:3}, at: ppp_release+0x178/0x240 drivers/net/ppp/ppp_generic.c:401
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: spin_trylock_bh include/linux/spinlock.h:414 [inline]
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: fib6_run_gc+0x21b/0x2d0 net/ipv6/ip6_fib.c:2312
     #2: ffffffff89bd6a40 (rcu_read_lock){....}-{1:2}, at: __fib6_clean_all+0x0/0x290 net/ipv6/ip6_fib.c:2613
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: spin_lock_bh include/linux/spinlock.h:359 [inline]
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: __fib6_clean_all+0x107/0x290 net/ipv6/ip6_fib.c:2245
    
    stack backtrace:
    CPU: 1 PID: 8095 Comm: syz-executor.5 Not tainted 5.9.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x198/0x1fd lib/dump_stack.c:118
     fib6_del+0x12b4/0x1630 net/ipv6/ip6_fib.c:1996
     fib6_clean_node+0x39b/0x570 net/ipv6/ip6_fib.c:2180
     fib6_walk_continue+0x4aa/0x8e0 net/ipv6/ip6_fib.c:2102
     fib6_walk+0x182/0x370 net/ipv6/ip6_fib.c:2150
     fib6_clean_tree+0xdb/0x120 net/ipv6/ip6_fib.c:2230
     __fib6_clean_all+0x120/0x290 net/ipv6/ip6_fib.c:2246
     fib6_clean_all net/ipv6/ip6_fib.c:2257 [inline]
     fib6_run_gc+0x113/0x2d0 net/ipv6/ip6_fib.c:2320
     ndisc_netdev_event+0x217/0x350 net/ipv6/ndisc.c:1805
     notifier_call_chain+0xb5/0x200 kernel/notifier.c:83
     call_netdevice_notifiers_info+0xb5/0x130 net/core/dev.c:2033
     call_netdevice_notifiers_extack net/core/dev.c:2045 [inline]
     call_netdevice_notifiers net/core/dev.c:2059 [inline]
     dev_close_many+0x30b/0x650 net/core/dev.c:1634
     rollback_registered_many+0x3a8/0x1210 net/core/dev.c:9261
     rollback_registered net/core/dev.c:9329 [inline]
     unregister_netdevice_queue+0x2dd/0x570 net/core/dev.c:10410
     unregister_netdevice include/linux/netdevice.h:2774 [inline]
     ppp_release+0x216/0x240 drivers/net/ppp/ppp_generic.c:403
     __fput+0x285/0x920 fs/file_table.c:281
     task_work_run+0xdd/0x190 kernel/task_work.c:141
     tracehook_notify_resume include/linux/tracehook.h:188 [inline]
     exit_to_user_mode_loop kernel/entry/common.c:163 [inline]
     exit_to_user_mode_prepare+0x1e1/0x200 kernel/entry/common.c:190
     syscall_exit_to_user_mode+0x7e/0x2e0 kernel/entry/common.c:265
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 421842edeaf6 ("net/ipv6: Add fib6_null_entry")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: David Ahern <dsahern@gmail.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 843d926b003ea692468c8cc5bea1f9f58dfa8c75
Author: Eric Dumazet <edumazet@google.com>
Date:   Tue Sep 8 01:20:23 2020 -0700

    ipv6: avoid lockdep issue in fib6_del()
    
    syzbot reported twice a lockdep issue in fib6_del() [1]
    which I think is caused by net->ipv6.fib6_null_entry
    having a NULL fib6_table pointer.
    
    fib6_del() already checks for fib6_null_entry special
    case, we only need to return earlier.
    
    Bug seems to occur very rarely, I have thus chosen
    a 'bug origin' that makes backports not too complex.
    
    [1]
    WARNING: suspicious RCU usage
    5.9.0-rc4-syzkaller #0 Not tainted
    -----------------------------
    net/ipv6/ip6_fib.c:1996 suspicious rcu_dereference_protected() usage!
    
    other info that might help us debug this:
    
    rcu_scheduler_active = 2, debug_locks = 1
    4 locks held by syz-executor.5/8095:
     #0: ffffffff8a7ea708 (rtnl_mutex){+.+.}-{3:3}, at: ppp_release+0x178/0x240 drivers/net/ppp/ppp_generic.c:401
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: spin_trylock_bh include/linux/spinlock.h:414 [inline]
     #1: ffff88804c422dd8 (&net->ipv6.fib6_gc_lock){+.-.}-{2:2}, at: fib6_run_gc+0x21b/0x2d0 net/ipv6/ip6_fib.c:2312
     #2: ffffffff89bd6a40 (rcu_read_lock){....}-{1:2}, at: __fib6_clean_all+0x0/0x290 net/ipv6/ip6_fib.c:2613
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: spin_lock_bh include/linux/spinlock.h:359 [inline]
     #3: ffff8880a82e6430 (&tb->tb6_lock){+.-.}-{2:2}, at: __fib6_clean_all+0x107/0x290 net/ipv6/ip6_fib.c:2245
    
    stack backtrace:
    CPU: 1 PID: 8095 Comm: syz-executor.5 Not tainted 5.9.0-rc4-syzkaller #0
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x198/0x1fd lib/dump_stack.c:118
     fib6_del+0x12b4/0x1630 net/ipv6/ip6_fib.c:1996
     fib6_clean_node+0x39b/0x570 net/ipv6/ip6_fib.c:2180
     fib6_walk_continue+0x4aa/0x8e0 net/ipv6/ip6_fib.c:2102
     fib6_walk+0x182/0x370 net/ipv6/ip6_fib.c:2150
     fib6_clean_tree+0xdb/0x120 net/ipv6/ip6_fib.c:2230
     __fib6_clean_all+0x120/0x290 net/ipv6/ip6_fib.c:2246
     fib6_clean_all net/ipv6/ip6_fib.c:2257 [inline]
     fib6_run_gc+0x113/0x2d0 net/ipv6/ip6_fib.c:2320
     ndisc_netdev_event+0x217/0x350 net/ipv6/ndisc.c:1805
     notifier_call_chain+0xb5/0x200 kernel/notifier.c:83
     call_netdevice_notifiers_info+0xb5/0x130 net/core/dev.c:2033
     call_netdevice_notifiers_extack net/core/dev.c:2045 [inline]
     call_netdevice_notifiers net/core/dev.c:2059 [inline]
     dev_close_many+0x30b/0x650 net/core/dev.c:1634
     rollback_registered_many+0x3a8/0x1210 net/core/dev.c:9261
     rollback_registered net/core/dev.c:9329 [inline]
     unregister_netdevice_queue+0x2dd/0x570 net/core/dev.c:10410
     unregister_netdevice include/linux/netdevice.h:2774 [inline]
     ppp_release+0x216/0x240 drivers/net/ppp/ppp_generic.c:403
     __fput+0x285/0x920 fs/file_table.c:281
     task_work_run+0xdd/0x190 kernel/task_work.c:141
     tracehook_notify_resume include/linux/tracehook.h:188 [inline]
     exit_to_user_mode_loop kernel/entry/common.c:163 [inline]
     exit_to_user_mode_prepare+0x1e1/0x200 kernel/entry/common.c:190
     syscall_exit_to_user_mode+0x7e/0x2e0 kernel/entry/common.c:265
     entry_SYSCALL_64_after_hwframe+0x44/0xa9
    
    Fixes: 421842edeaf6 ("net/ipv6: Add fib6_null_entry")
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: David Ahern <dsahern@gmail.com>
    Reviewed-by: David Ahern <dsahern@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 10b8d2696578858486629b21411422fd75f7d952
Author: Fred Oh <fred.oh@linux.intel.com>
Date:   Thu Jun 25 14:13:02 2020 -0500

    ASoC: Intel: Boards: cml_rt1011_rt5682: use statically define codec config
    
    [ Upstream commit 8a473c39ae54c27e694a131c34a739d0f8aa5300 ]
    
    When the cml_rt1011_rt5682_dailink[].codecs pointer is overridden by
    a quirk with a devm allocated structure and the probe is deferred,
    in the next probe we will see an use-after-free condition
    (verified with KASAN). This can be avoided by using statically allocated
    configurations - which simplifies the code quite a bit as well.
    
    KASAN issue fixed.
    [   23.301373] cml_rt1011_rt5682 cml_rt1011_rt5682: sof_rt1011_quirk = f
    [   23.301875] ==================================================================
    [   23.302018] BUG: KASAN: use-after-free in snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302178] Read of size 8 at addr ffff8881ec6acae0 by task kworker/0:2/105
    [   23.302320] CPU: 0 PID: 105 Comm: kworker/0:2 Not tainted 5.7.0-rc7-test+ #3
    [   23.302322] Hardware name: Google Helios/Helios, BIOS  01/21/2020
    [   23.302329] Workqueue: events deferred_probe_work_func
    [   23.302331] Call Trace:
    [   23.302339]  dump_stack+0x76/0xa0
    [   23.302345]  print_address_description.constprop.0.cold+0xd3/0x43e
    [   23.302351]  ? _raw_spin_lock_irqsave+0x7b/0xd0
    [   23.302355]  ? _raw_spin_trylock_bh+0xf0/0xf0
    [   23.302362]  ? snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302365]  __kasan_report.cold+0x37/0x86
    [   23.302371]  ? snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302375]  kasan_report+0x38/0x50
    [   23.302382]  snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302389]  platform_drv_probe+0x66/0xc0
    
    Fixes: 629ba12e9998 ("ASoC: Intel: boards: split woofer and tweeter support")
    Suggested-by: Ranjani Sridharan <ranjani.sridharan@linux.intel.com>
    Signed-off-by: Fred Oh <fred.oh@linux.intel.com>
    Signed-off-by: Pierre-Louis Bossart <pierre-louis.bossart@linux.intel.com>
    Reviewed-by: Ranjani Sridharan <ranjani.sridharan@linux.intel.com>
    Reviewed-by: Bard Liao <yung-chuan.liao@linux.intel.com>
    Link: https://lore.kernel.org/r/20200625191308.3322-12-pierre-louis.bossart@linux.intel.com
    Signed-off-by: Mark Brown <broonie@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 35fba0f0fd762a8b87d403ae3c723e0061c4aa25
Author: Tony Lindgren <tony@atomide.com>
Date:   Thu Jul 2 09:29:50 2020 -0700

    wlcore: Use spin_trylock in wlcore_irq() to see if we need to queue tx
    
    We currently have a collection of flags and locking between the
    threaded irq and tx work:
    
    - wl->flags bitops
    - wl->mutex
    - wl->wl_lock spinlock
    
    The bitops flags do not need a spinlock around them, and we only need
    the spinlock to see if we need to queue tx work or not. And wlcore_irq()
    holds the mutex.
    
    To simplify the locking, we can use spin_trylock and always queue tx
    work unless we know there's nothing to do.
    
    Let's also update the comment a bit while at it.
    
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20200702162951.45392-4-tony@atomide.com

commit f0325e38ab39c2e270770b72c79795772ac3b49e
Author: Tony Lindgren <tony@atomide.com>
Date:   Thu Jul 2 09:29:49 2020 -0700

    wlcore: Use spin_trylock in wlcore_irq_locked() for running the queue
    
    We currently have a collection of flags and locking between the
    threaded irq and tx work:
    
    - wl->flags bitops
    - wl->mutex
    - wl->wl_lock spinlock
    
    The bitops flags do not need a spinlock around them, and
    wlcore_irq() already holds the mutex calling wlcore_irq_locked().
    And we only need the spinlock to see if we need to run the queue
    or not.
    
    To simplify the locking, we can use spin_trylock and always run the
    tx queue unless we know there's nothing to do.
    
    Signed-off-by: Tony Lindgren <tony@atomide.com>
    Signed-off-by: Kalle Valo <kvalo@codeaurora.org>
    Link: https://lore.kernel.org/r/20200702162951.45392-3-tony@atomide.com

commit 8a473c39ae54c27e694a131c34a739d0f8aa5300
Author: Fred Oh <fred.oh@linux.intel.com>
Date:   Thu Jun 25 14:13:02 2020 -0500

    ASoC: Intel: Boards: cml_rt1011_rt5682: use statically define codec config
    
    When the cml_rt1011_rt5682_dailink[].codecs pointer is overridden by
    a quirk with a devm allocated structure and the probe is deferred,
    in the next probe we will see an use-after-free condition
    (verified with KASAN). This can be avoided by using statically allocated
    configurations - which simplifies the code quite a bit as well.
    
    KASAN issue fixed.
    [   23.301373] cml_rt1011_rt5682 cml_rt1011_rt5682: sof_rt1011_quirk = f
    [   23.301875] ==================================================================
    [   23.302018] BUG: KASAN: use-after-free in snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302178] Read of size 8 at addr ffff8881ec6acae0 by task kworker/0:2/105
    [   23.302320] CPU: 0 PID: 105 Comm: kworker/0:2 Not tainted 5.7.0-rc7-test+ #3
    [   23.302322] Hardware name: Google Helios/Helios, BIOS  01/21/2020
    [   23.302329] Workqueue: events deferred_probe_work_func
    [   23.302331] Call Trace:
    [   23.302339]  dump_stack+0x76/0xa0
    [   23.302345]  print_address_description.constprop.0.cold+0xd3/0x43e
    [   23.302351]  ? _raw_spin_lock_irqsave+0x7b/0xd0
    [   23.302355]  ? _raw_spin_trylock_bh+0xf0/0xf0
    [   23.302362]  ? snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302365]  __kasan_report.cold+0x37/0x86
    [   23.302371]  ? snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302375]  kasan_report+0x38/0x50
    [   23.302382]  snd_cml_rt1011_probe+0x23a/0x3d0 [snd_soc_cml_rt1011_rt5682]
    [   23.302389]  platform_drv_probe+0x66/0xc0
    
    Fixes: 629ba12e9998 ("ASoC: Intel: boards: split woofer and tweeter support")
    Suggested-by: Ranjani Sridharan <ranjani.sridharan@linux.intel.com>
    Signed-off-by: Fred Oh <fred.oh@linux.intel.com>
    Signed-off-by: Pierre-Louis Bossart <pierre-louis.bossart@linux.intel.com>
    Reviewed-by: Ranjani Sridharan <ranjani.sridharan@linux.intel.com>
    Reviewed-by: Bard Liao <yung-chuan.liao@linux.intel.com>
    Link: https://lore.kernel.org/r/20200625191308.3322-12-pierre-louis.bossart@linux.intel.com
    Signed-off-by: Mark Brown <broonie@kernel.org>

commit 9ced454807191e44ef093aeeee68194be9ce3a1a
Author: Jules Irenge <jbi.octave@gmail.com>
Date:   Mon Jan 20 22:42:15 2020 +0000

    rcu: Add missing annotation for rcu_nocb_bypass_lock()
    
    Sparse reports warning at rcu_nocb_bypass_lock()
    
    |warning: context imbalance in rcu_nocb_bypass_lock() - wrong count at exit
    
    To fix this, this commit adds an __acquires(&rdp->nocb_bypass_lock).
    Given that rcu_nocb_bypass_lock() does actually call raw_spin_lock()
    when raw_spin_trylock() fails, this not only fixes the warning but also
    improves on the readability of the code.
    
    Signed-off-by: Jules Irenge <jbi.octave@gmail.com>
    Signed-off-by: Paul E. McKenney <paulmck@kernel.org>

commit 81c0b3d724f419c0524f432c1ac22b9f518c2899
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Tue May 28 07:18:08 2019 -0700

    rcu/nocb: Avoid ->nocb_lock capture by corresponding CPU
    
    A given rcu_data structure's ->nocb_lock can be acquired very frequently
    by the corresponding CPU and occasionally by the corresponding no-CBs
    grace-period and callbacks kthreads.  In particular, these two kthreads
    will have frequent gaps between ->nocb_lock acquisitions that are roughly
    a grace period in duration.  This means that any excessive ->nocb_lock
    contention will be due to the CPU's acquisitions, and this in turn
    enables a very naive contention-avoidance strategy to be quite effective.
    
    This commit therefore modifies rcu_nocb_lock() to first
    attempt a raw_spin_trylock(), and to atomically increment a
    separate ->nocb_lock_contended across a raw_spin_lock().  This new
    ->nocb_lock_contended field is checked in __call_rcu_nocb_wake() when
    interrupts are enabled, with a spin-wait for contending acquisitions
    to complete, thus allowing the kthreads a chance to acquire the lock.
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.ibm.com>

commit 6cd34b10cd642c15a8e4b2ed5fc4815c12c41d52
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Aug 9 08:37:23 2019 +0100

    drm/i915/execlists: Backtrack along timeline
    
    After a preempt-to-busy, we may find an active request that is caught
    between execution states. Walk back along the timeline instead of the
    execution list to be safe.
    
    [  106.417541] i915 0000:00:02.0: Resetting rcs0 for preemption time out
    [  106.417659] ==================================================================
    [  106.418041] BUG: KASAN: slab-out-of-bounds in __execlists_reset+0x2f2/0x440 [i915]
    [  106.418123] Read of size 8 at addr ffff888703506b30 by task swapper/1/0
    [  106.418194]
    [  106.418267] CPU: 1 PID: 0 Comm: swapper/1 Tainted: G     U            5.3.0-rc3+ #5
    [  106.418344] Hardware name: Intel Corporation NUC7i5BNK/NUC7i5BNB, BIOS BNKBL357.86A.0052.2017.0918.1346 09/18/2017
    [  106.418434] Call Trace:
    [  106.418508]  <IRQ>
    [  106.418585]  dump_stack+0x5b/0x90
    [  106.418941]  ? __execlists_reset+0x2f2/0x440 [i915]
    [  106.419022]  print_address_description+0x67/0x32d
    [  106.419376]  ? __execlists_reset+0x2f2/0x440 [i915]
    [  106.419731]  ? __execlists_reset+0x2f2/0x440 [i915]
    [  106.419810]  __kasan_report.cold.6+0x1a/0x3c
    [  106.419888]  ? __trace_bprintk+0xc0/0xd0
    [  106.420239]  ? __execlists_reset+0x2f2/0x440 [i915]
    [  106.420318]  check_memory_region+0x144/0x1c0
    [  106.420671]  __execlists_reset+0x2f2/0x440 [i915]
    [  106.421029]  execlists_reset+0x3d/0x50 [i915]
    [  106.421387]  intel_engine_reset+0x203/0x3a0 [i915]
    [  106.421744]  ? igt_reset_nop+0x2b0/0x2b0 [i915]
    [  106.421825]  ? _raw_spin_trylock_bh+0xe0/0xe0
    [  106.421901]  ? rcu_core+0x1b9/0x6a0
    [  106.422251]  preempt_reset+0x9a/0xf0 [i915]
    [  106.422333]  tasklet_action_common.isra.15+0xc0/0x1e0
    [  106.422685]  ? execlists_submit_request+0x200/0x200 [i915]
    [  106.422764]  __do_softirq+0x106/0x3cf
    [  106.422840]  irq_exit+0xdc/0xf0
    [  106.422914]  smp_apic_timer_interrupt+0x81/0x1c0
    [  106.422988]  apic_timer_interrupt+0xf/0x20
    [  106.423059]  </IRQ>
    [  106.423144] RIP: 0010:cpuidle_enter_state+0xc3/0x620
    [  106.423222] Code: 24 0f 1f 44 00 00 31 ff e8 da 87 9c ff 80 7c 24 10 00 74 12 9c 58 f6 c4 02 0f 85 33 05 00 00 31 ff e8 c1 77 a3 ff fb 45 85 e4 <0f> 89 bf 02 00 00 48 8d 7d 10 e8 4e 45 b9 ff c7 45 10 00 00 00 00
    [  106.423311] RSP: 0018:ffff88881c30fda8 EFLAGS: 00000202 ORIG_RAX: ffffffffffffff13
    [  106.423390] RAX: 0000000000000000 RBX: ffffffff825b4c80 RCX: ffffffff810c8a00
    [  106.423465] RDX: dffffc0000000000 RSI: 0000000039f89620 RDI: ffff88881f6b00a8
    [  106.423540] RBP: ffff88881f6b5bf8 R08: 0000000000000002 R09: 000000000002ed80
    [  106.423616] R10: 0000003fdd956146 R11: ffff88881c2d1e47 R12: 0000000000000008
    [  106.423691] R13: 0000000000000008 R14: ffffffff825b4f80 R15: ffffffff825b4fc0
    [  106.423772]  ? sched_idle_set_state+0x20/0x30
    [  106.423851]  ? cpuidle_enter_state+0xa6/0x620
    [  106.423874]  ? tick_nohz_idle_stop_tick+0x1d1/0x3f0
    [  106.423896]  cpuidle_enter+0x37/0x60
    [  106.423919]  do_idle+0x246/0x280
    [  106.423941]  ? arch_cpu_idle_exit+0x30/0x30
    [  106.423964]  ? __wake_up_common+0x46/0x240
    [  106.423986]  cpu_startup_entry+0x14/0x20
    [  106.424009]  start_secondary+0x1b0/0x200
    [  106.424031]  ? set_cpu_sibling_map+0x990/0x990
    [  106.424054]  secondary_startup_64+0xa4/0xb0
    [  106.424075]
    [  106.424096] Allocated by task 626:
    [  106.424119]  save_stack+0x19/0x80
    [  106.424143]  __kasan_kmalloc.constprop.7+0xc1/0xd0
    [  106.424165]  kmem_cache_alloc+0xb2/0x1d0
    [  106.424277]  i915_sched_lookup_priolist+0x1ab/0x320 [i915]
    [  106.424385]  execlists_submit_request+0x73/0x200 [i915]
    [  106.424498]  submit_notify+0x59/0x60 [i915]
    [  106.424600]  __i915_sw_fence_complete+0x9b/0x330 [i915]
    [  106.424713]  __i915_request_commit+0x4bf/0x570 [i915]
    [  106.424818]  intel_engine_pulse+0x213/0x310 [i915]
    [  106.424925]  context_close+0x22f/0x470 [i915]
    [  106.425033]  i915_gem_context_destroy_ioctl+0x7b/0xa0 [i915]
    [  106.425058]  drm_ioctl_kernel+0x131/0x170
    [  106.425081]  drm_ioctl+0x2d9/0x4f1
    [  106.425104]  do_vfs_ioctl+0x115/0x890
    [  106.425126]  ksys_ioctl+0x35/0x70
    [  106.425147]  __x64_sys_ioctl+0x38/0x40
    [  106.425169]  do_syscall_64+0x66/0x220
    [  106.425191]  entry_SYSCALL_64_after_hwframe+0x44/0xa9
    [  106.425213]
    [  106.425234] Freed by task 0:
    [  106.425255] (stack is not available)
    [  106.425276]
    [  106.425297] The buggy address belongs to the object at ffff888703506a40
    [  106.425297]  which belongs to the cache i915_priolist of size 104
    [  106.425321] The buggy address is located 136 bytes to the right of
    [  106.425321]  104-byte region [ffff888703506a40, ffff888703506aa8)
    [  106.425345] The buggy address belongs to the page:
    [  106.425367] page:ffffea001c0d4180 refcount:1 mapcount:0 mapping:ffff88873e1cf740 index:0xffff888703506e40 compound_mapcount: 0
    [  106.425391] flags: 0x8000000000010200(slab|head)
    [  106.425415] raw: 8000000000010200 ffffea0020192b88 ffff8888174b5450 ffff88873e1cf740
    [  106.425439] raw: ffff888703506e40 000000000010000e 00000001ffffffff 0000000000000000
    [  106.425464] page dumped because: kasan: bad access detected
    [  106.425486]
    [  106.425506] Memory state around the buggy address:
    [  106.425528]  ffff888703506a00: fc fc fc fc fc fc fc fc 00 00 00 00 00 00 00 00
    [  106.425551]  ffff888703506a80: 00 00 00 00 00 fc fc fc fc fc fc fc fc fc fc fc
    [  106.425573] >ffff888703506b00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  106.425597]                                      ^
    [  106.425619]  ffff888703506b80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
    [  106.425642]  ffff888703506c00: fc fc fc fc fc fc fc fc 00 00 00 00 00 00 00 00
    [  106.425664] ==================================================================
    
    Fixes: 22b7a426bbe1 ("drm/i915/execlists: Preempt-to-busy")
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Reviewed-by: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Link: https://patchwork.freedesktop.org/patch/msgid/20190809073723.6593-1-chris@chris-wilson.co.uk

commit bce6f5221374ba451a337d0a3773e6eb99dad3e8
Author: Fabien Dessenne <fabien.dessenne@st.com>
Date:   Thu Mar 7 16:58:22 2019 +0100

    hwspinlock: document the hwspinlock 'raw' API
    
    Document the hwspin_lock_timeout_raw(), hwspin_trylock_raw() and
    hwspin_unlock_raw() API.
    
    Signed-off-by: Fabien Dessenne <fabien.dessenne@st.com>
    Signed-off-by: Bjorn Andersson <bjorn.andersson@linaro.org>

commit 6fe533378795f87bfa5075520742116f13d30ed3
Author: Felix Fietkau <nbd@nbd.name>
Date:   Thu Jan 31 22:38:28 2019 +0100

    mt76: mt76x02: remove irqsave/restore in locking for tx status fifo
    
    Use a separate lock and spin_trylock to avoid disabling interrupts.
    Should improve performance and latency
    
    Signed-off-by: Felix Fietkau <nbd@nbd.name>

commit e79b5482b190fbadda112d351d0f9bcefc7a1797
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Oct 25 19:10:36 2018 +0900

    panic: avoid deadlocks in re-entrant console drivers
    
    commit c7c3f05e341a9a2bd1a92993d4f996cfd6e7348e upstream.
    
    From printk()/serial console point of view panic() is special, because
    it may force CPU to re-enter printk() or/and serial console driver.
    Therefore, some of serial consoles drivers are re-entrant. E.g. 8250:
    
    serial8250_console_write()
    {
            if (port->sysrq)
                    locked = 0;
            else if (oops_in_progress)
                    locked = spin_trylock_irqsave(&port->lock, flags);
            else
                    spin_lock_irqsave(&port->lock, flags);
            ...
    }
    
    panic() does set oops_in_progress via bust_spinlocks(1), so in theory
    we should be able to re-enter serial console driver from panic():
    
            CPU0
            <NMI>
            uart_console_write()
            serial8250_console_write()              // if (oops_in_progress)
                                                    //    spin_trylock_irqsave()
            call_console_drivers()
            console_unlock()
            console_flush_on_panic()
            bust_spinlocks(1)                       // oops_in_progress++
            panic()
            <NMI/>
            spin_lock_irqsave(&port->lock, flags)   // spin_lock_irqsave()
            serial8250_console_write()
            call_console_drivers()
            console_unlock()
            printk()
            ...
    
    However, this does not happen and we deadlock in serial console on
    port->lock spinlock. And the problem is that console_flush_on_panic()
    called after bust_spinlocks(0):
    
    void panic(const char *fmt, ...)
    {
            bust_spinlocks(1);
            ...
            bust_spinlocks(0);
            console_flush_on_panic();
            ...
    }
    
    bust_spinlocks(0) decrements oops_in_progress, so oops_in_progress
    can go back to zero. Thus even re-entrant console drivers will simply
    spin on port->lock spinlock. Given that port->lock may already be
    locked either by a stopped CPU, or by the very same CPU we execute
    panic() on (for instance, NMI panic() on printing CPU) the system
    deadlocks and does not reboot.
    
    Fix this by removing bust_spinlocks(0), so oops_in_progress is always
    set in panic() now and, thus, re-entrant console drivers will trylock
    the port->lock instead of spinning on it forever, when we call them
    from console_flush_on_panic().
    
    Link: http://lkml.kernel.org/r/20181025101036.6823-1-sergey.senozhatsky@gmail.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Wang <wonderfly@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: linux-serial@vger.kernel.org
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit ef9ef4adb85c3d14ab838a886c153432046c6c02
Author: Li RongQing <lirongqing@baidu.com>
Date:   Wed Mar 6 14:46:27 2019 +0800

    connector: fix unsafe usage of ->real_parent
    
    [ Upstream commit 6d2b0f02f5a07a4bf02e4cbc90d7eaa85cac2986 ]
    
    proc_exit_connector() uses ->real_parent lockless. This is not
    safe that its parent can go away at any moment, so use RCU to
    protect it, and ensure that this task is not released.
    
    [  747.624551] ==================================================================
    [  747.632946] BUG: KASAN: use-after-free in proc_exit_connector+0x1f7/0x310
    [  747.640686] Read of size 4 at addr ffff88a0276988e0 by task sshd/2882
    [  747.648032]
    [  747.649804] CPU: 11 PID: 2882 Comm: sshd Tainted: G            E     4.19.26-rc2 #11
    [  747.658629] Hardware name: IBM x3550M4 -[7914OFV]-/00AM544, BIOS -[D7E142BUS-1.71]- 07/31/2014
    [  747.668419] Call Trace:
    [  747.671269]  dump_stack+0xf0/0x19b
    [  747.675186]  ? show_regs_print_info+0x5/0x5
    [  747.679988]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [  747.685302]  print_address_description+0x6a/0x270
    [  747.691162]  kasan_report+0x258/0x380
    [  747.695835]  ? proc_exit_connector+0x1f7/0x310
    [  747.701402]  proc_exit_connector+0x1f7/0x310
    [  747.706767]  ? proc_coredump_connector+0x2d0/0x2d0
    [  747.712715]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.718270]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.723820]  ? ___preempt_schedule+0x16/0x18
    [  747.729193]  ? ___preempt_schedule+0x16/0x18
    [  747.734574]  do_exit+0xa11/0x14f0
    [  747.738880]  ? mm_update_next_owner+0x590/0x590
    [  747.744525]  ? debug_show_all_locks+0x3c0/0x3c0
    [  747.761448]  ? ktime_get_coarse_real_ts64+0xeb/0x1c0
    [  747.767589]  ? lockdep_hardirqs_on+0x1a6/0x290
    [  747.773154]  ? check_chain_key+0x139/0x1f0
    [  747.778345]  ? check_flags.part.35+0x240/0x240
    [  747.783908]  ? __lock_acquire+0x2300/0x2300
    [  747.789171]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.795316]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.801457]  ? do_raw_spin_unlock+0x10f/0x1e0
    [  747.806914]  ? do_raw_spin_trylock+0x120/0x120
    [  747.812481]  ? preempt_count_sub+0x14/0xc0
    [  747.817645]  ? _raw_spin_unlock+0x2e/0x50
    [  747.822708]  ? __handle_mm_fault+0x12db/0x1fa0
    [  747.828367]  ? __pmd_alloc+0x2d0/0x2d0
    [  747.833143]  ? check_noncircular+0x50/0x50
    [  747.838309]  ? match_held_lock+0x7f/0x340
    [  747.843380]  ? check_noncircular+0x50/0x50
    [  747.848561]  ? handle_mm_fault+0x21a/0x5f0
    [  747.853730]  ? check_flags.part.35+0x240/0x240
    [  747.859290]  ? check_chain_key+0x139/0x1f0
    [  747.864474]  ? __do_page_fault+0x40f/0x760
    [  747.869655]  ? __audit_syscall_entry+0x4b/0x1f0
    [  747.875319]  ? syscall_trace_enter+0x1d5/0x7b0
    [  747.880877]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.887895]  ? trace_raw_output_sys_exit+0x80/0x80
    [  747.893860]  ? up_read+0x3b/0x90
    [  747.898142]  ? stop_critical_timings+0x260/0x260
    [  747.903909]  do_group_exit+0xe0/0x1c0
    [  747.908591]  ? __x64_sys_exit+0x30/0x30
    [  747.913460]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.920485]  ? tracer_hardirqs_on+0x270/0x270
    [  747.925956]  __x64_sys_exit_group+0x28/0x30
    [  747.931214]  do_syscall_64+0x117/0x400
    [  747.935988]  ? syscall_return_slowpath+0x2f0/0x2f0
    [  747.941931]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.947788]  ? trace_hardirqs_on_caller+0x1d0/0x1d0
    [  747.953838]  ? lockdep_sys_exit+0x16/0x8e
    [  747.958915]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.964784]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  747.971021] RIP: 0033:0x7f572f154c68
    [  747.975606] Code: Bad RIP value.
    [  747.979791] RSP: 002b:00007ffed2dfaa58 EFLAGS: 00000246 ORIG_RAX: 00000000000000e7
    [  747.989324] RAX: ffffffffffffffda RBX: 00007f572f431840 RCX: 00007f572f154c68
    [  747.997910] RDX: 0000000000000001 RSI: 000000000000003c RDI: 0000000000000001
    [  748.006495] RBP: 0000000000000001 R08: 00000000000000e7 R09: fffffffffffffee0
    [  748.015079] R10: 00007f572f4387e8 R11: 0000000000000246 R12: 00007f572f431840
    [  748.023664] R13: 000055a7f90f2c50 R14: 000055a7f96e2310 R15: 000055a7f96e2310
    [  748.032287]
    [  748.034509] Allocated by task 2300:
    [  748.038982]  kasan_kmalloc+0xa0/0xd0
    [  748.043562]  kmem_cache_alloc_node+0xf5/0x2e0
    [  748.049018]  copy_process+0x1781/0x4790
    [  748.053884]  _do_fork+0x166/0x9a0
    [  748.058163]  do_syscall_64+0x117/0x400
    [  748.062943]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.069180]
    [  748.071405] Freed by task 15395:
    [  748.075591]  __kasan_slab_free+0x130/0x180
    [  748.080752]  kmem_cache_free+0xc2/0x310
    [  748.085619]  free_task+0xea/0x130
    [  748.089901]  __put_task_struct+0x177/0x230
    [  748.095063]  finish_task_switch+0x51b/0x5d0
    [  748.100315]  __schedule+0x506/0xfa0
    [  748.104791]  schedule+0xca/0x260
    [  748.108978]  futex_wait_queue_me+0x27e/0x420
    [  748.114333]  futex_wait+0x251/0x550
    [  748.118814]  do_futex+0x75b/0xf80
    [  748.123097]  __x64_sys_futex+0x231/0x2a0
    [  748.128065]  do_syscall_64+0x117/0x400
    [  748.132835]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.139066]
    [  748.141289] The buggy address belongs to the object at ffff88a027698000
    [  748.141289]  which belongs to the cache task_struct of size 12160
    [  748.156589] The buggy address is located 2272 bytes inside of
    [  748.156589]  12160-byte region [ffff88a027698000, ffff88a02769af80)
    [  748.171114] The buggy address belongs to the page:
    [  748.177055] page:ffffea00809da600 count:1 mapcount:0 mapping:ffff888107d01e00 index:0x0 compound_mapcount: 0
    [  748.189136] flags: 0x57ffffc0008100(slab|head)
    [  748.194688] raw: 0057ffffc0008100 ffffea00809a3200 0000000300000003 ffff888107d01e00
    [  748.204424] raw: 0000000000000000 0000000000020002 00000001ffffffff 0000000000000000
    [  748.214146] page dumped because: kasan: bad access detected
    [  748.220976]
    [  748.223197] Memory state around the buggy address:
    [  748.229128]  ffff88a027698780: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.238271]  ffff88a027698800: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.247414] >ffff88a027698880: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.256564]                                                        ^
    [  748.264267]  ffff88a027698900: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.273493]  ffff88a027698980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.282630] ==================================================================
    
    Fixes: b086ff87251b4a4 ("connector: add parent pid and tgid to coredump and exit events")
    Signed-off-by: Zhang Yu <zhangyu31@baidu.com>
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Acked-by: Evgeniy Polyakov <zbr@ioremap.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28d1ecc9f529d995282d95b8b16785227ed87537
Author: Li RongQing <lirongqing@baidu.com>
Date:   Wed Mar 6 14:46:27 2019 +0800

    connector: fix unsafe usage of ->real_parent
    
    [ Upstream commit 6d2b0f02f5a07a4bf02e4cbc90d7eaa85cac2986 ]
    
    proc_exit_connector() uses ->real_parent lockless. This is not
    safe that its parent can go away at any moment, so use RCU to
    protect it, and ensure that this task is not released.
    
    [  747.624551] ==================================================================
    [  747.632946] BUG: KASAN: use-after-free in proc_exit_connector+0x1f7/0x310
    [  747.640686] Read of size 4 at addr ffff88a0276988e0 by task sshd/2882
    [  747.648032]
    [  747.649804] CPU: 11 PID: 2882 Comm: sshd Tainted: G            E     4.19.26-rc2 #11
    [  747.658629] Hardware name: IBM x3550M4 -[7914OFV]-/00AM544, BIOS -[D7E142BUS-1.71]- 07/31/2014
    [  747.668419] Call Trace:
    [  747.671269]  dump_stack+0xf0/0x19b
    [  747.675186]  ? show_regs_print_info+0x5/0x5
    [  747.679988]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [  747.685302]  print_address_description+0x6a/0x270
    [  747.691162]  kasan_report+0x258/0x380
    [  747.695835]  ? proc_exit_connector+0x1f7/0x310
    [  747.701402]  proc_exit_connector+0x1f7/0x310
    [  747.706767]  ? proc_coredump_connector+0x2d0/0x2d0
    [  747.712715]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.718270]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.723820]  ? ___preempt_schedule+0x16/0x18
    [  747.729193]  ? ___preempt_schedule+0x16/0x18
    [  747.734574]  do_exit+0xa11/0x14f0
    [  747.738880]  ? mm_update_next_owner+0x590/0x590
    [  747.744525]  ? debug_show_all_locks+0x3c0/0x3c0
    [  747.761448]  ? ktime_get_coarse_real_ts64+0xeb/0x1c0
    [  747.767589]  ? lockdep_hardirqs_on+0x1a6/0x290
    [  747.773154]  ? check_chain_key+0x139/0x1f0
    [  747.778345]  ? check_flags.part.35+0x240/0x240
    [  747.783908]  ? __lock_acquire+0x2300/0x2300
    [  747.789171]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.795316]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.801457]  ? do_raw_spin_unlock+0x10f/0x1e0
    [  747.806914]  ? do_raw_spin_trylock+0x120/0x120
    [  747.812481]  ? preempt_count_sub+0x14/0xc0
    [  747.817645]  ? _raw_spin_unlock+0x2e/0x50
    [  747.822708]  ? __handle_mm_fault+0x12db/0x1fa0
    [  747.828367]  ? __pmd_alloc+0x2d0/0x2d0
    [  747.833143]  ? check_noncircular+0x50/0x50
    [  747.838309]  ? match_held_lock+0x7f/0x340
    [  747.843380]  ? check_noncircular+0x50/0x50
    [  747.848561]  ? handle_mm_fault+0x21a/0x5f0
    [  747.853730]  ? check_flags.part.35+0x240/0x240
    [  747.859290]  ? check_chain_key+0x139/0x1f0
    [  747.864474]  ? __do_page_fault+0x40f/0x760
    [  747.869655]  ? __audit_syscall_entry+0x4b/0x1f0
    [  747.875319]  ? syscall_trace_enter+0x1d5/0x7b0
    [  747.880877]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.887895]  ? trace_raw_output_sys_exit+0x80/0x80
    [  747.893860]  ? up_read+0x3b/0x90
    [  747.898142]  ? stop_critical_timings+0x260/0x260
    [  747.903909]  do_group_exit+0xe0/0x1c0
    [  747.908591]  ? __x64_sys_exit+0x30/0x30
    [  747.913460]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.920485]  ? tracer_hardirqs_on+0x270/0x270
    [  747.925956]  __x64_sys_exit_group+0x28/0x30
    [  747.931214]  do_syscall_64+0x117/0x400
    [  747.935988]  ? syscall_return_slowpath+0x2f0/0x2f0
    [  747.941931]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.947788]  ? trace_hardirqs_on_caller+0x1d0/0x1d0
    [  747.953838]  ? lockdep_sys_exit+0x16/0x8e
    [  747.958915]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.964784]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  747.971021] RIP: 0033:0x7f572f154c68
    [  747.975606] Code: Bad RIP value.
    [  747.979791] RSP: 002b:00007ffed2dfaa58 EFLAGS: 00000246 ORIG_RAX: 00000000000000e7
    [  747.989324] RAX: ffffffffffffffda RBX: 00007f572f431840 RCX: 00007f572f154c68
    [  747.997910] RDX: 0000000000000001 RSI: 000000000000003c RDI: 0000000000000001
    [  748.006495] RBP: 0000000000000001 R08: 00000000000000e7 R09: fffffffffffffee0
    [  748.015079] R10: 00007f572f4387e8 R11: 0000000000000246 R12: 00007f572f431840
    [  748.023664] R13: 000055a7f90f2c50 R14: 000055a7f96e2310 R15: 000055a7f96e2310
    [  748.032287]
    [  748.034509] Allocated by task 2300:
    [  748.038982]  kasan_kmalloc+0xa0/0xd0
    [  748.043562]  kmem_cache_alloc_node+0xf5/0x2e0
    [  748.049018]  copy_process+0x1781/0x4790
    [  748.053884]  _do_fork+0x166/0x9a0
    [  748.058163]  do_syscall_64+0x117/0x400
    [  748.062943]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.069180]
    [  748.071405] Freed by task 15395:
    [  748.075591]  __kasan_slab_free+0x130/0x180
    [  748.080752]  kmem_cache_free+0xc2/0x310
    [  748.085619]  free_task+0xea/0x130
    [  748.089901]  __put_task_struct+0x177/0x230
    [  748.095063]  finish_task_switch+0x51b/0x5d0
    [  748.100315]  __schedule+0x506/0xfa0
    [  748.104791]  schedule+0xca/0x260
    [  748.108978]  futex_wait_queue_me+0x27e/0x420
    [  748.114333]  futex_wait+0x251/0x550
    [  748.118814]  do_futex+0x75b/0xf80
    [  748.123097]  __x64_sys_futex+0x231/0x2a0
    [  748.128065]  do_syscall_64+0x117/0x400
    [  748.132835]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.139066]
    [  748.141289] The buggy address belongs to the object at ffff88a027698000
    [  748.141289]  which belongs to the cache task_struct of size 12160
    [  748.156589] The buggy address is located 2272 bytes inside of
    [  748.156589]  12160-byte region [ffff88a027698000, ffff88a02769af80)
    [  748.171114] The buggy address belongs to the page:
    [  748.177055] page:ffffea00809da600 count:1 mapcount:0 mapping:ffff888107d01e00 index:0x0 compound_mapcount: 0
    [  748.189136] flags: 0x57ffffc0008100(slab|head)
    [  748.194688] raw: 0057ffffc0008100 ffffea00809a3200 0000000300000003 ffff888107d01e00
    [  748.204424] raw: 0000000000000000 0000000000020002 00000001ffffffff 0000000000000000
    [  748.214146] page dumped because: kasan: bad access detected
    [  748.220976]
    [  748.223197] Memory state around the buggy address:
    [  748.229128]  ffff88a027698780: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.238271]  ffff88a027698800: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.247414] >ffff88a027698880: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.256564]                                                        ^
    [  748.264267]  ffff88a027698900: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.273493]  ffff88a027698980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.282630] ==================================================================
    
    Fixes: b086ff87251b4a4 ("connector: add parent pid and tgid to coredump and exit events")
    Signed-off-by: Zhang Yu <zhangyu31@baidu.com>
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Acked-by: Evgeniy Polyakov <zbr@ioremap.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c4b5717a016849b4eb437013e662f3546a0ed163
Author: Li RongQing <lirongqing@baidu.com>
Date:   Wed Mar 6 14:46:27 2019 +0800

    connector: fix unsafe usage of ->real_parent
    
    [ Upstream commit 6d2b0f02f5a07a4bf02e4cbc90d7eaa85cac2986 ]
    
    proc_exit_connector() uses ->real_parent lockless. This is not
    safe that its parent can go away at any moment, so use RCU to
    protect it, and ensure that this task is not released.
    
    [  747.624551] ==================================================================
    [  747.632946] BUG: KASAN: use-after-free in proc_exit_connector+0x1f7/0x310
    [  747.640686] Read of size 4 at addr ffff88a0276988e0 by task sshd/2882
    [  747.648032]
    [  747.649804] CPU: 11 PID: 2882 Comm: sshd Tainted: G            E     4.19.26-rc2 #11
    [  747.658629] Hardware name: IBM x3550M4 -[7914OFV]-/00AM544, BIOS -[D7E142BUS-1.71]- 07/31/2014
    [  747.668419] Call Trace:
    [  747.671269]  dump_stack+0xf0/0x19b
    [  747.675186]  ? show_regs_print_info+0x5/0x5
    [  747.679988]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [  747.685302]  print_address_description+0x6a/0x270
    [  747.691162]  kasan_report+0x258/0x380
    [  747.695835]  ? proc_exit_connector+0x1f7/0x310
    [  747.701402]  proc_exit_connector+0x1f7/0x310
    [  747.706767]  ? proc_coredump_connector+0x2d0/0x2d0
    [  747.712715]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.718270]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.723820]  ? ___preempt_schedule+0x16/0x18
    [  747.729193]  ? ___preempt_schedule+0x16/0x18
    [  747.734574]  do_exit+0xa11/0x14f0
    [  747.738880]  ? mm_update_next_owner+0x590/0x590
    [  747.744525]  ? debug_show_all_locks+0x3c0/0x3c0
    [  747.761448]  ? ktime_get_coarse_real_ts64+0xeb/0x1c0
    [  747.767589]  ? lockdep_hardirqs_on+0x1a6/0x290
    [  747.773154]  ? check_chain_key+0x139/0x1f0
    [  747.778345]  ? check_flags.part.35+0x240/0x240
    [  747.783908]  ? __lock_acquire+0x2300/0x2300
    [  747.789171]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.795316]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.801457]  ? do_raw_spin_unlock+0x10f/0x1e0
    [  747.806914]  ? do_raw_spin_trylock+0x120/0x120
    [  747.812481]  ? preempt_count_sub+0x14/0xc0
    [  747.817645]  ? _raw_spin_unlock+0x2e/0x50
    [  747.822708]  ? __handle_mm_fault+0x12db/0x1fa0
    [  747.828367]  ? __pmd_alloc+0x2d0/0x2d0
    [  747.833143]  ? check_noncircular+0x50/0x50
    [  747.838309]  ? match_held_lock+0x7f/0x340
    [  747.843380]  ? check_noncircular+0x50/0x50
    [  747.848561]  ? handle_mm_fault+0x21a/0x5f0
    [  747.853730]  ? check_flags.part.35+0x240/0x240
    [  747.859290]  ? check_chain_key+0x139/0x1f0
    [  747.864474]  ? __do_page_fault+0x40f/0x760
    [  747.869655]  ? __audit_syscall_entry+0x4b/0x1f0
    [  747.875319]  ? syscall_trace_enter+0x1d5/0x7b0
    [  747.880877]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.887895]  ? trace_raw_output_sys_exit+0x80/0x80
    [  747.893860]  ? up_read+0x3b/0x90
    [  747.898142]  ? stop_critical_timings+0x260/0x260
    [  747.903909]  do_group_exit+0xe0/0x1c0
    [  747.908591]  ? __x64_sys_exit+0x30/0x30
    [  747.913460]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.920485]  ? tracer_hardirqs_on+0x270/0x270
    [  747.925956]  __x64_sys_exit_group+0x28/0x30
    [  747.931214]  do_syscall_64+0x117/0x400
    [  747.935988]  ? syscall_return_slowpath+0x2f0/0x2f0
    [  747.941931]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.947788]  ? trace_hardirqs_on_caller+0x1d0/0x1d0
    [  747.953838]  ? lockdep_sys_exit+0x16/0x8e
    [  747.958915]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.964784]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  747.971021] RIP: 0033:0x7f572f154c68
    [  747.975606] Code: Bad RIP value.
    [  747.979791] RSP: 002b:00007ffed2dfaa58 EFLAGS: 00000246 ORIG_RAX: 00000000000000e7
    [  747.989324] RAX: ffffffffffffffda RBX: 00007f572f431840 RCX: 00007f572f154c68
    [  747.997910] RDX: 0000000000000001 RSI: 000000000000003c RDI: 0000000000000001
    [  748.006495] RBP: 0000000000000001 R08: 00000000000000e7 R09: fffffffffffffee0
    [  748.015079] R10: 00007f572f4387e8 R11: 0000000000000246 R12: 00007f572f431840
    [  748.023664] R13: 000055a7f90f2c50 R14: 000055a7f96e2310 R15: 000055a7f96e2310
    [  748.032287]
    [  748.034509] Allocated by task 2300:
    [  748.038982]  kasan_kmalloc+0xa0/0xd0
    [  748.043562]  kmem_cache_alloc_node+0xf5/0x2e0
    [  748.049018]  copy_process+0x1781/0x4790
    [  748.053884]  _do_fork+0x166/0x9a0
    [  748.058163]  do_syscall_64+0x117/0x400
    [  748.062943]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.069180]
    [  748.071405] Freed by task 15395:
    [  748.075591]  __kasan_slab_free+0x130/0x180
    [  748.080752]  kmem_cache_free+0xc2/0x310
    [  748.085619]  free_task+0xea/0x130
    [  748.089901]  __put_task_struct+0x177/0x230
    [  748.095063]  finish_task_switch+0x51b/0x5d0
    [  748.100315]  __schedule+0x506/0xfa0
    [  748.104791]  schedule+0xca/0x260
    [  748.108978]  futex_wait_queue_me+0x27e/0x420
    [  748.114333]  futex_wait+0x251/0x550
    [  748.118814]  do_futex+0x75b/0xf80
    [  748.123097]  __x64_sys_futex+0x231/0x2a0
    [  748.128065]  do_syscall_64+0x117/0x400
    [  748.132835]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.139066]
    [  748.141289] The buggy address belongs to the object at ffff88a027698000
    [  748.141289]  which belongs to the cache task_struct of size 12160
    [  748.156589] The buggy address is located 2272 bytes inside of
    [  748.156589]  12160-byte region [ffff88a027698000, ffff88a02769af80)
    [  748.171114] The buggy address belongs to the page:
    [  748.177055] page:ffffea00809da600 count:1 mapcount:0 mapping:ffff888107d01e00 index:0x0 compound_mapcount: 0
    [  748.189136] flags: 0x57ffffc0008100(slab|head)
    [  748.194688] raw: 0057ffffc0008100 ffffea00809a3200 0000000300000003 ffff888107d01e00
    [  748.204424] raw: 0000000000000000 0000000000020002 00000001ffffffff 0000000000000000
    [  748.214146] page dumped because: kasan: bad access detected
    [  748.220976]
    [  748.223197] Memory state around the buggy address:
    [  748.229128]  ffff88a027698780: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.238271]  ffff88a027698800: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.247414] >ffff88a027698880: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.256564]                                                        ^
    [  748.264267]  ffff88a027698900: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.273493]  ffff88a027698980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.282630] ==================================================================
    
    Fixes: b086ff87251b4a4 ("connector: add parent pid and tgid to coredump and exit events")
    Signed-off-by: Zhang Yu <zhangyu31@baidu.com>
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Acked-by: Evgeniy Polyakov <zbr@ioremap.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f5e66cdb51fd352d7091cb2516b24734e524cb33
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Feb 8 16:59:49 2019 -0800

    aio: Fix locking in aio_poll()
    
    commit d3d6a18d7d351cbcc9b33dbedf710e65f8ce1595 upstream.
    
    wake_up_locked() may but does not have to be called with interrupts
    disabled. Since the fuse filesystem calls wake_up_locked() without
    disabling interrupts aio_poll_wake() may be called with interrupts
    enabled. Since the kioctx.ctx_lock may be acquired from IRQ context,
    all code that acquires that lock from thread context must disable
    interrupts. Hence change the spin_trylock() call in aio_poll_wake()
    into a spin_trylock_irqsave() call. This patch fixes the following
    lockdep complaint:
    
    =====================================================
    WARNING: SOFTIRQ-safe -> SOFTIRQ-unsafe lock order detected
    5.0.0-rc4-next-20190131 #23 Not tainted
    -----------------------------------------------------
    syz-executor2/13779 [HC0[0]:SC0[0]:HE0:SE1] is trying to acquire:
    0000000098ac1230 (&fiq->waitq){+.+.}, at: spin_lock include/linux/spinlock.h:329 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: aio_poll fs/aio.c:1772 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: __io_submit_one fs/aio.c:1875 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
    
    and this task is already holding:
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    which would create a new lock dependency:
     (&(&ctx->ctx_lock)->rlock){..-.} -> (&fiq->waitq){+.+.}
    
    but this new dependency connects a SOFTIRQ-irq-safe lock:
     (&(&ctx->ctx_lock)->rlock){..-.}
    
    ... which became SOFTIRQ-irq-safe at:
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
      _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
      spin_lock_irq include/linux/spinlock.h:354 [inline]
      free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
      percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
      percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
      percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
      percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
      __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
      rcu_do_batch kernel/rcu/tree.c:2486 [inline]
      invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
      rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
      __do_softirq+0x266/0x95a kernel/softirq.c:292
      run_ksoftirqd kernel/softirq.c:654 [inline]
      run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
      smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
      kthread+0x357/0x430 kernel/kthread.c:247
      ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
    
    to a SOFTIRQ-irq-unsafe lock:
     (&fiq->waitq){+.+.}
    
    ... which became SOFTIRQ-irq-unsafe at:
    ...
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
      _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
      spin_lock include/linux/spinlock.h:329 [inline]
      flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
      fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
      fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
      fuse_send_init fs/fuse/inode.c:989 [inline]
      fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
      mount_nodev+0x68/0x110 fs/super.c:1392
      fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
      legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
      vfs_get_tree+0x123/0x450 fs/super.c:1481
      do_new_mount fs/namespace.c:2610 [inline]
      do_mount+0x1436/0x2c40 fs/namespace.c:2932
      ksys_mount+0xdb/0x150 fs/namespace.c:3148
      __do_sys_mount fs/namespace.c:3162 [inline]
      __se_sys_mount fs/namespace.c:3159 [inline]
      __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
      do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    other info that might help us debug this:
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&fiq->waitq);
                                   local_irq_disable();
                                   lock(&(&ctx->ctx_lock)->rlock);
                                   lock(&fiq->waitq);
      <Interrupt>
        lock(&(&ctx->ctx_lock)->rlock);
    
     *** DEADLOCK ***
    
    1 lock held by syz-executor2/13779:
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    
    the dependencies between SOFTIRQ-irq-safe lock and the holding lock:
    -> (&(&ctx->ctx_lock)->rlock){..-.} {
       IN-SOFTIRQ-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                        _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                        spin_lock_irq include/linux/spinlock.h:354 [inline]
                        free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
                        percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
                        percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
                        percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
                        percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
                        __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
                        rcu_do_batch kernel/rcu/tree.c:2486 [inline]
                        invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
                        rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
                        __do_softirq+0x266/0x95a kernel/softirq.c:292
                        run_ksoftirqd kernel/softirq.c:654 [inline]
                        run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
                        smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
                        kthread+0x357/0x430 kernel/kthread.c:247
                        ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                       _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                       spin_lock_irq include/linux/spinlock.h:354 [inline]
                       __do_sys_io_cancel fs/aio.c:2052 [inline]
                       __se_sys_io_cancel fs/aio.c:2035 [inline]
                       __x64_sys_io_cancel+0xd5/0x5a0 fs/aio.c:2035
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a574140>] __key.52370+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    the dependencies between the lock to be acquired
     and SOFTIRQ-irq-unsafe lock:
    -> (&fiq->waitq){+.+.} {
       HARDIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       SOFTIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                       spin_lock include/linux/spinlock.h:329 [inline]
                       flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                       fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                       fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                       fuse_send_init fs/fuse/inode.c:989 [inline]
                       fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                       mount_nodev+0x68/0x110 fs/super.c:1392
                       fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                       legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                       vfs_get_tree+0x123/0x450 fs/super.c:1481
                       do_new_mount fs/namespace.c:2610 [inline]
                       do_mount+0x1436/0x2c40 fs/namespace.c:2932
                       ksys_mount+0xdb/0x150 fs/namespace.c:3148
                       __do_sys_mount fs/namespace.c:3162 [inline]
                       __se_sys_mount fs/namespace.c:3159 [inline]
                       __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a60dec0>] __key.43450+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    stack backtrace:
    CPU: 0 PID: 13779 Comm: syz-executor2 Not tainted 5.0.0-rc4-next-20190131 #23
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_bad_irq_dependency kernel/locking/lockdep.c:1573 [inline]
     check_usage.cold+0x60f/0x940 kernel/locking/lockdep.c:1605
     check_irq_usage kernel/locking/lockdep.c:1650 [inline]
     check_prev_add_irq kernel/locking/lockdep_states.h:8 [inline]
     check_prev_add kernel/locking/lockdep.c:1860 [inline]
     check_prevs_add kernel/locking/lockdep.c:1968 [inline]
     validate_chain kernel/locking/lockdep.c:2339 [inline]
     __lock_acquire+0x1f12/0x4790 kernel/locking/lockdep.c:3320
     lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
     spin_lock include/linux/spinlock.h:329 [inline]
     aio_poll fs/aio.c:1772 [inline]
     __io_submit_one fs/aio.c:1875 [inline]
     io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
     __do_sys_io_submit fs/aio.c:1953 [inline]
     __se_sys_io_submit fs/aio.c:1923 [inline]
     __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
     do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Avi Kivity <avi@scylladb.com>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: <stable@vger.kernel.org>
    Fixes: e8693bcfa0b4 ("aio: allow direct aio poll comletions for keyed wakeups") # v4.19
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    [ bvanassche: added a comment ]
    Reluctantly-Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f8250934cf1c5289aa81bcbcfe110097471f804b
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Feb 8 16:59:49 2019 -0800

    aio: Fix locking in aio_poll()
    
    commit d3d6a18d7d351cbcc9b33dbedf710e65f8ce1595 upstream.
    
    wake_up_locked() may but does not have to be called with interrupts
    disabled. Since the fuse filesystem calls wake_up_locked() without
    disabling interrupts aio_poll_wake() may be called with interrupts
    enabled. Since the kioctx.ctx_lock may be acquired from IRQ context,
    all code that acquires that lock from thread context must disable
    interrupts. Hence change the spin_trylock() call in aio_poll_wake()
    into a spin_trylock_irqsave() call. This patch fixes the following
    lockdep complaint:
    
    =====================================================
    WARNING: SOFTIRQ-safe -> SOFTIRQ-unsafe lock order detected
    5.0.0-rc4-next-20190131 #23 Not tainted
    -----------------------------------------------------
    syz-executor2/13779 [HC0[0]:SC0[0]:HE0:SE1] is trying to acquire:
    0000000098ac1230 (&fiq->waitq){+.+.}, at: spin_lock include/linux/spinlock.h:329 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: aio_poll fs/aio.c:1772 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: __io_submit_one fs/aio.c:1875 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
    
    and this task is already holding:
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    which would create a new lock dependency:
     (&(&ctx->ctx_lock)->rlock){..-.} -> (&fiq->waitq){+.+.}
    
    but this new dependency connects a SOFTIRQ-irq-safe lock:
     (&(&ctx->ctx_lock)->rlock){..-.}
    
    ... which became SOFTIRQ-irq-safe at:
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
      _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
      spin_lock_irq include/linux/spinlock.h:354 [inline]
      free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
      percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
      percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
      percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
      percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
      __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
      rcu_do_batch kernel/rcu/tree.c:2486 [inline]
      invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
      rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
      __do_softirq+0x266/0x95a kernel/softirq.c:292
      run_ksoftirqd kernel/softirq.c:654 [inline]
      run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
      smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
      kthread+0x357/0x430 kernel/kthread.c:247
      ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
    
    to a SOFTIRQ-irq-unsafe lock:
     (&fiq->waitq){+.+.}
    
    ... which became SOFTIRQ-irq-unsafe at:
    ...
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
      _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
      spin_lock include/linux/spinlock.h:329 [inline]
      flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
      fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
      fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
      fuse_send_init fs/fuse/inode.c:989 [inline]
      fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
      mount_nodev+0x68/0x110 fs/super.c:1392
      fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
      legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
      vfs_get_tree+0x123/0x450 fs/super.c:1481
      do_new_mount fs/namespace.c:2610 [inline]
      do_mount+0x1436/0x2c40 fs/namespace.c:2932
      ksys_mount+0xdb/0x150 fs/namespace.c:3148
      __do_sys_mount fs/namespace.c:3162 [inline]
      __se_sys_mount fs/namespace.c:3159 [inline]
      __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
      do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    other info that might help us debug this:
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&fiq->waitq);
                                   local_irq_disable();
                                   lock(&(&ctx->ctx_lock)->rlock);
                                   lock(&fiq->waitq);
      <Interrupt>
        lock(&(&ctx->ctx_lock)->rlock);
    
     *** DEADLOCK ***
    
    1 lock held by syz-executor2/13779:
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    
    the dependencies between SOFTIRQ-irq-safe lock and the holding lock:
    -> (&(&ctx->ctx_lock)->rlock){..-.} {
       IN-SOFTIRQ-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                        _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                        spin_lock_irq include/linux/spinlock.h:354 [inline]
                        free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
                        percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
                        percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
                        percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
                        percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
                        __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
                        rcu_do_batch kernel/rcu/tree.c:2486 [inline]
                        invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
                        rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
                        __do_softirq+0x266/0x95a kernel/softirq.c:292
                        run_ksoftirqd kernel/softirq.c:654 [inline]
                        run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
                        smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
                        kthread+0x357/0x430 kernel/kthread.c:247
                        ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                       _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                       spin_lock_irq include/linux/spinlock.h:354 [inline]
                       __do_sys_io_cancel fs/aio.c:2052 [inline]
                       __se_sys_io_cancel fs/aio.c:2035 [inline]
                       __x64_sys_io_cancel+0xd5/0x5a0 fs/aio.c:2035
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a574140>] __key.52370+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    the dependencies between the lock to be acquired
     and SOFTIRQ-irq-unsafe lock:
    -> (&fiq->waitq){+.+.} {
       HARDIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       SOFTIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                       spin_lock include/linux/spinlock.h:329 [inline]
                       flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                       fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                       fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                       fuse_send_init fs/fuse/inode.c:989 [inline]
                       fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                       mount_nodev+0x68/0x110 fs/super.c:1392
                       fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                       legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                       vfs_get_tree+0x123/0x450 fs/super.c:1481
                       do_new_mount fs/namespace.c:2610 [inline]
                       do_mount+0x1436/0x2c40 fs/namespace.c:2932
                       ksys_mount+0xdb/0x150 fs/namespace.c:3148
                       __do_sys_mount fs/namespace.c:3162 [inline]
                       __se_sys_mount fs/namespace.c:3159 [inline]
                       __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a60dec0>] __key.43450+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    stack backtrace:
    CPU: 0 PID: 13779 Comm: syz-executor2 Not tainted 5.0.0-rc4-next-20190131 #23
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_bad_irq_dependency kernel/locking/lockdep.c:1573 [inline]
     check_usage.cold+0x60f/0x940 kernel/locking/lockdep.c:1605
     check_irq_usage kernel/locking/lockdep.c:1650 [inline]
     check_prev_add_irq kernel/locking/lockdep_states.h:8 [inline]
     check_prev_add kernel/locking/lockdep.c:1860 [inline]
     check_prevs_add kernel/locking/lockdep.c:1968 [inline]
     validate_chain kernel/locking/lockdep.c:2339 [inline]
     __lock_acquire+0x1f12/0x4790 kernel/locking/lockdep.c:3320
     lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
     spin_lock include/linux/spinlock.h:329 [inline]
     aio_poll fs/aio.c:1772 [inline]
     __io_submit_one fs/aio.c:1875 [inline]
     io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
     __do_sys_io_submit fs/aio.c:1953 [inline]
     __se_sys_io_submit fs/aio.c:1923 [inline]
     __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
     do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Avi Kivity <avi@scylladb.com>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: <stable@vger.kernel.org>
    Fixes: e8693bcfa0b4 ("aio: allow direct aio poll comletions for keyed wakeups") # v4.19
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    [ bvanassche: added a comment ]
    Reluctantly-Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9255e2479efb61dd68a5f6bed598631ece21295
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Feb 8 16:59:49 2019 -0800

    aio: Fix locking in aio_poll()
    
    commit d3d6a18d7d351cbcc9b33dbedf710e65f8ce1595 upstream.
    
    wake_up_locked() may but does not have to be called with interrupts
    disabled. Since the fuse filesystem calls wake_up_locked() without
    disabling interrupts aio_poll_wake() may be called with interrupts
    enabled. Since the kioctx.ctx_lock may be acquired from IRQ context,
    all code that acquires that lock from thread context must disable
    interrupts. Hence change the spin_trylock() call in aio_poll_wake()
    into a spin_trylock_irqsave() call. This patch fixes the following
    lockdep complaint:
    
    =====================================================
    WARNING: SOFTIRQ-safe -> SOFTIRQ-unsafe lock order detected
    5.0.0-rc4-next-20190131 #23 Not tainted
    -----------------------------------------------------
    syz-executor2/13779 [HC0[0]:SC0[0]:HE0:SE1] is trying to acquire:
    0000000098ac1230 (&fiq->waitq){+.+.}, at: spin_lock include/linux/spinlock.h:329 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: aio_poll fs/aio.c:1772 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: __io_submit_one fs/aio.c:1875 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
    
    and this task is already holding:
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    which would create a new lock dependency:
     (&(&ctx->ctx_lock)->rlock){..-.} -> (&fiq->waitq){+.+.}
    
    but this new dependency connects a SOFTIRQ-irq-safe lock:
     (&(&ctx->ctx_lock)->rlock){..-.}
    
    ... which became SOFTIRQ-irq-safe at:
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
      _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
      spin_lock_irq include/linux/spinlock.h:354 [inline]
      free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
      percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
      percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
      percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
      percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
      __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
      rcu_do_batch kernel/rcu/tree.c:2486 [inline]
      invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
      rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
      __do_softirq+0x266/0x95a kernel/softirq.c:292
      run_ksoftirqd kernel/softirq.c:654 [inline]
      run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
      smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
      kthread+0x357/0x430 kernel/kthread.c:247
      ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
    
    to a SOFTIRQ-irq-unsafe lock:
     (&fiq->waitq){+.+.}
    
    ... which became SOFTIRQ-irq-unsafe at:
    ...
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
      _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
      spin_lock include/linux/spinlock.h:329 [inline]
      flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
      fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
      fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
      fuse_send_init fs/fuse/inode.c:989 [inline]
      fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
      mount_nodev+0x68/0x110 fs/super.c:1392
      fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
      legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
      vfs_get_tree+0x123/0x450 fs/super.c:1481
      do_new_mount fs/namespace.c:2610 [inline]
      do_mount+0x1436/0x2c40 fs/namespace.c:2932
      ksys_mount+0xdb/0x150 fs/namespace.c:3148
      __do_sys_mount fs/namespace.c:3162 [inline]
      __se_sys_mount fs/namespace.c:3159 [inline]
      __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
      do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    other info that might help us debug this:
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&fiq->waitq);
                                   local_irq_disable();
                                   lock(&(&ctx->ctx_lock)->rlock);
                                   lock(&fiq->waitq);
      <Interrupt>
        lock(&(&ctx->ctx_lock)->rlock);
    
     *** DEADLOCK ***
    
    1 lock held by syz-executor2/13779:
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    
    the dependencies between SOFTIRQ-irq-safe lock and the holding lock:
    -> (&(&ctx->ctx_lock)->rlock){..-.} {
       IN-SOFTIRQ-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                        _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                        spin_lock_irq include/linux/spinlock.h:354 [inline]
                        free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
                        percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
                        percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
                        percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
                        percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
                        __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
                        rcu_do_batch kernel/rcu/tree.c:2486 [inline]
                        invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
                        rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
                        __do_softirq+0x266/0x95a kernel/softirq.c:292
                        run_ksoftirqd kernel/softirq.c:654 [inline]
                        run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
                        smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
                        kthread+0x357/0x430 kernel/kthread.c:247
                        ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                       _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                       spin_lock_irq include/linux/spinlock.h:354 [inline]
                       __do_sys_io_cancel fs/aio.c:2052 [inline]
                       __se_sys_io_cancel fs/aio.c:2035 [inline]
                       __x64_sys_io_cancel+0xd5/0x5a0 fs/aio.c:2035
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a574140>] __key.52370+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    the dependencies between the lock to be acquired
     and SOFTIRQ-irq-unsafe lock:
    -> (&fiq->waitq){+.+.} {
       HARDIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       SOFTIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                       spin_lock include/linux/spinlock.h:329 [inline]
                       flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                       fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                       fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                       fuse_send_init fs/fuse/inode.c:989 [inline]
                       fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                       mount_nodev+0x68/0x110 fs/super.c:1392
                       fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                       legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                       vfs_get_tree+0x123/0x450 fs/super.c:1481
                       do_new_mount fs/namespace.c:2610 [inline]
                       do_mount+0x1436/0x2c40 fs/namespace.c:2932
                       ksys_mount+0xdb/0x150 fs/namespace.c:3148
                       __do_sys_mount fs/namespace.c:3162 [inline]
                       __se_sys_mount fs/namespace.c:3159 [inline]
                       __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a60dec0>] __key.43450+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    stack backtrace:
    CPU: 0 PID: 13779 Comm: syz-executor2 Not tainted 5.0.0-rc4-next-20190131 #23
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_bad_irq_dependency kernel/locking/lockdep.c:1573 [inline]
     check_usage.cold+0x60f/0x940 kernel/locking/lockdep.c:1605
     check_irq_usage kernel/locking/lockdep.c:1650 [inline]
     check_prev_add_irq kernel/locking/lockdep_states.h:8 [inline]
     check_prev_add kernel/locking/lockdep.c:1860 [inline]
     check_prevs_add kernel/locking/lockdep.c:1968 [inline]
     validate_chain kernel/locking/lockdep.c:2339 [inline]
     __lock_acquire+0x1f12/0x4790 kernel/locking/lockdep.c:3320
     lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
     spin_lock include/linux/spinlock.h:329 [inline]
     aio_poll fs/aio.c:1772 [inline]
     __io_submit_one fs/aio.c:1875 [inline]
     io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
     __do_sys_io_submit fs/aio.c:1953 [inline]
     __se_sys_io_submit fs/aio.c:1923 [inline]
     __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
     do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Avi Kivity <avi@scylladb.com>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: <stable@vger.kernel.org>
    Fixes: e8693bcfa0b4 ("aio: allow direct aio poll comletions for keyed wakeups") # v4.19
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    [ bvanassche: added a comment ]
    Reluctantly-Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6d2b0f02f5a07a4bf02e4cbc90d7eaa85cac2986
Author: Li RongQing <lirongqing@baidu.com>
Date:   Wed Mar 6 14:46:27 2019 +0800

    connector: fix unsafe usage of ->real_parent
    
    proc_exit_connector() uses ->real_parent lockless. This is not
    safe that its parent can go away at any moment, so use RCU to
    protect it, and ensure that this task is not released.
    
    [  747.624551] ==================================================================
    [  747.632946] BUG: KASAN: use-after-free in proc_exit_connector+0x1f7/0x310
    [  747.640686] Read of size 4 at addr ffff88a0276988e0 by task sshd/2882
    [  747.648032]
    [  747.649804] CPU: 11 PID: 2882 Comm: sshd Tainted: G            E     4.19.26-rc2 #11
    [  747.658629] Hardware name: IBM x3550M4 -[7914OFV]-/00AM544, BIOS -[D7E142BUS-1.71]- 07/31/2014
    [  747.668419] Call Trace:
    [  747.671269]  dump_stack+0xf0/0x19b
    [  747.675186]  ? show_regs_print_info+0x5/0x5
    [  747.679988]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [  747.685302]  print_address_description+0x6a/0x270
    [  747.691162]  kasan_report+0x258/0x380
    [  747.695835]  ? proc_exit_connector+0x1f7/0x310
    [  747.701402]  proc_exit_connector+0x1f7/0x310
    [  747.706767]  ? proc_coredump_connector+0x2d0/0x2d0
    [  747.712715]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.718270]  ? _raw_write_unlock_irq+0x29/0x50
    [  747.723820]  ? ___preempt_schedule+0x16/0x18
    [  747.729193]  ? ___preempt_schedule+0x16/0x18
    [  747.734574]  do_exit+0xa11/0x14f0
    [  747.738880]  ? mm_update_next_owner+0x590/0x590
    [  747.744525]  ? debug_show_all_locks+0x3c0/0x3c0
    [  747.761448]  ? ktime_get_coarse_real_ts64+0xeb/0x1c0
    [  747.767589]  ? lockdep_hardirqs_on+0x1a6/0x290
    [  747.773154]  ? check_chain_key+0x139/0x1f0
    [  747.778345]  ? check_flags.part.35+0x240/0x240
    [  747.783908]  ? __lock_acquire+0x2300/0x2300
    [  747.789171]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.795316]  ? _raw_spin_unlock_irqrestore+0x59/0x70
    [  747.801457]  ? do_raw_spin_unlock+0x10f/0x1e0
    [  747.806914]  ? do_raw_spin_trylock+0x120/0x120
    [  747.812481]  ? preempt_count_sub+0x14/0xc0
    [  747.817645]  ? _raw_spin_unlock+0x2e/0x50
    [  747.822708]  ? __handle_mm_fault+0x12db/0x1fa0
    [  747.828367]  ? __pmd_alloc+0x2d0/0x2d0
    [  747.833143]  ? check_noncircular+0x50/0x50
    [  747.838309]  ? match_held_lock+0x7f/0x340
    [  747.843380]  ? check_noncircular+0x50/0x50
    [  747.848561]  ? handle_mm_fault+0x21a/0x5f0
    [  747.853730]  ? check_flags.part.35+0x240/0x240
    [  747.859290]  ? check_chain_key+0x139/0x1f0
    [  747.864474]  ? __do_page_fault+0x40f/0x760
    [  747.869655]  ? __audit_syscall_entry+0x4b/0x1f0
    [  747.875319]  ? syscall_trace_enter+0x1d5/0x7b0
    [  747.880877]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.887895]  ? trace_raw_output_sys_exit+0x80/0x80
    [  747.893860]  ? up_read+0x3b/0x90
    [  747.898142]  ? stop_critical_timings+0x260/0x260
    [  747.903909]  do_group_exit+0xe0/0x1c0
    [  747.908591]  ? __x64_sys_exit+0x30/0x30
    [  747.913460]  ? trace_raw_output_preemptirq_template+0x90/0x90
    [  747.920485]  ? tracer_hardirqs_on+0x270/0x270
    [  747.925956]  __x64_sys_exit_group+0x28/0x30
    [  747.931214]  do_syscall_64+0x117/0x400
    [  747.935988]  ? syscall_return_slowpath+0x2f0/0x2f0
    [  747.941931]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.947788]  ? trace_hardirqs_on_caller+0x1d0/0x1d0
    [  747.953838]  ? lockdep_sys_exit+0x16/0x8e
    [  747.958915]  ? trace_hardirqs_off_thunk+0x1a/0x1c
    [  747.964784]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  747.971021] RIP: 0033:0x7f572f154c68
    [  747.975606] Code: Bad RIP value.
    [  747.979791] RSP: 002b:00007ffed2dfaa58 EFLAGS: 00000246 ORIG_RAX: 00000000000000e7
    [  747.989324] RAX: ffffffffffffffda RBX: 00007f572f431840 RCX: 00007f572f154c68
    [  747.997910] RDX: 0000000000000001 RSI: 000000000000003c RDI: 0000000000000001
    [  748.006495] RBP: 0000000000000001 R08: 00000000000000e7 R09: fffffffffffffee0
    [  748.015079] R10: 00007f572f4387e8 R11: 0000000000000246 R12: 00007f572f431840
    [  748.023664] R13: 000055a7f90f2c50 R14: 000055a7f96e2310 R15: 000055a7f96e2310
    [  748.032287]
    [  748.034509] Allocated by task 2300:
    [  748.038982]  kasan_kmalloc+0xa0/0xd0
    [  748.043562]  kmem_cache_alloc_node+0xf5/0x2e0
    [  748.049018]  copy_process+0x1781/0x4790
    [  748.053884]  _do_fork+0x166/0x9a0
    [  748.058163]  do_syscall_64+0x117/0x400
    [  748.062943]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.069180]
    [  748.071405] Freed by task 15395:
    [  748.075591]  __kasan_slab_free+0x130/0x180
    [  748.080752]  kmem_cache_free+0xc2/0x310
    [  748.085619]  free_task+0xea/0x130
    [  748.089901]  __put_task_struct+0x177/0x230
    [  748.095063]  finish_task_switch+0x51b/0x5d0
    [  748.100315]  __schedule+0x506/0xfa0
    [  748.104791]  schedule+0xca/0x260
    [  748.108978]  futex_wait_queue_me+0x27e/0x420
    [  748.114333]  futex_wait+0x251/0x550
    [  748.118814]  do_futex+0x75b/0xf80
    [  748.123097]  __x64_sys_futex+0x231/0x2a0
    [  748.128065]  do_syscall_64+0x117/0x400
    [  748.132835]  entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [  748.139066]
    [  748.141289] The buggy address belongs to the object at ffff88a027698000
    [  748.141289]  which belongs to the cache task_struct of size 12160
    [  748.156589] The buggy address is located 2272 bytes inside of
    [  748.156589]  12160-byte region [ffff88a027698000, ffff88a02769af80)
    [  748.171114] The buggy address belongs to the page:
    [  748.177055] page:ffffea00809da600 count:1 mapcount:0 mapping:ffff888107d01e00 index:0x0 compound_mapcount: 0
    [  748.189136] flags: 0x57ffffc0008100(slab|head)
    [  748.194688] raw: 0057ffffc0008100 ffffea00809a3200 0000000300000003 ffff888107d01e00
    [  748.204424] raw: 0000000000000000 0000000000020002 00000001ffffffff 0000000000000000
    [  748.214146] page dumped because: kasan: bad access detected
    [  748.220976]
    [  748.223197] Memory state around the buggy address:
    [  748.229128]  ffff88a027698780: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.238271]  ffff88a027698800: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.247414] >ffff88a027698880: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.256564]                                                        ^
    [  748.264267]  ffff88a027698900: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.273493]  ffff88a027698980: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
    [  748.282630] ==================================================================
    
    Fixes: b086ff87251b4a4 ("connector: add parent pid and tgid to coredump and exit events")
    Signed-off-by: Zhang Yu <zhangyu31@baidu.com>
    Signed-off-by: Li RongQing <lirongqing@baidu.com>
    Acked-by: Evgeniy Polyakov <zbr@ioremap.net>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit d3d6a18d7d351cbcc9b33dbedf710e65f8ce1595
Author: Bart Van Assche <bvanassche@acm.org>
Date:   Fri Feb 8 16:59:49 2019 -0800

    aio: Fix locking in aio_poll()
    
    wake_up_locked() may but does not have to be called with interrupts
    disabled. Since the fuse filesystem calls wake_up_locked() without
    disabling interrupts aio_poll_wake() may be called with interrupts
    enabled. Since the kioctx.ctx_lock may be acquired from IRQ context,
    all code that acquires that lock from thread context must disable
    interrupts. Hence change the spin_trylock() call in aio_poll_wake()
    into a spin_trylock_irqsave() call. This patch fixes the following
    lockdep complaint:
    
    =====================================================
    WARNING: SOFTIRQ-safe -> SOFTIRQ-unsafe lock order detected
    5.0.0-rc4-next-20190131 #23 Not tainted
    -----------------------------------------------------
    syz-executor2/13779 [HC0[0]:SC0[0]:HE0:SE1] is trying to acquire:
    0000000098ac1230 (&fiq->waitq){+.+.}, at: spin_lock include/linux/spinlock.h:329 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: aio_poll fs/aio.c:1772 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: __io_submit_one fs/aio.c:1875 [inline]
    0000000098ac1230 (&fiq->waitq){+.+.}, at: io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
    
    and this task is already holding:
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
    000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    which would create a new lock dependency:
     (&(&ctx->ctx_lock)->rlock){..-.} -> (&fiq->waitq){+.+.}
    
    but this new dependency connects a SOFTIRQ-irq-safe lock:
     (&(&ctx->ctx_lock)->rlock){..-.}
    
    ... which became SOFTIRQ-irq-safe at:
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
      _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
      spin_lock_irq include/linux/spinlock.h:354 [inline]
      free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
      percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
      percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
      percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
      percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
      __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
      rcu_do_batch kernel/rcu/tree.c:2486 [inline]
      invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
      rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
      __do_softirq+0x266/0x95a kernel/softirq.c:292
      run_ksoftirqd kernel/softirq.c:654 [inline]
      run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
      smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
      kthread+0x357/0x430 kernel/kthread.c:247
      ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
    
    to a SOFTIRQ-irq-unsafe lock:
     (&fiq->waitq){+.+.}
    
    ... which became SOFTIRQ-irq-unsafe at:
    ...
      lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
      __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
      _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
      spin_lock include/linux/spinlock.h:329 [inline]
      flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
      fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
      fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
      fuse_send_init fs/fuse/inode.c:989 [inline]
      fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
      mount_nodev+0x68/0x110 fs/super.c:1392
      fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
      legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
      vfs_get_tree+0x123/0x450 fs/super.c:1481
      do_new_mount fs/namespace.c:2610 [inline]
      do_mount+0x1436/0x2c40 fs/namespace.c:2932
      ksys_mount+0xdb/0x150 fs/namespace.c:3148
      __do_sys_mount fs/namespace.c:3162 [inline]
      __se_sys_mount fs/namespace.c:3159 [inline]
      __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
      do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
      entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    other info that might help us debug this:
    
     Possible interrupt unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&fiq->waitq);
                                   local_irq_disable();
                                   lock(&(&ctx->ctx_lock)->rlock);
                                   lock(&fiq->waitq);
      <Interrupt>
        lock(&(&ctx->ctx_lock)->rlock);
    
     *** DEADLOCK ***
    
    1 lock held by syz-executor2/13779:
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: spin_lock_irq include/linux/spinlock.h:354 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: aio_poll fs/aio.c:1771 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: __io_submit_one fs/aio.c:1875 [inline]
     #0: 000000003c46111c (&(&ctx->ctx_lock)->rlock){..-.}, at: io_submit_one+0xeb6/0x1cf0 fs/aio.c:1908
    
    the dependencies between SOFTIRQ-irq-safe lock and the holding lock:
    -> (&(&ctx->ctx_lock)->rlock){..-.} {
       IN-SOFTIRQ-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                        _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                        spin_lock_irq include/linux/spinlock.h:354 [inline]
                        free_ioctx_users+0x2d/0x4a0 fs/aio.c:610
                        percpu_ref_put_many include/linux/percpu-refcount.h:285 [inline]
                        percpu_ref_put include/linux/percpu-refcount.h:301 [inline]
                        percpu_ref_call_confirm_rcu lib/percpu-refcount.c:123 [inline]
                        percpu_ref_switch_to_atomic_rcu+0x3e7/0x520 lib/percpu-refcount.c:158
                        __rcu_reclaim kernel/rcu/rcu.h:240 [inline]
                        rcu_do_batch kernel/rcu/tree.c:2486 [inline]
                        invoke_rcu_callbacks kernel/rcu/tree.c:2799 [inline]
                        rcu_core+0x928/0x1390 kernel/rcu/tree.c:2780
                        __do_softirq+0x266/0x95a kernel/softirq.c:292
                        run_ksoftirqd kernel/softirq.c:654 [inline]
                        run_ksoftirqd+0x8e/0x110 kernel/softirq.c:646
                        smpboot_thread_fn+0x6ab/0xa10 kernel/smpboot.c:164
                        kthread+0x357/0x430 kernel/kthread.c:247
                        ret_from_fork+0x3a/0x50 arch/x86/entry/entry_64.S:352
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock_irq include/linux/spinlock_api_smp.h:128 [inline]
                       _raw_spin_lock_irq+0x60/0x80 kernel/locking/spinlock.c:160
                       spin_lock_irq include/linux/spinlock.h:354 [inline]
                       __do_sys_io_cancel fs/aio.c:2052 [inline]
                       __se_sys_io_cancel fs/aio.c:2035 [inline]
                       __x64_sys_io_cancel+0xd5/0x5a0 fs/aio.c:2035
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a574140>] __key.52370+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    the dependencies between the lock to be acquired
     and SOFTIRQ-irq-unsafe lock:
    -> (&fiq->waitq){+.+.} {
       HARDIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       SOFTIRQ-ON-W at:
                        lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                        __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                        _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                        spin_lock include/linux/spinlock.h:329 [inline]
                        flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                        fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                        fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                        fuse_send_init fs/fuse/inode.c:989 [inline]
                        fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                        mount_nodev+0x68/0x110 fs/super.c:1392
                        fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                        legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                        vfs_get_tree+0x123/0x450 fs/super.c:1481
                        do_new_mount fs/namespace.c:2610 [inline]
                        do_mount+0x1436/0x2c40 fs/namespace.c:2932
                        ksys_mount+0xdb/0x150 fs/namespace.c:3148
                        __do_sys_mount fs/namespace.c:3162 [inline]
                        __se_sys_mount fs/namespace.c:3159 [inline]
                        __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                        do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                        entry_SYSCALL_64_after_hwframe+0x49/0xbe
       INITIAL USE at:
                       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
                       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
                       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
                       spin_lock include/linux/spinlock.h:329 [inline]
                       flush_bg_queue+0x1f3/0x3c0 fs/fuse/dev.c:415
                       fuse_request_queue_background+0x2d1/0x580 fs/fuse/dev.c:676
                       fuse_request_send_background+0x58/0x120 fs/fuse/dev.c:687
                       fuse_send_init fs/fuse/inode.c:989 [inline]
                       fuse_fill_super+0x13bb/0x1730 fs/fuse/inode.c:1214
                       mount_nodev+0x68/0x110 fs/super.c:1392
                       fuse_mount+0x2d/0x40 fs/fuse/inode.c:1239
                       legacy_get_tree+0xf2/0x200 fs/fs_context.c:590
                       vfs_get_tree+0x123/0x450 fs/super.c:1481
                       do_new_mount fs/namespace.c:2610 [inline]
                       do_mount+0x1436/0x2c40 fs/namespace.c:2932
                       ksys_mount+0xdb/0x150 fs/namespace.c:3148
                       __do_sys_mount fs/namespace.c:3162 [inline]
                       __se_sys_mount fs/namespace.c:3159 [inline]
                       __x64_sys_mount+0xbe/0x150 fs/namespace.c:3159
                       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
                       entry_SYSCALL_64_after_hwframe+0x49/0xbe
     }
     ... key      at: [<ffffffff8a60dec0>] __key.43450+0x0/0x40
     ... acquired at:
       lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
       __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
       _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
       spin_lock include/linux/spinlock.h:329 [inline]
       aio_poll fs/aio.c:1772 [inline]
       __io_submit_one fs/aio.c:1875 [inline]
       io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
       __do_sys_io_submit fs/aio.c:1953 [inline]
       __se_sys_io_submit fs/aio.c:1923 [inline]
       __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
       do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
       entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    stack backtrace:
    CPU: 0 PID: 13779 Comm: syz-executor2 Not tainted 5.0.0-rc4-next-20190131 #23
    Hardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack+0x172/0x1f0 lib/dump_stack.c:113
     print_bad_irq_dependency kernel/locking/lockdep.c:1573 [inline]
     check_usage.cold+0x60f/0x940 kernel/locking/lockdep.c:1605
     check_irq_usage kernel/locking/lockdep.c:1650 [inline]
     check_prev_add_irq kernel/locking/lockdep_states.h:8 [inline]
     check_prev_add kernel/locking/lockdep.c:1860 [inline]
     check_prevs_add kernel/locking/lockdep.c:1968 [inline]
     validate_chain kernel/locking/lockdep.c:2339 [inline]
     __lock_acquire+0x1f12/0x4790 kernel/locking/lockdep.c:3320
     lock_acquire+0x16f/0x3f0 kernel/locking/lockdep.c:3826
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x2f/0x40 kernel/locking/spinlock.c:144
     spin_lock include/linux/spinlock.h:329 [inline]
     aio_poll fs/aio.c:1772 [inline]
     __io_submit_one fs/aio.c:1875 [inline]
     io_submit_one+0xedf/0x1cf0 fs/aio.c:1908
     __do_sys_io_submit fs/aio.c:1953 [inline]
     __se_sys_io_submit fs/aio.c:1923 [inline]
     __x64_sys_io_submit+0x1bd/0x580 fs/aio.c:1923
     do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290
     entry_SYSCALL_64_after_hwframe+0x49/0xbe
    
    Reported-by: syzbot <syzkaller@googlegroups.com>
    Cc: Christoph Hellwig <hch@lst.de>
    Cc: Avi Kivity <avi@scylladb.com>
    Cc: Miklos Szeredi <miklos@szeredi.hu>
    Cc: <stable@vger.kernel.org>
    Fixes: e8693bcfa0b4 ("aio: allow direct aio poll comletions for keyed wakeups") # v4.19
    Signed-off-by: Miklos Szeredi <miklos@szeredi.hu>
    [ bvanassche: added a comment ]
    Reluctantly-Acked-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Bart Van Assche <bvanassche@acm.org>
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>

commit 452eb4bdf2181b64501b61fdbc9e54ec2c1ad7e3
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Oct 25 19:10:36 2018 +0900

    panic: avoid deadlocks in re-entrant console drivers
    
    commit c7c3f05e341a9a2bd1a92993d4f996cfd6e7348e upstream.
    
    From printk()/serial console point of view panic() is special, because
    it may force CPU to re-enter printk() or/and serial console driver.
    Therefore, some of serial consoles drivers are re-entrant. E.g. 8250:
    
    serial8250_console_write()
    {
            if (port->sysrq)
                    locked = 0;
            else if (oops_in_progress)
                    locked = spin_trylock_irqsave(&port->lock, flags);
            else
                    spin_lock_irqsave(&port->lock, flags);
            ...
    }
    
    panic() does set oops_in_progress via bust_spinlocks(1), so in theory
    we should be able to re-enter serial console driver from panic():
    
            CPU0
            <NMI>
            uart_console_write()
            serial8250_console_write()              // if (oops_in_progress)
                                                    //    spin_trylock_irqsave()
            call_console_drivers()
            console_unlock()
            console_flush_on_panic()
            bust_spinlocks(1)                       // oops_in_progress++
            panic()
            <NMI/>
            spin_lock_irqsave(&port->lock, flags)   // spin_lock_irqsave()
            serial8250_console_write()
            call_console_drivers()
            console_unlock()
            printk()
            ...
    
    However, this does not happen and we deadlock in serial console on
    port->lock spinlock. And the problem is that console_flush_on_panic()
    called after bust_spinlocks(0):
    
    void panic(const char *fmt, ...)
    {
            bust_spinlocks(1);
            ...
            bust_spinlocks(0);
            console_flush_on_panic();
            ...
    }
    
    bust_spinlocks(0) decrements oops_in_progress, so oops_in_progress
    can go back to zero. Thus even re-entrant console drivers will simply
    spin on port->lock spinlock. Given that port->lock may already be
    locked either by a stopped CPU, or by the very same CPU we execute
    panic() on (for instance, NMI panic() on printing CPU) the system
    deadlocks and does not reboot.
    
    Fix this by removing bust_spinlocks(0), so oops_in_progress is always
    set in panic() now and, thus, re-entrant console drivers will trylock
    the port->lock instead of spinning on it forever, when we call them
    from console_flush_on_panic().
    
    Link: http://lkml.kernel.org/r/20181025101036.6823-1-sergey.senozhatsky@gmail.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Wang <wonderfly@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: linux-serial@vger.kernel.org
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6c976b42dc1540cf7cd0fc013928adf53b4f8791
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Oct 25 19:10:36 2018 +0900

    panic: avoid deadlocks in re-entrant console drivers
    
    commit c7c3f05e341a9a2bd1a92993d4f996cfd6e7348e upstream.
    
    From printk()/serial console point of view panic() is special, because
    it may force CPU to re-enter printk() or/and serial console driver.
    Therefore, some of serial consoles drivers are re-entrant. E.g. 8250:
    
    serial8250_console_write()
    {
            if (port->sysrq)
                    locked = 0;
            else if (oops_in_progress)
                    locked = spin_trylock_irqsave(&port->lock, flags);
            else
                    spin_lock_irqsave(&port->lock, flags);
            ...
    }
    
    panic() does set oops_in_progress via bust_spinlocks(1), so in theory
    we should be able to re-enter serial console driver from panic():
    
            CPU0
            <NMI>
            uart_console_write()
            serial8250_console_write()              // if (oops_in_progress)
                                                    //    spin_trylock_irqsave()
            call_console_drivers()
            console_unlock()
            console_flush_on_panic()
            bust_spinlocks(1)                       // oops_in_progress++
            panic()
            <NMI/>
            spin_lock_irqsave(&port->lock, flags)   // spin_lock_irqsave()
            serial8250_console_write()
            call_console_drivers()
            console_unlock()
            printk()
            ...
    
    However, this does not happen and we deadlock in serial console on
    port->lock spinlock. And the problem is that console_flush_on_panic()
    called after bust_spinlocks(0):
    
    void panic(const char *fmt, ...)
    {
            bust_spinlocks(1);
            ...
            bust_spinlocks(0);
            console_flush_on_panic();
            ...
    }
    
    bust_spinlocks(0) decrements oops_in_progress, so oops_in_progress
    can go back to zero. Thus even re-entrant console drivers will simply
    spin on port->lock spinlock. Given that port->lock may already be
    locked either by a stopped CPU, or by the very same CPU we execute
    panic() on (for instance, NMI panic() on printing CPU) the system
    deadlocks and does not reboot.
    
    Fix this by removing bust_spinlocks(0), so oops_in_progress is always
    set in panic() now and, thus, re-entrant console drivers will trylock
    the port->lock instead of spinning on it forever, when we call them
    from console_flush_on_panic().
    
    Link: http://lkml.kernel.org/r/20181025101036.6823-1-sergey.senozhatsky@gmail.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Wang <wonderfly@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: linux-serial@vger.kernel.org
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e1240a10f34d452bf9f50da7cc062022b586c2f4
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Oct 25 19:10:36 2018 +0900

    panic: avoid deadlocks in re-entrant console drivers
    
    commit c7c3f05e341a9a2bd1a92993d4f996cfd6e7348e upstream.
    
    From printk()/serial console point of view panic() is special, because
    it may force CPU to re-enter printk() or/and serial console driver.
    Therefore, some of serial consoles drivers are re-entrant. E.g. 8250:
    
    serial8250_console_write()
    {
            if (port->sysrq)
                    locked = 0;
            else if (oops_in_progress)
                    locked = spin_trylock_irqsave(&port->lock, flags);
            else
                    spin_lock_irqsave(&port->lock, flags);
            ...
    }
    
    panic() does set oops_in_progress via bust_spinlocks(1), so in theory
    we should be able to re-enter serial console driver from panic():
    
            CPU0
            <NMI>
            uart_console_write()
            serial8250_console_write()              // if (oops_in_progress)
                                                    //    spin_trylock_irqsave()
            call_console_drivers()
            console_unlock()
            console_flush_on_panic()
            bust_spinlocks(1)                       // oops_in_progress++
            panic()
            <NMI/>
            spin_lock_irqsave(&port->lock, flags)   // spin_lock_irqsave()
            serial8250_console_write()
            call_console_drivers()
            console_unlock()
            printk()
            ...
    
    However, this does not happen and we deadlock in serial console on
    port->lock spinlock. And the problem is that console_flush_on_panic()
    called after bust_spinlocks(0):
    
    void panic(const char *fmt, ...)
    {
            bust_spinlocks(1);
            ...
            bust_spinlocks(0);
            console_flush_on_panic();
            ...
    }
    
    bust_spinlocks(0) decrements oops_in_progress, so oops_in_progress
    can go back to zero. Thus even re-entrant console drivers will simply
    spin on port->lock spinlock. Given that port->lock may already be
    locked either by a stopped CPU, or by the very same CPU we execute
    panic() on (for instance, NMI panic() on printing CPU) the system
    deadlocks and does not reboot.
    
    Fix this by removing bust_spinlocks(0), so oops_in_progress is always
    set in panic() now and, thus, re-entrant console drivers will trylock
    the port->lock instead of spinning on it forever, when we call them
    from console_flush_on_panic().
    
    Link: http://lkml.kernel.org/r/20181025101036.6823-1-sergey.senozhatsky@gmail.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Wang <wonderfly@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: linux-serial@vger.kernel.org
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 384221cbb918136863016a582dd7475febc7d4b9
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Oct 25 19:10:36 2018 +0900

    panic: avoid deadlocks in re-entrant console drivers
    
    commit c7c3f05e341a9a2bd1a92993d4f996cfd6e7348e upstream.
    
    From printk()/serial console point of view panic() is special, because
    it may force CPU to re-enter printk() or/and serial console driver.
    Therefore, some of serial consoles drivers are re-entrant. E.g. 8250:
    
    serial8250_console_write()
    {
            if (port->sysrq)
                    locked = 0;
            else if (oops_in_progress)
                    locked = spin_trylock_irqsave(&port->lock, flags);
            else
                    spin_lock_irqsave(&port->lock, flags);
            ...
    }
    
    panic() does set oops_in_progress via bust_spinlocks(1), so in theory
    we should be able to re-enter serial console driver from panic():
    
            CPU0
            <NMI>
            uart_console_write()
            serial8250_console_write()              // if (oops_in_progress)
                                                    //    spin_trylock_irqsave()
            call_console_drivers()
            console_unlock()
            console_flush_on_panic()
            bust_spinlocks(1)                       // oops_in_progress++
            panic()
            <NMI/>
            spin_lock_irqsave(&port->lock, flags)   // spin_lock_irqsave()
            serial8250_console_write()
            call_console_drivers()
            console_unlock()
            printk()
            ...
    
    However, this does not happen and we deadlock in serial console on
    port->lock spinlock. And the problem is that console_flush_on_panic()
    called after bust_spinlocks(0):
    
    void panic(const char *fmt, ...)
    {
            bust_spinlocks(1);
            ...
            bust_spinlocks(0);
            console_flush_on_panic();
            ...
    }
    
    bust_spinlocks(0) decrements oops_in_progress, so oops_in_progress
    can go back to zero. Thus even re-entrant console drivers will simply
    spin on port->lock spinlock. Given that port->lock may already be
    locked either by a stopped CPU, or by the very same CPU we execute
    panic() on (for instance, NMI panic() on printing CPU) the system
    deadlocks and does not reboot.
    
    Fix this by removing bust_spinlocks(0), so oops_in_progress is always
    set in panic() now and, thus, re-entrant console drivers will trylock
    the port->lock instead of spinning on it forever, when we call them
    from console_flush_on_panic().
    
    Link: http://lkml.kernel.org/r/20181025101036.6823-1-sergey.senozhatsky@gmail.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Wang <wonderfly@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: linux-serial@vger.kernel.org
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fb94109b764e7676fa63834b9033ba97175877a0
Author: Benjamin Gaignard <benjamin.gaignard@st.com>
Date:   Mon Dec 17 15:22:14 2018 +0100

    irqchip/stm32: protect configuration registers with hwspinlock
    
    If a hwspinlock is defined in device tree use it to protect
    configuration registers.
    
    Do not request for hwspinlock during the exti driver init since the
    hwspinlock driver is not probed yet at that stage and the exti driver
    does not support deferred probe.
    Instead of this, postpone the hwspinlock request at the first time the
    hwspinlock is actually needed.
    
    Use the hwspin_trylock_raw() API which is the most appropriated here
    Indeed:
    - hwspin_lock_() calls are under spin_lock protection (chip_data->rlock
      or gc->lock).
    - the _timeout() API relies on jiffies count which won't work if IRQs
      are disabled which is the case here (a large part of the IRQ setup is
      done atomically (see irq/manage.c))
    As a consequence implement the retry/timeout lock from here. And since
    all of this is done atomically, reduce the timeout delay to 1 ms.
    
    Signed-off-by: Benjamin Gaignard <benjamin.gaignard@st.com>
    Signed-off-by: Fabien Dessenne <fabien.dessenne@st.com>
    Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>

commit ae60f4705f95889cdb3cc9d8c4fd3ef2486074bc
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Mon Nov 5 03:44:11 2018 +0900

    netfilter: nf_conncount: fix list_del corruption in conn_free
    
    [ Upstream commit 31568ec09ea02a050249921698c9729419539cce ]
    
    nf_conncount_tuple is an element of nft_connlimit and that is deleted by
    conn_free(). Elements can be deleted by both GC routine and data path
    functions (nf_conncount_lookup, nf_conncount_add) and they call
    conn_free() to free elements. But conn_free() only protects lists, not
    each element. So that list_del corruption could occurred.
    
    The conn_free() doesn't check whether element is already deleted. In
    order to protect elements, dead flag is added. If an element is deleted,
    dead flag is set. The only conn_free() can delete elements so that both
    list lock and dead flag are enough to protect it.
    
    test commands:
       %nft add table ip filter
       %nft add chain ip filter input { type filter hook input priority 0\; }
       %nft add rule filter input meter test { ip id ct count over 2 } counter
    
    splat looks like:
    [ 1779.495778] list_del corruption, ffff8800b6e12008->prev is LIST_POISON2 (dead000000000200)
    [ 1779.505453] ------------[ cut here ]------------
    [ 1779.506260] kernel BUG at lib/list_debug.c:50!
    [ 1779.515831] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [ 1779.516772] CPU: 0 PID: 33 Comm: kworker/0:2 Not tainted 4.19.0-rc6+ #22
    [ 1779.516772] Workqueue: events_power_efficient nft_rhash_gc [nf_tables_set]
    [ 1779.516772] RIP: 0010:__list_del_entry_valid+0xd8/0x150
    [ 1779.516772] Code: 39 48 83 c4 08 b8 01 00 00 00 5b 5d c3 48 89 ea 48 c7 c7 00 c3 5b 98 e8 0f dc 40 ff 0f 0b 48 c7 c7 60 c3 5b 98 e8 01 dc 40 ff <0f> 0b 48 c7 c7 c0 c3 5b 98 e8 f3 db 40 ff 0f 0b 48 c7 c7 20 c4 5b
    [ 1779.516772] RSP: 0018:ffff880119127420 EFLAGS: 00010286
    [ 1779.516772] RAX: 000000000000004e RBX: dead000000000200 RCX: 0000000000000000
    [ 1779.516772] RDX: 000000000000004e RSI: 0000000000000008 RDI: ffffed0023224e7a
    [ 1779.516772] RBP: ffff88011934bc10 R08: ffffed002367cea9 R09: ffffed002367cea9
    [ 1779.516772] R10: 0000000000000001 R11: ffffed002367cea8 R12: ffff8800b6e12008
    [ 1779.516772] R13: ffff8800b6e12010 R14: ffff88011934bc20 R15: ffff8800b6e12008
    [ 1779.516772] FS:  0000000000000000(0000) GS:ffff88011b200000(0000) knlGS:0000000000000000
    [ 1779.516772] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1779.516772] CR2: 00007fc876534010 CR3: 000000010da16000 CR4: 00000000001006f0
    [ 1779.516772] Call Trace:
    [ 1779.516772]  conn_free+0x9f/0x2b0 [nf_conncount]
    [ 1779.516772]  ? nf_ct_tmpl_alloc+0x2a0/0x2a0 [nf_conntrack]
    [ 1779.516772]  ? nf_conncount_add+0x520/0x520 [nf_conncount]
    [ 1779.516772]  ? do_raw_spin_trylock+0x1a0/0x1a0
    [ 1779.516772]  ? do_raw_spin_trylock+0x10/0x1a0
    [ 1779.516772]  find_or_evict+0xe5/0x150 [nf_conncount]
    [ 1779.516772]  nf_conncount_gc_list+0x162/0x360 [nf_conncount]
    [ 1779.516772]  ? nf_conncount_lookup+0xee0/0xee0 [nf_conncount]
    [ 1779.516772]  ? _raw_spin_unlock_irqrestore+0x45/0x50
    [ 1779.516772]  ? trace_hardirqs_off+0x6b/0x220
    [ 1779.516772]  ? trace_hardirqs_on_caller+0x220/0x220
    [ 1779.516772]  nft_rhash_gc+0x16b/0x540 [nf_tables_set]
    [ ... ]
    
    Fixes: 5c789e131cbb ("netfilter: nf_conncount: Add list lock and gc worker, and RCU for init tree search")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 4e3fbd7433d7bbeca4db70ae9ecae9bfa688e2a4
Author: Jon Maloy <donmalo99@gmail.com>
Date:   Mon Nov 26 12:26:14 2018 -0500

    tipc: fix lockdep warning during node delete
    
    [ Upstream commit ec835f891232d7763dea9da0358f31e24ca6dfb7 ]
    
    We see the following lockdep warning:
    
    [ 2284.078521] ======================================================
    [ 2284.078604] WARNING: possible circular locking dependency detected
    [ 2284.078604] 4.19.0+ #42 Tainted: G            E
    [ 2284.078604] ------------------------------------------------------
    [ 2284.078604] rmmod/254 is trying to acquire lock:
    [ 2284.078604] 00000000acd94e28 ((&n->timer)#2){+.-.}, at: del_timer_sync+0x5/0xa0
    [ 2284.078604]
    [ 2284.078604] but task is already holding lock:
    [ 2284.078604] 00000000f997afc0 (&(&tn->node_list_lock)->rlock){+.-.}, at: tipc_node_stop+0xac/0x190 [tipc]
    [ 2284.078604]
    [ 2284.078604] which lock already depends on the new lock.
    [ 2284.078604]
    [ 2284.078604]
    [ 2284.078604] the existing dependency chain (in reverse order) is:
    [ 2284.078604]
    [ 2284.078604] -> #1 (&(&tn->node_list_lock)->rlock){+.-.}:
    [ 2284.078604]        tipc_node_timeout+0x20a/0x330 [tipc]
    [ 2284.078604]        call_timer_fn+0xa1/0x280
    [ 2284.078604]        run_timer_softirq+0x1f2/0x4d0
    [ 2284.078604]        __do_softirq+0xfc/0x413
    [ 2284.078604]        irq_exit+0xb5/0xc0
    [ 2284.078604]        smp_apic_timer_interrupt+0xac/0x210
    [ 2284.078604]        apic_timer_interrupt+0xf/0x20
    [ 2284.078604]        default_idle+0x1c/0x140
    [ 2284.078604]        do_idle+0x1bc/0x280
    [ 2284.078604]        cpu_startup_entry+0x19/0x20
    [ 2284.078604]        start_secondary+0x187/0x1c0
    [ 2284.078604]        secondary_startup_64+0xa4/0xb0
    [ 2284.078604]
    [ 2284.078604] -> #0 ((&n->timer)#2){+.-.}:
    [ 2284.078604]        del_timer_sync+0x34/0xa0
    [ 2284.078604]        tipc_node_delete+0x1a/0x40 [tipc]
    [ 2284.078604]        tipc_node_stop+0xcb/0x190 [tipc]
    [ 2284.078604]        tipc_net_stop+0x154/0x170 [tipc]
    [ 2284.078604]        tipc_exit_net+0x16/0x30 [tipc]
    [ 2284.078604]        ops_exit_list.isra.8+0x36/0x70
    [ 2284.078604]        unregister_pernet_operations+0x87/0xd0
    [ 2284.078604]        unregister_pernet_subsys+0x1d/0x30
    [ 2284.078604]        tipc_exit+0x11/0x6f2 [tipc]
    [ 2284.078604]        __x64_sys_delete_module+0x1df/0x240
    [ 2284.078604]        do_syscall_64+0x66/0x460
    [ 2284.078604]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [ 2284.078604]
    [ 2284.078604] other info that might help us debug this:
    [ 2284.078604]
    [ 2284.078604]  Possible unsafe locking scenario:
    [ 2284.078604]
    [ 2284.078604]        CPU0                    CPU1
    [ 2284.078604]        ----                    ----
    [ 2284.078604]   lock(&(&tn->node_list_lock)->rlock);
    [ 2284.078604]                                lock((&n->timer)#2);
    [ 2284.078604]                                lock(&(&tn->node_list_lock)->rlock);
    [ 2284.078604]   lock((&n->timer)#2);
    [ 2284.078604]
    [ 2284.078604]  *** DEADLOCK ***
    [ 2284.078604]
    [ 2284.078604] 3 locks held by rmmod/254:
    [ 2284.078604]  #0: 000000003368be9b (pernet_ops_rwsem){+.+.}, at: unregister_pernet_subsys+0x15/0x30
    [ 2284.078604]  #1: 0000000046ed9c86 (rtnl_mutex){+.+.}, at: tipc_net_stop+0x144/0x170 [tipc]
    [ 2284.078604]  #2: 00000000f997afc0 (&(&tn->node_list_lock)->rlock){+.-.}, at: tipc_node_stop+0xac/0x19
    [...}
    
    The reason is that the node timer handler sometimes needs to delete a
    node which has been disconnected for too long. To do this, it grabs
    the lock 'node_list_lock', which may at the same time be held by the
    generic node cleanup function, tipc_node_stop(), during module removal.
    Since the latter is calling del_timer_sync() inside the same lock, we
    have a potential deadlock.
    
    We fix this letting the timer cleanup function use spin_trylock()
    instead of just spin_lock(), and when it fails to grab the lock it
    just returns so that the timer handler can terminate its execution.
    This is safe to do, since tipc_node_stop() anyway is about to
    delete both the timer and the node instance.
    
    Fixes: 6a939f365bdb ("tipc: Auto removal of peer down node instance")
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ec835f891232d7763dea9da0358f31e24ca6dfb7
Author: Jon Maloy <donmalo99@gmail.com>
Date:   Mon Nov 26 12:26:14 2018 -0500

    tipc: fix lockdep warning during node delete
    
    We see the following lockdep warning:
    
    [ 2284.078521] ======================================================
    [ 2284.078604] WARNING: possible circular locking dependency detected
    [ 2284.078604] 4.19.0+ #42 Tainted: G            E
    [ 2284.078604] ------------------------------------------------------
    [ 2284.078604] rmmod/254 is trying to acquire lock:
    [ 2284.078604] 00000000acd94e28 ((&n->timer)#2){+.-.}, at: del_timer_sync+0x5/0xa0
    [ 2284.078604]
    [ 2284.078604] but task is already holding lock:
    [ 2284.078604] 00000000f997afc0 (&(&tn->node_list_lock)->rlock){+.-.}, at: tipc_node_stop+0xac/0x190 [tipc]
    [ 2284.078604]
    [ 2284.078604] which lock already depends on the new lock.
    [ 2284.078604]
    [ 2284.078604]
    [ 2284.078604] the existing dependency chain (in reverse order) is:
    [ 2284.078604]
    [ 2284.078604] -> #1 (&(&tn->node_list_lock)->rlock){+.-.}:
    [ 2284.078604]        tipc_node_timeout+0x20a/0x330 [tipc]
    [ 2284.078604]        call_timer_fn+0xa1/0x280
    [ 2284.078604]        run_timer_softirq+0x1f2/0x4d0
    [ 2284.078604]        __do_softirq+0xfc/0x413
    [ 2284.078604]        irq_exit+0xb5/0xc0
    [ 2284.078604]        smp_apic_timer_interrupt+0xac/0x210
    [ 2284.078604]        apic_timer_interrupt+0xf/0x20
    [ 2284.078604]        default_idle+0x1c/0x140
    [ 2284.078604]        do_idle+0x1bc/0x280
    [ 2284.078604]        cpu_startup_entry+0x19/0x20
    [ 2284.078604]        start_secondary+0x187/0x1c0
    [ 2284.078604]        secondary_startup_64+0xa4/0xb0
    [ 2284.078604]
    [ 2284.078604] -> #0 ((&n->timer)#2){+.-.}:
    [ 2284.078604]        del_timer_sync+0x34/0xa0
    [ 2284.078604]        tipc_node_delete+0x1a/0x40 [tipc]
    [ 2284.078604]        tipc_node_stop+0xcb/0x190 [tipc]
    [ 2284.078604]        tipc_net_stop+0x154/0x170 [tipc]
    [ 2284.078604]        tipc_exit_net+0x16/0x30 [tipc]
    [ 2284.078604]        ops_exit_list.isra.8+0x36/0x70
    [ 2284.078604]        unregister_pernet_operations+0x87/0xd0
    [ 2284.078604]        unregister_pernet_subsys+0x1d/0x30
    [ 2284.078604]        tipc_exit+0x11/0x6f2 [tipc]
    [ 2284.078604]        __x64_sys_delete_module+0x1df/0x240
    [ 2284.078604]        do_syscall_64+0x66/0x460
    [ 2284.078604]        entry_SYSCALL_64_after_hwframe+0x49/0xbe
    [ 2284.078604]
    [ 2284.078604] other info that might help us debug this:
    [ 2284.078604]
    [ 2284.078604]  Possible unsafe locking scenario:
    [ 2284.078604]
    [ 2284.078604]        CPU0                    CPU1
    [ 2284.078604]        ----                    ----
    [ 2284.078604]   lock(&(&tn->node_list_lock)->rlock);
    [ 2284.078604]                                lock((&n->timer)#2);
    [ 2284.078604]                                lock(&(&tn->node_list_lock)->rlock);
    [ 2284.078604]   lock((&n->timer)#2);
    [ 2284.078604]
    [ 2284.078604]  *** DEADLOCK ***
    [ 2284.078604]
    [ 2284.078604] 3 locks held by rmmod/254:
    [ 2284.078604]  #0: 000000003368be9b (pernet_ops_rwsem){+.+.}, at: unregister_pernet_subsys+0x15/0x30
    [ 2284.078604]  #1: 0000000046ed9c86 (rtnl_mutex){+.+.}, at: tipc_net_stop+0x144/0x170 [tipc]
    [ 2284.078604]  #2: 00000000f997afc0 (&(&tn->node_list_lock)->rlock){+.-.}, at: tipc_node_stop+0xac/0x19
    [...}
    
    The reason is that the node timer handler sometimes needs to delete a
    node which has been disconnected for too long. To do this, it grabs
    the lock 'node_list_lock', which may at the same time be held by the
    generic node cleanup function, tipc_node_stop(), during module removal.
    Since the latter is calling del_timer_sync() inside the same lock, we
    have a potential deadlock.
    
    We fix this letting the timer cleanup function use spin_trylock()
    instead of just spin_lock(), and when it fails to grab the lock it
    just returns so that the timer handler can terminate its execution.
    This is safe to do, since tipc_node_stop() anyway is about to
    delete both the timer and the node instance.
    
    Fixes: 6a939f365bdb ("tipc: Auto removal of peer down node instance")
    Acked-by: Ying Xue <ying.xue@windriver.com>
    Signed-off-by: Jon Maloy <jon.maloy@ericsson.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c7c3f05e341a9a2bd1a92993d4f996cfd6e7348e
Author: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
Date:   Thu Oct 25 19:10:36 2018 +0900

    panic: avoid deadlocks in re-entrant console drivers
    
    From printk()/serial console point of view panic() is special, because
    it may force CPU to re-enter printk() or/and serial console driver.
    Therefore, some of serial consoles drivers are re-entrant. E.g. 8250:
    
    serial8250_console_write()
    {
            if (port->sysrq)
                    locked = 0;
            else if (oops_in_progress)
                    locked = spin_trylock_irqsave(&port->lock, flags);
            else
                    spin_lock_irqsave(&port->lock, flags);
            ...
    }
    
    panic() does set oops_in_progress via bust_spinlocks(1), so in theory
    we should be able to re-enter serial console driver from panic():
    
            CPU0
            <NMI>
            uart_console_write()
            serial8250_console_write()              // if (oops_in_progress)
                                                    //    spin_trylock_irqsave()
            call_console_drivers()
            console_unlock()
            console_flush_on_panic()
            bust_spinlocks(1)                       // oops_in_progress++
            panic()
            <NMI/>
            spin_lock_irqsave(&port->lock, flags)   // spin_lock_irqsave()
            serial8250_console_write()
            call_console_drivers()
            console_unlock()
            printk()
            ...
    
    However, this does not happen and we deadlock in serial console on
    port->lock spinlock. And the problem is that console_flush_on_panic()
    called after bust_spinlocks(0):
    
    void panic(const char *fmt, ...)
    {
            bust_spinlocks(1);
            ...
            bust_spinlocks(0);
            console_flush_on_panic();
            ...
    }
    
    bust_spinlocks(0) decrements oops_in_progress, so oops_in_progress
    can go back to zero. Thus even re-entrant console drivers will simply
    spin on port->lock spinlock. Given that port->lock may already be
    locked either by a stopped CPU, or by the very same CPU we execute
    panic() on (for instance, NMI panic() on printing CPU) the system
    deadlocks and does not reboot.
    
    Fix this by removing bust_spinlocks(0), so oops_in_progress is always
    set in panic() now and, thus, re-entrant console drivers will trylock
    the port->lock instead of spinning on it forever, when we call them
    from console_flush_on_panic().
    
    Link: http://lkml.kernel.org/r/20181025101036.6823-1-sergey.senozhatsky@gmail.com
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Daniel Wang <wonderfly@google.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Alan Cox <gnomes@lxorguk.ukuu.org.uk>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: Peter Feiner <pfeiner@google.com>
    Cc: linux-serial@vger.kernel.org
    Cc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sergey Senozhatsky <sergey.senozhatsky@gmail.com>
    Signed-off-by: Petr Mladek <pmladek@suse.com>

commit 31568ec09ea02a050249921698c9729419539cce
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Mon Nov 5 03:44:11 2018 +0900

    netfilter: nf_conncount: fix list_del corruption in conn_free
    
    nf_conncount_tuple is an element of nft_connlimit and that is deleted by
    conn_free(). Elements can be deleted by both GC routine and data path
    functions (nf_conncount_lookup, nf_conncount_add) and they call
    conn_free() to free elements. But conn_free() only protects lists, not
    each element. So that list_del corruption could occurred.
    
    The conn_free() doesn't check whether element is already deleted. In
    order to protect elements, dead flag is added. If an element is deleted,
    dead flag is set. The only conn_free() can delete elements so that both
    list lock and dead flag are enough to protect it.
    
    test commands:
       %nft add table ip filter
       %nft add chain ip filter input { type filter hook input priority 0\; }
       %nft add rule filter input meter test { ip id ct count over 2 } counter
    
    splat looks like:
    [ 1779.495778] list_del corruption, ffff8800b6e12008->prev is LIST_POISON2 (dead000000000200)
    [ 1779.505453] ------------[ cut here ]------------
    [ 1779.506260] kernel BUG at lib/list_debug.c:50!
    [ 1779.515831] invalid opcode: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [ 1779.516772] CPU: 0 PID: 33 Comm: kworker/0:2 Not tainted 4.19.0-rc6+ #22
    [ 1779.516772] Workqueue: events_power_efficient nft_rhash_gc [nf_tables_set]
    [ 1779.516772] RIP: 0010:__list_del_entry_valid+0xd8/0x150
    [ 1779.516772] Code: 39 48 83 c4 08 b8 01 00 00 00 5b 5d c3 48 89 ea 48 c7 c7 00 c3 5b 98 e8 0f dc 40 ff 0f 0b 48 c7 c7 60 c3 5b 98 e8 01 dc 40 ff <0f> 0b 48 c7 c7 c0 c3 5b 98 e8 f3 db 40 ff 0f 0b 48 c7 c7 20 c4 5b
    [ 1779.516772] RSP: 0018:ffff880119127420 EFLAGS: 00010286
    [ 1779.516772] RAX: 000000000000004e RBX: dead000000000200 RCX: 0000000000000000
    [ 1779.516772] RDX: 000000000000004e RSI: 0000000000000008 RDI: ffffed0023224e7a
    [ 1779.516772] RBP: ffff88011934bc10 R08: ffffed002367cea9 R09: ffffed002367cea9
    [ 1779.516772] R10: 0000000000000001 R11: ffffed002367cea8 R12: ffff8800b6e12008
    [ 1779.516772] R13: ffff8800b6e12010 R14: ffff88011934bc20 R15: ffff8800b6e12008
    [ 1779.516772] FS:  0000000000000000(0000) GS:ffff88011b200000(0000) knlGS:0000000000000000
    [ 1779.516772] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 1779.516772] CR2: 00007fc876534010 CR3: 000000010da16000 CR4: 00000000001006f0
    [ 1779.516772] Call Trace:
    [ 1779.516772]  conn_free+0x9f/0x2b0 [nf_conncount]
    [ 1779.516772]  ? nf_ct_tmpl_alloc+0x2a0/0x2a0 [nf_conntrack]
    [ 1779.516772]  ? nf_conncount_add+0x520/0x520 [nf_conncount]
    [ 1779.516772]  ? do_raw_spin_trylock+0x1a0/0x1a0
    [ 1779.516772]  ? do_raw_spin_trylock+0x10/0x1a0
    [ 1779.516772]  find_or_evict+0xe5/0x150 [nf_conncount]
    [ 1779.516772]  nf_conncount_gc_list+0x162/0x360 [nf_conncount]
    [ 1779.516772]  ? nf_conncount_lookup+0xee0/0xee0 [nf_conncount]
    [ 1779.516772]  ? _raw_spin_unlock_irqrestore+0x45/0x50
    [ 1779.516772]  ? trace_hardirqs_off+0x6b/0x220
    [ 1779.516772]  ? trace_hardirqs_on_caller+0x220/0x220
    [ 1779.516772]  nft_rhash_gc+0x16b/0x540 [nf_tables_set]
    [ ... ]
    
    Fixes: 5c789e131cbb ("netfilter: nf_conncount: Add list lock and gc worker, and RCU for init tree search")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 8d3156b3c109dbceea5ece40cfb74b3a22ee2fb1
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Thu Aug 30 17:56:52 2018 +0900

    netfilter: nft_set_rbtree: add missing rb_erase() in GC routine
    
    [ Upstream commit a13f814a67b12a2f29d1decf4b4f4e700658a517 ]
    
    The nft_set_gc_batch_check() checks whether gc buffer is full.
    If gc buffer is full, gc buffer is released by
    the nft_set_gc_batch_complete() internally.
    In case of rbtree, the rb_erase() should be called before calling the
    nft_set_gc_batch_complete(). therefore the rb_erase() should
    be called before calling the nft_set_gc_batch_check() too.
    
    test commands:
       table ip filter {
               set set1 {
                       type ipv4_addr; flags interval, timeout;
                       gc-interval 10s;
                       timeout 1s;
                       elements = {
                               1-2,
                               3-4,
                               5-6,
                               ...
                               10000-10001,
                       }
               }
       }
       %nft -f test.nft
    
    splat looks like:
    [  430.273885] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [  430.282158] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [  430.283116] CPU: 1 PID: 190 Comm: kworker/1:2 Tainted: G    B             4.18.0+ #7
    [  430.283116] Workqueue: events_power_efficient nft_rbtree_gc [nf_tables_set]
    [  430.313559] RIP: 0010:rb_next+0x81/0x130
    [  430.313559] Code: 08 49 bd 00 00 00 00 00 fc ff df 48 bb 00 00 00 00 00 fc ff df 48 85 c0 75 05 eb 58 48 89 d4
    [  430.313559] RSP: 0018:ffff88010cdb7680 EFLAGS: 00010207
    [  430.313559] RAX: 0000000000b84854 RBX: dffffc0000000000 RCX: ffffffff83f01973
    [  430.313559] RDX: 000000000017090c RSI: 0000000000000008 RDI: 0000000000b84864
    [  430.313559] RBP: ffff8801060d4588 R08: fffffbfff09bc349 R09: fffffbfff09bc349
    [  430.313559] R10: 0000000000000001 R11: fffffbfff09bc348 R12: ffff880100f081a8
    [  430.313559] R13: dffffc0000000000 R14: ffff880100ff8688 R15: dffffc0000000000
    [  430.313559] FS:  0000000000000000(0000) GS:ffff88011b400000(0000) knlGS:0000000000000000
    [  430.313559] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  430.313559] CR2: 0000000001551008 CR3: 000000005dc16000 CR4: 00000000001006e0
    [  430.313559] Call Trace:
    [  430.313559]  nft_rbtree_gc+0x112/0x5c0 [nf_tables_set]
    [  430.313559]  process_one_work+0xc13/0x1ec0
    [  430.313559]  ? _raw_spin_unlock_irq+0x29/0x40
    [  430.313559]  ? pwq_dec_nr_in_flight+0x3c0/0x3c0
    [  430.313559]  ? set_load_weight+0x270/0x270
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __schedule+0x6d3/0x1f50
    [  430.313559]  ? find_held_lock+0x39/0x1c0
    [  430.313559]  ? __sched_text_start+0x8/0x8
    [  430.313559]  ? cyc2ns_read_end+0x10/0x10
    [  430.313559]  ? save_trace+0x300/0x300
    [  430.313559]  ? sched_clock_local+0xd4/0x140
    [  430.313559]  ? find_held_lock+0x39/0x1c0
    [  430.313559]  ? worker_thread+0x353/0x1120
    [  430.313559]  ? worker_thread+0x353/0x1120
    [  430.313559]  ? lock_contended+0xe70/0xe70
    [  430.313559]  ? __lock_acquire+0x4500/0x4500
    [  430.535635]  ? do_raw_spin_unlock+0xa5/0x330
    [  430.535635]  ? do_raw_spin_trylock+0x101/0x1a0
    [  430.535635]  ? do_raw_spin_lock+0x1f0/0x1f0
    [  430.535635]  ? _raw_spin_lock_irq+0x10/0x70
    [  430.535635]  worker_thread+0x15d/0x1120
    [ ... ]
    
    Fixes: 8d8540c4f5e0 ("netfilter: nft_set_rbtree: add timeout support")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 5bd4af34a09a381a0f8b1552684650698937e6b0
Merge: 738b04fba18d 59eaeba63a17
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Mon Oct 29 10:42:20 2018 -0700

    Merge tag 'tty-4.20-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty
    
    Pull tty/serial updates from Greg KH:
     "Here is the big tty and serial pull request for 4.20-rc1
    
      Lots of little things here, including a merge from the SPI tree in
      order to keep things simpler for everyone to sync around for one
      platform.
    
      Major stuff is:
    
       - tty buffer clearing after use
    
       - atmel_serial fixes and additions
    
       - xilinx uart driver updates
    
      and of course, lots of tiny fixes and additions to individual serial
      drivers.
    
      All of these have been in linux-next with no reported issues for a
      while"
    
    * tag 'tty-4.20-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/tty: (66 commits)
      of: base: Change logic in of_alias_get_alias_list()
      of: base: Fix english spelling in of_alias_get_alias_list()
      serial: sh-sci: do not warn if DMA transfers are not supported
      serial: uartps: Do not allow use aliases >= MAX_UART_INSTANCES
      tty: check name length in tty_find_polling_driver()
      serial: sh-sci: Add r8a77990 support
      tty: wipe buffer if not echoing data
      tty: wipe buffer.
      serial: fsl_lpuart: Remove the alias node dependence
      TTY: sn_console: Replace spin_is_locked() with spin_trylock()
      Revert "serial:serial_core: Allow use of CTS for PPS line discipline"
      serial: 8250_uniphier: add auto-flow-control support
      serial: 8250_uniphier: flatten probe function
      serial: 8250_uniphier: remove unused "fifo-size" property
      dt-bindings: serial: sh-sci: Document r8a7744 bindings
      serial: uartps: Fix missing unlock on error in cdns_get_id()
      tty/serial: atmel: add ISO7816 support
      tty/serial_core: add ISO7816 infrastructure
      serial:serial_core: Allow use of CTS for PPS line discipline
      serial: docs: Fix filename for serial reference implementation
      ...

commit 8be673735e5144e13fe739fba5a0a33fc50f3a16
Merge: 1df377db3d01 37355bdc5a12
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Fri Oct 5 15:39:38 2018 -0700

    Merge branch 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    Ingo writes:
      "scheduler fixes:
    
       These fixes address a rather involved performance regression between
       v4.17->v4.19 in the sched/numa auto-balancing code. Since distros
       really need this fix we accelerated it to sched/urgent for a faster
       upstream merge.
    
       NUMA scheduling and balancing performance is now largely back to
       v4.17 levels, without reintroducing the NUMA placement bugs that
       v4.18 and v4.19 fixed.
    
       Many thanks to Srikar Dronamraju, Mel Gorman and Jirka Hladky, for
       reporting, testing, re-testing and solving this rather complex set of
       bugs."
    
    * 'sched-urgent-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      sched/numa: Migrate pages to local nodes quicker early in the lifetime of a task
      mm, sched/numa: Remove rate-limiting of automatic NUMA balancing migration
      sched/numa: Avoid task migration for small NUMA improvement
      mm/migrate: Use spin_trylock() while resetting rate limit
      sched/numa: Limit the conditions where scan period is reset
      sched/numa: Reset scan rate whenever task moves across nodes
      sched/numa: Pass destination CPU as a parameter to migrate_task_rq
      sched/numa: Stop multiple tasks from moving to the CPU at the same time

commit 9a694c1de396e24565bfd05d0e36f72d10c3bce2
Author: Lance Roy <ldr709@gmail.com>
Date:   Thu Oct 4 00:46:57 2018 -0700

    atm: nicstar: Replace spin_is_locked() with spin_trylock()
    
    ns_poll() used spin_is_locked() + spin_lock() to get achieve the same
    thing as a spin_trylock(), so simplify it by using that instead. This is
    also a step towards possibly removing spin_is_locked().
    
    Signed-off-by: Lance Roy <ldr709@gmail.com>
    Cc: Chas Williams <3chas3@gmail.com>
    Cc: <linux-atm-general@lists.sourceforge.net>
    Cc: <netdev@vger.kernel.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 8ebfe885c65ec82a0b1e955cf99ed62664e84414
Author: Lance Roy <ldr709@gmail.com>
Date:   Thu Oct 4 00:14:04 2018 -0700

    TTY: sn_console: Replace spin_is_locked() with spin_trylock()
    
    sn_sal_console_write() used spin_is_locked() + spin_lock() to get
    achieve the same thing as a spin_trylock(), so simplify it by using that
    instead. This is also a step towards possibly removing spin_is_locked().
    
    Signed-off-by: Lance Roy <ldr709@gmail.com>
    Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Cc: Jiri Slaby <jslaby@suse.com>
    Cc: <linux-serial@vger.kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7534612123e0f5d020aba1076a6bb505db0e6bfe
Author: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
Date:   Fri Sep 21 23:19:00 2018 +0530

    mm/migrate: Use spin_trylock() while resetting rate limit
    
    Since this spinlock will only serialize the migrate rate limiting,
    convert the spin_lock() to a spin_trylock(). If another thread is updating, this
    task can move on.
    
    Specjbb2005 results (8 warehouses)
    Higher bops are better
    
    2 Socket - 2  Node Haswell - X86
    JVMS  Prev    Current  %Change
    4     205332  198512   -3.32145
    1     319785  313559   -1.94693
    
    2 Socket - 4 Node Power8 - PowerNV
    JVMS  Prev    Current  %Change
    8     74912   74761.9  -0.200368
    1     206585  214874   4.01239
    
    2 Socket - 2  Node Power9 - PowerNV
    JVMS  Prev    Current  %Change
    4     189162  180536   -4.56011
    1     213760  210281   -1.62753
    
    4 Socket - 4  Node Power7 - PowerVM
    JVMS  Prev     Current  %Change
    8     58736.8  56511.4  -3.78877
    1     105419   104899   -0.49327
    
    Avoiding stretching of window intervals may be the reason for the
    regression. Also code now uses READ_ONCE/WRITE_ONCE. That may
    also be hurting performance to some extent.
    
    Some events stats before and after applying the patch.
    
    perf stats 8th warehouse Multi JVM 2 Socket - 2  Node Haswell - X86
    Event                     Before          After
    cs                        14,285,708      13,818,546
    migrations                1,180,621       1,149,960
    faults                    339,114         385,583
    cache-misses              55,205,631,894  55,259,546,768
    sched:sched_move_numa     843             2,257
    sched:sched_stick_numa    6               9
    sched:sched_swap_numa     219             512
    migrate:mm_migrate_pages  365             2,225
    
    vmstat 8th warehouse Multi JVM 2 Socket - 2  Node Haswell - X86
    Event                   Before  After
    numa_hint_faults        26907   72692
    numa_hint_faults_local  24279   62270
    numa_hit                239771  238762
    numa_huge_pte_updates   0       48
    numa_interleave         68      75
    numa_local              239688  238676
    numa_other              83      86
    numa_pages_migrated     363     2225
    numa_pte_updates        27415   98557
    
    perf stats 8th warehouse Single JVM 2 Socket - 2  Node Haswell - X86
    Event                     Before          After
    cs                        3,202,779       3,173,490
    migrations                37,186          36,966
    faults                    106,076         108,776
    cache-misses              12,024,873,744  12,200,075,320
    sched:sched_move_numa     931             1,264
    sched:sched_stick_numa    0               0
    sched:sched_swap_numa     1               0
    migrate:mm_migrate_pages  637             899
    
    vmstat 8th warehouse Single JVM 2 Socket - 2  Node Haswell - X86
    Event                   Before  After
    numa_hint_faults        17409   21109
    numa_hint_faults_local  14367   17120
    numa_hit                73953   72934
    numa_huge_pte_updates   20      42
    numa_interleave         25      33
    numa_local              73892   72866
    numa_other              61      68
    numa_pages_migrated     668     915
    numa_pte_updates        27276   42326
    
    perf stats 8th warehouse Multi JVM 2 Socket - 2  Node Power9 - PowerNV
    Event                     Before       After
    cs                        8,474,013    8,312,022
    migrations                254,934      231,705
    faults                    320,506      310,242
    cache-misses              110,580,458  402,324,573
    sched:sched_move_numa     725          193
    sched:sched_stick_numa    0            0
    sched:sched_swap_numa     7            3
    migrate:mm_migrate_pages  145          93
    
    vmstat 8th warehouse Multi JVM 2 Socket - 2  Node Power9 - PowerNV
    Event                   Before  After
    numa_hint_faults        22797   11838
    numa_hint_faults_local  21539   11216
    numa_hit                89308   90689
    numa_huge_pte_updates   0       0
    numa_interleave         865     1579
    numa_local              88955   89634
    numa_other              353     1055
    numa_pages_migrated     149     92
    numa_pte_updates        22930   12109
    
    perf stats 8th warehouse Single JVM 2 Socket - 2  Node Power9 - PowerNV
    Event                     Before     After
    cs                        2,195,628  2,170,481
    migrations                11,179     10,126
    faults                    149,656    160,962
    cache-misses              8,117,515  10,834,845
    sched:sched_move_numa     49         10
    sched:sched_stick_numa    0          0
    sched:sched_swap_numa     0          0
    migrate:mm_migrate_pages  5          2
    
    vmstat 8th warehouse Single JVM 2 Socket - 2  Node Power9 - PowerNV
    Event                   Before  After
    numa_hint_faults        3577    403
    numa_hint_faults_local  3476    358
    numa_hit                26142   25898
    numa_huge_pte_updates   0       0
    numa_interleave         358     207
    numa_local              26042   25860
    numa_other              100     38
    numa_pages_migrated     5       2
    numa_pte_updates        3587    400
    
    perf stats 8th warehouse Multi JVM 4 Socket - 4  Node Power7 - PowerVM
    Event                     Before           After
    cs                        100,602,296      110,339,633
    migrations                4,135,630        4,139,812
    faults                    789,256          863,622
    cache-misses              226,160,621,058  231,838,045,660
    sched:sched_move_numa     1,366            2,196
    sched:sched_stick_numa    16               33
    sched:sched_swap_numa     374              544
    migrate:mm_migrate_pages  1,350            2,469
    
    vmstat 8th warehouse Multi JVM 4 Socket - 4  Node Power7 - PowerVM
    Event                   Before  After
    numa_hint_faults        47857   85748
    numa_hint_faults_local  39768   66831
    numa_hit                240165  242213
    numa_huge_pte_updates   0       0
    numa_interleave         0       0
    numa_local              240165  242211
    numa_other              0       2
    numa_pages_migrated     1224    2376
    numa_pte_updates        48354   86233
    
    perf stats 8th warehouse Single JVM 4 Socket - 4  Node Power7 - PowerVM
    Event                     Before          After
    cs                        58,515,496      59,331,057
    migrations                564,845         552,019
    faults                    245,807         266,586
    cache-misses              73,603,757,976  73,796,312,990
    sched:sched_move_numa     996             981
    sched:sched_stick_numa    10              54
    sched:sched_swap_numa     193             286
    migrate:mm_migrate_pages  646             713
    
    vmstat 8th warehouse Single JVM 4 Socket - 4  Node Power7 - PowerVM
    Event                   Before  After
    numa_hint_faults        13422   14807
    numa_hint_faults_local  5619    5738
    numa_hit                36118   36230
    numa_huge_pte_updates   0       0
    numa_interleave         0       0
    numa_local              36116   36228
    numa_other              2       2
    numa_pages_migrated     616     703
    numa_pte_updates        13374   14742
    
    Suggested-by: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Jirka Hladky <jhladky@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Mel Gorman <mgorman@techsingularity.net>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Rik van Riel <riel@surriel.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/1537552141-27815-6-git-send-email-srikar@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit a13f814a67b12a2f29d1decf4b4f4e700658a517
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Thu Aug 30 17:56:52 2018 +0900

    netfilter: nft_set_rbtree: add missing rb_erase() in GC routine
    
    The nft_set_gc_batch_check() checks whether gc buffer is full.
    If gc buffer is full, gc buffer is released by
    the nft_set_gc_batch_complete() internally.
    In case of rbtree, the rb_erase() should be called before calling the
    nft_set_gc_batch_complete(). therefore the rb_erase() should
    be called before calling the nft_set_gc_batch_check() too.
    
    test commands:
       table ip filter {
               set set1 {
                       type ipv4_addr; flags interval, timeout;
                       gc-interval 10s;
                       timeout 1s;
                       elements = {
                               1-2,
                               3-4,
                               5-6,
                               ...
                               10000-10001,
                       }
               }
       }
       %nft -f test.nft
    
    splat looks like:
    [  430.273885] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [  430.282158] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [  430.283116] CPU: 1 PID: 190 Comm: kworker/1:2 Tainted: G    B             4.18.0+ #7
    [  430.283116] Workqueue: events_power_efficient nft_rbtree_gc [nf_tables_set]
    [  430.313559] RIP: 0010:rb_next+0x81/0x130
    [  430.313559] Code: 08 49 bd 00 00 00 00 00 fc ff df 48 bb 00 00 00 00 00 fc ff df 48 85 c0 75 05 eb 58 48 89 d4
    [  430.313559] RSP: 0018:ffff88010cdb7680 EFLAGS: 00010207
    [  430.313559] RAX: 0000000000b84854 RBX: dffffc0000000000 RCX: ffffffff83f01973
    [  430.313559] RDX: 000000000017090c RSI: 0000000000000008 RDI: 0000000000b84864
    [  430.313559] RBP: ffff8801060d4588 R08: fffffbfff09bc349 R09: fffffbfff09bc349
    [  430.313559] R10: 0000000000000001 R11: fffffbfff09bc348 R12: ffff880100f081a8
    [  430.313559] R13: dffffc0000000000 R14: ffff880100ff8688 R15: dffffc0000000000
    [  430.313559] FS:  0000000000000000(0000) GS:ffff88011b400000(0000) knlGS:0000000000000000
    [  430.313559] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  430.313559] CR2: 0000000001551008 CR3: 000000005dc16000 CR4: 00000000001006e0
    [  430.313559] Call Trace:
    [  430.313559]  nft_rbtree_gc+0x112/0x5c0 [nf_tables_set]
    [  430.313559]  process_one_work+0xc13/0x1ec0
    [  430.313559]  ? _raw_spin_unlock_irq+0x29/0x40
    [  430.313559]  ? pwq_dec_nr_in_flight+0x3c0/0x3c0
    [  430.313559]  ? set_load_weight+0x270/0x270
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __switch_to_asm+0x40/0x70
    [  430.313559]  ? __switch_to_asm+0x34/0x70
    [  430.313559]  ? __schedule+0x6d3/0x1f50
    [  430.313559]  ? find_held_lock+0x39/0x1c0
    [  430.313559]  ? __sched_text_start+0x8/0x8
    [  430.313559]  ? cyc2ns_read_end+0x10/0x10
    [  430.313559]  ? save_trace+0x300/0x300
    [  430.313559]  ? sched_clock_local+0xd4/0x140
    [  430.313559]  ? find_held_lock+0x39/0x1c0
    [  430.313559]  ? worker_thread+0x353/0x1120
    [  430.313559]  ? worker_thread+0x353/0x1120
    [  430.313559]  ? lock_contended+0xe70/0xe70
    [  430.313559]  ? __lock_acquire+0x4500/0x4500
    [  430.535635]  ? do_raw_spin_unlock+0xa5/0x330
    [  430.535635]  ? do_raw_spin_trylock+0x101/0x1a0
    [  430.535635]  ? do_raw_spin_lock+0x1f0/0x1f0
    [  430.535635]  ? _raw_spin_lock_irq+0x10/0x70
    [  430.535635]  worker_thread+0x15d/0x1120
    [ ... ]
    
    Fixes: 8d8540c4f5e0 ("netfilter: nft_set_rbtree: add timeout support")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 70cc08c44fb55b587c7485a15549e9f9a12c9405
Author: Prateek Sood <prsood@codeaurora.org>
Date:   Thu Sep 7 20:00:58 2017 +0530

    locking/rwsem-xadd: Fix missed wakeup due to reordering of load
    
    commit 9c29c31830a4eca724e137a9339137204bbb31be upstream.
    
    If a spinner is present, there is a chance that the load of
    rwsem_has_spinner() in rwsem_wake() can be reordered with
    respect to decrement of rwsem count in __up_write() leading
    to wakeup being missed:
    
     spinning writer                  up_write caller
     ---------------                  -----------------------
     [S] osq_unlock()                 [L] osq
      spin_lock(wait_lock)
      sem->count=0xFFFFFFFF00000001
                +0xFFFFFFFF00000000
      count=sem->count
      MB
                                       sem->count=0xFFFFFFFE00000001
                                                 -0xFFFFFFFF00000001
                                       spin_trylock(wait_lock)
                                       return
     rwsem_try_write_lock(count)
     spin_unlock(wait_lock)
     schedule()
    
    Reordering of atomic_long_sub_return_release() in __up_write()
    and rwsem_has_spinner() in rwsem_wake() can cause missing of
    wakeup in up_write() context. In spinning writer, sem->count
    and local variable count is 0XFFFFFFFE00000001. It would result
    in rwsem_try_write_lock() failing to acquire rwsem and spinning
    writer going to sleep in rwsem_down_write_failed().
    
    The smp_rmb() will make sure that the spinner state is
    consulted after sem->count is updated in up_write context.
    
    Signed-off-by: Prateek Sood <prsood@codeaurora.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: dave@stgolabs.net
    Cc: longman@redhat.com
    Cc: parri.andrea@gmail.com
    Cc: sramana@codeaurora.org
    Link: http://lkml.kernel.org/r/1504794658-15397-1-git-send-email-prsood@codeaurora.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0cbde6c5b67307f353636f8074881fb4d1924709
Author: Prateek Sood <prsood@codeaurora.org>
Date:   Thu Sep 7 20:00:58 2017 +0530

    locking/rwsem-xadd: Fix missed wakeup due to reordering of load
    
    commit 9c29c31830a4eca724e137a9339137204bbb31be upstream.
    
    If a spinner is present, there is a chance that the load of
    rwsem_has_spinner() in rwsem_wake() can be reordered with
    respect to decrement of rwsem count in __up_write() leading
    to wakeup being missed:
    
     spinning writer                  up_write caller
     ---------------                  -----------------------
     [S] osq_unlock()                 [L] osq
      spin_lock(wait_lock)
      sem->count=0xFFFFFFFF00000001
                +0xFFFFFFFF00000000
      count=sem->count
      MB
                                       sem->count=0xFFFFFFFE00000001
                                                 -0xFFFFFFFF00000001
                                       spin_trylock(wait_lock)
                                       return
     rwsem_try_write_lock(count)
     spin_unlock(wait_lock)
     schedule()
    
    Reordering of atomic_long_sub_return_release() in __up_write()
    and rwsem_has_spinner() in rwsem_wake() can cause missing of
    wakeup in up_write() context. In spinning writer, sem->count
    and local variable count is 0XFFFFFFFE00000001. It would result
    in rwsem_try_write_lock() failing to acquire rwsem and spinning
    writer going to sleep in rwsem_down_write_failed().
    
    The smp_rmb() will make sure that the spinner state is
    consulted after sem->count is updated in up_write context.
    
    Signed-off-by: Prateek Sood <prsood@codeaurora.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: dave@stgolabs.net
    Cc: longman@redhat.com
    Cc: parri.andrea@gmail.com
    Cc: sramana@codeaurora.org
    Link: http://lkml.kernel.org/r/1504794658-15397-1-git-send-email-prsood@codeaurora.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Amit Pundir <amit.pundir@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c293ac959f809ee1cd31609d9e62bccf6804b2e6
Author: Taehee Yoo <ap420073@gmail.com>
Date:   Tue Jul 10 23:22:01 2018 +0900

    netfilter: nft_set_rbtree: fix panic when destroying set by GC
    
    This patch fixes below.
    1. check null pointer of rb_next.
     rb_next can return null. so null check routine should be added.
    2. add rcu_barrier in destroy routine.
     GC uses call_rcu to remove elements. but all elements should be
     removed before destroying set and chains. so that rcu_barrier is added.
    
    test script:
       %cat test.nft
       table inet aa {
               map map1 {
                       type ipv4_addr : verdict; flags interval, timeout;
                       elements = {
                               0-1 : jump a0,
                               3-4 : jump a0,
                               6-7 : jump a0,
                               9-10 : jump a0,
                               12-13 : jump a0,
                               15-16 : jump a0,
                               18-19 : jump a0,
                               21-22 : jump a0,
                               24-25 : jump a0,
                               27-28 : jump a0,
                       }
                       timeout 1s;
               }
               chain a0 {
               }
       }
       flush ruleset
       table inet aa {
               map map1 {
                       type ipv4_addr : verdict; flags interval, timeout;
                       elements = {
                               0-1 : jump a0,
                               3-4 : jump a0,
                               6-7 : jump a0,
                               9-10 : jump a0,
                               12-13 : jump a0,
                               15-16 : jump a0,
                               18-19 : jump a0,
                               21-22 : jump a0,
                               24-25 : jump a0,
                               27-28 : jump a0,
                       }
                       timeout 1s;
               }
               chain a0 {
               }
       }
       flush ruleset
    
    splat looks like:
    [ 2402.419838] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [ 2402.428433] general protection fault: 0000 [#1] SMP DEBUG_PAGEALLOC KASAN PTI
    [ 2402.429343] CPU: 1 PID: 1350 Comm: kworker/1:1 Not tainted 4.18.0-rc2+ #1
    [ 2402.429343] Hardware name: To be filled by O.E.M. To be filled by O.E.M./Aptio CRB, BIOS 5.6.5 03/23/2017
    [ 2402.429343] Workqueue: events_power_efficient nft_rbtree_gc [nft_set_rbtree]
    [ 2402.429343] RIP: 0010:rb_next+0x1e/0x130
    [ 2402.429343] Code: e9 de f2 ff ff 0f 1f 80 00 00 00 00 41 55 48 89 fa 41 54 55 53 48 c1 ea 03 48 b8 00 00 00 0
    [ 2402.429343] RSP: 0018:ffff880105f77678 EFLAGS: 00010296
    [ 2402.429343] RAX: dffffc0000000000 RBX: ffff8801143e3428 RCX: 1ffff1002287c69c
    [ 2402.429343] RDX: 0000000000000000 RSI: 0000000000000004 RDI: 0000000000000000
    [ 2402.429343] RBP: 0000000000000000 R08: ffffed0016aabc24 R09: ffffed0016aabc24
    [ 2402.429343] R10: 0000000000000001 R11: ffffed0016aabc23 R12: 0000000000000000
    [ 2402.429343] R13: ffff8800b6933388 R14: dffffc0000000000 R15: ffff8801143e3440
    [ 2402.534486] kasan: CONFIG_KASAN_INLINE enabled
    [ 2402.534212] FS:  0000000000000000(0000) GS:ffff88011b600000(0000) knlGS:0000000000000000
    [ 2402.534212] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [ 2402.534212] CR2: 0000000000863008 CR3: 00000000a3c16000 CR4: 00000000001006e0
    [ 2402.534212] Call Trace:
    [ 2402.534212]  nft_rbtree_gc+0x2b5/0x5f0 [nft_set_rbtree]
    [ 2402.534212]  process_one_work+0xc1b/0x1ee0
    [ 2402.540329] kasan: GPF could be caused by NULL-ptr deref or user memory access
    [ 2402.534212]  ? _raw_spin_unlock_irq+0x29/0x40
    [ 2402.534212]  ? pwq_dec_nr_in_flight+0x3e0/0x3e0
    [ 2402.534212]  ? set_load_weight+0x270/0x270
    [ 2402.534212]  ? __schedule+0x6ea/0x1fb0
    [ 2402.534212]  ? __sched_text_start+0x8/0x8
    [ 2402.534212]  ? save_trace+0x320/0x320
    [ 2402.534212]  ? sched_clock_local+0xe2/0x150
    [ 2402.534212]  ? find_held_lock+0x39/0x1c0
    [ 2402.534212]  ? worker_thread+0x35f/0x1150
    [ 2402.534212]  ? lock_contended+0xe90/0xe90
    [ 2402.534212]  ? __lock_acquire+0x4520/0x4520
    [ 2402.534212]  ? do_raw_spin_unlock+0xb1/0x350
    [ 2402.534212]  ? do_raw_spin_trylock+0x111/0x1b0
    [ 2402.534212]  ? do_raw_spin_lock+0x1f0/0x1f0
    [ 2402.534212]  worker_thread+0x169/0x1150
    
    Fixes: 8d8540c4f5e0("netfilter: nft_set_rbtree: add timeout support")
    Signed-off-by: Taehee Yoo <ap420073@gmail.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>

commit 68d2f84a1368cc5d4ccbbbfc6821f159d27681c9
Author: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
Date:   Thu Jul 12 16:24:59 2018 +0900

    net: gro: properly remove skb from list
    
    Following crash occurs in validate_xmit_skb_list() when same skb is
    iterated multiple times in the loop and consume_skb() is called.
    
    The root cause is calling list_del_init(&skb->list) and not clearing
    skb->next in d4546c2509b1. list_del_init(&skb->list) sets skb->next
    to point to skb itself. skb->next needs to be cleared because other
    parts of network stack uses another kind of SKB lists.
    validate_xmit_skb_list() uses such list.
    
    A similar type of bugfix was reported by Jesper Dangaard Brouer.
    https://patchwork.ozlabs.org/patch/942541/
    
    This patch clears skb->next and changes list_del_init() to list_del()
    so that list->prev will maintain the list poison.
    
    [  148.185511] ==================================================================
    [  148.187865] BUG: KASAN: use-after-free in validate_xmit_skb_list+0x4b/0xa0
    [  148.190158] Read of size 8 at addr ffff8801e52eefc0 by task swapper/1/0
    [  148.192940]
    [  148.193642] CPU: 1 PID: 0 Comm: swapper/1 Not tainted 4.18.0-rc3+ #25
    [  148.195423] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS ?-20180531_142017-buildhw-08.phx2.fedoraproject.org-1.fc28 04/01/2014
    [  148.199129] Call Trace:
    [  148.200565]  <IRQ>
    [  148.201911]  dump_stack+0xc6/0x14c
    [  148.203572]  ? dump_stack_print_info.cold.1+0x2f/0x2f
    [  148.205083]  ? kmsg_dump_rewind_nolock+0x59/0x59
    [  148.206307]  ? validate_xmit_skb+0x2c6/0x560
    [  148.207432]  ? debug_show_held_locks+0x30/0x30
    [  148.208571]  ? validate_xmit_skb_list+0x4b/0xa0
    [  148.211144]  print_address_description+0x6c/0x23c
    [  148.212601]  ? validate_xmit_skb_list+0x4b/0xa0
    [  148.213782]  kasan_report.cold.6+0x241/0x2fd
    [  148.214958]  validate_xmit_skb_list+0x4b/0xa0
    [  148.216494]  sch_direct_xmit+0x1b0/0x680
    [  148.217601]  ? dev_watchdog+0x4e0/0x4e0
    [  148.218675]  ? do_raw_spin_trylock+0x10/0x120
    [  148.219818]  ? do_raw_spin_lock+0xe0/0xe0
    [  148.221032]  __dev_queue_xmit+0x1167/0x1810
    [  148.222155]  ? sched_clock+0x5/0x10
    [...]
    
    [  148.474257] Allocated by task 0:
    [  148.475363]  kasan_kmalloc+0xbf/0xe0
    [  148.476503]  kmem_cache_alloc+0xb4/0x1b0
    [  148.477654]  __build_skb+0x91/0x250
    [  148.478677]  build_skb+0x67/0x180
    [  148.479657]  e1000_clean_rx_irq+0x542/0x8a0
    [  148.480757]  e1000_clean+0x652/0xd10
    [  148.481772]  net_rx_action+0x4ea/0xc20
    [  148.482808]  __do_softirq+0x1f9/0x574
    [  148.483831]
    [  148.484575] Freed by task 0:
    [  148.485504]  __kasan_slab_free+0x12e/0x180
    [  148.486589]  kmem_cache_free+0xb4/0x240
    [  148.487634]  kfree_skbmem+0xed/0x150
    [  148.488648]  consume_skb+0x146/0x250
    [  148.489665]  validate_xmit_skb+0x2b7/0x560
    [  148.490754]  validate_xmit_skb_list+0x70/0xa0
    [  148.491897]  sch_direct_xmit+0x1b0/0x680
    [  148.493949]  __dev_queue_xmit+0x1167/0x1810
    [  148.495103]  br_dev_queue_push_xmit+0xce/0x250
    [  148.496196]  br_forward_finish+0x276/0x280
    [  148.497234]  __br_forward+0x44f/0x520
    [  148.498260]  br_forward+0x19f/0x1b0
    [  148.499264]  br_handle_frame_finish+0x65e/0x980
    [  148.500398]  NF_HOOK.constprop.10+0x290/0x2a0
    [  148.501522]  br_handle_frame+0x417/0x640
    [  148.502582]  __netif_receive_skb_core+0xaac/0x18f0
    [  148.503753]  __netif_receive_skb_one_core+0x98/0x120
    [  148.504958]  netif_receive_skb_internal+0xe3/0x330
    [  148.506154]  napi_gro_complete+0x190/0x2a0
    [  148.507243]  dev_gro_receive+0x9f7/0x1100
    [  148.508316]  napi_gro_receive+0xcb/0x260
    [  148.509387]  e1000_clean_rx_irq+0x2fc/0x8a0
    [  148.510501]  e1000_clean+0x652/0xd10
    [  148.511523]  net_rx_action+0x4ea/0xc20
    [  148.512566]  __do_softirq+0x1f9/0x574
    [  148.513598]
    [  148.514346] The buggy address belongs to the object at ffff8801e52eefc0
    [  148.514346]  which belongs to the cache skbuff_head_cache of size 232
    [  148.517047] The buggy address is located 0 bytes inside of
    [  148.517047]  232-byte region [ffff8801e52eefc0, ffff8801e52ef0a8)
    [  148.519549] The buggy address belongs to the page:
    [  148.520726] page:ffffea000794bb00 count:1 mapcount:0 mapping:ffff880106f4dfc0 index:0xffff8801e52ee840 compound_mapcount: 0
    [  148.524325] flags: 0x17ffffc0008100(slab|head)
    [  148.525481] raw: 0017ffffc0008100 ffff880106b938d0 ffff880106b938d0 ffff880106f4dfc0
    [  148.527503] raw: ffff8801e52ee840 0000000000190011 00000001ffffffff 0000000000000000
    [  148.529547] page dumped because: kasan: bad access detected
    
    Fixes: d4546c2509b1 ("net: Convert GRO SKB handling to list_head.")
    Signed-off-by: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
    Reported-by: Tyler Hicks <tyhicks@canonical.com>
    Tested-by: Tyler Hicks <tyhicks@canonical.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 510e1e8020a8a1b7cf53a84f18a7d03757daba55
Author: Sebastian Ott <sebott@linux.ibm.com>
Date:   Tue May 15 14:05:13 2018 +0200

    s390/dasd: use blk_mq_rq_from_pdu for per request data
    
    [ Upstream commit f0f59a2fab8e52b9d582b39da39f22230ca80aee ]
    
    Dasd uses completion_data from struct request to store per request
    private data - this is problematic since this member is part of a
    union which is also used by IO schedulers.
    Let the block layer maintain space for per request data behind each
    struct request.
    
    Fixes crashes on block layer timeouts like this one:
    
    Unable to handle kernel pointer dereference in virtual kernel address space
    Failing address: 0000000000000000 TEID: 0000000000000483
    Fault in home space mode while using kernel ASCE.
    AS:0000000001308007 R3:00000000fffc8007 S:00000000fffcc000 P:000000000000013d
    Oops: 0004 ilc:2 [#1] PREEMPT SMP
    Modules linked in: [...]
    CPU: 0 PID: 1480 Comm: kworker/0:2H Not tainted 4.17.0-rc4-00046-gaa3bcd43b5af #203
    Hardware name: IBM 3906 M02 702 (LPAR)
    Workqueue: kblockd blk_mq_timeout_work
    Krnl PSW : 0000000067ac406b 00000000b6960308 (do_raw_spin_trylock+0x30/0x78)
               R:0 T:1 IO:0 EX:0 Key:0 M:1 W:0 P:0 AS:3 CC:2 PM:0 RI:0 EA:3
    Krnl GPRS: 0000000000000c00 0000000000000000 0000000000000000 0000000000000001
               0000000000b9d3c8 0000000000000000 0000000000000001 00000000cf9639d8
               0000000000000000 0700000000000000 0000000000000000 000000000099f09e
               0000000000000000 000000000076e9d0 000000006247bb08 000000006247bae0
    Krnl Code: 00000000001c159c: b90400c2           lgr     %r12,%r2
               00000000001c15a0: a7180000           lhi     %r1,0
              #00000000001c15a4: 583003a4           l       %r3,932
              >00000000001c15a8: ba132000           cs      %r1,%r3,0(%r2)
               00000000001c15ac: a7180001           lhi     %r1,1
               00000000001c15b0: a784000b           brc     8,1c15c6
               00000000001c15b4: c0e5004e72aa       brasl   %r14,b8fb08
               00000000001c15ba: 1812               lr      %r1,%r2
    Call Trace:
    ([<0700000000000000>] 0x700000000000000)
     [<0000000000b9d3d2>] _raw_spin_lock_irqsave+0x7a/0xb8
     [<000000000099f09e>] dasd_times_out+0x46/0x278
     [<000000000076ea6e>] blk_mq_terminate_expired+0x9e/0x108
     [<000000000077497a>] bt_for_each+0x102/0x130
     [<0000000000774e54>] blk_mq_queue_tag_busy_iter+0x74/0xd8
     [<000000000076fea0>] blk_mq_timeout_work+0x260/0x320
     [<0000000000169dd4>] process_one_work+0x3bc/0x708
     [<000000000016a382>] worker_thread+0x262/0x408
     [<00000000001723a8>] kthread+0x160/0x178
     [<0000000000b9e73a>] kernel_thread_starter+0x6/0xc
     [<0000000000b9e734>] kernel_thread_starter+0x0/0xc
    INFO: lockdep is turned off.
    Last Breaking-Event-Address:
     [<0000000000b9d3cc>] _raw_spin_lock_irqsave+0x74/0xb8
    
    Kernel panic - not syncing: Fatal exception: panic_on_oops
    
    Signed-off-by: Sebastian Ott <sebott@linux.ibm.com>
    Reviewed-by: Stefan Haberland <sth@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9203311e5bd6e8a8121a1df9f8b52c77d691c15
Author: Leon Romanovsky <leon@kernel.org>
Date:   Wed Mar 7 15:29:09 2018 +0200

    RDMA/mlx5: Fix integer overflow while resizing CQ
    
    commit 28e9091e3119933c38933cb8fc48d5618eb784c8 upstream.
    
    The user can provide very large cqe_size which will cause to integer
    overflow as it can be seen in the following UBSAN warning:
    
    =======================================================================
    UBSAN: Undefined behaviour in drivers/infiniband/hw/mlx5/cq.c:1192:53
    signed integer overflow:
    64870 * 65536 cannot be represented in type 'int'
    CPU: 0 PID: 267 Comm: syzkaller605279 Not tainted 4.15.0+ #90 Hardware
    name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ubsan_epilogue+0xe/0x81
     handle_overflow+0x1f3/0x251
     ? __ubsan_handle_negate_overflow+0x19b/0x19b
     ? lock_acquire+0x440/0x440
     mlx5_ib_resize_cq+0x17e7/0x1e40
     ? cyc2ns_read_end+0x10/0x10
     ? native_read_msr_safe+0x6c/0x9b
     ? cyc2ns_read_end+0x10/0x10
     ? mlx5_ib_modify_cq+0x220/0x220
     ? sched_clock_cpu+0x18/0x200
     ? lookup_get_idr_uobject+0x200/0x200
     ? rdma_lookup_get_uobject+0x145/0x2f0
     ib_uverbs_resize_cq+0x207/0x3e0
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ib_uverbs_write+0x7f9/0xef0
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ? uverbs_devnode+0x110/0x110
     ? sched_clock_cpu+0x18/0x200
     ? do_raw_spin_trylock+0x100/0x100
     ? __lru_cache_add+0x16e/0x290
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? sched_clock_cpu+0x18/0x200
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433549
    RSP: 002b:00007ffe63bd1ea8 EFLAGS: 00000217
    =======================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Fixes: bde51583f49b ("IB/mlx5: Add support for resize CQ")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 0675ec13c63f9eb918342b63614738767ef079a3
Author: Will Deacon <will@kernel.org>
Date:   Wed Jan 31 12:12:20 2018 +0000

    arm64: spinlock: Fix theoretical trylock() A-B-A with LSE atomics
    
    [ Upstream commit 202fb4ef81e3ec765c23bd1e6746a5c25b797d0e ]
    
    If the spinlock "next" ticket wraps around between the initial LDR
    and the cmpxchg in the LSE version of spin_trylock, then we can erroneously
    think that we have successfuly acquired the lock because we only check
    whether the next ticket return by the cmpxchg is equal to the owner ticket
    in our updated lock word.
    
    This patch fixes the issue by performing a full 32-bit check of the lock
    word when trying to determine whether or not the CASA instruction updated
    memory.
    
    Reported-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07b1d60d79e7772dddbfd69a2fa8b4f471feb582
Author: Will Deacon <will@kernel.org>
Date:   Wed Jan 31 12:12:20 2018 +0000

    arm64: spinlock: Fix theoretical trylock() A-B-A with LSE atomics
    
    [ Upstream commit 202fb4ef81e3ec765c23bd1e6746a5c25b797d0e ]
    
    If the spinlock "next" ticket wraps around between the initial LDR
    and the cmpxchg in the LSE version of spin_trylock, then we can erroneously
    think that we have successfuly acquired the lock because we only check
    whether the next ticket return by the cmpxchg is equal to the owner ticket
    in our updated lock word.
    
    This patch fixes the issue by performing a full 32-bit check of the lock
    word when trying to determine whether or not the CASA instruction updated
    memory.
    
    Reported-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 003ad57484d9154db1ba93370a20c92d8356a61d
Author: Petr Machata <petrm@mellanox.com>
Date:   Thu May 17 16:36:15 2018 +0200

    net: ip6_gre: Fix headroom request in ip6erspan_tunnel_xmit()
    
    [ Upstream commit 5691484df961aff897d824bcc26cd1a2aa036b5b ]
    
    dev->needed_headroom is not primed until ip6_tnl_xmit(), so it starts
    out zero. Thus the call to skb_cow_head() fails to actually make sure
    there's enough headroom to push the ERSPAN headers to. That can lead to
    the panic cited below. (Reproducer below that).
    
    Fix by requesting either needed_headroom if already primed, or just the
    bare minimum needed for the header otherwise.
    
    [  190.703567] kernel BUG at net/core/skbuff.c:104!
    [  190.708384] invalid opcode: 0000 [#1] PREEMPT SMP KASAN PTI
    [  190.714007] Modules linked in: act_mirred cls_matchall ip6_gre ip6_tunnel tunnel6 gre sch_ingress vrf veth x86_pkg_temp_thermal mlx_platform nfsd e1000e leds_mlxcpld
    [  190.728975] CPU: 1 PID: 959 Comm: kworker/1:2 Not tainted 4.17.0-rc4-net_master-custom-139 #10
    [  190.737647] Hardware name: Mellanox Technologies Ltd. "MSN2410-CB2F"/"SA000874", BIOS 4.6.5 03/08/2016
    [  190.747006] Workqueue: ipv6_addrconf addrconf_dad_work
    [  190.752222] RIP: 0010:skb_panic+0xc3/0x100
    [  190.756358] RSP: 0018:ffff8801d54072f0 EFLAGS: 00010282
    [  190.761629] RAX: 0000000000000085 RBX: ffff8801c1a8ecc0 RCX: 0000000000000000
    [  190.768830] RDX: 0000000000000085 RSI: dffffc0000000000 RDI: ffffed003aa80e54
    [  190.776025] RBP: ffff8801bd1ec5a0 R08: ffffed003aabce19 R09: ffffed003aabce19
    [  190.783226] R10: 0000000000000001 R11: ffffed003aabce18 R12: ffff8801bf695dbe
    [  190.790418] R13: 0000000000000084 R14: 00000000000006c0 R15: ffff8801bf695dc8
    [  190.797621] FS:  0000000000000000(0000) GS:ffff8801d5400000(0000) knlGS:0000000000000000
    [  190.805786] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  190.811582] CR2: 000055fa929aced0 CR3: 0000000003228004 CR4: 00000000001606e0
    [  190.818790] Call Trace:
    [  190.821264]  <IRQ>
    [  190.823314]  ? ip6erspan_tunnel_xmit+0x5e4/0x1982 [ip6_gre]
    [  190.828940]  ? ip6erspan_tunnel_xmit+0x5e4/0x1982 [ip6_gre]
    [  190.834562]  skb_push+0x78/0x90
    [  190.837749]  ip6erspan_tunnel_xmit+0x5e4/0x1982 [ip6_gre]
    [  190.843219]  ? ip6gre_tunnel_ioctl+0xd90/0xd90 [ip6_gre]
    [  190.848577]  ? debug_check_no_locks_freed+0x210/0x210
    [  190.853679]  ? debug_check_no_locks_freed+0x210/0x210
    [  190.858783]  ? print_irqtrace_events+0x120/0x120
    [  190.863451]  ? sched_clock_cpu+0x18/0x210
    [  190.867496]  ? cyc2ns_read_end+0x10/0x10
    [  190.871474]  ? skb_network_protocol+0x76/0x200
    [  190.875977]  dev_hard_start_xmit+0x137/0x770
    [  190.880317]  ? do_raw_spin_trylock+0x6d/0xa0
    [  190.884624]  sch_direct_xmit+0x2ef/0x5d0
    [  190.888589]  ? pfifo_fast_dequeue+0x3fa/0x670
    [  190.892994]  ? pfifo_fast_change_tx_queue_len+0x810/0x810
    [  190.898455]  ? __lock_is_held+0xa0/0x160
    [  190.902422]  __qdisc_run+0x39e/0xfc0
    [  190.906041]  ? _raw_spin_unlock+0x29/0x40
    [  190.910090]  ? pfifo_fast_enqueue+0x24b/0x3e0
    [  190.914501]  ? sch_direct_xmit+0x5d0/0x5d0
    [  190.918658]  ? pfifo_fast_dequeue+0x670/0x670
    [  190.923047]  ? __dev_queue_xmit+0x172/0x1770
    [  190.927365]  ? preempt_count_sub+0xf/0xd0
    [  190.931421]  __dev_queue_xmit+0x410/0x1770
    [  190.935553]  ? ___slab_alloc+0x605/0x930
    [  190.939524]  ? print_irqtrace_events+0x120/0x120
    [  190.944186]  ? memcpy+0x34/0x50
    [  190.947364]  ? netdev_pick_tx+0x1c0/0x1c0
    [  190.951428]  ? __skb_clone+0x2fd/0x3d0
    [  190.955218]  ? __copy_skb_header+0x270/0x270
    [  190.959537]  ? rcu_read_lock_sched_held+0x93/0xa0
    [  190.964282]  ? kmem_cache_alloc+0x344/0x4d0
    [  190.968520]  ? cyc2ns_read_end+0x10/0x10
    [  190.972495]  ? skb_clone+0x123/0x230
    [  190.976112]  ? skb_split+0x820/0x820
    [  190.979747]  ? tcf_mirred+0x554/0x930 [act_mirred]
    [  190.984582]  tcf_mirred+0x554/0x930 [act_mirred]
    [  190.989252]  ? tcf_mirred_act_wants_ingress.part.2+0x10/0x10 [act_mirred]
    [  190.996109]  ? __lock_acquire+0x706/0x26e0
    [  191.000239]  ? sched_clock_cpu+0x18/0x210
    [  191.004294]  tcf_action_exec+0xcf/0x2a0
    [  191.008179]  tcf_classify+0xfa/0x340
    [  191.011794]  __netif_receive_skb_core+0x8e1/0x1c60
    [  191.016630]  ? debug_check_no_locks_freed+0x210/0x210
    [  191.021732]  ? nf_ingress+0x500/0x500
    [  191.025458]  ? process_backlog+0x347/0x4b0
    [  191.029619]  ? print_irqtrace_events+0x120/0x120
    [  191.034302]  ? lock_acquire+0xd8/0x320
    [  191.038089]  ? process_backlog+0x1b6/0x4b0
    [  191.042246]  ? process_backlog+0xc2/0x4b0
    [  191.046303]  process_backlog+0xc2/0x4b0
    [  191.050189]  net_rx_action+0x5cc/0x980
    [  191.053991]  ? napi_complete_done+0x2c0/0x2c0
    [  191.058386]  ? mark_lock+0x13d/0xb40
    [  191.062001]  ? clockevents_program_event+0x6b/0x1d0
    [  191.066922]  ? print_irqtrace_events+0x120/0x120
    [  191.071593]  ? __lock_is_held+0xa0/0x160
    [  191.075566]  __do_softirq+0x1d4/0x9d2
    [  191.079282]  ? ip6_finish_output2+0x524/0x1460
    [  191.083771]  do_softirq_own_stack+0x2a/0x40
    [  191.087994]  </IRQ>
    [  191.090130]  do_softirq.part.13+0x38/0x40
    [  191.094178]  __local_bh_enable_ip+0x135/0x190
    [  191.098591]  ip6_finish_output2+0x54d/0x1460
    [  191.102916]  ? ip6_forward_finish+0x2f0/0x2f0
    [  191.107314]  ? ip6_mtu+0x3c/0x2c0
    [  191.110674]  ? ip6_finish_output+0x2f8/0x650
    [  191.114992]  ? ip6_output+0x12a/0x500
    [  191.118696]  ip6_output+0x12a/0x500
    [  191.122223]  ? ip6_route_dev_notify+0x5b0/0x5b0
    [  191.126807]  ? ip6_finish_output+0x650/0x650
    [  191.131120]  ? ip6_fragment+0x1a60/0x1a60
    [  191.135182]  ? icmp6_dst_alloc+0x26e/0x470
    [  191.139317]  mld_sendpack+0x672/0x830
    [  191.143021]  ? igmp6_mcf_seq_next+0x2f0/0x2f0
    [  191.147429]  ? __local_bh_enable_ip+0x77/0x190
    [  191.151913]  ipv6_mc_dad_complete+0x47/0x90
    [  191.156144]  addrconf_dad_completed+0x561/0x720
    [  191.160731]  ? addrconf_rs_timer+0x3a0/0x3a0
    [  191.165036]  ? mark_held_locks+0xc9/0x140
    [  191.169095]  ? __local_bh_enable_ip+0x77/0x190
    [  191.173570]  ? addrconf_dad_work+0x50d/0xa20
    [  191.177886]  ? addrconf_dad_work+0x529/0xa20
    [  191.182194]  addrconf_dad_work+0x529/0xa20
    [  191.186342]  ? addrconf_dad_completed+0x720/0x720
    [  191.191088]  ? __lock_is_held+0xa0/0x160
    [  191.195059]  ? process_one_work+0x45d/0xe20
    [  191.199302]  ? process_one_work+0x51e/0xe20
    [  191.203531]  ? rcu_read_lock_sched_held+0x93/0xa0
    [  191.208279]  process_one_work+0x51e/0xe20
    [  191.212340]  ? pwq_dec_nr_in_flight+0x200/0x200
    [  191.216912]  ? get_lock_stats+0x4b/0xf0
    [  191.220788]  ? preempt_count_sub+0xf/0xd0
    [  191.224844]  ? worker_thread+0x219/0x860
    [  191.228823]  ? do_raw_spin_trylock+0x6d/0xa0
    [  191.233142]  worker_thread+0xeb/0x860
    [  191.236848]  ? process_one_work+0xe20/0xe20
    [  191.241095]  kthread+0x206/0x300
    [  191.244352]  ? process_one_work+0xe20/0xe20
    [  191.248587]  ? kthread_stop+0x570/0x570
    [  191.252459]  ret_from_fork+0x3a/0x50
    [  191.256082] Code: 14 3e ff 8b 4b 78 55 4d 89 f9 41 56 41 55 48 c7 c7 a0 cf db 82 41 54 44 8b 44 24 2c 48 8b 54 24 30 48 8b 74 24 20 e8 16 94 13 ff <0f> 0b 48 c7 c7 60 8e 1f 85 48 83 c4 20 e8 55 ef a6 ff 89 74 24
    [  191.275327] RIP: skb_panic+0xc3/0x100 RSP: ffff8801d54072f0
    [  191.281024] ---[ end trace 7ea51094e099e006 ]---
    [  191.285724] Kernel panic - not syncing: Fatal exception in interrupt
    [  191.292168] Kernel Offset: disabled
    [  191.295697] ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---
    
    Reproducer:
    
            ip link add h1 type veth peer name swp1
            ip link add h3 type veth peer name swp3
    
            ip link set dev h1 up
            ip address add 192.0.2.1/28 dev h1
    
            ip link add dev vh3 type vrf table 20
            ip link set dev h3 master vh3
            ip link set dev vh3 up
            ip link set dev h3 up
    
            ip link set dev swp3 up
            ip address add dev swp3 2001:db8:2::1/64
    
            ip link set dev swp1 up
            tc qdisc add dev swp1 clsact
    
            ip link add name gt6 type ip6erspan \
                    local 2001:db8:2::1 remote 2001:db8:2::2 oseq okey 123
            ip link set dev gt6 up
    
            sleep 1
    
            tc filter add dev swp1 ingress pref 1000 matchall skip_hw \
                    action mirred egress mirror dev gt6
            ping -I h1 192.0.2.2
    
    Fixes: e41c7c68ea77 ("ip6erspan: make sure enough headroom at xmit.")
    Signed-off-by: Petr Machata <petrm@mellanox.com>
    Acked-by: William Tu <u9012063@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f0f59a2fab8e52b9d582b39da39f22230ca80aee
Author: Sebastian Ott <sebott@linux.ibm.com>
Date:   Tue May 15 14:05:13 2018 +0200

    s390/dasd: use blk_mq_rq_from_pdu for per request data
    
    Dasd uses completion_data from struct request to store per request
    private data - this is problematic since this member is part of a
    union which is also used by IO schedulers.
    Let the block layer maintain space for per request data behind each
    struct request.
    
    Fixes crashes on block layer timeouts like this one:
    
    Unable to handle kernel pointer dereference in virtual kernel address space
    Failing address: 0000000000000000 TEID: 0000000000000483
    Fault in home space mode while using kernel ASCE.
    AS:0000000001308007 R3:00000000fffc8007 S:00000000fffcc000 P:000000000000013d
    Oops: 0004 ilc:2 [#1] PREEMPT SMP
    Modules linked in: [...]
    CPU: 0 PID: 1480 Comm: kworker/0:2H Not tainted 4.17.0-rc4-00046-gaa3bcd43b5af #203
    Hardware name: IBM 3906 M02 702 (LPAR)
    Workqueue: kblockd blk_mq_timeout_work
    Krnl PSW : 0000000067ac406b 00000000b6960308 (do_raw_spin_trylock+0x30/0x78)
               R:0 T:1 IO:0 EX:0 Key:0 M:1 W:0 P:0 AS:3 CC:2 PM:0 RI:0 EA:3
    Krnl GPRS: 0000000000000c00 0000000000000000 0000000000000000 0000000000000001
               0000000000b9d3c8 0000000000000000 0000000000000001 00000000cf9639d8
               0000000000000000 0700000000000000 0000000000000000 000000000099f09e
               0000000000000000 000000000076e9d0 000000006247bb08 000000006247bae0
    Krnl Code: 00000000001c159c: b90400c2           lgr     %r12,%r2
               00000000001c15a0: a7180000           lhi     %r1,0
              #00000000001c15a4: 583003a4           l       %r3,932
              >00000000001c15a8: ba132000           cs      %r1,%r3,0(%r2)
               00000000001c15ac: a7180001           lhi     %r1,1
               00000000001c15b0: a784000b           brc     8,1c15c6
               00000000001c15b4: c0e5004e72aa       brasl   %r14,b8fb08
               00000000001c15ba: 1812               lr      %r1,%r2
    Call Trace:
    ([<0700000000000000>] 0x700000000000000)
     [<0000000000b9d3d2>] _raw_spin_lock_irqsave+0x7a/0xb8
     [<000000000099f09e>] dasd_times_out+0x46/0x278
     [<000000000076ea6e>] blk_mq_terminate_expired+0x9e/0x108
     [<000000000077497a>] bt_for_each+0x102/0x130
     [<0000000000774e54>] blk_mq_queue_tag_busy_iter+0x74/0xd8
     [<000000000076fea0>] blk_mq_timeout_work+0x260/0x320
     [<0000000000169dd4>] process_one_work+0x3bc/0x708
     [<000000000016a382>] worker_thread+0x262/0x408
     [<00000000001723a8>] kthread+0x160/0x178
     [<0000000000b9e73a>] kernel_thread_starter+0x6/0xc
     [<0000000000b9e734>] kernel_thread_starter+0x0/0xc
    INFO: lockdep is turned off.
    Last Breaking-Event-Address:
     [<0000000000b9d3cc>] _raw_spin_lock_irqsave+0x74/0xb8
    
    Kernel panic - not syncing: Fatal exception: panic_on_oops
    
    Signed-off-by: Sebastian Ott <sebott@linux.ibm.com>
    Reviewed-by: Stefan Haberland <sth@linux.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 5691484df961aff897d824bcc26cd1a2aa036b5b
Author: Petr Machata <petrm@mellanox.com>
Date:   Thu May 17 16:36:15 2018 +0200

    net: ip6_gre: Fix headroom request in ip6erspan_tunnel_xmit()
    
    dev->needed_headroom is not primed until ip6_tnl_xmit(), so it starts
    out zero. Thus the call to skb_cow_head() fails to actually make sure
    there's enough headroom to push the ERSPAN headers to. That can lead to
    the panic cited below. (Reproducer below that).
    
    Fix by requesting either needed_headroom if already primed, or just the
    bare minimum needed for the header otherwise.
    
    [  190.703567] kernel BUG at net/core/skbuff.c:104!
    [  190.708384] invalid opcode: 0000 [#1] PREEMPT SMP KASAN PTI
    [  190.714007] Modules linked in: act_mirred cls_matchall ip6_gre ip6_tunnel tunnel6 gre sch_ingress vrf veth x86_pkg_temp_thermal mlx_platform nfsd e1000e leds_mlxcpld
    [  190.728975] CPU: 1 PID: 959 Comm: kworker/1:2 Not tainted 4.17.0-rc4-net_master-custom-139 #10
    [  190.737647] Hardware name: Mellanox Technologies Ltd. "MSN2410-CB2F"/"SA000874", BIOS 4.6.5 03/08/2016
    [  190.747006] Workqueue: ipv6_addrconf addrconf_dad_work
    [  190.752222] RIP: 0010:skb_panic+0xc3/0x100
    [  190.756358] RSP: 0018:ffff8801d54072f0 EFLAGS: 00010282
    [  190.761629] RAX: 0000000000000085 RBX: ffff8801c1a8ecc0 RCX: 0000000000000000
    [  190.768830] RDX: 0000000000000085 RSI: dffffc0000000000 RDI: ffffed003aa80e54
    [  190.776025] RBP: ffff8801bd1ec5a0 R08: ffffed003aabce19 R09: ffffed003aabce19
    [  190.783226] R10: 0000000000000001 R11: ffffed003aabce18 R12: ffff8801bf695dbe
    [  190.790418] R13: 0000000000000084 R14: 00000000000006c0 R15: ffff8801bf695dc8
    [  190.797621] FS:  0000000000000000(0000) GS:ffff8801d5400000(0000) knlGS:0000000000000000
    [  190.805786] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [  190.811582] CR2: 000055fa929aced0 CR3: 0000000003228004 CR4: 00000000001606e0
    [  190.818790] Call Trace:
    [  190.821264]  <IRQ>
    [  190.823314]  ? ip6erspan_tunnel_xmit+0x5e4/0x1982 [ip6_gre]
    [  190.828940]  ? ip6erspan_tunnel_xmit+0x5e4/0x1982 [ip6_gre]
    [  190.834562]  skb_push+0x78/0x90
    [  190.837749]  ip6erspan_tunnel_xmit+0x5e4/0x1982 [ip6_gre]
    [  190.843219]  ? ip6gre_tunnel_ioctl+0xd90/0xd90 [ip6_gre]
    [  190.848577]  ? debug_check_no_locks_freed+0x210/0x210
    [  190.853679]  ? debug_check_no_locks_freed+0x210/0x210
    [  190.858783]  ? print_irqtrace_events+0x120/0x120
    [  190.863451]  ? sched_clock_cpu+0x18/0x210
    [  190.867496]  ? cyc2ns_read_end+0x10/0x10
    [  190.871474]  ? skb_network_protocol+0x76/0x200
    [  190.875977]  dev_hard_start_xmit+0x137/0x770
    [  190.880317]  ? do_raw_spin_trylock+0x6d/0xa0
    [  190.884624]  sch_direct_xmit+0x2ef/0x5d0
    [  190.888589]  ? pfifo_fast_dequeue+0x3fa/0x670
    [  190.892994]  ? pfifo_fast_change_tx_queue_len+0x810/0x810
    [  190.898455]  ? __lock_is_held+0xa0/0x160
    [  190.902422]  __qdisc_run+0x39e/0xfc0
    [  190.906041]  ? _raw_spin_unlock+0x29/0x40
    [  190.910090]  ? pfifo_fast_enqueue+0x24b/0x3e0
    [  190.914501]  ? sch_direct_xmit+0x5d0/0x5d0
    [  190.918658]  ? pfifo_fast_dequeue+0x670/0x670
    [  190.923047]  ? __dev_queue_xmit+0x172/0x1770
    [  190.927365]  ? preempt_count_sub+0xf/0xd0
    [  190.931421]  __dev_queue_xmit+0x410/0x1770
    [  190.935553]  ? ___slab_alloc+0x605/0x930
    [  190.939524]  ? print_irqtrace_events+0x120/0x120
    [  190.944186]  ? memcpy+0x34/0x50
    [  190.947364]  ? netdev_pick_tx+0x1c0/0x1c0
    [  190.951428]  ? __skb_clone+0x2fd/0x3d0
    [  190.955218]  ? __copy_skb_header+0x270/0x270
    [  190.959537]  ? rcu_read_lock_sched_held+0x93/0xa0
    [  190.964282]  ? kmem_cache_alloc+0x344/0x4d0
    [  190.968520]  ? cyc2ns_read_end+0x10/0x10
    [  190.972495]  ? skb_clone+0x123/0x230
    [  190.976112]  ? skb_split+0x820/0x820
    [  190.979747]  ? tcf_mirred+0x554/0x930 [act_mirred]
    [  190.984582]  tcf_mirred+0x554/0x930 [act_mirred]
    [  190.989252]  ? tcf_mirred_act_wants_ingress.part.2+0x10/0x10 [act_mirred]
    [  190.996109]  ? __lock_acquire+0x706/0x26e0
    [  191.000239]  ? sched_clock_cpu+0x18/0x210
    [  191.004294]  tcf_action_exec+0xcf/0x2a0
    [  191.008179]  tcf_classify+0xfa/0x340
    [  191.011794]  __netif_receive_skb_core+0x8e1/0x1c60
    [  191.016630]  ? debug_check_no_locks_freed+0x210/0x210
    [  191.021732]  ? nf_ingress+0x500/0x500
    [  191.025458]  ? process_backlog+0x347/0x4b0
    [  191.029619]  ? print_irqtrace_events+0x120/0x120
    [  191.034302]  ? lock_acquire+0xd8/0x320
    [  191.038089]  ? process_backlog+0x1b6/0x4b0
    [  191.042246]  ? process_backlog+0xc2/0x4b0
    [  191.046303]  process_backlog+0xc2/0x4b0
    [  191.050189]  net_rx_action+0x5cc/0x980
    [  191.053991]  ? napi_complete_done+0x2c0/0x2c0
    [  191.058386]  ? mark_lock+0x13d/0xb40
    [  191.062001]  ? clockevents_program_event+0x6b/0x1d0
    [  191.066922]  ? print_irqtrace_events+0x120/0x120
    [  191.071593]  ? __lock_is_held+0xa0/0x160
    [  191.075566]  __do_softirq+0x1d4/0x9d2
    [  191.079282]  ? ip6_finish_output2+0x524/0x1460
    [  191.083771]  do_softirq_own_stack+0x2a/0x40
    [  191.087994]  </IRQ>
    [  191.090130]  do_softirq.part.13+0x38/0x40
    [  191.094178]  __local_bh_enable_ip+0x135/0x190
    [  191.098591]  ip6_finish_output2+0x54d/0x1460
    [  191.102916]  ? ip6_forward_finish+0x2f0/0x2f0
    [  191.107314]  ? ip6_mtu+0x3c/0x2c0
    [  191.110674]  ? ip6_finish_output+0x2f8/0x650
    [  191.114992]  ? ip6_output+0x12a/0x500
    [  191.118696]  ip6_output+0x12a/0x500
    [  191.122223]  ? ip6_route_dev_notify+0x5b0/0x5b0
    [  191.126807]  ? ip6_finish_output+0x650/0x650
    [  191.131120]  ? ip6_fragment+0x1a60/0x1a60
    [  191.135182]  ? icmp6_dst_alloc+0x26e/0x470
    [  191.139317]  mld_sendpack+0x672/0x830
    [  191.143021]  ? igmp6_mcf_seq_next+0x2f0/0x2f0
    [  191.147429]  ? __local_bh_enable_ip+0x77/0x190
    [  191.151913]  ipv6_mc_dad_complete+0x47/0x90
    [  191.156144]  addrconf_dad_completed+0x561/0x720
    [  191.160731]  ? addrconf_rs_timer+0x3a0/0x3a0
    [  191.165036]  ? mark_held_locks+0xc9/0x140
    [  191.169095]  ? __local_bh_enable_ip+0x77/0x190
    [  191.173570]  ? addrconf_dad_work+0x50d/0xa20
    [  191.177886]  ? addrconf_dad_work+0x529/0xa20
    [  191.182194]  addrconf_dad_work+0x529/0xa20
    [  191.186342]  ? addrconf_dad_completed+0x720/0x720
    [  191.191088]  ? __lock_is_held+0xa0/0x160
    [  191.195059]  ? process_one_work+0x45d/0xe20
    [  191.199302]  ? process_one_work+0x51e/0xe20
    [  191.203531]  ? rcu_read_lock_sched_held+0x93/0xa0
    [  191.208279]  process_one_work+0x51e/0xe20
    [  191.212340]  ? pwq_dec_nr_in_flight+0x200/0x200
    [  191.216912]  ? get_lock_stats+0x4b/0xf0
    [  191.220788]  ? preempt_count_sub+0xf/0xd0
    [  191.224844]  ? worker_thread+0x219/0x860
    [  191.228823]  ? do_raw_spin_trylock+0x6d/0xa0
    [  191.233142]  worker_thread+0xeb/0x860
    [  191.236848]  ? process_one_work+0xe20/0xe20
    [  191.241095]  kthread+0x206/0x300
    [  191.244352]  ? process_one_work+0xe20/0xe20
    [  191.248587]  ? kthread_stop+0x570/0x570
    [  191.252459]  ret_from_fork+0x3a/0x50
    [  191.256082] Code: 14 3e ff 8b 4b 78 55 4d 89 f9 41 56 41 55 48 c7 c7 a0 cf db 82 41 54 44 8b 44 24 2c 48 8b 54 24 30 48 8b 74 24 20 e8 16 94 13 ff <0f> 0b 48 c7 c7 60 8e 1f 85 48 83 c4 20 e8 55 ef a6 ff 89 74 24
    [  191.275327] RIP: skb_panic+0xc3/0x100 RSP: ffff8801d54072f0
    [  191.281024] ---[ end trace 7ea51094e099e006 ]---
    [  191.285724] Kernel panic - not syncing: Fatal exception in interrupt
    [  191.292168] Kernel Offset: disabled
    [  191.295697] ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---
    
    Reproducer:
    
            ip link add h1 type veth peer name swp1
            ip link add h3 type veth peer name swp3
    
            ip link set dev h1 up
            ip address add 192.0.2.1/28 dev h1
    
            ip link add dev vh3 type vrf table 20
            ip link set dev h3 master vh3
            ip link set dev vh3 up
            ip link set dev h3 up
    
            ip link set dev swp3 up
            ip address add dev swp3 2001:db8:2::1/64
    
            ip link set dev swp1 up
            tc qdisc add dev swp1 clsact
    
            ip link add name gt6 type ip6erspan \
                    local 2001:db8:2::1 remote 2001:db8:2::2 oseq okey 123
            ip link set dev gt6 up
    
            sleep 1
    
            tc filter add dev swp1 ingress pref 1000 matchall skip_hw \
                    action mirred egress mirror dev gt6
            ping -I h1 192.0.2.2
    
    Fixes: e41c7c68ea77 ("ip6erspan: make sure enough headroom at xmit.")
    Signed-off-by: Petr Machata <petrm@mellanox.com>
    Acked-by: William Tu <u9012063@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 8559183ccaec97454b2515ac426f113967256cf9
Author: Alan Stern <stern@rowland.harvard.edu>
Date:   Mon May 14 16:33:50 2018 -0700

    tools/memory-model: Remove duplicated code from lock.cat
    
    This patch simplifies the implementation of spin_is_locked in the
    LKMM.  It capitalizes on the fact that a failed spin_trylock() and a
    spin_is_locked() which returns True have exactly the same semantics
    (those of READ_ONCE) and ordering properties (none).  Therefore the
    two kinds of events can be combined and handled by the same code,
    instead of treated separately as they are currently.
    
    Tested-by: Andrea Parri <andrea.parri@amarulasolutions.com>
    Signed-off-by: Alan Stern <stern@rowland.harvard.edu>
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Akira Yokosawa <akiyks@gmail.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Boqun Feng <boqun.feng@gmail.com>
    Cc: David Howells <dhowells@redhat.com>
    Cc: Jade Alglave <j.alglave@ucl.ac.uk>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Luc Maranget <luc.maranget@inria.fr>
    Cc: Nicholas Piggin <npiggin@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Will Deacon <will.deacon@arm.com>
    Cc: linux-arch@vger.kernel.org
    Cc: parri.andrea@gmail.com
    Link: http://lkml.kernel.org/r/1526340837-12222-12-git-send-email-paulmck@linux.vnet.ibm.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 4ec317a41d80145de90bd320928da6916572b6f0
Author: Will Deacon <will@kernel.org>
Date:   Wed Jan 31 12:12:20 2018 +0000

    arm64: spinlock: Fix theoretical trylock() A-B-A with LSE atomics
    
    
    [ Upstream commit 202fb4ef81e3ec765c23bd1e6746a5c25b797d0e ]
    
    If the spinlock "next" ticket wraps around between the initial LDR
    and the cmpxchg in the LSE version of spin_trylock, then we can erroneously
    think that we have successfuly acquired the lock because we only check
    whether the next ticket return by the cmpxchg is equal to the owner ticket
    in our updated lock word.
    
    This patch fixes the issue by performing a full 32-bit check of the lock
    word when trying to determine whether or not the CASA instruction updated
    memory.
    
    Reported-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Sasha Levin <alexander.levin@microsoft.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b951ffb160f765db6b06b9ee065f79faed5fa9e1
Author: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
Date:   Mon Apr 9 19:03:46 2018 +0900

    perf/core: Fix use-after-free in uprobe_perf_close()
    
    commit 621b6d2ea297d0fb6030452c5bcd221f12165fcf upstream.
    
    A use-after-free bug was caught by KASAN while running usdt related
    code (BCC project. bcc/tests/python/test_usdt2.py):
    
            ==================================================================
            BUG: KASAN: use-after-free in uprobe_perf_close+0x222/0x3b0
            Read of size 4 at addr ffff880384f9b4a4 by task test_usdt2.py/870
    
            CPU: 4 PID: 870 Comm: test_usdt2.py Tainted: G        W         4.16.0-next-20180409 #215
            Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
            Call Trace:
             dump_stack+0xc7/0x15b
             ? show_regs_print_info+0x5/0x5
             ? printk+0x9c/0xc3
             ? kmsg_dump_rewind_nolock+0x6e/0x6e
             ? uprobe_perf_close+0x222/0x3b0
             print_address_description+0x83/0x3a0
             ? uprobe_perf_close+0x222/0x3b0
             kasan_report+0x1dd/0x460
             ? uprobe_perf_close+0x222/0x3b0
             uprobe_perf_close+0x222/0x3b0
             ? probes_open+0x180/0x180
             ? free_filters_list+0x290/0x290
             trace_uprobe_register+0x1bb/0x500
             ? perf_event_attach_bpf_prog+0x310/0x310
             ? probe_event_disable+0x4e0/0x4e0
             perf_uprobe_destroy+0x63/0xd0
             _free_event+0x2bc/0xbd0
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ring_buffer_attach+0x550/0x550
             ? kvm_sched_clock_read+0x1a/0x30
             ? perf_event_release_kernel+0x3e4/0xc00
             ? __mutex_unlock_slowpath+0x12e/0x540
             ? wait_for_completion+0x430/0x430
             ? lock_downgrade+0x3c0/0x3c0
             ? lock_release+0x980/0x980
             ? do_raw_spin_trylock+0x118/0x150
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             perf_event_release_kernel+0x5d4/0xc00
             ? put_event+0x30/0x30
             ? fsnotify+0xd2d/0xea0
             ? sched_clock_cpu+0x18/0x1a0
             ? __fsnotify_update_child_dentry_flags.part.0+0x1b0/0x1b0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? pvclock_read_flags+0x80/0x80
             ? kvm_sched_clock_read+0x1a/0x30
             ? sched_clock_cpu+0x18/0x1a0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? locks_remove_file+0xec/0x470
             ? pvclock_read_flags+0x80/0x80
             ? fcntl_setlk+0x880/0x880
             ? ima_file_free+0x8d/0x390
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ima_file_check+0x110/0x110
             ? fsnotify+0xea0/0xea0
             ? kvm_sched_clock_read+0x1a/0x30
             ? rcu_note_context_switch+0x600/0x600
             perf_release+0x21/0x40
             __fput+0x264/0x620
             ? fput+0xf0/0xf0
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             ? SyS_fchdir+0x100/0x100
             ? fsnotify+0xea0/0xea0
             task_work_run+0x14b/0x1e0
             ? task_work_cancel+0x1c0/0x1c0
             ? copy_fd_bitmaps+0x150/0x150
             ? vfs_read+0xe5/0x260
             exit_to_usermode_loop+0x17b/0x1b0
             ? trace_event_raw_event_sys_exit+0x1a0/0x1a0
             do_syscall_64+0x3f6/0x490
             ? syscall_return_slowpath+0x2c0/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? syscall_return_slowpath+0x1a3/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? prepare_exit_to_usermode+0x11c/0x1e0
             ? enter_from_user_mode+0x30/0x30
            random: crng init done
             ? __put_user_4+0x1c/0x30
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
            RIP: 0033:0x7f41d95f9340
            RSP: 002b:00007fffe71e4268 EFLAGS: 00000246 ORIG_RAX: 0000000000000003
            RAX: 0000000000000000 RBX: 000000000000000d RCX: 00007f41d95f9340
            RDX: 0000000000000000 RSI: 0000000000002401 RDI: 000000000000000d
            RBP: 0000000000000000 R08: 00007f41ca8ff700 R09: 00007f41d996dd1f
            R10: 00007fffe71e41e0 R11: 0000000000000246 R12: 00007fffe71e4330
            R13: 0000000000000000 R14: fffffffffffffffc R15: 00007fffe71e4290
    
            Allocated by task 870:
             kasan_kmalloc+0xa0/0xd0
             kmem_cache_alloc_node+0x11a/0x430
             copy_process.part.19+0x11a0/0x41c0
             _do_fork+0x1be/0xa20
             do_syscall_64+0x198/0x490
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
    
            Freed by task 0:
             __kasan_slab_free+0x12e/0x180
             kmem_cache_free+0x102/0x4d0
             free_task+0xfe/0x160
             __put_task_struct+0x189/0x290
             delayed_put_task_struct+0x119/0x250
             rcu_process_callbacks+0xa6c/0x1b60
             __do_softirq+0x238/0x7ae
    
            The buggy address belongs to the object at ffff880384f9b480
             which belongs to the cache task_struct of size 12928
    
    It occurs because task_struct is freed before perf_event which refers
    to the task and task flags are checked while teardown of the event.
    perf_event_alloc() assigns task_struct to hw.target of perf_event,
    but there is no reference counting for it.
    
    As a fix we get_task_struct() in perf_event_alloc() at above mentioned
    assignment and put_task_struct() in _free_event().
    
    Signed-off-by: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <stable@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 63b6da39bb38e8f1a1ef3180d32a39d6 ("perf: Fix perf_event_exit_task() race")
    Link: http://lkml.kernel.org/r/20180409100346.6416-1-bhole_prashant_q7@lab.ntt.co.jp
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6f22be4ba787eb76abbf66aad14b4d60ec59e641
Author: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
Date:   Mon Apr 9 19:03:46 2018 +0900

    perf/core: Fix use-after-free in uprobe_perf_close()
    
    commit 621b6d2ea297d0fb6030452c5bcd221f12165fcf upstream.
    
    A use-after-free bug was caught by KASAN while running usdt related
    code (BCC project. bcc/tests/python/test_usdt2.py):
    
            ==================================================================
            BUG: KASAN: use-after-free in uprobe_perf_close+0x222/0x3b0
            Read of size 4 at addr ffff880384f9b4a4 by task test_usdt2.py/870
    
            CPU: 4 PID: 870 Comm: test_usdt2.py Tainted: G        W         4.16.0-next-20180409 #215
            Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
            Call Trace:
             dump_stack+0xc7/0x15b
             ? show_regs_print_info+0x5/0x5
             ? printk+0x9c/0xc3
             ? kmsg_dump_rewind_nolock+0x6e/0x6e
             ? uprobe_perf_close+0x222/0x3b0
             print_address_description+0x83/0x3a0
             ? uprobe_perf_close+0x222/0x3b0
             kasan_report+0x1dd/0x460
             ? uprobe_perf_close+0x222/0x3b0
             uprobe_perf_close+0x222/0x3b0
             ? probes_open+0x180/0x180
             ? free_filters_list+0x290/0x290
             trace_uprobe_register+0x1bb/0x500
             ? perf_event_attach_bpf_prog+0x310/0x310
             ? probe_event_disable+0x4e0/0x4e0
             perf_uprobe_destroy+0x63/0xd0
             _free_event+0x2bc/0xbd0
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ring_buffer_attach+0x550/0x550
             ? kvm_sched_clock_read+0x1a/0x30
             ? perf_event_release_kernel+0x3e4/0xc00
             ? __mutex_unlock_slowpath+0x12e/0x540
             ? wait_for_completion+0x430/0x430
             ? lock_downgrade+0x3c0/0x3c0
             ? lock_release+0x980/0x980
             ? do_raw_spin_trylock+0x118/0x150
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             perf_event_release_kernel+0x5d4/0xc00
             ? put_event+0x30/0x30
             ? fsnotify+0xd2d/0xea0
             ? sched_clock_cpu+0x18/0x1a0
             ? __fsnotify_update_child_dentry_flags.part.0+0x1b0/0x1b0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? pvclock_read_flags+0x80/0x80
             ? kvm_sched_clock_read+0x1a/0x30
             ? sched_clock_cpu+0x18/0x1a0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? locks_remove_file+0xec/0x470
             ? pvclock_read_flags+0x80/0x80
             ? fcntl_setlk+0x880/0x880
             ? ima_file_free+0x8d/0x390
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ima_file_check+0x110/0x110
             ? fsnotify+0xea0/0xea0
             ? kvm_sched_clock_read+0x1a/0x30
             ? rcu_note_context_switch+0x600/0x600
             perf_release+0x21/0x40
             __fput+0x264/0x620
             ? fput+0xf0/0xf0
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             ? SyS_fchdir+0x100/0x100
             ? fsnotify+0xea0/0xea0
             task_work_run+0x14b/0x1e0
             ? task_work_cancel+0x1c0/0x1c0
             ? copy_fd_bitmaps+0x150/0x150
             ? vfs_read+0xe5/0x260
             exit_to_usermode_loop+0x17b/0x1b0
             ? trace_event_raw_event_sys_exit+0x1a0/0x1a0
             do_syscall_64+0x3f6/0x490
             ? syscall_return_slowpath+0x2c0/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? syscall_return_slowpath+0x1a3/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? prepare_exit_to_usermode+0x11c/0x1e0
             ? enter_from_user_mode+0x30/0x30
            random: crng init done
             ? __put_user_4+0x1c/0x30
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
            RIP: 0033:0x7f41d95f9340
            RSP: 002b:00007fffe71e4268 EFLAGS: 00000246 ORIG_RAX: 0000000000000003
            RAX: 0000000000000000 RBX: 000000000000000d RCX: 00007f41d95f9340
            RDX: 0000000000000000 RSI: 0000000000002401 RDI: 000000000000000d
            RBP: 0000000000000000 R08: 00007f41ca8ff700 R09: 00007f41d996dd1f
            R10: 00007fffe71e41e0 R11: 0000000000000246 R12: 00007fffe71e4330
            R13: 0000000000000000 R14: fffffffffffffffc R15: 00007fffe71e4290
    
            Allocated by task 870:
             kasan_kmalloc+0xa0/0xd0
             kmem_cache_alloc_node+0x11a/0x430
             copy_process.part.19+0x11a0/0x41c0
             _do_fork+0x1be/0xa20
             do_syscall_64+0x198/0x490
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
    
            Freed by task 0:
             __kasan_slab_free+0x12e/0x180
             kmem_cache_free+0x102/0x4d0
             free_task+0xfe/0x160
             __put_task_struct+0x189/0x290
             delayed_put_task_struct+0x119/0x250
             rcu_process_callbacks+0xa6c/0x1b60
             __do_softirq+0x238/0x7ae
    
            The buggy address belongs to the object at ffff880384f9b480
             which belongs to the cache task_struct of size 12928
    
    It occurs because task_struct is freed before perf_event which refers
    to the task and task flags are checked while teardown of the event.
    perf_event_alloc() assigns task_struct to hw.target of perf_event,
    but there is no reference counting for it.
    
    As a fix we get_task_struct() in perf_event_alloc() at above mentioned
    assignment and put_task_struct() in _free_event().
    
    Signed-off-by: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <stable@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 63b6da39bb38e8f1a1ef3180d32a39d6 ("perf: Fix perf_event_exit_task() race")
    Link: http://lkml.kernel.org/r/20180409100346.6416-1-bhole_prashant_q7@lab.ntt.co.jp
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ab0ed342375f15e4316e7295e661125596b654ae
Author: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
Date:   Mon Apr 9 19:03:46 2018 +0900

    perf/core: Fix use-after-free in uprobe_perf_close()
    
    commit 621b6d2ea297d0fb6030452c5bcd221f12165fcf upstream.
    
    A use-after-free bug was caught by KASAN while running usdt related
    code (BCC project. bcc/tests/python/test_usdt2.py):
    
            ==================================================================
            BUG: KASAN: use-after-free in uprobe_perf_close+0x222/0x3b0
            Read of size 4 at addr ffff880384f9b4a4 by task test_usdt2.py/870
    
            CPU: 4 PID: 870 Comm: test_usdt2.py Tainted: G        W         4.16.0-next-20180409 #215
            Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
            Call Trace:
             dump_stack+0xc7/0x15b
             ? show_regs_print_info+0x5/0x5
             ? printk+0x9c/0xc3
             ? kmsg_dump_rewind_nolock+0x6e/0x6e
             ? uprobe_perf_close+0x222/0x3b0
             print_address_description+0x83/0x3a0
             ? uprobe_perf_close+0x222/0x3b0
             kasan_report+0x1dd/0x460
             ? uprobe_perf_close+0x222/0x3b0
             uprobe_perf_close+0x222/0x3b0
             ? probes_open+0x180/0x180
             ? free_filters_list+0x290/0x290
             trace_uprobe_register+0x1bb/0x500
             ? perf_event_attach_bpf_prog+0x310/0x310
             ? probe_event_disable+0x4e0/0x4e0
             perf_uprobe_destroy+0x63/0xd0
             _free_event+0x2bc/0xbd0
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ring_buffer_attach+0x550/0x550
             ? kvm_sched_clock_read+0x1a/0x30
             ? perf_event_release_kernel+0x3e4/0xc00
             ? __mutex_unlock_slowpath+0x12e/0x540
             ? wait_for_completion+0x430/0x430
             ? lock_downgrade+0x3c0/0x3c0
             ? lock_release+0x980/0x980
             ? do_raw_spin_trylock+0x118/0x150
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             perf_event_release_kernel+0x5d4/0xc00
             ? put_event+0x30/0x30
             ? fsnotify+0xd2d/0xea0
             ? sched_clock_cpu+0x18/0x1a0
             ? __fsnotify_update_child_dentry_flags.part.0+0x1b0/0x1b0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? pvclock_read_flags+0x80/0x80
             ? kvm_sched_clock_read+0x1a/0x30
             ? sched_clock_cpu+0x18/0x1a0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? locks_remove_file+0xec/0x470
             ? pvclock_read_flags+0x80/0x80
             ? fcntl_setlk+0x880/0x880
             ? ima_file_free+0x8d/0x390
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ima_file_check+0x110/0x110
             ? fsnotify+0xea0/0xea0
             ? kvm_sched_clock_read+0x1a/0x30
             ? rcu_note_context_switch+0x600/0x600
             perf_release+0x21/0x40
             __fput+0x264/0x620
             ? fput+0xf0/0xf0
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             ? SyS_fchdir+0x100/0x100
             ? fsnotify+0xea0/0xea0
             task_work_run+0x14b/0x1e0
             ? task_work_cancel+0x1c0/0x1c0
             ? copy_fd_bitmaps+0x150/0x150
             ? vfs_read+0xe5/0x260
             exit_to_usermode_loop+0x17b/0x1b0
             ? trace_event_raw_event_sys_exit+0x1a0/0x1a0
             do_syscall_64+0x3f6/0x490
             ? syscall_return_slowpath+0x2c0/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? syscall_return_slowpath+0x1a3/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? prepare_exit_to_usermode+0x11c/0x1e0
             ? enter_from_user_mode+0x30/0x30
            random: crng init done
             ? __put_user_4+0x1c/0x30
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
            RIP: 0033:0x7f41d95f9340
            RSP: 002b:00007fffe71e4268 EFLAGS: 00000246 ORIG_RAX: 0000000000000003
            RAX: 0000000000000000 RBX: 000000000000000d RCX: 00007f41d95f9340
            RDX: 0000000000000000 RSI: 0000000000002401 RDI: 000000000000000d
            RBP: 0000000000000000 R08: 00007f41ca8ff700 R09: 00007f41d996dd1f
            R10: 00007fffe71e41e0 R11: 0000000000000246 R12: 00007fffe71e4330
            R13: 0000000000000000 R14: fffffffffffffffc R15: 00007fffe71e4290
    
            Allocated by task 870:
             kasan_kmalloc+0xa0/0xd0
             kmem_cache_alloc_node+0x11a/0x430
             copy_process.part.19+0x11a0/0x41c0
             _do_fork+0x1be/0xa20
             do_syscall_64+0x198/0x490
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
    
            Freed by task 0:
             __kasan_slab_free+0x12e/0x180
             kmem_cache_free+0x102/0x4d0
             free_task+0xfe/0x160
             __put_task_struct+0x189/0x290
             delayed_put_task_struct+0x119/0x250
             rcu_process_callbacks+0xa6c/0x1b60
             __do_softirq+0x238/0x7ae
    
            The buggy address belongs to the object at ffff880384f9b480
             which belongs to the cache task_struct of size 12928
    
    It occurs because task_struct is freed before perf_event which refers
    to the task and task flags are checked while teardown of the event.
    perf_event_alloc() assigns task_struct to hw.target of perf_event,
    but there is no reference counting for it.
    
    As a fix we get_task_struct() in perf_event_alloc() at above mentioned
    assignment and put_task_struct() in _free_event().
    
    Signed-off-by: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <stable@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 63b6da39bb38e8f1a1ef3180d32a39d6 ("perf: Fix perf_event_exit_task() race")
    Link: http://lkml.kernel.org/r/20180409100346.6416-1-bhole_prashant_q7@lab.ntt.co.jp
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 122a80f16ee6d8bb3cd4e3b81a9bf32cda2ba61d
Author: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
Date:   Mon Apr 9 19:03:46 2018 +0900

    perf/core: Fix use-after-free in uprobe_perf_close()
    
    commit 621b6d2ea297d0fb6030452c5bcd221f12165fcf upstream.
    
    A use-after-free bug was caught by KASAN while running usdt related
    code (BCC project. bcc/tests/python/test_usdt2.py):
    
            ==================================================================
            BUG: KASAN: use-after-free in uprobe_perf_close+0x222/0x3b0
            Read of size 4 at addr ffff880384f9b4a4 by task test_usdt2.py/870
    
            CPU: 4 PID: 870 Comm: test_usdt2.py Tainted: G        W         4.16.0-next-20180409 #215
            Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
            Call Trace:
             dump_stack+0xc7/0x15b
             ? show_regs_print_info+0x5/0x5
             ? printk+0x9c/0xc3
             ? kmsg_dump_rewind_nolock+0x6e/0x6e
             ? uprobe_perf_close+0x222/0x3b0
             print_address_description+0x83/0x3a0
             ? uprobe_perf_close+0x222/0x3b0
             kasan_report+0x1dd/0x460
             ? uprobe_perf_close+0x222/0x3b0
             uprobe_perf_close+0x222/0x3b0
             ? probes_open+0x180/0x180
             ? free_filters_list+0x290/0x290
             trace_uprobe_register+0x1bb/0x500
             ? perf_event_attach_bpf_prog+0x310/0x310
             ? probe_event_disable+0x4e0/0x4e0
             perf_uprobe_destroy+0x63/0xd0
             _free_event+0x2bc/0xbd0
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ring_buffer_attach+0x550/0x550
             ? kvm_sched_clock_read+0x1a/0x30
             ? perf_event_release_kernel+0x3e4/0xc00
             ? __mutex_unlock_slowpath+0x12e/0x540
             ? wait_for_completion+0x430/0x430
             ? lock_downgrade+0x3c0/0x3c0
             ? lock_release+0x980/0x980
             ? do_raw_spin_trylock+0x118/0x150
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             perf_event_release_kernel+0x5d4/0xc00
             ? put_event+0x30/0x30
             ? fsnotify+0xd2d/0xea0
             ? sched_clock_cpu+0x18/0x1a0
             ? __fsnotify_update_child_dentry_flags.part.0+0x1b0/0x1b0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? pvclock_read_flags+0x80/0x80
             ? kvm_sched_clock_read+0x1a/0x30
             ? sched_clock_cpu+0x18/0x1a0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? locks_remove_file+0xec/0x470
             ? pvclock_read_flags+0x80/0x80
             ? fcntl_setlk+0x880/0x880
             ? ima_file_free+0x8d/0x390
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ima_file_check+0x110/0x110
             ? fsnotify+0xea0/0xea0
             ? kvm_sched_clock_read+0x1a/0x30
             ? rcu_note_context_switch+0x600/0x600
             perf_release+0x21/0x40
             __fput+0x264/0x620
             ? fput+0xf0/0xf0
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             ? SyS_fchdir+0x100/0x100
             ? fsnotify+0xea0/0xea0
             task_work_run+0x14b/0x1e0
             ? task_work_cancel+0x1c0/0x1c0
             ? copy_fd_bitmaps+0x150/0x150
             ? vfs_read+0xe5/0x260
             exit_to_usermode_loop+0x17b/0x1b0
             ? trace_event_raw_event_sys_exit+0x1a0/0x1a0
             do_syscall_64+0x3f6/0x490
             ? syscall_return_slowpath+0x2c0/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? syscall_return_slowpath+0x1a3/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? prepare_exit_to_usermode+0x11c/0x1e0
             ? enter_from_user_mode+0x30/0x30
            random: crng init done
             ? __put_user_4+0x1c/0x30
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
            RIP: 0033:0x7f41d95f9340
            RSP: 002b:00007fffe71e4268 EFLAGS: 00000246 ORIG_RAX: 0000000000000003
            RAX: 0000000000000000 RBX: 000000000000000d RCX: 00007f41d95f9340
            RDX: 0000000000000000 RSI: 0000000000002401 RDI: 000000000000000d
            RBP: 0000000000000000 R08: 00007f41ca8ff700 R09: 00007f41d996dd1f
            R10: 00007fffe71e41e0 R11: 0000000000000246 R12: 00007fffe71e4330
            R13: 0000000000000000 R14: fffffffffffffffc R15: 00007fffe71e4290
    
            Allocated by task 870:
             kasan_kmalloc+0xa0/0xd0
             kmem_cache_alloc_node+0x11a/0x430
             copy_process.part.19+0x11a0/0x41c0
             _do_fork+0x1be/0xa20
             do_syscall_64+0x198/0x490
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
    
            Freed by task 0:
             __kasan_slab_free+0x12e/0x180
             kmem_cache_free+0x102/0x4d0
             free_task+0xfe/0x160
             __put_task_struct+0x189/0x290
             delayed_put_task_struct+0x119/0x250
             rcu_process_callbacks+0xa6c/0x1b60
             __do_softirq+0x238/0x7ae
    
            The buggy address belongs to the object at ffff880384f9b480
             which belongs to the cache task_struct of size 12928
    
    It occurs because task_struct is freed before perf_event which refers
    to the task and task flags are checked while teardown of the event.
    perf_event_alloc() assigns task_struct to hw.target of perf_event,
    but there is no reference counting for it.
    
    As a fix we get_task_struct() in perf_event_alloc() at above mentioned
    assignment and put_task_struct() in _free_event().
    
    Signed-off-by: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <stable@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 63b6da39bb38e8f1a1ef3180d32a39d6 ("perf: Fix perf_event_exit_task() race")
    Link: http://lkml.kernel.org/r/20180409100346.6416-1-bhole_prashant_q7@lab.ntt.co.jp
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 621b6d2ea297d0fb6030452c5bcd221f12165fcf
Author: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
Date:   Mon Apr 9 19:03:46 2018 +0900

    perf/core: Fix use-after-free in uprobe_perf_close()
    
    A use-after-free bug was caught by KASAN while running usdt related
    code (BCC project. bcc/tests/python/test_usdt2.py):
    
            ==================================================================
            BUG: KASAN: use-after-free in uprobe_perf_close+0x222/0x3b0
            Read of size 4 at addr ffff880384f9b4a4 by task test_usdt2.py/870
    
            CPU: 4 PID: 870 Comm: test_usdt2.py Tainted: G        W         4.16.0-next-20180409 #215
            Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014
            Call Trace:
             dump_stack+0xc7/0x15b
             ? show_regs_print_info+0x5/0x5
             ? printk+0x9c/0xc3
             ? kmsg_dump_rewind_nolock+0x6e/0x6e
             ? uprobe_perf_close+0x222/0x3b0
             print_address_description+0x83/0x3a0
             ? uprobe_perf_close+0x222/0x3b0
             kasan_report+0x1dd/0x460
             ? uprobe_perf_close+0x222/0x3b0
             uprobe_perf_close+0x222/0x3b0
             ? probes_open+0x180/0x180
             ? free_filters_list+0x290/0x290
             trace_uprobe_register+0x1bb/0x500
             ? perf_event_attach_bpf_prog+0x310/0x310
             ? probe_event_disable+0x4e0/0x4e0
             perf_uprobe_destroy+0x63/0xd0
             _free_event+0x2bc/0xbd0
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ring_buffer_attach+0x550/0x550
             ? kvm_sched_clock_read+0x1a/0x30
             ? perf_event_release_kernel+0x3e4/0xc00
             ? __mutex_unlock_slowpath+0x12e/0x540
             ? wait_for_completion+0x430/0x430
             ? lock_downgrade+0x3c0/0x3c0
             ? lock_release+0x980/0x980
             ? do_raw_spin_trylock+0x118/0x150
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             perf_event_release_kernel+0x5d4/0xc00
             ? put_event+0x30/0x30
             ? fsnotify+0xd2d/0xea0
             ? sched_clock_cpu+0x18/0x1a0
             ? __fsnotify_update_child_dentry_flags.part.0+0x1b0/0x1b0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? pvclock_read_flags+0x80/0x80
             ? kvm_sched_clock_read+0x1a/0x30
             ? sched_clock_cpu+0x18/0x1a0
             ? pvclock_clocksource_read+0x152/0x2b0
             ? locks_remove_file+0xec/0x470
             ? pvclock_read_flags+0x80/0x80
             ? fcntl_setlk+0x880/0x880
             ? ima_file_free+0x8d/0x390
             ? lockdep_rcu_suspicious+0x100/0x100
             ? ima_file_check+0x110/0x110
             ? fsnotify+0xea0/0xea0
             ? kvm_sched_clock_read+0x1a/0x30
             ? rcu_note_context_switch+0x600/0x600
             perf_release+0x21/0x40
             __fput+0x264/0x620
             ? fput+0xf0/0xf0
             ? do_raw_spin_unlock+0x121/0x210
             ? do_raw_spin_trylock+0x150/0x150
             ? SyS_fchdir+0x100/0x100
             ? fsnotify+0xea0/0xea0
             task_work_run+0x14b/0x1e0
             ? task_work_cancel+0x1c0/0x1c0
             ? copy_fd_bitmaps+0x150/0x150
             ? vfs_read+0xe5/0x260
             exit_to_usermode_loop+0x17b/0x1b0
             ? trace_event_raw_event_sys_exit+0x1a0/0x1a0
             do_syscall_64+0x3f6/0x490
             ? syscall_return_slowpath+0x2c0/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? syscall_return_slowpath+0x1a3/0x2c0
             ? lockdep_sys_exit+0x1f/0xaa
             ? prepare_exit_to_usermode+0x11c/0x1e0
             ? enter_from_user_mode+0x30/0x30
            random: crng init done
             ? __put_user_4+0x1c/0x30
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
            RIP: 0033:0x7f41d95f9340
            RSP: 002b:00007fffe71e4268 EFLAGS: 00000246 ORIG_RAX: 0000000000000003
            RAX: 0000000000000000 RBX: 000000000000000d RCX: 00007f41d95f9340
            RDX: 0000000000000000 RSI: 0000000000002401 RDI: 000000000000000d
            RBP: 0000000000000000 R08: 00007f41ca8ff700 R09: 00007f41d996dd1f
            R10: 00007fffe71e41e0 R11: 0000000000000246 R12: 00007fffe71e4330
            R13: 0000000000000000 R14: fffffffffffffffc R15: 00007fffe71e4290
    
            Allocated by task 870:
             kasan_kmalloc+0xa0/0xd0
             kmem_cache_alloc_node+0x11a/0x430
             copy_process.part.19+0x11a0/0x41c0
             _do_fork+0x1be/0xa20
             do_syscall_64+0x198/0x490
             entry_SYSCALL_64_after_hwframe+0x3d/0xa2
    
            Freed by task 0:
             __kasan_slab_free+0x12e/0x180
             kmem_cache_free+0x102/0x4d0
             free_task+0xfe/0x160
             __put_task_struct+0x189/0x290
             delayed_put_task_struct+0x119/0x250
             rcu_process_callbacks+0xa6c/0x1b60
             __do_softirq+0x238/0x7ae
    
            The buggy address belongs to the object at ffff880384f9b480
             which belongs to the cache task_struct of size 12928
    
    It occurs because task_struct is freed before perf_event which refers
    to the task and task flags are checked while teardown of the event.
    perf_event_alloc() assigns task_struct to hw.target of perf_event,
    but there is no reference counting for it.
    
    As a fix we get_task_struct() in perf_event_alloc() at above mentioned
    assignment and put_task_struct() in _free_event().
    
    Signed-off-by: Prashant Bhole <bhole_prashant_q7@lab.ntt.co.jp>
    Reviewed-by: Oleg Nesterov <oleg@redhat.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: <stable@kernel.org>
    Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
    Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
    Cc: Jiri Olsa <jolsa@redhat.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Fixes: 63b6da39bb38e8f1a1ef3180d32a39d6 ("perf: Fix perf_event_exit_task() race")
    Link: http://lkml.kernel.org/r/20180409100346.6416-1-bhole_prashant_q7@lab.ntt.co.jp
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 3563289208ecef339853692ecbf8690084744b53
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Fri Mar 16 14:37:33 2018 -0300

    perf annotate: Use the default annotation options for --stdio2
    
    With an empty '[annotate]' section in ~/.perfconfig:
    
      # perf record -a --all-kernel -e '{cycles,instructions}:P' sleep 5
      [ perf record: Woken up 1 times to write data ]
      [ perf record: Captured and wrote 2.243 MB perf.data (5513 samples) ]
      # perf annotate --stdio2 _raw_spin_lock | head -20
    
                         Disassembly of section .text:
    
                         ffffffff81868790 <_raw_spin_lock>:
                         _raw_spin_lock():
                         EXPORT_SYMBOL(_raw_spin_trylock_bh);
                         #endif
    
                         #ifndef CONFIG_INLINE_SPIN_LOCK
                         void __lockfunc _raw_spin_lock(raw_spinlock_t *lock)
                         {
                          callq  __fentry__
                         atomic_cmpxchg():
                                 return xadd(&v->counter, -i);
                         }
    
                         static __always_inline int atomic_cmpxchg(atomic_t *v, int old, int new)
                         {
      # perf annotate --stdio2 _raw_spin_lock | head -20
                          callq  __fentry__
                           xor    %eax,%eax
                           mov    $0x1,%edx
       87.50 100.00        lock   cmpxchg %edx,(%rdi)
        6.25   0.00        test   %eax,%eax
                          jne    16
        6.25   0.00        repz   retq
                     16:   mov    %eax,%esi
                          jmpq   ffffffff810e96b0 <queued_spin_lock_slowpath>
      #
      # cat ~/.perfconfig
      [annotate]
    
        hide_src_code = false
        show_linenr = true
      # perf annotate --stdio2 _raw_spin_lock | head -20
    
                     3   Disassembly of section .text:
    
                     5   ffffffff81868790 <_raw_spin_lock>:
                     6   _raw_spin_lock():
                     143 EXPORT_SYMBOL(_raw_spin_trylock_bh);
                     144 #endif
    
                     146 #ifndef CONFIG_INLINE_SPIN_LOCK
                     147 void __lockfunc _raw_spin_lock(raw_spinlock_t *lock)
                     148 {
                          callq  __fentry__
                     150 atomic_cmpxchg():
                     187         return xadd(&v->counter, -i);
                     188 }
    
                     190 static __always_inline int atomic_cmpxchg(atomic_t *v, int old, int new)
                     191 {
      #
      # cat ~/.perfconfig
      [annotate]
    
        hide_src_code = true
        show_total_period = true
      # perf annotate --stdio2 _raw_spin_lock | head -20
                                    callq  __fentry__
                                     xor    %eax,%eax
                                     mov    $0x1,%edx
          1411316      152339        lock   cmpxchg %edx,(%rdi)
           344694           0        test   %eax,%eax
                                    jne    16
            80806           0        repz   retq
                               16:   mov    %eax,%esi
                                    jmpq   ffffffff810e96b0 <queued_spin_lock_slowpath>
      #
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Andi Kleen <ak@linux.intel.com>
    Cc: David Ahern <dsahern@gmail.com>
    Cc: Jin Yao <yao.jin@linux.intel.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Wang Nan <wangnan0@huawei.com>
    Link: https://lkml.kernel.org/n/tip-nu4rxg5zkdtgs1b2gc40p7v7@git.kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 1bb454527e18b04437c41b2b4dfe31678fb4146d
Author: Leon Romanovsky <leon@kernel.org>
Date:   Wed Mar 7 15:29:09 2018 +0200

    RDMA/mlx5: Fix integer overflow while resizing CQ
    
    commit 28e9091e3119933c38933cb8fc48d5618eb784c8 upstream.
    
    The user can provide very large cqe_size which will cause to integer
    overflow as it can be seen in the following UBSAN warning:
    
    =======================================================================
    UBSAN: Undefined behaviour in drivers/infiniband/hw/mlx5/cq.c:1192:53
    signed integer overflow:
    64870 * 65536 cannot be represented in type 'int'
    CPU: 0 PID: 267 Comm: syzkaller605279 Not tainted 4.15.0+ #90 Hardware
    name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ubsan_epilogue+0xe/0x81
     handle_overflow+0x1f3/0x251
     ? __ubsan_handle_negate_overflow+0x19b/0x19b
     ? lock_acquire+0x440/0x440
     mlx5_ib_resize_cq+0x17e7/0x1e40
     ? cyc2ns_read_end+0x10/0x10
     ? native_read_msr_safe+0x6c/0x9b
     ? cyc2ns_read_end+0x10/0x10
     ? mlx5_ib_modify_cq+0x220/0x220
     ? sched_clock_cpu+0x18/0x200
     ? lookup_get_idr_uobject+0x200/0x200
     ? rdma_lookup_get_uobject+0x145/0x2f0
     ib_uverbs_resize_cq+0x207/0x3e0
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ib_uverbs_write+0x7f9/0xef0
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ? uverbs_devnode+0x110/0x110
     ? sched_clock_cpu+0x18/0x200
     ? do_raw_spin_trylock+0x100/0x100
     ? __lru_cache_add+0x16e/0x290
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? sched_clock_cpu+0x18/0x200
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433549
    RSP: 002b:00007ffe63bd1ea8 EFLAGS: 00000217
    =======================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 3.13
    Fixes: bde51583f49b ("IB/mlx5: Add support for resize CQ")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6f8b6627f367d040877afd44635b867109c142e9
Author: Leon Romanovsky <leon@kernel.org>
Date:   Wed Mar 7 15:29:09 2018 +0200

    RDMA/mlx5: Fix integer overflow while resizing CQ
    
    commit 28e9091e3119933c38933cb8fc48d5618eb784c8 upstream.
    
    The user can provide very large cqe_size which will cause to integer
    overflow as it can be seen in the following UBSAN warning:
    
    =======================================================================
    UBSAN: Undefined behaviour in drivers/infiniband/hw/mlx5/cq.c:1192:53
    signed integer overflow:
    64870 * 65536 cannot be represented in type 'int'
    CPU: 0 PID: 267 Comm: syzkaller605279 Not tainted 4.15.0+ #90 Hardware
    name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ubsan_epilogue+0xe/0x81
     handle_overflow+0x1f3/0x251
     ? __ubsan_handle_negate_overflow+0x19b/0x19b
     ? lock_acquire+0x440/0x440
     mlx5_ib_resize_cq+0x17e7/0x1e40
     ? cyc2ns_read_end+0x10/0x10
     ? native_read_msr_safe+0x6c/0x9b
     ? cyc2ns_read_end+0x10/0x10
     ? mlx5_ib_modify_cq+0x220/0x220
     ? sched_clock_cpu+0x18/0x200
     ? lookup_get_idr_uobject+0x200/0x200
     ? rdma_lookup_get_uobject+0x145/0x2f0
     ib_uverbs_resize_cq+0x207/0x3e0
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ib_uverbs_write+0x7f9/0xef0
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ? uverbs_devnode+0x110/0x110
     ? sched_clock_cpu+0x18/0x200
     ? do_raw_spin_trylock+0x100/0x100
     ? __lru_cache_add+0x16e/0x290
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? sched_clock_cpu+0x18/0x200
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433549
    RSP: 002b:00007ffe63bd1ea8 EFLAGS: 00000217
    =======================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 3.13
    Fixes: bde51583f49b ("IB/mlx5: Add support for resize CQ")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4c6994806f708559c2812b73501406e21ae5dcd0
Author: Joseph Qi <joseph.qi@linux.alibaba.com>
Date:   Fri Mar 16 14:51:27 2018 +0800

    blk-throttle: fix race between blkcg_bio_issue_check() and cgroup_rmdir()
    
    We've triggered a WARNING in blk_throtl_bio() when throttling writeback
    io, which complains blkg->refcnt is already 0 when calling blkg_get(),
    and then kernel crashes with invalid page request.
    After investigating this issue, we've found it is caused by a race
    between blkcg_bio_issue_check() and cgroup_rmdir(), which is described
    below:
    
    writeback kworker               cgroup_rmdir
                                      cgroup_destroy_locked
                                        kill_css
                                          css_killed_ref_fn
                                            css_killed_work_fn
                                              offline_css
                                                blkcg_css_offline
      blkcg_bio_issue_check
        rcu_read_lock
        blkg_lookup
                                                  spin_trylock(q->queue_lock)
                                                  blkg_destroy
                                                  spin_unlock(q->queue_lock)
        blk_throtl_bio
        spin_lock_irq(q->queue_lock)
        ...
        spin_unlock_irq(q->queue_lock)
      rcu_read_unlock
    
    Since rcu can only prevent blkg from releasing when it is being used,
    the blkg->refcnt can be decreased to 0 during blkg_destroy() and schedule
    blkg release.
    Then trying to blkg_get() in blk_throtl_bio() will complains the WARNING.
    And then the corresponding blkg_put() will schedule blkg release again,
    which result in double free.
    This race is introduced by commit ae1188963611 ("blkcg: consolidate blkg
    creation in blkcg_bio_issue_check()"). Before this commit, it will
    lookup first and then try to lookup/create again with queue_lock. Since
    revive this logic is a bit drastic, so fix it by only offlining pd during
    blkcg_css_offline(), and move the rest destruction (especially
    blkg_put()) into blkcg_css_free(), which should be the right way as
    discussed.
    
    Fixes: ae1188963611 ("blkcg: consolidate blkg creation in blkcg_bio_issue_check()")
    Reported-by: Jiufei Xue <jiufei.xue@linux.alibaba.com>
    Signed-off-by: Joseph Qi <joseph.qi@linux.alibaba.com>
    Acked-by: Tejun Heo <tj@kernel.org>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 45c0604dbeae88a00d773473dd0f3532257b9fd6
Author: Leon Romanovsky <leon@kernel.org>
Date:   Wed Mar 7 15:29:09 2018 +0200

    RDMA/mlx5: Fix integer overflow while resizing CQ
    
    commit 28e9091e3119933c38933cb8fc48d5618eb784c8 upstream.
    
    The user can provide very large cqe_size which will cause to integer
    overflow as it can be seen in the following UBSAN warning:
    
    =======================================================================
    UBSAN: Undefined behaviour in drivers/infiniband/hw/mlx5/cq.c:1192:53
    signed integer overflow:
    64870 * 65536 cannot be represented in type 'int'
    CPU: 0 PID: 267 Comm: syzkaller605279 Not tainted 4.15.0+ #90 Hardware
    name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ubsan_epilogue+0xe/0x81
     handle_overflow+0x1f3/0x251
     ? __ubsan_handle_negate_overflow+0x19b/0x19b
     ? lock_acquire+0x440/0x440
     mlx5_ib_resize_cq+0x17e7/0x1e40
     ? cyc2ns_read_end+0x10/0x10
     ? native_read_msr_safe+0x6c/0x9b
     ? cyc2ns_read_end+0x10/0x10
     ? mlx5_ib_modify_cq+0x220/0x220
     ? sched_clock_cpu+0x18/0x200
     ? lookup_get_idr_uobject+0x200/0x200
     ? rdma_lookup_get_uobject+0x145/0x2f0
     ib_uverbs_resize_cq+0x207/0x3e0
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ib_uverbs_write+0x7f9/0xef0
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ? uverbs_devnode+0x110/0x110
     ? sched_clock_cpu+0x18/0x200
     ? do_raw_spin_trylock+0x100/0x100
     ? __lru_cache_add+0x16e/0x290
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? sched_clock_cpu+0x18/0x200
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433549
    RSP: 002b:00007ffe63bd1ea8 EFLAGS: 00000217
    =======================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 3.13
    Fixes: bde51583f49b ("IB/mlx5: Add support for resize CQ")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dbfed071633c27242eba0fe710d396168fd2dba7
Author: Leon Romanovsky <leon@kernel.org>
Date:   Wed Mar 7 15:29:09 2018 +0200

    RDMA/mlx5: Fix integer overflow while resizing CQ
    
    commit 28e9091e3119933c38933cb8fc48d5618eb784c8 upstream.
    
    The user can provide very large cqe_size which will cause to integer
    overflow as it can be seen in the following UBSAN warning:
    
    =======================================================================
    UBSAN: Undefined behaviour in drivers/infiniband/hw/mlx5/cq.c:1192:53
    signed integer overflow:
    64870 * 65536 cannot be represented in type 'int'
    CPU: 0 PID: 267 Comm: syzkaller605279 Not tainted 4.15.0+ #90 Hardware
    name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ubsan_epilogue+0xe/0x81
     handle_overflow+0x1f3/0x251
     ? __ubsan_handle_negate_overflow+0x19b/0x19b
     ? lock_acquire+0x440/0x440
     mlx5_ib_resize_cq+0x17e7/0x1e40
     ? cyc2ns_read_end+0x10/0x10
     ? native_read_msr_safe+0x6c/0x9b
     ? cyc2ns_read_end+0x10/0x10
     ? mlx5_ib_modify_cq+0x220/0x220
     ? sched_clock_cpu+0x18/0x200
     ? lookup_get_idr_uobject+0x200/0x200
     ? rdma_lookup_get_uobject+0x145/0x2f0
     ib_uverbs_resize_cq+0x207/0x3e0
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ib_uverbs_write+0x7f9/0xef0
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ? uverbs_devnode+0x110/0x110
     ? sched_clock_cpu+0x18/0x200
     ? do_raw_spin_trylock+0x100/0x100
     ? __lru_cache_add+0x16e/0x290
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? sched_clock_cpu+0x18/0x200
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433549
    RSP: 002b:00007ffe63bd1ea8 EFLAGS: 00000217
    =======================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 3.13
    Fixes: bde51583f49b ("IB/mlx5: Add support for resize CQ")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28e9091e3119933c38933cb8fc48d5618eb784c8
Author: Leon Romanovsky <leon@kernel.org>
Date:   Wed Mar 7 15:29:09 2018 +0200

    RDMA/mlx5: Fix integer overflow while resizing CQ
    
    The user can provide very large cqe_size which will cause to integer
    overflow as it can be seen in the following UBSAN warning:
    
    =======================================================================
    UBSAN: Undefined behaviour in drivers/infiniband/hw/mlx5/cq.c:1192:53
    signed integer overflow:
    64870 * 65536 cannot be represented in type 'int'
    CPU: 0 PID: 267 Comm: syzkaller605279 Not tainted 4.15.0+ #90 Hardware
    name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS
    rel-1.7.5-0-ge51488c-20140602_164612-nilsson.home.kraxel.org 04/01/2014
    Call Trace:
     dump_stack+0xde/0x164
     ? dma_virt_map_sg+0x22c/0x22c
     ubsan_epilogue+0xe/0x81
     handle_overflow+0x1f3/0x251
     ? __ubsan_handle_negate_overflow+0x19b/0x19b
     ? lock_acquire+0x440/0x440
     mlx5_ib_resize_cq+0x17e7/0x1e40
     ? cyc2ns_read_end+0x10/0x10
     ? native_read_msr_safe+0x6c/0x9b
     ? cyc2ns_read_end+0x10/0x10
     ? mlx5_ib_modify_cq+0x220/0x220
     ? sched_clock_cpu+0x18/0x200
     ? lookup_get_idr_uobject+0x200/0x200
     ? rdma_lookup_get_uobject+0x145/0x2f0
     ib_uverbs_resize_cq+0x207/0x3e0
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ib_uverbs_write+0x7f9/0xef0
     ? cyc2ns_read_end+0x10/0x10
     ? print_irqtrace_events+0x280/0x280
     ? ib_uverbs_ex_create_cq+0x250/0x250
     ? uverbs_devnode+0x110/0x110
     ? sched_clock_cpu+0x18/0x200
     ? do_raw_spin_trylock+0x100/0x100
     ? __lru_cache_add+0x16e/0x290
     __vfs_write+0x10d/0x700
     ? uverbs_devnode+0x110/0x110
     ? kernel_read+0x170/0x170
     ? sched_clock_cpu+0x18/0x200
     ? security_file_permission+0x93/0x260
     vfs_write+0x1b0/0x550
     SyS_write+0xc7/0x1a0
     ? SyS_read+0x1a0/0x1a0
     ? trace_hardirqs_on_thunk+0x1a/0x1c
     entry_SYSCALL_64_fastpath+0x1e/0x8b
    RIP: 0033:0x433549
    RSP: 002b:00007ffe63bd1ea8 EFLAGS: 00000217
    =======================================================================
    
    Cc: syzkaller <syzkaller@googlegroups.com>
    Cc: <stable@vger.kernel.org> # 3.13
    Fixes: bde51583f49b ("IB/mlx5: Add support for resize CQ")
    Reported-by: Noa Osherovich <noaos@mellanox.com>
    Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
    Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
    Signed-off-by: Doug Ledford <dledford@redhat.com>

commit 58cea8e8f1c09cb52fdbe3915f7bf2014dd2ecb0
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Mon Feb 5 22:23:01 2018 +0100

    cls_u32: fix use after free in u32_destroy_key()
    
    
    [ Upstream commit d7cdee5ea8d28ae1b6922deb0c1badaa3aa0ef8c ]
    
    Li Shuang reported an Oops with cls_u32 due to an use-after-free
    in u32_destroy_key(). The use-after-free can be triggered with:
    
    dev=lo
    tc qdisc add dev $dev root handle 1: htb default 10
    tc filter add dev $dev parent 1: prio 5 handle 1: protocol ip u32 divisor 256
    tc filter add dev $dev protocol ip parent 1: prio 5 u32 ht 800:: match ip dst\
     10.0.0.0/8 hashkey mask 0x0000ff00 at 16 link 1:
    tc qdisc del dev $dev root
    
    Which causes the following kasan splat:
    
     ==================================================================
     BUG: KASAN: use-after-free in u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
     Read of size 4 at addr ffff881b83dae618 by task kworker/u48:5/571
    
     CPU: 17 PID: 571 Comm: kworker/u48:5 Not tainted 4.15.0+ #87
     Hardware name: Dell Inc. PowerEdge R730/072T6D, BIOS 2.1.7 06/16/2016
     Workqueue: tc_filter_workqueue u32_delete_key_freepf_work [cls_u32]
     Call Trace:
      dump_stack+0xd6/0x182
      ? dma_virt_map_sg+0x22e/0x22e
      print_address_description+0x73/0x290
      kasan_report+0x277/0x360
      ? u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
      u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
      u32_delete_key_freepf_work+0x1c/0x30 [cls_u32]
      process_one_work+0xae0/0x1c80
      ? sched_clock+0x5/0x10
      ? pwq_dec_nr_in_flight+0x3c0/0x3c0
      ? _raw_spin_unlock_irq+0x29/0x40
      ? trace_hardirqs_on_caller+0x381/0x570
      ? _raw_spin_unlock_irq+0x29/0x40
      ? finish_task_switch+0x1e5/0x760
      ? finish_task_switch+0x208/0x760
      ? preempt_notifier_dec+0x20/0x20
      ? __schedule+0x839/0x1ee0
      ? check_noncircular+0x20/0x20
      ? firmware_map_remove+0x73/0x73
      ? find_held_lock+0x39/0x1c0
      ? worker_thread+0x434/0x1820
      ? lock_contended+0xee0/0xee0
      ? lock_release+0x1100/0x1100
      ? init_rescuer.part.16+0x150/0x150
      ? retint_kernel+0x10/0x10
      worker_thread+0x216/0x1820
      ? process_one_work+0x1c80/0x1c80
      ? lock_acquire+0x1a5/0x540
      ? lock_downgrade+0x6b0/0x6b0
      ? sched_clock+0x5/0x10
      ? lock_release+0x1100/0x1100
      ? compat_start_thread+0x80/0x80
      ? do_raw_spin_trylock+0x190/0x190
      ? _raw_spin_unlock_irq+0x29/0x40
      ? trace_hardirqs_on_caller+0x381/0x570
      ? _raw_spin_unlock_irq+0x29/0x40
      ? finish_task_switch+0x1e5/0x760
      ? finish_task_switch+0x208/0x760
      ? preempt_notifier_dec+0x20/0x20
      ? __schedule+0x839/0x1ee0
      ? kmem_cache_alloc_trace+0x143/0x320
      ? firmware_map_remove+0x73/0x73
      ? sched_clock+0x5/0x10
      ? sched_clock_cpu+0x18/0x170
      ? find_held_lock+0x39/0x1c0
      ? schedule+0xf3/0x3b0
      ? lock_downgrade+0x6b0/0x6b0
      ? __schedule+0x1ee0/0x1ee0
      ? do_wait_intr_irq+0x340/0x340
      ? do_raw_spin_trylock+0x190/0x190
      ? _raw_spin_unlock_irqrestore+0x32/0x60
      ? process_one_work+0x1c80/0x1c80
      ? process_one_work+0x1c80/0x1c80
      kthread+0x312/0x3d0
      ? kthread_create_worker_on_cpu+0xc0/0xc0
      ret_from_fork+0x3a/0x50
    
     Allocated by task 1688:
      kasan_kmalloc+0xa0/0xd0
      __kmalloc+0x162/0x380
      u32_change+0x1220/0x3c9e [cls_u32]
      tc_ctl_tfilter+0x1ba6/0x2f80
      rtnetlink_rcv_msg+0x4f0/0x9d0
      netlink_rcv_skb+0x124/0x320
      netlink_unicast+0x430/0x600
      netlink_sendmsg+0x8fa/0xd60
      sock_sendmsg+0xb1/0xe0
      ___sys_sendmsg+0x678/0x980
      __sys_sendmsg+0xc4/0x210
      do_syscall_64+0x232/0x7f0
      return_from_SYSCALL_64+0x0/0x75
    
     Freed by task 112:
      kasan_slab_free+0x71/0xc0
      kfree+0x114/0x320
      rcu_process_callbacks+0xc3f/0x1600
      __do_softirq+0x2bf/0xc06
    
     The buggy address belongs to the object at ffff881b83dae600
      which belongs to the cache kmalloc-4096 of size 4096
     The buggy address is located 24 bytes inside of
      4096-byte region [ffff881b83dae600, ffff881b83daf600)
     The buggy address belongs to the page:
     page:ffffea006e0f6a00 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
     flags: 0x17ffffc0008100(slab|head)
     raw: 0017ffffc0008100 0000000000000000 0000000000000000 0000000100070007
     raw: dead000000000100 dead000000000200 ffff880187c0e600 0000000000000000
     page dumped because: kasan: bad access detected
    
     Memory state around the buggy address:
      ffff881b83dae500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
      ffff881b83dae580: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     >ffff881b83dae600: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                 ^
      ffff881b83dae680: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
      ffff881b83dae700: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ==================================================================
    
    The problem is that the htnode is freed before the linked knodes and the
    latter will try to access the first at u32_destroy_key() time.
    This change addresses the issue using the htnode refcnt to guarantee
    the correct free order. While at it also add a RCU annotation,
    to keep sparse happy.
    
    v1 -> v2: use rtnl_derefence() instead of RCU read locks
    v2 -> v3:
      - don't check refcnt in u32_destroy_hnode()
      - cleaned-up u32_destroy() implementation
      - cleaned-up code comment
    v3 -> v4:
      - dropped unneeded comment
    
    Reported-by: Li Shuang <shuali@redhat.com>
    Fixes: c0d378ef1266 ("net_sched: use tcf_queue_work() in u32 filter")
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Acked-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ebadf888288c9e069b0141a4f00784e7245c5e28
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Mon Feb 5 22:23:01 2018 +0100

    cls_u32: fix use after free in u32_destroy_key()
    
    
    [ Upstream commit d7cdee5ea8d28ae1b6922deb0c1badaa3aa0ef8c ]
    
    Li Shuang reported an Oops with cls_u32 due to an use-after-free
    in u32_destroy_key(). The use-after-free can be triggered with:
    
    dev=lo
    tc qdisc add dev $dev root handle 1: htb default 10
    tc filter add dev $dev parent 1: prio 5 handle 1: protocol ip u32 divisor 256
    tc filter add dev $dev protocol ip parent 1: prio 5 u32 ht 800:: match ip dst\
     10.0.0.0/8 hashkey mask 0x0000ff00 at 16 link 1:
    tc qdisc del dev $dev root
    
    Which causes the following kasan splat:
    
     ==================================================================
     BUG: KASAN: use-after-free in u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
     Read of size 4 at addr ffff881b83dae618 by task kworker/u48:5/571
    
     CPU: 17 PID: 571 Comm: kworker/u48:5 Not tainted 4.15.0+ #87
     Hardware name: Dell Inc. PowerEdge R730/072T6D, BIOS 2.1.7 06/16/2016
     Workqueue: tc_filter_workqueue u32_delete_key_freepf_work [cls_u32]
     Call Trace:
      dump_stack+0xd6/0x182
      ? dma_virt_map_sg+0x22e/0x22e
      print_address_description+0x73/0x290
      kasan_report+0x277/0x360
      ? u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
      u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
      u32_delete_key_freepf_work+0x1c/0x30 [cls_u32]
      process_one_work+0xae0/0x1c80
      ? sched_clock+0x5/0x10
      ? pwq_dec_nr_in_flight+0x3c0/0x3c0
      ? _raw_spin_unlock_irq+0x29/0x40
      ? trace_hardirqs_on_caller+0x381/0x570
      ? _raw_spin_unlock_irq+0x29/0x40
      ? finish_task_switch+0x1e5/0x760
      ? finish_task_switch+0x208/0x760
      ? preempt_notifier_dec+0x20/0x20
      ? __schedule+0x839/0x1ee0
      ? check_noncircular+0x20/0x20
      ? firmware_map_remove+0x73/0x73
      ? find_held_lock+0x39/0x1c0
      ? worker_thread+0x434/0x1820
      ? lock_contended+0xee0/0xee0
      ? lock_release+0x1100/0x1100
      ? init_rescuer.part.16+0x150/0x150
      ? retint_kernel+0x10/0x10
      worker_thread+0x216/0x1820
      ? process_one_work+0x1c80/0x1c80
      ? lock_acquire+0x1a5/0x540
      ? lock_downgrade+0x6b0/0x6b0
      ? sched_clock+0x5/0x10
      ? lock_release+0x1100/0x1100
      ? compat_start_thread+0x80/0x80
      ? do_raw_spin_trylock+0x190/0x190
      ? _raw_spin_unlock_irq+0x29/0x40
      ? trace_hardirqs_on_caller+0x381/0x570
      ? _raw_spin_unlock_irq+0x29/0x40
      ? finish_task_switch+0x1e5/0x760
      ? finish_task_switch+0x208/0x760
      ? preempt_notifier_dec+0x20/0x20
      ? __schedule+0x839/0x1ee0
      ? kmem_cache_alloc_trace+0x143/0x320
      ? firmware_map_remove+0x73/0x73
      ? sched_clock+0x5/0x10
      ? sched_clock_cpu+0x18/0x170
      ? find_held_lock+0x39/0x1c0
      ? schedule+0xf3/0x3b0
      ? lock_downgrade+0x6b0/0x6b0
      ? __schedule+0x1ee0/0x1ee0
      ? do_wait_intr_irq+0x340/0x340
      ? do_raw_spin_trylock+0x190/0x190
      ? _raw_spin_unlock_irqrestore+0x32/0x60
      ? process_one_work+0x1c80/0x1c80
      ? process_one_work+0x1c80/0x1c80
      kthread+0x312/0x3d0
      ? kthread_create_worker_on_cpu+0xc0/0xc0
      ret_from_fork+0x3a/0x50
    
     Allocated by task 1688:
      kasan_kmalloc+0xa0/0xd0
      __kmalloc+0x162/0x380
      u32_change+0x1220/0x3c9e [cls_u32]
      tc_ctl_tfilter+0x1ba6/0x2f80
      rtnetlink_rcv_msg+0x4f0/0x9d0
      netlink_rcv_skb+0x124/0x320
      netlink_unicast+0x430/0x600
      netlink_sendmsg+0x8fa/0xd60
      sock_sendmsg+0xb1/0xe0
      ___sys_sendmsg+0x678/0x980
      __sys_sendmsg+0xc4/0x210
      do_syscall_64+0x232/0x7f0
      return_from_SYSCALL_64+0x0/0x75
    
     Freed by task 112:
      kasan_slab_free+0x71/0xc0
      kfree+0x114/0x320
      rcu_process_callbacks+0xc3f/0x1600
      __do_softirq+0x2bf/0xc06
    
     The buggy address belongs to the object at ffff881b83dae600
      which belongs to the cache kmalloc-4096 of size 4096
     The buggy address is located 24 bytes inside of
      4096-byte region [ffff881b83dae600, ffff881b83daf600)
     The buggy address belongs to the page:
     page:ffffea006e0f6a00 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
     flags: 0x17ffffc0008100(slab|head)
     raw: 0017ffffc0008100 0000000000000000 0000000000000000 0000000100070007
     raw: dead000000000100 dead000000000200 ffff880187c0e600 0000000000000000
     page dumped because: kasan: bad access detected
    
     Memory state around the buggy address:
      ffff881b83dae500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
      ffff881b83dae580: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     >ffff881b83dae600: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                 ^
      ffff881b83dae680: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
      ffff881b83dae700: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ==================================================================
    
    The problem is that the htnode is freed before the linked knodes and the
    latter will try to access the first at u32_destroy_key() time.
    This change addresses the issue using the htnode refcnt to guarantee
    the correct free order. While at it also add a RCU annotation,
    to keep sparse happy.
    
    v1 -> v2: use rtnl_derefence() instead of RCU read locks
    v2 -> v3:
      - don't check refcnt in u32_destroy_hnode()
      - cleaned-up u32_destroy() implementation
      - cleaned-up code comment
    v3 -> v4:
      - dropped unneeded comment
    
    Reported-by: Li Shuang <shuali@redhat.com>
    Fixes: c0d378ef1266 ("net_sched: use tcf_queue_work() in u32 filter")
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Acked-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 294975841483c08e84572713f348cd51b8408021
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon Feb 5 22:18:11 2018 -0500

    tracing: Fix parsing of globs with a wildcard at the beginning
    
    commit 07234021410bbc27b7c86c18de98616c29fbe667 upstream.
    
    Al Viro reported:
    
        For substring - sure, but what about something like "*a*b" and "a*b"?
        AFAICS, filter_parse_regex() ends up with identical results in both
        cases - MATCH_GLOB and *search = "a*b".  And no way for the caller
        to tell one from another.
    
    Testing this with the following:
    
     # cd /sys/kernel/tracing
     # echo '*raw*lock' > set_ftrace_filter
     bash: echo: write error: Invalid argument
    
    With this patch:
    
     # echo '*raw*lock' > set_ftrace_filter
     # cat set_ftrace_filter
    _raw_read_trylock
    _raw_write_trylock
    _raw_read_unlock
    _raw_spin_unlock
    _raw_write_unlock
    _raw_spin_trylock
    _raw_spin_lock
    _raw_write_lock
    _raw_read_lock
    
    Al recommended not setting the search buffer to skip the first '*' unless we
    know we are not using MATCH_GLOB. This implements his suggested logic.
    
    Link: http://lkml.kernel.org/r/20180127170748.GF13338@ZenIV.linux.org.uk
    
    Cc: stable@vger.kernel.org
    Fixes: 60f1d5e3bac44 ("ftrace: Support full glob matching")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Suggsted-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 95f92d0a0ca9dd0f4a92e9eb02b2b7b3d257d46f
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon Feb 5 22:18:11 2018 -0500

    tracing: Fix parsing of globs with a wildcard at the beginning
    
    commit 07234021410bbc27b7c86c18de98616c29fbe667 upstream.
    
    Al Viro reported:
    
        For substring - sure, but what about something like "*a*b" and "a*b"?
        AFAICS, filter_parse_regex() ends up with identical results in both
        cases - MATCH_GLOB and *search = "a*b".  And no way for the caller
        to tell one from another.
    
    Testing this with the following:
    
     # cd /sys/kernel/tracing
     # echo '*raw*lock' > set_ftrace_filter
     bash: echo: write error: Invalid argument
    
    With this patch:
    
     # echo '*raw*lock' > set_ftrace_filter
     # cat set_ftrace_filter
    _raw_read_trylock
    _raw_write_trylock
    _raw_read_unlock
    _raw_spin_unlock
    _raw_write_unlock
    _raw_spin_trylock
    _raw_spin_lock
    _raw_write_lock
    _raw_read_lock
    
    Al recommended not setting the search buffer to skip the first '*' unless we
    know we are not using MATCH_GLOB. This implements his suggested logic.
    
    Link: http://lkml.kernel.org/r/20180127170748.GF13338@ZenIV.linux.org.uk
    
    Cc: stable@vger.kernel.org
    Fixes: 60f1d5e3bac44 ("ftrace: Support full glob matching")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Suggsted-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07234021410bbc27b7c86c18de98616c29fbe667
Author: Steven Rostedt (VMware) <rostedt@goodmis.org>
Date:   Mon Feb 5 22:18:11 2018 -0500

    tracing: Fix parsing of globs with a wildcard at the beginning
    
    Al Viro reported:
    
        For substring - sure, but what about something like "*a*b" and "a*b"?
        AFAICS, filter_parse_regex() ends up with identical results in both
        cases - MATCH_GLOB and *search = "a*b".  And no way for the caller
        to tell one from another.
    
    Testing this with the following:
    
     # cd /sys/kernel/tracing
     # echo '*raw*lock' > set_ftrace_filter
     bash: echo: write error: Invalid argument
    
    With this patch:
    
     # echo '*raw*lock' > set_ftrace_filter
     # cat set_ftrace_filter
    _raw_read_trylock
    _raw_write_trylock
    _raw_read_unlock
    _raw_spin_unlock
    _raw_write_unlock
    _raw_spin_trylock
    _raw_spin_lock
    _raw_write_lock
    _raw_read_lock
    
    Al recommended not setting the search buffer to skip the first '*' unless we
    know we are not using MATCH_GLOB. This implements his suggested logic.
    
    Link: http://lkml.kernel.org/r/20180127170748.GF13338@ZenIV.linux.org.uk
    
    Cc: stable@vger.kernel.org
    Fixes: 60f1d5e3bac44 ("ftrace: Support full glob matching")
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Reported-by: Al Viro <viro@ZenIV.linux.org.uk>
    Suggsted-by: Al Viro <viro@ZenIV.linux.org.uk>
    Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>

commit 202fb4ef81e3ec765c23bd1e6746a5c25b797d0e
Author: Will Deacon <will@kernel.org>
Date:   Wed Jan 31 12:12:20 2018 +0000

    arm64: spinlock: Fix theoretical trylock() A-B-A with LSE atomics
    
    If the spinlock "next" ticket wraps around between the initial LDR
    and the cmpxchg in the LSE version of spin_trylock, then we can erroneously
    think that we have successfuly acquired the lock because we only check
    whether the next ticket return by the cmpxchg is equal to the owner ticket
    in our updated lock word.
    
    This patch fixes the issue by performing a full 32-bit check of the lock
    word when trying to determine whether or not the CASA instruction updated
    memory.
    
    Reported-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>

commit d7cdee5ea8d28ae1b6922deb0c1badaa3aa0ef8c
Author: Paolo Abeni <pabeni@redhat.com>
Date:   Mon Feb 5 22:23:01 2018 +0100

    cls_u32: fix use after free in u32_destroy_key()
    
    Li Shuang reported an Oops with cls_u32 due to an use-after-free
    in u32_destroy_key(). The use-after-free can be triggered with:
    
    dev=lo
    tc qdisc add dev $dev root handle 1: htb default 10
    tc filter add dev $dev parent 1: prio 5 handle 1: protocol ip u32 divisor 256
    tc filter add dev $dev protocol ip parent 1: prio 5 u32 ht 800:: match ip dst\
     10.0.0.0/8 hashkey mask 0x0000ff00 at 16 link 1:
    tc qdisc del dev $dev root
    
    Which causes the following kasan splat:
    
     ==================================================================
     BUG: KASAN: use-after-free in u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
     Read of size 4 at addr ffff881b83dae618 by task kworker/u48:5/571
    
     CPU: 17 PID: 571 Comm: kworker/u48:5 Not tainted 4.15.0+ #87
     Hardware name: Dell Inc. PowerEdge R730/072T6D, BIOS 2.1.7 06/16/2016
     Workqueue: tc_filter_workqueue u32_delete_key_freepf_work [cls_u32]
     Call Trace:
      dump_stack+0xd6/0x182
      ? dma_virt_map_sg+0x22e/0x22e
      print_address_description+0x73/0x290
      kasan_report+0x277/0x360
      ? u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
      u32_destroy_key.constprop.21+0x117/0x140 [cls_u32]
      u32_delete_key_freepf_work+0x1c/0x30 [cls_u32]
      process_one_work+0xae0/0x1c80
      ? sched_clock+0x5/0x10
      ? pwq_dec_nr_in_flight+0x3c0/0x3c0
      ? _raw_spin_unlock_irq+0x29/0x40
      ? trace_hardirqs_on_caller+0x381/0x570
      ? _raw_spin_unlock_irq+0x29/0x40
      ? finish_task_switch+0x1e5/0x760
      ? finish_task_switch+0x208/0x760
      ? preempt_notifier_dec+0x20/0x20
      ? __schedule+0x839/0x1ee0
      ? check_noncircular+0x20/0x20
      ? firmware_map_remove+0x73/0x73
      ? find_held_lock+0x39/0x1c0
      ? worker_thread+0x434/0x1820
      ? lock_contended+0xee0/0xee0
      ? lock_release+0x1100/0x1100
      ? init_rescuer.part.16+0x150/0x150
      ? retint_kernel+0x10/0x10
      worker_thread+0x216/0x1820
      ? process_one_work+0x1c80/0x1c80
      ? lock_acquire+0x1a5/0x540
      ? lock_downgrade+0x6b0/0x6b0
      ? sched_clock+0x5/0x10
      ? lock_release+0x1100/0x1100
      ? compat_start_thread+0x80/0x80
      ? do_raw_spin_trylock+0x190/0x190
      ? _raw_spin_unlock_irq+0x29/0x40
      ? trace_hardirqs_on_caller+0x381/0x570
      ? _raw_spin_unlock_irq+0x29/0x40
      ? finish_task_switch+0x1e5/0x760
      ? finish_task_switch+0x208/0x760
      ? preempt_notifier_dec+0x20/0x20
      ? __schedule+0x839/0x1ee0
      ? kmem_cache_alloc_trace+0x143/0x320
      ? firmware_map_remove+0x73/0x73
      ? sched_clock+0x5/0x10
      ? sched_clock_cpu+0x18/0x170
      ? find_held_lock+0x39/0x1c0
      ? schedule+0xf3/0x3b0
      ? lock_downgrade+0x6b0/0x6b0
      ? __schedule+0x1ee0/0x1ee0
      ? do_wait_intr_irq+0x340/0x340
      ? do_raw_spin_trylock+0x190/0x190
      ? _raw_spin_unlock_irqrestore+0x32/0x60
      ? process_one_work+0x1c80/0x1c80
      ? process_one_work+0x1c80/0x1c80
      kthread+0x312/0x3d0
      ? kthread_create_worker_on_cpu+0xc0/0xc0
      ret_from_fork+0x3a/0x50
    
     Allocated by task 1688:
      kasan_kmalloc+0xa0/0xd0
      __kmalloc+0x162/0x380
      u32_change+0x1220/0x3c9e [cls_u32]
      tc_ctl_tfilter+0x1ba6/0x2f80
      rtnetlink_rcv_msg+0x4f0/0x9d0
      netlink_rcv_skb+0x124/0x320
      netlink_unicast+0x430/0x600
      netlink_sendmsg+0x8fa/0xd60
      sock_sendmsg+0xb1/0xe0
      ___sys_sendmsg+0x678/0x980
      __sys_sendmsg+0xc4/0x210
      do_syscall_64+0x232/0x7f0
      return_from_SYSCALL_64+0x0/0x75
    
     Freed by task 112:
      kasan_slab_free+0x71/0xc0
      kfree+0x114/0x320
      rcu_process_callbacks+0xc3f/0x1600
      __do_softirq+0x2bf/0xc06
    
     The buggy address belongs to the object at ffff881b83dae600
      which belongs to the cache kmalloc-4096 of size 4096
     The buggy address is located 24 bytes inside of
      4096-byte region [ffff881b83dae600, ffff881b83daf600)
     The buggy address belongs to the page:
     page:ffffea006e0f6a00 count:1 mapcount:0 mapping:          (null) index:0x0 compound_mapcount: 0
     flags: 0x17ffffc0008100(slab|head)
     raw: 0017ffffc0008100 0000000000000000 0000000000000000 0000000100070007
     raw: dead000000000100 dead000000000200 ffff880187c0e600 0000000000000000
     page dumped because: kasan: bad access detected
    
     Memory state around the buggy address:
      ffff881b83dae500: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
      ffff881b83dae580: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc
     >ffff881b83dae600: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
                                 ^
      ffff881b83dae680: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
      ffff881b83dae700: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb
     ==================================================================
    
    The problem is that the htnode is freed before the linked knodes and the
    latter will try to access the first at u32_destroy_key() time.
    This change addresses the issue using the htnode refcnt to guarantee
    the correct free order. While at it also add a RCU annotation,
    to keep sparse happy.
    
    v1 -> v2: use rtnl_derefence() instead of RCU read locks
    v2 -> v3:
      - don't check refcnt in u32_destroy_hnode()
      - cleaned-up u32_destroy() implementation
      - cleaned-up code comment
    v3 -> v4:
      - dropped unneeded comment
    
    Reported-by: Li Shuang <shuali@redhat.com>
    Fixes: c0d378ef1266 ("net_sched: use tcf_queue_work() in u32 filter")
    Signed-off-by: Paolo Abeni <pabeni@redhat.com>
    Acked-by: Cong Wang <xiyou.wangcong@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit a12aa8a68dfef5de181f2e555aa950a0ab05411f
Author: David Lechner <david@lechnology.com>
Date:   Thu Jan 4 19:46:08 2018 -0600

    clk: fix reentrancy of clk_enable() on UP systems
    
    Reentrant calls to clk_enable() are not working on UP systems. This is
    caused by the fact spin_trylock_irqsave() always returns true when
    CONFIG_SMP=n (and CONFIG_DEBUG_SPINLOCK=n) which causes the reference
    counting to not work correctly when clk_enable_lock() is called twice
    before clk_enable_unlock() is called (this happens when clk_enable()
    is called from within another clk_enable()).
    
    This fixes the problem by skipping the call to spin_trylock_irqsave() on UP
    systems and relying solely on reference counting. We also make sure to set
    flags in this case so that we are not returning an uninitialized value.
    
    Suggested-by: Stephen Boyd <sboyd@codeaurora.org>
    Signed-off-by: David Lechner <david@lechnology.com>
    Signed-off-by: Stephen Boyd <sboyd@codeaurora.org>

commit 7656871eff6ae5957394767a08ee0ce581023ed7
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 22 08:57:15 2017 -0700

    inet: frag: release spinlock before calling icmp_send()
    
    
    [ Upstream commit ec4fbd64751de18729eaa816ec69e4b504b5a7a2 ]
    
    Dmitry reported a lockdep splat [1] (false positive) that we can fix
    by releasing the spinlock before calling icmp_send() from ip_expire()
    
    This is a false positive because sending an ICMP message can not
    possibly re-enter the IP frag engine.
    
    [1]
    [ INFO: possible circular locking dependency detected ]
    4.10.0+ #29 Not tainted
    -------------------------------------------------------
    modprobe/12392 is trying to acquire lock:
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>] spin_lock
    include/linux/spinlock.h:299 [inline]
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>] __netif_tx_lock
    include/linux/netdevice.h:3486 [inline]
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>]
    sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
    
    but task is already holding lock:
     (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>] spin_lock
    include/linux/spinlock.h:299 [inline]
     (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>]
    ip_expire+0x51/0x6c0 net/ipv4/ip_fragment.c:201
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #1 (&(&q->lock)->rlock){+.-...}:
           validate_chain kernel/locking/lockdep.c:2267 [inline]
           __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
           lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
           __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
           _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
           spin_lock include/linux/spinlock.h:299 [inline]
           ip_defrag+0x3a2/0x4130 net/ipv4/ip_fragment.c:669
           ip_check_defrag+0x4e3/0x8b0 net/ipv4/ip_fragment.c:713
           packet_rcv_fanout+0x282/0x800 net/packet/af_packet.c:1459
           deliver_skb net/core/dev.c:1834 [inline]
           dev_queue_xmit_nit+0x294/0xa90 net/core/dev.c:1890
           xmit_one net/core/dev.c:2903 [inline]
           dev_hard_start_xmit+0x16b/0xab0 net/core/dev.c:2923
           sch_direct_xmit+0x31f/0x6d0 net/sched/sch_generic.c:182
           __dev_xmit_skb net/core/dev.c:3092 [inline]
           __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
           dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
           neigh_resolve_output+0x6b9/0xb10 net/core/neighbour.c:1308
           neigh_output include/net/neighbour.h:478 [inline]
           ip_finish_output2+0x8b8/0x15a0 net/ipv4/ip_output.c:228
           ip_do_fragment+0x1d93/0x2720 net/ipv4/ip_output.c:672
           ip_fragment.constprop.54+0x145/0x200 net/ipv4/ip_output.c:545
           ip_finish_output+0x82d/0xe10 net/ipv4/ip_output.c:314
           NF_HOOK_COND include/linux/netfilter.h:246 [inline]
           ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
           dst_output include/net/dst.h:486 [inline]
           ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
           ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
           ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
           raw_sendmsg+0x26de/0x3a00 net/ipv4/raw.c:655
           inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:761
           sock_sendmsg_nosec net/socket.c:633 [inline]
           sock_sendmsg+0xca/0x110 net/socket.c:643
           ___sys_sendmsg+0x4a3/0x9f0 net/socket.c:1985
           __sys_sendmmsg+0x25c/0x750 net/socket.c:2075
           SYSC_sendmmsg net/socket.c:2106 [inline]
           SyS_sendmmsg+0x35/0x60 net/socket.c:2101
           do_syscall_64+0x2e8/0x930 arch/x86/entry/common.c:281
           return_from_SYSCALL_64+0x0/0x7a
    
    -> #0 (_xmit_ETHER#2){+.-...}:
           check_prev_add kernel/locking/lockdep.c:1830 [inline]
           check_prevs_add+0xa8f/0x19f0 kernel/locking/lockdep.c:1940
           validate_chain kernel/locking/lockdep.c:2267 [inline]
           __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
           lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
           __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
           _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
           spin_lock include/linux/spinlock.h:299 [inline]
           __netif_tx_lock include/linux/netdevice.h:3486 [inline]
           sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
           __dev_xmit_skb net/core/dev.c:3092 [inline]
           __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
           dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
           neigh_hh_output include/net/neighbour.h:468 [inline]
           neigh_output include/net/neighbour.h:476 [inline]
           ip_finish_output2+0xf6c/0x15a0 net/ipv4/ip_output.c:228
           ip_finish_output+0xa29/0xe10 net/ipv4/ip_output.c:316
           NF_HOOK_COND include/linux/netfilter.h:246 [inline]
           ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
           dst_output include/net/dst.h:486 [inline]
           ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
           ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
           ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
           icmp_push_reply+0x372/0x4d0 net/ipv4/icmp.c:394
           icmp_send+0x156c/0x1c80 net/ipv4/icmp.c:754
           ip_expire+0x40e/0x6c0 net/ipv4/ip_fragment.c:239
           call_timer_fn+0x241/0x820 kernel/time/timer.c:1268
           expire_timers kernel/time/timer.c:1307 [inline]
           __run_timers+0x960/0xcf0 kernel/time/timer.c:1601
           run_timer_softirq+0x21/0x80 kernel/time/timer.c:1614
           __do_softirq+0x31f/0xbe7 kernel/softirq.c:284
           invoke_softirq kernel/softirq.c:364 [inline]
           irq_exit+0x1cc/0x200 kernel/softirq.c:405
           exiting_irq arch/x86/include/asm/apic.h:657 [inline]
           smp_apic_timer_interrupt+0x76/0xa0 arch/x86/kernel/apic/apic.c:962
           apic_timer_interrupt+0x93/0xa0 arch/x86/entry/entry_64.S:707
           __read_once_size include/linux/compiler.h:254 [inline]
           atomic_read arch/x86/include/asm/atomic.h:26 [inline]
           rcu_dynticks_curr_cpu_in_eqs kernel/rcu/tree.c:350 [inline]
           __rcu_is_watching kernel/rcu/tree.c:1133 [inline]
           rcu_is_watching+0x83/0x110 kernel/rcu/tree.c:1147
           rcu_read_lock_held+0x87/0xc0 kernel/rcu/update.c:293
           radix_tree_deref_slot include/linux/radix-tree.h:238 [inline]
           filemap_map_pages+0x6d4/0x1570 mm/filemap.c:2335
           do_fault_around mm/memory.c:3231 [inline]
           do_read_fault mm/memory.c:3265 [inline]
           do_fault+0xbd5/0x2080 mm/memory.c:3370
           handle_pte_fault mm/memory.c:3600 [inline]
           __handle_mm_fault+0x1062/0x2cb0 mm/memory.c:3714
           handle_mm_fault+0x1e2/0x480 mm/memory.c:3751
           __do_page_fault+0x4f6/0xb60 arch/x86/mm/fault.c:1397
           do_page_fault+0x54/0x70 arch/x86/mm/fault.c:1460
           page_fault+0x28/0x30 arch/x86/entry/entry_64.S:1011
    
    other info that might help us debug this:
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&(&q->lock)->rlock);
                                   lock(_xmit_ETHER#2);
                                   lock(&(&q->lock)->rlock);
      lock(_xmit_ETHER#2);
    
     *** DEADLOCK ***
    
    10 locks held by modprobe/12392:
     #0:  (&mm->mmap_sem){++++++}, at: [<ffffffff81329758>]
    __do_page_fault+0x2b8/0xb60 arch/x86/mm/fault.c:1336
     #1:  (rcu_read_lock){......}, at: [<ffffffff8188cab6>]
    filemap_map_pages+0x1e6/0x1570 mm/filemap.c:2324
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    spin_lock include/linux/spinlock.h:299 [inline]
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    pte_alloc_one_map mm/memory.c:2944 [inline]
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    alloc_set_pte+0x13b8/0x1b90 mm/memory.c:3072
     #3:  (((&q->timer))){+.-...}, at: [<ffffffff81627e72>]
    lockdep_copy_map include/linux/lockdep.h:175 [inline]
     #3:  (((&q->timer))){+.-...}, at: [<ffffffff81627e72>]
    call_timer_fn+0x1c2/0x820 kernel/time/timer.c:1258
     #4:  (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>] spin_lock
    include/linux/spinlock.h:299 [inline]
     #4:  (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>]
    ip_expire+0x51/0x6c0 net/ipv4/ip_fragment.c:201
     #5:  (rcu_read_lock){......}, at: [<ffffffff8389a633>]
    ip_expire+0x1b3/0x6c0 net/ipv4/ip_fragment.c:216
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>] spin_trylock
    include/linux/spinlock.h:309 [inline]
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>] icmp_xmit_lock
    net/ipv4/icmp.c:219 [inline]
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>]
    icmp_send+0x803/0x1c80 net/ipv4/icmp.c:681
     #7:  (rcu_read_lock_bh){......}, at: [<ffffffff838ab9a1>]
    ip_finish_output2+0x2c1/0x15a0 net/ipv4/ip_output.c:198
     #8:  (rcu_read_lock_bh){......}, at: [<ffffffff836d1dee>]
    __dev_queue_xmit+0x23e/0x1e60 net/core/dev.c:3324
     #9:  (dev->qdisc_running_key ?: &qdisc_running_key){+.....}, at:
    [<ffffffff836d3a27>] dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
    
    stack backtrace:
    CPU: 0 PID: 12392 Comm: modprobe Not tainted 4.10.0+ #29
    Hardware name: Google Google Compute Engine/Google Compute Engine,
    BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x2ee/0x3ef lib/dump_stack.c:52
     print_circular_bug+0x307/0x3b0 kernel/locking/lockdep.c:1204
     check_prev_add kernel/locking/lockdep.c:1830 [inline]
     check_prevs_add+0xa8f/0x19f0 kernel/locking/lockdep.c:1940
     validate_chain kernel/locking/lockdep.c:2267 [inline]
     __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
     lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
     spin_lock include/linux/spinlock.h:299 [inline]
     __netif_tx_lock include/linux/netdevice.h:3486 [inline]
     sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
     __dev_xmit_skb net/core/dev.c:3092 [inline]
     __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
     dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
     neigh_hh_output include/net/neighbour.h:468 [inline]
     neigh_output include/net/neighbour.h:476 [inline]
     ip_finish_output2+0xf6c/0x15a0 net/ipv4/ip_output.c:228
     ip_finish_output+0xa29/0xe10 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
     ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
     ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
     icmp_push_reply+0x372/0x4d0 net/ipv4/icmp.c:394
     icmp_send+0x156c/0x1c80 net/ipv4/icmp.c:754
     ip_expire+0x40e/0x6c0 net/ipv4/ip_fragment.c:239
     call_timer_fn+0x241/0x820 kernel/time/timer.c:1268
     expire_timers kernel/time/timer.c:1307 [inline]
     __run_timers+0x960/0xcf0 kernel/time/timer.c:1601
     run_timer_softirq+0x21/0x80 kernel/time/timer.c:1614
     __do_softirq+0x31f/0xbe7 kernel/softirq.c:284
     invoke_softirq kernel/softirq.c:364 [inline]
     irq_exit+0x1cc/0x200 kernel/softirq.c:405
     exiting_irq arch/x86/include/asm/apic.h:657 [inline]
     smp_apic_timer_interrupt+0x76/0xa0 arch/x86/kernel/apic/apic.c:962
     apic_timer_interrupt+0x93/0xa0 arch/x86/entry/entry_64.S:707
    RIP: 0010:__read_once_size include/linux/compiler.h:254 [inline]
    RIP: 0010:atomic_read arch/x86/include/asm/atomic.h:26 [inline]
    RIP: 0010:rcu_dynticks_curr_cpu_in_eqs kernel/rcu/tree.c:350 [inline]
    RIP: 0010:__rcu_is_watching kernel/rcu/tree.c:1133 [inline]
    RIP: 0010:rcu_is_watching+0x83/0x110 kernel/rcu/tree.c:1147
    RSP: 0000:ffff8801c391f120 EFLAGS: 00000a03 ORIG_RAX: ffffffffffffff10
    RAX: dffffc0000000000 RBX: ffff8801c391f148 RCX: 0000000000000000
    RDX: 0000000000000000 RSI: 000055edd4374000 RDI: ffff8801dbe1ae0c
    RBP: ffff8801c391f1a0 R08: 0000000000000002 R09: 0000000000000000
    R10: dffffc0000000000 R11: 0000000000000002 R12: 1ffff10038723e25
    R13: ffff8801dbe1ae00 R14: ffff8801c391f680 R15: dffffc0000000000
     </IRQ>
     rcu_read_lock_held+0x87/0xc0 kernel/rcu/update.c:293
     radix_tree_deref_slot include/linux/radix-tree.h:238 [inline]
     filemap_map_pages+0x6d4/0x1570 mm/filemap.c:2335
     do_fault_around mm/memory.c:3231 [inline]
     do_read_fault mm/memory.c:3265 [inline]
     do_fault+0xbd5/0x2080 mm/memory.c:3370
     handle_pte_fault mm/memory.c:3600 [inline]
     __handle_mm_fault+0x1062/0x2cb0 mm/memory.c:3714
     handle_mm_fault+0x1e2/0x480 mm/memory.c:3751
     __do_page_fault+0x4f6/0xb60 arch/x86/mm/fault.c:1397
     do_page_fault+0x54/0x70 arch/x86/mm/fault.c:1460
     page_fault+0x28/0x30 arch/x86/entry/entry_64.S:1011
    RIP: 0033:0x7f83172f2786
    RSP: 002b:00007fffe859ae80 EFLAGS: 00010293
    RAX: 000055edd4373040 RBX: 00007f83175111c8 RCX: 000055edd4373238
    RDX: 0000000000000000 RSI: 0000000000000000 RDI: 00007f8317510970
    RBP: 00007fffe859afd0 R08: 0000000000000009 R09: 0000000000000000
    R10: 0000000000000064 R11: 0000000000000000 R12: 000055edd4373040
    R13: 0000000000000000 R14: 00007fffe859afe8 R15: 0000000000000000
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1d75c214cebc2c97894288da3b279ae118d4d59e
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 22 08:57:15 2017 -0700

    inet: frag: release spinlock before calling icmp_send()
    
    
    [ Upstream commit ec4fbd64751de18729eaa816ec69e4b504b5a7a2 ]
    
    Dmitry reported a lockdep splat [1] (false positive) that we can fix
    by releasing the spinlock before calling icmp_send() from ip_expire()
    
    This is a false positive because sending an ICMP message can not
    possibly re-enter the IP frag engine.
    
    [1]
    [ INFO: possible circular locking dependency detected ]
    4.10.0+ #29 Not tainted
    -------------------------------------------------------
    modprobe/12392 is trying to acquire lock:
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>] spin_lock
    include/linux/spinlock.h:299 [inline]
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>] __netif_tx_lock
    include/linux/netdevice.h:3486 [inline]
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>]
    sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
    
    but task is already holding lock:
     (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>] spin_lock
    include/linux/spinlock.h:299 [inline]
     (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>]
    ip_expire+0x51/0x6c0 net/ipv4/ip_fragment.c:201
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #1 (&(&q->lock)->rlock){+.-...}:
           validate_chain kernel/locking/lockdep.c:2267 [inline]
           __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
           lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
           __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
           _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
           spin_lock include/linux/spinlock.h:299 [inline]
           ip_defrag+0x3a2/0x4130 net/ipv4/ip_fragment.c:669
           ip_check_defrag+0x4e3/0x8b0 net/ipv4/ip_fragment.c:713
           packet_rcv_fanout+0x282/0x800 net/packet/af_packet.c:1459
           deliver_skb net/core/dev.c:1834 [inline]
           dev_queue_xmit_nit+0x294/0xa90 net/core/dev.c:1890
           xmit_one net/core/dev.c:2903 [inline]
           dev_hard_start_xmit+0x16b/0xab0 net/core/dev.c:2923
           sch_direct_xmit+0x31f/0x6d0 net/sched/sch_generic.c:182
           __dev_xmit_skb net/core/dev.c:3092 [inline]
           __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
           dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
           neigh_resolve_output+0x6b9/0xb10 net/core/neighbour.c:1308
           neigh_output include/net/neighbour.h:478 [inline]
           ip_finish_output2+0x8b8/0x15a0 net/ipv4/ip_output.c:228
           ip_do_fragment+0x1d93/0x2720 net/ipv4/ip_output.c:672
           ip_fragment.constprop.54+0x145/0x200 net/ipv4/ip_output.c:545
           ip_finish_output+0x82d/0xe10 net/ipv4/ip_output.c:314
           NF_HOOK_COND include/linux/netfilter.h:246 [inline]
           ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
           dst_output include/net/dst.h:486 [inline]
           ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
           ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
           ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
           raw_sendmsg+0x26de/0x3a00 net/ipv4/raw.c:655
           inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:761
           sock_sendmsg_nosec net/socket.c:633 [inline]
           sock_sendmsg+0xca/0x110 net/socket.c:643
           ___sys_sendmsg+0x4a3/0x9f0 net/socket.c:1985
           __sys_sendmmsg+0x25c/0x750 net/socket.c:2075
           SYSC_sendmmsg net/socket.c:2106 [inline]
           SyS_sendmmsg+0x35/0x60 net/socket.c:2101
           do_syscall_64+0x2e8/0x930 arch/x86/entry/common.c:281
           return_from_SYSCALL_64+0x0/0x7a
    
    -> #0 (_xmit_ETHER#2){+.-...}:
           check_prev_add kernel/locking/lockdep.c:1830 [inline]
           check_prevs_add+0xa8f/0x19f0 kernel/locking/lockdep.c:1940
           validate_chain kernel/locking/lockdep.c:2267 [inline]
           __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
           lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
           __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
           _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
           spin_lock include/linux/spinlock.h:299 [inline]
           __netif_tx_lock include/linux/netdevice.h:3486 [inline]
           sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
           __dev_xmit_skb net/core/dev.c:3092 [inline]
           __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
           dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
           neigh_hh_output include/net/neighbour.h:468 [inline]
           neigh_output include/net/neighbour.h:476 [inline]
           ip_finish_output2+0xf6c/0x15a0 net/ipv4/ip_output.c:228
           ip_finish_output+0xa29/0xe10 net/ipv4/ip_output.c:316
           NF_HOOK_COND include/linux/netfilter.h:246 [inline]
           ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
           dst_output include/net/dst.h:486 [inline]
           ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
           ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
           ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
           icmp_push_reply+0x372/0x4d0 net/ipv4/icmp.c:394
           icmp_send+0x156c/0x1c80 net/ipv4/icmp.c:754
           ip_expire+0x40e/0x6c0 net/ipv4/ip_fragment.c:239
           call_timer_fn+0x241/0x820 kernel/time/timer.c:1268
           expire_timers kernel/time/timer.c:1307 [inline]
           __run_timers+0x960/0xcf0 kernel/time/timer.c:1601
           run_timer_softirq+0x21/0x80 kernel/time/timer.c:1614
           __do_softirq+0x31f/0xbe7 kernel/softirq.c:284
           invoke_softirq kernel/softirq.c:364 [inline]
           irq_exit+0x1cc/0x200 kernel/softirq.c:405
           exiting_irq arch/x86/include/asm/apic.h:657 [inline]
           smp_apic_timer_interrupt+0x76/0xa0 arch/x86/kernel/apic/apic.c:962
           apic_timer_interrupt+0x93/0xa0 arch/x86/entry/entry_64.S:707
           __read_once_size include/linux/compiler.h:254 [inline]
           atomic_read arch/x86/include/asm/atomic.h:26 [inline]
           rcu_dynticks_curr_cpu_in_eqs kernel/rcu/tree.c:350 [inline]
           __rcu_is_watching kernel/rcu/tree.c:1133 [inline]
           rcu_is_watching+0x83/0x110 kernel/rcu/tree.c:1147
           rcu_read_lock_held+0x87/0xc0 kernel/rcu/update.c:293
           radix_tree_deref_slot include/linux/radix-tree.h:238 [inline]
           filemap_map_pages+0x6d4/0x1570 mm/filemap.c:2335
           do_fault_around mm/memory.c:3231 [inline]
           do_read_fault mm/memory.c:3265 [inline]
           do_fault+0xbd5/0x2080 mm/memory.c:3370
           handle_pte_fault mm/memory.c:3600 [inline]
           __handle_mm_fault+0x1062/0x2cb0 mm/memory.c:3714
           handle_mm_fault+0x1e2/0x480 mm/memory.c:3751
           __do_page_fault+0x4f6/0xb60 arch/x86/mm/fault.c:1397
           do_page_fault+0x54/0x70 arch/x86/mm/fault.c:1460
           page_fault+0x28/0x30 arch/x86/entry/entry_64.S:1011
    
    other info that might help us debug this:
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&(&q->lock)->rlock);
                                   lock(_xmit_ETHER#2);
                                   lock(&(&q->lock)->rlock);
      lock(_xmit_ETHER#2);
    
     *** DEADLOCK ***
    
    10 locks held by modprobe/12392:
     #0:  (&mm->mmap_sem){++++++}, at: [<ffffffff81329758>]
    __do_page_fault+0x2b8/0xb60 arch/x86/mm/fault.c:1336
     #1:  (rcu_read_lock){......}, at: [<ffffffff8188cab6>]
    filemap_map_pages+0x1e6/0x1570 mm/filemap.c:2324
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    spin_lock include/linux/spinlock.h:299 [inline]
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    pte_alloc_one_map mm/memory.c:2944 [inline]
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    alloc_set_pte+0x13b8/0x1b90 mm/memory.c:3072
     #3:  (((&q->timer))){+.-...}, at: [<ffffffff81627e72>]
    lockdep_copy_map include/linux/lockdep.h:175 [inline]
     #3:  (((&q->timer))){+.-...}, at: [<ffffffff81627e72>]
    call_timer_fn+0x1c2/0x820 kernel/time/timer.c:1258
     #4:  (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>] spin_lock
    include/linux/spinlock.h:299 [inline]
     #4:  (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>]
    ip_expire+0x51/0x6c0 net/ipv4/ip_fragment.c:201
     #5:  (rcu_read_lock){......}, at: [<ffffffff8389a633>]
    ip_expire+0x1b3/0x6c0 net/ipv4/ip_fragment.c:216
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>] spin_trylock
    include/linux/spinlock.h:309 [inline]
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>] icmp_xmit_lock
    net/ipv4/icmp.c:219 [inline]
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>]
    icmp_send+0x803/0x1c80 net/ipv4/icmp.c:681
     #7:  (rcu_read_lock_bh){......}, at: [<ffffffff838ab9a1>]
    ip_finish_output2+0x2c1/0x15a0 net/ipv4/ip_output.c:198
     #8:  (rcu_read_lock_bh){......}, at: [<ffffffff836d1dee>]
    __dev_queue_xmit+0x23e/0x1e60 net/core/dev.c:3324
     #9:  (dev->qdisc_running_key ?: &qdisc_running_key){+.....}, at:
    [<ffffffff836d3a27>] dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
    
    stack backtrace:
    CPU: 0 PID: 12392 Comm: modprobe Not tainted 4.10.0+ #29
    Hardware name: Google Google Compute Engine/Google Compute Engine,
    BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x2ee/0x3ef lib/dump_stack.c:52
     print_circular_bug+0x307/0x3b0 kernel/locking/lockdep.c:1204
     check_prev_add kernel/locking/lockdep.c:1830 [inline]
     check_prevs_add+0xa8f/0x19f0 kernel/locking/lockdep.c:1940
     validate_chain kernel/locking/lockdep.c:2267 [inline]
     __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
     lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
     spin_lock include/linux/spinlock.h:299 [inline]
     __netif_tx_lock include/linux/netdevice.h:3486 [inline]
     sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
     __dev_xmit_skb net/core/dev.c:3092 [inline]
     __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
     dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
     neigh_hh_output include/net/neighbour.h:468 [inline]
     neigh_output include/net/neighbour.h:476 [inline]
     ip_finish_output2+0xf6c/0x15a0 net/ipv4/ip_output.c:228
     ip_finish_output+0xa29/0xe10 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
     ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
     ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
     icmp_push_reply+0x372/0x4d0 net/ipv4/icmp.c:394
     icmp_send+0x156c/0x1c80 net/ipv4/icmp.c:754
     ip_expire+0x40e/0x6c0 net/ipv4/ip_fragment.c:239
     call_timer_fn+0x241/0x820 kernel/time/timer.c:1268
     expire_timers kernel/time/timer.c:1307 [inline]
     __run_timers+0x960/0xcf0 kernel/time/timer.c:1601
     run_timer_softirq+0x21/0x80 kernel/time/timer.c:1614
     __do_softirq+0x31f/0xbe7 kernel/softirq.c:284
     invoke_softirq kernel/softirq.c:364 [inline]
     irq_exit+0x1cc/0x200 kernel/softirq.c:405
     exiting_irq arch/x86/include/asm/apic.h:657 [inline]
     smp_apic_timer_interrupt+0x76/0xa0 arch/x86/kernel/apic/apic.c:962
     apic_timer_interrupt+0x93/0xa0 arch/x86/entry/entry_64.S:707
    RIP: 0010:__read_once_size include/linux/compiler.h:254 [inline]
    RIP: 0010:atomic_read arch/x86/include/asm/atomic.h:26 [inline]
    RIP: 0010:rcu_dynticks_curr_cpu_in_eqs kernel/rcu/tree.c:350 [inline]
    RIP: 0010:__rcu_is_watching kernel/rcu/tree.c:1133 [inline]
    RIP: 0010:rcu_is_watching+0x83/0x110 kernel/rcu/tree.c:1147
    RSP: 0000:ffff8801c391f120 EFLAGS: 00000a03 ORIG_RAX: ffffffffffffff10
    RAX: dffffc0000000000 RBX: ffff8801c391f148 RCX: 0000000000000000
    RDX: 0000000000000000 RSI: 000055edd4374000 RDI: ffff8801dbe1ae0c
    RBP: ffff8801c391f1a0 R08: 0000000000000002 R09: 0000000000000000
    R10: dffffc0000000000 R11: 0000000000000002 R12: 1ffff10038723e25
    R13: ffff8801dbe1ae00 R14: ffff8801c391f680 R15: dffffc0000000000
     </IRQ>
     rcu_read_lock_held+0x87/0xc0 kernel/rcu/update.c:293
     radix_tree_deref_slot include/linux/radix-tree.h:238 [inline]
     filemap_map_pages+0x6d4/0x1570 mm/filemap.c:2335
     do_fault_around mm/memory.c:3231 [inline]
     do_read_fault mm/memory.c:3265 [inline]
     do_fault+0xbd5/0x2080 mm/memory.c:3370
     handle_pte_fault mm/memory.c:3600 [inline]
     __handle_mm_fault+0x1062/0x2cb0 mm/memory.c:3714
     handle_mm_fault+0x1e2/0x480 mm/memory.c:3751
     __do_page_fault+0x4f6/0xb60 arch/x86/mm/fault.c:1397
     do_page_fault+0x54/0x70 arch/x86/mm/fault.c:1460
     page_fault+0x28/0x30 arch/x86/entry/entry_64.S:1011
    RIP: 0033:0x7f83172f2786
    RSP: 002b:00007fffe859ae80 EFLAGS: 00010293
    RAX: 000055edd4373040 RBX: 00007f83175111c8 RCX: 000055edd4373238
    RDX: 0000000000000000 RSI: 0000000000000000 RDI: 00007f8317510970
    RBP: 00007fffe859afd0 R08: 0000000000000009 R09: 0000000000000000
    R10: 0000000000000064 R11: 0000000000000000 R12: 000055edd4373040
    R13: 0000000000000000 R14: 00007fffe859afe8 R15: 0000000000000000
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <alexander.levin@verizon.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c0093f1a38a0fd6c32a2269f0533bb13fb95143d
Author: Paul Mackerras <paulus@ozlabs.org>
Date:   Mon Nov 20 16:12:25 2017 +1100

    KVM: PPC: Book3S HV: Fix conditions for starting vcpu
    
    This corrects the test that determines whether a vcpu that has just
    become able to run in the guest (e.g. it has just finished handling
    a hypercall or hypervisor page fault) and whose virtual core is
    already running somewhere as a "piggybacked" vcore can start
    immediately or not.  (A piggybacked vcore is one which is executing
    along with another vcore as a result of dynamic micro-threading.)
    
    Previously the test tried to lock the piggybacked vcore using
    spin_trylock, which would always fail because the vcore was already
    locked, and so the vcpu would have to wait until its vcore exited
    the guest before it could enter.
    
    In fact the vcpu can enter if its vcore is in VCORE_PIGGYBACK state
    and not already exiting (or exited) the guest, so the test in
    VCORE_PIGGYBACK state is basically the same as for VCORE_RUNNING
    state.
    
    Coverity detected this as a double unlock issue, which it isn't
    because the spin_trylock would always fail.  This will fix the
    apparent double unlock as well.
    
    Signed-off-by: Paul Mackerras <paulus@ozlabs.org>

commit 9c29c31830a4eca724e137a9339137204bbb31be
Author: Prateek Sood <prsood@codeaurora.org>
Date:   Thu Sep 7 20:00:58 2017 +0530

    locking/rwsem-xadd: Fix missed wakeup due to reordering of load
    
    If a spinner is present, there is a chance that the load of
    rwsem_has_spinner() in rwsem_wake() can be reordered with
    respect to decrement of rwsem count in __up_write() leading
    to wakeup being missed:
    
     spinning writer                  up_write caller
     ---------------                  -----------------------
     [S] osq_unlock()                 [L] osq
      spin_lock(wait_lock)
      sem->count=0xFFFFFFFF00000001
                +0xFFFFFFFF00000000
      count=sem->count
      MB
                                       sem->count=0xFFFFFFFE00000001
                                                 -0xFFFFFFFF00000001
                                       spin_trylock(wait_lock)
                                       return
     rwsem_try_write_lock(count)
     spin_unlock(wait_lock)
     schedule()
    
    Reordering of atomic_long_sub_return_release() in __up_write()
    and rwsem_has_spinner() in rwsem_wake() can cause missing of
    wakeup in up_write() context. In spinning writer, sem->count
    and local variable count is 0XFFFFFFFE00000001. It would result
    in rwsem_try_write_lock() failing to acquire rwsem and spinning
    writer going to sleep in rwsem_down_write_failed().
    
    The smp_rmb() will make sure that the spinner state is
    consulted after sem->count is updated in up_write context.
    
    Signed-off-by: Prateek Sood <prsood@codeaurora.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: dave@stgolabs.net
    Cc: longman@redhat.com
    Cc: parri.andrea@gmail.com
    Cc: sramana@codeaurora.org
    Link: http://lkml.kernel.org/r/1504794658-15397-1-git-send-email-prsood@codeaurora.org
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit e2204d254f27087a71e58d371b2a60bddf3e7c54
Author: Sean Young <sean@mess.org>
Date:   Fri Aug 4 10:12:03 2017 -0400

    media: Revert "[media] lirc_dev: remove superfluous get/put_device() calls"
    
    commit a607f51e5a4c421e2097077db88105402099c528 upstream.
    
    This reverts commit 5be2b76a9ca4ea5fd3e221114d62eeb0d78267ca.
    
    Only when the lirc device is freed, should we drop our reference to
    rc_dev, else we the rc_dev is freed to early. If userspace has
    a file descriptor open during unplug, it goes bang.
    
    ==================================================================
    BUG: KASAN: use-after-free in __lock_acquire+0x7bb/0x1e10
    Read of size 8 at addr ffff8801d7d61ed0 by task ir-rec/2609
    
    -snip-
     mutex_lock_nested+0x1b/0x20
     ? mutex_lock_nested+0x1b/0x20
     rc_close.part.6+0x20/0x60 [rc_core]
     rc_close+0x13/0x20 [rc_core]
     lirc_dev_fop_close+0x62/0xd0 [lirc_dev]
     __fput+0x236/0x410
     ? fput+0xb0/0xb0
     ? do_raw_spin_trylock+0x110/0x110
     ? set_rq_offline.part.70+0xa0/0xa0
     ____fput+0xe/0x10
     task_work_run+0x116/0x180
     ? task_work_cancel+0x170/0x170
     ? _raw_spin_unlock+0x27/0x40
     ? switch_task_namespaces+0x5f/0x90
     do_exit+0x68b/0xe80
    
    Fixes: 5be2b76a9ca4 ("[media] lirc_dev: remove superfluous get/put_device() calls")
    Signed-off-by: Sean Young <sean@mess.org>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@s-opensource.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a607f51e5a4c421e2097077db88105402099c528
Author: Sean Young <sean@mess.org>
Date:   Fri Aug 4 10:12:03 2017 -0400

    media: Revert "[media] lirc_dev: remove superfluous get/put_device() calls"
    
    This reverts commit 5be2b76a9ca4ea5fd3e221114d62eeb0d78267ca.
    
    Only when the lirc device is freed, should we drop our reference to
    rc_dev, else we the rc_dev is freed to early. If userspace has
    a file descriptor open during unplug, it goes bang.
    
    ==================================================================
    BUG: KASAN: use-after-free in __lock_acquire+0x7bb/0x1e10
    Read of size 8 at addr ffff8801d7d61ed0 by task ir-rec/2609
    
    -snip-
     mutex_lock_nested+0x1b/0x20
     ? mutex_lock_nested+0x1b/0x20
     rc_close.part.6+0x20/0x60 [rc_core]
     rc_close+0x13/0x20 [rc_core]
     lirc_dev_fop_close+0x62/0xd0 [lirc_dev]
     __fput+0x236/0x410
     ? fput+0xb0/0xb0
     ? do_raw_spin_trylock+0x110/0x110
     ? set_rq_offline.part.70+0xa0/0xa0
     ____fput+0xe/0x10
     task_work_run+0x116/0x180
     ? task_work_cancel+0x170/0x170
     ? _raw_spin_unlock+0x27/0x40
     ? switch_task_namespaces+0x5f/0x90
     do_exit+0x68b/0xe80
    
    Cc: stable@vger.kernel.org # For Kernel 4.13
    Fixes: 5be2b76a9ca4 ("[media] lirc_dev: remove superfluous get/put_device() calls")
    Signed-off-by: Sean Young <sean@mess.org>
    Signed-off-by: Mauro Carvalho Chehab <mchehab@s-opensource.com>

commit 8d32e0624392bb4abfbe122f754757a4cb326d7f
Author: Sean Wang <sean.wang@mediatek.com>
Date:   Tue Jul 4 11:17:36 2017 +0800

    net: ethernet: mediatek: fixed deadlock captured by lockdep
    
    Lockdep found an inconsistent lock state when mtk_get_stats64 is called
    in user context while NAPI updates MAC statistics in softirq.
    
    Use spin_trylock_bh/spin_unlock_bh fix following lockdep warning.
    
    [   81.321030] WARNING: inconsistent lock state
    [   81.325266] 4.12.0-rc1-00035-gd9dda65 #32 Not tainted
    [   81.330273] --------------------------------
    [   81.334505] inconsistent {SOFTIRQ-ON-W} -> {IN-SOFTIRQ-W} usage.
    [   81.340464] ksoftirqd/0/7 [HC0[0]:SC1[1]:HE1:SE0] takes:
    [   81.345731]  (&syncp->seq#2){+.?...}, at: [<c054ba3c>] mtk_handle_status_irq.part.6+0x70/0x84
    [   81.354219] {SOFTIRQ-ON-W} state was registered at:
    [   81.359062]   lock_acquire+0xfc/0x2b0
    [   81.362696]   mtk_stats_update_mac+0x60/0x2c0
    [   81.367017]   mtk_get_stats64+0x17c/0x18c
    [   81.370995]   dev_get_stats+0x48/0xbc
    [   81.374628]   rtnl_fill_stats+0x48/0x128
    [   81.378520]   rtnl_fill_ifinfo+0x4ac/0xd1c
    [   81.382584]   rtmsg_ifinfo_build_skb+0x7c/0xe0
    [   81.386991]   rtmsg_ifinfo.part.5+0x24/0x54
    [   81.391139]   rtmsg_ifinfo+0x24/0x28
    [   81.394685]   __dev_notify_flags+0xa4/0xac
    [   81.398749]   dev_change_flags+0x50/0x58
    [   81.402640]   devinet_ioctl+0x768/0x85c
    [   81.406444]   inet_ioctl+0x1a4/0x1d0
    [   81.409990]   sock_ioctl+0x16c/0x33c
    [   81.413538]   do_vfs_ioctl+0xb4/0xa34
    [   81.417169]   SyS_ioctl+0x44/0x6c
    [   81.420458]   ret_fast_syscall+0x0/0x1c
    [   81.424260] irq event stamp: 3354692
    [   81.427806] hardirqs last  enabled at (3354692): [<c0678168>] net_rx_action+0xc0/0x504
    [   81.435660] hardirqs last disabled at (3354691): [<c0678134>] net_rx_action+0x8c/0x504
    [   81.443515] softirqs last  enabled at (3354106): [<c0101944>] __do_softirq+0x4b4/0x614
    [   81.451370] softirqs last disabled at (3354109): [<c012f0c4>] run_ksoftirqd+0x44/0x80
    [   81.459134]
    [   81.459134] other info that might help us debug this:
    [   81.465608]  Possible unsafe locking scenario:
    [   81.465608]
    [   81.471478]        CPU0
    [   81.473900]        ----
    [   81.476321]   lock(&syncp->seq#2);
    [   81.479701]   <Interrupt>
    [   81.482294]     lock(&syncp->seq#2);
    [   81.485847]
    [   81.485847]  *** DEADLOCK ***
    [   81.485847]
    [   81.491720] 1 lock held by ksoftirqd/0/7:
    [   81.495693]  #0:  (&(&mac->hw_stats->stats_lock)->rlock){+.+...}, at: [<c054ba14>] mtk_handle_status_irq.part.6+0x48/0x84
    [   81.506579]
    [   81.506579] stack backtrace:
    [   81.510904] CPU: 0 PID: 7 Comm: ksoftirqd/0 Not tainted 4.12.0-rc1-00035-gd9dda65 #32
    [   81.518668] Hardware name: Mediatek Cortex-A7 (Device Tree)
    [   81.524208] [<c0113dc4>] (unwind_backtrace) from [<c010e3f0>] (show_stack+0x20/0x24)
    [   81.531899] [<c010e3f0>] (show_stack) from [<c03f9c64>] (dump_stack+0xb4/0xe0)
    [   81.539072] [<c03f9c64>] (dump_stack) from [<c017e970>] (print_usage_bug+0x234/0x2e0)
    [   81.546846] [<c017e970>] (print_usage_bug) from [<c017f058>] (mark_lock+0x63c/0x7bc)
    [   81.554532] [<c017f058>] (mark_lock) from [<c017fe90>] (__lock_acquire+0x654/0x1bfc)
    [   81.562217] [<c017fe90>] (__lock_acquire) from [<c0181d04>] (lock_acquire+0xfc/0x2b0)
    [   81.569990] [<c0181d04>] (lock_acquire) from [<c054b76c>] (mtk_stats_update_mac+0x60/0x2c0)
    [   81.578283] [<c054b76c>] (mtk_stats_update_mac) from [<c054ba3c>] (mtk_handle_status_irq.part.6+0x70/0x84)
    [   81.587865] [<c054ba3c>] (mtk_handle_status_irq.part.6) from [<c054c2b8>] (mtk_napi_tx+0x358/0x37c)
    [   81.596845] [<c054c2b8>] (mtk_napi_tx) from [<c06782ec>] (net_rx_action+0x244/0x504)
    [   81.604533] [<c06782ec>] (net_rx_action) from [<c01015c4>] (__do_softirq+0x134/0x614)
    [   81.612306] [<c01015c4>] (__do_softirq) from [<c012f0c4>] (run_ksoftirqd+0x44/0x80)
    [   81.619907] [<c012f0c4>] (run_ksoftirqd) from [<c0154680>] (smpboot_thread_fn+0x14c/0x25c)
    [   81.628110] [<c0154680>] (smpboot_thread_fn) from [<c014f8cc>] (kthread+0x150/0x180)
    [   81.635798] [<c014f8cc>] (kthread) from [<c0109290>] (ret_from_fork+0x14/0x24)
    
    Signed-off-by: Sean Wang <sean.wang@mediatek.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 290271de34f6c22ec2337e3293224575459747d6
Author: Chris Wilson <chris@chris-wilson.co.uk>
Date:   Fri Jun 9 12:03:49 2017 +0100

    drm/i915: Spin for struct_mutex inside shrinker
    
    Having resolved whether or not we would deadlock upon a call to
    mutex_lock(&dev->struct_mutex), we can then spin for the contended
    struct_mutex if we are not the owner. We cannot afford to simply block
    and wait for the mutex, as the owner may itself be waiting for the
    allocator -- i.e. a cyclic deadlock. This should significantly improve
    the chance of running the shrinker for other processes whilst the GPU is
    busy.
    
    A more balanced approach would be to optimistically spin whilst the
    mutex owner was on the cpu and there was an opportunity to acquire the
    mutex for ourselves quickly. However, that requires support from
    kernel/locking/ and a new mutex_spin_trylock() primitive.
    
    Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
    Cc: Mika Kuoppala <mika.kuoppala@linux.intel.com>
    Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
    Link: http://patchwork.freedesktop.org/patch/msgid/20170609110350.1767-4-chris@chris-wilson.co.uk
    Reviewed-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>

commit 33fc80e2574737e6e21eecc4c1d7942370a2c752
Author: Minchan Kim <minchan@kernel.org>
Date:   Wed May 3 14:54:17 2017 -0700

    mm: remove SWAP_AGAIN in ttu
    
    In 2002, [1] introduced SWAP_AGAIN.  At that time, try_to_unmap_one used
    spin_trylock(&mm->page_table_lock) so it's really easy to contend and
    fail to hold a lock so SWAP_AGAIN to keep LRU status makes sense.
    
    However, now we changed it to mutex-based lock and be able to block
    without skip pte so there is few of small window to return SWAP_AGAIN so
    remove SWAP_AGAIN and just return SWAP_FAIL.
    
    [1] c48c43e, minimal rmap
    
    Link: http://lkml.kernel.org/r/1489555493-14659-7-git-send-email-minchan@kernel.org
    Signed-off-by: Minchan Kim <minchan@kernel.org>
    Cc: Anshuman Khandual <khandual@linux.vnet.ibm.com>
    Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
    Cc: Johannes Weiner <hannes@cmpxchg.org>
    Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
    Cc: Michal Hocko <mhocko@suse.com>
    Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
    Cc: Vlastimil Babka <vbabka@suse.cz>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit ec4fbd64751de18729eaa816ec69e4b504b5a7a2
Author: Eric Dumazet <edumazet@google.com>
Date:   Wed Mar 22 08:57:15 2017 -0700

    inet: frag: release spinlock before calling icmp_send()
    
    Dmitry reported a lockdep splat [1] (false positive) that we can fix
    by releasing the spinlock before calling icmp_send() from ip_expire()
    
    This is a false positive because sending an ICMP message can not
    possibly re-enter the IP frag engine.
    
    [1]
    [ INFO: possible circular locking dependency detected ]
    4.10.0+ #29 Not tainted
    -------------------------------------------------------
    modprobe/12392 is trying to acquire lock:
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>] spin_lock
    include/linux/spinlock.h:299 [inline]
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>] __netif_tx_lock
    include/linux/netdevice.h:3486 [inline]
     (_xmit_ETHER#2){+.-...}, at: [<ffffffff837a8182>]
    sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
    
    but task is already holding lock:
     (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>] spin_lock
    include/linux/spinlock.h:299 [inline]
     (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>]
    ip_expire+0x51/0x6c0 net/ipv4/ip_fragment.c:201
    
    which lock already depends on the new lock.
    
    the existing dependency chain (in reverse order) is:
    
    -> #1 (&(&q->lock)->rlock){+.-...}:
           validate_chain kernel/locking/lockdep.c:2267 [inline]
           __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
           lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
           __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
           _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
           spin_lock include/linux/spinlock.h:299 [inline]
           ip_defrag+0x3a2/0x4130 net/ipv4/ip_fragment.c:669
           ip_check_defrag+0x4e3/0x8b0 net/ipv4/ip_fragment.c:713
           packet_rcv_fanout+0x282/0x800 net/packet/af_packet.c:1459
           deliver_skb net/core/dev.c:1834 [inline]
           dev_queue_xmit_nit+0x294/0xa90 net/core/dev.c:1890
           xmit_one net/core/dev.c:2903 [inline]
           dev_hard_start_xmit+0x16b/0xab0 net/core/dev.c:2923
           sch_direct_xmit+0x31f/0x6d0 net/sched/sch_generic.c:182
           __dev_xmit_skb net/core/dev.c:3092 [inline]
           __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
           dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
           neigh_resolve_output+0x6b9/0xb10 net/core/neighbour.c:1308
           neigh_output include/net/neighbour.h:478 [inline]
           ip_finish_output2+0x8b8/0x15a0 net/ipv4/ip_output.c:228
           ip_do_fragment+0x1d93/0x2720 net/ipv4/ip_output.c:672
           ip_fragment.constprop.54+0x145/0x200 net/ipv4/ip_output.c:545
           ip_finish_output+0x82d/0xe10 net/ipv4/ip_output.c:314
           NF_HOOK_COND include/linux/netfilter.h:246 [inline]
           ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
           dst_output include/net/dst.h:486 [inline]
           ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
           ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
           ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
           raw_sendmsg+0x26de/0x3a00 net/ipv4/raw.c:655
           inet_sendmsg+0x164/0x5b0 net/ipv4/af_inet.c:761
           sock_sendmsg_nosec net/socket.c:633 [inline]
           sock_sendmsg+0xca/0x110 net/socket.c:643
           ___sys_sendmsg+0x4a3/0x9f0 net/socket.c:1985
           __sys_sendmmsg+0x25c/0x750 net/socket.c:2075
           SYSC_sendmmsg net/socket.c:2106 [inline]
           SyS_sendmmsg+0x35/0x60 net/socket.c:2101
           do_syscall_64+0x2e8/0x930 arch/x86/entry/common.c:281
           return_from_SYSCALL_64+0x0/0x7a
    
    -> #0 (_xmit_ETHER#2){+.-...}:
           check_prev_add kernel/locking/lockdep.c:1830 [inline]
           check_prevs_add+0xa8f/0x19f0 kernel/locking/lockdep.c:1940
           validate_chain kernel/locking/lockdep.c:2267 [inline]
           __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
           lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
           __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
           _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
           spin_lock include/linux/spinlock.h:299 [inline]
           __netif_tx_lock include/linux/netdevice.h:3486 [inline]
           sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
           __dev_xmit_skb net/core/dev.c:3092 [inline]
           __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
           dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
           neigh_hh_output include/net/neighbour.h:468 [inline]
           neigh_output include/net/neighbour.h:476 [inline]
           ip_finish_output2+0xf6c/0x15a0 net/ipv4/ip_output.c:228
           ip_finish_output+0xa29/0xe10 net/ipv4/ip_output.c:316
           NF_HOOK_COND include/linux/netfilter.h:246 [inline]
           ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
           dst_output include/net/dst.h:486 [inline]
           ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
           ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
           ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
           icmp_push_reply+0x372/0x4d0 net/ipv4/icmp.c:394
           icmp_send+0x156c/0x1c80 net/ipv4/icmp.c:754
           ip_expire+0x40e/0x6c0 net/ipv4/ip_fragment.c:239
           call_timer_fn+0x241/0x820 kernel/time/timer.c:1268
           expire_timers kernel/time/timer.c:1307 [inline]
           __run_timers+0x960/0xcf0 kernel/time/timer.c:1601
           run_timer_softirq+0x21/0x80 kernel/time/timer.c:1614
           __do_softirq+0x31f/0xbe7 kernel/softirq.c:284
           invoke_softirq kernel/softirq.c:364 [inline]
           irq_exit+0x1cc/0x200 kernel/softirq.c:405
           exiting_irq arch/x86/include/asm/apic.h:657 [inline]
           smp_apic_timer_interrupt+0x76/0xa0 arch/x86/kernel/apic/apic.c:962
           apic_timer_interrupt+0x93/0xa0 arch/x86/entry/entry_64.S:707
           __read_once_size include/linux/compiler.h:254 [inline]
           atomic_read arch/x86/include/asm/atomic.h:26 [inline]
           rcu_dynticks_curr_cpu_in_eqs kernel/rcu/tree.c:350 [inline]
           __rcu_is_watching kernel/rcu/tree.c:1133 [inline]
           rcu_is_watching+0x83/0x110 kernel/rcu/tree.c:1147
           rcu_read_lock_held+0x87/0xc0 kernel/rcu/update.c:293
           radix_tree_deref_slot include/linux/radix-tree.h:238 [inline]
           filemap_map_pages+0x6d4/0x1570 mm/filemap.c:2335
           do_fault_around mm/memory.c:3231 [inline]
           do_read_fault mm/memory.c:3265 [inline]
           do_fault+0xbd5/0x2080 mm/memory.c:3370
           handle_pte_fault mm/memory.c:3600 [inline]
           __handle_mm_fault+0x1062/0x2cb0 mm/memory.c:3714
           handle_mm_fault+0x1e2/0x480 mm/memory.c:3751
           __do_page_fault+0x4f6/0xb60 arch/x86/mm/fault.c:1397
           do_page_fault+0x54/0x70 arch/x86/mm/fault.c:1460
           page_fault+0x28/0x30 arch/x86/entry/entry_64.S:1011
    
    other info that might help us debug this:
    
     Possible unsafe locking scenario:
    
           CPU0                    CPU1
           ----                    ----
      lock(&(&q->lock)->rlock);
                                   lock(_xmit_ETHER#2);
                                   lock(&(&q->lock)->rlock);
      lock(_xmit_ETHER#2);
    
     *** DEADLOCK ***
    
    10 locks held by modprobe/12392:
     #0:  (&mm->mmap_sem){++++++}, at: [<ffffffff81329758>]
    __do_page_fault+0x2b8/0xb60 arch/x86/mm/fault.c:1336
     #1:  (rcu_read_lock){......}, at: [<ffffffff8188cab6>]
    filemap_map_pages+0x1e6/0x1570 mm/filemap.c:2324
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    spin_lock include/linux/spinlock.h:299 [inline]
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    pte_alloc_one_map mm/memory.c:2944 [inline]
     #2:  (&(ptlock_ptr(page))->rlock#2){+.+...}, at: [<ffffffff81984a78>]
    alloc_set_pte+0x13b8/0x1b90 mm/memory.c:3072
     #3:  (((&q->timer))){+.-...}, at: [<ffffffff81627e72>]
    lockdep_copy_map include/linux/lockdep.h:175 [inline]
     #3:  (((&q->timer))){+.-...}, at: [<ffffffff81627e72>]
    call_timer_fn+0x1c2/0x820 kernel/time/timer.c:1258
     #4:  (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>] spin_lock
    include/linux/spinlock.h:299 [inline]
     #4:  (&(&q->lock)->rlock){+.-...}, at: [<ffffffff8389a4d1>]
    ip_expire+0x51/0x6c0 net/ipv4/ip_fragment.c:201
     #5:  (rcu_read_lock){......}, at: [<ffffffff8389a633>]
    ip_expire+0x1b3/0x6c0 net/ipv4/ip_fragment.c:216
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>] spin_trylock
    include/linux/spinlock.h:309 [inline]
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>] icmp_xmit_lock
    net/ipv4/icmp.c:219 [inline]
     #6:  (slock-AF_INET){+.-...}, at: [<ffffffff839b3313>]
    icmp_send+0x803/0x1c80 net/ipv4/icmp.c:681
     #7:  (rcu_read_lock_bh){......}, at: [<ffffffff838ab9a1>]
    ip_finish_output2+0x2c1/0x15a0 net/ipv4/ip_output.c:198
     #8:  (rcu_read_lock_bh){......}, at: [<ffffffff836d1dee>]
    __dev_queue_xmit+0x23e/0x1e60 net/core/dev.c:3324
     #9:  (dev->qdisc_running_key ?: &qdisc_running_key){+.....}, at:
    [<ffffffff836d3a27>] dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
    
    stack backtrace:
    CPU: 0 PID: 12392 Comm: modprobe Not tainted 4.10.0+ #29
    Hardware name: Google Google Compute Engine/Google Compute Engine,
    BIOS Google 01/01/2011
    Call Trace:
     <IRQ>
     __dump_stack lib/dump_stack.c:16 [inline]
     dump_stack+0x2ee/0x3ef lib/dump_stack.c:52
     print_circular_bug+0x307/0x3b0 kernel/locking/lockdep.c:1204
     check_prev_add kernel/locking/lockdep.c:1830 [inline]
     check_prevs_add+0xa8f/0x19f0 kernel/locking/lockdep.c:1940
     validate_chain kernel/locking/lockdep.c:2267 [inline]
     __lock_acquire+0x2149/0x3430 kernel/locking/lockdep.c:3340
     lock_acquire+0x2a1/0x630 kernel/locking/lockdep.c:3755
     __raw_spin_lock include/linux/spinlock_api_smp.h:142 [inline]
     _raw_spin_lock+0x33/0x50 kernel/locking/spinlock.c:151
     spin_lock include/linux/spinlock.h:299 [inline]
     __netif_tx_lock include/linux/netdevice.h:3486 [inline]
     sch_direct_xmit+0x282/0x6d0 net/sched/sch_generic.c:180
     __dev_xmit_skb net/core/dev.c:3092 [inline]
     __dev_queue_xmit+0x13e5/0x1e60 net/core/dev.c:3358
     dev_queue_xmit+0x17/0x20 net/core/dev.c:3423
     neigh_hh_output include/net/neighbour.h:468 [inline]
     neigh_output include/net/neighbour.h:476 [inline]
     ip_finish_output2+0xf6c/0x15a0 net/ipv4/ip_output.c:228
     ip_finish_output+0xa29/0xe10 net/ipv4/ip_output.c:316
     NF_HOOK_COND include/linux/netfilter.h:246 [inline]
     ip_output+0x1f0/0x7a0 net/ipv4/ip_output.c:404
     dst_output include/net/dst.h:486 [inline]
     ip_local_out+0x95/0x170 net/ipv4/ip_output.c:124
     ip_send_skb+0x3c/0xc0 net/ipv4/ip_output.c:1492
     ip_push_pending_frames+0x64/0x80 net/ipv4/ip_output.c:1512
     icmp_push_reply+0x372/0x4d0 net/ipv4/icmp.c:394
     icmp_send+0x156c/0x1c80 net/ipv4/icmp.c:754
     ip_expire+0x40e/0x6c0 net/ipv4/ip_fragment.c:239
     call_timer_fn+0x241/0x820 kernel/time/timer.c:1268
     expire_timers kernel/time/timer.c:1307 [inline]
     __run_timers+0x960/0xcf0 kernel/time/timer.c:1601
     run_timer_softirq+0x21/0x80 kernel/time/timer.c:1614
     __do_softirq+0x31f/0xbe7 kernel/softirq.c:284
     invoke_softirq kernel/softirq.c:364 [inline]
     irq_exit+0x1cc/0x200 kernel/softirq.c:405
     exiting_irq arch/x86/include/asm/apic.h:657 [inline]
     smp_apic_timer_interrupt+0x76/0xa0 arch/x86/kernel/apic/apic.c:962
     apic_timer_interrupt+0x93/0xa0 arch/x86/entry/entry_64.S:707
    RIP: 0010:__read_once_size include/linux/compiler.h:254 [inline]
    RIP: 0010:atomic_read arch/x86/include/asm/atomic.h:26 [inline]
    RIP: 0010:rcu_dynticks_curr_cpu_in_eqs kernel/rcu/tree.c:350 [inline]
    RIP: 0010:__rcu_is_watching kernel/rcu/tree.c:1133 [inline]
    RIP: 0010:rcu_is_watching+0x83/0x110 kernel/rcu/tree.c:1147
    RSP: 0000:ffff8801c391f120 EFLAGS: 00000a03 ORIG_RAX: ffffffffffffff10
    RAX: dffffc0000000000 RBX: ffff8801c391f148 RCX: 0000000000000000
    RDX: 0000000000000000 RSI: 000055edd4374000 RDI: ffff8801dbe1ae0c
    RBP: ffff8801c391f1a0 R08: 0000000000000002 R09: 0000000000000000
    R10: dffffc0000000000 R11: 0000000000000002 R12: 1ffff10038723e25
    R13: ffff8801dbe1ae00 R14: ffff8801c391f680 R15: dffffc0000000000
     </IRQ>
     rcu_read_lock_held+0x87/0xc0 kernel/rcu/update.c:293
     radix_tree_deref_slot include/linux/radix-tree.h:238 [inline]
     filemap_map_pages+0x6d4/0x1570 mm/filemap.c:2335
     do_fault_around mm/memory.c:3231 [inline]
     do_read_fault mm/memory.c:3265 [inline]
     do_fault+0xbd5/0x2080 mm/memory.c:3370
     handle_pte_fault mm/memory.c:3600 [inline]
     __handle_mm_fault+0x1062/0x2cb0 mm/memory.c:3714
     handle_mm_fault+0x1e2/0x480 mm/memory.c:3751
     __do_page_fault+0x4f6/0xb60 arch/x86/mm/fault.c:1397
     do_page_fault+0x54/0x70 arch/x86/mm/fault.c:1460
     page_fault+0x28/0x30 arch/x86/entry/entry_64.S:1011
    RIP: 0033:0x7f83172f2786
    RSP: 002b:00007fffe859ae80 EFLAGS: 00010293
    RAX: 000055edd4373040 RBX: 00007f83175111c8 RCX: 000055edd4373238
    RDX: 0000000000000000 RSI: 0000000000000000 RDI: 00007f8317510970
    RBP: 00007fffe859afd0 R08: 0000000000000009 R09: 0000000000000000
    R10: 0000000000000064 R11: 0000000000000000 R12: 000055edd4373040
    R13: 0000000000000000 R14: 00007fffe859afe8 R15: 0000000000000000
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Reported-by: Dmitry Vyukov <dvyukov@google.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 24c2503255d35c269b67162c397a1a1c1e02f6ce
Author: Borislav Petkov <bp@suse.de>
Date:   Wed Jan 25 21:00:48 2017 +0100

    x86/microcode: Do not access the initrd after it has been freed
    
    When we look for microcode blobs, we first try builtin and if that
    doesn't succeed, we fallback to the initrd supplied to the kernel.
    
    However, at some point doing boot, that initrd gets jettisoned and we
    shouldn't access it anymore. But we do, as the below KASAN report shows.
    That's because find_microcode_in_initrd() doesn't check whether the
    initrd is still valid or not.
    
    So do that.
    
      ==================================================================
      BUG: KASAN: use-after-free in find_cpio_data
      Read of size 1 by task swapper/1/0
      page:ffffea0000db9d40 count:0 mapcount:0 mapping:          (null) index:0x1
      flags: 0x100000000000000()
      raw: 0100000000000000 0000000000000000 0000000000000001 00000000ffffffff
      raw: dead000000000100 dead000000000200 0000000000000000 0000000000000000
      page dumped because: kasan: bad access detected
      CPU: 1 PID: 0 Comm: swapper/1 Tainted: G        W       4.10.0-rc5-debug-00075-g2dbde22 #3
      Hardware name: Dell Inc. XPS 13 9360/0839Y6, BIOS 1.2.3 12/01/2016
      Call Trace:
       dump_stack
       ? _atomic_dec_and_lock
       ? __dump_page
       kasan_report_error
       ? pointer
       ? find_cpio_data
       __asan_report_load1_noabort
       ? find_cpio_data
       find_cpio_data
       ? vsprintf
       ? dump_stack
       ? get_ucode_user
       ? print_usage_bug
       find_microcode_in_initrd
       __load_ucode_intel
       ? collect_cpu_info_early
       ? debug_check_no_locks_freed
       load_ucode_intel_ap
       ? collect_cpu_info
       ? trace_hardirqs_on
       ? flat_send_IPI_mask_allbutself
       load_ucode_ap
       ? get_builtin_firmware
       ? flush_tlb_func
       ? do_raw_spin_trylock
       ? cpumask_weight
       cpu_init
       ? trace_hardirqs_off
       ? play_dead_common
       ? native_play_dead
       ? hlt_play_dead
       ? syscall_init
       ? arch_cpu_idle_dead
       ? do_idle
       start_secondary
       start_cpu
      Memory state around the buggy address:
       ffff880036e74f00: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
       ffff880036e74f80: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
      >ffff880036e75000: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
                         ^
       ffff880036e75080: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
       ffff880036e75100: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff
      ==================================================================
    
    Reported-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Tested-by: Andrey Ryabinin <aryabinin@virtuozzo.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Link: http://lkml.kernel.org/r/20170126165833.evjemhbqzaepirxo@pd.tnic
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 3bcb846ca4cf55415d3719e64bb45a124792c589
Author: Eric Dumazet <edumazet@google.com>
Date:   Sat Jun 4 20:02:28 2016 -0700

    net: get rid of spin_trylock() in net_tx_action()
    
    Note: Tom Herbert posted almost same patch 3 months back, but for
    different reasons.
    
    The reasons we want to get rid of this spin_trylock() are :
    
    1) Under high qdisc pressure, the spin_trylock() has almost no
    chance to succeed.
    
    2) We loop multiple times in softirq handler, eventually reaching
    the max retry count (10), and we schedule ksoftirqd.
    
    Since we want to adhere more strictly to ksoftirqd being waked up in
    the future (https://lwn.net/Articles/687617/), better avoid spurious
    wakeups.
    
    3) calls to __netif_reschedule() dirty the cache line containing
    q->next_sched, slowing down the owner of qdisc.
    
    4) RT kernels can not use the spin_trylock() here.
    
    With help of busylock, we get the qdisc spinlock fast enough, and
    the trylock trick brings only performance penalty.
    
    Depending on qdisc setup, I observed a gain of up to 19 % in qdisc
    performance (1016600 pps instead of 853400 pps, using prio+tbf+fq_codel)
    
    ("mpstat -I SCPU 1" is much happier now)
    
    Signed-off-by: Eric Dumazet <edumazet@google.com>
    Cc: Tom Herbert <tom@herbertland.com>
    Acked-by: Tom Herbert <tom@herbertland.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c578e9ab4cd467bd7b9e1ea391b5376894c56d0d
Merge: c971c0e580a6 f0cdf76c103f
Author: David S. Miller <davem@davemloft.net>
Date:   Tue Apr 26 15:53:06 2016 -0400

    Merge branch 'netdev_tx_locked-removal'
    
    Florian Westphal says:
    
    ====================
    net: core: remove TX_LOCKED support
    
    Not that many users left, lets kill it.
    
    TX_LOCKED was meant to be used by LLTX drivers when spin_trylock()
    failed.  Stack then re-queued if collisions happened on different
    cpus or free'd the skb to prevent deadlocks.
    
    Most of the driver removal patches fall into one of three categories:
    1. remove the driver-private tx lock (and LLTX flag), or...
    2. convert spin_trylock to plain spin_lock, or...
    3. convert TX_LOCKED to free+TX_OK
    
    Patches are grouped by these categories, last patch is the actual removal.
    All driver changes were compile tested only with exception of atl1e.
    ====================
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 5317d9af12a59e83a6f173eac3808cc21f6e9d2b
Author: Michal Kubeek <mkubecek@suse.cz>
Date:   Thu Aug 1 10:04:14 2013 +0200

    ipv6: prevent fib6_run_gc() contention
    
    commit 2ac3ac8f86f2fe065d746d9a9abaca867adec577 upstream.
    
    On a high-traffic router with many processors and many IPv6 dst
    entries, soft lockup in fib6_run_gc() can occur when number of
    entries reaches gc_thresh.
    
    This happens because fib6_run_gc() uses fib6_gc_lock to allow
    only one thread to run the garbage collector but ip6_dst_gc()
    doesn't update net->ipv6.ip6_rt_last_gc until fib6_run_gc()
    returns. On a system with many entries, this can take some time
    so that in the meantime, other threads pass the tests in
    ip6_dst_gc() (ip6_rt_last_gc is still not updated) and wait for
    the lock. They then have to run the garbage collector one after
    another which blocks them for quite long.
    
    Resolve this by replacing special value ~0UL of expire parameter
    to fib6_run_gc() by explicit "force" parameter to choose between
    spin_lock_bh() and spin_trylock_bh() and call fib6_run_gc() with
    force=false if gc_thresh is reached but not max_size.
    
    Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [lizf: Backported to 3.4: adjust context]
    Signed-off-by: Zefan Li <lizefan@huawei.com>

commit 58c5661f2144c089bbc2e5d87c9ec1dc1d2964fe
Author: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
Date:   Mon Dec 14 11:19:10 2015 +0100

    panic, x86: Allow CPUs to save registers even if looping in NMI context
    
    Currently, kdump_nmi_shootdown_cpus(), a subroutine of crash_kexec(),
    sends an NMI IPI to CPUs which haven't called panic() to stop them,
    save their register information and do some cleanups for crash dumping.
    However, if such a CPU is infinitely looping in NMI context, we fail to
    save its register information into the crash dump.
    
    For example, this can happen when unknown NMIs are broadcast to all
    CPUs as follows:
    
      CPU 0                             CPU 1
      ===========================       ==========================
      receive an unknown NMI
      unknown_nmi_error()
        panic()                         receive an unknown NMI
          spin_trylock(&panic_lock)     unknown_nmi_error()
          crash_kexec()                   panic()
                                            spin_trylock(&panic_lock)
                                            panic_smp_self_stop()
                                              infinite loop
            kdump_nmi_shootdown_cpus()
              issue NMI IPI -----------> blocked until IRET
                                              infinite loop...
    
    Here, since CPU 1 is in NMI context, the second NMI from CPU 0 is
    blocked until CPU 1 executes IRET. However, CPU 1 never executes IRET,
    so the NMI is not handled and the callback function to save registers is
    never called.
    
    In practice, this can happen on some servers which broadcast NMIs to all
    CPUs when the NMI button is pushed.
    
    To save registers in this case, we need to:
    
      a) Return from NMI handler instead of looping infinitely
      or
      b) Call the callback function directly from the infinite loop
    
    Inherently, a) is risky because NMI is also used to prevent corrupted
    data from being propagated to devices.  So, we chose b).
    
    This patch does the following:
    
    1. Move the infinite looping of CPUs which haven't called panic() in NMI
       context (actually done by panic_smp_self_stop()) outside of panic() to
       enable us to refer pt_regs. Please note that panic_smp_self_stop() is
       still used for normal context.
    
    2. Call a callback of kdump_nmi_shootdown_cpus() directly to save
       registers and do some cleanups after setting waiting_for_crash_ipi which
       is used for counting down the number of CPUs which handled the callback
    
    Signed-off-by: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Acked-by: Michal Hocko <mhocko@suse.com>
    Cc: Aaron Tomlin <atomlin@redhat.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Andy Lutomirski <luto@kernel.org>
    Cc: Baoquan He <bhe@redhat.com>
    Cc: Chris Metcalf <cmetcalf@ezchip.com>
    Cc: Dave Young <dyoung@redhat.com>
    Cc: David Hildenbrand <dahi@linux.vnet.ibm.com>
    Cc: Don Zickus <dzickus@redhat.com>
    Cc: Eric Biederman <ebiederm@xmission.com>
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Gobinda Charan Maji <gobinda.cemk07@gmail.com>
    Cc: HATAYAMA Daisuke <d.hatayama@jp.fujitsu.com>
    Cc: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
    Cc: "H. Peter Anvin" <hpa@zytor.com>
    Cc: Ingo Molnar <mingo@kernel.org>
    Cc: Javi Merino <javi.merino@arm.com>
    Cc: Jiang Liu <jiang.liu@linux.intel.com>
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: kexec@lists.infradead.org
    Cc: linux-doc@vger.kernel.org
    Cc: lkml <linux-kernel@vger.kernel.org>
    Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
    Cc: Michal Nazarewicz <mina86@mina86.com>
    Cc: Nicolas Iooss <nicolas.iooss_linux@m4x.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Prarit Bhargava <prarit@redhat.com>
    Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
    Cc: Seth Jennings <sjenning@redhat.com>
    Cc: Stefan Lippers-Hollmann <s.l-h@gmx.de>
    Cc: Steven Rostedt <rostedt@goodmis.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Ulrich Obergfell <uobergfe@redhat.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: Vivek Goyal <vgoyal@redhat.com>
    Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
    Link: http://lkml.kernel.org/r/20151210014628.25437.75256.stgit@softrs
    [ Cleanup comments, fixup formatting. ]
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit 2491f0184830c5f1e1c794283177179937def4b7
Author: Michal Kubeek <mkubecek@suse.cz>
Date:   Thu Aug 1 10:04:14 2013 +0200

    ipv6: prevent fib6_run_gc() contention
    
    commit 2ac3ac8f86f2fe065d746d9a9abaca867adec577 upstream.
    
    On a high-traffic router with many processors and many IPv6 dst
    entries, soft lockup in fib6_run_gc() can occur when number of
    entries reaches gc_thresh.
    
    This happens because fib6_run_gc() uses fib6_gc_lock to allow
    only one thread to run the garbage collector but ip6_dst_gc()
    doesn't update net->ipv6.ip6_rt_last_gc until fib6_run_gc()
    returns. On a system with many entries, this can take some time
    so that in the meantime, other threads pass the tests in
    ip6_dst_gc() (ip6_rt_last_gc is still not updated) and wait for
    the lock. They then have to run the garbage collector one after
    another which blocks them for quite long.
    
    Resolve this by replacing special value ~0UL of expire parameter
    to fib6_run_gc() by explicit "force" parameter to choose between
    spin_lock_bh() and spin_trylock_bh() and call fib6_run_gc() with
    force=false if gc_thresh is reached but not max_size.
    
    Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>

commit 9511ca19dafbd503fb467d451fe331a6008f08cf
Author: Will Deacon <will@kernel.org>
Date:   Wed Jul 22 18:25:52 2015 +0100

    arm64: rwlocks: don't fail trylock purely due to contention
    
    STXR can fail for a number of reasons, so don't fail an rwlock trylock
    operation simply because the STXR reported failure.
    
    I'm not aware of any issues with the current code, but this makes it
    consistent with spin_trylock and also other architectures (e.g. arch/arm).
    
    Reported-by: Catalin Marinas <catalin.marinas@arm.com>
    Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
    Signed-off-by: Will Deacon <will.deacon@arm.com>

commit ba310bc86f54169bf4ec414683bd61dcd2f8675f
Author: Michal Kubeek <mkubecek@suse.cz>
Date:   Thu Aug 1 10:04:14 2013 +0200

    ipv6: prevent fib6_run_gc() contention
    
    commit 2ac3ac8f86f2fe065d746d9a9abaca867adec577 upstream.
    
    On a high-traffic router with many processors and many IPv6 dst
    entries, soft lockup in fib6_run_gc() can occur when number of
    entries reaches gc_thresh.
    
    This happens because fib6_run_gc() uses fib6_gc_lock to allow
    only one thread to run the garbage collector but ip6_dst_gc()
    doesn't update net->ipv6.ip6_rt_last_gc until fib6_run_gc()
    returns. On a system with many entries, this can take some time
    so that in the meantime, other threads pass the tests in
    ip6_dst_gc() (ip6_rt_last_gc is still not updated) and wait for
    the lock. They then have to run the garbage collector one after
    another which blocks them for quite long.
    
    Resolve this by replacing special value ~0UL of expire parameter
    to fib6_run_gc() by explicit "force" parameter to choose between
    spin_lock_bh() and spin_trylock_bh() and call fib6_run_gc() with
    force=false if gc_thresh is reached but not max_size.
    
    Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c17af4dd96aa99e6e58b5d715a7c66db63a15106
Author: David Ahern <david.ahern@oracle.com>
Date:   Mon Jun 15 16:15:43 2015 -0400

    sparc: perf: Disable pagefaults while walking userspace stacks
    
    Page faults generated walking userspace stacks can call schedule to switch
    out the task. When collecting callchains for scheduler tracepoints this
    causes a deadlock as the tracepoints can be hit with the runqueue lock held:
    
    [ 8138.159054] WARNING: CPU: 758 PID: 12488 at /opt/dahern/linux.git/arch/sparc/kernel/nmi.c:80 perfctr_irq+0x1f8/0x2b4()
    
    [ 8138.203152] Watchdog detected hard LOCKUP on cpu 758
    
    [ 8138.410969] CPU: 758 PID: 12488 Comm: perf Not tainted 4.0.0-rc6+ #6
    [ 8138.437146] Call Trace:
    [ 8138.447193]  [000000000045cdd4] warn_slowpath_common+0x7c/0xa0
    [ 8138.471238]  [000000000045ce90] warn_slowpath_fmt+0x30/0x40
    [ 8138.494189]  [0000000000983e38] perfctr_irq+0x1f8/0x2b4
    [ 8138.515716]  [00000000004209f4] tl0_irq15+0x14/0x20
    [ 8138.535791]  [00000000009839ec] _raw_spin_trylock_bh+0x68/0x108
    [ 8138.560180]  [0000000000980018] __schedule+0xcc/0x710
    [ 8138.580981]  [00000000009806dc] preempt_schedule_common+0x10/0x3c
    [ 8138.606082]  [000000000098077c] _cond_resched+0x34/0x44
    [ 8138.627603]  [0000000000565990] kmem_cache_alloc_node+0x24/0x1a0
    [ 8138.652345]  [0000000000450b60] tsb_grow+0xac/0x488
    [ 8138.672429]  [0000000000985040] do_sparc64_fault+0x4dc/0x6e4
    [ 8138.695736]  [0000000000407c2c] sparc64_realfault_common+0x10/0x20
    [ 8138.721202]  [00000000006f2e24] NG4copy_from_user+0xa4/0x3c0
    [ 8138.744510]  [000000000044f900] perf_callchain_user+0x5c/0x6c
    [ 8138.768182]  [0000000000517b5c] perf_callchain+0x16c/0x19c
    [ 8138.790774]  [0000000000515f84] perf_prepare_sample+0x68/0x218
    [ 8138.814801] ---[ end trace 42ca6294b1ff7573 ]---
    
    As with PowerPC (b59a1bfcc240, "powerpc/perf: Disable pagefaults during
    callchain stack read") disable pagefaults while walking userspace stacks.
    
    Signed-off-by: David Ahern <david.ahern@oracle.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 6403bd7d0ea1878a487296114eccf78658d7dd7a
Author: Waiman Long <Waiman.Long@hp.com>
Date:   Fri Apr 24 14:56:33 2015 -0400

    locking/qspinlock: Extract out code snippets for the next patch
    
    This is a preparatory patch that extracts out the following 2 code
    snippets to prepare for the next performance optimization patch.
    
     1) the logic for the exchange of new and previous tail code words
        into a new xchg_tail() function.
     2) the logic for clearing the pending bit and setting the locked bit
        into a new clear_pending_set_locked() function.
    
    This patch also simplifies the trylock operation before queuing by
    calling queued_spin_trylock() directly.
    
    Signed-off-by: Waiman Long <Waiman.Long@hp.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Cc: Borislav Petkov <bp@alien8.de>
    Cc: Daniel J Blueman <daniel@numascale.com>
    Cc: David Vrabel <david.vrabel@citrix.com>
    Cc: Douglas Hatch <doug.hatch@hp.com>
    Cc: H. Peter Anvin <hpa@zytor.com>
    Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Cc: Linus Torvalds <torvalds@linux-foundation.org>
    Cc: Oleg Nesterov <oleg@redhat.com>
    Cc: Paolo Bonzini <paolo.bonzini@gmail.com>
    Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Raghavendra K T <raghavendra.kt@linux.vnet.ibm.com>
    Cc: Rik van Riel <riel@redhat.com>
    Cc: Scott J Norton <scott.norton@hp.com>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: virtualization@lists.linux-foundation.org
    Cc: xen-devel@lists.xenproject.org
    Link: http://lkml.kernel.org/r/1429901803-29771-5-git-send-email-Waiman.Long@hp.com
    Signed-off-by: Ingo Molnar <mingo@kernel.org>

commit 6fad18fa51392c9847a4e3a95134b2e57155e563
Author: Rabin Vincent <rabin@rab.in>
Date:   Fri Nov 14 19:00:41 2014 +0100

    serial: 8250: don't attempt a trylock if in sysrq
    
    Attempting to use SysRq via the 8250 serial port with spin lock
    debugging on on a uniprocessor system results in the following splat:
    
     SysRq :
     BUG: spinlock trylock failure on UP on CPU#0, swapper/0
      lock: serial8250_ports+0x0/0x8c0, .magic: dead4ead, .owner: swapper/0, .owner_cpu: 0
     CPU: 0 PID: 0 Comm: swapper Not tainted 3.18.0-rc4+ #37
     Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.7.5-20140531_083030-gandalf 04/01/2014
      ffffffff8245ba00 ffffffff81628b28 ffffffff812c8d27 ffffffff81628b48
      ffffffff8106812e ffffffff8245ba00 ffffffff814e22ed ffffffff81628b68
      ffffffff810681a6 0000000000000000 0000000000000000 ffffffff81628b88
     Call Trace:
      <IRQ>  [<ffffffff812c8d27>] dump_stack+0x19/0x1b
      [<ffffffff8106812e>] spin_dump+0x7e/0xd0
      [<ffffffff810681a6>] spin_bug+0x26/0x30
      [<ffffffff8106843c>] do_raw_spin_trylock+0x4c/0x60
      [<ffffffff812cdb1d>] _raw_spin_trylock+0x1d/0x60
      [<ffffffff812336d8>] serial8250_console_write+0x68/0x190
      [<ffffffff811eb0b0>] ? sprintf+0x40/0x50
      [<ffffffff8106ab5e>] call_console_drivers.constprop.11+0x9e/0xf0
      [<ffffffff8106b276>] console_unlock+0x3e6/0x490
      [<ffffffff8106b595>] vprintk_emit+0x275/0x530
      [<ffffffff812c869a>] printk+0x4d/0x4f
      [<ffffffff8121e612>] __handle_sysrq+0x62/0x1b0
      [<ffffffff8121e5b5>] ? __handle_sysrq+0x5/0x1b0
      [<ffffffff8121ebc6>] handle_sysrq+0x26/0x30
      [<ffffffff81233157>] serial8250_rx_chars+0x1d7/0x250
      [<ffffffff812338bb>] serial8250_handle_irq+0x7b/0x90
      [<ffffffff812338f3>] serial8250_default_handle_irq+0x23/0x30
      [<ffffffff812318b3>] serial8250_interrupt+0x63/0xe0
      [<ffffffff8106d80e>] handle_irq_event_percpu+0x4e/0x200
      [<ffffffff8106da01>] handle_irq_event+0x41/0x70
      [<ffffffff810701ee>] ? handle_edge_irq+0x1e/0x110
      [<ffffffff8107026e>] handle_edge_irq+0x9e/0x110
      [<ffffffff810041c2>] handle_irq+0x22/0x40
      [<ffffffff812d096e>] do_IRQ+0x4e/0xf0
      [<ffffffff812cf4ed>] common_interrupt+0x6d/0x6d
      <EOI>  [<ffffffff8100acbf>] ? default_idle+0x1f/0xd0
      [<ffffffff8100acbd>] ? default_idle+0x1d/0xd0
      [<ffffffff8100b61f>] arch_cpu_idle+0xf/0x20
      [<ffffffff8105c1db>] cpu_startup_entry+0x25b/0x360
      [<ffffffff812c726e>] rest_init+0xbe/0xd0
      [<ffffffff816a4dcb>] start_kernel+0x339/0x346
      [<ffffffff816a4495>] x86_64_start_reservations+0x2a/0x2c
      [<ffffffff816a4589>] x86_64_start_kernel+0xf2/0xf6
     HELP : loglevel(0-9) reboot(b) crash(c) show-all-locks(d) te...
    
    Before ebade5e833eda30 ("serial: 8250: Clean up the locking for -rt")
    this was handled by not even attempting to try the lock if port->sysrq,
    since it is known to be taken by the interrupt handler; see
    https://bugzilla.kernel.org/show_bug.cgi?id=6716#c1.  Restore that
    behavior.
    
    Signed-off-by: Rabin Vincent <rabin@rab.in>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 91fcb532efe366d79b93a3c8c368b9dca6176a55
Author: Theodore Ts'o <tytso@mit.edu>
Date:   Tue Jun 10 22:46:37 2014 -0400

    random: always update the entropy pool under the spinlock
    
    Instead of using lockless techniques introduced in commit
    902c098a3663, use spin_trylock to try to grab entropy pool's lock.  If
    we can't get the lock, then just try again on the next interrupt.
    
    Based on discussions with George Spelvin.
    
    Signed-off-by: Theodore Ts'o <tytso@mit.edu>
    Cc: George Spelvin <linux@horizon.com>

commit 5b3f683e694a835f5dfdab06102be1a50604c3b7
Author: Philipp Hachtmann <phacht@linux.vnet.ibm.com>
Date:   Mon Apr 7 18:25:23 2014 +0200

    s390/spinlock: cleanup spinlock code
    
    Improve the spinlock code in several aspects:
     - Have _raw_compare_and_swap return true if the operation has been
       successful instead of returning the old value.
     - Remove the "volatile" from arch_spinlock_t and arch_rwlock_t
     - Rename 'owner_cpu' to 'lock'
     - Add helper functions arch_spin_trylock_once / arch_spin_tryrelease_once
    
    [ Martin Schwidefsky: patch breakdown and code beautification ]
    
    Signed-off-by: Philipp Hachtmann <phacht@linux.vnet.ibm.com>
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>

commit 9400319cc170bec3ff02f0adcb978552682725af
Author: Will Deacon <will@kernel.org>
Date:   Mon Aug 12 18:03:26 2013 +0100

    ARM: 7811/1: locks: use early clobber in arch_spin_trylock
    
    commit afa31d8eb86fc2f25083e675d57ac8173a98f999 upstream.
    
    The res variable is written before we've finished with the input
    operands (namely the lock address), so ensure that we mark it as `early
    clobber' to avoid unintended register sharing.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Wang Weidong <wangweidong1@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 63f12e8d2bea38715b30a6051325230f6ec25a3b
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue Apr 16 14:08:50 2013 -0400

    xen/smp/spinlock: Fix leakage of the spinlock interrupt line for every CPU online/offline
    
    commit 66ff0fe9e7bda8aec99985b24daad03652f7304e upstream.
    
    While we don't use the spinlock interrupt line (see for details
    commit f10cd522c5fbfec9ae3cc01967868c9c2401ed23 -
    xen: disable PV spinlocks on HVM) - we should still do the proper
    init / deinit sequence. We did not do that correctly and for the
    CPU init for PVHVM guest we would allocate an interrupt line - but
    failed to deallocate the old interrupt line.
    
    This resulted in leakage of an irq_desc but more importantly this splat
    as we online an offlined CPU:
    
    genirq: Flags mismatch irq 71. 0002cc20 (spinlock1) vs. 0002cc20 (spinlock1)
    Pid: 2542, comm: init.late Not tainted 3.9.0-rc6upstream #1
    Call Trace:
     [<ffffffff811156de>] __setup_irq+0x23e/0x4a0
     [<ffffffff81194191>] ? kmem_cache_alloc_trace+0x221/0x250
     [<ffffffff811161bb>] request_threaded_irq+0xfb/0x160
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff813a8423>] bind_ipi_to_irqhandler+0xa3/0x160
     [<ffffffff81303758>] ? kasprintf+0x38/0x40
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff810cad35>] ? update_max_interval+0x15/0x40
     [<ffffffff816605db>] xen_init_lock_cpu+0x3c/0x78
     [<ffffffff81660029>] xen_hvm_cpu_notify+0x29/0x33
     [<ffffffff81676bdd>] notifier_call_chain+0x4d/0x70
     [<ffffffff810bb2a9>] __raw_notifier_call_chain+0x9/0x10
     [<ffffffff8109402b>] __cpu_notify+0x1b/0x30
     [<ffffffff8166834a>] _cpu_up+0xa0/0x14b
     [<ffffffff816684ce>] cpu_up+0xd9/0xec
     [<ffffffff8165f754>] store_online+0x94/0xd0
     [<ffffffff8141d15b>] dev_attr_store+0x1b/0x20
     [<ffffffff81218f44>] sysfs_write_file+0xf4/0x170
     [<ffffffff811a2864>] vfs_write+0xb4/0x130
     [<ffffffff811a302a>] sys_write+0x5a/0xa0
     [<ffffffff8167ada9>] system_call_fastpath+0x16/0x1b
    cpu 1 spinlock event irq -16
    smpboot: Booting Node 0 Processor 1 APIC 0x2
    
    And if one looks at the /proc/interrupts right after
    offlining (CPU1):
    
      70:          0          0  xen-percpu-ipi       spinlock0
      71:          0          0  xen-percpu-ipi       spinlock1
      77:          0          0  xen-percpu-ipi       spinlock2
    
    There is the oddity of the 'spinlock1' still being present.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Cc: Yijing Wang <wangyijing@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fed783a535fe9cf3068977562235cf334fbff0b3
Author: Will Deacon <will@kernel.org>
Date:   Mon Aug 12 18:04:05 2013 +0100

    ARM: 7812/1: rwlocks: retry trylock operation if strex fails on free lock
    
    commit 00efaa0250939dc148e2d3104fb3c18395d24a2d upstream.
    
    Commit 15e7e5c1ebf5 ("ARM: 7749/1: spinlock: retry trylock operation if
    strex fails on free lock") modifying our arch_spin_trylock to retry the
    acquisition if the lock appeared uncontended, but the strex failed.
    
    This patch does the same for rwlocks, which were missed by the original
    patch.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: Li Zefan <lizefan@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2620bf06f168527e8d5159d6c21ea80e60b663fd
Merge: 359d16ca1bd6 2a2822475d0e
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Aug 16 16:52:29 2013 -0700

    Merge branch 'fixes' of git://git.linaro.org/people/rmk/linux-arm
    
    Pull ARM fixes from Russell King:
     "The usual collection of random fixes.  Also some further fixes to the
      last set of security fixes, and some more from Will (which you may
      already have in a slightly different form)"
    
    * 'fixes' of git://git.linaro.org/people/rmk/linux-arm:
      ARM: 7807/1: kexec: validate CPU hotplug support
      ARM: 7812/1: rwlocks: retry trylock operation if strex fails on free lock
      ARM: 7811/1: locks: use early clobber in arch_spin_trylock
      ARM: 7810/1: perf: Fix array out of bounds access in armpmu_map_hw_event()
      ARM: 7809/1: perf: fix event validation for software group leaders
      ARM: Fix FIQ code on VIVT CPUs
      ARM: Fix !kuser helpers case
      ARM: Fix the world famous typo with is_gate_vma()

commit 00efaa0250939dc148e2d3104fb3c18395d24a2d
Author: Will Deacon <will@kernel.org>
Date:   Mon Aug 12 18:04:05 2013 +0100

    ARM: 7812/1: rwlocks: retry trylock operation if strex fails on free lock
    
    Commit 15e7e5c1ebf5 ("ARM: 7749/1: spinlock: retry trylock operation if
    strex fails on free lock") modifying our arch_spin_trylock to retry the
    acquisition if the lock appeared uncontended, but the strex failed.
    
    This patch does the same for rwlocks, which were missed by the original
    patch.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

commit afa31d8eb86fc2f25083e675d57ac8173a98f999
Author: Will Deacon <will@kernel.org>
Date:   Mon Aug 12 18:03:26 2013 +0100

    ARM: 7811/1: locks: use early clobber in arch_spin_trylock
    
    The res variable is written before we've finished with the input
    operands (namely the lock address), so ensure that we mark it as `early
    clobber' to avoid unintended register sharing.
    
    Signed-off-by: Will Deacon <will.deacon@arm.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>

commit 2ac3ac8f86f2fe065d746d9a9abaca867adec577
Author: Michal Kubeek <mkubecek@suse.cz>
Date:   Thu Aug 1 10:04:14 2013 +0200

    ipv6: prevent fib6_run_gc() contention
    
    On a high-traffic router with many processors and many IPv6 dst
    entries, soft lockup in fib6_run_gc() can occur when number of
    entries reaches gc_thresh.
    
    This happens because fib6_run_gc() uses fib6_gc_lock to allow
    only one thread to run the garbage collector but ip6_dst_gc()
    doesn't update net->ipv6.ip6_rt_last_gc until fib6_run_gc()
    returns. On a system with many entries, this can take some time
    so that in the meantime, other threads pass the tests in
    ip6_dst_gc() (ip6_rt_last_gc is still not updated) and wait for
    the lock. They then have to run the garbage collector one after
    another which blocks them for quite long.
    
    Resolve this by replacing special value ~0UL of expire parameter
    to fib6_run_gc() by explicit "force" parameter to choose between
    spin_lock_bh() and spin_trylock_bh() and call fib6_run_gc() with
    force=false if gc_thresh is reached but not max_size.
    
    Signed-off-by: Michal Kubecek <mkubecek@suse.cz>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 02f52975eb0858eb03ca091f644c8eb171895f92
Author: Helge Deller <deller@gmx.de>
Date:   Fri May 24 21:27:35 2013 +0000

    parisc: fix irq stack on UP and SMP
    
    commit d96b51ec14650b490ab98e738bcc02309396e5bc upstream.
    
    The logic to detect if the irq stack was already in use with
    raw_spin_trylock() is wrong, because it will generate a "trylock failure
    on UP" error message with CONFIG_SMP=n and CONFIG_DEBUG_SPINLOCK=y.
    
    arch_spin_trylock() can't be used either since in the CONFIG_SMP=n case
    no atomic protection is given and we are reentrant here. A mutex didn't
    worked either and brings more overhead by turning off interrupts.
    
    So, let's use the fastest path for parisc which is the ldcw instruction.
    
    Counting how often the irq stack was used is pretty useless, so just
    drop this piece of code.
    
    Signed-off-by: Helge Deller <deller@gmx.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d96b51ec14650b490ab98e738bcc02309396e5bc
Author: Helge Deller <deller@gmx.de>
Date:   Fri May 24 21:27:35 2013 +0000

    parisc: fix irq stack on UP and SMP
    
    The logic to detect if the irq stack was already in use with
    raw_spin_trylock() is wrong, because it will generate a "trylock failure
    on UP" error message with CONFIG_SMP=n and CONFIG_DEBUG_SPINLOCK=y.
    
    arch_spin_trylock() can't be used either since in the CONFIG_SMP=n case
    no atomic protection is given and we are reentrant here. A mutex didn't
    worked either and brings more overhead by turning off interrupts.
    
    So, let's use the fastest path for parisc which is the ldcw instruction.
    
    Counting how often the irq stack was used is pretty useless, so just
    drop this piece of code.
    
    Signed-off-by: Helge Deller <deller@gmx.de>

commit abfcdd7ef364708e54276e97041fe4dc1dd8dc12
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue Apr 16 14:08:50 2013 -0400

    xen/smp/spinlock: Fix leakage of the spinlock interrupt line for every CPU online/offline
    
    commit 66ff0fe9e7bda8aec99985b24daad03652f7304e upstream.
    
    While we don't use the spinlock interrupt line (see for details
    commit f10cd522c5fbfec9ae3cc01967868c9c2401ed23 -
    xen: disable PV spinlocks on HVM) - we should still do the proper
    init / deinit sequence. We did not do that correctly and for the
    CPU init for PVHVM guest we would allocate an interrupt line - but
    failed to deallocate the old interrupt line.
    
    This resulted in leakage of an irq_desc but more importantly this splat
    as we online an offlined CPU:
    
    genirq: Flags mismatch irq 71. 0002cc20 (spinlock1) vs. 0002cc20 (spinlock1)
    Pid: 2542, comm: init.late Not tainted 3.9.0-rc6upstream #1
    Call Trace:
     [<ffffffff811156de>] __setup_irq+0x23e/0x4a0
     [<ffffffff81194191>] ? kmem_cache_alloc_trace+0x221/0x250
     [<ffffffff811161bb>] request_threaded_irq+0xfb/0x160
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff813a8423>] bind_ipi_to_irqhandler+0xa3/0x160
     [<ffffffff81303758>] ? kasprintf+0x38/0x40
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff810cad35>] ? update_max_interval+0x15/0x40
     [<ffffffff816605db>] xen_init_lock_cpu+0x3c/0x78
     [<ffffffff81660029>] xen_hvm_cpu_notify+0x29/0x33
     [<ffffffff81676bdd>] notifier_call_chain+0x4d/0x70
     [<ffffffff810bb2a9>] __raw_notifier_call_chain+0x9/0x10
     [<ffffffff8109402b>] __cpu_notify+0x1b/0x30
     [<ffffffff8166834a>] _cpu_up+0xa0/0x14b
     [<ffffffff816684ce>] cpu_up+0xd9/0xec
     [<ffffffff8165f754>] store_online+0x94/0xd0
     [<ffffffff8141d15b>] dev_attr_store+0x1b/0x20
     [<ffffffff81218f44>] sysfs_write_file+0xf4/0x170
     [<ffffffff811a2864>] vfs_write+0xb4/0x130
     [<ffffffff811a302a>] sys_write+0x5a/0xa0
     [<ffffffff8167ada9>] system_call_fastpath+0x16/0x1b
    cpu 1 spinlock event irq -16
    smpboot: Booting Node 0 Processor 1 APIC 0x2
    
    And if one looks at the /proc/interrupts right after
    offlining (CPU1):
    
      70:          0          0  xen-percpu-ipi       spinlock0
      71:          0          0  xen-percpu-ipi       spinlock1
      77:          0          0  xen-percpu-ipi       spinlock2
    
    There is the oddity of the 'spinlock1' still being present.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    [bwh: Backported to 3.2: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit dab8388184da849e3fa51eafbcd4ddf85910bd2c
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue Apr 16 14:08:50 2013 -0400

    xen/smp/spinlock: Fix leakage of the spinlock interrupt line for every CPU online/offline
    
    commit 66ff0fe9e7bda8aec99985b24daad03652f7304e upstream.
    
    While we don't use the spinlock interrupt line (see for details
    commit f10cd522c5fbfec9ae3cc01967868c9c2401ed23 -
    xen: disable PV spinlocks on HVM) - we should still do the proper
    init / deinit sequence. We did not do that correctly and for the
    CPU init for PVHVM guest we would allocate an interrupt line - but
    failed to deallocate the old interrupt line.
    
    This resulted in leakage of an irq_desc but more importantly this splat
    as we online an offlined CPU:
    
    genirq: Flags mismatch irq 71. 0002cc20 (spinlock1) vs. 0002cc20 (spinlock1)
    Pid: 2542, comm: init.late Not tainted 3.9.0-rc6upstream #1
    Call Trace:
     [<ffffffff811156de>] __setup_irq+0x23e/0x4a0
     [<ffffffff81194191>] ? kmem_cache_alloc_trace+0x221/0x250
     [<ffffffff811161bb>] request_threaded_irq+0xfb/0x160
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff813a8423>] bind_ipi_to_irqhandler+0xa3/0x160
     [<ffffffff81303758>] ? kasprintf+0x38/0x40
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff810cad35>] ? update_max_interval+0x15/0x40
     [<ffffffff816605db>] xen_init_lock_cpu+0x3c/0x78
     [<ffffffff81660029>] xen_hvm_cpu_notify+0x29/0x33
     [<ffffffff81676bdd>] notifier_call_chain+0x4d/0x70
     [<ffffffff810bb2a9>] __raw_notifier_call_chain+0x9/0x10
     [<ffffffff8109402b>] __cpu_notify+0x1b/0x30
     [<ffffffff8166834a>] _cpu_up+0xa0/0x14b
     [<ffffffff816684ce>] cpu_up+0xd9/0xec
     [<ffffffff8165f754>] store_online+0x94/0xd0
     [<ffffffff8141d15b>] dev_attr_store+0x1b/0x20
     [<ffffffff81218f44>] sysfs_write_file+0xf4/0x170
     [<ffffffff811a2864>] vfs_write+0xb4/0x130
     [<ffffffff811a302a>] sys_write+0x5a/0xa0
     [<ffffffff8167ada9>] system_call_fastpath+0x16/0x1b
    cpu 1 spinlock event irq -16
    smpboot: Booting Node 0 Processor 1 APIC 0x2
    
    And if one looks at the /proc/interrupts right after
    offlining (CPU1):
    
      70:          0          0  xen-percpu-ipi       spinlock0
      71:          0          0  xen-percpu-ipi       spinlock1
      77:          0          0  xen-percpu-ipi       spinlock2
    
    There is the oddity of the 'spinlock1' still being present.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7ede7ac52827b403b4a878011f71a354eb7e8de2
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue Apr 16 14:08:50 2013 -0400

    xen/smp/spinlock: Fix leakage of the spinlock interrupt line for every CPU online/offline
    
    commit 66ff0fe9e7bda8aec99985b24daad03652f7304e upstream.
    
    While we don't use the spinlock interrupt line (see for details
    commit f10cd522c5fbfec9ae3cc01967868c9c2401ed23 -
    xen: disable PV spinlocks on HVM) - we should still do the proper
    init / deinit sequence. We did not do that correctly and for the
    CPU init for PVHVM guest we would allocate an interrupt line - but
    failed to deallocate the old interrupt line.
    
    This resulted in leakage of an irq_desc but more importantly this splat
    as we online an offlined CPU:
    
    genirq: Flags mismatch irq 71. 0002cc20 (spinlock1) vs. 0002cc20 (spinlock1)
    Pid: 2542, comm: init.late Not tainted 3.9.0-rc6upstream #1
    Call Trace:
     [<ffffffff811156de>] __setup_irq+0x23e/0x4a0
     [<ffffffff81194191>] ? kmem_cache_alloc_trace+0x221/0x250
     [<ffffffff811161bb>] request_threaded_irq+0xfb/0x160
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff813a8423>] bind_ipi_to_irqhandler+0xa3/0x160
     [<ffffffff81303758>] ? kasprintf+0x38/0x40
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff810cad35>] ? update_max_interval+0x15/0x40
     [<ffffffff816605db>] xen_init_lock_cpu+0x3c/0x78
     [<ffffffff81660029>] xen_hvm_cpu_notify+0x29/0x33
     [<ffffffff81676bdd>] notifier_call_chain+0x4d/0x70
     [<ffffffff810bb2a9>] __raw_notifier_call_chain+0x9/0x10
     [<ffffffff8109402b>] __cpu_notify+0x1b/0x30
     [<ffffffff8166834a>] _cpu_up+0xa0/0x14b
     [<ffffffff816684ce>] cpu_up+0xd9/0xec
     [<ffffffff8165f754>] store_online+0x94/0xd0
     [<ffffffff8141d15b>] dev_attr_store+0x1b/0x20
     [<ffffffff81218f44>] sysfs_write_file+0xf4/0x170
     [<ffffffff811a2864>] vfs_write+0xb4/0x130
     [<ffffffff811a302a>] sys_write+0x5a/0xa0
     [<ffffffff8167ada9>] system_call_fastpath+0x16/0x1b
    cpu 1 spinlock event irq -16
    smpboot: Booting Node 0 Processor 1 APIC 0x2
    
    And if one looks at the /proc/interrupts right after
    offlining (CPU1):
    
      70:          0          0  xen-percpu-ipi       spinlock0
      71:          0          0  xen-percpu-ipi       spinlock1
      77:          0          0  xen-percpu-ipi       spinlock2
    
    There is the oddity of the 'spinlock1' still being present.
    
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 66ff0fe9e7bda8aec99985b24daad03652f7304e
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Tue Apr 16 14:08:50 2013 -0400

    xen/smp/spinlock: Fix leakage of the spinlock interrupt line for every CPU online/offline
    
    While we don't use the spinlock interrupt line (see for details
    commit f10cd522c5fbfec9ae3cc01967868c9c2401ed23 -
    xen: disable PV spinlocks on HVM) - we should still do the proper
    init / deinit sequence. We did not do that correctly and for the
    CPU init for PVHVM guest we would allocate an interrupt line - but
    failed to deallocate the old interrupt line.
    
    This resulted in leakage of an irq_desc but more importantly this splat
    as we online an offlined CPU:
    
    genirq: Flags mismatch irq 71. 0002cc20 (spinlock1) vs. 0002cc20 (spinlock1)
    Pid: 2542, comm: init.late Not tainted 3.9.0-rc6upstream #1
    Call Trace:
     [<ffffffff811156de>] __setup_irq+0x23e/0x4a0
     [<ffffffff81194191>] ? kmem_cache_alloc_trace+0x221/0x250
     [<ffffffff811161bb>] request_threaded_irq+0xfb/0x160
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff813a8423>] bind_ipi_to_irqhandler+0xa3/0x160
     [<ffffffff81303758>] ? kasprintf+0x38/0x40
     [<ffffffff8104c6f0>] ? xen_spin_trylock+0x20/0x20
     [<ffffffff810cad35>] ? update_max_interval+0x15/0x40
     [<ffffffff816605db>] xen_init_lock_cpu+0x3c/0x78
     [<ffffffff81660029>] xen_hvm_cpu_notify+0x29/0x33
     [<ffffffff81676bdd>] notifier_call_chain+0x4d/0x70
     [<ffffffff810bb2a9>] __raw_notifier_call_chain+0x9/0x10
     [<ffffffff8109402b>] __cpu_notify+0x1b/0x30
     [<ffffffff8166834a>] _cpu_up+0xa0/0x14b
     [<ffffffff816684ce>] cpu_up+0xd9/0xec
     [<ffffffff8165f754>] store_online+0x94/0xd0
     [<ffffffff8141d15b>] dev_attr_store+0x1b/0x20
     [<ffffffff81218f44>] sysfs_write_file+0xf4/0x170
     [<ffffffff811a2864>] vfs_write+0xb4/0x130
     [<ffffffff811a302a>] sys_write+0x5a/0xa0
     [<ffffffff8167ada9>] system_call_fastpath+0x16/0x1b
    cpu 1 spinlock event irq -16
    smpboot: Booting Node 0 Processor 1 APIC 0x2
    
    And if one looks at the /proc/interrupts right after
    offlining (CPU1):
    
      70:          0          0  xen-percpu-ipi       spinlock0
      71:          0          0  xen-percpu-ipi       spinlock1
      77:          0          0  xen-percpu-ipi       spinlock2
    
    There is the oddity of the 'spinlock1' still being present.
    
    CC: stable@vger.kernel.org
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>

commit 019c74a99a5278cbeea999779f998a326d1d40c7
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Fri Jan 11 18:09:41 2013 +0000

    pstore: Avoid deadlock in panic and emergency-restart path
    
    commit 9f244e9cfd70c7c0f82d3c92ce772ab2a92d9f64 upstream.
    
    [Issue]
    
    When pstore is in panic and emergency-restart paths, it may be blocked
    in those paths because it simply takes spin_lock.
    
    This is an example scenario which pstore may hang up in a panic path:
    
     - cpuA grabs psinfo->buf_lock
     - cpuB panics and calls smp_send_stop
     - smp_send_stop sends IRQ to cpuA
     - after 1 second, cpuB gives up on cpuA and sends an NMI instead
     - cpuA is now in an NMI handler while still holding buf_lock
     - cpuB is deadlocked
    
    This case may happen if a firmware has a bug and
    cpuA is stuck talking with it more than one second.
    
    Also, this is a similar scenario in an emergency-restart path:
    
     - cpuA grabs psinfo->buf_lock and stucks in a firmware
     - cpuB kicks emergency-restart via either sysrq-b or hangcheck timer.
       And then, cpuB is deadlocked by taking psinfo->buf_lock again.
    
    [Solution]
    
    This patch avoids the deadlocking issues in both panic and emergency_restart
    paths by introducing a function, is_non_blocking_path(), to check if a cpu
    can be blocked in current path.
    
    With this patch, pstore is not blocked even if another cpu has
    taken a spin_lock, in those paths by changing from spin_lock_irqsave
    to spin_trylock_irqsave.
    
    In addition, according to a comment of emergency_restart() in kernel/sys.c,
    spin_lock shouldn't be taken in an emergency_restart path to avoid
    deadlock. This patch fits the comment below.
    
    <snip>
    /**
     *      emergency_restart - reboot the system
     *
     *      Without shutting down any hardware or taking any locks
     *      reboot the system.  This is called when we know we are in
     *      trouble so this is our best effort to reboot.  This is
     *      safe to call in interrupt context.
     */
    void emergency_restart(void)
    <snip>
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    [bwh: Backported to 3.2:
     - Adjust context
     - Add #include <linux/kmsg_dump.h>]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>

commit 68412b1718c488e58783d1c576d0aeb34012092d
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Fri Jan 11 18:09:41 2013 +0000

    pstore: Avoid deadlock in panic and emergency-restart path
    
    commit 9f244e9cfd70c7c0f82d3c92ce772ab2a92d9f64 upstream.
    
    [Issue]
    
    When pstore is in panic and emergency-restart paths, it may be blocked
    in those paths because it simply takes spin_lock.
    
    This is an example scenario which pstore may hang up in a panic path:
    
     - cpuA grabs psinfo->buf_lock
     - cpuB panics and calls smp_send_stop
     - smp_send_stop sends IRQ to cpuA
     - after 1 second, cpuB gives up on cpuA and sends an NMI instead
     - cpuA is now in an NMI handler while still holding buf_lock
     - cpuB is deadlocked
    
    This case may happen if a firmware has a bug and
    cpuA is stuck talking with it more than one second.
    
    Also, this is a similar scenario in an emergency-restart path:
    
     - cpuA grabs psinfo->buf_lock and stucks in a firmware
     - cpuB kicks emergency-restart via either sysrq-b or hangcheck timer.
       And then, cpuB is deadlocked by taking psinfo->buf_lock again.
    
    [Solution]
    
    This patch avoids the deadlocking issues in both panic and emergency_restart
    paths by introducing a function, is_non_blocking_path(), to check if a cpu
    can be blocked in current path.
    
    With this patch, pstore is not blocked even if another cpu has
    taken a spin_lock, in those paths by changing from spin_lock_irqsave
    to spin_trylock_irqsave.
    
    In addition, according to a comment of emergency_restart() in kernel/sys.c,
    spin_lock shouldn't be taken in an emergency_restart path to avoid
    deadlock. This patch fits the comment below.
    
    <snip>
    /**
     *      emergency_restart - reboot the system
     *
     *      Without shutting down any hardware or taking any locks
     *      reboot the system.  This is called when we know we are in
     *      trouble so this is our best effort to reboot.  This is
     *      safe to call in interrupt context.
     */
    void emergency_restart(void)
    <snip>
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Cc: CAI Qian <caiqian@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 225234a28f6f7655ae3ed5bfbba536d0468209bd
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Fri Jan 11 18:09:41 2013 +0000

    pstore: Avoid deadlock in panic and emergency-restart path
    
    commit 9f244e9cfd70c7c0f82d3c92ce772ab2a92d9f64 upstream.
    
    [Issue]
    
    When pstore is in panic and emergency-restart paths, it may be blocked
    in those paths because it simply takes spin_lock.
    
    This is an example scenario which pstore may hang up in a panic path:
    
     - cpuA grabs psinfo->buf_lock
     - cpuB panics and calls smp_send_stop
     - smp_send_stop sends IRQ to cpuA
     - after 1 second, cpuB gives up on cpuA and sends an NMI instead
     - cpuA is now in an NMI handler while still holding buf_lock
     - cpuB is deadlocked
    
    This case may happen if a firmware has a bug and
    cpuA is stuck talking with it more than one second.
    
    Also, this is a similar scenario in an emergency-restart path:
    
     - cpuA grabs psinfo->buf_lock and stucks in a firmware
     - cpuB kicks emergency-restart via either sysrq-b or hangcheck timer.
       And then, cpuB is deadlocked by taking psinfo->buf_lock again.
    
    [Solution]
    
    This patch avoids the deadlocking issues in both panic and emergency_restart
    paths by introducing a function, is_non_blocking_path(), to check if a cpu
    can be blocked in current path.
    
    With this patch, pstore is not blocked even if another cpu has
    taken a spin_lock, in those paths by changing from spin_lock_irqsave
    to spin_trylock_irqsave.
    
    In addition, according to a comment of emergency_restart() in kernel/sys.c,
    spin_lock shouldn't be taken in an emergency_restart path to avoid
    deadlock. This patch fits the comment below.
    
    <snip>
    /**
     *      emergency_restart - reboot the system
     *
     *      Without shutting down any hardware or taking any locks
     *      reboot the system.  This is called when we know we are in
     *      trouble so this is our best effort to reboot.  This is
     *      safe to call in interrupt context.
     */
    void emergency_restart(void)
    <snip>
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>
    Cc: CAI Qian <caiqian@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e93a85ac6120ec0b3b53add0a5409f84aad135d8
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 14 21:01:06 2013 +0100

    serial: imx: Fix recursive locking bug
    
    commit 677fe555cbfb188af58cce105f4dae9505e58c31 upstream.
    
    commit 9ec1882df2 (tty: serial: imx: console write routing is unsafe
    on SMP) introduced a recursive locking bug in imx_console_write().
    
    The callchain is:
    
    imx_rxint()
      spin_lock_irqsave(&sport->port.lock,flags);
      ...
      uart_handle_sysrq_char();
        sysrq_function();
          printk();
            imx_console_write();
              spin_lock_irqsave(&sport->port.lock,flags); <--- DEAD
    
    The bad news is that the kernel debugging facilities can dectect the
    problem, but the printks never surface on the serial console for
    obvious reasons.
    
    There is a similar issue with oops_in_progress. If the kernel crashes
    we really don't want to be stuck on the lock and unable to tell what
    happened.
    
    In general most UP originated drivers miss these checks and nobody
    ever notices because CONFIG_PROVE_LOCKING seems to be still ignored by
    a large number of developers.
    
    The solution is to avoid locking in the sysrq case and trylock in the
    oops_in_progress case.
    
    This scheme is used in other drivers as well and it would be nice if
    we could move this to a common place, so the usual copy/paste/modify
    bugs can be avoided.
    
    Now there is another issue with this scheme:
    
    CPU0                     CPU1
    printk()
                             rxint()
                               sysrq_detection() -> sets port->sysrq
                             return from interrupt
      console_write()
         if (port->sysrq)
            avoid locking
    
    port->sysrq is reset with the next receive character. So as long as
    the port->sysrq is not reset and this can take an endless amount of
    time if after the break no futher receive character follows, all
    console writes happen unlocked.
    
    While the current writer is protected against other console writers by
    the console sem, it's unprotected against open/close or other
    operations which fiddle with the port. That's what the above mentioned
    commit tried to solve.
    
    That's an issue in all drivers which use that scheme and unfortunately
    there is no easy workaround. The only solution is to have a separate
    indicator port->sysrq_cpu. uart_handle_sysrq_char() then sets it to
    smp_processor_id() before calling into handle_sysrq() and resets it to
    -1 after that. Then change the locking check to:
    
         if (port->sysrq_cpu == smp_processor_id())
             locked = 0;
         else if (oops_in_progress)
             locked = spin_trylock_irqsave(port->lock, flags);
         else
             spin_lock_irqsave(port->lock, flags);
    
    That would force all other cpus into the spin_lock path. Problem
    solved, but that's way beyond the scope of this fix and really wants
    to be implemented in a common function which calls the uart specific
    write function to avoid another gazillion of hard to debug
    copy/paste/modify bugs.
    
    Reported-and-tested-by: Tim Sander <tim@krieglstein.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cf9b490b5f6137023d01cf284b3fbe2a5bf5190a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 14 21:01:06 2013 +0100

    serial: imx: Fix recursive locking bug
    
    commit 677fe555cbfb188af58cce105f4dae9505e58c31 upstream.
    
    commit 9ec1882df2 (tty: serial: imx: console write routing is unsafe
    on SMP) introduced a recursive locking bug in imx_console_write().
    
    The callchain is:
    
    imx_rxint()
      spin_lock_irqsave(&sport->port.lock,flags);
      ...
      uart_handle_sysrq_char();
        sysrq_function();
          printk();
            imx_console_write();
              spin_lock_irqsave(&sport->port.lock,flags); <--- DEAD
    
    The bad news is that the kernel debugging facilities can dectect the
    problem, but the printks never surface on the serial console for
    obvious reasons.
    
    There is a similar issue with oops_in_progress. If the kernel crashes
    we really don't want to be stuck on the lock and unable to tell what
    happened.
    
    In general most UP originated drivers miss these checks and nobody
    ever notices because CONFIG_PROVE_LOCKING seems to be still ignored by
    a large number of developers.
    
    The solution is to avoid locking in the sysrq case and trylock in the
    oops_in_progress case.
    
    This scheme is used in other drivers as well and it would be nice if
    we could move this to a common place, so the usual copy/paste/modify
    bugs can be avoided.
    
    Now there is another issue with this scheme:
    
    CPU0                     CPU1
    printk()
                             rxint()
                               sysrq_detection() -> sets port->sysrq
                             return from interrupt
      console_write()
         if (port->sysrq)
            avoid locking
    
    port->sysrq is reset with the next receive character. So as long as
    the port->sysrq is not reset and this can take an endless amount of
    time if after the break no futher receive character follows, all
    console writes happen unlocked.
    
    While the current writer is protected against other console writers by
    the console sem, it's unprotected against open/close or other
    operations which fiddle with the port. That's what the above mentioned
    commit tried to solve.
    
    That's an issue in all drivers which use that scheme and unfortunately
    there is no easy workaround. The only solution is to have a separate
    indicator port->sysrq_cpu. uart_handle_sysrq_char() then sets it to
    smp_processor_id() before calling into handle_sysrq() and resets it to
    -1 after that. Then change the locking check to:
    
         if (port->sysrq_cpu == smp_processor_id())
             locked = 0;
         else if (oops_in_progress)
             locked = spin_trylock_irqsave(port->lock, flags);
         else
             spin_lock_irqsave(port->lock, flags);
    
    That would force all other cpus into the spin_lock path. Problem
    solved, but that's way beyond the scope of this fix and really wants
    to be implemented in a common function which calls the uart specific
    write function to avoid another gazillion of hard to debug
    copy/paste/modify bugs.
    
    Reported-and-tested-by: Tim Sander <tim@krieglstein.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 677fe555cbfb188af58cce105f4dae9505e58c31
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Thu Feb 14 21:01:06 2013 +0100

    serial: imx: Fix recursive locking bug
    
    commit 9ec1882df2 (tty: serial: imx: console write routing is unsafe
    on SMP) introduced a recursive locking bug in imx_console_write().
    
    The callchain is:
    
    imx_rxint()
      spin_lock_irqsave(&sport->port.lock,flags);
      ...
      uart_handle_sysrq_char();
        sysrq_function();
          printk();
            imx_console_write();
              spin_lock_irqsave(&sport->port.lock,flags); <--- DEAD
    
    The bad news is that the kernel debugging facilities can dectect the
    problem, but the printks never surface on the serial console for
    obvious reasons.
    
    There is a similar issue with oops_in_progress. If the kernel crashes
    we really don't want to be stuck on the lock and unable to tell what
    happened.
    
    In general most UP originated drivers miss these checks and nobody
    ever notices because CONFIG_PROVE_LOCKING seems to be still ignored by
    a large number of developers.
    
    The solution is to avoid locking in the sysrq case and trylock in the
    oops_in_progress case.
    
    This scheme is used in other drivers as well and it would be nice if
    we could move this to a common place, so the usual copy/paste/modify
    bugs can be avoided.
    
    Now there is another issue with this scheme:
    
    CPU0                     CPU1
    printk()
                             rxint()
                               sysrq_detection() -> sets port->sysrq
                             return from interrupt
      console_write()
         if (port->sysrq)
            avoid locking
    
    port->sysrq is reset with the next receive character. So as long as
    the port->sysrq is not reset and this can take an endless amount of
    time if after the break no futher receive character follows, all
    console writes happen unlocked.
    
    While the current writer is protected against other console writers by
    the console sem, it's unprotected against open/close or other
    operations which fiddle with the port. That's what the above mentioned
    commit tried to solve.
    
    That's an issue in all drivers which use that scheme and unfortunately
    there is no easy workaround. The only solution is to have a separate
    indicator port->sysrq_cpu. uart_handle_sysrq_char() then sets it to
    smp_processor_id() before calling into handle_sysrq() and resets it to
    -1 after that. Then change the locking check to:
    
         if (port->sysrq_cpu == smp_processor_id())
             locked = 0;
         else if (oops_in_progress)
             locked = spin_trylock_irqsave(port->lock, flags);
         else
             spin_lock_irqsave(port->lock, flags);
    
    That would force all other cpus into the spin_lock path. Problem
    solved, but that's way beyond the scope of this fix and really wants
    to be implemented in a common function which calls the uart specific
    write function to avoid another gazillion of hard to debug
    copy/paste/modify bugs.
    
    Reported-and-tested-by: Tim Sander <tim@krieglstein.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Cc: stable <stable@vger.kernel.org>  # 3.6+
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e59310adf5eebce108f78b6c47bb330aae2e1666
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Fri Jan 11 18:10:05 2013 +0000

    efi_pstore: Avoid deadlock in non-blocking paths
    
    [Issue]
    
    There is a scenario which efi_pstore may hang up:
    
     - cpuA grabs efivars->lock
     - cpuB panics and calls smp_send_stop
     - smp_send_stop sends IRQ to cpuA
     - after 1 second, cpuB gives up on cpuA and sends an NMI instead
     - cpuA is now in an NMI handler while still holding efivars->lock
     - cpuB is deadlocked
    
    This case may happen if a firmware has a bug and
    cpuA is stuck talking with it.
    
    [Solution]
    
    This patch changes a spin_lock to a spin_trylock in non-blocking paths.
    and if the spin_lock has already taken by another cpu,
    it returns without accessing to a firmware to avoid the deadlock.
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

commit 9f244e9cfd70c7c0f82d3c92ce772ab2a92d9f64
Author: Seiji Aguchi <seiji.aguchi@hds.com>
Date:   Fri Jan 11 18:09:41 2013 +0000

    pstore: Avoid deadlock in panic and emergency-restart path
    
    [Issue]
    
    When pstore is in panic and emergency-restart paths, it may be blocked
    in those paths because it simply takes spin_lock.
    
    This is an example scenario which pstore may hang up in a panic path:
    
     - cpuA grabs psinfo->buf_lock
     - cpuB panics and calls smp_send_stop
     - smp_send_stop sends IRQ to cpuA
     - after 1 second, cpuB gives up on cpuA and sends an NMI instead
     - cpuA is now in an NMI handler while still holding buf_lock
     - cpuB is deadlocked
    
    This case may happen if a firmware has a bug and
    cpuA is stuck talking with it more than one second.
    
    Also, this is a similar scenario in an emergency-restart path:
    
     - cpuA grabs psinfo->buf_lock and stucks in a firmware
     - cpuB kicks emergency-restart via either sysrq-b or hangcheck timer.
       And then, cpuB is deadlocked by taking psinfo->buf_lock again.
    
    [Solution]
    
    This patch avoids the deadlocking issues in both panic and emergency_restart
    paths by introducing a function, is_non_blocking_path(), to check if a cpu
    can be blocked in current path.
    
    With this patch, pstore is not blocked even if another cpu has
    taken a spin_lock, in those paths by changing from spin_lock_irqsave
    to spin_trylock_irqsave.
    
    In addition, according to a comment of emergency_restart() in kernel/sys.c,
    spin_lock shouldn't be taken in an emergency_restart path to avoid
    deadlock. This patch fits the comment below.
    
    <snip>
    /**
     *      emergency_restart - reboot the system
     *
     *      Without shutting down any hardware or taking any locks
     *      reboot the system.  This is called when we know we are in
     *      trouble so this is our best effort to reboot.  This is
     *      safe to call in interrupt context.
     */
    void emergency_restart(void)
    <snip>
    
    Signed-off-by: Seiji Aguchi <seiji.aguchi@hds.com>
    Acked-by: Don Zickus <dzickus@redhat.com>
    Signed-off-by: Tony Luck <tony.luck@intel.com>

commit de2070fc4aa7c0205348010f500f5abce012e67b
Author: Mohammed Shafi Shajakhan <mohammed@qca.qualcomm.com>
Date:   Fri Nov 16 18:22:40 2012 +0530

    ath6kl: Fix kernel panic on continuous driver load/unload
    
    On continuous loading and unloading of AR6004 ath6kl USB
    driver it triggers a panic due to NULL pointer dereference of
    'target' pointer.
    
    while true; do sudo modprobe -v ath6kl_core;
    sudo modprobe -v ath6kl_usb; sudo modprobe -r usb;
    sudo modprobe -r ath6kl_core; done
    
    ar->htc_target can be NULL due to a race condition that can occur
    during driver initialization(we do 'ath6kl_hif_power_on' before
    initializing 'ar->htc_target' via 'ath6kl_htc_create').
    'ath6kl_hif_power_on' assigns 'ath6kl_recv_complete' as
    usb_complete_t/callback function for 'usb_fill_bulk_urb'.
    Thus the possibility of ar->htc_target being NULL
    via ath6kl_recv_complete -> ath6kl_usb_io_comp_work
    before even 'ath6kl_htc_create' is finished to initialize
    ar->htc_create.
    
    Worth noting is the obvious solution  of doing 'ath6kl_hif_power_on'
    later(i.e after we are done with 'ath6kl_htc_create', causes a
    h/w bring up failure in AR6003 SDIO, as 'ath6kl_hif_power_on' is a
    pre-requisite to get the target version 'ath6kl_bmi_get_target_info'.
    So simply check for NULL pointer for 'ar->htc_target' and bail out.
    
    [23614.518282] BUG: unable to handle kernel NULL pointer dereference at
    00000904
    [23614.518463] IP: [<c012e7a6>] __ticket_spin_trylock+0x6/0x30
    [23614.518570] *pde = 00000000
    [23614.518664] Oops: 0000 [#1] SMP
    [23614.518795] Modules linked in: ath6kl_usb(O+) ath6kl_core(O)
    [23614.520012] EIP: 0060:[<c012e7a6>] EFLAGS: 00010286 CPU: 0
    [23614.520012] EIP is at __ticket_spin_trylock+0x6/0x30
    Call Trace:
            [<c03f2a44>] do_raw_spin_trylock+0x14/0x40
            [<c06daa12>] _raw_spin_lock_bh+0x52/0x80
            [<f85464b4>] ? ath6kl_htc_pipe_rx_complete+0x3b4/0x4c0 [ath6kl_core]
            [<f85464b4>] ath6kl_htc_pipe_rx_complete+0x3b4/0x4c0 [ath6kl_core]
            [<c05bc272>] ? skb_dequeue+0x22/0x70
            [<c05bc272>] ? skb_dequeue+0x22/0x70
            [<f855bb32>] ath6kl_core_rx_complete+0x12/0x20 [ath6kl_core]
            [<f848771a>] ath6kl_usb_io_comp_work+0xaa/0xb0 [ath6kl_usb]
            [<c015b863>] process_one_work+0x1a3/0x5e0
            [<c015b7e7>] ? process_one_work+0x127/0x5e0
            [<f8487670>] ? ath6kl_usb_reset_resume+0x30/0x30 [ath6kl_usb]
            [<c015bfde>] worker_thread+0x11e/0x3f0
            Kernel panic - not syncing: Fatal exception in interrupt
    
    Signed-off-by: Mohammed Shafi Shajakhan <mohammed@qca.qualcomm.com>
    Signed-off-by: Kalle Valo <kvalo@qca.qualcomm.com>

commit 214f766ea0909e743122966c4617b3a112e405d7
Author: Vikram Mulukutla <markivx@codeaurora.org>
Date:   Thu Oct 4 17:13:22 2012 -0700

    lib/spinlock_debug: avoid livelock in do_raw_spin_lock()
    
    The logic in do_raw_spin_lock() attempts to acquire a spinlock by invoking
    arch_spin_trylock() in a loop with a delay between each attempt.  Now
    consider the following situation in a 2 CPU system:
    
    1. CPU-0 continually acquires and releases a spinlock in a
       tight loop; it stays in this loop until some condition X
       is satisfied. X can only be satisfied by another CPU.
    
    2. CPU-1 tries to acquire the same spinlock, in an attempt
       to satisfy the aforementioned condition X. However, it
       never sees the unlocked value of the lock because the
       debug spinlock code uses trylock instead of just lock;
       it checks at all the wrong moments - whenever CPU-0 has
       locked the lock.
    
    Now in the absence of debug spinlocks, the architecture specific spinlock
    code can correctly allow CPU-1 to wait in a "queue" (e.g., ticket
    spinlocks), ensuring that it acquires the lock at some point.  However,
    with the debug spinlock code, livelock can easily occur due to the use of
    try_lock, which obviously cannot put the CPU in that "queue".  This
    queueing mechanism is implemented in both x86 and ARM spinlock code.
    
    Note that the situation mentioned above is not hypothetical.  A real
    problem was encountered where CPU-0 was running hrtimer_cancel with
    interrupts disabled, and CPU-1 was attempting to run the hrtimer that
    CPU-0 was trying to cancel.
    
    Address this by actually attempting arch_spin_lock once it is suspected
    that there is a spinlock lockup.  If we're in a situation that is
    described above, the arch_spin_lock should succeed; otherwise other
    timeout mechanisms (e.g., watchdog) should alert the system of a lockup.
    Therefore, if there is a genuine system problem and the spinlock can't be
    acquired, the end result (irrespective of this change being present) is
    the same.  If there is a livelock caused by the debug code, this change
    will allow the lock to be acquired, depending on the implementation of the
    lower level arch specific spinlock code.
    
    [akpm@linux-foundation.org: tweak comment]
    Signed-off-by: Vikram Mulukutla <markivx@codeaurora.org>
    Cc: Thomas Gleixner <tglx@linutronix.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 80c9d03c22f13a17df67b4b99a83ed5e9acf6093
Author: Chuansheng Liu <chuansheng.liu@intel.com>
Date:   Tue Sep 18 01:43:44 2012 +0800

    pstore: Avoid recursive spinlocks in the oops_in_progress case
    
    Like 8250 driver, when pstore is registered as a console,
    to avoid recursive spinlocks when panic happening, change the
    spin_lock_irqsave to spin_trylock_irqsave when oops_in_progress
    is true.
    
    Signed-off-by: liu chuansheng <chuansheng.liu@intel.com>
    Signed-off-by: Anton Vorontsov <anton.vorontsov@linaro.org>

commit d4d2dbcaedb9334d0c462129099346d617f61768
Author: Fengguang Wu <fengguang.wu@intel.com>
Date:   Sun Sep 9 16:23:46 2012 +0800

    Staging: panel: fix spinlock trylock failure on UP
    
    Use spin_lock_irq() to quiet warning:
    
             [    8.232324] BUG: spinlock trylock failure on UP on CPU#0, reboot/85
             [    8.234138]  lock: c161c760, .magic: dead4ead, .owner: reboot/85, .owner_cpu: 0
             [    8.236132] Pid: 85, comm: reboot Not tainted 3.4.0-rc7-00656-g82163ed #5
             [    8.237965] Call Trace:
             [    8.238648]  [<c13dfd20>] ? printk+0x18/0x1a
             [    8.239827]  [<c122a5e0>] spin_dump+0x80/0xd0
             [    8.241016]  [<c122a652>] spin_bug+0x22/0x30
             [    8.242181]  [<c122a93b>] do_raw_spin_trylock+0x5b/0x70
             [    8.243611]  [<c13e8bae>] _raw_spin_trylock+0xe/0x60
             [    8.244975]  [<c1392230>] ? keypad_send_key.constprop.9+0xe0/0xe0
     ==>     [    8.246638]  [<c13922ea>] panel_scan_timer+0xba/0x570
             [    8.248019]  [<c1392230>] ? keypad_send_key.constprop.9+0xe0/0xe0
             [    8.249689]  [<c102f6f5>] run_timer_softirq+0x1e5/0x370
             [    8.251191]  [<c102f645>] ? run_timer_softirq+0x135/0x370
             [    8.252718]  [<c1392230>] ? keypad_send_key.constprop.9+0xe0/0xe0
             [    8.254462]  [<c102a592>] __do_softirq+0xc2/0x1c0
             [    8.255758]  [<c102a4d0>] ? local_bh_enable_ip+0x130/0x130
             [    8.257228]  <IRQ>  [<c102a855>] ? irq_exit+0x65/0x70
             [    8.258647]  [<c1013ff9>] ? smp_apic_timer_interrupt+0x49/0x80
             [    8.260226]  [<c13e96c1>] ? apic_timer_interrupt+0x31/0x38
             [    8.261737]  [<c12700e0>] ? drm_vm_open_locked+0x70/0xb0
             [    8.263166]  [<c122489a>] ? delay_tsc+0x1a/0x30
             [    8.264452]  [<c12248c9>] ? __delay+0x9/0x10
             [    8.265621]  [<c12248ec>] ? __const_udelay+0x1c/0x20
     ==>     [    8.266967]  [<c139136c>] ? lcd_clear_fast_p8+0x9c/0xe0
             [    8.268386]  [<c1391a66>] ? lcd_write+0x226/0x810
             [    8.269653]  [<c1367900>] ? md_set_readonly+0xc0/0xc0
             [    8.271013]  [<c122a9ed>] ? do_raw_spin_unlock+0x9d/0xe0
             [    8.272470]  [<c1392a98>] ? panel_lcd_print+0x38/0x40
             [    8.273837]  [<c1392ace>] ? panel_notify_sys+0x2e/0x60
             [    8.275224]  [<c1046634>] ? notifier_call_chain+0x84/0xb0
             [    8.276754]  [<c10469ce>] ? __blocking_notifier_call_chain+0x3e/0x60
             [    8.278576]  [<c1046a0a>] ? blocking_notifier_call_chain+0x1a/0x20
             [    8.280267]  [<c1036a14>] ? kernel_restart_prepare+0x14/0x40
             [    8.281901]  [<c1036a8e>] ? kernel_restart+0xe/0x50
             [    8.283216]  [<c1036ce9>] ? sys_reboot+0x149/0x1e0
             [    8.284532]  [<c10b3fb3>] ? handle_pte_fault+0x93/0xd70
             [    8.285956]  [<c1019e35>] ? do_page_fault+0x215/0x5e0
             [    8.287330]  [<c101a113>] ? do_page_fault+0x4f3/0x5e0
             [    8.288704]  [<c1045ac6>] ? up_read+0x16/0x30
             [    8.289890]  [<c101a113>] ? do_page_fault+0x4f3/0x5e0
             [    8.291252]  [<c10d4486>] ? iterate_supers+0x86/0xd0
             [    8.292615]  [<c122a9ed>] ? do_raw_spin_unlock+0x9d/0xe0
             [    8.294049]  [<c13e8dcd>] ? _raw_spin_unlock+0x1d/0x20
             [    8.295449]  [<c10d44ab>] ? iterate_supers+0xab/0xd0
             [    8.296795]  [<c10fb620>] ? __sync_filesystem+0xa0/0xa0
             [    8.298199]  [<c13e9b03>] ? sysenter_do_call+0x12/0x37
             [    8.306899] Restarting system.
             [    8.307747] machine restart
    
    Signed-off-by: Fengguang Wu <fengguang.wu@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a5567932fc926739e29e98487128080f40c61710
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Thu Mar 29 20:57:08 2012 +0200

    blkcg: change a spin_lock() to spin_lock_irq()
    
    Smatch complains that we re-enable IRQs twice.  It looks like we forgot
    to disable them here on the spin_trylock() failure path.  This was added
    in 9f13ef678e "blkcg: use double locking instead of RCU for blkg
    synchronization".
    
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>`
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 9fa73472ddbcd3da87d35a7f4566eaaf345f798e
Author: Shaohua Li <shaohua.li@intel.com>
Date:   Mon Feb 6 08:57:29 2012 +0100

    block: fix ioc locking warning
    
    Meelis reported a warning:
    
    WARNING: at kernel/timer.c:1122 run_timer_softirq+0x199/0x1ec()
    Hardware name: 939Dual-SATA2
    timer: cfq_idle_slice_timer+0x0/0xaa preempt leak: 00000102 -> 00000103
    Modules linked in: sr_mod cdrom videodev media drm_kms_helper ohci_hcd ehci_hcd v4l2_compat_ioctl32 usbcore i2c_ali15x3 snd_seq drm snd_timer snd_seq
    Pid: 0, comm: swapper Not tainted 3.3.0-rc2-00110-gd125666 #176
    Call Trace:
     <IRQ>  [<ffffffff81022aaa>] warn_slowpath_common+0x7e/0x96
     [<ffffffff8114c485>] ? cfq_slice_expired+0x1d/0x1d
     [<ffffffff81022b56>] warn_slowpath_fmt+0x41/0x43
     [<ffffffff8114c526>] ? cfq_idle_slice_timer+0xa1/0xaa
     [<ffffffff8114c485>] ? cfq_slice_expired+0x1d/0x1d
     [<ffffffff8102c124>] run_timer_softirq+0x199/0x1ec
     [<ffffffff81047a53>] ? timekeeping_get_ns+0x12/0x31
     [<ffffffff810145fd>] ? apic_write+0x11/0x13
     [<ffffffff81027475>] __do_softirq+0x74/0xfa
     [<ffffffff812f337a>] call_softirq+0x1a/0x30
     [<ffffffff81002ff9>] do_softirq+0x31/0x68
     [<ffffffff810276cf>] irq_exit+0x3d/0xa3
     [<ffffffff81014aca>] smp_apic_timer_interrupt+0x6b/0x77
     [<ffffffff812f2de9>] apic_timer_interrupt+0x69/0x70
     <EOI>  [<ffffffff81040136>] ? sched_clock_cpu+0x73/0x7d
     [<ffffffff81040136>] ? sched_clock_cpu+0x73/0x7d
     [<ffffffff8100801f>] ? default_idle+0x1e/0x32
     [<ffffffff81008019>] ? default_idle+0x18/0x32
     [<ffffffff810008b1>] cpu_idle+0x87/0xd1
     [<ffffffff812de861>] rest_init+0x85/0x89
     [<ffffffff81659a4d>] start_kernel+0x2eb/0x2f8
     [<ffffffff8165926e>] x86_64_start_reservations+0x7e/0x82
     [<ffffffff81659362>] x86_64_start_kernel+0xf0/0xf7
    
    this_q == locked_q is possible. There are two problems here:
    1. In UP case, there is preemption counter issue as spin_trylock always
    successes.
    2. In SMP case, the loop breaks too earlier.
    
    Signed-off-by: Shaohua Li <shaohua.li@intel.com>
    Reported-by: Meelis Roos <mroos@linux.ee>
    Reported-by: Knut Petersen <Knut_Petersen@t-online.de>
    Tested-by: Knut Petersen <Knut_Petersen@t-online.de>
    Signed-off-by: Jens Axboe <axboe@kernel.dk>

commit 1d58996da6a8045c8df2899ce5689a19c721322f
Author: Paul Gortmaker <paul.gortmaker@windriver.com>
Date:   Thu Sep 15 17:56:39 2011 -0400

    bluetooth: macroize two small inlines to avoid module.h
    
    These two small inlines make calls to try_module_get() and
    module_put() which would force us to keep module.h present
    within yet another common include header.  We can avoid this
    by turning them into macros.  The hci_dev_hold construct
    is patterned off of raw_spin_trylock_irqsave() in spinlock.h
    
    Signed-off-by: Paul Gortmaker <paul.gortmaker@windriver.com>

commit 5fd862f1db941c302a872ed7e67eab593a6a931a
Merge: 8e6d539e0fd0 695d16f78708
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Fri Oct 28 05:43:29 2011 -0700

    Merge branch 'x86-spinlocks-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip
    
    * 'x86-spinlocks-for-linus' of git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip:
      x86, ticketlock: remove obsolete comment
      x86, cmpxchg: Use __compiletime_error() to make usage messages a bit nicer
      x86, ticketlock: Make __ticket_spin_trylock common
      x86, ticketlock: Convert __ticket_spin_lock to use xadd()
      x86, ticketlock: Convert spin loop to C
      x86, ticketlock: Clean up types and accessors
      x86: Use xadd helper more widely
      x86: Add xadd helper macro
      x86, cmpxchg: Unify cmpxchg into cmpxchg.h
      x86, cmpxchg: Move 64-bit set64_bit() to match 32-bit
      x86, cmpxchg: Move 32-bit __cmpxchg_wrong_size to match 64 bit.
      x86, cmpxchg: <linux/alternative.h> has LOCK_PREFIX

commit 00bf256011d362e7d61824f3cda8514f5d48585d
Author: Seth Jennings <sjenning@linux.vnet.ibm.com>
Date:   Wed Oct 12 14:41:00 2011 -0500

    staging: zcache: remove zcache_direct_reclaim_lock
    
    zcache_do_preload() currently does a spin_trylock() on the
    zcache_direct_reclaim_lock. Holding this lock intends to prevent
    shrink_zcache_memory() from evicting zbud pages as a result
    of a preload.
    
    However, it also prevents two threads from
    executing zcache_do_preload() at the same time.  The first
    thread will obtain the lock and the second thread's spin_trylock()
    will fail (an aborted preload) causing the page to be either lost
    (cleancache) or pushed out to the swap device (frontswap). It
    also doesn't ensure that the call to shrink_zcache_memory() is
    on the same thread as the call to zcache_do_preload().
    
    Additional, there is no need for this mechanism because all
    zcache_do_preload() calls that come down from cleancache already
    have PF_MEMALLOC set in the process flags which prevents
    direct reclaim in the memory manager. If the zcache_do_preload()
    call is done from the frontswap path, we _want_ reclaim to be
    done (which it isn't right now).
    
    This patch removes the zcache_direct_reclaim_lock and related
    statistics in zcache.
    
    Based on v3.1-rc8
    
    Signed-off-by: Seth Jennings <sjenning@linux.vnet.ibm.com>
    Reviewed-by: Dave Hansen <dave@linux.vnet.ibm.com>
    Acked-by: Dan Magenheimer <dan.magenheimer@oracle.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 229855d6f3b40d01a903120c433d75e483a0b06d
Author: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
Date:   Tue Jul 13 15:14:26 2010 -0700

    x86, ticketlock: Make __ticket_spin_trylock common
    
    Make trylock code common regardless of ticket size.
    
    (Also, rename arch_spinlock.slock to head_tail.)
    
    Signed-off-by: Jeremy Fitzhardinge <jeremy.fitzhardinge@citrix.com>
    Link: http://lkml.kernel.org/r/4E5BCC40.3030501@goop.org
    Signed-off-by: H. Peter Anvin <hpa@linux.intel.com>

commit df013ffb8119c89f062ab05b7f544704315db47b
Author: Huang Ying <ying.huang@intel.com>
Date:   Wed Jul 13 13:14:22 2011 +0800

    Add Kconfig option ARCH_HAVE_NMI_SAFE_CMPXCHG
    
    cmpxchg() is widely used by lockless code, including NMI-safe lockless
    code.  But on some architectures, the cmpxchg() implementation is not
    NMI-safe, on these architectures the lockless code may need a
    spin_trylock_irqsave() based implementation.
    
    This patch adds a Kconfig option: ARCH_HAVE_NMI_SAFE_CMPXCHG, so that
    NMI-safe lockless code can depend on it or provide different
    implementation according to it.
    
    On many architectures, cmpxchg is only NMI-safe for several specific
    operand sizes. So, ARCH_HAVE_NMI_SAFE_CMPXCHG define in this patch
    only guarantees cmpxchg is NMI-safe for sizeof(unsigned long).
    
    Signed-off-by: Huang Ying <ying.huang@intel.com>
    Acked-by: Mike Frysinger <vapier@gentoo.org>
    Acked-by: Paul Mundt <lethal@linux-sh.org>
    Acked-by: Hans-Christian Egtvedt <hans-christian.egtvedt@atmel.com>
    Acked-by: Benjamin Herrenschmidt <benh@kernel.crashing.org>
    Acked-by: Chris Metcalf <cmetcalf@tilera.com>
    Acked-by: Richard Henderson <rth@twiddle.net>
    CC: Mikael Starvik <starvik@axis.com>
    Acked-by: David Howells <dhowells@redhat.com>
    CC: Yoshinori Sato <ysato@users.sourceforge.jp>
    CC: Tony Luck <tony.luck@intel.com>
    CC: Hirokazu Takata <takata@linux-m32r.org>
    CC: Geert Uytterhoeven <geert@linux-m68k.org>
    CC: Michal Simek <monstr@monstr.eu>
    Acked-by: Ralf Baechle <ralf@linux-mips.org>
    CC: Kyle McMartin <kyle@mcmartin.ca>
    CC: Martin Schwidefsky <schwidefsky@de.ibm.com>
    CC: Chen Liqin <liqin.chen@sunplusct.com>
    CC: "David S. Miller" <davem@davemloft.net>
    CC: Ingo Molnar <mingo@redhat.com>
    CC: Chris Zankel <chris@zankel.net>
    Signed-off-by: Len Brown <len.brown@intel.com>

commit 0185a6fcc949e606b4de21afc01b2cb1bf632f73
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Jun 22 11:55:50 2011 +0100

    Fix CPU spinlock lockups on secondary CPU bringup
    
    commit 1b19ca9f0bdab7d5035821e1ec8f39df9a6e3ee0 upstream.
    
    Secondary CPU bringup typically calls calibrate_delay() during its
    initialization.  However, calibrate_delay() modifies a global variable
    (loops_per_jiffy) used for udelay() and __delay().
    
    A side effect of 71c696b1 ("calibrate: extract fall-back calculation
    into own helper") introduced in the 2.6.39 merge window means that we
    end up with a substantial period where loops_per_jiffy is zero.  This
    causes the spinlock debugging code to malfunction:
    
            u64 loops = loops_per_jiffy * HZ;
            for (;;) {
                    for (i = 0; i < loops; i++) {
                            if (arch_spin_trylock(&lock->raw_lock))
                                    return;
                            __delay(1);
                    }
                    ...
            }
    
    by never calling arch_spin_trylock() - resulting in the CPU locking
    up in an infinite loop inside __spin_lock_debug().
    
    Work around this by only writing to loops_per_jiffy only once we have
    completed all the calibration decisions.
    
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    --
    Better solutions (such as omitting the calibration for secondary CPUs,
    or arranging for calibrate_delay() to return the LPJ value and leave
    it to the caller to decide where to store it) are a possibility, but
    would be much more invasive into each architecture.
    
    I think this is the best solution for -rc and stable, but it should be
    revisited for the next merge window.
    
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 7fd29aa920273b70be50c14c4b7e2213fb6623ce
Author: Nicholas Bellinger <nab@linux-iscsi.org>
Date:   Thu Jun 23 23:48:32 2011 +0000

    target: Fix transport_get_lun_for_tmr failure cases
    
    This patch fixes two possible NULL pointer dereferences in target v4.0
    code where se_tmr release path in core_tmr_release_req() can OOPs upon
    transport_get_lun_for_tmr() failure by attempting to access se_device or
    se_tmr->tmr_list without a valid member of se_device->tmr_list during
    transport_free_se_cmd() release.  This patch moves the se_tmr->tmr_dev
    pointer assignment in transport_get_lun_for_tmr() until after possible
    -ENODEV failures during unpacked_lun lookup.
    
    This addresses an OOPs originally reported with LIO v4.1 upstream on
    .39 code here:
    
        TARGET_CORE[qla2xxx]: Detected NON_EXISTENT_LUN Access for 0x00000000
        BUG: unable to handle kernel NULL pointer dereference at 0000000000000550
        IP: [<ffffffff81035ec4>] __ticket_spin_trylock+0x4/0x20
        PGD 0
        Oops: 0000 [#1] SMP
        last sysfs file: /sys/devices/system/cpu/cpu23/cache/index2/shared_cpu_map
        CPU 1
        Modules linked in: netconsole target_core_pscsi target_core_file
    tcm_qla2xxx target_core_iblock tcm_loop target_core_mod configfs
    ipmi_devintf ipmi_si ipmi_msghandler serio_raw i7core_edac ioatdma dca
    edac_core ps_bdrv ses enclosure usbhid usb_storage ahci qla2xxx hid
    uas e1000e mpt2sas libahci mlx4_core scsi_transport_fc
    scsi_transport_sas raid_class scsi_tgt [last unloaded: netconsole]
    
        Pid: 0, comm: kworker/0:0 Tainted: G        W   2.6.39+ #1 Xyratex Storage Server
        RIP: 0010:[<ffffffff81035ec4>] [<ffffffff81035ec4>]__ticket_spin_trylock+0x4/0x20
        RSP: 0018:ffff88063e803c08  EFLAGS: 00010286
        RAX: ffff880619ab45e0 RBX: 0000000000000550 RCX: 0000000000000000
        RDX: 0000000000000000 RSI: 0000000000000000 RDI: 0000000000000550
        RBP: ffff88063e803c08 R08: 0000000000000002 R09: 0000000000000000
        R10: 0000000000000000 R11: 0000000000000001 R12: 0000000000000568
        R13: 0000000000000001 R14: 0000000000000000 R15: ffff88060cd96a20
        FS:  0000000000000000(0000) GS:ffff88063e800000(0000) knlGS:0000000000000000
        CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
        CR2: 0000000000000550 CR3: 0000000001a03000 CR4: 00000000000006e0
        DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
        DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
        Process kworker/0:0 (pid: 0, threadinfo ffff880619ab8000, task ffff880619ab45e0)
        Stack:
         ffff88063e803c28 ffffffff812cf039 0000000000000550 0000000000000568
         ffff88063e803c58 ffffffff8157071e ffffffffa028a1dc ffff88060f7e4600
         0000000000000550 ffff880616961480 ffff88063e803c78 ffffffffa028a1dc
        Call Trace:
    <IRQ>
         [<ffffffff812cf039>] do_raw_spin_trylock+0x19/0x50
         [<ffffffff8157071e>] _raw_spin_lock+0x3e/0x70
         [<ffffffffa028a1dc>] ? core_tmr_release_req+0x2c/0x60 [target_core_mod]
         [<ffffffffa028a1dc>] core_tmr_release_req+0x2c/0x60 [target_core_mod]
         [<ffffffffa028d0d2>] transport_free_se_cmd+0x22/0x50 [target_core_mod]
         [<ffffffffa028d120>] transport_release_cmd_to_pool+0x20/0x40 [target_core_mod]
         [<ffffffffa028e525>] transport_generic_free_cmd+0xa5/0xb0 [target_core_mod]
         [<ffffffffa0147cc4>] tcm_qla2xxx_handle_tmr+0xc4/0xd0 [tcm_qla2xxx]
         [<ffffffffa0191ba3>] __qla24xx_handle_abts+0xd3/0x150 [qla2xxx]
         [<ffffffffa0197651>] qla_tgt_response_pkt+0x171/0x520 [qla2xxx]
         [<ffffffffa0197a2d>] qla_tgt_response_pkt_all_vps+0x2d/0x220 [qla2xxx]
         [<ffffffffa0171dd3>] qla24xx_process_response_queue+0x1a3/0x670 [qla2xxx]
         [<ffffffffa0196281>] ? qla24xx_atio_pkt+0x81/0x120 [qla2xxx]
         [<ffffffffa0174025>] ? qla24xx_msix_default+0x45/0x2a0 [qla2xxx]
         [<ffffffffa0174198>] qla24xx_msix_default+0x1b8/0x2a0 [qla2xxx]
         [<ffffffff810dadb4>] handle_irq_event_percpu+0x54/0x210
         [<ffffffff810dafb8>] handle_irq_event+0x48/0x70
         [<ffffffff810dd5ee>] ? handle_edge_irq+0x1e/0x110
         [<ffffffff810dd647>] handle_edge_irq+0x77/0x110
         [<ffffffff8100d362>] handle_irq+0x22/0x40
         [<ffffffff8157b28d>] do_IRQ+0x5d/0xe0
         [<ffffffff81571413>] common_interrupt+0x13/0x13
    <EOI>
         [<ffffffff813003f7>] ? intel_idle+0xd7/0x130
         [<ffffffff813003f0>] ? intel_idle+0xd0/0x130
         [<ffffffff8144832b>] cpuidle_idle_call+0xab/0x1c0
         [<ffffffff8100a26b>] cpu_idle+0xab/0xf0
         [<ffffffff81566c59>] start_secondary+0x1cb/0x1d2
    
    Reported-by: Roland Dreier <roland@purestorage.com>
    Signed-off-by: Nicholas Bellinger <nab@linux-iscsi.org>

commit 1b19ca9f0bdab7d5035821e1ec8f39df9a6e3ee0
Author: Russell King <rmk+kernel@arm.linux.org.uk>
Date:   Wed Jun 22 11:55:50 2011 +0100

    Fix CPU spinlock lockups on secondary CPU bringup
    
    Secondary CPU bringup typically calls calibrate_delay() during its
    initialization.  However, calibrate_delay() modifies a global variable
    (loops_per_jiffy) used for udelay() and __delay().
    
    A side effect of 71c696b1 ("calibrate: extract fall-back calculation
    into own helper") introduced in the 2.6.39 merge window means that we
    end up with a substantial period where loops_per_jiffy is zero.  This
    causes the spinlock debugging code to malfunction:
    
            u64 loops = loops_per_jiffy * HZ;
            for (;;) {
                    for (i = 0; i < loops; i++) {
                            if (arch_spin_trylock(&lock->raw_lock))
                                    return;
                            __delay(1);
                    }
                    ...
            }
    
    by never calling arch_spin_trylock() - resulting in the CPU locking
    up in an infinite loop inside __spin_lock_debug().
    
    Work around this by only writing to loops_per_jiffy only once we have
    completed all the calibration decisions.
    
    Tested-by: Santosh Shilimkar <santosh.shilimkar@ti.com>
    Signed-off-by: Russell King <rmk+kernel@arm.linux.org.uk>
    Cc: <stable@kernel.org> (2.6.39-stable)
    --
    Better solutions (such as omitting the calibration for secondary CPUs,
    or arranging for calibrate_delay() to return the LPJ value and leave
    it to the caller to decide where to store it) are a possibility, but
    would be much more invasive into each architecture.
    
    I think this is the best solution for -rc and stable, but it should be
    revisited for the next merge window.
    
     init/calibrate.c |   14 ++++++++------
     1 files changed, 8 insertions(+), 6 deletions(-)
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit cb96632c185f13f746d009ec1125539e0b5cd899
Author: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
Date:   Thu Apr 21 14:10:08 2011 +0900

    usb: renesas_usbhs: modify spinlock method
    
    Current renesas_usbhs driver was using spin_trylock to avoid
    dead lock / nest lock.
    But acording to CONFIG_DEBUG_SPINLOCK, it is BUG under UP environment.
    This patch add usbhsg_trylock to avoid this issue.
    
    Signed-off-by: Kuninori Morimoto <kuninori.morimoto.gx@renesas.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit d3678758048308049cdad31ec3eae063be17c0db
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Tue Dec 21 23:38:37 2010 -0200

    perf test: Look forward for symbol aliases
    
    Not just before, fixing these false positives:
    
    [acme@mica linux]$ perf test -v 1
     1: vmlinux symtab matches kallsyms:
    --- start ---
    Looking at the vmlinux_path (6 entries long)
    Using //lib/modules/2.6.37-rc5-00180-ge06b6bf/build/vmlinux for symbols
    0xffffffff81058dc0: diff name v: sys_vm86old k: sys_ni_syscall
    0xffffffff81058dc0: diff name v: sys_vm86 k: sys_ni_syscall
    0xffffffff81058dc0: diff name v: sys_subpage_prot k: sys_ni_syscall
    0xffffffff810b5f7c: diff name v: probe_kernel_write k: __probe_kernel_write
    0xffffffff810b5fe5: diff name v: probe_kernel_read k: __probe_kernel_read
    0xffffffff811bc380: diff name v: __memset k: memset
    0xffffffff81384a98: diff name v: __sched_text_start k: sleep_on_common
    0xffffffff81386750: diff name v: __sched_text_end k: _raw_spin_trylock
    0xffffffff8138cee8: diff name v: __irqentry_text_start k: do_IRQ
    0xffffffff8138f079: diff name v: __start_notes k: _etext
    0xffffffff8138f079: diff name v: __stop_notes k: _etext
    ---- end ----
    vmlinux symtab matches kallsyms: FAILED!
    
    [acme@mica linux]$
    
    Some are weak functions, others are just markers, etc. They get in the rb tree
    with the same addr, so we need to look around to find the symbol with the same
    name.
    
    We were looking just at the previous entries with the same addr, look forward
    too.
    
    Cc: Frederic Weisbecker <fweisbec@gmail.com>
    Cc: Han Pingtian <phan@redhat.com>
    Cc: Mike Galbraith <efault@gmx.de>
    Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Stephane Eranian <eranian@google.com>
    LKML-Reference: <new-submission>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>

commit 7b7422a566aa0dc1e582ce263d4c7ff4a772700a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jan 26 12:51:10 2010 +0100

    clocksource: Prevent potential kgdb dead lock
    
    commit 0f8e8ef7 (clocksource: Simplify clocksource watchdog resume
    logic) introduced a potential kgdb dead lock. When the kernel is
    stopped by kgdb inside code which holds watchdog_lock then kgdb dead
    locks in clocksource_resume_watchdog().
    
    clocksource_resume_watchdog() is called from kbdg via
    clocksource_touch_watchdog() to avoid that the clock source watchdog
    marks TSC unstable after the kernel has been stopped.
    
    Solve this by replacing spin_lock with a spin_trylock and just return
    in case the lock is held. Not resetting the watchdog might result in
    TSC becoming marked unstable, but that's an acceptable penalty for
    using kgdb.
    
    The timekeeping is anyway easily screwed up by kgdb when the system
    uses either jiffies or a clock source which wraps in short intervals
    (e.g. pm_timer wraps about every 4.6s), so we really do not have to
    worry about that occasional TSC marked unstable side effect.
    
    The second caller of clocksource_resume_watchdog() is
    clocksource_resume(). The trylock is safe here as well because the
    system is UP at this point, interrupts are disabled and nothing else
    can hold watchdog_lock().
    
    Reported-by: Jason Wessel <jason.wessel@windriver.com>
    LKML-Reference: <1264480000-6997-4-git-send-email-jason.wessel@windriver.com>
    Cc: kgdb-bugreport@lists.sourceforge.net
    Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: John Stultz <johnstul@us.ibm.com>
    Cc: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

commit c541f7c75c5d41c9a3f2c7599ee425547cc49a42
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Nov 2 13:52:29 2009 -0800

    rcu: Fix note_new_gpnum() uses of ->gpnum
    
    commit 9160306e6f5b68bb64630c9031c517ca1cf463db upstream.
    
    Impose a clear locking design on the note_new_gpnum()
    function's use of the ->gpnum counter.  This is done by updating
    rdp->gpnum only from the corresponding leaf rcu_node structure's
    rnp->gpnum field, and even then only under the protection of
    that same rcu_node structure's ->lock field.  Performance and
    scalability are maintained using a form of double-checked
    locking, and excessive spinning is avoided by use of the
    spin_trylock() function.  The use of spin_trylock() is safe due
    to the fact that CPUs who fail to acquire this lock will try
    again later. The hierarchical nature of the rcu_node data
    structure limits contention (which could be limited further if
    need be using the RCU_FANOUT kernel parameter).
    
    Without this patch, obscure but quite possible races could
    result in a quiescent state that occurred during one grace
    period to be accounted to the following grace period, causing
    this following grace period to end prematurely.  Not good!
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    LKML-Reference: <12571987492350-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 29671f22a8b6522db3b126a3fdfb208759ce46e3
Author: Amerigo Wang <amwang@redhat.com>
Date:   Mon Dec 14 18:00:21 2009 -0800

    rwsem: fix rwsem_is_locked() bugs
    
    rwsem_is_locked() tests ->activity without locks, so we should always keep
    ->activity consistent.  However, the code in __rwsem_do_wake() breaks this
    rule, it updates ->activity after _all_ readers waken up, this may give
    some reader a wrong ->activity value, thus cause rwsem_is_locked() behaves
    wrong.
    
    Quote from Andrew:
    
    "
    - we have one or more processes sleeping in down_read(), waiting for access.
    
    - we wake one or more processes up without altering ->activity
    
    - they start to run and they do rwsem_is_locked().  This incorrectly
      returns "false", because the waker process is still crunching away in
      __rwsem_do_wake().
    
    - the waker now alters ->activity, but it was too late.
    "
    
    So we need get a spinlock to protect this.  And rwsem_is_locked() should
    not block, thus we use spin_trylock_irqsave().
    
    [akpm@linux-foundation.org: simplify code]
    Reported-by: Brian Behlendorf <behlendorf1@llnl.gov>
    Cc: Ben Woodard <bwoodard@llnl.gov>
    Cc: David Howells <dhowells@redhat.com>
    Signed-off-by: WANG Cong <amwang@redhat.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 9160306e6f5b68bb64630c9031c517ca1cf463db
Author: Paul E. McKenney <paulmck@kernel.org>
Date:   Mon Nov 2 13:52:29 2009 -0800

    rcu: Fix note_new_gpnum() uses of ->gpnum
    
    Impose a clear locking design on the note_new_gpnum()
    function's use of the ->gpnum counter.  This is done by updating
    rdp->gpnum only from the corresponding leaf rcu_node structure's
    rnp->gpnum field, and even then only under the protection of
    that same rcu_node structure's ->lock field.  Performance and
    scalability are maintained using a form of double-checked
    locking, and excessive spinning is avoided by use of the
    spin_trylock() function.  The use of spin_trylock() is safe due
    to the fact that CPUs who fail to acquire this lock will try
    again later. The hierarchical nature of the rcu_node data
    structure limits contention (which could be limited further if
    need be using the RCU_FANOUT kernel parameter).
    
    Without this patch, obscure but quite possible races could
    result in a quiescent state that occurred during one grace
    period to be accounted to the following grace period, causing
    this following grace period to end prematurely.  Not good!
    
    Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
    Cc: laijs@cn.fujitsu.com
    Cc: dipankar@in.ibm.com
    Cc: mathieu.desnoyers@polymtl.ca
    Cc: josh@joshtriplett.org
    Cc: dvhltc@us.ibm.com
    Cc: niv@us.ibm.com
    Cc: peterz@infradead.org
    Cc: rostedt@goodmis.org
    Cc: Valdis.Kletnieks@vt.edu
    Cc: dhowells@redhat.com
    Cc: <stable@kernel.org> # .32.x
    LKML-Reference: <12571987492350-git-send-email->
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit b8883a65be2d925ea82b14ca0068ce9a6c8bac1f
Author: Jiri Slaby <jirislaby@kernel.org>
Date:   Wed Nov 4 08:37:31 2009 -0800

    NET: sungem, use spin_trylock_irqsave
    
    Use spin_trylock_irqsave instead of open-coded
    local_irq_save+spin_trylock.
    
    Signed-off-by: Jiri Slaby <jirislaby@gmail.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 4871953c0ef2cafeb37bbe186d9d13dcb24fc2c5
Author: Dongdong Deng <dongdong.deng@windriver.com>
Date:   Sun Aug 23 19:49:07 2009 -0700

    drivers/net: fixed drivers that support netpoll use ndo_start_xmit()
    
    The NETPOLL API requires that interrupts remain disabled in
    netpoll_send_skb(). The use of "A functions set" in the NETPOLL API
    callbacks causes the interrupts to get enabled and can lead to kernel
    instability.
    
    The solution is to use "B functions set" to prevent the irqs from
    getting enabled while in netpoll_send_skb().
    
    A functions set:
    local_irq_disable()/local_irq_enable()
    spin_lock_irq()/spin_unlock_irq()
    spin_trylock_irq()/spin_unlock_irq()
    
    B functions set:
    local_irq_save()/local_irq_restore()
    spin_lock_irqsave()/spin_unlock_irqrestore()
    spin_trylock_irqsave()/spin_unlock_irqrestore()
    
    Signed-off-by: Dongdong Deng <dongdong.deng@windriver.com>
    Acked-by: Matt Mackall <mpm@selenic.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit ca8b86c5ae91b3041790085d296f5b8fbf71570b
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Wed Jul 15 12:29:06 2009 +0800

    tracing/function: Fix the return value of ftrace_trace_onoff_callback()
    
    commit 04aef32d39cc4ef80087c0ce8ed113c6d64f1a6b upstream.
    
    ftrace_trace_onoff_callback() will return an error even if we do the
    right operation, for example:
    
     # echo _spin_*:traceon:10 > set_ftrace_filter
     -bash: echo: write error: Invalid argument
     # cat set_ftrace_filter
     #### all functions enabled ####
     _spin_trylock_bh:traceon:count=10
     _spin_unlock_irq:traceon:count=10
     _spin_unlock_bh:traceon:count=10
     _spin_lock_irq:traceon:count=10
     _spin_unlock:traceon:count=10
     _spin_trylock:traceon:count=10
     _spin_unlock_irqrestore:traceon:count=10
     _spin_lock_irqsave:traceon:count=10
     _spin_lock_bh:traceon:count=10
     _spin_lock:traceon:count=10
    
    We want to set _spin_*:traceon:10 to set_ftrace_filter, it complains
    with "Invalid argument", but the operation is successful.
    
    This is because ftrace_process_regex() returns the number of functions that
    matched the pattern. If the number is not 0, this value is returned
    by ftrace_regex_write() whereas we want to return the number of bytes
    virtually written.
    Also the file offset pointer is not updated in this case.
    
    If the number of matched functions is lower than the number of bytes written
    by the user, this results to a reprocessing of the string given by the user with
    a lower size, leading to a malformed ftrace regex and then a -EINVAL returned.
    
    So, this patch fixes it by returning 0 if no error occured.
    The fix also applies on 2.6.30
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

commit 04aef32d39cc4ef80087c0ce8ed113c6d64f1a6b
Author: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
Date:   Wed Jul 15 12:29:06 2009 +0800

    tracing/function: Fix the return value of ftrace_trace_onoff_callback()
    
    ftrace_trace_onoff_callback() will return an error even if we do the
    right operation, for example:
    
     # echo _spin_*:traceon:10 > set_ftrace_filter
     -bash: echo: write error: Invalid argument
     # cat set_ftrace_filter
     #### all functions enabled ####
     _spin_trylock_bh:traceon:count=10
     _spin_unlock_irq:traceon:count=10
     _spin_unlock_bh:traceon:count=10
     _spin_lock_irq:traceon:count=10
     _spin_unlock:traceon:count=10
     _spin_trylock:traceon:count=10
     _spin_unlock_irqrestore:traceon:count=10
     _spin_lock_irqsave:traceon:count=10
     _spin_lock_bh:traceon:count=10
     _spin_lock:traceon:count=10
    
    We want to set _spin_*:traceon:10 to set_ftrace_filter, it complains
    with "Invalid argument", but the operation is successful.
    
    This is because ftrace_process_regex() returns the number of functions that
    matched the pattern. If the number is not 0, this value is returned
    by ftrace_regex_write() whereas we want to return the number of bytes
    virtually written.
    Also the file offset pointer is not updated in this case.
    
    If the number of matched functions is lower than the number of bytes written
    by the user, this results to a reprocessing of the string given by the user with
    a lower size, leading to a malformed ftrace regex and then a -EINVAL returned.
    
    So, this patch fixes it by returning 0 if no error occured.
    The fix also applies on 2.6.30
    
    Signed-off-by: Xiao Guangrong <xiaoguangrong@cn.fujitsu.com>
    Reviewed-by: Li Zefan <lizf@cn.fujitsu.com>
    Cc: stable@kernel.org
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>

commit 465440d2720543669841db5b0691ba41892ed0ae
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Mon May 25 20:57:21 2009 +0000

    mlx4_en: Fix a kernel panic when waking tx queue
    
    When the transmit queue gets full we enable interrupts for TX completions
    There was a race that we handled the TX queue both from the interrupt context
    and from the transmit function. Using "spin_trylock_irq()" ensures this
    doesn't happen.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 45141d4667d208421ca787a3301542b6a5e0b112
Author: Steven Rostedt <srostedt@redhat.com>
Date:   Thu Feb 12 13:19:48 2009 -0500

    ring-buffer: rename label out_unlock to out_reset
    
    Impact: clean up
    
    While reviewing the ring buffer code, I thougth I saw a bug with
    
            if (!__raw_spin_trylock(&cpu_buffer->lock))
                    goto out_unlock;
    
    But I forgot that we use a variable "lock_taken" that is set if
    the spinlock is taken, and only unlock it if that variable is set.
    
    To avoid further confusion from other reviewers, this patch
    renames the label out_unlock with out_reset, which is the more
    appropriate name.
    
    Signed-off-by: Steven Rostedt <srostedt@redhat.com>

commit 48374ddce72e278e29080e3177e74a13c034d8b4
Author: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
Date:   Thu Dec 25 18:13:45 2008 -0800

    mlx4_en: Removed TX locking when polling TX cq
    
    There is no need to synchronize the polling with the transmit
    function. The only place to synchronize is when we process
    the cq from the transmit function. Also removed spin_lock_irq,
    and using spin_trylock, if somebody else is already processing the cq,
    no need to wait for it to finish.
    
    Signed-off-by: Yevgeny Petrilin <yevgenyp@mellanox.co.il>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 1fd8f2a3f9a91b287a876cef830b21baafc8a799
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Wed Dec 3 23:45:11 2008 +0100

    tracing/function-graph-tracer: handle ftrace_printk entries
    
    Handle the TRACE_PRINT entries from the function grapg tracer
    and output them as a C comment just below the function that called
    it, as if it was a comment inside this function.
    
    Example with an ftrace_printk inside might_sleep() function:
    
    void __might_sleep(char *file, int line)
    {
            static unsigned long prev_jiffy;        /* ratelimiting */
    
            ftrace_printk("Hi I'm a comment in might_sleep() :-)");
    
    A chunk of a resulting trace:
    
     0)               |        _reiserfs_free_block() {
     0)               |          reiserfs_read_bitmap_block() {
     0)               |            __bread() {
     0)               |              __getblk() {
     0)               |                __find_get_block() {
     0)   0.698 us    |                  mark_page_accessed();
     0)   2.267 us    |                }
     0)               |                __might_sleep() {
     0)               |                  /* Hi I'm a comment in might_sleep() :-) */
     0)   1.321 us    |                }
     0)   5.872 us    |              }
     0)   7.313 us    |            }
     0)   8.718 us    |          }
    
    And this patch brings two minor fixes:
    
    - The newline after a switch-out task has disappeared
    - The "|" sign just before the cpu number on task-switch has been deleted.
    
     0)   0.616 us    |                pick_next_task_rt();
     0)   1.457 us    |                _spin_trylock();
     0)   0.653 us    |                _spin_unlock();
     0)   0.728 us    |                _spin_trylock();
     0)   0.631 us    |                _spin_unlock();
     0)   0.729 us    |                native_load_sp0();
     0)   0.593 us    |                native_load_tls();
     ------------------------------------------
     0)    cat-2834    =>   migrati-3
     ------------------------------------------
    
     0)               |    finish_task_switch() {
     0)   0.841 us    |      _spin_unlock_irq();
     0)   0.616 us    |      post_schedule_rt();
     0)   3.882 us    |    }
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Acked-by: Steven Rostedt <rostedt@goodmis.org>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit 83a8df618eb04bd2819a758f3b409b1449862434
Author: Frederic Weisbecker <fweisbec@gmail.com>
Date:   Thu Nov 27 01:46:33 2008 +0100

    tracing/function-graph-tracer: enhancements for the trace output
    
    Impact: enhance the output of the graph-tracer
    
    This patch applies some ideas of Ingo Molnar and Steven Rostedt.
    
    * Output leaf functions in one line with parenthesis, semicolon and duration
      output.
    
    * Add a second column (after cpu) for an overhead sign.
      if duration > 100 us, "!"
      if duration > 10 us, "+"
      else " "
    
    * Print output in us with remaining nanosec: u.n
    
    * Print duration on the right end, following the indentation of the functions.
      Use also visual clues: "-" on entry call (no duration to output) and "+" on
      return (duration output).
    
    The name of the tracer has been fixed as well: function-branch becomes
    function_branch.
    
    Here is an example of the new output:
    
    CPU[000]           dequeue_entity() {                    -
    CPU[000]             update_curr() {                    -
    CPU[000]               update_min_vruntime();                    + 0.512 us
    CPU[000]             }                                + 1.504 us
    CPU[000]             clear_buddies();                    + 0.481 us
    CPU[000]             update_min_vruntime();                    + 0.504 us
    CPU[000]           }                                + 4.557 us
    CPU[000]           hrtick_update() {                    -
    CPU[000]             hrtick_start_fair();                    + 0.489 us
    CPU[000]           }                                + 1.443 us
    CPU[000] +       }                                + 14.655 us
    CPU[000] +     }                                + 15.678 us
    CPU[000] +   }                                + 16.686 us
    CPU[000]     msecs_to_jiffies();                    + 0.481 us
    CPU[000]     put_prev_task_fair();                    + 0.504 us
    CPU[000]     pick_next_task_fair();                    + 0.482 us
    CPU[000]     pick_next_task_rt();                    + 0.504 us
    CPU[000]     pick_next_task_fair();                    + 0.481 us
    CPU[000]     pick_next_task_idle();                    + 0.489 us
    CPU[000]     _spin_trylock();                    + 0.655 us
    CPU[000]     _spin_unlock();                    + 0.609 us
    
    CPU[000]  ------------8<---------- thread bash-2794 ------------8<----------
    
    CPU[000]               finish_task_switch() {                    -
    CPU[000]                 _spin_unlock_irq();                    + 0.722 us
    CPU[000]               }                                + 2.369 us
    CPU[000] !           }                                + 501972.605 us
    CPU[000] !         }                                + 501973.763 us
    CPU[000]           copy_from_read_buf() {                    -
    CPU[000]             _spin_lock_irqsave();                    + 0.670 us
    CPU[000]             _spin_unlock_irqrestore();                    + 0.699 us
    CPU[000]             copy_to_user() {                    -
    CPU[000]               might_fault() {                    -
    CPU[000]                 __might_sleep();                    + 0.503 us
    CPU[000]               }                                + 1.632 us
    CPU[000]               __copy_to_user_ll();                    + 0.542 us
    CPU[000]             }                                + 3.858 us
    CPU[000]             tty_audit_add_data() {                    -
    CPU[000]               _spin_lock_irq();                    + 0.609 us
    CPU[000]               _spin_unlock_irq();                    + 0.624 us
    CPU[000]             }                                + 3.196 us
    CPU[000]             _spin_lock_irqsave();                    + 0.624 us
    CPU[000]             _spin_unlock_irqrestore();                    + 0.625 us
    CPU[000] +         }                                + 13.611 us
    CPU[000]           copy_from_read_buf() {                    -
    CPU[000]             _spin_lock_irqsave();                    + 0.624 us
    CPU[000]             _spin_unlock_irqrestore();                    + 0.616 us
    CPU[000]           }                                + 2.820 us
    CPU[000]
    
    Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>

commit d98d38f2014ab79f28c126ff175d034891f7aefc
Author: Arjan van de Ven <arjan@linux.intel.com>
Date:   Wed Oct 29 14:24:09 2008 -0700

    mutex: improve header comment to be actually informative about the API
    
    Impact: improve documentation
    
    It's nice to say that mutex_trylock follows the spin_trylock convention.
    It's a lot nicer if the comment also says which that is...  make it so.
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>

commit 64f26f745084872b916cd1bef6054e21b15c5784
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Thu Jul 24 10:09:43 2008 -0400

    Btrfs: Use assert_spin_locked instead of spin_trylock
    
    On UP systems spin_trylock always succeeds
    
    Signed-off-by: Chris Mason <chris.mason@oracle.com>

commit a76d7345a3f92bb8352f200e7b2e380dddcd7e36
Author: Stephen Hemminger <shemminger@vyatta.com>
Date:   Tue Jul 22 14:34:35 2008 -0700

    ipv6: use spin_trylock_bh
    
    Now there is spin_trylock_bh, use it rather than open coding.
    
    Signed-off-by: Stephen Hemminger <shemminger@vyatta.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit 50fd4407b8bfbde7c1a0bfe4f24de7df37164342
Author: David S. Miller <davem@davemloft.net>
Date:   Thu Mar 27 17:42:50 2008 -0700

    [NET]: Use local_irq_{save,restore}() in napi_complete().
    
    Based upon a lockdep report.
    
    Since ->poll() can be invoked from netpoll with interrupts
    disabled, we must not unconditionally enable interrupts
    in napi_complete().
    
    Instead we must use local_irq_{save,restore}().
    
    Noticed by Peter Zijlstra:
    
    <irqs disabled>
    
      netpoll_poll()
        poll_napi()
          spin_trylock(&napi->poll_lock)
          poll_one_napi()
            napi->poll() := sky2_poll()
              napi_complete()
                local_irq_disable()
                local_irq_enable() <--- *BUG*
    
      <irq>
        irq_exit()
          do_softirq()
            net_rx_action()
              spin_lock(&napi->poll_lock) <--- Deadlock!
    
    Because we still hold the lock....
    
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f5a3ea6f966700ae82504202fdd827f2d3c79e66
Author: David Woodhouse <dwmw2@infradead.org>
Date:   Thu Dec 13 01:53:57 2007 -0500

    libertas: use spin_is_locked() instead of spin_trylock() in lbs_interrupt()
    
    We get scary warnings on UP if we use spin_trylock() and find, as we
    hoped, that the lock in question is already locked.
    
    Signed-off-by: David Woodhouse <dwmw2@infradead.org>
    Signed-off-by: John W. Linville <linville@tuxdriver.com>

commit 5845b677cf7f64a0f104609e1dfe02a439f69f71
Author: Ingo Molnar <mingo@elte.hu>
Date:   Tue Jul 31 19:07:02 2007 -0500

    atl1: use spin_trylock_irqsave()
    
    use the simpler spin_trylock_irqsave() API to get the adapter lock.
    
    [ this is also a fix for -rt where adapter->lock is a sleeping lock. ]
    
    Signed-off-by: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Jay Cliburn <jacliburn@bellsouth.net>
    Signed-off-by: Jeff Garzik <jeff@garzik.org>

commit e1f4a88c5a15a86124a95ea712213bb7dab2ad99
Author: Satyam Sharma <ssatyam@cse.iitk.ac.in>
Date:   Sun Jul 15 23:39:24 2007 -0700

    introduce write_trylock_irqsave()
    
    Introduce a write_trylock_irqsave() implementation.  Similar in style to
    the implementation of spin_trylock_irqsave() in mainline.
    
    Signed-off-by: Satyam Sharma <ssatyam@cse.iitk.ac.in>
    Cc: Sripathi Kodi <sripathik@in.ibm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>

commit 13fdc9a74df0fec70f421c6891e184ed8c3b9088
Author: Ursula Braun <braunu@de.ibm.com>
Date:   Sat Jul 14 19:03:41 2007 -0700

    [AF_IUCV]: Avoid deadlock between iucv_path_connect and tasklet.
    
    An iucv deadlock may occur, where one CPU is spinning on the
    iucv_table_lock for iucv_tasklet_fn(), while another CPU is holding
    the iucv_table_lock for an iucv_path_connect() and is waiting for
    the first CPU in an smp_call_function.
    Solution: replace spin_lock in iucv_tasklet_fn by spin_trylock and
    reschedule tasklet in case of non-granted lock.
    
    Signed-off-by: Ursula Braun <braunu@de.ibm.com>
    Acked-by: Frank Pavlic <fpavlic@de.ibm.com>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit f50393fe869ba457cd75569c74c0f9bd2e7f7a0f
Author: Mark Huth <mhuth@mvista.com>
Date:   Tue Mar 6 08:57:26 2007 -0800

    e1000: FIX: Stop raw interrupts disabled nag from RT
    
    Current e1000_xmit_frame spews raw interrupt disabled nag messages when
    used with RT kernel patches.  This patch uses spin_trylock_irqsave,
    which allows RT patches to properly manage the irq semantics.
    
    Signed-off-by: Mark Huth <mhuth@mvista.com>
    Signed-off-by: Auke Kok <auke-jan.h.kok@intel.com>
    Signed-off-by: Jeff Garzik <jeff@garzik.org>

commit ef6edc9746dc2bfdacf44eefd5f881179971c478
Author: Martin Schwidefsky <schwidefsky@de.ibm.com>
Date:   Sat Sep 30 23:27:43 2006 -0700

    [PATCH] Directed yield: cpu_relax variants for spinlocks and rw-locks
    
    On systems running with virtual cpus there is optimization potential in
    regard to spinlocks and rw-locks.  If the virtual cpu that has taken a lock
    is known to a cpu that wants to acquire the same lock it is beneficial to
    yield the timeslice of the virtual cpu in favour of the cpu that has the
    lock (directed yield).
    
    With CONFIG_PREEMPT="n" this can be implemented by the architecture without
    common code changes.  Powerpc already does this.
    
    With CONFIG_PREEMPT="y" the lock loops are coded with _raw_spin_trylock,
    _raw_read_trylock and _raw_write_trylock in kernel/spinlock.c.  If the lock
    could not be taken cpu_relax is called.  A directed yield is not possible
    because cpu_relax doesn't know anything about the lock.  To be able to
    yield the lock in favour of the current lock holder variants of cpu_relax
    for spinlocks and rw-locks are needed.  The new _raw_spin_relax,
    _raw_read_relax and _raw_write_relax primitives differ from cpu_relax
    insofar that they have an argument: a pointer to the lock structure.
    
    Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
    Cc: Ingo Molnar <mingo@elte.hu>
    Cc: Paul Mackerras <paulus@samba.org>
    Cc: Haavard Skinnemoen <hskinnemoen@atmel.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 303912e2a32aa73785b4c4dee15466d944a38a46
Author: Josh Triplett <josh@joshtriplett.org>
Date:   Fri Sep 29 02:01:00 2006 -0700

    [PATCH] Replace _spin_trylock with spin_trylock in the IRQ variants to use __cond_lock
    
    spin_trylock_irq and spin_trylock_irqsave use _spin_trylock, which does not
    use the __cond_lock wrapper annotation and thus does not affect the lock
    context; change them to use spin_trylock instead, which does use
    __cond_lock.
    
    Signed-off-by: Josh Triplett <josh@freedesktop.org>
    Cc: Ingo Molnar <mingo@elte.hu>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit 53c4b2cc7a05c034fd21d104d2ab43ea8cc0e075
Author: Herbert Xu <herbert@gondor.apana.org.au>
Date:   Fri Jul 21 14:55:38 2006 -0700

    [NET]: Fix reversed error test in netif_tx_trylock
    
    A non-zero return value indicates success from spin_trylock,
    not error.
    
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>

commit c34d1b4d165c67b966bca4aba026443d7ff161eb
Author: Hugh Dickins <hugh@veritas.com>
Date:   Sat Oct 29 18:16:32 2005 -0700

    [PATCH] mm: kill check_user_page_readable
    
    check_user_page_readable is a problematic variant of follow_page.  It's used
    only by oprofile's i386 and arm backtrace code, at interrupt time, to
    establish whether a userspace stackframe is currently readable.
    
    This is problematic, because we want to push the page_table_lock down inside
    follow_page, and later split it; whereas oprofile is doing a spin_trylock on
    it (in the i386 case, forgotten in the arm case), and needs that to pin
    perhaps two pages spanned by the stackframe (which might be covered by
    different locks when we split).
    
    I think oprofile is going about this in the wrong way: it doesn't need to know
    the area is readable (neither i386 nor arm uses read protection of user
    pages), it doesn't need to pin the memory, it should simply
    __copy_from_user_inatomic, and see if that succeeds or not.  Sorry, but I've
    not got around to devising the sparse __user annotations for this.
    
    Then we can eliminate check_user_page_readable, and return to a single
    follow_page without the __follow_page variants.
    
    Signed-off-by: Hugh Dickins <hugh@veritas.com>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>

commit a20583a7c2e35d80b1dfc1f60c9729498838725e
Author: Roland Dreier <rolandd@cisco.com>
Date:   Sat Oct 29 13:54:40 2005 -0700

    [IPoIB] use spin_trylock_irqsave()
    
    Use spin_trylock_irqsave() in ipoib_start_xmit() instead of
    reinventing it out of local_irq_save(), spin_trylock() and
    local_irq_restore().
    
    Signed-off-by: Roland Dreier <rolandd@cisco.com>
